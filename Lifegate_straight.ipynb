{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMXanscsbCkMCwK5xJZS07w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajagota7/Shaping/blob/main/Lifegate_straight.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "zZ2S2CI8K_jT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsHzrhmfpiTr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from google.colab import drive\n",
        "import pickle\n",
        "# np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)\n",
        "from scipy.optimize import minimize\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.lines import Line2D\n",
        "import torch\n",
        "import sys\n",
        "import plotly.graph_objects as go"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# deadend dependencies"
      ],
      "metadata": {
        "id": "UMj8NNrGfwu8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !git clone https://github.com/microsoft/med-deadend.git\n"
      ],
      "metadata": {
        "id": "KStXBTWK3f64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lifegate class play"
      ],
      "metadata": {
        "id": "ek8__7lVidSf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from copy import deepcopy\n",
        "import pygame\n",
        "import numpy as np\n",
        "import click\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tbWAPyxi04a",
        "outputId": "1aaa4316-1639-4755-d8e4-ddc3e995c0ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pygame 2.5.2 (SDL 2.28.2, Python 3.10.12)\n",
            "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RGB colors\n",
        "WHITE = (255, 255, 255)\n",
        "BLACK = (0, 0, 0)\n",
        "RED = (255, 0, 0)\n",
        "BLUE = (0, 100, 255)\n",
        "GREEN = (0, 255, 0)\n",
        "WALL = (80, 80, 80)\n",
        "YELLOW = (255, 255, 0)\n",
        "\n",
        "\n",
        "\n",
        "class LifeGate(object):\n",
        "    def __init__(self, state_mode, rng, death_drag, max_steps=100, fixed_life=True, rendering=False, image_saving=False, render_dir=None):\n",
        "        self.rng = rng\n",
        "        self.state_dtype = np.float32\n",
        "        self.frame_skip = 1  # for env consistency\n",
        "        self.fixed_life = fixed_life\n",
        "        self.blue = BLUE\n",
        "        self.death_drag = death_drag\n",
        "        self.legal_actions = [0, 1, 2, 3, 4]\n",
        "        self.action_meanings = ['no-op', 'up', 'down', 'left', 'right']\n",
        "        self.reward_scheme = {'death': -1.0, 'recovery': +1.0, 'step': 0.0, 'barrier': 0.0}\n",
        "        self.nb_actions = len(self.legal_actions)\n",
        "        self.player_pos_x = None\n",
        "        self.player_pos_y = None\n",
        "        self.agent_init_pos = None\n",
        "        self.state_mode = state_mode    # how the returned state look like ('pixel' or '1hot' or 'multi-head')\n",
        "        # self.scr_w = None\n",
        "        # self.scr_h = None\n",
        "        # self.possible_recoveries = []\n",
        "        self.recovery_observablity = True\n",
        "        # self.observability_switch_point = None  # where to turn observability off\n",
        "        # self.rendering_scale = None\n",
        "        # self.barriers = None\n",
        "        self.recoveries = None\n",
        "        self.deaths = None\n",
        "        # self.dead_ends = None\n",
        "        self._rendering = rendering\n",
        "        # self.state_shape = None\n",
        "        self.init_subclass()\n",
        "        if rendering:\n",
        "            self._init_pygame()\n",
        "        self.image_saving = image_saving\n",
        "        self.render_dir_main = render_dir\n",
        "        self.render_dir = None\n",
        "        self.state = None\n",
        "        self.step_id = 0\n",
        "        self.game_over = False\n",
        "\n",
        "        self.max_steps = max_steps\n",
        "\n",
        "        self.reset()\n",
        "\n",
        "    def init_subclass(self):\n",
        "        # should implement sizes, barriers, recoveries, deaths, init_player(), and rendering_scale\n",
        "        self.scr_w, self.scr_h = 10, 10\n",
        "        self.tabular_state_shape = (self.scr_w, self.scr_h)\n",
        "        self.state_shape = [24]\n",
        "        self.rendering_scale = 30\n",
        "        self.barriers = [[0, 0], [1, 0], [2, 0], [3, 0], [4, 0], [1, 5], [2, 5], [3, 5], [4, 5]]\n",
        "        self.possible_recoveries = [[5, 0], [6, 0], [7, 0]]\n",
        "        self.main_deaths = [[self.scr_w - 1, k] for k in range(self.scr_h)] + [[8,0]]\n",
        "        self.dead_ends = [[x, y] for x in range(self.scr_w // 2, self.scr_w - 1) for y in range(self.scr_w // 2, self.scr_w)]\n",
        "        self.observability_switch_point = [0, 5]\n",
        "\n",
        "    @property\n",
        "    def rendering(self):\n",
        "        return self._rendering\n",
        "\n",
        "    @rendering.setter\n",
        "    def rendering(self, flag):\n",
        "        if flag is True:\n",
        "            if self._rendering is False:\n",
        "                self._init_pygame()\n",
        "                self._rendering = True\n",
        "        else:\n",
        "            self.close()\n",
        "            self._rendering = False\n",
        "\n",
        "    def _init_pygame(self):\n",
        "        pygame.init()\n",
        "        size = [self.rendering_scale * self.scr_w, self.rendering_scale * self.scr_h]\n",
        "        self.screen = pygame.display.set_mode(size)\n",
        "        pygame.display.set_caption(\"LifeGate\")\n",
        "\n",
        "    def _init_rendering_folder(self):\n",
        "        if self.render_dir_main is None:\n",
        "            self.render_dir_main = 'render'\n",
        "        if not os.path.exists(os.path.join(os.getcwd(), self.render_dir_main)):\n",
        "            os.mkdir(os.path.join(os.getcwd(), self.render_dir_main))\n",
        "        i = 0\n",
        "        while os.path.exists(os.path.join(os.getcwd(), self.render_dir_main, 'render' + str(i))):\n",
        "            i += 1\n",
        "        self.render_dir = os.path.join(os.getcwd(), self.render_dir_main, 'render' + str(i))\n",
        "        os.mkdir(self.render_dir)\n",
        "\n",
        "    def reset(self):\n",
        "        if self.image_saving:\n",
        "            self._init_rendering_folder()\n",
        "        self.game_over = False\n",
        "        self.step_id = 0\n",
        "        self.recovery_observablity = True\n",
        "        self.blue = BLUE\n",
        "        state = self.init_episode()\n",
        "        return state\n",
        "\n",
        "    def init_episode(self):\n",
        "        # should implement reconfigurations at the beginning of each episode\n",
        "        self.player_pos_x, self.player_pos_y = 2, self.scr_h - 1\n",
        "        targets = deepcopy(self.possible_recoveries)\n",
        "        # if self.fixed_life == True:\n",
        "        #     rec = targets.pop(2)  # fixed life-gate for DQN\n",
        "        # else:\n",
        "        #     rec = targets.pop(self.rng.randint(len(targets)))\n",
        "        self.recoveries = targets #[rec]\n",
        "        self.deaths = self.main_deaths #+ targets\n",
        "        return self.get_obs(self.state_mode)\n",
        "\n",
        "    def render(self):\n",
        "        if not self.rendering:\n",
        "            return\n",
        "        pygame.event.pump()\n",
        "        self.screen.fill(BLACK)\n",
        "        size = [self.rendering_scale, self.rendering_scale]\n",
        "        for pos in self.dead_ends:\n",
        "            p = [self.rendering_scale * pos[0], self.rendering_scale * pos[1]]\n",
        "            rec1 = pygame.Rect(p[0], p[1], size[0], size[1])\n",
        "            pygame.draw.rect(self.screen, YELLOW, rec1)\n",
        "        player = pygame.Rect(self.rendering_scale * self.player_pos_x, self.rendering_scale * self.player_pos_y,\n",
        "                             size[0], size[1])\n",
        "        pygame.draw.rect(self.screen, WHITE, player)\n",
        "        for pos in self.deaths:\n",
        "            p = [self.rendering_scale * pos[0], self.rendering_scale * pos[1]]\n",
        "            rec1 = pygame.Rect(p[0], p[1], size[0], size[1])\n",
        "            pygame.draw.rect(self.screen, RED, rec1)\n",
        "        for pos in self.recoveries:\n",
        "            p = [self.rendering_scale * pos[0], self.rendering_scale * pos[1]]\n",
        "            rec1 = pygame.Rect(p[0], p[1], size[0], size[1])\n",
        "            pygame.draw.rect(self.screen, self.blue, rec1)  # self.blue will change if reach obs point\n",
        "        for pos in self.barriers:\n",
        "            p = [self.rendering_scale * pos[0], self.rendering_scale * pos[1]]\n",
        "            rec1 = pygame.Rect(p[0], p[1], size[0], size[1])\n",
        "            pygame.draw.rect(self.screen, WALL, rec1)\n",
        "        pygame.display.flip()\n",
        "\n",
        "        if self.image_saving:\n",
        "            self.save_image()\n",
        "\n",
        "    def save_image(self):\n",
        "        if self.rendering and self.render_dir is not None:\n",
        "            pygame.image.save(self.screen, self.render_dir + '/render' + str(self.step_id) + '.jpg')\n",
        "        else:\n",
        "            raise ValueError('env.rendering is False and/or environment has not been reset.')\n",
        "\n",
        "    def close(self):\n",
        "        if self.rendering:\n",
        "            pygame.quit()\n",
        "\n",
        "    def _move_player(self, action):\n",
        "        x, y = (self.player_pos_x, self.player_pos_y)\n",
        "        # dead-end:\n",
        "        if [x, y] in self.dead_ends:\n",
        "            if self.rng.binomial(1, 0.70):\n",
        "                action = 4  # forceful right\n",
        "            else:\n",
        "                action = 0  # no-op\n",
        "        else:\n",
        "            # natural risk of death\n",
        "            if self.rng.binomial(1, self.death_drag):  # say with 25% if death_drag==0.25\n",
        "                action = 4\n",
        "\n",
        "        if action == 4:    # right\n",
        "            x += 1\n",
        "        elif action == 3:  # left\n",
        "            x -= 1\n",
        "        elif action == 2:  # down\n",
        "            y += 1\n",
        "        elif action == 1:  # up\n",
        "            y -= 1\n",
        "        # updating the position\n",
        "        if [x, y] in self.barriers or x < 0 or y < 0 or y >= self.scr_h:\n",
        "            return\n",
        "        else:\n",
        "            self.player_pos_x, self.player_pos_y = x, y\n",
        "\n",
        "    def _get_status(self):\n",
        "        # check the current situation\n",
        "        if [self.player_pos_x, self.player_pos_y] in self.deaths:\n",
        "            return 'death'\n",
        "        elif [self.player_pos_x, self.player_pos_y] in self.recoveries:\n",
        "            return 'recovery'\n",
        "\n",
        "    def step(self, action):\n",
        "        assert action in self.legal_actions, 'Illegal action.'\n",
        "        if self.step_id >= self.max_steps - 1:\n",
        "            self.game_over = True\n",
        "            return self.get_obs(self.state_mode), 0., self.game_over, {}\n",
        "        self.step_id += 1\n",
        "        self._move_player(action)\n",
        "        if [self.player_pos_x, self.player_pos_y] == self.observability_switch_point and self.recovery_observablity == True:\n",
        "            self.recovery_observablity = False\n",
        "            self.blue = BLACK\n",
        "        status = self._get_status()\n",
        "        if status == 'death':\n",
        "            self.game_over = True\n",
        "            reward = self.reward_scheme['death']\n",
        "        elif status == 'recovery':\n",
        "            self.game_over = True\n",
        "            reward = self.reward_scheme['recovery']\n",
        "        else:\n",
        "            reward = self.reward_scheme['step']\n",
        "        return self.get_obs(self.state_mode), reward, self.game_over, {}\n",
        "\n",
        "    def get_lives(self):\n",
        "        if self.game_over == True:\n",
        "            return 0\n",
        "        else:\n",
        "            return 1\n",
        "\n",
        "    def get_state(self):\n",
        "        return self.get_obs(self.state_mode)\n",
        "\n",
        "    def get_obs(self, method):\n",
        "        if method == 'vector':\n",
        "            return self._get_vec_obs()\n",
        "        elif method == 'pixel':\n",
        "            return self._get_pixel_obs()\n",
        "        elif method == 'tabular':\n",
        "            return self._get_tabular_obs()\n",
        "        else:\n",
        "            raise ValueError('Unknown observation method.')\n",
        "\n",
        "    def _get_vec_obs(self):\n",
        "        x = np.zeros(self.scr_w + self.scr_h + len(self.possible_recoveries), dtype=self.state_dtype)\n",
        "        x[self.player_pos_x] = 1.0\n",
        "        x[self.player_pos_y + self.scr_w] = 1.0\n",
        "        if self.recovery_observablity == True or self.fixed_life == True:\n",
        "            for k in self.recoveries:\n",
        "                x[k[0] - 5 + self.scr_w + self.scr_h] = 1.0\n",
        "        return x\n",
        "\n",
        "    def _get_tabular_obs(self):\n",
        "        return np.array([self.player_pos_x, self.player_pos_y])\n",
        "\n",
        "    def _get_pixel_obs(self):\n",
        "        raise NotImplementedError"
      ],
      "metadata": {
        "id": "1p8iyu4BifbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# shaping dependencies"
      ],
      "metadata": {
        "id": "AsZMw4C0f2K-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ajagota7/Shaping.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wu7X59dK3hqk",
        "outputId": "7f50d0de-b709-4e4a-87f2-9c7c42e80649"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Shaping'...\n",
            "remote: Enumerating objects: 150, done.\u001b[K\n",
            "remote: Counting objects: 100% (150/150), done.\u001b[K\n",
            "remote: Compressing objects: 100% (104/104), done.\u001b[K\n",
            "remote: Total 150 (delta 77), reused 110 (delta 45), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (150/150), 12.02 MiB | 19.64 MiB/s, done.\n",
            "Resolving deltas: 100% (77/77), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/Shaping"
      ],
      "metadata": {
        "id": "5SkpvWFqz631"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !git pull origin main"
      ],
      "metadata": {
        "id": "8QRHhC-G0AiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cd /content/"
      ],
      "metadata": {
        "id": "hZ8dnFnidxL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/Shaping\n",
        "\n",
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile('/content/Shaping/lifegate_1.zip', 'r') as zip_ref:\n",
        "    # zip_ref.extractall('/content/med-deadend/lifegate/results/lifegate_1')\n",
        "    zip_ref.extractall('/content/Shaping/')"
      ],
      "metadata": {
        "id": "2noY6FOTdsmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "# sys.path.append('/content/med-deadend/lifegate')\n",
        "sys.path.append('/content/Shaping/')\n",
        "\n"
      ],
      "metadata": {
        "id": "id2reVHQ3heg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import q_networks"
      ],
      "metadata": {
        "id": "DgppFp3cDm4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/med-deadend/lifegate\n",
        "\n",
        "\n",
        "# results_dir = 'results/lifegate_1/'\n",
        "results_dir = '/content/Shaping/'\n",
        "# Load the Q tables from the primary learning agent, Q_D and Q_R value functions\n",
        "with open(results_dir+'tabular_qnet.pkl', 'rb') as fq:\n",
        "    ai = pickle.load(fq)\n",
        "\n",
        "with open(results_dir+'tabular_qd.pkl', 'rb') as fd:\n",
        "    ai_d = pickle.load(fd)\n",
        "\n",
        "with open(results_dir+'tabular_qr.pkl', 'rb') as fr:\n",
        "    ai_r = pickle.load(fr)"
      ],
      "metadata": {
        "id": "7lv4ZIBkeLW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q_table = np.zeros((10, 10, 5))\n",
        "q_d = np.zeros_like(q_table)\n",
        "q_r = np.zeros_like(q_table)\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    for j in range(10):\n",
        "        for a in range(5):\n",
        "            key = tuple([j, i, a])\n",
        "            try:\n",
        "                q_table[i,j,a] = ai.q[key]\n",
        "                q_d[i,j,a] = ai_d.q[key]\n",
        "                q_r[i,j,a] = ai_r.q[key]\n",
        "            except:\n",
        "                pass"
      ],
      "metadata": {
        "id": "Rk0Z42sNebl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "import random\n",
        "# from lifegate import LifeGate\n",
        "params = yaml.safe_load(open(results_dir+'config.yaml', 'r'))\n",
        "np.random.seed(seed=params['random_seed'])\n",
        "random.seed(params['random_seed'])\n",
        "random_state = np.random.RandomState(params['random_seed'])"
      ],
      "metadata": {
        "id": "4uTTjsWNfK21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# env"
      ],
      "metadata": {
        "id": "fjTGtdx8wCeC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = LifeGate(max_steps=params['episode_max_len'], state_mode='tabular',\n",
        "                        rendering=True, image_saving=False, render_dir=None, rng=random_state, death_drag = 0.0)"
      ],
      "metadata": {
        "id": "XUoJuLN0fabn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env_30 = LifeGate(max_steps=30, state_mode='tabular',\n",
        "                        rendering=True, image_saving=False, render_dir=None, rng=random_state, death_drag = 0.1)"
      ],
      "metadata": {
        "id": "7wG_zU6SM3xY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env_50 = LifeGate(max_steps=50, state_mode='tabular',\n",
        "                        rendering=True, image_saving=False, render_dir=None, rng=random_state, death_drag = 0.1)"
      ],
      "metadata": {
        "id": "llhj96oRwFZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env_100 = LifeGate(max_steps=100, state_mode='tabular',\n",
        "                        rendering=True, image_saving=False, render_dir=None, rng=random_state, death_drag = 0.1)"
      ],
      "metadata": {
        "id": "yMHNl8Vj47xA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KZp-8-f7far2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import Shaping\n",
        "from Shaping import *\n",
        "# %cd /content/Shaping\n",
        "\n",
        "from choose_actions import action_probs_top_n_epsilon\n",
        "from shaping_features import *\n",
        "from gen_policies import *\n",
        "from IS import *\n",
        "from subset_policies import *\n",
        "from v_pi_e import *\n",
        "from optimization import *\n",
        "from neural_net import *\n",
        "from prep_variance import *\n",
        "from SCOPE_variance import SCOPE_variance"
      ],
      "metadata": {
        "id": "hS65UmL5Yu_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "JYUrYs3BCAMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test model with l2 reg\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EQrnwRzAJTKt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "class CustomizableFeatureNet(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dims, output_dim, dropout_prob=0.2, l2_lambda=0.01, dtype=torch.float32):\n",
        "        super(CustomizableFeatureNet, self).__init__()\n",
        "        self.hidden_layers = nn.ModuleList()\n",
        "\n",
        "        # Create the hidden layers based on the provided sizes\n",
        "        for in_dim, out_dim in zip([input_dim] + hidden_dims, hidden_dims):\n",
        "            layer = nn.Linear(in_dim, out_dim).to(dtype)\n",
        "            self.hidden_layers.append(layer)\n",
        "\n",
        "        self.output_layer = nn.Linear(hidden_dims[-1], output_dim).to(dtype)\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "        self.l2_lambda = l2_lambda\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.hidden_layers:\n",
        "            x = F.relu(layer(x))\n",
        "            x = self.dropout(x)\n",
        "        x = self.output_layer(x)\n",
        "        return x\n",
        "\n",
        "    def l2_regularization(self):\n",
        "        l2_reg = torch.tensor(0., device=self.output_layer.weight.device)\n",
        "        for layer in self.hidden_layers:\n",
        "            l2_reg += torch.norm(layer.weight)\n",
        "        l2_reg += torch.norm(self.output_layer.weight)\n",
        "        return self.l2_lambda * l2_reg\n"
      ],
      "metadata": {
        "id": "FVdQ4HDTJTK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test model with l1_reg"
      ],
      "metadata": {
        "id": "lyiKomU6mwzQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class NN_l1_reg(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dims, output_dim, dropout_prob=0.2, l1_lambda=0.01, dtype=torch.float32):\n",
        "        super(NN_l1_reg, self).__init__()\n",
        "        self.hidden_layers = nn.ModuleList()\n",
        "\n",
        "        # Create the hidden layers based on the provided sizes\n",
        "        for in_dim, out_dim in zip([input_dim] + hidden_dims, hidden_dims):\n",
        "            layer = nn.Linear(in_dim, out_dim).to(dtype)\n",
        "            self.hidden_layers.append(layer)\n",
        "\n",
        "        self.output_layer = nn.Linear(hidden_dims[-1], output_dim).to(dtype)\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "        self.l1_lambda = l1_lambda\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.hidden_layers:\n",
        "            x = F.relu(layer(x))\n",
        "            x = self.dropout(x)\n",
        "        x = self.output_layer(x)\n",
        "        return x\n",
        "\n",
        "    def l1_regularization(self):\n",
        "        l1_reg = torch.tensor(0., device=self.output_layer.weight.device)\n",
        "        for layer in self.hidden_layers:\n",
        "            l1_reg += torch.norm(layer.weight, p=1)\n",
        "        l1_reg += torch.norm(self.output_layer.weight, p=1)\n",
        "        return self.l1_lambda * l1_reg\n"
      ],
      "metadata": {
        "id": "KH_Mm9JJmzIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# L1 L2 reg"
      ],
      "metadata": {
        "id": "fGfd9yK4-S1K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class NN_l1_l2_reg(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dims, output_dim, dropout_prob=0.2, l1_lambda=0.01, l2_lambda=0.01, dtype=torch.float32):\n",
        "        super(NN_l1_l2_reg, self).__init__()\n",
        "        self.hidden_layers = nn.ModuleList()\n",
        "\n",
        "        # Create the hidden layers based on the provided sizes\n",
        "        for in_dim, out_dim in zip([input_dim] + hidden_dims, hidden_dims):\n",
        "            layer = nn.Linear(in_dim, out_dim).to(dtype)\n",
        "            self.hidden_layers.append(layer)\n",
        "\n",
        "        self.output_layer = nn.Linear(hidden_dims[-1], output_dim).to(dtype)\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "        self.l1_lambda = l1_lambda\n",
        "        self.l2_lambda = l2_lambda\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.hidden_layers:\n",
        "            x = F.relu(layer(x))\n",
        "            x = self.dropout(x)\n",
        "        x = self.output_layer(x)\n",
        "        return x\n",
        "\n",
        "    def l1_regularization(self):\n",
        "        l1_reg = torch.tensor(0., device=self.output_layer.weight.device)\n",
        "        for layer in self.hidden_layers:\n",
        "            l1_reg += torch.norm(layer.weight, p=1)\n",
        "        l1_reg += torch.norm(self.output_layer.weight, p=1)\n",
        "        return self.l1_lambda * l1_reg\n",
        "\n",
        "    def l2_regularization(self):\n",
        "        l2_reg = torch.tensor(0., device=self.output_layer.weight.device)\n",
        "        for layer in self.hidden_layers:\n",
        "            l2_reg += torch.norm(layer.weight, p=2)\n",
        "        l2_reg += torch.norm(self.output_layer.weight, p=2)\n",
        "        return self.l2_lambda * l2_reg\n",
        "\n",
        "    def total_regularization(self):\n",
        "        return self.l1_regularization() + self.l2_regularization()"
      ],
      "metadata": {
        "id": "3aaibNXf-U1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SCOPE straight"
      ],
      "metadata": {
        "id": "aIFnUpUIlyr7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SCOPE_straight(object):\n",
        "\n",
        "  def __init__(self, model, gamma, num_bootstraps, pi_b, P_pi_b, P_pi_e, percent_to_estimate_phi, dtype):\n",
        "        self.model = model\n",
        "        self.gamma = gamma\n",
        "        self.num_bootstraps = num_bootstraps\n",
        "        self.pi_b = pi_b\n",
        "        self.P_pi_b = P_pi_b\n",
        "        self.P_pi_e = P_pi_e\n",
        "        self.dtype = dtype\n",
        "\n",
        "        self.percent_to_estimate_phi = percent_to_estimate_phi\n",
        "        # self.num_epochs = num_epochs\n",
        "\n",
        "  def subset_policies(self):\n",
        "    # seed_value = 0\n",
        "    # np.random.seed(seed_value)\n",
        "    num_policies = len(self.pi_b)\n",
        "    num_policies_to_estimate_phi = int(num_policies * self.percent_to_estimate_phi)\n",
        "\n",
        "    policies_for_scope = self.pi_b[num_policies_to_estimate_phi:]\n",
        "    policies_for_phi = self.pi_b[:num_policies_to_estimate_phi]\n",
        "\n",
        "    return policies_for_phi, policies_for_scope\n",
        "\n",
        "\n",
        "  # ---------------\n",
        "  # Pre-processing\n",
        "  # ---------------\n",
        "\n",
        "  def prep_policies(self, chosen_policies):\n",
        "      # Initialize lists to store axis data for each policy\n",
        "      timesteps = []\n",
        "      # states = []\n",
        "      # state_first = []\n",
        "      # state_last = []\n",
        "      actions = []\n",
        "      rewards = []\n",
        "      # gamma_last = []\n",
        "      # weight_last = []\n",
        "      # weight_first = []\n",
        "      # all_weights_temp, weights = calculate_importance_weights(P_pi_e, P_pi_b, pi_b)\n",
        "      weights = calculate_importance_weights(self.P_pi_e, self.P_pi_b, chosen_policies)\n",
        "      psi = []\n",
        "\n",
        "      states_current = []\n",
        "      states_next = []\n",
        "      states_all = []\n",
        "\n",
        "      states_last = []\n",
        "      psi_last = []\n",
        "\n",
        "      for index, policy in enumerate(chosen_policies):\n",
        "          policy_array = np.array(policy)\n",
        "\n",
        "          timesteps.append(policy_array['timestep'].astype(int))\n",
        "          actions.append(policy_array['action'])\n",
        "          rewards.append(policy_array['reward'].astype(float))\n",
        "\n",
        "          state_last = policy_array['state_next'][-1]\n",
        "          last_psi = smallest_distance_to_deadend(state_last, env)\n",
        "          states_last.append(state_last)\n",
        "          psi_last.append(last_psi)\n",
        "\n",
        "          # Concatenate psi array with last_psi\n",
        "          # all_psi = np.concatenate((policy_array['psi'], [last_psi]))\n",
        "          # psi.append(all_psi)\n",
        "          psi.append(policy_array['psi'])\n",
        "\n",
        "          states_next.append(policy_array['state_next'])\n",
        "          states_current.append(policy_array['state'])\n",
        "          # all_states = policy_array['state'] + policy_array['state_next'][-1]\n",
        "          all_states = np.vstack((policy_array['state'],policy_array['state_next'][-1]))\n",
        "          states_all.append(all_states)\n",
        "\n",
        "          # states_all.append(np.concatenate((policy_array['state'], policy_array['state_next'][-1])))\n",
        "\n",
        "\n",
        "\n",
        "      return timesteps, rewards, states_next, states_current, weights, actions, psi, states_last, psi_last\n",
        "\n",
        "  def padding_IS_terms(self, timesteps, actions, rewards, weights):\n",
        "\n",
        "    # Find the maximum length among all lists\n",
        "    max_length = max(len(traj) for traj in timesteps)\n",
        "\n",
        "    # Define the padding values\n",
        "    zero_padding = 0\n",
        "\n",
        "    # Pad each list to match the maximum length\n",
        "    padded_timesteps = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in timesteps]\n",
        "    padded_rewards = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in rewards]\n",
        "    padded_actions = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in actions]\n",
        "    padded_weights = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in weights]\n",
        "\n",
        "    return padded_timesteps, padded_rewards, padded_actions, padded_weights\n",
        "\n",
        "\n",
        "  def tensorize_IS_terms(self, padded_timesteps, padded_rewards, padded_weights):\n",
        "\n",
        "    padded_timestep_tensors = torch.tensor(padded_timesteps, dtype = self.dtype)\n",
        "    padded_reward_tensors = torch.tensor(padded_rewards, dtype = self.dtype)\n",
        "    padded_weight_tensors = torch.tensor(padded_weights, dtype = self.dtype)\n",
        "\n",
        "    return padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors\n",
        "\n",
        "  def padding_states_all(self, states_all, psi):\n",
        "    max_length = max(len(trajectory) for trajectory in states_all)\n",
        "\n",
        "    zero_padding = 0\n",
        "\n",
        "    # Pad each trajectory to make them all the same length\n",
        "    padded_states_all = [\n",
        "        [list(item) for item in trajectory] + [[0, 0]] * (max_length - len(trajectory))\n",
        "        for trajectory in states_all\n",
        "    ]\n",
        "\n",
        "    padded_psi = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in psi]\n",
        "    mask = [[1] * len(trajectory) + [0] * (max_length - len(trajectory)) for trajectory in states_all]\n",
        "\n",
        "    return padded_states_all, padded_psi, mask\n",
        "\n",
        "\n",
        "\n",
        "  def padding_states(self, states_next, states_current, psi):\n",
        "    # Find the maximum length of trajectories\n",
        "    max_length = max(len(trajectory) for trajectory in states_current)\n",
        "\n",
        "    zero_padding = 0\n",
        "\n",
        "    # Pad each trajectory to make them all the same length\n",
        "    padded_states_next = [\n",
        "        [list(item) for item in trajectory] + [[0, 0]] * (max_length - len(trajectory))\n",
        "        for trajectory in states_next\n",
        "    ]\n",
        "\n",
        "    # Pad each trajectory to make them all the same length\n",
        "    padded_states_current = [\n",
        "        [list(item) for item in trajectory] + [[0, 0]] * (max_length - len(trajectory))\n",
        "        for trajectory in states_current\n",
        "    ]\n",
        "\n",
        "    padded_psi = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in psi]\n",
        "\n",
        "    # Create mask\n",
        "    mask = [[1] * len(trajectory) + [0] * (max_length - len(trajectory)) for trajectory in states_current]\n",
        "\n",
        "    return padded_states_next, padded_states_current, padded_psi, mask\n",
        "\n",
        "\n",
        "  def tensorize_padded_terms(self, padded_states_next, padded_states_current, padded_psi,mask):\n",
        "    padded_states_next_tensors = torch.tensor(padded_states_next, dtype = self.dtype)\n",
        "    padded_states_current_tensors = torch.tensor(padded_states_current, dtype = self.dtype)\n",
        "    padded_psi_tensors = torch.tensor(padded_psi, dtype = self.dtype)\n",
        "\n",
        "    mask_tensor = torch.tensor(mask, dtype = self.dtype)\n",
        "    return padded_states_next_tensors, padded_states_current_tensors, padded_psi_tensors, mask_tensor\n",
        "\n",
        "  def tensorize_all_states_psi(self, padded_states_all, padded_psi, mask):\n",
        "    padded_states_all_tensors = torch.tensor(padded_states_all, dtype = self.dtype)\n",
        "    padded_psi_tensors = torch.tensor(padded_psi, dtype = self.dtype)\n",
        "    mask_tensor = torch.tensor(mask, dtype = self.dtype)\n",
        "\n",
        "    return padded_states_all_tensors, padded_psi_tensors, mask_tensor\n",
        "\n",
        "  def tensorize_last_states_psi(self, states_last, psi_last):\n",
        "    states_last_tensor = torch.tensor(states_last, dtype = self.dtype)\n",
        "    psi_last_tensor = torch.tensor(psi_last, dtype = self.dtype)\n",
        "\n",
        "    return states_last_tensor, psi_last_tensor\n",
        "\n",
        "  #-----------------------\n",
        "  # Preparation Functions\n",
        "  # ----------------------\n",
        "\n",
        "  def prepare_IS(self):\n",
        "    timesteps, rewards, states_next, states_current, weights, actions,_,_,_ = self.prep_policies(self.pi_b)\n",
        "    padded_timesteps, padded_rewards, padded_actions, padded_weights = self.padding_IS_terms(timesteps, actions, rewards, weights)\n",
        "    padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors = self.tensorize_IS_terms(padded_timesteps, padded_rewards, padded_weights)\n",
        "\n",
        "    return padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors\n",
        "\n",
        "  def prepare_SCOPE(self, policies):\n",
        "    timesteps, rewards, states_next, states_current, weights, actions, psi,states_last, psi_last = self.prep_policies(policies)\n",
        "    padded_timesteps, padded_rewards, padded_actions, padded_weights = self.padding_IS_terms(timesteps, actions, rewards, weights)\n",
        "    padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors = self.tensorize_IS_terms(padded_timesteps, padded_rewards, padded_weights)\n",
        "    padded_states_next, padded_states_current, padded_psi, mask = self.padding_states(states_next, states_current, psi)\n",
        "    padded_states_next_tensors, padded_states_current_tensors, padded_psi_tensors, mask_tensor = self.tensorize_padded_terms(padded_states_next, padded_states_current, padded_psi, mask)\n",
        "    states_last_tensor, psi_last_tensor = self.tensorize_last_states_psi(states_last, psi_last)\n",
        "    return padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors, padded_states_next_tensors, padded_states_current_tensors, padded_psi_tensors, mask_tensor, states_last_tensor, psi_last_tensor\n",
        "\n",
        "  def prepare_SCOPE_phi(self):\n",
        "    phi_set,_ = self.subset_policies()\n",
        "    padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors, padded_states_next_tensors, padded_states_current_tensors, padded_psi_tensors, mask_tensor, states_last_tensor, psi_last_tensor = self.prepare_SCOPE(phi_set)\n",
        "\n",
        "    return padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors, padded_states_next_tensors, padded_states_current_tensors, padded_psi_tensors, mask_tensor, states_last_tensor, psi_last_tensor\n",
        "\n",
        "  def prepare_SCOPE_test(self):\n",
        "    _, scope_set = self.subset_policies()\n",
        "    padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors, padded_states_next_tensors, padded_states_current_tensors,_,_,_,_ = self.prepare_SCOPE(scope_set)\n",
        "\n",
        "    return padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors, padded_states_next_tensors, padded_states_current_tensors\n",
        "\n",
        "\n",
        "  # ----------------\n",
        "  # IS Calculations\n",
        "  # ----------------\n",
        "\n",
        "\n",
        "  def bootstrap_IS(self, padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors):\n",
        "    seed = 42\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    num_samples = self.num_bootstraps\n",
        "    num_bootstraps_lin = num_samples*padded_timestep_tensors.shape[0]\n",
        "\n",
        "    # Sample indices with replacement\n",
        "    sampled_indices = torch.randint(0, len(padded_timestep_tensors), size=(num_bootstraps_lin,), dtype=torch.long)\n",
        "\n",
        "    reshaped_size = (num_samples, padded_timestep_tensors.shape[0], padded_timestep_tensors.shape[1])\n",
        "\n",
        "    padded_IS = self.gamma**(padded_timestep_tensors)*padded_weight_tensors*padded_reward_tensors\n",
        "\n",
        "    IS_bootstraps = padded_IS[sampled_indices].view(reshaped_size)\n",
        "\n",
        "    # timestep_bootstraps = padded_timestep_tensors[sampled_indices].view(reshaped_size)\n",
        "    # rewards_bootstraps = padded_reward_tensors[sampled_indices].view(reshaped_size)\n",
        "    # weights_bootstraps = padded_weight_tensors[sampled_indices].view(reshaped_size)\n",
        "    # return timestep_bootstraps, rewards_bootstraps, weights_bootstraps, IS_bootstraps\n",
        "    return IS_bootstraps\n",
        "\n",
        "\n",
        "  def calc_var_IS(self, IS_bootstraps):\n",
        "    # Step 1: Sum along the third dimension\n",
        "    sum_IS_trajectories = torch.sum(IS_bootstraps, dim=2)  # Shape: [1000, 1000]\n",
        "\n",
        "    # Step 2: Take the mean along the second dimension\n",
        "    mean_IS_sum = torch.mean(sum_IS_trajectories, dim=1)  # Shape: [1000]\n",
        "\n",
        "    # Step 3: Calculate the variance across the first dimension\n",
        "    IS_variance = torch.var(mean_IS_sum)  # A single scalar value\n",
        "\n",
        "    IS_mean = torch.mean(mean_IS_sum) # A single scalar value\n",
        "\n",
        "    return IS_mean, IS_variance\n",
        "\n",
        "\n",
        "  def IS_pipeline(self):\n",
        "    padded_timestep_tensors_IS, padded_reward_tensors_IS, padded_weight_tensors_IS = self.prepare_IS()\n",
        "    # timestep_bootstraps_IS, rewards_bootstraps_IS, weights_bootstraps_IS = self.bootstrap_IS(padded_timestep_tensors_IS, padded_reward_tensors_IS, padded_weight_tensors_IS)\n",
        "    IS_bootstraps = self.bootstrap_IS(padded_timestep_tensors_IS, padded_reward_tensors_IS, padded_weight_tensors_IS)\n",
        "    # IS_mean, IS_variance = self.calc_variance_IS(timestep_bootstraps_IS, rewards_bootstraps_IS, weights_bootstraps_IS)\n",
        "    IS_mean, IS_variance = self.calc_var_IS(IS_bootstraps)\n",
        "\n",
        "    return IS_mean, IS_variance\n",
        "\n",
        "\n",
        "\n",
        "  # ---------------------\n",
        "  # SCOPE calculations\n",
        "  # ---------------------\n",
        "\n",
        "  def pass_states(self, padded_states_next_tensors, padded_states_current_tensors):\n",
        "    states_next_output = self.model(padded_states_next_tensors)\n",
        "    states_current_output = self.model(padded_states_current_tensors)\n",
        "\n",
        "    return states_next_output.squeeze(), states_current_output.squeeze()\n",
        "\n",
        "  def bootstrap_straight(self, padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors, states_next_output, states_current_output):\n",
        "      seed = 42\n",
        "      torch.manual_seed(seed)\n",
        "\n",
        "      num_samples = self.num_bootstraps\n",
        "      num_bootstraps_lin = num_samples*padded_timestep_tensors.shape[0]\n",
        "\n",
        "      # Sample indices with replacement\n",
        "      sampled_indices = torch.randint(0, len(padded_timestep_tensors), size=(num_bootstraps_lin,), dtype=torch.long)\n",
        "\n",
        "      reshaped_size = (num_samples, padded_timestep_tensors.shape[0], padded_timestep_tensors.shape[1])\n",
        "\n",
        "      padded_scope = self.gamma**(padded_timestep_tensors)*padded_weight_tensors*(padded_reward_tensors +self.gamma*states_next_output - states_current_output)\n",
        "      scope_bootstraps = padded_scope[sampled_indices].view(reshaped_size)\n",
        "\n",
        "      return scope_bootstraps\n",
        "\n",
        "  def pass_then_boostraps(self, padded_states_next_tensors, padded_states_current_tensors, padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors):\n",
        "    states_next_output, states_current_output = self.pass_states(padded_states_next_tensors, padded_states_current_tensors)\n",
        "    # timestep_bootstraps, rewards_bootstraps, weights_bootstraps, phi_states_next_bootstraps, phi_states_current_bootstraps = self.bootstrap_straight(padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors, states_next_output, states_current_output)\n",
        "    scope_bootstraps = self.bootstrap_straight(padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors, states_next_output, states_current_output)\n",
        "    # return timestep_bootstraps, rewards_bootstraps, weights_bootstraps, phi_states_next_bootstraps, phi_states_current_bootstraps\n",
        "    return scope_bootstraps\n",
        "\n",
        "  def calc_var_straight(self, scope_bootstraps):\n",
        "\n",
        "    # Step 1: Sum along the third dimension\n",
        "    sum_scope_trajectories = torch.sum(scope_bootstraps, dim=2)  # Shape: [1000, 1000]\n",
        "\n",
        "    # Step 2: Take the mean along the second dimension\n",
        "    mean_scope_sum = torch.mean(sum_scope_trajectories, dim=1)  # Shape: [1000]\n",
        "\n",
        "    # Step 3: Calculate the variance across the first dimension\n",
        "    scope_variance = torch.var(mean_scope_sum)  # A single scalar value\n",
        "\n",
        "    scope_mean = torch.mean(mean_scope_sum) # A single scalar value\n",
        "\n",
        "    return scope_mean, scope_variance\n",
        "\n",
        "  def train_var_scope(self, num_epochs, learning_rate, scope_weight=1, mse_weight=1):\n",
        "\n",
        "      # IS terms for comparison to SCOPE\n",
        "      padded_timestep_tensors_IS, padded_reward_tensors_IS, padded_weight_tensors_IS = self.prepare_IS()\n",
        "      # timestep_bootstraps_IS, rewards_bootstraps_IS, weights_bootstraps_IS = self.bootstrap_IS(padded_timestep_tensors_IS, padded_reward_tensors_IS, padded_weight_tensors_IS)\n",
        "      # IS_mean, IS_variance = self.calc_variance_IS(timestep_bootstraps_IS, rewards_bootstraps_IS, weights_bootstraps_IS)\n",
        "\n",
        "      IS_bootstraps = self.bootstrap_IS(padded_timestep_tensors_IS, padded_reward_tensors_IS, padded_weight_tensors_IS)\n",
        "      IS_mean, IS_variance = self.calc_var_IS(IS_bootstraps)\n",
        "\n",
        "      # SCOPE terms for training phi\n",
        "      padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors, padded_states_next_tensors, padded_states_current_tensors, padded_psi_tensors, mask_tensor, states_last_tensor, psi_last_tensor = self.prepare_SCOPE_phi()\n",
        "\n",
        "\n",
        "      self.model.train()\n",
        "\n",
        "      # Enable anomaly detection\n",
        "      torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "      optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
        "\n",
        "      for epoch in range(num_epochs):\n",
        "          total_loss = 0\n",
        "\n",
        "\n",
        "          # timestep_bootstraps, rewards_bootstraps, weights_bootstraps, phi_states_next_bootstraps, phi_states_current_bootstraps = self.pass_then_boostraps(padded_states_next_tensors, padded_states_current_tensors, padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors)\n",
        "\n",
        "          states_next_output, states_current_output = self.pass_states(padded_states_next_tensors, padded_states_current_tensors)\n",
        "          # timestep_bootstraps, rewards_bootstraps, weights_bootstraps, phi_states_next_bootstraps, phi_states_current_bootstraps = self.bootstrap_straight(padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors, states_next_output, states_current_output)\n",
        "          # SCOPE_mean, SCOPE_variance = self.calc_variance_straight(timestep_bootstraps, weights_bootstraps, rewards_bootstraps, phi_states_next_bootstraps, phi_states_current_bootstraps)\n",
        "\n",
        "          scope_bootstraps = self.bootstrap_straight(padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors, states_next_output, states_current_output)\n",
        "          SCOPE_mean, SCOPE_variance = self.calc_var_straight(scope_bootstraps)\n",
        "\n",
        "          # mse_loss = F.mse_loss(states_current_output, 0.2*padded_psi_tensors)\n",
        "          mse_loss = F.mse_loss(states_current_output, 0.1*padded_psi_tensors, reduction='none')\n",
        "          masked_mse_loss = mse_loss * mask_tensor\n",
        "\n",
        "          states_last_output = self.model(states_last_tensor)\n",
        "          mse_states_last_loss = F.mse_loss(states_last_output.squeeze(),0.1*psi_last_tensor, reduction = 'none')\n",
        "\n",
        "          # mean_mse_loss = masked_mse_loss.mean()\n",
        "          sum_mse_loss = torch.sum(masked_mse_loss, dim = 1)\n",
        "\n",
        "          mean_mse_loss = torch.mean(sum_mse_loss + mse_states_last_loss)\n",
        "\n",
        "\n",
        "          print(f\"Epoch {epoch+1}\")\n",
        "          print(f\"IS mean: {IS_mean},IS variance: {IS_variance}\")\n",
        "          print(\"SCOPE Var loss: \", SCOPE_variance)\n",
        "          print(\"MSE loss: \", mean_mse_loss.item())\n",
        "\n",
        "          # Testing evaluaton\n",
        "          scope_mean, scope_var = self.evaluate_scope()\n",
        "          print(f\"SCOPE mean: {scope_mean}, SCOPE var: {scope_var}\")\n",
        "          self.model.train()\n",
        "\n",
        "\n",
        "          # tot = SCOPE_variance\n",
        "          # tot = SCOPE_variance + mse_loss\n",
        "          tot = scope_weight*SCOPE_variance + mse_weight*mean_mse_loss\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          # Retain the graph to avoid clearing it before backward pass\n",
        "          tot.backward(retain_graph=True)\n",
        "\n",
        "          optimizer.step()\n",
        "\n",
        "          total_loss += tot.item()\n",
        "\n",
        "          print(f\"Total Loss: {total_loss}\")\n",
        "          print(\"-\" * 40)\n",
        "\n",
        "      # Disable anomaly detection after running the code\n",
        "      torch.autograd.set_detect_anomaly(False)\n",
        "\n",
        "      for name, param in self.model.named_parameters():\n",
        "          if param.requires_grad:\n",
        "              print(f\"Parameter name: {name}\")\n",
        "              print(f\"Weights: {param.data}\")\n",
        "\n",
        "      return self.model #, sum_mse_loss, mse_states_last_loss\n",
        "\n",
        "  def evaluate_scope(self):\n",
        "    self.model.eval()\n",
        "    padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors, padded_states_next_tensors, padded_states_current_tensors = self.prepare_SCOPE_test()\n",
        "    # timestep_bootstraps, rewards_bootstraps, weights_bootstraps, phi_states_next_bootstraps, phi_states_current_bootstraps = self.pass_then_boostraps(padded_states_next_tensors, padded_states_current_tensors, padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors)\n",
        "    # SCOPE_mean, SCOPE_variance = self.calc_variance_straight(timestep_bootstraps, weights_bootstraps, rewards_bootstraps, phi_states_next_bootstraps, phi_states_current_bootstraps)\n",
        "\n",
        "    scope_bootstraps = self.pass_then_boostraps(padded_states_next_tensors, padded_states_current_tensors, padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors)\n",
        "    SCOPE_mean, SCOPE_variance = self.calc_var_straight(scope_bootstraps)\n",
        "\n",
        "    return SCOPE_mean, SCOPE_variance\n",
        "\n",
        "\n",
        "  # -----------------------\n",
        "  # Heatmaps for lifegate\n",
        "  # -----------------------\n",
        "  def get_model_output_dict(self):\n",
        "\n",
        "    self.model.eval()\n",
        "\n",
        "    # Initialize an empty dictionary to store data\n",
        "    data = {}\n",
        "\n",
        "    # Loop through all combinations from [0,0] to [9,9]\n",
        "    for i in range(10):\n",
        "      for j in range(10):\n",
        "          # Prepare input data\n",
        "          input_data = torch.tensor([i, j], dtype=torch.float64)\n",
        "\n",
        "          # Pass input through the self.model\n",
        "          output = self.model(input_data)\n",
        "\n",
        "          # Store data in the dictionary\n",
        "          data[(i, j)] = output.item()\n",
        "\n",
        "    return data\n",
        "\n",
        "  def plot_heatmap(self, data):\n",
        "    values = np.zeros((10, 10))\n",
        "    for (x, y), value in data.items():\n",
        "        values[y, x] = value\n",
        "\n",
        "    # Create the heatmap\n",
        "    fig = go.Figure(data=go.Heatmap(z=values, colorscale='viridis'))\n",
        "\n",
        "    # Add colorbar\n",
        "    fig.update_layout(coloraxis_colorbar=dict(title='Values',\n",
        "                                              ticks='outside',\n",
        "                                              tickvals=[np.min(values), np.max(values)],\n",
        "                                              ticktext=[np.min(values), np.max(values)]))\n",
        "\n",
        "    # Add labels and title\n",
        "    fig.update_layout(xaxis=dict(tickvals=np.arange(10), ticktext=list(range(10)), title='X'),\n",
        "                      yaxis=dict(tickvals=np.arange(9, -1, -1), ticktext=list(range(9, -1, -1)), title='Y', autorange=\"reversed\"),\n",
        "                      title='Heatmap')\n",
        "\n",
        "    fig.show()\n",
        "\n",
        "  def get_heatmap(self):\n",
        "    data = self.get_model_output_dict()\n",
        "    self.plot_heatmap(data)\n",
        "\n",
        "  # ---------------------\n",
        "  # State Visitation Heatmap\n",
        "  # ---------------------\n",
        "\n",
        "  def count_state_visits(self):\n",
        "    state_visit_counts = {}\n",
        "    for trajectory in self.pi_b:\n",
        "        for data_point in trajectory:\n",
        "            state = tuple(data_point['state'])\n",
        "            if state not in state_visit_counts:\n",
        "                state_visit_counts[state] = 0\n",
        "            state_visit_counts[state] += 1\n",
        "\n",
        "        # Include last state_next of the trajectory\n",
        "        last_state_next = tuple(trajectory[-1]['state_next'])\n",
        "        if last_state_next not in state_visit_counts:\n",
        "            state_visit_counts[last_state_next] = 0\n",
        "        state_visit_counts[last_state_next] += 1\n",
        "\n",
        "    return state_visit_counts\n",
        "\n",
        "  def create_state_visit_dict(self):\n",
        "      state_visit_dict = {}\n",
        "      for i in range(10):\n",
        "          for j in range(10):\n",
        "              state_visit_dict[(i, j)] = 0\n",
        "      return state_visit_dict\n",
        "\n",
        "  def fill_state_visit_dict(self,state_visit_counts):\n",
        "      state_visit_dict = self.create_state_visit_dict()\n",
        "      for state, count in state_visit_counts.items():\n",
        "          state_visit_dict[state] = count\n",
        "      return state_visit_dict\n",
        "\n",
        "\n",
        "  def plot_state_visitations_heatmap(self, state_visit_dict):\n",
        "    # Create lists to store x, y, and z values\n",
        "    x = []\n",
        "    y = []\n",
        "    z = []\n",
        "\n",
        "    # Iterate through the state visit dictionary\n",
        "    for state, count in state_visit_dict.items():\n",
        "        x.append(state[0])\n",
        "        y.append(9 - state[1])  # Flip y-axis to have (0, 0) at the bottom-left\n",
        "        z.append(count)\n",
        "\n",
        "    # Create the heatmap trace\n",
        "    trace = go.Heatmap(\n",
        "        x=x,\n",
        "        y=y,\n",
        "        z=z,\n",
        "        colorscale='Viridis',  # Choose a colorscale\n",
        "        colorbar=dict(title='Visits'),\n",
        "        zmin=0,\n",
        "        zmax=max(z)  # Set maximum value for the color scale\n",
        "    )\n",
        "\n",
        "    # Create layout\n",
        "    layout = go.Layout(\n",
        "        title='State Visitations Heatmap',\n",
        "        xaxis=dict(title='X-axis'),\n",
        "        yaxis=dict(title='Y-axis', tickvals=list(range(10)), ticktext=list(range(9, -1, -1))),\n",
        "    )\n",
        "\n",
        "    # Create figure\n",
        "    fig = go.Figure(data=[trace], layout=layout)\n",
        "    fig.show()\n",
        "\n",
        "\n",
        "  def get_state_visitation_heatmap(self):\n",
        "\n",
        "    # Count state visits\n",
        "    state_visit_counts = self.count_state_visits()\n",
        "\n",
        "    # Fill state visit dictionary\n",
        "    state_visit_dict = self.fill_state_visit_dict(state_visit_counts)\n",
        "\n",
        "    # Assuming state_visit_dict is your dictionary with state visitations\n",
        "    self.plot_state_visitations_heatmap(state_visit_dict)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "P8buR941l0JC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment Class"
      ],
      "metadata": {
        "id": "jDPINl4-fUq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Running experiments across multiple trajectories\n",
        "\n",
        "class SCOPE_straight(object):\n",
        "\n",
        "  def __init__(self, num_trajectories, scope_class, env, pi_b, pi_e, ):\n",
        "        self.num_trajectories = num_trajectories\n",
        "        self.scope_class = scope_class\n",
        "        self.num_bootstraps = num_bootstraps\n",
        "        self.pi_b = pi_b\n",
        "        self.P_pi_b = P_pi_b\n",
        "        self.P_pi_e = P_pi_e\n",
        "        self.dtype = dtype\n",
        "\n",
        "        self.percent_to_estimate_phi = percent_to_estimate_phi\n",
        "        # self.num_epochs = num_epochs"
      ],
      "metadata": {
        "id": "FLRjLgQ7fZLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SCOPE_experiment(SCOPE_straight):\n",
        "    def __init__(self, model, gamma, num_bootstraps, pi_b, P_pi_b, P_pi_e, percent_to_estimate_phi, num_trajectories, q_table, pi_b_top_k, pi_b_epsilon, pi_e_top_k ,pi_e_epsilon, dtype):\n",
        "        super().__init__(model, gamma, num_bootstraps, pi_b, P_pi_b, P_pi_e, percent_to_estimate_phi, dtype)\n",
        "        self.num_trajectories = num_trajectories\n",
        "        self.q_table = q_table\n",
        "        self.pi_b_top_k = pi_b_top_k\n",
        "        self.pi_b_epsilon = pi_b_epsilon\n",
        "        self.pi_e_top_k = pi_e_top_k\n",
        "        self.pi_e_epsilon = pi_e_epsilon\n",
        "\n",
        "        # self.step_size\n",
        "        # self.l1_regularization\n",
        "        # self.l2_regularization\n",
        "        # self.\n",
        "\n",
        "    def run_experiment(self):\n",
        "        # Define action probabilities for behavior policy with epsilon = 0.4\n",
        "        behavior_action_probs = action_probs_top_n_epsilon(self.q_table, self.pi_b_top_k, self.pi_b_epsilon)\n",
        "        behavior_policy = experiment_actions(self.num_trajectories, self.env, behavior_action_probs)\n",
        "\n",
        "        # Define action probabilities for evaluation policy with epsilon = 0.05\n",
        "        evaluation_action_probs = action_probs_top_n_epsilon(self.q_table, self.pi_e_top_k, self.pi_e_epsilon)\n",
        "        evaluation_policy = experiment_actions(1000, self.env, evaluation_action_probs)\n",
        "\n",
        "        # Define and train the model for behavior policy\n",
        "        # behavior_model = CustomizableFeatureNet(input_dim=2, hidden_dims=[16, 16], output_dim=1, dtype=self.dtype, l2_lambda=0.002)\n",
        "        # behavior_test = SCOPE_straight(behavior_model, self.gamma, self.num_bootstraps, behavior_policy, behavior_action_probs, evaluation_action_probs, self.percent_to_estimate_phi, dtype=self.dtype)\n",
        "        # behavior_test.train_var_scope(400, 0.001, 1, 0)\n",
        "        self.train_var_scope(self.num_trajectories, self.learning_rate, self.variance_weight, self.feature_weight)\n",
        "\n",
        "        # Perform the experiment with the defined parameters\n",
        "        # (You might need to adjust the arguments according to your specific setup)\n",
        "        # experiment_results = ...\n",
        "\n",
        "# Create an instance of the SCOPE_experiment class and run the experiment\n",
        "experiment_instance = SCOPE_experiment(model=None, gamma=0.99, num_bootstraps=10000, pi_b=None, P_pi_b=None, P_pi_e=None, percent_to_estimate_phi=0.3, num_trajectories=400, dtype=torch.float64)\n",
        "experiment_instance.run_experiment()\n"
      ],
      "metadata": {
        "id": "n4PXkMgx7Hl7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SCOPE_experiment(SCOPE_straight):\n",
        "    def __init__(self, model, gamma, num_bootstraps, pi_b, P_pi_b, P_pi_e, percent_to_estimate_phi, num_trajectories, env, q_table, pi_b_top_k, pi_b_epsilon, pi_e_top_k, pi_e_epsilon, dtype):\n",
        "        super().__init__(model, gamma, num_bootstraps, pi_b, P_pi_b, P_pi_e, percent_to_estimate_phi, dtype)\n",
        "        self.num_trajectories = num_trajectories\n",
        "        self.env = env\n",
        "        self.q_table = q_table\n",
        "        self.pi_b_top_k = pi_b_top_k\n",
        "        self.pi_b_epsilon = pi_b_epsilon\n",
        "        self.pi_e_top_k = pi_e_top_k\n",
        "        self.pi_e_epsilon = pi_e_epsilon\n",
        "\n",
        "        # self.step_size\n",
        "        # self.l1_regularization\n",
        "        # self.l2_regularization\n",
        "        # self.\n",
        "\n",
        "    def run_experiment(self, num_epochs, learning_rate, scope_weight=1, mse_weight=1):\n",
        "        # Call the train_var_scope() method from the parent class\n",
        "        self.train_var_scope(num_epochs, learning_rate, scope_weight, mse_weight)\n",
        "        # Add additional functionality if needed\n",
        "\n",
        "    # def save_experiment(self):\n",
        "\n",
        "    # def store_experiment_data(self):\n"
      ],
      "metadata": {
        "id": "tOGSZqppFtrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment class breakdown"
      ],
      "metadata": {
        "id": "ptk1mW-x5Fi4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# class SCOPE_experiment()\n",
        "\n",
        "# SCOPE_straight\n",
        "# pi_b, pi_e, P_pi_b, P_pi_e, percent_to_estimate_phi, num_trajectories, num_bootstraps\n",
        "\n",
        "# SCOPE_experiment, Parameters and hyperparameters\n",
        "# Q_table, pi_b_top_k, pi_e_top_k, pi_b_epsilon, pi_e_epsilon\n",
        "# env (lifegate): env length, shaping features, death_drag\n",
        "# l1_reg, l2_reg, dim_sizes, learning_rate, scope_weight, mse_weight\n",
        "\n",
        "# Outline for SCOPE_experiment\n",
        "# Input: policy dependencies and parameters(q_table, top_k, epsilon)\n",
        "# Generate  P_pi_b, P_pi_e, pi_b, pi_e,\n",
        "\n",
        "# Input env and model parameters (max_length, death_drag), (dim_size, lr, l1, l2, scope_weight, mse_weight)\n",
        "# Initialize env with specific parameters\n",
        "# Initialize model with specific parameters\n",
        "\n",
        "# Input chosen feature\n",
        "# Set policy generation to collect that feature (e.g. dist to deadend/recovery)\n",
        "#   modify policy generation (maybe bring into class)\n",
        "#     action_probs_top_n_epsilon for policy, experiment_actions for generation\n",
        "\n",
        "# Input other experiment details\n",
        "# num_trajectories, num_bootstraps, train/test split (p_t_e_phi),\n",
        "\n",
        "# Misc\n",
        "# dtype"
      ],
      "metadata": {
        "id": "R6zdtLlcyvXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SCOPE_experiment(object):\n",
        "  # def __init__(self, model, gamma, num_bootstraps, pi_b, P_pi_b, P_pi_e, percent_to_estimate_phi, num_trajectories, env, q_table, pi_b_top_k, pi_b_epsilon, pi_e_top_k, pi_e_epsilon, dtype)\n",
        "  # def __init__(self, pi_b, P_pi_b, P_pi_e, model, percent_to_estimate_phi, )\n",
        "  def __init__(self, pi_b_top_k, pi_b_epsilon, pi_e_top_k, pi_e_epsilon, q_table, gamma, num_trajectories, num_bootstraps, percent_to_estimate_phi, hidden_dims, learning_rate, l1_reg, l2_reg, scope_weight, mse_weight, max_length, death_drag, shaping_feature, dtype):\n",
        "    self."
      ],
      "metadata": {
        "id": "wpXZ-VyI2FNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Union\n",
        "\n",
        "class SCOPE_experiment():\n",
        "    def __init__(self,\n",
        "                #  Parameters related to policy generation\n",
        "                 pi_b_top_k: int,\n",
        "                 pi_b_epsilon: float,\n",
        "                 pi_e_top_k: int,\n",
        "                 pi_e_epsilon: float,\n",
        "                 q_table,#: List[List[float]],\n",
        "                 gamma: float,\n",
        "                 num_trajectories: int,\n",
        "                 num_bootstraps: int,\n",
        "                 percent_to_estimate_phi: float,\n",
        "                 shaping_feature: str,\n",
        "                #  Parameters related to neural network architecture and training\n",
        "                 hidden_dims: List[int],\n",
        "                 learning_rate: float,\n",
        "                 l1_reg: float,\n",
        "                 l2_reg: float,\n",
        "                 scope_weight: float,\n",
        "                 mse_weight: float,\n",
        "                 num_epochs: int,\n",
        "                #  Parameters related to environment\n",
        "                 max_length: int,\n",
        "                 death_drag: float,\n",
        "\n",
        "                #  Other general parameters\n",
        "                 dtype: str):\n",
        "\n",
        "        self.pi_b_top_k = pi_b_top_k\n",
        "        self.pi_b_epsilon = pi_b_epsilon\n",
        "        self.pi_e_top_k = pi_e_top_k\n",
        "        self.pi_e_epsilon = pi_e_epsilon\n",
        "        self.q_table = q_table\n",
        "        self.gamma = gamma\n",
        "        self.num_trajectories = num_trajectories\n",
        "        self.num_bootstraps = num_bootstraps\n",
        "        self.percent_to_estimate_phi = percent_to_estimate_phi\n",
        "        self.shaping_feature = shaping_feature\n",
        "\n",
        "        self.hidden_dims = hidden_dims\n",
        "        self.learning_rate = learning_rate\n",
        "        self.l1_reg = l1_reg\n",
        "        self.l2_reg = l2_reg\n",
        "        self.scope_weight = scope_weight\n",
        "        self.mse_weight = mse_weight\n",
        "        self.num_epochs = num_epochs\n",
        "\n",
        "        self.max_length = max_length\n",
        "        self.death_drag = death_drag\n",
        "\n",
        "        self.dtype = dtype\n",
        "\n",
        "    def action_probs_top_n_epsilon(self, top_k, epsilon):\n",
        "      \"\"\"\n",
        "      Calculate action probabilities with epsilon-greedy strategy for top actions.\n",
        "\n",
        "      Parameters:\n",
        "      - n: Number of top actions\n",
        "      - epsilon: Exploration-exploitation trade-off parameter\n",
        "\n",
        "      Returns:\n",
        "      - action_probs: Calculated action probabilities\n",
        "      \"\"\"\n",
        "      # Define your epsilon value\n",
        "        # epsilon = 0.01  # Adjust the value of epsilon as needed\n",
        "\n",
        "      num_actions = self.q_table.shape[-1]\n",
        "\n",
        "      # Initialize a 2D array to represent action probabilities\n",
        "      action_probs = np.zeros_like(self.q_table)\n",
        "\n",
        "      # For each state, set the probability for the top two actions\n",
        "      for i in range(self.q_table.shape[0]):\n",
        "          for j in range(self.q_table.shape[1]):\n",
        "              sorted_actions = np.argsort(self.q_table[j, i])  # Get the indices of all actions, sorted by Q-value\n",
        "              top_actions = sorted_actions[-n:]  # Get the indices of the top two actions\n",
        "              non_top_actions = sorted_actions[:-n]\n",
        "              action_probs[i, j, top_actions] = (1 - epsilon) / n + epsilon/num_actions  # Split the probability evenly between the top two actions\n",
        "              action_probs[i, j, non_top_actions] = epsilon/num_actions\n",
        "\n",
        "      return action_probs\n",
        "\n",
        "    # def create_P_pi_b(self):\n",
        "    #   # generate transition dynamics for pi_b\n",
        "    #   return action_probs_top_n_epsilon(self.pi_b_top_k, self.pi_b_epsilon)\n",
        "\n",
        "    # def create_P_pi_e(self):\n",
        "    #   # Generate transition dynamics for pi_e\n",
        "    #   return action_probs_top_n_epsilon(self.pi_e_top_k, self.pi_e_epsilon)\n",
        "\n",
        "    def initialize_env(self):\n",
        "      # Initalize lifegate class\n",
        "      env = LifeGate(max_steps=self.max_length, state_mode='tabular',\n",
        "                        rendering=True, image_saving=False, render_dir=None, rng=random_state, death_drag = self.death_drag)\n",
        "\n",
        "      return env\n",
        "\n",
        "    # def generate_pi_b(self, num_trajectories, env, transition_dynamics):\n",
        "    #   pi_b = experiment_actions()\n",
        "    #   return 1\n",
        "\n",
        "    # def generate_pi_e(self):\n",
        "    #   return 1\n",
        "\n",
        "\n",
        "\n",
        "    def experiment_actions(self, nb_trajectories, env, action_probs)#, shaping_feature):\n",
        "        \"\"\"\n",
        "        Run the experiment for a specified number of episodes.\n",
        "\n",
        "        Parameters:\n",
        "        - nb_episodes: Number of episodes\n",
        "        - env: Experiment environment\n",
        "        - action_probs: Action probabilities\n",
        "\n",
        "        Returns:\n",
        "        - policies: List of policies (pi_b or pi_e)\n",
        "        \"\"\"\n",
        "        # Define the dtype for the structured array\n",
        "        dtype = [\n",
        "            ('state', np.float64, (2,)),\n",
        "            ('action', np.int64),\n",
        "            ('reward', np.float64),\n",
        "            ('state_next', np.float64, (2,)),\n",
        "            ('timestep', np.int64),\n",
        "            # ('dead_end_dist', np.float64),\n",
        "            # ('recovery_dist', np.float64),\n",
        "            # ('psi', np.float64, (2,))\n",
        "            ('psi', np.float64)\n",
        "\n",
        "        ]\n",
        "\n",
        "        policies = []\n",
        "        for i in range(nb_episodes):\n",
        "            trajectory = np.empty(0, dtype=dtype)\n",
        "            s = env.reset()\n",
        "            env.render()\n",
        "            term = False\n",
        "            timestep = 0\n",
        "            while not term:\n",
        "                state_last = s\n",
        "                action = choose_action(tuple(s), action_probs)\n",
        "                s, r, term, _ = env.step(action)\n",
        "\n",
        "                # Need to add feature variation here (e.g. dist to dead end, death, recovery, combo functions, etc.)\n",
        "\n",
        "                # dead_end_dist = smallest_distance_to_deadend(state_last, env)\n",
        "                # recovery_dist = smallest_distance_to_recovery(state_last, env)\n",
        "                # psi = [dead_end_dist, recovery_dist]\n",
        "\n",
        "                psi = smallest_distance_to_deadend(state_last, env)\n",
        "\n",
        "                data_point = np.array([(state_last, action, r, s, timestep, psi)], dtype=dtype)\n",
        "                trajectory = np.append(trajectory, data_point)\n",
        "                timestep += 1\n",
        "\n",
        "            policies.append(trajectory)\n",
        "\n",
        "        with open('policies.pkl', 'wb') as f:\n",
        "            pickle.dump(policies, f)\n",
        "\n",
        "        return policies\n",
        "\n",
        "    def generate_pi_b(self):\n",
        "      return self.experiment_actions(self.num_trajectories, initalize_env(), create_P_pi_b())\n",
        "\n",
        "    def generate_pi_e(self):\n",
        "      return self.experiment_actions(1000, initialize_env(), create_P_pi_e())\n",
        "\n",
        "    def initalize_model(self):\n",
        "      model = NN_l1_l2_reg(input_dim=2, hidden_dims=[6], output_dim=1, dtype = torch.float64, l1_lambda=0.00001, l2_lambda = 0.00001)\n",
        "\n",
        "    def prepare_experiment(self):\n",
        "      env = self.initialize_env()\n",
        "      P_pi_b = self.create_P_pi_b()\n",
        "      P_pi_e = self.create_P_pi_e\n",
        "      pi_b = self.experiment_actions(self.num_trajectories, env, P_pi_b)\n",
        "      pi_e = self.experiment_actions(1000, env, P_pi_e)\n",
        "\n",
        "      # consider changing this to method within class\n",
        "      model = NN_l1_l2_reg(input_dim=2, hidden_dims=self.hidden_sims, output_dim=1, dtype = dtype, l1_lambda=self.l1_reg, l2_lambda = self.l2_reg)\n",
        "\n",
        "      experiment_class = SCOPE_straight(model, self.gamma, self.num_bootstraps, pi_b, P_pi_b, P_pi_e, self.percent_to_estimate_phi, self.dtype)\n",
        "\n",
        "      return pi_b, pi_e, model experiment_class\n",
        "\n",
        "\n",
        "    def run_experiment(self):\n",
        "      pi_b, pi_e, experiment_class = self.prepare_experiment()\n",
        "      experiment_class.train_var_scope(self.num_epochs, self.learning_rate, self.scope_weight, self.mse_weight)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2KfF6_Mg8KNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b_200 = action_probs_top_n_epsilon(q_table, 1, 0.4)\n",
        "pi_b_200 = experiment_actions(200, env_50, P_pi_b_200)\n",
        "P_pi_e_200 = action_probs_top_n_epsilon(q_table, 1, 0.05)\n",
        "pi_e_200 = experiment_actions(1000, env_50, P_pi_e_200)\n",
        "model_200_random_pi_b_200 = CustomizableFeatureNet(input_dim=2, hidden_dims=[16, 16], output_dim=1, dtype = torch.float64, l2_lambda=0.002)\n",
        "test_200_random_pi_b_200 = SCOPE_straight(model_200_random_pi_b_200, 0.99, 10000, pi_b_200, P_pi_b_200, P_pi_e_200, 0.3, dtype = torch.float64)\n",
        "test_200_random_pi_b_200.train_var_scope(400, 0.001, 1, 0)"
      ],
      "metadata": {
        "id": "mpLSXcZthFQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experiments\n",
        "- Trajectory length\n",
        "- Number of trajectories\n",
        "- Train/test split\n",
        "- shaping features"
      ],
      "metadata": {
        "id": "2ZbfdvJ6wQi1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Information to save\n",
        "- architecture\n",
        "- Hyperparameters (regularization, etc.)\n",
        "- weights every 50 epochs\n",
        "- training loss every epoch\n",
        "- test loss every epoch\n",
        "- chosen feature\n",
        "\n",
        "Plots (for each experiment)\n",
        "- train vs test loss over time\n",
        "- variance loss, mse loss (train,test?)\n",
        "- heatmap\n",
        "-"
      ],
      "metadata": {
        "id": "u_qRnStnwuF8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thoughts on naming and running experiments\n",
        "- manual input names I think\n",
        "- have a few different pipelines\n",
        "- Folders for each set of experiments"
      ],
      "metadata": {
        "id": "wbOwZR1-yyHQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yVgoKANAzNE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test class"
      ],
      "metadata": {
        "id": "P6c1J5GDaf86"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env.possible_recoveries"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dN8X3qzxqG1",
        "outputId": "aec683cc-38f6-446b-e7da-9940b08aef3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[5, 0], [6, 0], [7, 0]]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b = action_probs_top_n_epsilon(q_table, 1, 0.4)\n",
        "pi_b = experiment_actions(200, env_50, P_pi_b)\n",
        "P_pi_e = action_probs_top_n_epsilon(q_table, 2, 0.05)\n",
        "# pi_e = experiment_actions(1000, env, P_pi_e)\n",
        "model_200_0p99 = CustomizableFeatureNet(input_dim=2, hidden_dims=[16, 16], output_dim=1, dtype = torch.float64)\n",
        "test_200_0p99 = SCOPE_straight(model_200_0p99, 0.99, 10000, pi_b, P_pi_b, P_pi_e, 0.3, dtype = torch.float64)\n"
      ],
      "metadata": {
        "id": "0ueKh2Cfahjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "timesteps, rewards, states_next, states_current, weights, actions, psi, states_last, psi_last = test_200_0p99.prep_policies(pi_b)"
      ],
      "metadata": {
        "id": "aoDGlkVEB3Tx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, masked_mean_set, last_set = test_200_0p99.train_var_scope(2, 0.001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6SNC1SJOuTQ",
        "outputId": "e62113e0-2f39-4185-92c3-2c2a97092b2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "IS variance:  tensor(6.6645e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0617, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "SCOPE mean: 0.03283755622152981, SCOPE var: 0.005437360955003497\n",
            "Total Loss: 1.0616657317194855\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "IS variance:  tensor(6.6645e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0278, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "SCOPE mean: 0.04225211428680145, SCOPE var: 0.005846893896544516\n",
            "Total Loss: 1.0278019486643444\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[-0.5256, -0.1831],\n",
            "        [ 0.4874, -0.2204],\n",
            "        [ 0.3107,  0.1398],\n",
            "        [ 0.0890, -0.3095],\n",
            "        [ 0.6320,  0.2276],\n",
            "        [-0.2607, -0.6321],\n",
            "        [-0.7033, -0.3404],\n",
            "        [-0.5834, -0.1342],\n",
            "        [ 0.0957, -0.5969],\n",
            "        [-0.4036,  0.4857],\n",
            "        [-0.4621, -0.6912],\n",
            "        [ 0.6774, -0.3109],\n",
            "        [ 0.2194, -0.6755],\n",
            "        [ 0.4790,  0.3212],\n",
            "        [ 0.6565, -0.0203],\n",
            "        [-0.1400, -0.2687]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([ 0.5916,  0.5307,  0.6659,  0.1979,  0.4248,  0.1721,  0.3640,  0.2282,\n",
            "         0.4869,  0.0936,  0.2460, -0.6385,  0.6843, -0.5377, -0.2398,  0.6074],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[ 2.0028e-01, -1.9150e-01, -2.4069e-02,  1.6687e-01,  2.1879e-01,\n",
            "          6.3637e-02,  3.5722e-02, -1.2352e-01, -1.8295e-01, -1.9474e-01,\n",
            "          1.7001e-01,  2.1148e-01, -9.0445e-03,  1.4426e-02, -1.1128e-01,\n",
            "         -5.9484e-02],\n",
            "        [-1.2590e-01, -1.1654e-01,  2.3379e-01,  1.1440e-01, -2.0756e-01,\n",
            "         -2.2469e-01,  3.2124e-02, -1.1786e-01, -1.8041e-01, -3.8652e-02,\n",
            "         -1.8120e-01, -1.6980e-01,  2.4513e-01,  2.0847e-01,  5.5338e-02,\n",
            "          1.1932e-01],\n",
            "        [ 3.1758e-02, -1.3842e-01, -1.3210e-01,  3.3371e-03,  1.8243e-01,\n",
            "         -8.9647e-02,  1.0802e-01,  8.8250e-02, -1.3918e-01,  8.0631e-03,\n",
            "         -2.4271e-02, -2.2108e-01, -1.5716e-01, -3.1119e-02,  1.2950e-02,\n",
            "          6.4989e-02],\n",
            "        [-1.3412e-01,  6.1866e-02,  9.4260e-02,  1.7324e-01,  8.8476e-02,\n",
            "          1.6742e-02,  6.0140e-02,  1.6866e-01, -4.2428e-02, -1.8848e-01,\n",
            "         -2.2014e-01, -1.8238e-01,  5.9408e-02, -2.4772e-01,  1.5292e-02,\n",
            "          1.0134e-02],\n",
            "        [ 2.0735e-01,  1.0819e-01,  2.1480e-01, -2.2879e-01, -1.9573e-01,\n",
            "         -2.4803e-01,  1.3377e-02, -4.9486e-02, -1.0148e-01, -1.5297e-01,\n",
            "          2.0011e-01,  1.5937e-01,  1.5667e-01, -1.8065e-01,  5.4387e-04,\n",
            "         -7.4076e-02],\n",
            "        [ 1.8545e-01, -4.1313e-02, -1.1475e-01,  4.3038e-02,  1.4214e-02,\n",
            "          1.5483e-01,  1.3361e-01,  1.3709e-01, -2.0066e-01,  2.0942e-01,\n",
            "          1.0681e-01,  1.0933e-01,  2.1655e-01,  9.0622e-02, -1.6535e-01,\n",
            "          8.7913e-02],\n",
            "        [-9.4016e-02,  7.5155e-02, -3.9988e-02,  2.2944e-02, -2.2417e-01,\n",
            "          6.1380e-02, -2.0414e-01, -8.1497e-02,  2.1949e-01,  1.3603e-01,\n",
            "          2.4309e-01,  1.5763e-01,  2.4262e-01,  6.3869e-02,  1.9673e-01,\n",
            "         -2.4734e-01],\n",
            "        [ 2.9435e-02,  7.0832e-02, -4.5244e-02,  2.4120e-01,  1.0661e-01,\n",
            "         -1.6126e-01,  1.8163e-01, -1.7269e-01,  1.3298e-01, -7.2866e-02,\n",
            "         -5.8181e-02, -5.0263e-02, -1.2517e-01, -1.0126e-01, -3.6885e-02,\n",
            "          1.2789e-01],\n",
            "        [ 1.1730e-01, -8.5566e-02, -1.6726e-01,  3.8499e-02,  2.3128e-01,\n",
            "         -1.2013e-01,  1.3873e-01,  1.5010e-01,  1.5989e-01, -1.9258e-01,\n",
            "         -1.8497e-01, -1.4312e-01, -1.4654e-01, -1.6513e-01,  2.1496e-01,\n",
            "          1.9387e-01],\n",
            "        [ 9.6692e-02, -2.0030e-01, -9.6532e-02,  1.4838e-01,  1.9529e-01,\n",
            "          1.6996e-01,  1.5586e-01, -1.0916e-01,  2.0352e-01, -7.0839e-02,\n",
            "         -2.4478e-01, -1.9085e-01, -1.8525e-01,  7.3185e-02, -2.4701e-01,\n",
            "          4.4840e-03],\n",
            "        [-6.0516e-02, -2.2240e-01,  2.1518e-01, -1.1809e-03,  2.3576e-01,\n",
            "         -2.0614e-01,  2.1780e-01, -1.8906e-01,  1.3330e-01, -1.9266e-01,\n",
            "          2.2091e-01,  8.0886e-02, -1.9792e-01,  1.4748e-01,  1.7092e-01,\n",
            "         -1.1895e-01],\n",
            "        [ 1.8442e-01, -1.4585e-01,  2.3946e-01, -1.0020e-01,  9.4425e-02,\n",
            "          1.5864e-01,  1.8815e-01,  7.4287e-03,  6.6943e-02, -5.0384e-02,\n",
            "         -1.3912e-04,  1.9527e-01, -7.8683e-03,  1.0256e-01,  2.1907e-01,\n",
            "         -1.9509e-01],\n",
            "        [ 7.2188e-02, -3.6822e-02,  7.0376e-02, -2.4671e-01,  1.7451e-01,\n",
            "         -2.0078e-01, -9.1050e-02,  3.8632e-02, -1.4463e-01, -2.5094e-01,\n",
            "         -1.4911e-02, -8.6221e-02, -7.9463e-02,  1.6998e-01, -1.6597e-02,\n",
            "          1.4905e-02],\n",
            "        [ 1.1007e-01, -4.2570e-02, -2.0597e-01,  5.6226e-02,  5.2142e-02,\n",
            "         -9.3782e-02,  1.5367e-01, -8.0826e-02,  1.4859e-01,  2.1185e-01,\n",
            "         -1.3212e-01,  1.2519e-02, -1.8085e-01, -1.0261e-01,  7.8652e-02,\n",
            "          5.8627e-02],\n",
            "        [-1.6615e-01,  2.3874e-01,  2.4147e-01, -2.2809e-02, -3.0182e-02,\n",
            "          4.9254e-02, -2.2479e-02,  1.1894e-01,  3.1404e-02,  1.4483e-01,\n",
            "          7.3961e-02,  2.4550e-03,  1.2213e-02, -2.1975e-01, -1.0782e-02,\n",
            "          1.6575e-01],\n",
            "        [-9.7037e-02,  1.1045e-01,  1.9928e-01,  6.1813e-02, -3.3081e-02,\n",
            "          7.1479e-02, -1.6773e-01,  2.0375e-01, -3.5086e-02,  9.5235e-02,\n",
            "         -1.7433e-01,  2.3101e-01,  1.4270e-01,  8.7972e-02, -1.5400e-02,\n",
            "         -1.2504e-01]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([ 0.1398, -0.0435, -0.0543,  0.0579,  0.2480,  0.2436,  0.1703,  0.0795,\n",
            "         0.0290,  0.1877, -0.2180,  0.0456, -0.0336,  0.0196,  0.0726,  0.2450],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[ 0.0218,  0.0405,  0.0153,  0.1337, -0.0724,  0.1623,  0.1891, -0.1632,\n",
            "         -0.2339,  0.1723, -0.1185, -0.0502,  0.0947, -0.2086,  0.0915,  0.0249]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([-0.0745], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "masked_mean_set"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8u8r2x9FQ9s9",
        "outputId": "cc53f841-d2b3-4230-9e94-22ff597728c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 9.1995,  5.6653,  6.6862,  5.5858, 10.7349, 11.2185,  8.0980, 11.1943,\n",
              "         7.5683,  5.2833, 10.5943,  8.1137,  8.2862,  7.7130,  7.1801,  5.7873,\n",
              "        13.8663,  6.1387,  4.9187,  6.9743,  9.1391, 10.0840,  6.5897,  4.5218,\n",
              "         7.6901,  4.7775, 14.2380,  8.5109,  4.9762,  6.2620,  7.8673,  5.6961,\n",
              "         5.3566,  5.9950,  1.8361,  6.7066, 11.8596,  4.8783, 10.2837,  5.2763,\n",
              "         5.0988,  3.5132,  5.1391,  9.1433,  6.4432,  5.8137,  5.3222,  7.7351,\n",
              "         8.4064,  5.9786,  9.1857,  6.0923,  5.1522,  8.4583,  3.8289,  6.1480,\n",
              "         8.8692,  9.6334, 14.3951,  3.6950], dtype=torch.float64,\n",
              "       grad_fn=<SumBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mean(masked_mean_set+last_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTgLOn_-QgnC",
        "outputId": "b26f3ad3-1537-4efd-b71a-066053141012"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7.7470, dtype=torch.float64, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "last_set"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N23fx3xTQWnn",
        "outputId": "2199f0ba-ca9f-49eb-c929-9f72cf7db81f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([6.2488e-02, 1.0773e-01, 6.2056e-01, 4.2670e-01, 7.4674e-01, 8.5925e-02,\n",
              "        4.5368e-01, 6.7436e-01, 7.9104e-03, 4.9821e-02, 1.0558e+00, 6.7005e-01,\n",
              "        1.4596e-01, 4.0665e-01, 6.6734e-01, 3.5449e-01, 1.8626e-01, 6.1782e-01,\n",
              "        1.3178e+00, 2.2973e-01, 6.7766e-01, 3.6193e-01, 1.4151e-02, 1.1771e-01,\n",
              "        3.3000e-01, 9.4572e-02, 1.7433e-02, 9.4038e-02, 2.8302e-01, 5.1651e-01,\n",
              "        3.3207e-01, 3.1182e-01, 1.6128e-03, 1.7661e-01, 2.1079e-01, 2.4753e-01,\n",
              "        3.5967e-01, 8.3684e-01, 3.0507e-04, 1.6805e+00, 1.0348e+00, 2.6982e-01,\n",
              "        2.9373e-01, 8.5336e-01, 4.3011e-01, 3.8731e-01, 1.8092e-01, 1.7744e-01,\n",
              "        2.8587e-01, 1.6206e-01, 1.3928e-01, 5.9762e-01, 1.2352e+00, 1.3601e-02,\n",
              "        8.0091e-02, 4.7974e-01, 1.9591e-01, 2.5214e-01, 6.2668e-01, 1.6981e-01],\n",
              "       dtype=torch.float64, grad_fn=<MseLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_200_0p99(torch.tensor(states_last)).squeeze()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERreTGZMNvjM",
        "outputId": "91e130b5-a1b3-4905-9969-5261c1b9cb1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 3.5931e-01,  3.1535e-01,  1.1579e-02,  4.1809e-01,  5.3519e-01,\n",
              "         8.3596e-02, -2.7350e-01, -7.7953e-02,  1.6937e-01,  7.5656e-02,\n",
              "        -5.9883e-01,  1.6519e-01,  5.4058e-01,  1.2196e-01,  7.0372e-03,\n",
              "        -1.7420e-02, -3.2525e-01,  3.3452e-01,  2.4492e-01,  3.1173e-01,\n",
              "        -9.0382e-02, -1.4154e-01, -1.5056e-01, -2.8426e-02, -4.4593e-01,\n",
              "        -2.8394e-01,  3.5727e-01, -5.7754e-01, -1.0026e-01, -9.1278e-02,\n",
              "         3.4936e-02,  3.1954e-01, -4.4189e-01, -1.0707e-01,  7.4240e-02,\n",
              "        -2.0949e-01, -1.4405e-01,  1.8865e-01, -2.4926e-01,  8.7673e-03,\n",
              "         2.9567e-02,  2.9281e-01,  1.1581e-01, -7.9609e-04,  2.1255e-01,\n",
              "        -6.5637e-02,  5.3519e-01,  3.3169e-01, -3.1210e-01,  2.9727e-01,\n",
              "         2.4818e-02,  4.5850e-01, -6.3380e-01,  1.9436e-01, -1.9333e-01,\n",
              "         2.6602e-02,  1.5739e-01,  1.6537e-01,  3.7224e-01, -1.5389e-01,\n",
              "         4.4906e-01, -1.0166e-01,  5.0598e-01, -3.7695e-01,  4.6480e-01,\n",
              "         2.2792e-01,  7.8922e-02, -4.3059e-01,  7.1211e-02, -4.5229e-02,\n",
              "         2.7552e-01,  5.3519e-01,  1.9450e-01, -1.4356e-01,  4.0551e-01,\n",
              "         2.4917e-01, -1.4612e-02, -3.8988e-02, -2.1193e-01,  5.3519e-01,\n",
              "         2.0199e-01,  4.1186e-01,  1.4292e-01,  3.0363e-01,  1.7007e-01,\n",
              "         2.5294e-01, -4.5981e-01, -2.6739e-01,  2.4955e-01,  2.0282e-01,\n",
              "        -1.1858e-01,  5.3519e-01,  1.5739e-01,  1.0239e-01, -8.6099e-01,\n",
              "         1.3699e-01,  4.0551e-01,  1.0043e-01,  5.4835e-01, -3.4195e-01,\n",
              "         6.7293e-01,  3.2125e-01, -6.8539e-02, -1.0237e-01, -8.8974e-02,\n",
              "         9.2004e-02,  2.9503e-01, -2.2997e-01,  3.1942e-01,  2.5019e-01,\n",
              "         3.7599e-01, -2.5283e-01, -6.0688e-01,  8.1666e-01,  2.6025e-01,\n",
              "         5.2121e-01, -3.2835e-01,  2.2098e-01, -3.9652e-03,  5.9655e-01,\n",
              "        -1.7180e-02, -5.6058e-01, -4.5479e-02, -6.7444e-01, -1.4953e-01,\n",
              "         2.0352e-01,  2.2393e-01,  5.2509e-01,  1.8153e-01,  2.8436e-01,\n",
              "        -1.1266e-01, -2.1353e-01, -6.9970e-01,  5.4749e-01, -3.8390e-02,\n",
              "         2.2460e-01, -4.4985e-01, -4.6775e-01,  4.4160e-04,  3.6183e-01,\n",
              "        -1.8838e-01,  6.1184e-01, -2.5283e-01,  4.4746e-01,  3.7109e-01,\n",
              "        -3.6335e-01,  1.5228e-01,  5.3519e-01, -8.2850e-02, -6.6999e-01,\n",
              "         3.6431e-01,  6.2073e-01,  6.9929e-02,  2.7198e-01,  6.3369e-01,\n",
              "         3.4418e-01, -2.5603e-01,  3.0231e-01,  1.0483e-01, -3.7420e-01,\n",
              "        -3.9696e-01, -4.6040e-01,  1.8942e-01, -6.2336e-02, -4.7331e-01,\n",
              "        -3.8913e-01,  6.1400e-01,  1.5141e-01,  5.7370e-01,  4.2501e-01,\n",
              "         5.0276e-02,  1.4292e-01,  1.4216e-01,  1.2180e-01, -3.4243e-02,\n",
              "         3.7539e-01,  6.6186e-01,  3.2594e-01,  9.8536e-02, -8.9099e-02,\n",
              "         3.4764e-01, -3.1273e-01,  2.9250e-01, -5.0072e-01, -2.6978e-01,\n",
              "         6.2904e-01, -3.6279e-01, -5.2317e-02,  4.1254e-01, -5.2884e-01,\n",
              "         1.3391e-01, -1.9145e-01,  5.0684e-01,  2.9481e-01, -2.6739e-01,\n",
              "        -2.0109e-01,  2.5747e-01,  1.6373e-01, -7.2330e-02, -2.0585e-02],\n",
              "       dtype=torch.float64, grad_fn=<SqueezeBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "psi_last"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOiInM2RHQGf",
        "outputId": "ac943fcd-2728-42fb-edca-d395e4105368"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 5.0]"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(states_current[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjzmqAFfIjaf",
        "outputId": "7ae75b3b-a7c3-4dcf-df48-f906367a8b32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(states_all[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-_WT5cLLasO",
        "outputId": "da07a72c-2dcf-4250-ef60-71df67b2b32c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(psi[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxRs7RyMLeht",
        "outputId": "ab8af6a4-05d2-4541-bf57-7763f6d920b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "states_all"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-qng8KXLknk",
        "outputId": "53781bb5-548d-4eae-c7ac-70d40de5487e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[2., 9.],\n",
              "        [2., 9.],\n",
              "        [2., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [3., 3.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 4.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [2., 2.],\n",
              "        [2., 1.],\n",
              "        [2., 1.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 2.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 3.],\n",
              "        [3., 2.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 8.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [1., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [3., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [1., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 5.],\n",
              "        [0., 6.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 3.],\n",
              "        [0., 3.],\n",
              "        [0., 3.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [0., 3.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [2., 4.],\n",
              "        [2., 3.],\n",
              "        [3., 3.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [3., 1.],\n",
              "        [3., 1.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [3., 9.],\n",
              "        [3., 9.],\n",
              "        [3., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [2., 2.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 8.],\n",
              "        [1., 8.],\n",
              "        [1., 7.],\n",
              "        [1., 6.],\n",
              "        [1., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [3., 1.],\n",
              "        [2., 1.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 8.],\n",
              "        [1., 7.],\n",
              "        [1., 8.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [1., 8.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 3.],\n",
              "        [0., 4.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [2., 4.],\n",
              "        [2., 4.],\n",
              "        [2., 3.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [2., 2.],\n",
              "        [1., 2.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 3.],\n",
              "        [3., 2.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 3.],\n",
              "        [3., 4.],\n",
              "        [3., 3.],\n",
              "        [4., 3.],\n",
              "        [4., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 3.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [6., 1.],\n",
              "        [6., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [4., 2.],\n",
              "        [4., 2.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [3., 3.],\n",
              "        [3., 4.],\n",
              "        [2., 4.],\n",
              "        [2., 4.],\n",
              "        [2., 3.],\n",
              "        [2., 4.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [2., 8.],\n",
              "        [1., 8.],\n",
              "        [2., 8.],\n",
              "        [1., 8.],\n",
              "        [1., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [4., 2.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [2., 9.],\n",
              "        [2., 9.],\n",
              "        [3., 9.],\n",
              "        [3., 8.],\n",
              "        [3., 9.],\n",
              "        [2., 9.],\n",
              "        [2., 9.],\n",
              "        [3., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 8.],\n",
              "        [1., 8.],\n",
              "        [1., 7.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [0., 4.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 2.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [3., 3.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 8.],\n",
              "        [1., 8.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 2.],\n",
              "        [0., 2.],\n",
              "        [0., 1.],\n",
              "        [0., 2.],\n",
              "        [0., 3.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [2., 4.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [2., 8.],\n",
              "        [1., 8.],\n",
              "        [1., 7.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 8.],\n",
              "        [1., 8.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [0., 3.],\n",
              "        [0., 4.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [2., 1.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [4., 2.],\n",
              "        [4., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 8.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 4.],\n",
              "        [2., 4.],\n",
              "        [2., 3.],\n",
              "        [2., 4.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [4., 1.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [2., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 8.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [2., 4.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [1., 2.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [2., 2.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [2., 1.],\n",
              "        [3., 1.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [4., 2.],\n",
              "        [4., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 3.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [2., 1.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [6., 1.],\n",
              "        [6., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [4., 2.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [1., 8.],\n",
              "        [1., 8.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [2., 4.],\n",
              "        [2., 4.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [2., 1.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [4., 2.],\n",
              "        [4., 2.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [1., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 3.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [2., 2.],\n",
              "        [1., 2.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [3., 1.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [1., 8.],\n",
              "        [1., 7.],\n",
              "        [2., 7.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [1., 6.],\n",
              "        [0., 6.],\n",
              "        [1., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 3.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 2.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 3.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [1., 2.],\n",
              "        [1., 1.],\n",
              "        [2., 1.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [4., 2.],\n",
              "        [4., 1.],\n",
              "        [3., 1.],\n",
              "        [3., 1.],\n",
              "        [2., 1.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 1.],\n",
              "        [6., 1.],\n",
              "        [6., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [2., 8.],\n",
              "        [1., 8.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [1., 8.],\n",
              "        [2., 8.],\n",
              "        [3., 8.],\n",
              "        [3., 9.],\n",
              "        [3., 8.],\n",
              "        [2., 8.],\n",
              "        [3., 8.],\n",
              "        [2., 8.],\n",
              "        [1., 8.],\n",
              "        [2., 8.],\n",
              "        [1., 8.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [1., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [2., 4.],\n",
              "        [2., 3.],\n",
              "        [3., 3.],\n",
              "        [3., 2.],\n",
              "        [3., 3.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [2., 9.],\n",
              "        [2., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [1., 8.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [1., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [0., 3.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [2., 2.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [2., 1.],\n",
              "        [2., 1.],\n",
              "        [3., 1.],\n",
              "        [2., 1.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [2., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 8.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 4.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 3.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [6., 1.],\n",
              "        [6., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [2., 1.],\n",
              "        [1., 1.],\n",
              "        [1., 2.],\n",
              "        [1., 3.],\n",
              "        [0., 3.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [4., 2.],\n",
              "        [4., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 3.],\n",
              "        [0., 2.],\n",
              "        [0., 2.],\n",
              "        [0., 1.],\n",
              "        [0., 2.],\n",
              "        [0., 2.],\n",
              "        [0., 3.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [0., 4.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 2.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [6., 1.],\n",
              "        [6., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [1., 7.],\n",
              "        [1., 6.],\n",
              "        [1., 6.],\n",
              "        [1., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [2., 1.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 8.],\n",
              "        [1., 8.],\n",
              "        [1., 7.],\n",
              "        [2., 7.],\n",
              "        [2., 8.],\n",
              "        [2., 7.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [4., 1.],\n",
              "        [4., 2.],\n",
              "        [4., 2.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [0., 3.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 4.],\n",
              "        [2., 4.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [6., 1.],\n",
              "        [6., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 8.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [4., 2.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [1., 7.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [1., 3.],\n",
              "        [1., 3.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [1., 2.],\n",
              "        [1., 3.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [1., 2.],\n",
              "        [1., 2.],\n",
              "        [1., 2.],\n",
              "        [2., 2.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [2., 1.],\n",
              "        [2., 1.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 2.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 4.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [2., 3.],\n",
              "        [2., 4.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [6., 1.],\n",
              "        [6., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [1., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 4.],\n",
              "        [0., 4.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [2., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 3.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 3.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [2., 8.],\n",
              "        [1., 8.],\n",
              "        [2., 8.],\n",
              "        [2., 8.],\n",
              "        [1., 8.],\n",
              "        [2., 8.],\n",
              "        [1., 8.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [4., 2.],\n",
              "        [4., 1.],\n",
              "        [4., 2.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [1., 7.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [0., 3.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 4.],\n",
              "        [2., 4.],\n",
              "        [2., 4.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [1., 2.],\n",
              "        [1., 3.],\n",
              "        [0., 3.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [2., 4.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [2., 2.],\n",
              "        [2., 1.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [6., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [4., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [2., 8.],\n",
              "        [3., 8.],\n",
              "        [3., 7.],\n",
              "        [2., 7.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [4., 2.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [3., 9.],\n",
              "        [4., 9.],\n",
              "        [3., 9.],\n",
              "        [3., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 4.],\n",
              "        [2., 4.],\n",
              "        [2., 3.],\n",
              "        [1., 3.],\n",
              "        [0., 3.],\n",
              "        [0., 3.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [0., 3.],\n",
              "        [0., 4.],\n",
              "        [0., 4.],\n",
              "        [0., 4.],\n",
              "        [0., 4.],\n",
              "        [0., 3.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 3.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [4., 2.],\n",
              "        [4., 3.],\n",
              "        [3., 3.],\n",
              "        [3., 4.],\n",
              "        [3., 3.],\n",
              "        [4., 3.],\n",
              "        [4., 2.],\n",
              "        [5., 2.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [2., 9.],\n",
              "        [2., 9.],\n",
              "        [3., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [2., 1.],\n",
              "        [1., 1.],\n",
              "        [1., 2.],\n",
              "        [2., 2.],\n",
              "        [2., 1.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [3., 1.],\n",
              "        [3., 1.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [1., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [2., 1.],\n",
              "        [1., 1.],\n",
              "        [1., 2.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [0., 3.],\n",
              "        [0., 4.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 3.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [3., 9.],\n",
              "        [3., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [1., 8.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [2., 4.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [2., 9.],\n",
              "        [2., 8.],\n",
              "        [1., 8.],\n",
              "        [1., 7.],\n",
              "        [1., 8.],\n",
              "        [1., 8.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 3.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 4.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [2., 9.],\n",
              "        [2., 9.],\n",
              "        [3., 9.],\n",
              "        [4., 9.],\n",
              "        [3., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [2., 1.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 3.],\n",
              "        [0., 4.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [4., 2.],\n",
              "        [5., 2.],\n",
              "        [5., 1.],\n",
              "        [5., 2.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 8.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [1., 7.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 4.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 3.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [2., 1.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [1., 2.],\n",
              "        [2., 2.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [2., 1.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [2., 8.],\n",
              "        [1., 8.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 6.],\n",
              "        [1., 6.],\n",
              "        [1., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [3., 1.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [4., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [1., 7.],\n",
              "        [1., 6.],\n",
              "        [0., 6.],\n",
              "        [1., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 4.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [2., 2.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [4., 2.],\n",
              "        [4., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [1., 8.],\n",
              "        [1., 7.],\n",
              "        [1., 8.],\n",
              "        [0., 8.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [2., 8.],\n",
              "        [1., 8.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [2., 4.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 8.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 3.],\n",
              "        [1., 2.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [3., 3.],\n",
              "        [3., 2.],\n",
              "        [2., 2.],\n",
              "        [2., 1.],\n",
              "        [2., 2.],\n",
              "        [1., 2.],\n",
              "        [1., 3.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [2., 9.],\n",
              "        [3., 9.],\n",
              "        [4., 9.],\n",
              "        [3., 9.],\n",
              "        [4., 9.],\n",
              "        [3., 9.],\n",
              "        [2., 9.],\n",
              "        [2., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 8.],\n",
              "        [1., 7.],\n",
              "        [1., 8.],\n",
              "        [1., 7.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 7.],\n",
              "        [0., 7.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [2., 4.],\n",
              "        [3., 4.],\n",
              "        [3., 3.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [3., 1.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [1., 7.],\n",
              "        [1., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [2., 9.],\n",
              "        [2., 9.],\n",
              "        [2., 8.],\n",
              "        [1., 8.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 3.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [2., 4.],\n",
              "        [3., 4.],\n",
              "        [3., 3.],\n",
              "        [3., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 8.],\n",
              "        [2., 8.],\n",
              "        [3., 8.],\n",
              "        [3., 8.],\n",
              "        [3., 7.],\n",
              "        [3., 8.],\n",
              "        [2., 8.],\n",
              "        [1., 8.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [2., 1.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [2., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [1., 8.],\n",
              "        [1., 7.],\n",
              "        [1., 8.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [1., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [3., 3.],\n",
              "        [4., 3.],\n",
              "        [4., 2.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 8.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [1., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 2.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [4., 1.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [2., 9.],\n",
              "        [2., 9.],\n",
              "        [2., 9.],\n",
              "        [2., 8.],\n",
              "        [1., 8.],\n",
              "        [1., 7.],\n",
              "        [2., 7.],\n",
              "        [1., 7.],\n",
              "        [2., 7.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 3.],\n",
              "        [4., 3.],\n",
              "        [4., 2.],\n",
              "        [4., 2.],\n",
              "        [4., 3.],\n",
              "        [4., 4.],\n",
              "        [4., 4.],\n",
              "        [4., 3.],\n",
              "        [4., 2.],\n",
              "        [3., 2.],\n",
              "        [2., 2.],\n",
              "        [2., 1.],\n",
              "        [1., 1.],\n",
              "        [1., 1.],\n",
              "        [1., 1.],\n",
              "        [1., 2.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [4., 2.],\n",
              "        [4., 1.],\n",
              "        [4., 2.],\n",
              "        [4., 3.],\n",
              "        [4., 2.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [2., 9.],\n",
              "        [3., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 8.],\n",
              "        [1., 8.],\n",
              "        [2., 8.],\n",
              "        [1., 8.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 4.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [6., 1.],\n",
              "        [6., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 8.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [1., 8.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [2., 4.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 3.],\n",
              "        [3., 2.],\n",
              "        [3., 3.],\n",
              "        [4., 3.],\n",
              "        [4., 2.],\n",
              "        [4., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 3.],\n",
              "        [0., 4.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 3.],\n",
              "        [0., 4.],\n",
              "        [0., 3.],\n",
              "        [0., 3.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [2., 1.],\n",
              "        [2., 2.],\n",
              "        [1., 2.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 8.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [2., 1.],\n",
              "        [3., 1.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [2., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 8.],\n",
              "        [1., 8.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [4., 2.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [1., 3.],\n",
              "        [1., 2.],\n",
              "        [1., 3.],\n",
              "        [1., 2.],\n",
              "        [1., 3.],\n",
              "        [1., 2.],\n",
              "        [2., 2.],\n",
              "        [1., 2.],\n",
              "        [1., 3.],\n",
              "        [1., 2.],\n",
              "        [0., 2.],\n",
              "        [0., 3.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 2.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [6., 1.],\n",
              "        [7., 1.],\n",
              "        [7., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [3., 9.],\n",
              "        [3., 9.],\n",
              "        [2., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 2.],\n",
              "        [5., 2.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [2., 9.],\n",
              "        [3., 9.],\n",
              "        [2., 9.],\n",
              "        [2., 9.],\n",
              "        [2., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 8.],\n",
              "        [0., 8.],\n",
              "        [0., 8.],\n",
              "        [0., 8.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 8.],\n",
              "        [1., 8.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 3.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [2., 1.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [1., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [2., 4.],\n",
              "        [2., 3.],\n",
              "        [2., 4.],\n",
              "        [3., 4.],\n",
              "        [3., 3.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [0., 3.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 3.],\n",
              "        [3., 2.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [4., 1.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 2.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [2., 2.],\n",
              "        [2., 3.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [4., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [6., 1.],\n",
              "        [7., 1.],\n",
              "        [7., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [1., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [0., 3.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [2., 4.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [3., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 8.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [1., 6.],\n",
              "        [2., 6.],\n",
              "        [1., 6.],\n",
              "        [0., 6.],\n",
              "        [1., 6.],\n",
              "        [2., 6.],\n",
              "        [1., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [3., 3.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 7.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 6.],\n",
              "        [1., 6.],\n",
              "        [0., 6.],\n",
              "        [1., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [4., 2.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 8.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [1., 8.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [2., 1.],\n",
              "        [2., 1.],\n",
              "        [2., 2.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [3., 1.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 8.],\n",
              "        [0., 8.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [1., 8.],\n",
              "        [1., 7.],\n",
              "        [1., 6.],\n",
              "        [1., 6.],\n",
              "        [0., 6.],\n",
              "        [1., 6.],\n",
              "        [1., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [1., 6.],\n",
              "        [2., 6.],\n",
              "        [3., 6.],\n",
              "        [3., 7.],\n",
              "        [2., 7.],\n",
              "        [2., 6.],\n",
              "        [1., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [0., 4.],\n",
              "        [0., 3.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [0., 3.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [0., 4.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [2., 4.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [4., 2.],\n",
              "        [3., 2.],\n",
              "        [4., 2.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [2., 1.],\n",
              "        [2., 1.],\n",
              "        [2., 2.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [4., 2.],\n",
              "        [4., 3.],\n",
              "        [4., 2.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [6., 1.],\n",
              "        [6., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [2., 8.],\n",
              "        [1., 8.],\n",
              "        [1., 8.],\n",
              "        [1., 7.],\n",
              "        [1., 8.],\n",
              "        [1., 7.],\n",
              "        [1., 6.],\n",
              "        [2., 6.],\n",
              "        [3., 6.],\n",
              "        [2., 6.],\n",
              "        [2., 7.],\n",
              "        [2., 6.],\n",
              "        [2., 7.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [0., 3.],\n",
              "        [0., 3.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 4.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 4.],\n",
              "        [2., 3.],\n",
              "        [3., 3.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [2., 1.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [4., 2.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 8.],\n",
              "        [2., 8.],\n",
              "        [3., 8.],\n",
              "        [2., 8.],\n",
              "        [1., 8.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 2.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 2.],\n",
              "        [0., 2.],\n",
              "        [0., 1.],\n",
              "        [0., 2.],\n",
              "        [0., 3.],\n",
              "        [1., 3.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [4., 2.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [2., 8.],\n",
              "        [1., 8.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 3.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 8.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [1., 2.],\n",
              "        [1., 1.],\n",
              "        [1., 2.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [3., 3.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [4., 2.],\n",
              "        [4., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 8.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [0., 3.],\n",
              "        [0., 3.],\n",
              "        [0., 3.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [3., 3.],\n",
              "        [3., 4.],\n",
              "        [2., 4.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 3.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [6., 1.],\n",
              "        [6., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [2., 8.],\n",
              "        [3., 8.],\n",
              "        [2., 8.],\n",
              "        [2., 8.],\n",
              "        [3., 8.],\n",
              "        [3., 8.],\n",
              "        [3., 8.],\n",
              "        [2., 8.],\n",
              "        [1., 8.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 4.],\n",
              "        [0., 3.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [0., 3.],\n",
              "        [0., 3.],\n",
              "        [0., 3.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 4.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [4., 2.],\n",
              "        [4., 3.],\n",
              "        [3., 3.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [2., 9.],\n",
              "        [2., 8.],\n",
              "        [3., 8.],\n",
              "        [3., 7.],\n",
              "        [3., 6.],\n",
              "        [2., 6.],\n",
              "        [1., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [3., 3.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [4., 2.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [4., 1.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [0., 4.],\n",
              "        [0., 4.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [2., 2.],\n",
              "        [1., 2.],\n",
              "        [1., 1.],\n",
              "        [1., 2.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [1., 2.],\n",
              "        [1., 1.],\n",
              "        [1., 1.],\n",
              "        [1., 2.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [4., 2.],\n",
              "        [4., 2.],\n",
              "        [4., 2.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 6.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 7.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [2., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 8.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [2., 1.],\n",
              "        [2., 1.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [2., 1.],\n",
              "        [2., 2.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 3.],\n",
              "        [3., 2.],\n",
              "        [2., 2.],\n",
              "        [2., 3.],\n",
              "        [2., 4.],\n",
              "        [2., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 4.],\n",
              "        [3., 4.],\n",
              "        [3., 3.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [1., 8.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [2., 4.],\n",
              "        [2., 3.],\n",
              "        [2., 4.],\n",
              "        [2., 3.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [2., 2.],\n",
              "        [2., 1.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [2., 4.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [4., 2.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [6., 1.],\n",
              "        [6., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 8.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 6.],\n",
              "        [1., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [1., 6.],\n",
              "        [0., 6.],\n",
              "        [1., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [2., 1.],\n",
              "        [2., 2.],\n",
              "        [2., 1.],\n",
              "        [2., 1.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 8.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [3., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 3.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [3., 3.],\n",
              "        [3., 4.],\n",
              "        [3., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [2., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 2.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [1., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 2.],\n",
              "        [4., 2.],\n",
              "        [4., 3.],\n",
              "        [4., 2.],\n",
              "        [4., 3.],\n",
              "        [4., 2.],\n",
              "        [4., 1.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 8.],\n",
              "        [1., 7.],\n",
              "        [1., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 4.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [1., 6.],\n",
              "        [1., 6.],\n",
              "        [1., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [3., 3.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [2., 9.],\n",
              "        [3., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [1., 7.],\n",
              "        [1., 6.],\n",
              "        [1., 7.],\n",
              "        [2., 7.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [1., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [2., 8.],\n",
              "        [1., 8.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [3., 3.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [3., 9.],\n",
              "        [3., 8.],\n",
              "        [2., 8.],\n",
              "        [2., 8.],\n",
              "        [1., 8.],\n",
              "        [1., 7.],\n",
              "        [1., 6.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 6.],\n",
              "        [0., 7.],\n",
              "        [0., 7.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 4.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [2., 1.],\n",
              "        [1., 1.],\n",
              "        [1., 2.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [1., 6.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 4.],\n",
              "        [0., 3.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [1., 3.],\n",
              "        [0., 3.],\n",
              "        [0., 4.],\n",
              "        [0., 4.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [3., 1.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [4., 2.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [2., 9.],\n",
              "        [2., 8.],\n",
              "        [1., 8.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 7.],\n",
              "        [1., 7.],\n",
              "        [1., 8.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [2., 9.],\n",
              "        [2., 8.],\n",
              "        [1., 8.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [1., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 4.],\n",
              "        [2., 3.],\n",
              "        [2., 3.],\n",
              "        [3., 3.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 2.],\n",
              "        [5., 1.],\n",
              "        [6., 1.],\n",
              "        [6., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 8.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 2.],\n",
              "        [1., 3.],\n",
              "        [0., 3.],\n",
              "        [0., 4.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [1., 2.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 2.],\n",
              "        [4., 2.],\n",
              "        [4., 2.],\n",
              "        [4., 3.],\n",
              "        [4., 2.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [6., 1.],\n",
              "        [6., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [2., 9.],\n",
              "        [2., 8.],\n",
              "        [2., 8.],\n",
              "        [1., 8.],\n",
              "        [1., 7.],\n",
              "        [1., 6.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [1., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 3.],\n",
              "        [0., 4.],\n",
              "        [0., 4.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 2.],\n",
              "        [1., 3.],\n",
              "        [1., 2.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [3., 3.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [1., 6.],\n",
              "        [1., 7.],\n",
              "        [1., 7.],\n",
              "        [2., 7.],\n",
              "        [1., 7.],\n",
              "        [2., 7.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [3., 3.],\n",
              "        [3., 3.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 4.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [2., 3.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [3., 3.],\n",
              "        [3., 2.],\n",
              "        [3., 3.],\n",
              "        [4., 3.],\n",
              "        [4., 2.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [2., 4.],\n",
              "        [3., 4.],\n",
              "        [3., 3.],\n",
              "        [3., 2.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [4., 2.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 8.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [1., 7.],\n",
              "        [2., 7.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 3.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [2., 1.],\n",
              "        [2., 2.],\n",
              "        [2., 1.],\n",
              "        [2., 1.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [3., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [6., 1.],\n",
              "        [6., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 3.],\n",
              "        [0., 4.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [2., 2.],\n",
              "        [1., 2.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [3., 1.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 2.],\n",
              "        [6., 2.],\n",
              "        [6., 1.],\n",
              "        [6., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [1., 7.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [2., 2.],\n",
              "        [2., 3.],\n",
              "        [3., 3.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 4.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [3., 3.],\n",
              "        [3., 2.],\n",
              "        [2., 2.],\n",
              "        [1., 2.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [3., 1.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [6., 1.],\n",
              "        [6., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [1., 8.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [1., 8.],\n",
              "        [1., 7.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [1., 2.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [6., 1.],\n",
              "        [6., 1.],\n",
              "        [6., 2.],\n",
              "        [6., 1.],\n",
              "        [6., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 3.],\n",
              "        [1., 2.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [1., 2.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 8.],\n",
              "        [1., 7.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 3.],\n",
              "        [0., 4.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 3.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 2.],\n",
              "        [4., 2.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [6., 1.],\n",
              "        [6., 2.],\n",
              "        [6., 3.],\n",
              "        [5., 3.],\n",
              "        [4., 3.],\n",
              "        [4., 2.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 8.],\n",
              "        [0., 8.],\n",
              "        [1., 8.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 8.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [1., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [0., 4.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 3.],\n",
              "        [3., 2.],\n",
              "        [3., 3.],\n",
              "        [3., 4.],\n",
              "        [4., 4.],\n",
              "        [5., 4.],\n",
              "        [4., 4.],\n",
              "        [4., 3.],\n",
              "        [4., 2.],\n",
              "        [4., 1.],\n",
              "        [4., 2.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [2., 8.],\n",
              "        [3., 8.],\n",
              "        [2., 8.],\n",
              "        [1., 8.],\n",
              "        [1., 7.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [4., 2.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 7.],\n",
              "        [0., 8.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 2.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [1., 3.],\n",
              "        [1., 2.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [3., 1.],\n",
              "        [2., 1.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [4., 2.],\n",
              "        [5., 2.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [2., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [1., 2.],\n",
              "        [1., 2.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 4.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [2., 3.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [2., 2.],\n",
              "        [2., 1.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [4., 2.],\n",
              "        [4., 2.],\n",
              "        [4., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [3., 1.],\n",
              "        [2., 1.],\n",
              "        [2., 1.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [4., 1.],\n",
              "        [4., 2.],\n",
              "        [4., 1.],\n",
              "        [4., 2.],\n",
              "        [4., 1.],\n",
              "        [4., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [6., 1.],\n",
              "        [6., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 8.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [2., 1.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [2., 2.],\n",
              "        [2., 2.],\n",
              "        [2., 1.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [2., 1.],\n",
              "        [1., 1.],\n",
              "        [1., 1.],\n",
              "        [1., 2.],\n",
              "        [1., 2.],\n",
              "        [1., 3.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [3., 3.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 4.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [2., 4.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [3., 2.],\n",
              "        [3., 3.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [2., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [3., 9.],\n",
              "        [4., 9.],\n",
              "        [3., 9.],\n",
              "        [3., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [1., 7.],\n",
              "        [1., 8.],\n",
              "        [1., 7.],\n",
              "        [1., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [2., 2.],\n",
              "        [1., 2.],\n",
              "        [1., 2.],\n",
              "        [1., 2.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [1., 2.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [3., 3.],\n",
              "        [3., 2.],\n",
              "        [3., 3.],\n",
              "        [4., 3.],\n",
              "        [4., 2.],\n",
              "        [4., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [0., 3.],\n",
              "        [0., 3.],\n",
              "        [0., 3.],\n",
              "        [0., 3.],\n",
              "        [0., 4.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 3.],\n",
              "        [0., 4.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [3., 2.],\n",
              "        [3., 3.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [4., 2.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 2.],\n",
              "        [6., 2.],\n",
              "        [6., 1.],\n",
              "        [6., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 4.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [4., 2.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [1., 8.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 3.],\n",
              "        [0., 3.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 2.],\n",
              "        [4., 2.],\n",
              "        [5., 2.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [1., 2.],\n",
              "        [1., 3.],\n",
              "        [1., 3.],\n",
              "        [1., 2.],\n",
              "        [1., 3.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [4., 1.],\n",
              "        [4., 2.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 2.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 8.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [1., 6.],\n",
              "        [0., 6.],\n",
              "        [1., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 2.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [1., 2.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [1., 7.],\n",
              "        [1., 8.],\n",
              "        [1., 7.],\n",
              "        [1., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 3.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [2., 8.],\n",
              "        [1., 8.],\n",
              "        [1., 8.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 4.],\n",
              "        [0., 3.],\n",
              "        [0., 4.],\n",
              "        [0., 4.],\n",
              "        [0., 3.],\n",
              "        [0., 3.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [1., 2.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [3., 3.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 2.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 8.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 2.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [2., 2.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [3., 1.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [2., 4.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [1., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 3.],\n",
              "        [4., 3.],\n",
              "        [4., 3.],\n",
              "        [4., 2.],\n",
              "        [4., 3.],\n",
              "        [3., 3.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [4., 1.],\n",
              "        [4., 2.],\n",
              "        [4., 1.],\n",
              "        [4., 2.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 8.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 3.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 3.],\n",
              "        [3., 4.],\n",
              "        [3., 3.],\n",
              "        [3., 3.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [1., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [1., 7.],\n",
              "        [2., 7.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [0., 3.],\n",
              "        [0., 4.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [2., 3.],\n",
              "        [1., 3.],\n",
              "        [1., 2.],\n",
              "        [1., 3.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [2., 3.],\n",
              "        [3., 3.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [2., 1.],\n",
              "        [2., 2.],\n",
              "        [2., 3.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 3.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [1., 3.],\n",
              "        [0., 3.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [4., 2.],\n",
              "        [5., 2.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 3.],\n",
              "        [3., 2.],\n",
              "        [4., 2.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [1., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [2., 4.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [1., 2.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [1., 3.],\n",
              "        [1., 4.],\n",
              "        [2., 4.],\n",
              "        [2., 4.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [4., 2.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [2., 8.],\n",
              "        [3., 8.],\n",
              "        [2., 8.],\n",
              "        [1., 8.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 8.],\n",
              "        [1., 8.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [1., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 2.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [2., 1.],\n",
              "        [2., 1.],\n",
              "        [1., 1.],\n",
              "        [1., 1.],\n",
              "        [1., 2.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 8.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 3.],\n",
              "        [0., 3.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [2., 1.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [2., 1.],\n",
              "        [3., 1.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [6., 1.],\n",
              "        [6., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [4., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 3.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [2., 4.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [2., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 4.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [3., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [2., 1.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [4., 2.],\n",
              "        [4., 3.],\n",
              "        [4., 2.],\n",
              "        [4., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [2., 9.],\n",
              "        [3., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [1., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 2.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [2., 1.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [0., 3.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 4.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [1., 7.],\n",
              "        [1., 6.],\n",
              "        [0., 6.],\n",
              "        [1., 6.],\n",
              "        [1., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [2., 8.],\n",
              "        [1., 8.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [2., 3.],\n",
              "        [3., 3.],\n",
              "        [3., 3.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 3.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [3., 2.],\n",
              "        [4., 2.],\n",
              "        [4., 1.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 2.],\n",
              "        [6., 2.],\n",
              "        [6., 1.],\n",
              "        [6., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [2., 4.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 3.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [3., 3.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [2., 9.],\n",
              "        [1., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [1., 7.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [1., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 4.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [3., 1.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [3., 9.],\n",
              "        [3., 8.],\n",
              "        [4., 8.],\n",
              "        [3., 8.],\n",
              "        [2., 8.],\n",
              "        [1., 8.],\n",
              "        [1., 7.],\n",
              "        [1., 7.],\n",
              "        [1., 6.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [2., 4.],\n",
              "        [2., 4.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]]),\n",
              " array([[2., 9.],\n",
              "        [1., 9.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 8.],\n",
              "        [0., 9.],\n",
              "        [0., 8.],\n",
              "        [0., 7.],\n",
              "        [0., 6.],\n",
              "        [0., 5.],\n",
              "        [0., 4.],\n",
              "        [0., 4.],\n",
              "        [0., 3.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [1., 2.],\n",
              "        [1., 3.],\n",
              "        [0., 3.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [0., 3.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [0., 4.],\n",
              "        [1., 4.],\n",
              "        [1., 3.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [2., 3.],\n",
              "        [2., 2.],\n",
              "        [3., 2.],\n",
              "        [3., 1.],\n",
              "        [4., 1.],\n",
              "        [5., 1.],\n",
              "        [5., 0.]])]"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "states_next[0][-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBtz8QT8KiSM",
        "outputId": "fb5eee64-38c8-4440-cb3b-2c3f7255f47a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.vstack((states_current[0],states_next[0][-1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oZSzB_LKJba",
        "outputId": "3e5e0e8d-32f5-47b3-f91f-eb088ad62738"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2., 9.],\n",
              "       [2., 8.],\n",
              "       [1., 8.],\n",
              "       [1., 7.],\n",
              "       [0., 7.],\n",
              "       [0., 7.],\n",
              "       [0., 6.],\n",
              "       [0., 5.],\n",
              "       [0., 5.],\n",
              "       [0., 4.],\n",
              "       [1., 4.],\n",
              "       [1., 3.],\n",
              "       [2., 3.],\n",
              "       [2., 3.],\n",
              "       [2., 4.],\n",
              "       [2., 4.],\n",
              "       [2., 4.],\n",
              "       [2., 3.],\n",
              "       [2., 3.],\n",
              "       [2., 2.],\n",
              "       [3., 2.],\n",
              "       [4., 2.],\n",
              "       [4., 1.],\n",
              "       [5., 1.],\n",
              "       [5., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "psi[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBOckqaxIME-",
        "outputId": "d0d2cb34-5bd3-45ad-ce0b-a7504e88bf41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 8.,  8.,  9.,  9., 10., 10., 10., 10., 10., 11., 10., 11., 10.,\n",
              "       10.,  9.,  9.,  9., 10., 10., 11., 10.,  9., 10.,  9.])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(states_next[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PmZa67xGh0F",
        "outputId": "64432f6a-a788-4d3f-a09d-84ec3f9a8e09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_timestep_tensors_IS, padded_reward_tensors_IS, padded_weight_tensors_IS = test_200_0p99.prepare_IS()\n",
        "timestep_bootstraps_IS, rewards_bootstraps_IS, weights_bootstraps_IS, IS_boostraps = test_200_0p99.bootstrap_IS(padded_timestep_tensors_IS, padded_reward_tensors_IS, padded_weight_tensors_IS)\n",
        "test_200_0p99.calc_variance_IS(timestep_bootstraps_IS, rewards_bootstraps_IS, weights_bootstraps_IS)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MW7zKTJ_DBHR",
        "outputId": "5354153a-87ad-48a2-c418-8435477186b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1634, dtype=torch.float64), tensor(0.0052, dtype=torch.float64))"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_200_0p99.calc_var_IS(IS_boostraps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olV3qblhET_6",
        "outputId": "c84fcd84-b7ca-4b55-b96e-0bfe41d03abd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1634, dtype=torch.float64), tensor(0.0052, dtype=torch.float64))"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors, padded_states_next_tensors, padded_states_current_tensors, padded_psi_tensors, mask_tensor = test_200_0p99.prepare_SCOPE_phi()\n",
        "\n",
        "states_next_output, states_current_output = test_200_0p99.pass_states(padded_states_next_tensors, padded_states_current_tensors)\n",
        "timestep_bootstraps, rewards_bootstraps, weights_bootstraps, phi_states_next_bootstraps, phi_states_current_bootstraps, scope_bootstraps = test_200_0p99.bootstrap_straight(padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors, states_next_output, states_current_output)\n",
        "test_200_0p99.calc_variance_straight(timestep_bootstraps, weights_bootstraps, rewards_bootstraps, phi_states_next_bootstraps, phi_states_current_bootstraps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l92kGwjEGKCG",
        "outputId": "1ef58d54-6844-4e77-cf44-036680aa5441"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.2590, dtype=torch.float64, grad_fn=<MeanBackward0>),\n",
              " tensor(0.0194, dtype=torch.float64, grad_fn=<VarBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_200_0p99.calc_var_straight(scope_bootstraps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "zIA5o7oiGmZI",
        "outputId": "49a176cb-302b-407d-d9fd-7ca73b4981f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'scope_bootstraps' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-96-c0298a2939f7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_200_0p99\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc_var_straight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscope_bootstraps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'scope_bootstraps' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IS_variance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAxZ9xNCD9ef",
        "outputId": "faaa96ba-a2bd-4728-9933-7c1fa3b14955"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0052, dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QrNhNl4FEN7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_200_0p99.get_state_visitation_heatmap()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "rbQIhOmDerdg",
        "outputId": "994c6891-f557-4de1-fae3-4a110cb60746"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"9b404d8c-a962-44ce-ba75-acabb0838fb6\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"9b404d8c-a962-44ce-ba75-acabb0838fb6\")) {                    Plotly.newPlot(                        \"9b404d8c-a962-44ce-ba75-acabb0838fb6\",                        [{\"colorbar\":{\"title\":{\"text\":\"Visits\"}},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"x\":[0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9],\"y\":[9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0],\"z\":[0,0,12,42,295,344,344,332,254,268,0,1,33,233,266,0,104,214,155,316,0,25,194,238,70,0,33,57,70,365,0,146,192,81,27,0,8,13,25,101,0,176,89,32,7,0,0,1,4,18,82,146,30,9,1,0,0,0,3,4,17,35,6,2,0,0,0,0,2,5,3,4,1,0,0,0,0,0,2,6,0,0,0,0,0,0,0,0,6,5,0,0,0,0,0,0,0,0,2,4],\"zmax\":365,\"zmin\":0,\"type\":\"heatmap\"}],                        {\"title\":{\"text\":\"State Visitations Heatmap\"},\"xaxis\":{\"title\":{\"text\":\"X-axis\"}},\"yaxis\":{\"ticktext\":[9,8,7,6,5,4,3,2,1,0],\"tickvals\":[0,1,2,3,4,5,6,7,8,9],\"title\":{\"text\":\"Y-axis\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('9b404d8c-a962-44ce-ba75-acabb0838fb6');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_200_0p99.IS_pipeline()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqq1JfG4oFEw",
        "outputId": "e1c3659f-c459-4944-ec70-565fcfbfa060"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0040, dtype=torch.float64), tensor(5.4213e-06, dtype=torch.float64))"
            ]
          },
          "metadata": {},
          "execution_count": 244
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pi_e = experiment_actions(1000, env_30, P_pi_e)\n"
      ],
      "metadata": {
        "id": "mqgINIVonyQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calc_V_pi_e(pi_e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5Qjc3OHnlwK",
        "outputId": "06a3cbd9-e6db-4e9b-d1e3-dc0dee39a86c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.02618155036170724"
            ]
          },
          "metadata": {},
          "execution_count": 243
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_200_0p99.evaluate_scope()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvFwsJRZoT4N",
        "outputId": "379cb0f9-40f4-4d32-a0a6-7f0fb96eb008"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1136, dtype=torch.float64, grad_fn=<MeanBackward0>),\n",
              " tensor(0.0029, dtype=torch.float64, grad_fn=<VarBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 241
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6bkJmw-NDCM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, masked_mean_set, last_set = test_200_0p99.train_var_scope(2, 0.001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "VlkljTT0j4JH",
        "outputId": "d82d7661-57bb-4f9f-e5d6-c98f4969a803"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "SCOPE_straight.pass_states() missing 1 required positional argument: 'states_last_tensor'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-125-8b94e0865e19>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasked_mean_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_200_0p99\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_var_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-123-0704e7a7b845>\u001b[0m in \u001b[0;36mtrain_var_scope\u001b[0;34m(self, num_epochs, learning_rate, scope_weight, mse_weight)\u001b[0m\n\u001b[1;32m    334\u001b[0m           \u001b[0;31m# timestep_bootstraps, rewards_bootstraps, weights_bootstraps, phi_states_next_bootstraps, phi_states_current_bootstraps = self.pass_then_boostraps(padded_states_next_tensors, padded_states_current_tensors, padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m           \u001b[0mstates_next_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates_current_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates_last_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpass_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_states_next_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded_states_current_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m           \u001b[0;31m# timestep_bootstraps, rewards_bootstraps, weights_bootstraps, phi_states_next_bootstraps, phi_states_current_bootstraps = self.bootstrap_straight(padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors, states_next_output, states_current_output)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m           \u001b[0;31m# SCOPE_mean, SCOPE_variance = self.calc_variance_straight(timestep_bootstraps, weights_bootstraps, rewards_bootstraps, phi_states_next_bootstraps, phi_states_current_bootstraps)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: SCOPE_straight.pass_states() missing 1 required positional argument: 'states_last_tensor'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.sum(masked_mean_set, dim = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMRG1lr8L3F5",
        "outputId": "bd1a0fad-a795-4ab8-f3d9-4399b7e2b5ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 8.5748,  4.6997,  9.4879,  5.7368,  8.7992, 12.2325,  9.0167,  7.4956,\n",
              "         8.9889,  5.5547,  7.1841,  6.8971, 11.3291,  4.0391, 10.0364,  7.8897,\n",
              "        10.0546,  5.6250,  4.2488,  5.0116,  6.4645,  8.6754,  9.2830,  5.0178,\n",
              "         7.2064,  4.4252,  5.2096,  9.4458,  5.3339, 12.6139, 14.0995,  5.3023,\n",
              "         5.8995,  5.9573,  7.1260,  6.6979, 12.6700,  8.7708, 14.1373,  8.8810,\n",
              "         7.4070,  5.6319,  1.4903,  6.4208,  6.5101,  5.2310,  5.2161, 14.1081,\n",
              "         6.2500,  7.6385,  8.8202,  5.3136,  4.6834,  4.8666,  4.5748,  8.1876,\n",
              "         7.9586,  6.6502,  6.2471,  4.7426], dtype=torch.float64,\n",
              "       grad_fn=<SumBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jUKoS77NMVcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_200_0p99.get_heatmap()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "V2sqlHKDE65f",
        "outputId": "72717d56-56de-41a5-b049-33848bc2c434"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"e2a185e0-65c0-4651-a516-5b47c3065a23\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e2a185e0-65c0-4651-a516-5b47c3065a23\")) {                    Plotly.newPlot(                        \"e2a185e0-65c0-4651-a516-5b47c3065a23\",                        [{\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"z\":[[1.2573835235247308,1.2121116654714608,1.1587351689698597,1.0890393940416507,1.0143056557679528,0.9313090597505751,0.8617729024957921,0.7990076466821899,0.7863456886466722,0.7935801778973488],[1.2085112588915081,1.1447958576670236,1.0763351059032564,1.0085342461033484,0.9261172825975943,0.8430389301719439,0.7746020564704048,0.741816423590127,0.7446123538621187,0.7474082841341105],[1.1608238213578468,1.0686309357924135,0.999458143835136,0.9209255054446135,0.8378471530189628,0.7588457113284159,0.7119414787474538,0.7139412153216829,0.7159409518959121,0.7179406884701411],[1.102010651711113,0.9940693603348467,0.9217957703562543,0.8329516342763816,0.773211480386571,0.716345506869289,0.7112311541046606,0.7061168013400325,0.7010024485754043,0.696073439815705],[1.043197482064379,0.9195077848772799,0.8423047753818742,0.7539253516512923,0.7228384307397022,0.7335278061688246,0.7325797350048119,0.7274653822401836,0.7238386239661239,0.7252619876969071],[0.9843843124176452,0.8526603800237074,0.7623998416838216,0.6848788916865534,0.6905980953960853,0.7203209153389134,0.7455386055634718,0.7674313287201477,0.7688546924509307,0.770278056181714],[0.9255711427709115,0.792202055974766,0.6757299752566394,0.6422186844752651,0.6598373101034973,0.7010700377790475,0.7316068938838929,0.7819053791481336,0.8138707609357378,0.8152941246665208],[0.8742660305588956,0.7417301144605792,0.615215816155854,0.6190760999009567,0.6499261689755642,0.6841347317017943,0.7209907204988244,0.7679736674685547,0.8182721527327954,0.860310193151328],[0.8430430198758123,0.7016719275101029,0.6162651307470943,0.6132226274070283,0.6484645336032338,0.6826644829368832,0.7191854482513631,0.7560414370483931,0.8043404410532164,0.8546389263174571],[0.8406265836133788,0.7374925532162699,0.6446115994179221,0.6239035536900341,0.6439497755453332,0.6795331901853141,0.7173801760039018,0.7542361648009319,0.791092153597962,0.8407072146378782]],\"type\":\"heatmap\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"Values\"},\"ticks\":\"outside\",\"tickvals\":[0.6132226274070283,1.2573835235247308],\"ticktext\":[0.6132226274070283,1.2573835235247308]}},\"xaxis\":{\"tickvals\":[0,1,2,3,4,5,6,7,8,9],\"ticktext\":[0,1,2,3,4,5,6,7,8,9],\"title\":{\"text\":\"X\"}},\"yaxis\":{\"tickvals\":[9,8,7,6,5,4,3,2,1,0],\"ticktext\":[9,8,7,6,5,4,3,2,1,0],\"title\":{\"text\":\"Y\"},\"autorange\":\"reversed\"},\"title\":{\"text\":\"Heatmap\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('e2a185e0-65c0-4651-a516-5b47c3065a23');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test random policy"
      ],
      "metadata": {
        "id": "1enrp4izvB3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b = action_probs_top_n_epsilon(q_table, 1, 0.4)\n",
        "pi_b = experiment_actions(200, env_30, P_pi_b)\n",
        "P_pi_e = action_probs_top_n_epsilon(q_table, 5, 0.05)\n",
        "# pi_e = experiment_actions(200, env_30, P_pi_e)\n",
        "model_200_random = CustomizableFeatureNet(input_dim=2, hidden_dims=[16, 16], output_dim=1, dtype = torch.float64)\n",
        "test_200_random = SCOPE_straight(model_200_random, 0.99, 10000, pi_b, P_pi_b, P_pi_e, 0.3, dtype = torch.float64)\n"
      ],
      "metadata": {
        "id": "o1Yatyj_vBQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_200_random.get_state_visitation_heatmap()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "fjpFSy9G3lEH",
        "outputId": "4526e9aa-acc8-4a51-a708-c567d838a230"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"b6b91938-caae-430b-8d88-c7dbe4d911de\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"b6b91938-caae-430b-8d88-c7dbe4d911de\")) {                    Plotly.newPlot(                        \"b6b91938-caae-430b-8d88-c7dbe4d911de\",                        [{\"colorbar\":{\"title\":{\"text\":\"Visits\"}},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"x\":[0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9],\"y\":[9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0],\"z\":[0,1,10,50,268,338,363,345,239,264,0,4,35,214,223,0,118,213,144,300,0,24,167,233,64,0,57,46,79,391,0,160,177,65,16,0,17,14,32,122,0,194,64,19,8,0,4,1,10,27,66,127,23,5,0,0,1,0,4,17,14,30,15,1,0,0,1,0,3,11,4,11,5,0,0,0,1,0,5,11,1,1,1,0,0,0,1,0,3,18,0,0,1,0,0,0,1,0,3,9],\"zmax\":391,\"zmin\":0,\"type\":\"heatmap\"}],                        {\"title\":{\"text\":\"State Visitations Heatmap\"},\"xaxis\":{\"title\":{\"text\":\"X-axis\"}},\"yaxis\":{\"ticktext\":[9,8,7,6,5,4,3,2,1,0],\"tickvals\":[0,1,2,3,4,5,6,7,8,9],\"title\":{\"text\":\"Y-axis\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('b6b91938-caae-430b-8d88-c7dbe4d911de');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_200_random.train_var_scope(200, 0.001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haUOaqCUwE1Z",
        "outputId": "61573e7c-84a8-4e29-a3d1-43b4ddf79a36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0005218583187486271\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.8199e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.819862798753365e-06\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0250e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.024958128773479e-05\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.3286e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.328558541237725e-06\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.3393e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.339343710615368e-06\n",
            "----------------------------------------\n",
            "Epoch 6\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.6211e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.6211430442459475e-06\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2653e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.265335151122525e-06\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0510e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.051047600597096e-06\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8702e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.870209703818152e-06\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7126e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.712563882034527e-06\n",
            "----------------------------------------\n",
            "Epoch 11\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5836e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.583572711832976e-06\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4577e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.4576827574062896e-06\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3125e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.3124976815032185e-06\n",
            "----------------------------------------\n",
            "Epoch 14\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.0066e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.006596834226985e-06\n",
            "----------------------------------------\n",
            "Epoch 15\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.6917e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.69172072462017e-06\n",
            "----------------------------------------\n",
            "Epoch 16\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.4814e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.481446272610602e-06\n",
            "----------------------------------------\n",
            "Epoch 17\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.4082e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.408237363289505e-06\n",
            "----------------------------------------\n",
            "Epoch 18\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.3609e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.360898500363375e-06\n",
            "----------------------------------------\n",
            "Epoch 19\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.2893e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.289300722576919e-06\n",
            "----------------------------------------\n",
            "Epoch 20\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.1854e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.185418847790483e-06\n",
            "----------------------------------------\n",
            "Epoch 21\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.0697e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.069714783891458e-06\n",
            "----------------------------------------\n",
            "Epoch 22\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.9426e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.942574680761142e-06\n",
            "----------------------------------------\n",
            "Epoch 23\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.7829e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.7829417752681105e-06\n",
            "----------------------------------------\n",
            "Epoch 24\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.5794e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.57935947901364e-06\n",
            "----------------------------------------\n",
            "Epoch 25\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.3608e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.360810140060177e-06\n",
            "----------------------------------------\n",
            "Epoch 26\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.1808e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.1807924057078715e-06\n",
            "----------------------------------------\n",
            "Epoch 27\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.0601e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.060120898765123e-06\n",
            "----------------------------------------\n",
            "Epoch 28\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.9717e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.9717408236799345e-06\n",
            "----------------------------------------\n",
            "Epoch 29\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.8730e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.872999221427799e-06\n",
            "----------------------------------------\n",
            "Epoch 30\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.7516e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.7516474596638177e-06\n",
            "----------------------------------------\n",
            "Epoch 31\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.6306e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.6305590452069293e-06\n",
            "----------------------------------------\n",
            "Epoch 32\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.5235e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.523523543249152e-06\n",
            "----------------------------------------\n",
            "Epoch 33\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.4194e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.4194498364047354e-06\n",
            "----------------------------------------\n",
            "Epoch 34\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.3129e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.3128939880993014e-06\n",
            "----------------------------------------\n",
            "Epoch 35\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.2141e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.214062016990148e-06\n",
            "----------------------------------------\n",
            "Epoch 36\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.1367e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.1367109298641893e-06\n",
            "----------------------------------------\n",
            "Epoch 37\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.0838e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.083815783841163e-06\n",
            "----------------------------------------\n",
            "Epoch 38\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.0376e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.0375979569506807e-06\n",
            "----------------------------------------\n",
            "Epoch 39\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.9805e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.9805008954865997e-06\n",
            "----------------------------------------\n",
            "Epoch 40\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.9141e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.914083240956638e-06\n",
            "----------------------------------------\n",
            "Epoch 41\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.8499e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.8498630487635488e-06\n",
            "----------------------------------------\n",
            "Epoch 42\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.7934e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.79340060248865e-06\n",
            "----------------------------------------\n",
            "Epoch 43\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.7418e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.7417869716767264e-06\n",
            "----------------------------------------\n",
            "Epoch 44\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.6932e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.693229088537973e-06\n",
            "----------------------------------------\n",
            "Epoch 45\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.6521e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.652083330895247e-06\n",
            "----------------------------------------\n",
            "Epoch 46\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.6183e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.6182684387381757e-06\n",
            "----------------------------------------\n",
            "Epoch 47\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.5885e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.588513485400126e-06\n",
            "----------------------------------------\n",
            "Epoch 48\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.5554e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.5554372379718102e-06\n",
            "----------------------------------------\n",
            "Epoch 49\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.5175e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.5175046438766148e-06\n",
            "----------------------------------------\n",
            "Epoch 50\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.4801e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.480053377309589e-06\n",
            "----------------------------------------\n",
            "Epoch 51\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.4473e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.447324435934277e-06\n",
            "----------------------------------------\n",
            "Epoch 52\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.4183e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.418310600076487e-06\n",
            "----------------------------------------\n",
            "Epoch 53\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.3903e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.390265070521835e-06\n",
            "----------------------------------------\n",
            "Epoch 54\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.3637e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.3637086263004655e-06\n",
            "----------------------------------------\n",
            "Epoch 55\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.3383e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.3383400083150835e-06\n",
            "----------------------------------------\n",
            "Epoch 56\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.3125e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.31250659928688e-06\n",
            "----------------------------------------\n",
            "Epoch 57\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.2847e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.2846957422101712e-06\n",
            "----------------------------------------\n",
            "Epoch 58\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.2560e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.2559596512447755e-06\n",
            "----------------------------------------\n",
            "Epoch 59\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.2286e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.228577050500867e-06\n",
            "----------------------------------------\n",
            "Epoch 60\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.2033e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.2033493843786976e-06\n",
            "----------------------------------------\n",
            "Epoch 61\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.1797e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.1797144203416527e-06\n",
            "----------------------------------------\n",
            "Epoch 62\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.1562e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.156154608006684e-06\n",
            "----------------------------------------\n",
            "Epoch 63\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.1327e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.132736368288874e-06\n",
            "----------------------------------------\n",
            "Epoch 64\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.1098e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.1098159459796553e-06\n",
            "----------------------------------------\n",
            "Epoch 65\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0874e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.087387176553559e-06\n",
            "----------------------------------------\n",
            "Epoch 66\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0654e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.0653765430733716e-06\n",
            "----------------------------------------\n",
            "Epoch 67\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0440e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.0440016768329383e-06\n",
            "----------------------------------------\n",
            "Epoch 68\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0238e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.023774640913568e-06\n",
            "----------------------------------------\n",
            "Epoch 69\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0046e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.004644345872273e-06\n",
            "----------------------------------------\n",
            "Epoch 70\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9855e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.9855444021115104e-06\n",
            "----------------------------------------\n",
            "Epoch 71\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9664e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.9664473496712084e-06\n",
            "----------------------------------------\n",
            "Epoch 72\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9480e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.9479648155239455e-06\n",
            "----------------------------------------\n",
            "Epoch 73\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9302e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.930246841945334e-06\n",
            "----------------------------------------\n",
            "Epoch 74\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9135e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.913469938622366e-06\n",
            "----------------------------------------\n",
            "Epoch 75\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8966e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8966349425248998e-06\n",
            "----------------------------------------\n",
            "Epoch 76\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8803e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8802689506063122e-06\n",
            "----------------------------------------\n",
            "Epoch 77\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8646e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8646384465865746e-06\n",
            "----------------------------------------\n",
            "Epoch 78\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8494e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8494220482641309e-06\n",
            "----------------------------------------\n",
            "Epoch 79\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8342e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.834248940106725e-06\n",
            "----------------------------------------\n",
            "Epoch 80\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8194e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8193945827479823e-06\n",
            "----------------------------------------\n",
            "Epoch 81\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8050e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8050239952374909e-06\n",
            "----------------------------------------\n",
            "Epoch 82\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7911e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.7910790319948859e-06\n",
            "----------------------------------------\n",
            "Epoch 83\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7775e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.777472533367116e-06\n",
            "----------------------------------------\n",
            "Epoch 84\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7643e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.7642696400697195e-06\n",
            "----------------------------------------\n",
            "Epoch 85\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7514e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.7513736303655654e-06\n",
            "----------------------------------------\n",
            "Epoch 86\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7386e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.7386393443419527e-06\n",
            "----------------------------------------\n",
            "Epoch 87\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7261e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.72605917588156e-06\n",
            "----------------------------------------\n",
            "Epoch 88\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7137e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.7137111172087957e-06\n",
            "----------------------------------------\n",
            "Epoch 89\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7017e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.70168246177967e-06\n",
            "----------------------------------------\n",
            "Epoch 90\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.6898e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.6898050135129278e-06\n",
            "----------------------------------------\n",
            "Epoch 91\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.6781e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.678111787146935e-06\n",
            "----------------------------------------\n",
            "Epoch 92\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.6667e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.666665924812708e-06\n",
            "----------------------------------------\n",
            "Epoch 93\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.6554e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.6554311453160312e-06\n",
            "----------------------------------------\n",
            "Epoch 94\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.6443e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.6443288200276103e-06\n",
            "----------------------------------------\n",
            "Epoch 95\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.6333e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.6332934110030025e-06\n",
            "----------------------------------------\n",
            "Epoch 96\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.6224e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.6224489114033852e-06\n",
            "----------------------------------------\n",
            "Epoch 97\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.6118e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.6118267902468544e-06\n",
            "----------------------------------------\n",
            "Epoch 98\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.6014e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.6013985499298854e-06\n",
            "----------------------------------------\n",
            "Epoch 99\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.5912e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.591187594489545e-06\n",
            "----------------------------------------\n",
            "Epoch 100\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.5811e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.5811012101060652e-06\n",
            "----------------------------------------\n",
            "Epoch 101\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.5711e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.57113862838106e-06\n",
            "----------------------------------------\n",
            "Epoch 102\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.5613e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.56128487380117e-06\n",
            "----------------------------------------\n",
            "Epoch 103\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.5516e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.5515787813700968e-06\n",
            "----------------------------------------\n",
            "Epoch 104\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.5420e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.5420405119450996e-06\n",
            "----------------------------------------\n",
            "Epoch 105\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.5326e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.5325912797062999e-06\n",
            "----------------------------------------\n",
            "Epoch 106\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.5233e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.5232583624091237e-06\n",
            "----------------------------------------\n",
            "Epoch 107\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.5140e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.5140374537668416e-06\n",
            "----------------------------------------\n",
            "Epoch 108\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.5049e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.5049193258219863e-06\n",
            "----------------------------------------\n",
            "Epoch 109\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4959e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.495938102032153e-06\n",
            "----------------------------------------\n",
            "Epoch 110\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4872e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.4871653763708906e-06\n",
            "----------------------------------------\n",
            "Epoch 111\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4785e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.4785098772109553e-06\n",
            "----------------------------------------\n",
            "Epoch 112\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4700e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.4699533544220917e-06\n",
            "----------------------------------------\n",
            "Epoch 113\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4615e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.4614845358204992e-06\n",
            "----------------------------------------\n",
            "Epoch 114\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4531e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.4530988801505674e-06\n",
            "----------------------------------------\n",
            "Epoch 115\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4448e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.444794670666121e-06\n",
            "----------------------------------------\n",
            "Epoch 116\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4366e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.4366200492836897e-06\n",
            "----------------------------------------\n",
            "Epoch 117\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4286e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.4285575526343965e-06\n",
            "----------------------------------------\n",
            "Epoch 118\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4206e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.4206169498874845e-06\n",
            "----------------------------------------\n",
            "Epoch 119\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4128e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.412758364642678e-06\n",
            "----------------------------------------\n",
            "Epoch 120\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4049e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.4049271362319458e-06\n",
            "----------------------------------------\n",
            "Epoch 121\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3972e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3971676686681605e-06\n",
            "----------------------------------------\n",
            "Epoch 122\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3895e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3895229745871703e-06\n",
            "----------------------------------------\n",
            "Epoch 123\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3820e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3819691075902093e-06\n",
            "----------------------------------------\n",
            "Epoch 124\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3745e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3744673334075072e-06\n",
            "----------------------------------------\n",
            "Epoch 125\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3670e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3670360353007032e-06\n",
            "----------------------------------------\n",
            "Epoch 126\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3597e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3596744211206814e-06\n",
            "----------------------------------------\n",
            "Epoch 127\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3523e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.352348448508024e-06\n",
            "----------------------------------------\n",
            "Epoch 128\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3450e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3450428355096257e-06\n",
            "----------------------------------------\n",
            "Epoch 129\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3378e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3377695234585822e-06\n",
            "----------------------------------------\n",
            "Epoch 130\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3305e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.33053801186768e-06\n",
            "----------------------------------------\n",
            "Epoch 131\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3234e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3233702453599088e-06\n",
            "----------------------------------------\n",
            "Epoch 132\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3163e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3163022681213861e-06\n",
            "----------------------------------------\n",
            "Epoch 133\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3094e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3093599621481132e-06\n",
            "----------------------------------------\n",
            "Epoch 134\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3023e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3023491527108688e-06\n",
            "----------------------------------------\n",
            "Epoch 135\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2955e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2954738530788846e-06\n",
            "----------------------------------------\n",
            "Epoch 136\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2886e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2886319027444451e-06\n",
            "----------------------------------------\n",
            "Epoch 137\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2818e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2818478290293494e-06\n",
            "----------------------------------------\n",
            "Epoch 138\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2752e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2752080422592504e-06\n",
            "----------------------------------------\n",
            "Epoch 139\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2688e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2687634407935566e-06\n",
            "----------------------------------------\n",
            "Epoch 140\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2623e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.262301999489526e-06\n",
            "----------------------------------------\n",
            "Epoch 141\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2560e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.255998893826394e-06\n",
            "----------------------------------------\n",
            "Epoch 142\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2495e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2494783983748676e-06\n",
            "----------------------------------------\n",
            "Epoch 143\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2430e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.242969612112399e-06\n",
            "----------------------------------------\n",
            "Epoch 144\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2367e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2366863057883822e-06\n",
            "----------------------------------------\n",
            "Epoch 145\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2305e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.230498586588437e-06\n",
            "----------------------------------------\n",
            "Epoch 146\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2243e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2243098508692354e-06\n",
            "----------------------------------------\n",
            "Epoch 147\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2181e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2181108655731147e-06\n",
            "----------------------------------------\n",
            "Epoch 148\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2119e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2119121829076057e-06\n",
            "----------------------------------------\n",
            "Epoch 149\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2057e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2057381808493915e-06\n",
            "----------------------------------------\n",
            "Epoch 150\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1998e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1997800473889394e-06\n",
            "----------------------------------------\n",
            "Epoch 151\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1937e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1937131089699019e-06\n",
            "----------------------------------------\n",
            "Epoch 152\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1876e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1876458393676022e-06\n",
            "----------------------------------------\n",
            "Epoch 153\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1818e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.181773606693398e-06\n",
            "----------------------------------------\n",
            "Epoch 154\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1759e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1758905989545526e-06\n",
            "----------------------------------------\n",
            "Epoch 155\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1700e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1699926729808505e-06\n",
            "----------------------------------------\n",
            "Epoch 156\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1640e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.163994028472344e-06\n",
            "----------------------------------------\n",
            "Epoch 157\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1581e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1581407484250805e-06\n",
            "----------------------------------------\n",
            "Epoch 158\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1522e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1522375862878014e-06\n",
            "----------------------------------------\n",
            "Epoch 159\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1464e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1464352317216299e-06\n",
            "----------------------------------------\n",
            "Epoch 160\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1407e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1406573996968808e-06\n",
            "----------------------------------------\n",
            "Epoch 161\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1349e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1348688616956476e-06\n",
            "----------------------------------------\n",
            "Epoch 162\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1291e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1291225899890357e-06\n",
            "----------------------------------------\n",
            "Epoch 163\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1234e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1234246321396223e-06\n",
            "----------------------------------------\n",
            "Epoch 164\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1177e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1176959485926347e-06\n",
            "----------------------------------------\n",
            "Epoch 165\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1120e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1119844601246873e-06\n",
            "----------------------------------------\n",
            "Epoch 166\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1065e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.106545404528081e-06\n",
            "----------------------------------------\n",
            "Epoch 167\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1010e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1009598616667592e-06\n",
            "----------------------------------------\n",
            "Epoch 168\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0953e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0952879991166997e-06\n",
            "----------------------------------------\n",
            "Epoch 169\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0898e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.089796881799858e-06\n",
            "----------------------------------------\n",
            "Epoch 170\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0843e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0843320026362492e-06\n",
            "----------------------------------------\n",
            "Epoch 171\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0789e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0788984591451425e-06\n",
            "----------------------------------------\n",
            "Epoch 172\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0735e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.073479139144111e-06\n",
            "----------------------------------------\n",
            "Epoch 173\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0681e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0681016344893633e-06\n",
            "----------------------------------------\n",
            "Epoch 174\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0628e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.062755341972131e-06\n",
            "----------------------------------------\n",
            "Epoch 175\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0574e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0574296328530208e-06\n",
            "----------------------------------------\n",
            "Epoch 176\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0522e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0522455339942676e-06\n",
            "----------------------------------------\n",
            "Epoch 177\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0470e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0469772202589901e-06\n",
            "----------------------------------------\n",
            "Epoch 178\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0418e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0417855918657226e-06\n",
            "----------------------------------------\n",
            "Epoch 179\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0367e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0366911934089256e-06\n",
            "----------------------------------------\n",
            "Epoch 180\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0316e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0316145825176385e-06\n",
            "----------------------------------------\n",
            "Epoch 181\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0265e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0265281392125857e-06\n",
            "----------------------------------------\n",
            "Epoch 182\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0214e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.021445206457885e-06\n",
            "----------------------------------------\n",
            "Epoch 183\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0164e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.016406392588562e-06\n",
            "----------------------------------------\n",
            "Epoch 184\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0115e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0114971322467864e-06\n",
            "----------------------------------------\n",
            "Epoch 185\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0066e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.006569971077742e-06\n",
            "----------------------------------------\n",
            "Epoch 186\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0018e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0018493962329524e-06\n",
            "----------------------------------------\n",
            "Epoch 187\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.9700e-07, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.970021111012322e-07\n",
            "----------------------------------------\n",
            "Epoch 188\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.9221e-07, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.92208605463252e-07\n",
            "----------------------------------------\n",
            "Epoch 189\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.8756e-07, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.87559806023695e-07\n",
            "----------------------------------------\n",
            "Epoch 190\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.8290e-07, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.828956505026449e-07\n",
            "----------------------------------------\n",
            "Epoch 191\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.7822e-07, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.782213794239675e-07\n",
            "----------------------------------------\n",
            "Epoch 192\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.7367e-07, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.736746673102684e-07\n",
            "----------------------------------------\n",
            "Epoch 193\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.6909e-07, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.690934024226122e-07\n",
            "----------------------------------------\n",
            "Epoch 194\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.6459e-07, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.645924509598353e-07\n",
            "----------------------------------------\n",
            "Epoch 195\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.6012e-07, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.60123381744426e-07\n",
            "----------------------------------------\n",
            "Epoch 196\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.5564e-07, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.55641787749128e-07\n",
            "----------------------------------------\n",
            "Epoch 197\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.5122e-07, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.512165528154774e-07\n",
            "----------------------------------------\n",
            "Epoch 198\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.4685e-07, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.46854749711329e-07\n",
            "----------------------------------------\n",
            "Epoch 199\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.4257e-07, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.425665982668925e-07\n",
            "----------------------------------------\n",
            "Epoch 200\n",
            "IS variance:  tensor(8.9415e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.3830e-07, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.382997772972921e-07\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[-0.4160, -0.5639],\n",
            "        [-0.0252,  0.5018],\n",
            "        [-0.2653, -0.4130],\n",
            "        [-0.4997,  0.5405],\n",
            "        [-0.1369,  0.1777],\n",
            "        [-0.5486,  0.5722],\n",
            "        [-0.5864,  0.2929],\n",
            "        [ 0.0592, -0.6384],\n",
            "        [ 0.1675, -0.5224],\n",
            "        [ 0.5592, -0.0803],\n",
            "        [-0.3333,  0.2056],\n",
            "        [-0.1957,  0.1838],\n",
            "        [ 0.1333,  0.1802],\n",
            "        [-0.2681, -0.1993],\n",
            "        [-0.1323, -0.1753],\n",
            "        [ 0.4818,  0.4107]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([ 0.5324,  0.6085,  0.4263, -0.1060,  0.0831, -0.1741, -0.2859, -0.2251,\n",
            "        -0.2082, -0.1651,  0.4732,  0.3228,  0.3390,  0.5883, -0.2635, -0.4474],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[ 0.1070, -0.2702, -0.0483, -0.2136,  0.1762,  0.1867, -0.1716,  0.1543,\n",
            "         -0.0730, -0.2434,  0.0650,  0.1376, -0.1726, -0.0664, -0.0461, -0.0685],\n",
            "        [ 0.2396, -0.1336, -0.0745, -0.0321, -0.0140,  0.1095,  0.1047, -0.1067,\n",
            "         -0.0900,  0.3086, -0.1483, -0.1186, -0.2119,  0.0208,  0.2383, -0.0535],\n",
            "        [-0.2005, -0.1586,  0.0359, -0.2290, -0.2166, -0.0359, -0.2091,  0.0215,\n",
            "         -0.0640,  0.0093, -0.1375,  0.0683,  0.0392,  0.0846, -0.0960, -0.1645],\n",
            "        [ 0.0424, -0.0669,  0.0631, -0.1053, -0.1674, -0.0228,  0.0862, -0.0299,\n",
            "          0.0131, -0.2525, -0.1101,  0.2235, -0.1300,  0.0178, -0.0321,  0.0657],\n",
            "        [-0.0862, -0.1556, -0.0223,  0.1965,  0.2476,  0.0061,  0.2042, -0.0860,\n",
            "          0.0050, -0.0380,  0.1883,  0.1462, -0.0586,  0.1278, -0.2156, -0.0348],\n",
            "        [-0.0610, -0.0633, -0.0139, -0.1922,  0.0268,  0.2602, -0.1128, -0.1555,\n",
            "         -0.0180, -0.2591,  0.1349, -0.1974, -0.2445,  0.0949,  0.1655,  0.0896],\n",
            "        [-0.1709, -0.0613,  0.1730,  0.1006,  0.0804,  0.1342, -0.1666, -0.0862,\n",
            "         -0.1633,  0.0841, -0.2249, -0.2067,  0.0528,  0.1978, -0.0231, -0.1150],\n",
            "        [ 0.0101, -0.1598,  0.0618, -0.1438,  0.1242,  0.1703, -0.1244,  0.1451,\n",
            "         -0.0706, -0.0748, -0.1685, -0.0056, -0.3079,  0.1874, -0.1245, -0.1703],\n",
            "        [ 0.2167, -0.0338,  0.2416, -0.1259,  0.1644,  0.0219,  0.2940, -0.0612,\n",
            "          0.1897,  0.2130, -0.1672, -0.1017, -0.0618,  0.0045, -0.1073, -0.0891],\n",
            "        [ 0.0406,  0.0587,  0.1533,  0.0328, -0.2861, -0.1048,  0.2664, -0.1565,\n",
            "         -0.0930, -0.3120,  0.0886, -0.0790, -0.1761,  0.0170, -0.1685, -0.1635],\n",
            "        [-0.0381,  0.1997, -0.1271, -0.1610, -0.1112,  0.0758,  0.2706, -0.1461,\n",
            "          0.0094,  0.0642, -0.2784, -0.2383,  0.1415, -0.0176,  0.2465,  0.0517],\n",
            "        [-0.0303,  0.1057, -0.1684, -0.1017,  0.1226, -0.0618, -0.1092, -0.0255,\n",
            "         -0.0422, -0.2011, -0.0173, -0.2302,  0.1458, -0.0878, -0.2043,  0.0288],\n",
            "        [ 0.2119,  0.0598, -0.1821, -0.0253, -0.1287, -0.0026, -0.1990,  0.2326,\n",
            "          0.0518, -0.2119,  0.1062, -0.0222,  0.0961,  0.2374,  0.1947,  0.0329],\n",
            "        [-0.1676,  0.0646, -0.1637, -0.1722,  0.1660, -0.0766,  0.1817,  0.2113,\n",
            "         -0.0733, -0.2040,  0.0988, -0.2459, -0.1081, -0.1914,  0.0588, -0.1499],\n",
            "        [ 0.1433,  0.1387,  0.1297,  0.1363, -0.1367, -0.1227, -0.1628, -0.2121,\n",
            "         -0.0241,  0.2838,  0.0140,  0.0870, -0.1988, -0.1736,  0.0209, -0.0470],\n",
            "        [ 0.1765,  0.1835, -0.0616,  0.0656,  0.2218,  0.1011,  0.0832, -0.0714,\n",
            "         -0.2270,  0.1006, -0.0272, -0.0073, -0.2399,  0.0144,  0.1693,  0.1717]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([-0.2081, -0.1037, -0.0968, -0.1189, -0.0342, -0.1509, -0.1145,  0.1007,\n",
            "         0.0441,  0.0807, -0.2352,  0.0309, -0.2310, -0.0054,  0.0056, -0.0388],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[ 0.2270,  0.1609, -0.0928, -0.2061, -0.0097, -0.0516,  0.0728,  0.1352,\n",
            "         -0.0922, -0.0372, -0.0109,  0.0101, -0.0600,  0.1787, -0.0322,  0.0047]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([0.2554], dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomizableFeatureNet(\n",
              "  (hidden_layers): ModuleList(\n",
              "    (0): Linear(in_features=2, out_features=16, bias=True)\n",
              "    (1): Linear(in_features=16, out_features=16, bias=True)\n",
              "  )\n",
              "  (output_layer): Linear(in_features=16, out_features=1, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_200_random.get_heatmap()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "FWrKK2gq1saa",
        "outputId": "b4ffd8e0-55b8-4603-f6aa-af1509382657"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"2b109429-c4fd-4b6c-9c66-42c9b997c534\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"2b109429-c4fd-4b6c-9c66-42c9b997c534\")) {                    Plotly.newPlot(                        \"2b109429-c4fd-4b6c-9c66-42c9b997c534\",                        [{\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"z\":[[0.23332330352492367,0.24258862148102012,0.23326124374902843,0.22878496516599747,0.23283042956419,0.23671336700501938,0.2405963044458487,0.24447924188667805,0.2483621793275074,0.2522451167683367],[0.25413643178137496,0.2543538585060284,0.24413886937359366,0.23220636506747233,0.23015959799339447,0.23620391182244574,0.2402891258198424,0.2443743398172391,0.24845955381463578,0.2525447678120325],[0.25369140656555744,0.2549150708830124,0.2503195817929705,0.24058524914151114,0.22915152788461285,0.22200536514036334,0.23151309079690852,0.24102081645345372,0.24770807247629067,0.25179328647368737],[0.2535487848738608,0.2553627495507404,0.25164981117617097,0.24607433853601487,0.23715388889797126,0.22609669070175334,0.21520767261430818,0.2233588579438774,0.23286658360042256,0.24237430925696773],[0.2535897042622119,0.2563298737031791,0.2532750516346418,0.2473929340825205,0.24183266378065255,0.2337225286544314,0.22304185351889383,0.2121123596374682,0.21520462509084626,0.22471235074739143],[0.2531524882894386,0.2566668811877895,0.25424189966710403,0.24901817454099137,0.24313605698887003,0.23779751312068914,0.23029116841089153,0.21989192794329337,0.20905752245460868,0.2070503922378151],[0.2527152723166653,0.255055520532074,0.25459055723578977,0.25064341499946224,0.2447612974473409,0.2388791798952196,0.23376236246072576,0.22685980816735168,0.21654106325645045,0.20600268527174923],[0.2517107972563284,0.2539434013785719,0.25493921480447557,0.25050390949868095,0.24638653790581178,0.24050442035369043,0.23482181940783137,0.2297272118007624,0.2234284479238118,0.21319019856960758],[0.2505986781028264,0.2528312822250699,0.25528787237316136,0.2508983942747231,0.24801177836428265,0.2421296608121613,0.23624754326004,0.23085721048438684,0.22573812491142803,0.21999708768027199],[0.2494865589493243,0.25171916307156783,0.25398403144691317,0.25129287905076525,0.24669240342662943,0.24375490127063218,0.23787278371851084,0.2320116871339011,0.2268926015609423,0.2217735159879835]],\"type\":\"heatmap\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"Values\"},\"ticks\":\"outside\",\"tickvals\":[0.20600268527174923,0.2566668811877895],\"ticktext\":[0.20600268527174923,0.2566668811877895]}},\"xaxis\":{\"tickvals\":[0,1,2,3,4,5,6,7,8,9],\"ticktext\":[0,1,2,3,4,5,6,7,8,9],\"title\":{\"text\":\"X\"}},\"yaxis\":{\"tickvals\":[9,8,7,6,5,4,3,2,1,0],\"ticktext\":[9,8,7,6,5,4,3,2,1,0],\"title\":{\"text\":\"Y\"},\"autorange\":\"reversed\"},\"title\":{\"text\":\"Heatmap\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('2b109429-c4fd-4b6c-9c66-42c9b997c534');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_200_random.IS_pipeline()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf3d71c3-4913-4be4-c72a-80e2a6c028f6",
        "id": "bMNdZyX0wP74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(-0.0130, dtype=torch.float64), tensor(8.9415e-05, dtype=torch.float64))"
            ]
          },
          "metadata": {},
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pi_e = experiment_actions(1000, env_30, P_pi_e)\n"
      ],
      "metadata": {
        "id": "dNqOUUhNwP8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calc_V_pi_e(pi_e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f86508de-5c8a-4490-9ee5-80cf50f2ec8f",
        "id": "_BFL3TclwP8L"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.12203056843017494"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_200_random.evaluate_scope()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2a06dbe-d37a-40d3-ca90-e867b34f5706",
        "id": "XXIslB1ZwP8M"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(-0.0521, dtype=torch.float64, grad_fn=<MeanBackward0>),\n",
              " tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test random pi_b"
      ],
      "metadata": {
        "id": "AT8DEpH257IN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b = action_probs_top_n_epsilon(q_table, 1, 0.4)\n",
        "pi_b = experiment_actions(200, env_50, P_pi_b)\n",
        "P_pi_e = action_probs_top_n_epsilon(q_table, 2, 0.05)\n",
        "pi_e = experiment_actions(1000, env_50, P_pi_e)\n",
        "model_200_random_pi_b = CustomizableFeatureNet(input_dim=2, hidden_dims=[16, 16], output_dim=1, dtype = torch.float64)\n",
        "test_200_random_pi_b = SCOPE_straight(model_200_random_pi_b, 0.99, 10000, pi_b, P_pi_b, P_pi_e, 0.3, dtype = torch.float64)\n"
      ],
      "metadata": {
        "id": "WMPIrLYl5-8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_200_random_pi_b.IS_pipeline()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQo5eTV3wy2q",
        "outputId": "046fc409-1017-4d57-b105-7346f1b4560b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(2.6041, dtype=torch.float64), tensor(6.1715, dtype=torch.float64))"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_200_random_pi_b.get_state_visitation_heatmap()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "Eappd8gl338Y",
        "outputId": "24fe4a9f-fa8e-4cac-b421-ce6f8fb3086c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"92d136b8-32cf-44d9-9a4e-72fd1b077c5e\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"92d136b8-32cf-44d9-9a4e-72fd1b077c5e\")) {                    Plotly.newPlot(                        \"92d136b8-32cf-44d9-9a4e-72fd1b077c5e\",                        [{\"colorbar\":{\"title\":{\"text\":\"Visits\"}},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"x\":[0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9],\"y\":[9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0],\"z\":[0,1,19,74,392,348,301,304,242,250,0,9,73,360,347,0,43,108,103,258,0,52,302,331,78,0,14,19,54,304,0,287,302,48,10,0,5,2,9,30,0,342,92,16,7,0,1,0,0,3,177,253,27,5,1,0,0,0,0,0,19,41,11,0,0,0,0,0,0,0,4,4,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\"zmax\":392,\"zmin\":0,\"type\":\"heatmap\"}],                        {\"title\":{\"text\":\"State Visitations Heatmap\"},\"xaxis\":{\"title\":{\"text\":\"X-axis\"}},\"yaxis\":{\"ticktext\":[9,8,7,6,5,4,3,2,1,0],\"tickvals\":[0,1,2,3,4,5,6,7,8,9],\"title\":{\"text\":\"Y-axis\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('92d136b8-32cf-44d9-9a4e-72fd1b077c5e');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_200_random_pi_b.train_var_scope(300, 0.001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbp_-3l56PPN",
        "outputId": "2d06049b-f526-4044-8f4c-a76cfad2aa10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.1993, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.04945267717328408\n",
            "Total Loss: 0.24875341891612565\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0029, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.04854473065112503\n",
            "Total Loss: 0.05144933898137734\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0029, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.04864399770972223\n",
            "Total Loss: 0.05152271293468217\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0029, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.04866784514199147\n",
            "Total Loss: 0.051536243945871946\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0028, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.048615524104309624\n",
            "Total Loss: 0.051456531593814775\n",
            "----------------------------------------\n",
            "Epoch 6\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0028, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.04849324975461501\n",
            "Total Loss: 0.05129381081879754\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0028, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.048312368946103\n",
            "Total Loss: 0.051068472854216375\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0027, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.04808510664483826\n",
            "Total Loss: 0.05080233676055136\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0027, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.047823059414614455\n",
            "Total Loss: 0.05051311905677309\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0027, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.04753419416889371\n",
            "Total Loss: 0.05021146838496162\n",
            "----------------------------------------\n",
            "Epoch 11\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0027, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.04722807551361388\n",
            "Total Loss: 0.049901004960354024\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0027, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.04691277498134304\n",
            "Total Loss: 0.04958687463320923\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0027, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.04659304279898141\n",
            "Total Loss: 0.04926749648956022\n",
            "----------------------------------------\n",
            "Epoch 14\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0027, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.046272942741294266\n",
            "Total Loss: 0.04894278287548763\n",
            "----------------------------------------\n",
            "Epoch 15\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0027, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.04595591695553651\n",
            "Total Loss: 0.04861457584941882\n",
            "----------------------------------------\n",
            "Epoch 16\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0026, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.04564403838554215\n",
            "Total Loss: 0.04828432210083874\n",
            "----------------------------------------\n",
            "Epoch 17\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0026, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.04533760245366354\n",
            "Total Loss: 0.047956796039588356\n",
            "----------------------------------------\n",
            "Epoch 18\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0026, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.04503700286409159\n",
            "Total Loss: 0.04763495530437685\n",
            "----------------------------------------\n",
            "Epoch 19\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0026, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.04474146323908528\n",
            "Total Loss: 0.04732146475834983\n",
            "----------------------------------------\n",
            "Epoch 20\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0026, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.044450754256739944\n",
            "Total Loss: 0.047021420606675204\n",
            "----------------------------------------\n",
            "Epoch 21\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0026, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.04416397203018826\n",
            "Total Loss: 0.04673580603533978\n",
            "----------------------------------------\n",
            "Epoch 22\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0026, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.04388233225981902\n",
            "Total Loss: 0.04645699445010106\n",
            "----------------------------------------\n",
            "Epoch 23\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0026, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.043603678756781755\n",
            "Total Loss: 0.046177584960981274\n",
            "----------------------------------------\n",
            "Epoch 24\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0026, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.04332833023998148\n",
            "Total Loss: 0.04589407181185849\n",
            "----------------------------------------\n",
            "Epoch 25\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0025, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.043055934588074954\n",
            "Total Loss: 0.04560548184441549\n",
            "----------------------------------------\n",
            "Epoch 26\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0025, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.04278634332973145\n",
            "Total Loss: 0.04531169247385323\n",
            "----------------------------------------\n",
            "Epoch 27\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0025, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.04252074241438567\n",
            "Total Loss: 0.045018647089610724\n",
            "----------------------------------------\n",
            "Epoch 28\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0025, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.042259248346763596\n",
            "Total Loss: 0.04472366945423052\n",
            "----------------------------------------\n",
            "Epoch 29\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0024, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.04200227647433682\n",
            "Total Loss: 0.04443084477144617\n",
            "----------------------------------------\n",
            "Epoch 30\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0024, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.04174682517805569\n",
            "Total Loss: 0.04414081163147765\n",
            "----------------------------------------\n",
            "Epoch 31\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0024, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.04149124233419884\n",
            "Total Loss: 0.0438529593292618\n",
            "----------------------------------------\n",
            "Epoch 32\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0023, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.04123434443318772\n",
            "Total Loss: 0.043565842125013396\n",
            "----------------------------------------\n",
            "Epoch 33\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0023, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.04097669582950763\n",
            "Total Loss: 0.043280626042309506\n",
            "----------------------------------------\n",
            "Epoch 34\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0023, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.040719604644652116\n",
            "Total Loss: 0.04298870713722543\n",
            "----------------------------------------\n",
            "Epoch 35\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0022, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0404622600231216\n",
            "Total Loss: 0.04268962867704999\n",
            "----------------------------------------\n",
            "Epoch 36\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0022, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.04020670588951857\n",
            "Total Loss: 0.042389470681551765\n",
            "----------------------------------------\n",
            "Epoch 37\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0021, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.039953007689818965\n",
            "Total Loss: 0.042090959869297\n",
            "----------------------------------------\n",
            "Epoch 38\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0021, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0397040310695286\n",
            "Total Loss: 0.04179458260694084\n",
            "----------------------------------------\n",
            "Epoch 39\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0020, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.03945700799764345\n",
            "Total Loss: 0.04149656599511773\n",
            "----------------------------------------\n",
            "Epoch 40\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0020, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.03921001819622812\n",
            "Total Loss: 0.041196694948528616\n",
            "----------------------------------------\n",
            "Epoch 41\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0019, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.038964229225037325\n",
            "Total Loss: 0.040899319300946424\n",
            "----------------------------------------\n",
            "Epoch 42\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0019, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.03872097989747095\n",
            "Total Loss: 0.04060832670097764\n",
            "----------------------------------------\n",
            "Epoch 43\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0018, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.03848278548872226\n",
            "Total Loss: 0.0403241845095867\n",
            "----------------------------------------\n",
            "Epoch 44\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0018, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.03824822096660062\n",
            "Total Loss: 0.04004731451541948\n",
            "----------------------------------------\n",
            "Epoch 45\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0018, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.03801701581472115\n",
            "Total Loss: 0.03979722262232877\n",
            "----------------------------------------\n",
            "Epoch 46\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0018, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.03778867378836817\n",
            "Total Loss: 0.0395482813830392\n",
            "----------------------------------------\n",
            "Epoch 47\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0017, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.03756496156811893\n",
            "Total Loss: 0.039285037111903565\n",
            "----------------------------------------\n",
            "Epoch 48\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0017, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.03734492444370271\n",
            "Total Loss: 0.039011574138313763\n",
            "----------------------------------------\n",
            "Epoch 49\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0016, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.037129042224008285\n",
            "Total Loss: 0.038739952850723\n",
            "----------------------------------------\n",
            "Epoch 50\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0016, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.03691556313961234\n",
            "Total Loss: 0.03848513703915277\n",
            "----------------------------------------\n",
            "Epoch 51\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0015, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.036700684809237716\n",
            "Total Loss: 0.038238687767602725\n",
            "----------------------------------------\n",
            "Epoch 52\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0015, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.036483439675281816\n",
            "Total Loss: 0.0379941689911375\n",
            "----------------------------------------\n",
            "Epoch 53\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0015, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.036264010987566216\n",
            "Total Loss: 0.037747021232492864\n",
            "----------------------------------------\n",
            "Epoch 54\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0015, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.03604080241836738\n",
            "Total Loss: 0.03749578083462312\n",
            "----------------------------------------\n",
            "Epoch 55\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0014, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0358162979321748\n",
            "Total Loss: 0.037246438748284316\n",
            "----------------------------------------\n",
            "Epoch 56\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0014, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.03559218420161251\n",
            "Total Loss: 0.037002976865311295\n",
            "----------------------------------------\n",
            "Epoch 57\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0014, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.035370390248440416\n",
            "Total Loss: 0.03676658070812876\n",
            "----------------------------------------\n",
            "Epoch 58\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0014, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.035152061095278464\n",
            "Total Loss: 0.03653376487947622\n",
            "----------------------------------------\n",
            "Epoch 59\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0014, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.03493610572152552\n",
            "Total Loss: 0.03629806893712749\n",
            "----------------------------------------\n",
            "Epoch 60\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.03472570303094824\n",
            "Total Loss: 0.03606165002877402\n",
            "----------------------------------------\n",
            "Epoch 61\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.034519636998314465\n",
            "Total Loss: 0.03582657829037465\n",
            "----------------------------------------\n",
            "Epoch 62\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.03431632428327262\n",
            "Total Loss: 0.035595242534100416\n",
            "----------------------------------------\n",
            "Epoch 63\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.034114294170846465\n",
            "Total Loss: 0.03536911710903119\n",
            "----------------------------------------\n",
            "Epoch 64\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.03391246894580996\n",
            "Total Loss: 0.035147546204267806\n",
            "----------------------------------------\n",
            "Epoch 65\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.033709584183012564\n",
            "Total Loss: 0.03492709409053595\n",
            "----------------------------------------\n",
            "Epoch 66\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.03350555363665455\n",
            "Total Loss: 0.034706740752203494\n",
            "----------------------------------------\n",
            "Epoch 67\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0333009000091261\n",
            "Total Loss: 0.034487743203362134\n",
            "----------------------------------------\n",
            "Epoch 68\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.03309689775671131\n",
            "Total Loss: 0.034271352164935646\n",
            "----------------------------------------\n",
            "Epoch 69\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.03289522618742891\n",
            "Total Loss: 0.034062508386576394\n",
            "----------------------------------------\n",
            "Epoch 70\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.032698693004125146\n",
            "Total Loss: 0.03386262322128427\n",
            "----------------------------------------\n",
            "Epoch 71\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.03250933494312577\n",
            "Total Loss: 0.03365961509764954\n",
            "----------------------------------------\n",
            "Epoch 72\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.03232705621774532\n",
            "Total Loss: 0.03345325069867564\n",
            "----------------------------------------\n",
            "Epoch 73\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.03214945208228399\n",
            "Total Loss: 0.03325197904279367\n",
            "----------------------------------------\n",
            "Epoch 74\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.031969078706416874\n",
            "Total Loss: 0.03305762498034988\n",
            "----------------------------------------\n",
            "Epoch 75\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.03178739609351097\n",
            "Total Loss: 0.03286448614424302\n",
            "----------------------------------------\n",
            "Epoch 76\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.03160472176512849\n",
            "Total Loss: 0.03267168734564331\n",
            "----------------------------------------\n",
            "Epoch 77\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.03142147250828222\n",
            "Total Loss: 0.0324792427332623\n",
            "----------------------------------------\n",
            "Epoch 78\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.031239001048223396\n",
            "Total Loss: 0.032290971257610435\n",
            "----------------------------------------\n",
            "Epoch 79\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.031058938853701586\n",
            "Total Loss: 0.03210830545150763\n",
            "----------------------------------------\n",
            "Epoch 80\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.030881709462510655\n",
            "Total Loss: 0.0319247712636638\n",
            "----------------------------------------\n",
            "Epoch 81\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.030707599043085832\n",
            "Total Loss: 0.031741027063447586\n",
            "----------------------------------------\n",
            "Epoch 82\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.030535611333163414\n",
            "Total Loss: 0.03156104411393954\n",
            "----------------------------------------\n",
            "Epoch 83\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.03036501589774746\n",
            "Total Loss: 0.0313828796600467\n",
            "----------------------------------------\n",
            "Epoch 84\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.030195169304680438\n",
            "Total Loss: 0.031205299707098597\n",
            "----------------------------------------\n",
            "Epoch 85\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.030025291484208495\n",
            "Total Loss: 0.03102849273117923\n",
            "----------------------------------------\n",
            "Epoch 86\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.029855973233586783\n",
            "Total Loss: 0.03085360700165191\n",
            "----------------------------------------\n",
            "Epoch 87\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.029688322326705638\n",
            "Total Loss: 0.030679704498985282\n",
            "----------------------------------------\n",
            "Epoch 88\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.029522313421967126\n",
            "Total Loss: 0.03050663339229394\n",
            "----------------------------------------\n",
            "Epoch 89\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.029357520446253317\n",
            "Total Loss: 0.030334439851922655\n",
            "----------------------------------------\n",
            "Epoch 90\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.029193983492424292\n",
            "Total Loss: 0.030164749258931325\n",
            "----------------------------------------\n",
            "Epoch 91\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.029031378635397998\n",
            "Total Loss: 0.02999515556860708\n",
            "----------------------------------------\n",
            "Epoch 92\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.02886991893201097\n",
            "Total Loss: 0.029826190218432688\n",
            "----------------------------------------\n",
            "Epoch 93\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.028710135310381867\n",
            "Total Loss: 0.029659221510265604\n",
            "----------------------------------------\n",
            "Epoch 94\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.028551954666903544\n",
            "Total Loss: 0.029492721676264128\n",
            "----------------------------------------\n",
            "Epoch 95\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.02839502616873332\n",
            "Total Loss: 0.029327462048411038\n",
            "----------------------------------------\n",
            "Epoch 96\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.028238517286046868\n",
            "Total Loss: 0.029163277022912566\n",
            "----------------------------------------\n",
            "Epoch 97\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.028082790030764113\n",
            "Total Loss: 0.029000013441074005\n",
            "----------------------------------------\n",
            "Epoch 98\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.02792759675527582\n",
            "Total Loss: 0.028838349819270664\n",
            "----------------------------------------\n",
            "Epoch 99\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.027773428428421246\n",
            "Total Loss: 0.028677382854680983\n",
            "----------------------------------------\n",
            "Epoch 100\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.027620516521045278\n",
            "Total Loss: 0.028516518683088465\n",
            "----------------------------------------\n",
            "Epoch 101\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.027468542595094975\n",
            "Total Loss: 0.02835628364797853\n",
            "----------------------------------------\n",
            "Epoch 102\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.027317185749429176\n",
            "Total Loss: 0.028197331777617837\n",
            "----------------------------------------\n",
            "Epoch 103\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.02716582609778817\n",
            "Total Loss: 0.028038695597995447\n",
            "----------------------------------------\n",
            "Epoch 104\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.027014689126839842\n",
            "Total Loss: 0.0278808720377992\n",
            "----------------------------------------\n",
            "Epoch 105\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.026864176878806035\n",
            "Total Loss: 0.02772375878473636\n",
            "----------------------------------------\n",
            "Epoch 106\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.026714805646693766\n",
            "Total Loss: 0.027567548305359908\n",
            "----------------------------------------\n",
            "Epoch 107\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.02656702989021822\n",
            "Total Loss: 0.02741289476529418\n",
            "----------------------------------------\n",
            "Epoch 108\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.02641708097707591\n",
            "Total Loss: 0.027256217359741132\n",
            "----------------------------------------\n",
            "Epoch 109\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.026266769470711302\n",
            "Total Loss: 0.027099692438693864\n",
            "----------------------------------------\n",
            "Epoch 110\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.02611685139399621\n",
            "Total Loss: 0.02694299815501798\n",
            "----------------------------------------\n",
            "Epoch 111\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.025967603552981878\n",
            "Total Loss: 0.026786539126156566\n",
            "----------------------------------------\n",
            "Epoch 112\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.02581879605170001\n",
            "Total Loss: 0.02663085931650037\n",
            "----------------------------------------\n",
            "Epoch 113\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.02567001183692824\n",
            "Total Loss: 0.026475992590889594\n",
            "----------------------------------------\n",
            "Epoch 114\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.02552131577460556\n",
            "Total Loss: 0.026321930088510265\n",
            "----------------------------------------\n",
            "Epoch 115\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.025372187661414906\n",
            "Total Loss: 0.02616811325179297\n",
            "----------------------------------------\n",
            "Epoch 116\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.025223521625193937\n",
            "Total Loss: 0.02601492293057072\n",
            "----------------------------------------\n",
            "Epoch 117\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.025075899057256077\n",
            "Total Loss: 0.02586207994085572\n",
            "----------------------------------------\n",
            "Epoch 118\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.024928946913592157\n",
            "Total Loss: 0.025709095918681948\n",
            "----------------------------------------\n",
            "Epoch 119\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.024782714154479035\n",
            "Total Loss: 0.025556639953846782\n",
            "----------------------------------------\n",
            "Epoch 120\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.024636689311154154\n",
            "Total Loss: 0.025403911643382945\n",
            "----------------------------------------\n",
            "Epoch 121\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.024491107000194842\n",
            "Total Loss: 0.025251771428352433\n",
            "----------------------------------------\n",
            "Epoch 122\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.024346112744800676\n",
            "Total Loss: 0.025100100330748804\n",
            "----------------------------------------\n",
            "Epoch 123\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.02420163809422769\n",
            "Total Loss: 0.024949223754352254\n",
            "----------------------------------------\n",
            "Epoch 124\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.024057708651825906\n",
            "Total Loss: 0.024799328705755918\n",
            "----------------------------------------\n",
            "Epoch 125\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.02391394973432977\n",
            "Total Loss: 0.024650076159729178\n",
            "----------------------------------------\n",
            "Epoch 126\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.023770269677040975\n",
            "Total Loss: 0.024501261018107\n",
            "----------------------------------------\n",
            "Epoch 127\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.023626902489020014\n",
            "Total Loss: 0.024352795677952205\n",
            "----------------------------------------\n",
            "Epoch 128\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.023483804499146013\n",
            "Total Loss: 0.0242032911478199\n",
            "----------------------------------------\n",
            "Epoch 129\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.023341077732581553\n",
            "Total Loss: 0.024050943829703762\n",
            "----------------------------------------\n",
            "Epoch 130\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.02319844588324014\n",
            "Total Loss: 0.023896065895412304\n",
            "----------------------------------------\n",
            "Epoch 131\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.02305600452927503\n",
            "Total Loss: 0.02373993458877167\n",
            "----------------------------------------\n",
            "Epoch 132\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.02291385188451716\n",
            "Total Loss: 0.02358737615670228\n",
            "----------------------------------------\n",
            "Epoch 133\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.02277197953593389\n",
            "Total Loss: 0.023435638765637826\n",
            "----------------------------------------\n",
            "Epoch 134\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.022630394207658916\n",
            "Total Loss: 0.023284544459237604\n",
            "----------------------------------------\n",
            "Epoch 135\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.02249015582654771\n",
            "Total Loss: 0.02313502408884195\n",
            "----------------------------------------\n",
            "Epoch 136\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.02235041349099149\n",
            "Total Loss: 0.02298556398237943\n",
            "----------------------------------------\n",
            "Epoch 137\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.022211090250914115\n",
            "Total Loss: 0.022836133758181054\n",
            "----------------------------------------\n",
            "Epoch 138\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.022072247043313453\n",
            "Total Loss: 0.022687144884497197\n",
            "----------------------------------------\n",
            "Epoch 139\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.021934465294753253\n",
            "Total Loss: 0.022542329399190344\n",
            "----------------------------------------\n",
            "Epoch 140\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.021798498285674466\n",
            "Total Loss: 0.022397342657655587\n",
            "----------------------------------------\n",
            "Epoch 141\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.02166191945542206\n",
            "Total Loss: 0.022249508584162202\n",
            "----------------------------------------\n",
            "Epoch 142\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.021525280209144192\n",
            "Total Loss: 0.02210483112483976\n",
            "----------------------------------------\n",
            "Epoch 143\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.021389352054586124\n",
            "Total Loss: 0.02196416798089218\n",
            "----------------------------------------\n",
            "Epoch 144\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.021253974267399778\n",
            "Total Loss: 0.021824601551170386\n",
            "----------------------------------------\n",
            "Epoch 145\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.021120850286590286\n",
            "Total Loss: 0.02168441186765273\n",
            "----------------------------------------\n",
            "Epoch 146\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.020987718536063054\n",
            "Total Loss: 0.021546739801023847\n",
            "----------------------------------------\n",
            "Epoch 147\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.02085311236470807\n",
            "Total Loss: 0.0214078663440855\n",
            "----------------------------------------\n",
            "Epoch 148\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.020718954044245837\n",
            "Total Loss: 0.021270912276076446\n",
            "----------------------------------------\n",
            "Epoch 149\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.02058690087342954\n",
            "Total Loss: 0.021136285112275017\n",
            "----------------------------------------\n",
            "Epoch 150\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.02045775534825959\n",
            "Total Loss: 0.02100216680873213\n",
            "----------------------------------------\n",
            "Epoch 151\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.020330190137579304\n",
            "Total Loss: 0.0208698705508048\n",
            "----------------------------------------\n",
            "Epoch 152\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.020197140308575685\n",
            "Total Loss: 0.020731807704300054\n",
            "----------------------------------------\n",
            "Epoch 153\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.020062241278119154\n",
            "Total Loss: 0.020592682366378467\n",
            "----------------------------------------\n",
            "Epoch 154\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.019927463018715518\n",
            "Total Loss: 0.020454680438533678\n",
            "----------------------------------------\n",
            "Epoch 155\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01979351640854209\n",
            "Total Loss: 0.020316764306595698\n",
            "----------------------------------------\n",
            "Epoch 156\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01966054098539313\n",
            "Total Loss: 0.02017931360037044\n",
            "----------------------------------------\n",
            "Epoch 157\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.019527906512076504\n",
            "Total Loss: 0.020043168719918934\n",
            "----------------------------------------\n",
            "Epoch 158\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01939521361598454\n",
            "Total Loss: 0.01990753045288724\n",
            "----------------------------------------\n",
            "Epoch 159\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01926288571959303\n",
            "Total Loss: 0.01977316762293595\n",
            "----------------------------------------\n",
            "Epoch 160\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01913202838129444\n",
            "Total Loss: 0.01964009825718444\n",
            "----------------------------------------\n",
            "Epoch 161\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.019003398440630134\n",
            "Total Loss: 0.019508561382744524\n",
            "----------------------------------------\n",
            "Epoch 162\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01887637680942546\n",
            "Total Loss: 0.019377273547066823\n",
            "----------------------------------------\n",
            "Epoch 163\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01875035549605594\n",
            "Total Loss: 0.019246582093013283\n",
            "----------------------------------------\n",
            "Epoch 164\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.018624976409901736\n",
            "Total Loss: 0.019117610549579226\n",
            "----------------------------------------\n",
            "Epoch 165\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01850059513348684\n",
            "Total Loss: 0.01899008427589519\n",
            "----------------------------------------\n",
            "Epoch 166\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.018377572233956488\n",
            "Total Loss: 0.01886342090867842\n",
            "----------------------------------------\n",
            "Epoch 167\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.018255778662891218\n",
            "Total Loss: 0.018737894035363068\n",
            "----------------------------------------\n",
            "Epoch 168\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.018134558028595347\n",
            "Total Loss: 0.018613257611096258\n",
            "----------------------------------------\n",
            "Epoch 169\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.018013838385722552\n",
            "Total Loss: 0.01849010738535888\n",
            "----------------------------------------\n",
            "Epoch 170\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.017894590619172368\n",
            "Total Loss: 0.01836880460856639\n",
            "----------------------------------------\n",
            "Epoch 171\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.017777315219740197\n",
            "Total Loss: 0.0182494231468843\n",
            "----------------------------------------\n",
            "Epoch 172\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01766167315909077\n",
            "Total Loss: 0.018131402495362943\n",
            "----------------------------------------\n",
            "Epoch 173\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01754727086810803\n",
            "Total Loss: 0.018014756427061015\n",
            "----------------------------------------\n",
            "Epoch 174\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.017433496108014982\n",
            "Total Loss: 0.017899247067561644\n",
            "----------------------------------------\n",
            "Epoch 175\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.017320518588694885\n",
            "Total Loss: 0.017785096111284603\n",
            "----------------------------------------\n",
            "Epoch 176\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.017205491311864753\n",
            "Total Loss: 0.01766895171409266\n",
            "----------------------------------------\n",
            "Epoch 177\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.017091667480834207\n",
            "Total Loss: 0.017553115494410836\n",
            "----------------------------------------\n",
            "Epoch 178\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.016979503662563976\n",
            "Total Loss: 0.017438594826889402\n",
            "----------------------------------------\n",
            "Epoch 179\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01686833682788095\n",
            "Total Loss: 0.017325587607140615\n",
            "----------------------------------------\n",
            "Epoch 180\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.016758430019867376\n",
            "Total Loss: 0.01721392885677529\n",
            "----------------------------------------\n",
            "Epoch 181\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.016650262899030665\n",
            "Total Loss: 0.017103675650959042\n",
            "----------------------------------------\n",
            "Epoch 182\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.016543944173240444\n",
            "Total Loss: 0.01699467889074927\n",
            "----------------------------------------\n",
            "Epoch 183\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.016439138435330233\n",
            "Total Loss: 0.016887173435300516\n",
            "----------------------------------------\n",
            "Epoch 184\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.016335404788414727\n",
            "Total Loss: 0.01678102386440071\n",
            "----------------------------------------\n",
            "Epoch 185\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.016233221795650135\n",
            "Total Loss: 0.01667592676662776\n",
            "----------------------------------------\n",
            "Epoch 186\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.016132539584324906\n",
            "Total Loss: 0.016572200698318242\n",
            "----------------------------------------\n",
            "Epoch 187\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.016033301006540754\n",
            "Total Loss: 0.016469816708098783\n",
            "----------------------------------------\n",
            "Epoch 188\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01593613478448741\n",
            "Total Loss: 0.016369145190262856\n",
            "----------------------------------------\n",
            "Epoch 189\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01584039860073178\n",
            "Total Loss: 0.016270365133684878\n",
            "----------------------------------------\n",
            "Epoch 190\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.015746841265441052\n",
            "Total Loss: 0.01617302013281707\n",
            "----------------------------------------\n",
            "Epoch 191\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.015654888727292288\n",
            "Total Loss: 0.01607755402412153\n",
            "----------------------------------------\n",
            "Epoch 192\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.015564484685481517\n",
            "Total Loss: 0.015983646242436977\n",
            "----------------------------------------\n",
            "Epoch 193\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01547947675783937\n",
            "Total Loss: 0.015895064351121466\n",
            "----------------------------------------\n",
            "Epoch 194\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.015396680467479823\n",
            "Total Loss: 0.01580828774850752\n",
            "----------------------------------------\n",
            "Epoch 195\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.015315644884431984\n",
            "Total Loss: 0.01572310519000634\n",
            "----------------------------------------\n",
            "Epoch 196\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.015236126383292626\n",
            "Total Loss: 0.015639589161985094\n",
            "----------------------------------------\n",
            "Epoch 197\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.015158268628996076\n",
            "Total Loss: 0.015557873559152464\n",
            "----------------------------------------\n",
            "Epoch 198\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.015082857087817791\n",
            "Total Loss: 0.015478224587482147\n",
            "----------------------------------------\n",
            "Epoch 199\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.015010025379354405\n",
            "Total Loss: 0.015400916794470452\n",
            "----------------------------------------\n",
            "Epoch 200\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.014938818188047492\n",
            "Total Loss: 0.015325209451458342\n",
            "----------------------------------------\n",
            "Epoch 201\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.014868993314741813\n",
            "Total Loss: 0.015251071714328266\n",
            "----------------------------------------\n",
            "Epoch 202\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.014799983689822244\n",
            "Total Loss: 0.015178168533072035\n",
            "----------------------------------------\n",
            "Epoch 203\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.014731986544678131\n",
            "Total Loss: 0.01510614020718345\n",
            "----------------------------------------\n",
            "Epoch 204\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.014664589226793114\n",
            "Total Loss: 0.015035070424161984\n",
            "----------------------------------------\n",
            "Epoch 205\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.014598040720822384\n",
            "Total Loss: 0.014964683298632734\n",
            "----------------------------------------\n",
            "Epoch 206\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.014533087416442193\n",
            "Total Loss: 0.014896111151875058\n",
            "----------------------------------------\n",
            "Epoch 207\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.014469820941312174\n",
            "Total Loss: 0.014829469821920406\n",
            "----------------------------------------\n",
            "Epoch 208\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01440727071806753\n",
            "Total Loss: 0.014763235623713641\n",
            "----------------------------------------\n",
            "Epoch 209\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.014345616524046286\n",
            "Total Loss: 0.014699337709401055\n",
            "----------------------------------------\n",
            "Epoch 210\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.014284451479959274\n",
            "Total Loss: 0.014635807181736543\n",
            "----------------------------------------\n",
            "Epoch 211\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.014223482420036184\n",
            "Total Loss: 0.014573760694954547\n",
            "----------------------------------------\n",
            "Epoch 212\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.014163007897253225\n",
            "Total Loss: 0.014511600081783876\n",
            "----------------------------------------\n",
            "Epoch 213\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.014102570646818012\n",
            "Total Loss: 0.0144505834774519\n",
            "----------------------------------------\n",
            "Epoch 214\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.014043639352624246\n",
            "Total Loss: 0.01439050123052608\n",
            "----------------------------------------\n",
            "Epoch 215\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.013985527529671844\n",
            "Total Loss: 0.01433138438839587\n",
            "----------------------------------------\n",
            "Epoch 216\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.013927346079011818\n",
            "Total Loss: 0.01427284548483857\n",
            "----------------------------------------\n",
            "Epoch 217\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.013870212244171388\n",
            "Total Loss: 0.014215418939479706\n",
            "----------------------------------------\n",
            "Epoch 218\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.013814411850707347\n",
            "Total Loss: 0.01415915445062968\n",
            "----------------------------------------\n",
            "Epoch 219\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.013759581541837401\n",
            "Total Loss: 0.014103588112831864\n",
            "----------------------------------------\n",
            "Epoch 220\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.013705394997101357\n",
            "Total Loss: 0.014049173483573084\n",
            "----------------------------------------\n",
            "Epoch 221\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.013651267454540983\n",
            "Total Loss: 0.013995291051233871\n",
            "----------------------------------------\n",
            "Epoch 222\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.013597186985154311\n",
            "Total Loss: 0.013942670102243405\n",
            "----------------------------------------\n",
            "Epoch 223\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.013544775761818052\n",
            "Total Loss: 0.013890902770545683\n",
            "----------------------------------------\n",
            "Epoch 224\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.013493429937544366\n",
            "Total Loss: 0.013840550816181886\n",
            "----------------------------------------\n",
            "Epoch 225\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.013442693022176681\n",
            "Total Loss: 0.013790891823237596\n",
            "----------------------------------------\n",
            "Epoch 226\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.013392373846478081\n",
            "Total Loss: 0.013741841196605025\n",
            "----------------------------------------\n",
            "Epoch 227\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.013342329653764445\n",
            "Total Loss: 0.013693541184358893\n",
            "----------------------------------------\n",
            "Epoch 228\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.013292517967985255\n",
            "Total Loss: 0.013645763254456414\n",
            "----------------------------------------\n",
            "Epoch 229\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.013243721323154196\n",
            "Total Loss: 0.013598922955954329\n",
            "----------------------------------------\n",
            "Epoch 230\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01319642473907032\n",
            "Total Loss: 0.013553549037279844\n",
            "----------------------------------------\n",
            "Epoch 231\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01314935268567442\n",
            "Total Loss: 0.013509100113060685\n",
            "----------------------------------------\n",
            "Epoch 232\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.013102916979143824\n",
            "Total Loss: 0.013464393631526869\n",
            "----------------------------------------\n",
            "Epoch 233\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.013057256956307745\n",
            "Total Loss: 0.013419999624719774\n",
            "----------------------------------------\n",
            "Epoch 234\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.013012310170395251\n",
            "Total Loss: 0.013377306707058945\n",
            "----------------------------------------\n",
            "Epoch 235\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.012968228957065836\n",
            "Total Loss: 0.0133356576246721\n",
            "----------------------------------------\n",
            "Epoch 236\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01292475498779753\n",
            "Total Loss: 0.013294287789280474\n",
            "----------------------------------------\n",
            "Epoch 237\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.012881854351393732\n",
            "Total Loss: 0.013253751519725536\n",
            "----------------------------------------\n",
            "Epoch 238\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.012842339818246026\n",
            "Total Loss: 0.013215967594694763\n",
            "----------------------------------------\n",
            "Epoch 239\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01280310767988597\n",
            "Total Loss: 0.013178614015054503\n",
            "----------------------------------------\n",
            "Epoch 240\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.012764034855767763\n",
            "Total Loss: 0.013141315958140295\n",
            "----------------------------------------\n",
            "Epoch 241\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01272489886064019\n",
            "Total Loss: 0.013104117590237597\n",
            "----------------------------------------\n",
            "Epoch 242\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.012685868070710654\n",
            "Total Loss: 0.013068078904315493\n",
            "----------------------------------------\n",
            "Epoch 243\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.012647804127420071\n",
            "Total Loss: 0.013032196596014579\n",
            "----------------------------------------\n",
            "Epoch 244\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.012610830712544116\n",
            "Total Loss: 0.01299698549106762\n",
            "----------------------------------------\n",
            "Epoch 245\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.012575455063957915\n",
            "Total Loss: 0.012961369240760356\n",
            "----------------------------------------\n",
            "Epoch 246\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.012540561669039062\n",
            "Total Loss: 0.01292665985295561\n",
            "----------------------------------------\n",
            "Epoch 247\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.012505572976652278\n",
            "Total Loss: 0.01289281725044122\n",
            "----------------------------------------\n",
            "Epoch 248\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.012470509886089918\n",
            "Total Loss: 0.012859104533168646\n",
            "----------------------------------------\n",
            "Epoch 249\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.012435546332462084\n",
            "Total Loss: 0.012825416708455467\n",
            "----------------------------------------\n",
            "Epoch 250\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.012400568613000712\n",
            "Total Loss: 0.012792439429185842\n",
            "----------------------------------------\n",
            "Epoch 251\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.012366144967897234\n",
            "Total Loss: 0.012760059746030736\n",
            "----------------------------------------\n",
            "Epoch 252\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.012332400951338146\n",
            "Total Loss: 0.012727802362968216\n",
            "----------------------------------------\n",
            "Epoch 253\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.012299648056258517\n",
            "Total Loss: 0.012694955730906838\n",
            "----------------------------------------\n",
            "Epoch 254\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01226782062704371\n",
            "Total Loss: 0.012662515991584643\n",
            "----------------------------------------\n",
            "Epoch 255\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.012237596697114592\n",
            "Total Loss: 0.012630827784575466\n",
            "----------------------------------------\n",
            "Epoch 256\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0122068041367195\n",
            "Total Loss: 0.012599290166787364\n",
            "----------------------------------------\n",
            "Epoch 257\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.012175465510140879\n",
            "Total Loss: 0.012567318694442258\n",
            "----------------------------------------\n",
            "Epoch 258\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.012144028724291234\n",
            "Total Loss: 0.012535804835000481\n",
            "----------------------------------------\n",
            "Epoch 259\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.012112825140652709\n",
            "Total Loss: 0.012504427132176834\n",
            "----------------------------------------\n",
            "Epoch 260\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.012083381045631959\n",
            "Total Loss: 0.012473607080062314\n",
            "----------------------------------------\n",
            "Epoch 261\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.012054383440307327\n",
            "Total Loss: 0.012443304699772886\n",
            "----------------------------------------\n",
            "Epoch 262\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.012025269253708098\n",
            "Total Loss: 0.012413192910216938\n",
            "----------------------------------------\n",
            "Epoch 263\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011997386348012208\n",
            "Total Loss: 0.012383726788645289\n",
            "----------------------------------------\n",
            "Epoch 264\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011970244776785825\n",
            "Total Loss: 0.012354536765766817\n",
            "----------------------------------------\n",
            "Epoch 265\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011942646451179935\n",
            "Total Loss: 0.012325891854777622\n",
            "----------------------------------------\n",
            "Epoch 266\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011916036220296425\n",
            "Total Loss: 0.012297851567228183\n",
            "----------------------------------------\n",
            "Epoch 267\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011888522946316614\n",
            "Total Loss: 0.012269270747108846\n",
            "----------------------------------------\n",
            "Epoch 268\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011860308034248148\n",
            "Total Loss: 0.01224140903268112\n",
            "----------------------------------------\n",
            "Epoch 269\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01183322963115964\n",
            "Total Loss: 0.01221367677483205\n",
            "----------------------------------------\n",
            "Epoch 270\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011806126006786927\n",
            "Total Loss: 0.012186288705446973\n",
            "----------------------------------------\n",
            "Epoch 271\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011779176998902935\n",
            "Total Loss: 0.012158982622858049\n",
            "----------------------------------------\n",
            "Epoch 272\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011751707437816337\n",
            "Total Loss: 0.012131690476960243\n",
            "----------------------------------------\n",
            "Epoch 273\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011724595764374452\n",
            "Total Loss: 0.012104528977475968\n",
            "----------------------------------------\n",
            "Epoch 274\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011698167050723027\n",
            "Total Loss: 0.012077932487465286\n",
            "----------------------------------------\n",
            "Epoch 275\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011672420247403021\n",
            "Total Loss: 0.01205171605878809\n",
            "----------------------------------------\n",
            "Epoch 276\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011646244155497951\n",
            "Total Loss: 0.012025748893562317\n",
            "----------------------------------------\n",
            "Epoch 277\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011621200119995907\n",
            "Total Loss: 0.01199965022403778\n",
            "----------------------------------------\n",
            "Epoch 278\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011596080310801454\n",
            "Total Loss: 0.01197364925522822\n",
            "----------------------------------------\n",
            "Epoch 279\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011570647292675129\n",
            "Total Loss: 0.011946249414019948\n",
            "----------------------------------------\n",
            "Epoch 280\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011544660740362077\n",
            "Total Loss: 0.011919393016219247\n",
            "----------------------------------------\n",
            "Epoch 281\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011517403861943597\n",
            "Total Loss: 0.011892058771155973\n",
            "----------------------------------------\n",
            "Epoch 282\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0114902477278543\n",
            "Total Loss: 0.01186518430516524\n",
            "----------------------------------------\n",
            "Epoch 283\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011464252651922179\n",
            "Total Loss: 0.01183768812445604\n",
            "----------------------------------------\n",
            "Epoch 284\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01143802721270292\n",
            "Total Loss: 0.011810577374388972\n",
            "----------------------------------------\n",
            "Epoch 285\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011413214372842706\n",
            "Total Loss: 0.011783595099677698\n",
            "----------------------------------------\n",
            "Epoch 286\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011388737533849497\n",
            "Total Loss: 0.011756901316123105\n",
            "----------------------------------------\n",
            "Epoch 287\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011363389998337938\n",
            "Total Loss: 0.011730067367567803\n",
            "----------------------------------------\n",
            "Epoch 288\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011337958635767012\n",
            "Total Loss: 0.011703597630423406\n",
            "----------------------------------------\n",
            "Epoch 289\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011313673089174445\n",
            "Total Loss: 0.011676135978752136\n",
            "----------------------------------------\n",
            "Epoch 290\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01128918423020416\n",
            "Total Loss: 0.011649015511352796\n",
            "----------------------------------------\n",
            "Epoch 291\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011266710870765298\n",
            "Total Loss: 0.011621665378479407\n",
            "----------------------------------------\n",
            "Epoch 292\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011243619163872749\n",
            "Total Loss: 0.011594806749663835\n",
            "----------------------------------------\n",
            "Epoch 293\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01121866028075188\n",
            "Total Loss: 0.011567404483257306\n",
            "----------------------------------------\n",
            "Epoch 294\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01119455499374248\n",
            "Total Loss: 0.011540788200252545\n",
            "----------------------------------------\n",
            "Epoch 295\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01117022311793842\n",
            "Total Loss: 0.01151411436049818\n",
            "----------------------------------------\n",
            "Epoch 296\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011145524611575383\n",
            "Total Loss: 0.01148949682616665\n",
            "----------------------------------------\n",
            "Epoch 297\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011124226248315156\n",
            "Total Loss: 0.011463121588096127\n",
            "----------------------------------------\n",
            "Epoch 298\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011101697395952915\n",
            "Total Loss: 0.011437488894749055\n",
            "----------------------------------------\n",
            "Epoch 299\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011077850858885662\n",
            "Total Loss: 0.011412487157661652\n",
            "----------------------------------------\n",
            "Epoch 300\n",
            "IS variance:  tensor(1.6278e-19, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011054548343907997\n",
            "Total Loss: 0.011387159076841876\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[-0.2923,  0.2339],\n",
            "        [ 0.3194,  0.2682],\n",
            "        [-0.2634, -0.0373],\n",
            "        [ 0.5838, -0.0355],\n",
            "        [-0.4373,  0.4338],\n",
            "        [-0.6965, -0.0170],\n",
            "        [-0.7056, -0.1768],\n",
            "        [ 0.4269, -0.5237],\n",
            "        [-0.6634,  0.4686],\n",
            "        [-0.2940,  0.0116],\n",
            "        [-0.0910, -0.0699],\n",
            "        [ 0.4628, -0.5533],\n",
            "        [-0.4880,  0.2012],\n",
            "        [-0.3394, -0.3179],\n",
            "        [-0.0898,  0.2170],\n",
            "        [ 0.2648,  0.0378]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([-0.0980, -0.5624,  0.7502, -0.7612,  0.3475, -0.6895,  0.8333,  0.4590,\n",
            "        -0.4031,  0.7324,  0.7440, -0.1095,  0.3259, -0.4964, -0.1910, -0.2662],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[-7.9441e-02, -2.2863e-02,  3.3402e-01, -1.0591e-01,  1.5772e-01,\n",
            "         -6.6172e-02,  4.3558e-01,  1.7566e-01, -1.8136e-01, -7.8936e-02,\n",
            "         -6.3431e-03,  1.5941e-01,  8.8961e-02, -4.1249e-02, -1.5283e-01,\n",
            "         -2.6457e-02],\n",
            "        [ 1.7969e-01, -1.4301e-01, -2.4433e-01,  2.6367e-01,  2.5167e-02,\n",
            "         -2.1137e-01, -7.4701e-02,  1.5997e-01,  6.5696e-02, -1.4813e-03,\n",
            "         -2.0838e-01,  2.8921e-01,  8.4904e-02,  2.4934e-01, -5.4332e-02,\n",
            "          3.0071e-01],\n",
            "        [-4.7580e-02, -7.6481e-02,  3.4109e-02, -1.5673e-01,  1.0375e-01,\n",
            "          1.9831e-01, -4.1480e-02,  4.8797e-02, -2.8900e-02, -1.9595e-02,\n",
            "          4.0486e-02,  1.1943e-02,  6.6604e-02, -4.2723e-02, -1.4520e-01,\n",
            "          3.2637e-01],\n",
            "        [ 1.2829e-01,  9.3031e-02,  3.6918e-01, -3.4444e-01,  1.6909e-01,\n",
            "          4.9133e-02,  3.2781e-01,  3.7070e-01,  6.0510e-02, -3.5023e-02,\n",
            "         -5.3891e-02,  3.5990e-01,  1.2973e-01, -5.1246e-02,  1.8039e-03,\n",
            "         -1.6265e-01],\n",
            "        [-1.2253e-01, -6.6055e-03, -7.9068e-02, -2.1709e-02, -1.2566e-01,\n",
            "         -7.2884e-02,  7.3626e-01,  2.7695e-01,  1.9757e-01,  3.0867e-01,\n",
            "          3.0060e-01,  4.6456e-01, -2.4232e-01,  1.9947e-01,  1.1047e-01,\n",
            "         -1.1790e-01],\n",
            "        [ 1.6138e-01,  2.5353e-01,  1.5377e-01, -2.8039e-01,  2.8337e-02,\n",
            "          1.2423e-01, -1.1123e-02,  2.1677e-01, -1.3816e-01, -5.0837e-02,\n",
            "          2.4725e-03,  6.4861e-02, -1.2000e-01, -2.3955e-01, -2.2835e-01,\n",
            "         -1.0388e-01],\n",
            "        [ 1.5097e-02, -2.7803e-02,  2.3893e-01, -1.1563e-01, -5.0485e-02,\n",
            "         -2.0249e-02,  2.9245e-01,  6.3526e-02, -9.7638e-02,  1.8421e-03,\n",
            "          1.2326e-01, -2.7872e-02,  4.3301e-03,  1.0163e-03, -1.5171e-04,\n",
            "         -1.7258e-01],\n",
            "        [ 1.4679e-02, -1.2914e-01, -3.0964e-01,  2.7260e-01,  1.2236e-01,\n",
            "         -3.5776e-02, -4.1735e-01, -1.1538e-01, -1.2335e-01, -1.8252e-01,\n",
            "         -1.0157e-01, -2.1411e-01, -1.8586e-01,  4.8755e-02,  1.2369e-01,\n",
            "         -6.1582e-02],\n",
            "        [ 2.5373e-02, -2.1935e-01,  9.7885e-02,  8.9743e-02,  1.0752e-01,\n",
            "         -1.7486e-01, -1.6255e-01, -1.3223e-01, -6.7109e-02, -1.6156e-01,\n",
            "         -2.9660e-01, -2.2071e-01, -2.9908e-01, -2.4921e-01, -1.0130e-01,\n",
            "          1.1813e-02],\n",
            "        [ 1.9539e-01, -2.2595e-02,  2.7461e-01, -2.0555e-02,  4.2501e-02,\n",
            "         -1.5530e-02,  4.0770e-01,  2.2047e-01,  8.4262e-02,  2.6203e-01,\n",
            "          3.1747e-01,  6.8576e-01,  5.4033e-03, -1.3110e-02,  1.6135e-02,\n",
            "         -2.0092e-01],\n",
            "        [-1.4154e-01, -5.8579e-04,  1.3027e-01,  9.2789e-02,  1.3463e-01,\n",
            "          7.6270e-02, -1.9917e-01,  2.7212e-01, -4.7681e-02, -1.0469e-01,\n",
            "         -1.3409e-01,  1.6722e-01,  6.5315e-02,  1.7841e-02,  2.2486e-02,\n",
            "          6.2742e-03],\n",
            "        [-2.0700e-01, -1.4263e-01,  8.4379e-02, -1.6187e-01,  2.4448e-01,\n",
            "         -2.0527e-01,  3.2996e-01,  4.1570e-01, -9.0828e-02,  2.5860e-01,\n",
            "          1.0366e-01,  3.2441e-01,  1.3427e-01, -1.2278e-01, -2.1734e-01,\n",
            "          8.9342e-02],\n",
            "        [ 3.6721e-02,  3.9912e-02,  6.6431e-02, -4.9642e-01,  1.0567e-01,\n",
            "          2.2308e-01,  3.3282e-01, -4.7398e-01,  2.9180e-01,  1.8957e-01,\n",
            "         -9.9124e-02,  3.6361e-01,  3.2616e-01, -4.9789e-02, -1.4960e-01,\n",
            "          1.3086e-01],\n",
            "        [-9.7579e-02,  9.7209e-02,  1.3024e-01, -3.5350e-01, -7.0200e-02,\n",
            "         -1.7615e-01, -2.3083e-01, -4.1906e-02, -1.7637e-01,  2.1140e-02,\n",
            "          1.2557e-01, -2.4515e-01, -3.1865e-01,  1.3735e-01,  6.2464e-02,\n",
            "          1.7466e-01],\n",
            "        [-1.3518e-01,  1.8079e-01, -2.9341e-01,  5.8846e-02, -4.0695e-02,\n",
            "          8.6645e-02, -1.9028e-01,  1.0380e-01, -3.3052e-02, -2.5059e-01,\n",
            "         -2.5654e-01, -2.0229e-01, -8.6180e-02, -6.7891e-02, -5.1838e-02,\n",
            "         -2.9030e-01],\n",
            "        [-9.8133e-02, -2.0684e-02,  5.3039e-02, -1.0932e-01,  4.9404e-03,\n",
            "         -1.8339e-01,  1.9471e-01,  3.4571e-01,  7.5404e-02,  1.5377e-01,\n",
            "          1.8933e-01, -3.6479e-01, -1.3679e-01,  3.8795e-02, -9.4737e-02,\n",
            "         -1.0179e-01]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([ 0.2691, -0.3710, -0.1495,  0.2137,  0.2169, -0.1911,  0.5582,  0.0711,\n",
            "         0.0751,  0.3362, -0.3139,  0.4170, -0.0125, -0.0197,  0.0014,  0.4918],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[ 0.1809, -0.0669, -0.4371,  0.0653,  0.1017, -0.2506,  0.5259, -0.0835,\n",
            "         -0.1449,  0.0995, -0.1663,  0.1267,  0.0470, -0.1495, -0.2830,  0.2597]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([0.2566], dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomizableFeatureNet(\n",
              "  (hidden_layers): ModuleList(\n",
              "    (0): Linear(in_features=2, out_features=16, bias=True)\n",
              "    (1): Linear(in_features=16, out_features=16, bias=True)\n",
              "  )\n",
              "  (output_layer): Linear(in_features=16, out_features=1, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_200_random_pi_b.get_heatmap()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "It3Bo2HN6YX6",
        "outputId": "950ca4ac-9d5c-451d-c0c5-3557fdc20bf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"c1e4d5a6-3632-4c3f-9e25-f04dd68935c9\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"c1e4d5a6-3632-4c3f-9e25-f04dd68935c9\")) {                    Plotly.newPlot(                        \"c1e4d5a6-3632-4c3f-9e25-f04dd68935c9\",                        [{\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"z\":[[1.7967267603800279,1.467908576865813,1.3258707471462574,1.1899142791159545,1.1217831616368792,1.053652044157804,0.9855209266787288,0.9183278508621946,0.947467219377844,0.9851509505088547],[1.5809156896321797,1.2179458629662732,1.136065500613331,1.028887396544338,0.9637965548217926,0.8987057130992473,0.833614871376702,0.7858303912803377,0.8201291561756285,0.8595501468819213],[1.4540686034856911,1.0964223157926922,0.9349160078432159,0.8482153289191623,0.7932571831775987,0.7281663414550537,0.6630754997325081,0.642210152110949,0.6814511220732009,0.7239687462723023],[1.3182147856477346,1.0453921270249023,0.821743244501745,0.6469974793981104,0.5788784884756291,0.5248625782694767,0.4700937355935156,0.4896438907555515,0.5345590321286656,0.5794774589719762],[1.1813961025595003,0.9874242153659007,0.7853168423586621,0.570303610003962,0.4084429535902846,0.31816869988011776,0.29077986345077855,0.31446738971643473,0.3572265446450995,0.4132908418071449],[1.0688035060904368,0.929456303706899,0.7372086862823217,0.536661571510497,0.3528746150830465,0.2109542345566836,0.1705939664624107,0.14974939817970323,0.19025128240884573,0.24253076153280412],[1.0163943233216586,0.8714883920478975,0.6863830035210761,0.49138976902850434,0.3263701364062183,0.1851142533348975,0.14801641168813673,0.10501986627121473,0.07609069081110909,0.08715082855163148],[0.9639851405528805,0.813520480388896,0.644368319254772,0.4571537173201099,0.3077850538526008,0.17497913784262317,0.13830142094044998,0.11326083370805004,0.06986953796906675,0.021305209698340627],[0.9062601924509346,0.7555525687298943,0.6023536349884678,0.4332924219673123,0.2935360587140924,0.18117039520899209,0.12710518045546745,0.1011384266635379,0.07609783943113807,0.039956678791043254],[0.8440181481104385,0.6950484383657092,0.5801067803258085,0.4379438315716432,0.3159948502152683,0.20492389786663362,0.1268879630987494,0.0890160196190257,0.0639754323866259,0.03893484515422596]],\"type\":\"heatmap\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"Values\"},\"ticks\":\"outside\",\"tickvals\":[0.021305209698340627,1.7967267603800279],\"ticktext\":[0.021305209698340627,1.7967267603800279]}},\"xaxis\":{\"tickvals\":[0,1,2,3,4,5,6,7,8,9],\"ticktext\":[0,1,2,3,4,5,6,7,8,9],\"title\":{\"text\":\"X\"}},\"yaxis\":{\"tickvals\":[9,8,7,6,5,4,3,2,1,0],\"ticktext\":[9,8,7,6,5,4,3,2,1,0],\"title\":{\"text\":\"Y\"},\"autorange\":\"reversed\"},\"title\":{\"text\":\"Heatmap\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('c1e4d5a6-3632-4c3f-9e25-f04dd68935c9');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_200_random_pi_b.IS_pipeline()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36231419-9312-4c1d-aa15-04a63506aa73",
        "id": "sRHfeo2M61vf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(-4.8178e-10, dtype=torch.float64),\n",
              " tensor(1.6278e-19, dtype=torch.float64))"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calc_V_pi_e(pi_e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "993fb05b-9179-4330-d630-78ba0de54a48",
        "id": "wfsewrsW61vp"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1871443974984857"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_200_random_pi_b.evaluate_scope()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bf46b4f-3bc6-41f8-f1c2-5520cd56718c",
        "id": "A9HyHxak61vq"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.4028, dtype=torch.float64, grad_fn=<MeanBackward0>),\n",
              " tensor(0.0122, dtype=torch.float64, grad_fn=<VarBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test random 400 pi_b"
      ],
      "metadata": {
        "id": "fFDrIbdhCntF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b = action_probs_top_n_epsilon(q_table, 1, 0.4)\n",
        "pi_b = experiment_actions(400, env_50, P_pi_b)\n",
        "P_pi_e = action_probs_top_n_epsilon(q_table, 1, 0.05)\n",
        "pi_e = experiment_actions(1000, env_50, P_pi_e)\n",
        "model_400_random_pi_b = CustomizableFeatureNet(input_dim=2, hidden_dims=[16, 16], output_dim=1, dtype = torch.float64)\n",
        "test_400_random_pi_b = SCOPE_straight(model_400_random_pi_b, 0.99, 10000, pi_b, P_pi_b, P_pi_e, 0.3, dtype = torch.float64)\n"
      ],
      "metadata": {
        "id": "GrHBDiSzCntP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_400_random_pi_b.IS_pipeline()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4879b8f-2271-4ead-a6b4-1d43a0c58ef9",
        "id": "zIT3vLftCntQ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.7103, dtype=torch.float64), tensor(0.0590, dtype=torch.float64))"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_400_random_pi_b.get_state_visitation_heatmap()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "403b9d5e-643e-4eab-b7e5-270edce11e42",
        "id": "nHuUijSWCntP"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"11827d77-a379-4557-98e4-5853b9196352\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"11827d77-a379-4557-98e4-5853b9196352\")) {                    Plotly.newPlot(                        \"11827d77-a379-4557-98e4-5853b9196352\",                        [{\"colorbar\":{\"title\":{\"text\":\"Visits\"}},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"x\":[0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9],\"y\":[9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0],\"z\":[0,0,23,184,436,830,920,663,520,320,0,11,60,362,411,0,850,441,377,332,0,84,203,361,125,0,678,341,405,655,0,150,202,88,23,0,320,173,170,162,0,121,51,20,7,0,89,77,69,43,20,76,9,6,0,0,19,17,9,14,1,11,1,3,0,0,18,17,8,11,1,1,0,0,0,0,19,15,10,21,0,0,0,0,0,0,15,16,11,12,0,0,0,0,0,0,13,8,7,9],\"zmax\":920,\"zmin\":0,\"type\":\"heatmap\"}],                        {\"title\":{\"text\":\"State Visitations Heatmap\"},\"xaxis\":{\"title\":{\"text\":\"X-axis\"}},\"yaxis\":{\"ticktext\":[9,8,7,6,5,4,3,2,1,0],\"tickvals\":[0,1,2,3,4,5,6,7,8,9],\"title\":{\"text\":\"Y-axis\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('11827d77-a379-4557-98e4-5853b9196352');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_400_random_pi_b.train_var_scope(500, 0.001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4e5b9b4-9248-41c7-dfb7-8671d569d6e3",
        "id": "2SaDrZikCntQ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.2298, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2863851925761847\n",
            "Total Loss: 0.5162089638144078\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.5702, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2473059801237863\n",
            "Total Loss: 0.8175554880907143\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.5554, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2326082591574042\n",
            "Total Loss: 0.7880451023448775\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.5384, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.21986669348691343\n",
            "Total Loss: 0.7582925337594453\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.5203, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.20852381842836246\n",
            "Total Loss: 0.728832287868817\n",
            "----------------------------------------\n",
            "Epoch 6\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.5018, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.19826675288001688\n",
            "Total Loss: 0.7000363003809686\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.4834, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.18897165089833828\n",
            "Total Loss: 0.6723549508317651\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.4651, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.18055707200899376\n",
            "Total Loss: 0.6456580612285572\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.4470, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.172912477742959\n",
            "Total Loss: 0.6199570756052522\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.4293, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1659557436250448\n",
            "Total Loss: 0.5952608125412007\n",
            "----------------------------------------\n",
            "Epoch 11\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.4118, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.15959548311099986\n",
            "Total Loss: 0.5713970194820261\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.3947, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1537579790146848\n",
            "Total Loss: 0.5485058420300066\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.3785, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.14840443604510045\n",
            "Total Loss: 0.5268567739326011\n",
            "----------------------------------------\n",
            "Epoch 14\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.3625, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.14348833599280547\n",
            "Total Loss: 0.5060349171699419\n",
            "----------------------------------------\n",
            "Epoch 15\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.3472, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.13895918143484104\n",
            "Total Loss: 0.48613854212261365\n",
            "----------------------------------------\n",
            "Epoch 16\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.3323, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.13478196591529057\n",
            "Total Loss: 0.467122800321549\n",
            "----------------------------------------\n",
            "Epoch 17\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.3180, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1309268905269555\n",
            "Total Loss: 0.44893933800596186\n",
            "----------------------------------------\n",
            "Epoch 18\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.3043, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.12735200770945743\n",
            "Total Loss: 0.4316061594195954\n",
            "----------------------------------------\n",
            "Epoch 19\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.2911, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.12403121282357239\n",
            "Total Loss: 0.4151066725447233\n",
            "----------------------------------------\n",
            "Epoch 20\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.2785, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1209448456195101\n",
            "Total Loss: 0.3994010276619956\n",
            "----------------------------------------\n",
            "Epoch 21\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.2664, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1180631581066447\n",
            "Total Loss: 0.3844554182469116\n",
            "----------------------------------------\n",
            "Epoch 22\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.2549, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11537090630803047\n",
            "Total Loss: 0.37025061344569205\n",
            "----------------------------------------\n",
            "Epoch 23\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.2439, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11284169480833979\n",
            "Total Loss: 0.35670228404949506\n",
            "----------------------------------------\n",
            "Epoch 24\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.2331, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.11043526522024422\n",
            "Total Loss: 0.3435595699773738\n",
            "----------------------------------------\n",
            "Epoch 25\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.2230, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10814175225102787\n",
            "Total Loss: 0.3311123826201646\n",
            "----------------------------------------\n",
            "Epoch 26\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.2133, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.1059537333932855\n",
            "Total Loss: 0.31922928899606723\n",
            "----------------------------------------\n",
            "Epoch 27\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.2040, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10386661592352302\n",
            "Total Loss: 0.3079035782151253\n",
            "----------------------------------------\n",
            "Epoch 28\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.1953, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.10187557411230364\n",
            "Total Loss: 0.29713167798483725\n",
            "----------------------------------------\n",
            "Epoch 29\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.1870, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.09997924860198962\n",
            "Total Loss: 0.2869340966810977\n",
            "----------------------------------------\n",
            "Epoch 30\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.1792, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.09817163936327368\n",
            "Total Loss: 0.2773241402174001\n",
            "----------------------------------------\n",
            "Epoch 31\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.1718, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.09645014374147605\n",
            "Total Loss: 0.2682052348710992\n",
            "----------------------------------------\n",
            "Epoch 32\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.1648, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.09481718353025245\n",
            "Total Loss: 0.25964553921256694\n",
            "----------------------------------------\n",
            "Epoch 33\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.1583, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.09326467886582544\n",
            "Total Loss: 0.25152615449274535\n",
            "----------------------------------------\n",
            "Epoch 34\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.1520, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.09178609853516995\n",
            "Total Loss: 0.24382416403809826\n",
            "----------------------------------------\n",
            "Epoch 35\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.1461, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.09037666413476403\n",
            "Total Loss: 0.2365178165127424\n",
            "----------------------------------------\n",
            "Epoch 36\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.1405, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.08903552593916654\n",
            "Total Loss: 0.2295664935358125\n",
            "----------------------------------------\n",
            "Epoch 37\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.1352, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.08775721072010959\n",
            "Total Loss: 0.22298839008537572\n",
            "----------------------------------------\n",
            "Epoch 38\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.1302, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.08652874656286054\n",
            "Total Loss: 0.21674102285155183\n",
            "----------------------------------------\n",
            "Epoch 39\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.1255, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0853480508898544\n",
            "Total Loss: 0.21081088176642782\n",
            "----------------------------------------\n",
            "Epoch 40\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.1210, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.08421519431331585\n",
            "Total Loss: 0.20518317454940221\n",
            "----------------------------------------\n",
            "Epoch 41\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.1167, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.08312780448058639\n",
            "Total Loss: 0.19984912785894587\n",
            "----------------------------------------\n",
            "Epoch 42\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.1127, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.08208055872546424\n",
            "Total Loss: 0.19478991971158105\n",
            "----------------------------------------\n",
            "Epoch 43\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.1089, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.08107028716545518\n",
            "Total Loss: 0.18998263977150298\n",
            "----------------------------------------\n",
            "Epoch 44\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.1053, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.080090547759785\n",
            "Total Loss: 0.18541184371060163\n",
            "----------------------------------------\n",
            "Epoch 45\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.1019, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0791399507629104\n",
            "Total Loss: 0.18106328302642946\n",
            "----------------------------------------\n",
            "Epoch 46\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0987, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.07821595475855339\n",
            "Total Loss: 0.1769236263903342\n",
            "----------------------------------------\n",
            "Epoch 47\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0957, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.07731178571945062\n",
            "Total Loss: 0.1729751572604095\n",
            "----------------------------------------\n",
            "Epoch 48\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0928, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.07642446995174586\n",
            "Total Loss: 0.16919397053789206\n",
            "----------------------------------------\n",
            "Epoch 49\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0900, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.07555561159738797\n",
            "Total Loss: 0.16558068951425942\n",
            "----------------------------------------\n",
            "Epoch 50\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0874, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.07470584834317465\n",
            "Total Loss: 0.1621069287314654\n",
            "----------------------------------------\n",
            "Epoch 51\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0849, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.07387586081773648\n",
            "Total Loss: 0.15878110341571183\n",
            "----------------------------------------\n",
            "Epoch 52\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0825, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.07306191069071502\n",
            "Total Loss: 0.15560899498432212\n",
            "----------------------------------------\n",
            "Epoch 53\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0803, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.07226486847737125\n",
            "Total Loss: 0.15256901270163356\n",
            "----------------------------------------\n",
            "Epoch 54\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0782, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.07148802072258266\n",
            "Total Loss: 0.1496397385209185\n",
            "----------------------------------------\n",
            "Epoch 55\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0761, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0707269357205651\n",
            "Total Loss: 0.14682552100209711\n",
            "----------------------------------------\n",
            "Epoch 56\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0741, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.06998026556721548\n",
            "Total Loss: 0.1441198956295167\n",
            "----------------------------------------\n",
            "Epoch 57\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0723, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.06924920704957288\n",
            "Total Loss: 0.1415177581802436\n",
            "----------------------------------------\n",
            "Epoch 58\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0705, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.06853085115471098\n",
            "Total Loss: 0.13902656159943427\n",
            "----------------------------------------\n",
            "Epoch 59\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0688, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.06782726310867607\n",
            "Total Loss: 0.1366391552071028\n",
            "----------------------------------------\n",
            "Epoch 60\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0672, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.06713849499049344\n",
            "Total Loss: 0.13433653376608662\n",
            "----------------------------------------\n",
            "Epoch 61\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0657, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.06645620656491633\n",
            "Total Loss: 0.13210677608267948\n",
            "----------------------------------------\n",
            "Epoch 62\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0642, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.06577686168207701\n",
            "Total Loss: 0.12995154715967458\n",
            "----------------------------------------\n",
            "Epoch 63\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0628, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.06510804504962012\n",
            "Total Loss: 0.1278646458090396\n",
            "----------------------------------------\n",
            "Epoch 64\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0614, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.06444432108979715\n",
            "Total Loss: 0.1258392622890399\n",
            "----------------------------------------\n",
            "Epoch 65\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0601, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0637901749619609\n",
            "Total Loss: 0.1238824248670695\n",
            "----------------------------------------\n",
            "Epoch 66\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0588, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.06314147183492513\n",
            "Total Loss: 0.12197779561186442\n",
            "----------------------------------------\n",
            "Epoch 67\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0576, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.06249759529367658\n",
            "Total Loss: 0.12010817508182835\n",
            "----------------------------------------\n",
            "Epoch 68\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0564, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.06186130439320088\n",
            "Total Loss: 0.1182825018582988\n",
            "----------------------------------------\n",
            "Epoch 69\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0553, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.06122817448727384\n",
            "Total Loss: 0.11649104755779341\n",
            "----------------------------------------\n",
            "Epoch 70\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0543, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.060581153599471756\n",
            "Total Loss: 0.11486767775522956\n",
            "----------------------------------------\n",
            "Epoch 71\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0533, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.05994914109266375\n",
            "Total Loss: 0.11328724655527114\n",
            "----------------------------------------\n",
            "Epoch 72\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0524, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.05932585185519192\n",
            "Total Loss: 0.11169445158053454\n",
            "----------------------------------------\n",
            "Epoch 73\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0514, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.05871540913676362\n",
            "Total Loss: 0.11012863488733543\n",
            "----------------------------------------\n",
            "Epoch 74\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0505, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.058123131446184556\n",
            "Total Loss: 0.10860626749277749\n",
            "----------------------------------------\n",
            "Epoch 75\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0496, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.05755371129562669\n",
            "Total Loss: 0.10712076089106196\n",
            "----------------------------------------\n",
            "Epoch 76\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0487, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.05700377488842894\n",
            "Total Loss: 0.10565426926208238\n",
            "----------------------------------------\n",
            "Epoch 77\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0477, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.05647144311488744\n",
            "Total Loss: 0.10420329880151763\n",
            "----------------------------------------\n",
            "Epoch 78\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0468, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.05595499832786017\n",
            "Total Loss: 0.10276857377485152\n",
            "----------------------------------------\n",
            "Epoch 79\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0459, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.05545321038687514\n",
            "Total Loss: 0.10135239889760742\n",
            "----------------------------------------\n",
            "Epoch 80\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0450, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.054958842083758896\n",
            "Total Loss: 0.09998268444682643\n",
            "----------------------------------------\n",
            "Epoch 81\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0442, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.05446981144215227\n",
            "Total Loss: 0.0986490294573816\n",
            "----------------------------------------\n",
            "Epoch 82\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0433, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.053996962383926254\n",
            "Total Loss: 0.09733683865870635\n",
            "----------------------------------------\n",
            "Epoch 83\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0425, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.05354179941197838\n",
            "Total Loss: 0.09603788560120095\n",
            "----------------------------------------\n",
            "Epoch 84\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0417, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.05310483651932846\n",
            "Total Loss: 0.09475689406040208\n",
            "----------------------------------------\n",
            "Epoch 85\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0408, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.05268088712517449\n",
            "Total Loss: 0.0935124525885123\n",
            "----------------------------------------\n",
            "Epoch 86\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0400, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.05226412037367053\n",
            "Total Loss: 0.0922957830410684\n",
            "----------------------------------------\n",
            "Epoch 87\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0392, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.051849733973555016\n",
            "Total Loss: 0.0910940168343146\n",
            "----------------------------------------\n",
            "Epoch 88\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0385, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.051434616096853944\n",
            "Total Loss: 0.08990214369082292\n",
            "----------------------------------------\n",
            "Epoch 89\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0377, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.05102068671390002\n",
            "Total Loss: 0.08872537794511716\n",
            "----------------------------------------\n",
            "Epoch 90\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0370, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.050606204757828024\n",
            "Total Loss: 0.08757118122227919\n",
            "----------------------------------------\n",
            "Epoch 91\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0362, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.05019149336548305\n",
            "Total Loss: 0.08641552207549899\n",
            "----------------------------------------\n",
            "Epoch 92\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0355, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.04978479144252726\n",
            "Total Loss: 0.08532445818751327\n",
            "----------------------------------------\n",
            "Epoch 93\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0349, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.04938738499172196\n",
            "Total Loss: 0.08424760990755979\n",
            "----------------------------------------\n",
            "Epoch 94\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0342, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.048993168490777936\n",
            "Total Loss: 0.08316098968076371\n",
            "----------------------------------------\n",
            "Epoch 95\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0335, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.04860184388712316\n",
            "Total Loss: 0.08212453213152807\n",
            "----------------------------------------\n",
            "Epoch 96\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0329, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.048212226997318385\n",
            "Total Loss: 0.08109747170133938\n",
            "----------------------------------------\n",
            "Epoch 97\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0323, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.04781627247316049\n",
            "Total Loss: 0.08008895191837334\n",
            "----------------------------------------\n",
            "Epoch 98\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0317, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.047416440881913074\n",
            "Total Loss: 0.07911662975331128\n",
            "----------------------------------------\n",
            "Epoch 99\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0312, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.04701422121477403\n",
            "Total Loss: 0.0781793069637758\n",
            "----------------------------------------\n",
            "Epoch 100\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0306, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.04661533301623461\n",
            "Total Loss: 0.07726476574042299\n",
            "----------------------------------------\n",
            "Epoch 101\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0301, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.04622126108954041\n",
            "Total Loss: 0.07636753152123993\n",
            "----------------------------------------\n",
            "Epoch 102\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0297, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.04583561474847478\n",
            "Total Loss: 0.07549574978777773\n",
            "----------------------------------------\n",
            "Epoch 103\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0292, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.04545756618820542\n",
            "Total Loss: 0.07465727051050285\n",
            "----------------------------------------\n",
            "Epoch 104\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0287, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.045086321213661344\n",
            "Total Loss: 0.07382637879054067\n",
            "----------------------------------------\n",
            "Epoch 105\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0283, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.044721864890589026\n",
            "Total Loss: 0.07301216116223425\n",
            "----------------------------------------\n",
            "Epoch 106\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0278, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.04436331086004217\n",
            "Total Loss: 0.07221003984719583\n",
            "----------------------------------------\n",
            "Epoch 107\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0274, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.044010885125226086\n",
            "Total Loss: 0.07141735854678588\n",
            "----------------------------------------\n",
            "Epoch 108\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0270, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0436638050117803\n",
            "Total Loss: 0.07063088055628043\n",
            "----------------------------------------\n",
            "Epoch 109\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0265, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.04332099894566407\n",
            "Total Loss: 0.06985055401975412\n",
            "----------------------------------------\n",
            "Epoch 110\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0261, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.04298279148968409\n",
            "Total Loss: 0.06907933917334455\n",
            "----------------------------------------\n",
            "Epoch 111\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0257, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.04264972039557376\n",
            "Total Loss: 0.06831729474994916\n",
            "----------------------------------------\n",
            "Epoch 112\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0252, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0423200743065059\n",
            "Total Loss: 0.06756778620726046\n",
            "----------------------------------------\n",
            "Epoch 113\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0248, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.04199304761579122\n",
            "Total Loss: 0.06683170991210652\n",
            "----------------------------------------\n",
            "Epoch 114\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0244, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.04166940768353809\n",
            "Total Loss: 0.0661165382788514\n",
            "----------------------------------------\n",
            "Epoch 115\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0241, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.04134871687487795\n",
            "Total Loss: 0.06541474829031751\n",
            "----------------------------------------\n",
            "Epoch 116\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0237, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.041030956301435315\n",
            "Total Loss: 0.06472836323328576\n",
            "----------------------------------------\n",
            "Epoch 117\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0233, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.04071465237314019\n",
            "Total Loss: 0.0640532377906766\n",
            "----------------------------------------\n",
            "Epoch 118\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0230, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.040400782448351845\n",
            "Total Loss: 0.06339004778522986\n",
            "----------------------------------------\n",
            "Epoch 119\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0226, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.04008957359950369\n",
            "Total Loss: 0.06273878924935052\n",
            "----------------------------------------\n",
            "Epoch 120\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0223, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.03978120944884346\n",
            "Total Loss: 0.06209851636660791\n",
            "----------------------------------------\n",
            "Epoch 121\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0220, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.03947562371540651\n",
            "Total Loss: 0.06146950423009423\n",
            "----------------------------------------\n",
            "Epoch 122\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0217, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.03916941391769405\n",
            "Total Loss: 0.060852392294632615\n",
            "----------------------------------------\n",
            "Epoch 123\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0214, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.03885823289652614\n",
            "Total Loss: 0.06023372428302032\n",
            "----------------------------------------\n",
            "Epoch 124\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0211, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.038547312808513284\n",
            "Total Loss: 0.059620393889821446\n",
            "----------------------------------------\n",
            "Epoch 125\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0208, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.038237247546435926\n",
            "Total Loss: 0.05901236746888863\n",
            "----------------------------------------\n",
            "Epoch 126\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0205, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.037918326099439945\n",
            "Total Loss: 0.05838921765791244\n",
            "----------------------------------------\n",
            "Epoch 127\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0202, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.03759409211266411\n",
            "Total Loss: 0.05776964473178225\n",
            "----------------------------------------\n",
            "Epoch 128\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0199, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.03726653921043609\n",
            "Total Loss: 0.057155240699902875\n",
            "----------------------------------------\n",
            "Epoch 129\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0196, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.03693775848353213\n",
            "Total Loss: 0.05654828256105143\n",
            "----------------------------------------\n",
            "Epoch 130\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0193, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.036609719061350285\n",
            "Total Loss: 0.0559504322409041\n",
            "----------------------------------------\n",
            "Epoch 131\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0191, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.03628538239664475\n",
            "Total Loss: 0.05536424249240464\n",
            "----------------------------------------\n",
            "Epoch 132\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0188, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.03596539949892757\n",
            "Total Loss: 0.05478995454605908\n",
            "----------------------------------------\n",
            "Epoch 133\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0186, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.035651222136588806\n",
            "Total Loss: 0.05422838604769424\n",
            "----------------------------------------\n",
            "Epoch 134\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0183, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.03534162583435268\n",
            "Total Loss: 0.05368073599130145\n",
            "----------------------------------------\n",
            "Epoch 135\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0181, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0350394341036949\n",
            "Total Loss: 0.053150835342942404\n",
            "----------------------------------------\n",
            "Epoch 136\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0179, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.034745576195332785\n",
            "Total Loss: 0.052633455829767375\n",
            "----------------------------------------\n",
            "Epoch 137\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0177, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.034461791463839944\n",
            "Total Loss: 0.052119658046063666\n",
            "----------------------------------------\n",
            "Epoch 138\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0174, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.03418758407922605\n",
            "Total Loss: 0.05160889937299116\n",
            "----------------------------------------\n",
            "Epoch 139\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0172, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.03392133661682674\n",
            "Total Loss: 0.05110021844858314\n",
            "----------------------------------------\n",
            "Epoch 140\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0169, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.03366218941534514\n",
            "Total Loss: 0.05059405962751857\n",
            "----------------------------------------\n",
            "Epoch 141\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0167, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.03340973722530215\n",
            "Total Loss: 0.050091147677094036\n",
            "----------------------------------------\n",
            "Epoch 142\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0164, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.033163404966195784\n",
            "Total Loss: 0.049591868010022036\n",
            "----------------------------------------\n",
            "Epoch 143\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0162, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.03292174844046603\n",
            "Total Loss: 0.049096618352357485\n",
            "----------------------------------------\n",
            "Epoch 144\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0159, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.03268582933286656\n",
            "Total Loss: 0.04860800506592863\n",
            "----------------------------------------\n",
            "Epoch 145\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0157, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.03245382026751554\n",
            "Total Loss: 0.0481254814637017\n",
            "----------------------------------------\n",
            "Epoch 146\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0154, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.03222534530519837\n",
            "Total Loss: 0.047652623155973024\n",
            "----------------------------------------\n",
            "Epoch 147\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0152, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.03199922925354483\n",
            "Total Loss: 0.04719224015066533\n",
            "----------------------------------------\n",
            "Epoch 148\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0150, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.03177445588515271\n",
            "Total Loss: 0.04673783759245872\n",
            "----------------------------------------\n",
            "Epoch 149\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0147, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.03155083270404695\n",
            "Total Loss: 0.046289893334339804\n",
            "----------------------------------------\n",
            "Epoch 150\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0145, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0313282299227026\n",
            "Total Loss: 0.045850428493589446\n",
            "----------------------------------------\n",
            "Epoch 151\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0143, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.03110640546944043\n",
            "Total Loss: 0.04541740577368132\n",
            "----------------------------------------\n",
            "Epoch 152\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0141, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.03088321333663167\n",
            "Total Loss: 0.044985220422290334\n",
            "----------------------------------------\n",
            "Epoch 153\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0139, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.03065862302832907\n",
            "Total Loss: 0.04455626394260144\n",
            "----------------------------------------\n",
            "Epoch 154\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0137, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.030433208418621616\n",
            "Total Loss: 0.04414986478994152\n",
            "----------------------------------------\n",
            "Epoch 155\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0136, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.030210687482944473\n",
            "Total Loss: 0.043770793467949015\n",
            "----------------------------------------\n",
            "Epoch 156\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0134, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.02999007774468181\n",
            "Total Loss: 0.04339377506609139\n",
            "----------------------------------------\n",
            "Epoch 157\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0132, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.02976846987065737\n",
            "Total Loss: 0.04300680253761639\n",
            "----------------------------------------\n",
            "Epoch 158\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0131, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.029548592198163387\n",
            "Total Loss: 0.04262213533720177\n",
            "----------------------------------------\n",
            "Epoch 159\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0129, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.029331119130934735\n",
            "Total Loss: 0.04223881638041371\n",
            "----------------------------------------\n",
            "Epoch 160\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0127, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.029116306424930054\n",
            "Total Loss: 0.04185595824940202\n",
            "----------------------------------------\n",
            "Epoch 161\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0126, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.028901971605551736\n",
            "Total Loss: 0.04147894866329137\n",
            "----------------------------------------\n",
            "Epoch 162\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0124, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.02868982056343206\n",
            "Total Loss: 0.04111308192826179\n",
            "----------------------------------------\n",
            "Epoch 163\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0123, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0284793797918868\n",
            "Total Loss: 0.04074862037980683\n",
            "----------------------------------------\n",
            "Epoch 164\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0121, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.028246397194270797\n",
            "Total Loss: 0.0403556631340559\n",
            "----------------------------------------\n",
            "Epoch 165\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0120, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.028000332227181783\n",
            "Total Loss: 0.0399540405498715\n",
            "----------------------------------------\n",
            "Epoch 166\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0118, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.02775190081841106\n",
            "Total Loss: 0.03954394264672406\n",
            "----------------------------------------\n",
            "Epoch 167\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0116, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.02750338857523835\n",
            "Total Loss: 0.039128519869296205\n",
            "----------------------------------------\n",
            "Epoch 168\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0115, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.027256189909828366\n",
            "Total Loss: 0.038720698977747776\n",
            "----------------------------------------\n",
            "Epoch 169\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0113, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.02701376623002641\n",
            "Total Loss: 0.03832444477958472\n",
            "----------------------------------------\n",
            "Epoch 170\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0112, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.026777636137806513\n",
            "Total Loss: 0.0379380704987082\n",
            "----------------------------------------\n",
            "Epoch 171\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0110, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.026551932422239057\n",
            "Total Loss: 0.037566801686716375\n",
            "----------------------------------------\n",
            "Epoch 172\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0109, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.026338937981374873\n",
            "Total Loss: 0.037211448476734965\n",
            "----------------------------------------\n",
            "Epoch 173\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0107, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.02613508809887547\n",
            "Total Loss: 0.03685394962487807\n",
            "----------------------------------------\n",
            "Epoch 174\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0106, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.025935445503062832\n",
            "Total Loss: 0.036501341148016446\n",
            "----------------------------------------\n",
            "Epoch 175\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0104, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.025741540534538355\n",
            "Total Loss: 0.03615384041812582\n",
            "----------------------------------------\n",
            "Epoch 176\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0103, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.025549197392461698\n",
            "Total Loss: 0.035810289592215765\n",
            "----------------------------------------\n",
            "Epoch 177\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0101, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.02536075687147473\n",
            "Total Loss: 0.0354714715332376\n",
            "----------------------------------------\n",
            "Epoch 178\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0100, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.02517510916804732\n",
            "Total Loss: 0.03513696271030128\n",
            "----------------------------------------\n",
            "Epoch 179\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0098, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.02499185974168578\n",
            "Total Loss: 0.03480620130261567\n",
            "----------------------------------------\n",
            "Epoch 180\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0097, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.02481128840848596\n",
            "Total Loss: 0.03448079369920013\n",
            "----------------------------------------\n",
            "Epoch 181\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0094, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.024638644611883947\n",
            "Total Loss: 0.03406505466183364\n",
            "----------------------------------------\n",
            "Epoch 182\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0092, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.02447141645364346\n",
            "Total Loss: 0.033630179753628316\n",
            "----------------------------------------\n",
            "Epoch 183\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0089, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.02431251525562206\n",
            "Total Loss: 0.03321421646050007\n",
            "----------------------------------------\n",
            "Epoch 184\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0087, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.024160749578489807\n",
            "Total Loss: 0.03282868498561535\n",
            "----------------------------------------\n",
            "Epoch 185\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0084, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.024021032865008993\n",
            "Total Loss: 0.032383248832078416\n",
            "----------------------------------------\n",
            "Epoch 186\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0080, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.023889013179937215\n",
            "Total Loss: 0.03192564071983202\n",
            "----------------------------------------\n",
            "Epoch 187\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0077, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.02376077123939021\n",
            "Total Loss: 0.03148299415463817\n",
            "----------------------------------------\n",
            "Epoch 188\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0074, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.023635381021469108\n",
            "Total Loss: 0.031058403778608322\n",
            "----------------------------------------\n",
            "Epoch 189\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0071, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.023520020419840932\n",
            "Total Loss: 0.030669190377574082\n",
            "----------------------------------------\n",
            "Epoch 190\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0069, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.023411330604175325\n",
            "Total Loss: 0.030307192316351293\n",
            "----------------------------------------\n",
            "Epoch 191\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0067, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.02330146727504272\n",
            "Total Loss: 0.029960819957041085\n",
            "----------------------------------------\n",
            "Epoch 192\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0064, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.023188609559277096\n",
            "Total Loss: 0.029628432556149418\n",
            "----------------------------------------\n",
            "Epoch 193\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0062, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.023070867467658917\n",
            "Total Loss: 0.029308330380233973\n",
            "----------------------------------------\n",
            "Epoch 194\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0061, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.022948385266796337\n",
            "Total Loss: 0.028999960440583148\n",
            "----------------------------------------\n",
            "Epoch 195\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0059, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.022824392597623876\n",
            "Total Loss: 0.028703984049282438\n",
            "----------------------------------------\n",
            "Epoch 196\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0057, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.022708502711754477\n",
            "Total Loss: 0.028424450038810913\n",
            "----------------------------------------\n",
            "Epoch 197\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0056, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.02259092008863513\n",
            "Total Loss: 0.028159131595310423\n",
            "----------------------------------------\n",
            "Epoch 198\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0054, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.022472672064205054\n",
            "Total Loss: 0.027905947961791217\n",
            "----------------------------------------\n",
            "Epoch 199\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0053, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.02235281880148933\n",
            "Total Loss: 0.027661092987826125\n",
            "----------------------------------------\n",
            "Epoch 200\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0052, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.022232427761918017\n",
            "Total Loss: 0.02742446601716244\n",
            "----------------------------------------\n",
            "Epoch 201\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0051, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.02211129011946284\n",
            "Total Loss: 0.027194850942211475\n",
            "----------------------------------------\n",
            "Epoch 202\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0050, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.02199012014231942\n",
            "Total Loss: 0.026971854142489326\n",
            "----------------------------------------\n",
            "Epoch 203\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0049, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.021869684801606084\n",
            "Total Loss: 0.026755441394524987\n",
            "----------------------------------------\n",
            "Epoch 204\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0048, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.021750344698274686\n",
            "Total Loss: 0.026544323915980203\n",
            "----------------------------------------\n",
            "Epoch 205\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0047, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.021631162769415263\n",
            "Total Loss: 0.02634035962189059\n",
            "----------------------------------------\n",
            "Epoch 206\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.02151246864251592\n",
            "Total Loss: 0.026141677706511175\n",
            "----------------------------------------\n",
            "Epoch 207\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.021394727163919002\n",
            "Total Loss: 0.025948199215775927\n",
            "----------------------------------------\n",
            "Epoch 208\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0045, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.021277752340374826\n",
            "Total Loss: 0.025759329207053486\n",
            "----------------------------------------\n",
            "Epoch 209\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0044, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.02116107419681907\n",
            "Total Loss: 0.025573202934883525\n",
            "----------------------------------------\n",
            "Epoch 210\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0043, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.021042982334961\n",
            "Total Loss: 0.025386974657418786\n",
            "----------------------------------------\n",
            "Epoch 211\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0043, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.020925696127797457\n",
            "Total Loss: 0.02520493067246923\n",
            "----------------------------------------\n",
            "Epoch 212\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0042, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.020809582487823428\n",
            "Total Loss: 0.025024886128787734\n",
            "----------------------------------------\n",
            "Epoch 213\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0042, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.020691008267232348\n",
            "Total Loss: 0.024844119436485013\n",
            "----------------------------------------\n",
            "Epoch 214\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0041, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.020570985315430286\n",
            "Total Loss: 0.02466397256847261\n",
            "----------------------------------------\n",
            "Epoch 215\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0040, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.020451540127642685\n",
            "Total Loss: 0.024487635276464966\n",
            "----------------------------------------\n",
            "Epoch 216\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0040, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.02033307843139012\n",
            "Total Loss: 0.02431583154627709\n",
            "----------------------------------------\n",
            "Epoch 217\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0039, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.020215729643910905\n",
            "Total Loss: 0.0241483214494183\n",
            "----------------------------------------\n",
            "Epoch 218\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0039, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.020100004501516923\n",
            "Total Loss: 0.023985348455425482\n",
            "----------------------------------------\n",
            "Epoch 219\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0038, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.019985616385614923\n",
            "Total Loss: 0.023826327988190586\n",
            "----------------------------------------\n",
            "Epoch 220\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0038, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.019872798314217982\n",
            "Total Loss: 0.023670898974847147\n",
            "----------------------------------------\n",
            "Epoch 221\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0038, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01976125377123689\n",
            "Total Loss: 0.02351799739467002\n",
            "----------------------------------------\n",
            "Epoch 222\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0037, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.019650982445226815\n",
            "Total Loss: 0.02336831721092818\n",
            "----------------------------------------\n",
            "Epoch 223\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0037, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01954187643996658\n",
            "Total Loss: 0.023221391389795985\n",
            "----------------------------------------\n",
            "Epoch 224\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01943229483376504\n",
            "Total Loss: 0.023081684451973963\n",
            "----------------------------------------\n",
            "Epoch 225\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.019323349854674585\n",
            "Total Loss: 0.022948377521483893\n",
            "----------------------------------------\n",
            "Epoch 226\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01921683860571461\n",
            "Total Loss: 0.022816476809898997\n",
            "----------------------------------------\n",
            "Epoch 227\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01911281181758891\n",
            "Total Loss: 0.022686529898613493\n",
            "----------------------------------------\n",
            "Epoch 228\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0035, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.019010925119410934\n",
            "Total Loss: 0.022558728312446933\n",
            "----------------------------------------\n",
            "Epoch 229\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0035, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01891098721590745\n",
            "Total Loss: 0.022433168240175917\n",
            "----------------------------------------\n",
            "Epoch 230\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0035, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.018812350427061454\n",
            "Total Loss: 0.022309508133703134\n",
            "----------------------------------------\n",
            "Epoch 231\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0035, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.018715307538834738\n",
            "Total Loss: 0.022188241219401057\n",
            "----------------------------------------\n",
            "Epoch 232\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0034, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01862004928379276\n",
            "Total Loss: 0.02206952554133193\n",
            "----------------------------------------\n",
            "Epoch 233\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0034, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.018526212022095073\n",
            "Total Loss: 0.021952905474883253\n",
            "----------------------------------------\n",
            "Epoch 234\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0034, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.018434292176902494\n",
            "Total Loss: 0.021838831728692755\n",
            "----------------------------------------\n",
            "Epoch 235\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0034, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01834394251505628\n",
            "Total Loss: 0.021726648994204865\n",
            "----------------------------------------\n",
            "Epoch 236\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0034, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.018255050329945025\n",
            "Total Loss: 0.021616013593771292\n",
            "----------------------------------------\n",
            "Epoch 237\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0033, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.018167417288009347\n",
            "Total Loss: 0.021506619579220933\n",
            "----------------------------------------\n",
            "Epoch 238\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0033, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.018081318959893528\n",
            "Total Loss: 0.021398521696258735\n",
            "----------------------------------------\n",
            "Epoch 239\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0033, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.017996743477036968\n",
            "Total Loss: 0.02129156794264606\n",
            "----------------------------------------\n",
            "Epoch 240\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0033, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01791372680141476\n",
            "Total Loss: 0.021185768815610483\n",
            "----------------------------------------\n",
            "Epoch 241\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0032, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.017832281697720335\n",
            "Total Loss: 0.021080920101096513\n",
            "----------------------------------------\n",
            "Epoch 242\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0032, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.017752171095816012\n",
            "Total Loss: 0.02097698523037168\n",
            "----------------------------------------\n",
            "Epoch 243\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0032, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.017673721118550922\n",
            "Total Loss: 0.02087443723578258\n",
            "----------------------------------------\n",
            "Epoch 244\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0032, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01759704452960472\n",
            "Total Loss: 0.02077341397348414\n",
            "----------------------------------------\n",
            "Epoch 245\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0032, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.017522119164340117\n",
            "Total Loss: 0.020673926013915687\n",
            "----------------------------------------\n",
            "Epoch 246\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0031, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.017448777184719502\n",
            "Total Loss: 0.020575797302708067\n",
            "----------------------------------------\n",
            "Epoch 247\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0031, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.017377057901143328\n",
            "Total Loss: 0.020479112717426515\n",
            "----------------------------------------\n",
            "Epoch 248\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0031, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.017306190898558726\n",
            "Total Loss: 0.020383177321953036\n",
            "----------------------------------------\n",
            "Epoch 249\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0031, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.017236274484922223\n",
            "Total Loss: 0.02028823716666425\n",
            "----------------------------------------\n",
            "Epoch 250\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0030, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.017167401839215585\n",
            "Total Loss: 0.020194429722343178\n",
            "----------------------------------------\n",
            "Epoch 251\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0030, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.017099485805858395\n",
            "Total Loss: 0.020101724903607874\n",
            "----------------------------------------\n",
            "Epoch 252\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0030, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.017032455213715107\n",
            "Total Loss: 0.02001011446275016\n",
            "----------------------------------------\n",
            "Epoch 253\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0030, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01696627215797274\n",
            "Total Loss: 0.019919527940584224\n",
            "----------------------------------------\n",
            "Epoch 254\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0029, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01690082954113198\n",
            "Total Loss: 0.019829903315190415\n",
            "----------------------------------------\n",
            "Epoch 255\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0029, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.016836366001168224\n",
            "Total Loss: 0.019741524418353428\n",
            "----------------------------------------\n",
            "Epoch 256\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0029, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.016772255732756446\n",
            "Total Loss: 0.01965379148519754\n",
            "----------------------------------------\n",
            "Epoch 257\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0029, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.016708695477231316\n",
            "Total Loss: 0.019566954200786135\n",
            "----------------------------------------\n",
            "Epoch 258\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0028, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.016645706620239863\n",
            "Total Loss: 0.019481038658190602\n",
            "----------------------------------------\n",
            "Epoch 259\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0028, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.016583374833206967\n",
            "Total Loss: 0.01939612907004961\n",
            "----------------------------------------\n",
            "Epoch 260\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0028, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.016521796431098662\n",
            "Total Loss: 0.01931230651872068\n",
            "----------------------------------------\n",
            "Epoch 261\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0028, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.016461130381680247\n",
            "Total Loss: 0.019229741813045705\n",
            "----------------------------------------\n",
            "Epoch 262\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0027, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.016401135060559124\n",
            "Total Loss: 0.01914818643424\n",
            "----------------------------------------\n",
            "Epoch 263\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0027, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.016341760841607687\n",
            "Total Loss: 0.019067560726223273\n",
            "----------------------------------------\n",
            "Epoch 264\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0027, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.016283014317184298\n",
            "Total Loss: 0.018987841952847955\n",
            "----------------------------------------\n",
            "Epoch 265\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0027, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.016224826380025575\n",
            "Total Loss: 0.018908992199654764\n",
            "----------------------------------------\n",
            "Epoch 266\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0027, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.016167720185187688\n",
            "Total Loss: 0.018831534620099465\n",
            "----------------------------------------\n",
            "Epoch 267\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0026, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.016111286902431726\n",
            "Total Loss: 0.01875505407077086\n",
            "----------------------------------------\n",
            "Epoch 268\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0026, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.016055363111735724\n",
            "Total Loss: 0.018679395313124507\n",
            "----------------------------------------\n",
            "Epoch 269\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0026, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.015999989030502787\n",
            "Total Loss: 0.018604608221498682\n",
            "----------------------------------------\n",
            "Epoch 270\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0026, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01594512559027011\n",
            "Total Loss: 0.018530639410681216\n",
            "----------------------------------------\n",
            "Epoch 271\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0026, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.015890747858740045\n",
            "Total Loss: 0.018457455871004082\n",
            "----------------------------------------\n",
            "Epoch 272\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0025, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.015836912036625565\n",
            "Total Loss: 0.018385103504420443\n",
            "----------------------------------------\n",
            "Epoch 273\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0025, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01578315666840273\n",
            "Total Loss: 0.018312859939753783\n",
            "----------------------------------------\n",
            "Epoch 274\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0025, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.015725437868793626\n",
            "Total Loss: 0.018236064859166196\n",
            "----------------------------------------\n",
            "Epoch 275\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0025, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01566640267131052\n",
            "Total Loss: 0.018158655454407355\n",
            "----------------------------------------\n",
            "Epoch 276\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0025, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.015607074785664128\n",
            "Total Loss: 0.018081734161530475\n",
            "----------------------------------------\n",
            "Epoch 277\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0025, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.015547621893602977\n",
            "Total Loss: 0.018005530243443774\n",
            "----------------------------------------\n",
            "Epoch 278\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0024, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.015487230990531472\n",
            "Total Loss: 0.0179292081445324\n",
            "----------------------------------------\n",
            "Epoch 279\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0024, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.015427287658222091\n",
            "Total Loss: 0.017853792321986434\n",
            "----------------------------------------\n",
            "Epoch 280\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0024, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01536760420391518\n",
            "Total Loss: 0.017778809672208157\n",
            "----------------------------------------\n",
            "Epoch 281\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0024, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.015308459099116958\n",
            "Total Loss: 0.017704404121113328\n",
            "----------------------------------------\n",
            "Epoch 282\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0024, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.015250276115236725\n",
            "Total Loss: 0.01763059339209347\n",
            "----------------------------------------\n",
            "Epoch 283\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0024, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.015193321690135502\n",
            "Total Loss: 0.01755737640572743\n",
            "----------------------------------------\n",
            "Epoch 284\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0023, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.015136743200361411\n",
            "Total Loss: 0.017483938767576812\n",
            "----------------------------------------\n",
            "Epoch 285\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0023, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.015080667611956557\n",
            "Total Loss: 0.017410840560669733\n",
            "----------------------------------------\n",
            "Epoch 286\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0023, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01502552949640736\n",
            "Total Loss: 0.01733853166608225\n",
            "----------------------------------------\n",
            "Epoch 287\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0023, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.014971214468203955\n",
            "Total Loss: 0.01726711692459553\n",
            "----------------------------------------\n",
            "Epoch 288\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0023, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.014917728885808773\n",
            "Total Loss: 0.0171967384061476\n",
            "----------------------------------------\n",
            "Epoch 289\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0023, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.014864974895953615\n",
            "Total Loss: 0.017127401148070084\n",
            "----------------------------------------\n",
            "Epoch 290\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0022, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.014812929405840012\n",
            "Total Loss: 0.017059178342348366\n",
            "----------------------------------------\n",
            "Epoch 291\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0022, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.014761553891238871\n",
            "Total Loss: 0.01699205750239327\n",
            "----------------------------------------\n",
            "Epoch 292\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0022, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.014710933029798251\n",
            "Total Loss: 0.01692610732483349\n",
            "----------------------------------------\n",
            "Epoch 293\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0022, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.014660163468710645\n",
            "Total Loss: 0.01686054990706287\n",
            "----------------------------------------\n",
            "Epoch 294\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0022, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.014609713579640566\n",
            "Total Loss: 0.016795836263385256\n",
            "----------------------------------------\n",
            "Epoch 295\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0022, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.014559256523479194\n",
            "Total Loss: 0.016731499736605406\n",
            "----------------------------------------\n",
            "Epoch 296\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0022, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01450925147893104\n",
            "Total Loss: 0.01666812288545145\n",
            "----------------------------------------\n",
            "Epoch 297\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0021, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.014459986479688214\n",
            "Total Loss: 0.016606034968520058\n",
            "----------------------------------------\n",
            "Epoch 298\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0021, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.014411677021751501\n",
            "Total Loss: 0.016545120339537728\n",
            "----------------------------------------\n",
            "Epoch 299\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0021, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0143643255862036\n",
            "Total Loss: 0.016485328336790693\n",
            "----------------------------------------\n",
            "Epoch 300\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0021, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.014317984582538542\n",
            "Total Loss: 0.01642662337782829\n",
            "----------------------------------------\n",
            "Epoch 301\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0021, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.014272776528205891\n",
            "Total Loss: 0.016370411264957106\n",
            "----------------------------------------\n",
            "Epoch 302\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0021, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.014228596171495455\n",
            "Total Loss: 0.016315884701988803\n",
            "----------------------------------------\n",
            "Epoch 303\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0021, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.014185536854380445\n",
            "Total Loss: 0.016262224200974455\n",
            "----------------------------------------\n",
            "Epoch 304\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0021, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.014143389364598533\n",
            "Total Loss: 0.016209156617097088\n",
            "----------------------------------------\n",
            "Epoch 305\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0021, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.014100839192715632\n",
            "Total Loss: 0.016155559837564754\n",
            "----------------------------------------\n",
            "Epoch 306\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0020, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01405907939592662\n",
            "Total Loss: 0.016102600612398533\n",
            "----------------------------------------\n",
            "Epoch 307\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0020, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.014017389033422386\n",
            "Total Loss: 0.016049658403010855\n",
            "----------------------------------------\n",
            "Epoch 308\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0020, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.013976508974222356\n",
            "Total Loss: 0.01599749638750267\n",
            "----------------------------------------\n",
            "Epoch 309\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0020, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.013936488507242755\n",
            "Total Loss: 0.01594607210913511\n",
            "----------------------------------------\n",
            "Epoch 310\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0020, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01389706182312656\n",
            "Total Loss: 0.015895113603407503\n",
            "----------------------------------------\n",
            "Epoch 311\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0020, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01385820297259963\n",
            "Total Loss: 0.01584461875686296\n",
            "----------------------------------------\n",
            "Epoch 312\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0020, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.013820042583574622\n",
            "Total Loss: 0.01579418224299863\n",
            "----------------------------------------\n",
            "Epoch 313\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0020, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.013781868580235716\n",
            "Total Loss: 0.015739082978295422\n",
            "----------------------------------------\n",
            "Epoch 314\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0019, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.013743714714847224\n",
            "Total Loss: 0.015684889494911775\n",
            "----------------------------------------\n",
            "Epoch 315\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0019, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.013705960600942384\n",
            "Total Loss: 0.01563218925322161\n",
            "----------------------------------------\n",
            "Epoch 316\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0019, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01366906866846554\n",
            "Total Loss: 0.015580359476912343\n",
            "----------------------------------------\n",
            "Epoch 317\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0019, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.013632987925214973\n",
            "Total Loss: 0.01552928409351132\n",
            "----------------------------------------\n",
            "Epoch 318\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0019, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.013597654759257014\n",
            "Total Loss: 0.015479156169220137\n",
            "----------------------------------------\n",
            "Epoch 319\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0019, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.013563324461823368\n",
            "Total Loss: 0.015430011751761962\n",
            "----------------------------------------\n",
            "Epoch 320\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0019, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.013530031176526399\n",
            "Total Loss: 0.01538179754202133\n",
            "----------------------------------------\n",
            "Epoch 321\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0018, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.013497412321587552\n",
            "Total Loss: 0.015334562081527446\n",
            "----------------------------------------\n",
            "Epoch 322\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0018, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01346595744666856\n",
            "Total Loss: 0.015288130532821385\n",
            "----------------------------------------\n",
            "Epoch 323\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0018, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01343580864564062\n",
            "Total Loss: 0.015241448276479485\n",
            "----------------------------------------\n",
            "Epoch 324\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0018, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.013406743333551397\n",
            "Total Loss: 0.015194673748547691\n",
            "----------------------------------------\n",
            "Epoch 325\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0018, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.013378758765062566\n",
            "Total Loss: 0.015148105787285725\n",
            "----------------------------------------\n",
            "Epoch 326\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0018, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0133518117388026\n",
            "Total Loss: 0.015102099853344174\n",
            "----------------------------------------\n",
            "Epoch 327\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0017, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.013325508580353187\n",
            "Total Loss: 0.015056131538669814\n",
            "----------------------------------------\n",
            "Epoch 328\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0017, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01329968445278198\n",
            "Total Loss: 0.015011093640480384\n",
            "----------------------------------------\n",
            "Epoch 329\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0017, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.013273810293042112\n",
            "Total Loss: 0.014966616393705692\n",
            "----------------------------------------\n",
            "Epoch 330\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0017, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.013247751619926942\n",
            "Total Loss: 0.014922395814098259\n",
            "----------------------------------------\n",
            "Epoch 331\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0017, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.013221268192515628\n",
            "Total Loss: 0.014878617462769373\n",
            "----------------------------------------\n",
            "Epoch 332\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0016, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.013194779167202672\n",
            "Total Loss: 0.014835877322943761\n",
            "----------------------------------------\n",
            "Epoch 333\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0016, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.013167868183299267\n",
            "Total Loss: 0.014793619511045984\n",
            "----------------------------------------\n",
            "Epoch 334\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0016, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.013140468506047482\n",
            "Total Loss: 0.014751970568572075\n",
            "----------------------------------------\n",
            "Epoch 335\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0016, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.013112603282342393\n",
            "Total Loss: 0.014710532515684238\n",
            "----------------------------------------\n",
            "Epoch 336\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0016, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.013084253671228781\n",
            "Total Loss: 0.014669345544573591\n",
            "----------------------------------------\n",
            "Epoch 337\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0016, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.013055522334569108\n",
            "Total Loss: 0.014628493703008791\n",
            "----------------------------------------\n",
            "Epoch 338\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0016, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.013026503334947783\n",
            "Total Loss: 0.014587882639689612\n",
            "----------------------------------------\n",
            "Epoch 339\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0016, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.012997175958339083\n",
            "Total Loss: 0.014547378390913312\n",
            "----------------------------------------\n",
            "Epoch 340\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0015, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.012967607906276718\n",
            "Total Loss: 0.014507032976902735\n",
            "----------------------------------------\n",
            "Epoch 341\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0015, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.012937754531966269\n",
            "Total Loss: 0.014466788413198872\n",
            "----------------------------------------\n",
            "Epoch 342\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0015, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.012907709649465098\n",
            "Total Loss: 0.014426706490029749\n",
            "----------------------------------------\n",
            "Epoch 343\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0015, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.012877498648194588\n",
            "Total Loss: 0.014386827992462384\n",
            "----------------------------------------\n",
            "Epoch 344\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0015, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01284697222611054\n",
            "Total Loss: 0.01434716006240137\n",
            "----------------------------------------\n",
            "Epoch 345\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0015, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.012816296864018951\n",
            "Total Loss: 0.01430781992263811\n",
            "----------------------------------------\n",
            "Epoch 346\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0015, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.012785455044130001\n",
            "Total Loss: 0.014268769255434797\n",
            "----------------------------------------\n",
            "Epoch 347\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0015, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01275466937448788\n",
            "Total Loss: 0.014230427835662392\n",
            "----------------------------------------\n",
            "Epoch 348\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0015, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01272386057427073\n",
            "Total Loss: 0.014192282285628627\n",
            "----------------------------------------\n",
            "Epoch 349\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0015, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.012693075072098577\n",
            "Total Loss: 0.014154317742226082\n",
            "----------------------------------------\n",
            "Epoch 350\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0015, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.012662313956739056\n",
            "Total Loss: 0.014116758081170171\n",
            "----------------------------------------\n",
            "Epoch 351\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0014, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.012631611975250211\n",
            "Total Loss: 0.014079435005175242\n",
            "----------------------------------------\n",
            "Epoch 352\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0014, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.012600996539004447\n",
            "Total Loss: 0.0140422829304435\n",
            "----------------------------------------\n",
            "Epoch 353\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0014, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.012570510978598298\n",
            "Total Loss: 0.014005361567561428\n",
            "----------------------------------------\n",
            "Epoch 354\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0014, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.012540485268450606\n",
            "Total Loss: 0.013968855096648714\n",
            "----------------------------------------\n",
            "Epoch 355\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0014, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.012510684582464305\n",
            "Total Loss: 0.013932627564666256\n",
            "----------------------------------------\n",
            "Epoch 356\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0014, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.012481272613844751\n",
            "Total Loss: 0.013896590634273719\n",
            "----------------------------------------\n",
            "Epoch 357\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0014, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.012452395732561817\n",
            "Total Loss: 0.013860597202473299\n",
            "----------------------------------------\n",
            "Epoch 358\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0014, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.012423903230786544\n",
            "Total Loss: 0.01382440852589769\n",
            "----------------------------------------\n",
            "Epoch 359\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0014, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.012395723483219545\n",
            "Total Loss: 0.013788363875771065\n",
            "----------------------------------------\n",
            "Epoch 360\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0014, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.012367738424458104\n",
            "Total Loss: 0.013752669655476195\n",
            "----------------------------------------\n",
            "Epoch 361\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0014, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01233999094775701\n",
            "Total Loss: 0.01371722188191847\n",
            "----------------------------------------\n",
            "Epoch 362\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0014, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.012312437957550833\n",
            "Total Loss: 0.013682006135360596\n",
            "----------------------------------------\n",
            "Epoch 363\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0014, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01228530539697904\n",
            "Total Loss: 0.013646954179935845\n",
            "----------------------------------------\n",
            "Epoch 364\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0014, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.012258405203217098\n",
            "Total Loss: 0.013612337742825891\n",
            "----------------------------------------\n",
            "Epoch 365\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.012231501427255298\n",
            "Total Loss: 0.013577918342146741\n",
            "----------------------------------------\n",
            "Epoch 366\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.012204582195591538\n",
            "Total Loss: 0.013543676467779176\n",
            "----------------------------------------\n",
            "Epoch 367\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01217757447942272\n",
            "Total Loss: 0.013509572277656642\n",
            "----------------------------------------\n",
            "Epoch 368\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.012150531492183718\n",
            "Total Loss: 0.013475625029118653\n",
            "----------------------------------------\n",
            "Epoch 369\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.012123460987987581\n",
            "Total Loss: 0.013441829698589609\n",
            "----------------------------------------\n",
            "Epoch 370\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.012096275273668994\n",
            "Total Loss: 0.013408126470013807\n",
            "----------------------------------------\n",
            "Epoch 371\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.012068974675151242\n",
            "Total Loss: 0.013374532686840596\n",
            "----------------------------------------\n",
            "Epoch 372\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.012041606225228594\n",
            "Total Loss: 0.013341144832047784\n",
            "----------------------------------------\n",
            "Epoch 373\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.012014199889085026\n",
            "Total Loss: 0.01330799977379832\n",
            "----------------------------------------\n",
            "Epoch 374\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011986743504416577\n",
            "Total Loss: 0.013275016698342045\n",
            "----------------------------------------\n",
            "Epoch 375\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011959285422162872\n",
            "Total Loss: 0.013242194373619058\n",
            "----------------------------------------\n",
            "Epoch 376\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011931816283271566\n",
            "Total Loss: 0.01320952869878826\n",
            "----------------------------------------\n",
            "Epoch 377\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011904662252475747\n",
            "Total Loss: 0.013177008843366863\n",
            "----------------------------------------\n",
            "Epoch 378\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011877940898688719\n",
            "Total Loss: 0.013144846448690132\n",
            "----------------------------------------\n",
            "Epoch 379\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011851199334472236\n",
            "Total Loss: 0.013112962907155424\n",
            "----------------------------------------\n",
            "Epoch 380\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011823986492561273\n",
            "Total Loss: 0.013081691957077493\n",
            "----------------------------------------\n",
            "Epoch 381\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011796846657892419\n",
            "Total Loss: 0.013051013084845017\n",
            "----------------------------------------\n",
            "Epoch 382\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011769856452405976\n",
            "Total Loss: 0.013020551621091161\n",
            "----------------------------------------\n",
            "Epoch 383\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011743056221764083\n",
            "Total Loss: 0.01299026641784676\n",
            "----------------------------------------\n",
            "Epoch 384\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011716410965408361\n",
            "Total Loss: 0.012959242942834692\n",
            "----------------------------------------\n",
            "Epoch 385\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01169017333765334\n",
            "Total Loss: 0.01292775124462878\n",
            "----------------------------------------\n",
            "Epoch 386\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011664309772773747\n",
            "Total Loss: 0.01289599546616143\n",
            "----------------------------------------\n",
            "Epoch 387\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011639092577163177\n",
            "Total Loss: 0.012864081806451372\n",
            "----------------------------------------\n",
            "Epoch 388\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011614369392768706\n",
            "Total Loss: 0.012832276317667781\n",
            "----------------------------------------\n",
            "Epoch 389\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01158991205748415\n",
            "Total Loss: 0.012800142380512147\n",
            "----------------------------------------\n",
            "Epoch 390\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011565818311689466\n",
            "Total Loss: 0.012768154805955313\n",
            "----------------------------------------\n",
            "Epoch 391\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011542059868699247\n",
            "Total Loss: 0.012736422189531844\n",
            "----------------------------------------\n",
            "Epoch 392\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011518406227765541\n",
            "Total Loss: 0.012704843621976434\n",
            "----------------------------------------\n",
            "Epoch 393\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011494931251481315\n",
            "Total Loss: 0.012673536653881538\n",
            "----------------------------------------\n",
            "Epoch 394\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011471535714226605\n",
            "Total Loss: 0.012642521812917524\n",
            "----------------------------------------\n",
            "Epoch 395\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011448162140666738\n",
            "Total Loss: 0.012611759181809139\n",
            "----------------------------------------\n",
            "Epoch 396\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011424913239434389\n",
            "Total Loss: 0.012581235507063533\n",
            "----------------------------------------\n",
            "Epoch 397\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011401448684713817\n",
            "Total Loss: 0.012550998149158056\n",
            "----------------------------------------\n",
            "Epoch 398\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011377693508145844\n",
            "Total Loss: 0.012521060666298076\n",
            "----------------------------------------\n",
            "Epoch 399\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01135385778084957\n",
            "Total Loss: 0.012491427897485731\n",
            "----------------------------------------\n",
            "Epoch 400\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011329827773329547\n",
            "Total Loss: 0.012461984518914717\n",
            "----------------------------------------\n",
            "Epoch 401\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01130534698166462\n",
            "Total Loss: 0.012432806133330388\n",
            "----------------------------------------\n",
            "Epoch 402\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01128043880969346\n",
            "Total Loss: 0.012403783475608011\n",
            "----------------------------------------\n",
            "Epoch 403\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011255169821848385\n",
            "Total Loss: 0.012374819853758863\n",
            "----------------------------------------\n",
            "Epoch 404\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01122957482882288\n",
            "Total Loss: 0.012346019234484624\n",
            "----------------------------------------\n",
            "Epoch 405\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011204017483577753\n",
            "Total Loss: 0.012317440376267136\n",
            "----------------------------------------\n",
            "Epoch 406\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011178481463351415\n",
            "Total Loss: 0.012289024469376162\n",
            "----------------------------------------\n",
            "Epoch 407\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011153033079289878\n",
            "Total Loss: 0.012260810171296065\n",
            "----------------------------------------\n",
            "Epoch 408\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011127739488928225\n",
            "Total Loss: 0.012232817268468447\n",
            "----------------------------------------\n",
            "Epoch 409\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01110259771021934\n",
            "Total Loss: 0.012205046847279126\n",
            "----------------------------------------\n",
            "Epoch 410\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011077460353234352\n",
            "Total Loss: 0.012177492898809034\n",
            "----------------------------------------\n",
            "Epoch 411\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011052287598395796\n",
            "Total Loss: 0.012150059325957713\n",
            "----------------------------------------\n",
            "Epoch 412\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.011027141155823364\n",
            "Total Loss: 0.012122855596200873\n",
            "----------------------------------------\n",
            "Epoch 413\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01100232204123735\n",
            "Total Loss: 0.012095848713055003\n",
            "----------------------------------------\n",
            "Epoch 414\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.010977850517116005\n",
            "Total Loss: 0.012069013487277989\n",
            "----------------------------------------\n",
            "Epoch 415\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.010953674665775556\n",
            "Total Loss: 0.012042298587869864\n",
            "----------------------------------------\n",
            "Epoch 416\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.010929653859034367\n",
            "Total Loss: 0.012015569620312022\n",
            "----------------------------------------\n",
            "Epoch 417\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.010905884712443739\n",
            "Total Loss: 0.01198894367822571\n",
            "----------------------------------------\n",
            "Epoch 418\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01088234677124341\n",
            "Total Loss: 0.01196245778965117\n",
            "----------------------------------------\n",
            "Epoch 419\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01085899738691578\n",
            "Total Loss: 0.011936171091037322\n",
            "----------------------------------------\n",
            "Epoch 420\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.010835588471733404\n",
            "Total Loss: 0.011909955088310603\n",
            "----------------------------------------\n",
            "Epoch 421\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.010812308810601606\n",
            "Total Loss: 0.011883840467110383\n",
            "----------------------------------------\n",
            "Epoch 422\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.010789135640304455\n",
            "Total Loss: 0.01185790274639682\n",
            "----------------------------------------\n",
            "Epoch 423\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.010766345329514738\n",
            "Total Loss: 0.011832113226223337\n",
            "----------------------------------------\n",
            "Epoch 424\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.010743915165472602\n",
            "Total Loss: 0.011806435408104169\n",
            "----------------------------------------\n",
            "Epoch 425\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.010721821895844915\n",
            "Total Loss: 0.011780869826605428\n",
            "----------------------------------------\n",
            "Epoch 426\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.010700050639059936\n",
            "Total Loss: 0.01175543383790537\n",
            "----------------------------------------\n",
            "Epoch 427\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01067855135604503\n",
            "Total Loss: 0.011730138668482918\n",
            "----------------------------------------\n",
            "Epoch 428\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0106572906370163\n",
            "Total Loss: 0.011704986650641354\n",
            "----------------------------------------\n",
            "Epoch 429\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.010636204786404962\n",
            "Total Loss: 0.011679958821229946\n",
            "----------------------------------------\n",
            "Epoch 430\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.010615237163769265\n",
            "Total Loss: 0.011655141096556153\n",
            "----------------------------------------\n",
            "Epoch 431\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01059419630851281\n",
            "Total Loss: 0.011630404749818612\n",
            "----------------------------------------\n",
            "Epoch 432\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.010573073001661746\n",
            "Total Loss: 0.011605739532697026\n",
            "----------------------------------------\n",
            "Epoch 433\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.010551732110608792\n",
            "Total Loss: 0.0115812420992525\n",
            "----------------------------------------\n",
            "Epoch 434\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0105303943459808\n",
            "Total Loss: 0.01155686720595112\n",
            "----------------------------------------\n",
            "Epoch 435\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.010509108231177051\n",
            "Total Loss: 0.01153261360301475\n",
            "----------------------------------------\n",
            "Epoch 436\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.010487896407295801\n",
            "Total Loss: 0.011508483183078892\n",
            "----------------------------------------\n",
            "Epoch 437\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.010466741284131751\n",
            "Total Loss: 0.011484461500892218\n",
            "----------------------------------------\n",
            "Epoch 438\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.010445653245279287\n",
            "Total Loss: 0.011460585653632132\n",
            "----------------------------------------\n",
            "Epoch 439\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.010424731814641099\n",
            "Total Loss: 0.011436818226847677\n",
            "----------------------------------------\n",
            "Epoch 440\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.010403958120132416\n",
            "Total Loss: 0.011413184630641537\n",
            "----------------------------------------\n",
            "Epoch 441\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.010383312389055785\n",
            "Total Loss: 0.011389690408155316\n",
            "----------------------------------------\n",
            "Epoch 442\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01036273848351008\n",
            "Total Loss: 0.011366359198235582\n",
            "----------------------------------------\n",
            "Epoch 443\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.010342027083731007\n",
            "Total Loss: 0.011343104754540884\n",
            "----------------------------------------\n",
            "Epoch 444\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.010321154937410978\n",
            "Total Loss: 0.011319858081495512\n",
            "----------------------------------------\n",
            "Epoch 445\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01030021953321073\n",
            "Total Loss: 0.011296753156532469\n",
            "----------------------------------------\n",
            "Epoch 446\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.010279596563393122\n",
            "Total Loss: 0.01127390600513741\n",
            "----------------------------------------\n",
            "Epoch 447\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.010259178708811871\n",
            "Total Loss: 0.011251178356535399\n",
            "----------------------------------------\n",
            "Epoch 448\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.010238948153859024\n",
            "Total Loss: 0.0112285506994394\n",
            "----------------------------------------\n",
            "Epoch 449\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.010218909319295833\n",
            "Total Loss: 0.01120602087287221\n",
            "----------------------------------------\n",
            "Epoch 450\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.010199062083159582\n",
            "Total Loss: 0.011183625165472444\n",
            "----------------------------------------\n",
            "Epoch 451\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.010179397216587298\n",
            "Total Loss: 0.011161477543956765\n",
            "----------------------------------------\n",
            "Epoch 452\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.010159719556116938\n",
            "Total Loss: 0.01113944707101371\n",
            "----------------------------------------\n",
            "Epoch 453\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.010139993320354968\n",
            "Total Loss: 0.011117540239197738\n",
            "----------------------------------------\n",
            "Epoch 454\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.010120006572856994\n",
            "Total Loss: 0.011095747545877784\n",
            "----------------------------------------\n",
            "Epoch 455\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.010099896294682734\n",
            "Total Loss: 0.011074076146409857\n",
            "----------------------------------------\n",
            "Epoch 456\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.01008001521113971\n",
            "Total Loss: 0.011052568534088208\n",
            "----------------------------------------\n",
            "Epoch 457\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.010060389050999657\n",
            "Total Loss: 0.011031183627185047\n",
            "----------------------------------------\n",
            "Epoch 458\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.010041020943245837\n",
            "Total Loss: 0.011009926332953288\n",
            "----------------------------------------\n",
            "Epoch 459\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.010022064097141197\n",
            "Total Loss: 0.010988993157613513\n",
            "----------------------------------------\n",
            "Epoch 460\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.010003350770303277\n",
            "Total Loss: 0.010968259470368337\n",
            "----------------------------------------\n",
            "Epoch 461\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.009984756320472516\n",
            "Total Loss: 0.01094759985376113\n",
            "----------------------------------------\n",
            "Epoch 462\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.009966497954186509\n",
            "Total Loss: 0.010927076252446625\n",
            "----------------------------------------\n",
            "Epoch 463\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.009948605467880931\n",
            "Total Loss: 0.010906715255458868\n",
            "----------------------------------------\n",
            "Epoch 464\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.009930861047459332\n",
            "Total Loss: 0.010886525408780153\n",
            "----------------------------------------\n",
            "Epoch 465\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.009913248494871803\n",
            "Total Loss: 0.010866546193217063\n",
            "----------------------------------------\n",
            "Epoch 466\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.009895904326736753\n",
            "Total Loss: 0.010846713652939582\n",
            "----------------------------------------\n",
            "Epoch 467\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.009878784969667383\n",
            "Total Loss: 0.010827016695189883\n",
            "----------------------------------------\n",
            "Epoch 468\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.009861680593892384\n",
            "Total Loss: 0.010807443899384653\n",
            "----------------------------------------\n",
            "Epoch 469\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.009844601984300073\n",
            "Total Loss: 0.010787991476690186\n",
            "----------------------------------------\n",
            "Epoch 470\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.009827742969691317\n",
            "Total Loss: 0.010768676117236736\n",
            "----------------------------------------\n",
            "Epoch 471\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.009810942592068167\n",
            "Total Loss: 0.010749521476914697\n",
            "----------------------------------------\n",
            "Epoch 472\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.009794447669184648\n",
            "Total Loss: 0.010730554910122005\n",
            "----------------------------------------\n",
            "Epoch 473\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.009778075265874169\n",
            "Total Loss: 0.010711719086623862\n",
            "----------------------------------------\n",
            "Epoch 474\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.009761879679208461\n",
            "Total Loss: 0.01069256092389754\n",
            "----------------------------------------\n",
            "Epoch 475\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.009745821293895845\n",
            "Total Loss: 0.01067308523085006\n",
            "----------------------------------------\n",
            "Epoch 476\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.009730000672963616\n",
            "Total Loss: 0.010653700572217676\n",
            "----------------------------------------\n",
            "Epoch 477\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0097143420210323\n",
            "Total Loss: 0.01063453087466818\n",
            "----------------------------------------\n",
            "Epoch 478\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.009698759319642819\n",
            "Total Loss: 0.010615669185357593\n",
            "----------------------------------------\n",
            "Epoch 479\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.009683043365104263\n",
            "Total Loss: 0.010597088225397547\n",
            "----------------------------------------\n",
            "Epoch 480\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.009667064231471628\n",
            "Total Loss: 0.010578653667338804\n",
            "----------------------------------------\n",
            "Epoch 481\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0096507700749507\n",
            "Total Loss: 0.010560259066505468\n",
            "----------------------------------------\n",
            "Epoch 482\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.009634180277891572\n",
            "Total Loss: 0.010541858499338502\n",
            "----------------------------------------\n",
            "Epoch 483\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.00961735488760195\n",
            "Total Loss: 0.010523458883764858\n",
            "----------------------------------------\n",
            "Epoch 484\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.00960050371994839\n",
            "Total Loss: 0.010505186878169133\n",
            "----------------------------------------\n",
            "Epoch 485\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.009583789153161732\n",
            "Total Loss: 0.010487008069389313\n",
            "----------------------------------------\n",
            "Epoch 486\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.009567250206023049\n",
            "Total Loss: 0.010468903122116355\n",
            "----------------------------------------\n",
            "Epoch 487\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.00955098757012509\n",
            "Total Loss: 0.010450911039419898\n",
            "----------------------------------------\n",
            "Epoch 488\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.009534629895196841\n",
            "Total Loss: 0.01043270247160051\n",
            "----------------------------------------\n",
            "Epoch 489\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.009518495301074294\n",
            "Total Loss: 0.010414355696120958\n",
            "----------------------------------------\n",
            "Epoch 490\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.009502632210104084\n",
            "Total Loss: 0.010395913604832142\n",
            "----------------------------------------\n",
            "Epoch 491\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.009487057552706202\n",
            "Total Loss: 0.010377588656766945\n",
            "----------------------------------------\n",
            "Epoch 492\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.009471593583673148\n",
            "Total Loss: 0.010359335605952553\n",
            "----------------------------------------\n",
            "Epoch 493\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.009456216454963402\n",
            "Total Loss: 0.01034115458944453\n",
            "----------------------------------------\n",
            "Epoch 494\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.009440955120373693\n",
            "Total Loss: 0.010323079641238086\n",
            "----------------------------------------\n",
            "Epoch 495\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.009425734958546575\n",
            "Total Loss: 0.010305081462771253\n",
            "----------------------------------------\n",
            "Epoch 496\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.009410560487990202\n",
            "Total Loss: 0.010287194298345797\n",
            "----------------------------------------\n",
            "Epoch 497\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.009395525198409048\n",
            "Total Loss: 0.010269394998405361\n",
            "----------------------------------------\n",
            "Epoch 498\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.009380567875073924\n",
            "Total Loss: 0.01025166704965922\n",
            "----------------------------------------\n",
            "Epoch 499\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.009365703207995454\n",
            "Total Loss: 0.010234046163818783\n",
            "----------------------------------------\n",
            "Epoch 500\n",
            "IS variance:  tensor(4.4092e-11, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.009350940396313259\n",
            "Total Loss: 0.01021654645715603\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[-0.0186, -0.1972],\n",
            "        [-0.3706, -0.3068],\n",
            "        [ 0.2751,  0.1081],\n",
            "        [-0.5364, -0.5308],\n",
            "        [ 0.2213,  0.3552],\n",
            "        [ 0.4289, -0.5128],\n",
            "        [-0.3092, -0.5198],\n",
            "        [-0.6256,  0.5239],\n",
            "        [-0.3738, -0.4623],\n",
            "        [-0.3052, -0.0055],\n",
            "        [ 0.2603,  0.0117],\n",
            "        [-0.7439,  0.4636],\n",
            "        [ 0.1646,  0.0771],\n",
            "        [ 0.0946, -0.1665],\n",
            "        [-0.0081,  0.1858],\n",
            "        [-0.2221, -0.4742]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([-0.0533, -0.3120, -0.7187, -0.5761,  0.2779,  0.3973, -0.2647, -0.4171,\n",
            "        -0.5832, -0.2371, -0.2243, -0.5920, -0.5850,  0.5120,  0.3300, -0.4199],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[-0.1177,  0.0552, -0.2745, -0.1992,  0.1423,  0.0961, -0.1609, -0.0457,\n",
            "         -0.1216,  0.1443, -0.1822,  0.1093,  0.0511, -0.0117, -0.1981, -0.0437],\n",
            "        [ 0.1405,  0.0375, -0.1717, -0.0944, -0.1968, -0.1396,  0.0098, -0.0300,\n",
            "         -0.0414, -0.0584, -0.0884, -0.0543,  0.1135, -0.1216, -0.0309, -0.1156],\n",
            "        [-0.1156, -0.2106, -0.1480, -0.1215, -0.0610,  0.0407,  0.1165,  0.0117,\n",
            "          0.0276,  0.0368, -0.2178, -0.0089,  0.1860,  0.2664,  0.0288,  0.0711],\n",
            "        [ 0.0458,  0.2251,  0.2779, -0.0038, -0.2295,  0.0824, -0.0106,  0.0183,\n",
            "         -0.0628, -0.0223, -0.3327,  0.0642, -0.0504,  0.0935, -0.2593, -0.1720],\n",
            "        [-0.0031, -0.2483,  0.1123,  0.1643, -0.0140, -0.0593,  0.0911, -0.1093,\n",
            "          0.1842, -0.2327,  0.1611,  0.1282, -0.1679,  0.0528,  0.1971, -0.2459],\n",
            "        [-0.2132,  0.2441,  0.4509, -0.1061,  0.0307, -0.3210,  0.2160,  0.1631,\n",
            "          0.0179, -0.1739,  0.1290, -0.0996, -0.1300, -0.2949,  0.2493, -0.0475],\n",
            "        [ 0.2275, -0.1066, -0.5028,  0.1472,  0.1261, -0.1080, -0.1157, -0.0163,\n",
            "          0.0511,  0.2034, -0.0849,  0.0721, -0.1762, -0.1261,  0.1521,  0.2126],\n",
            "        [ 0.0831,  0.1702, -0.1650,  0.2022, -0.0474, -0.1346,  0.1440,  0.0190,\n",
            "         -0.0738,  0.0414, -0.0146, -0.1236, -0.4238,  0.1959, -0.0404, -0.2164],\n",
            "        [ 0.2111, -0.0143, -0.1892,  0.0009, -0.2418,  0.1937, -0.0071, -0.1693,\n",
            "         -0.1809,  0.2044, -0.1419, -0.2157,  0.1146,  0.1251, -0.1787, -0.0017],\n",
            "        [ 0.1093, -0.1100, -0.1713, -0.1925,  0.0480,  0.1909,  0.0990, -0.0854,\n",
            "          0.0691,  0.2447, -0.0030,  0.1170, -0.0011,  0.0178,  0.1488,  0.0439],\n",
            "        [-0.1150, -0.0344, -0.2067,  0.0541, -0.1238,  0.2437,  0.0160,  0.0390,\n",
            "         -0.0168,  0.2171, -0.1809,  0.1055, -0.1627,  0.1798,  0.0395,  0.1476],\n",
            "        [ 0.0539, -0.2007, -0.0718, -0.2019,  0.1162,  0.0344,  0.2311,  0.0403,\n",
            "          0.0942, -0.1031,  0.1650, -0.0881, -0.1250, -0.1125,  0.0571, -0.2097],\n",
            "        [ 0.0199,  0.1871,  0.1457,  0.2301, -0.0352,  0.1512,  0.0172, -0.2027,\n",
            "         -0.2080, -0.2113,  0.0072,  0.0773, -0.1488, -0.0041,  0.0402,  0.1663],\n",
            "        [ 0.0864,  0.1208,  0.0769, -0.1497, -0.0844, -0.3141,  0.1436, -0.0325,\n",
            "          0.1342,  0.1814,  0.0277, -0.1441, -0.2540, -0.0291,  0.0316,  0.0246],\n",
            "        [ 0.0765,  0.0677, -0.1492, -0.0259,  0.1809,  0.0167,  0.2338, -0.0056,\n",
            "          0.0088, -0.0649, -0.1796, -0.1616, -0.0874,  0.1306, -0.0031,  0.0133],\n",
            "        [-0.2097,  0.1283,  0.2576, -0.0258, -0.0257,  0.0645,  0.0710,  0.1343,\n",
            "         -0.1164, -0.1588, -0.0194, -0.1565,  0.2038, -0.1204, -0.2051, -0.0748]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([ 0.0563, -0.1365,  0.4128, -0.1557, -0.2748, -0.1153,  0.0699,  0.4607,\n",
            "        -0.0208,  0.0074,  0.1967,  0.1786, -0.0784, -0.0171, -0.0900,  0.1305],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[ 0.1444, -0.2177,  0.1513, -0.3088, -0.2583, -0.0259,  0.0883,  0.3571,\n",
            "         -0.2419,  0.0796,  0.1273,  0.0099,  0.1786, -0.1827,  0.0104, -0.1571]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([0.2638], dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomizableFeatureNet(\n",
              "  (hidden_layers): ModuleList(\n",
              "    (0): Linear(in_features=2, out_features=16, bias=True)\n",
              "    (1): Linear(in_features=16, out_features=16, bias=True)\n",
              "  )\n",
              "  (output_layer): Linear(in_features=16, out_features=1, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_400_random_pi_b.get_heatmap()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "7fe7ebf3-e6db-480b-c29e-ce0af762563e",
        "id": "KHFBY772CntQ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"f226683d-5e5c-4015-8dcd-75c6386ecb0e\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"f226683d-5e5c-4015-8dcd-75c6386ecb0e\")) {                    Plotly.newPlot(                        \"f226683d-5e5c-4015-8dcd-75c6386ecb0e\",                        [{\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"z\":[[0.5910281195652765,0.599944144285047,0.6013064210361019,0.5897657549049931,0.5360130654784725,0.4585975197533225,0.4383518386132964,0.42414605123639765,0.4132574754565863,0.402368899676775],[0.5673928269701577,0.5766625209428555,0.5694647762396494,0.5292376775694243,0.45458847955645065,0.3877638766574545,0.37618849311104685,0.3652999173312355,0.35441134155142423,0.34199716963240345],[0.5401064339373612,0.5491106998762553,0.5279206696226268,0.45315791936725625,0.3756607431251288,0.3285945288230362,0.3211070539161256,0.3097391439189039,0.2983712339216822,0.28700332392446043],[0.5114085085743607,0.5194862940789842,0.47969578678444985,0.4042953231808297,0.31630134818377675,0.28318154172656357,0.27200808760263717,0.26126634464002574,0.2505340265773957,0.23980170851476568],[0.5026906739231902,0.49735751027161945,0.42958678370511916,0.35299454254540236,0.2598939640081788,0.23143978388134448,0.2202663297574181,0.2099866975368489,0.20498089792841823,0.19997509831998758],[0.49571373276349195,0.46789607863520066,0.38490624481142877,0.3023745946704749,0.22989118391852087,0.19220222682241828,0.17631757772706677,0.1711284189707795,0.16612261936234887,0.16111681975391817],[0.48874387924549245,0.42952717940147356,0.3410282688257626,0.27157922538468576,0.21639250510209646,0.18246370649773583,0.15109720385415643,0.1322701404047102,0.12726434079627952,0.12225854118784885],[0.47666887098828253,0.3989803874635753,0.32726129770871554,0.2639738220305926,0.2051932797994397,0.17450452426900348,0.1424071560721632,0.11004316506465711,0.08840606223021014,0.08340026262177946],[0.4684860715641469,0.3913241265376082,0.31973107697679903,0.25474197895552736,0.19642660475192245,0.16511281714854953,0.13481077147056084,0.10235060564659051,0.07012050775057105,0.04454198405571019],[0.46153839104589073,0.38276988981808513,0.311365787698716,0.24551013588046203,0.18998586706038895,0.1557211100280957,0.125419064350107,0.09482862891751437,0.06229405522101794,0.030306353519190893]],\"type\":\"heatmap\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"Values\"},\"ticks\":\"outside\",\"tickvals\":[0.030306353519190893,0.6013064210361019],\"ticktext\":[0.030306353519190893,0.6013064210361019]}},\"xaxis\":{\"tickvals\":[0,1,2,3,4,5,6,7,8,9],\"ticktext\":[0,1,2,3,4,5,6,7,8,9],\"title\":{\"text\":\"X\"}},\"yaxis\":{\"tickvals\":[9,8,7,6,5,4,3,2,1,0],\"ticktext\":[9,8,7,6,5,4,3,2,1,0],\"title\":{\"text\":\"Y\"},\"autorange\":\"reversed\"},\"title\":{\"text\":\"Heatmap\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('f226683d-5e5c-4015-8dcd-75c6386ecb0e');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calc_V_pi_e(pi_e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5825b5e-ac9d-45a0-cc7d-531201d224cc",
        "id": "NGrNE464EYE7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.15634452293280188"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_400_random_pi_b.evaluate_scope()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1274a4f7-03e3-48e5-929a-1e6ad27b28c2",
        "id": "xe06MjZgEYE9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1504, dtype=torch.float64, grad_fn=<MeanBackward0>),\n",
              " tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test 600 pi_b top 2"
      ],
      "metadata": {
        "id": "ULn4Hoyu85kB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b = action_probs_top_n_epsilon(q_table, 1, 0.4)\n",
        "pi_b = experiment_actions(600, env_50, P_pi_b)\n",
        "P_pi_e = action_probs_top_n_epsilon(q_table, 1, 0.05)\n",
        "pi_e = experiment_actions(1000, env_50, P_pi_e)\n",
        "model_600_random_pi_b = CustomizableFeatureNet(input_dim=2, hidden_dims=[16, 16], output_dim=1, dtype = torch.float64)\n",
        "test_600_random_pi_b = SCOPE_straight(model_600_random_pi_b, 0.99, 10000, pi_b, P_pi_b, P_pi_e, 0.3, dtype = torch.float64)\n"
      ],
      "metadata": {
        "id": "FIfZx1bS8-7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_600_random_pi_b.IS_pipeline()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "986bd42a-2ae3-46d3-c6e8-8e7017817eeb",
        "id": "IwDciHMj8-7H"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(24.2014, dtype=torch.float64), tensor(134.2654, dtype=torch.float64))"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_600_random_pi_b.get_state_visitation_heatmap()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "f12e95aa-75e3-44ea-8f9b-6a31de00b563",
        "id": "o0IMnlZV8-7I"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"e1e46cec-4570-4dec-aa7f-987a12b3db14\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e1e46cec-4570-4dec-aa7f-987a12b3db14\")) {                    Plotly.newPlot(                        \"e1e46cec-4570-4dec-aa7f-987a12b3db14\",                        [{\"colorbar\":{\"title\":{\"text\":\"Visits\"}},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"x\":[0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9],\"y\":[9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0],\"z\":[0,3,34,290,636,1312,1441,875,730,505,0,11,81,560,559,0,1345,678,619,546,0,104,238,458,158,0,980,523,602,1011,0,181,211,110,50,0,535,268,246,245,0,176,74,41,16,0,167,113,103,69,27,115,33,13,4,0,33,21,40,16,7,22,7,1,0,0,34,18,44,19,1,1,2,0,0,0,32,19,32,10,0,0,1,0,0,0,39,18,34,12,0,0,1,0,0,0,23,13,23,9],\"zmax\":1441,\"zmin\":0,\"type\":\"heatmap\"}],                        {\"title\":{\"text\":\"State Visitations Heatmap\"},\"xaxis\":{\"title\":{\"text\":\"X-axis\"}},\"yaxis\":{\"ticktext\":[9,8,7,6,5,4,3,2,1,0],\"tickvals\":[0,1,2,3,4,5,6,7,8,9],\"title\":{\"text\":\"Y-axis\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('e1e46cec-4570-4dec-aa7f-987a12b3db14');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_600_random_pi_b.train_var_scope(300, 0.001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b7d380d-2e99-42dc-e32b-c2a97d5a707c",
        "id": "AMPHu0qv8-7I"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0033, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.008124469012146312\n",
            "SCOPE mean: 0.11593467505750471, SCOPE var: 0.001134831577478478\n",
            "Total Loss: 0.011470035771407587\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.007877572700959606\n",
            "SCOPE mean: 0.11402489523061764, SCOPE var: 0.0011566205224887104\n",
            "Total Loss: 0.008660720224668825\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.007835659068336106\n",
            "SCOPE mean: 0.1149561133499077, SCOPE var: 0.0011602695166762504\n",
            "Total Loss: 0.00864455892775779\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.00781327248599228\n",
            "SCOPE mean: 0.11650521160052017, SCOPE var: 0.0011712368107998686\n",
            "Total Loss: 0.008583540773734768\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0078068080769548446\n",
            "SCOPE mean: 0.11759279905746084, SCOPE var: 0.0011825409781654355\n",
            "Total Loss: 0.008531025569341417\n",
            "----------------------------------------\n",
            "Epoch 6\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.007791067258056491\n",
            "SCOPE mean: 0.11760819029879795, SCOPE var: 0.0011810892179655761\n",
            "Total Loss: 0.008478166583153212\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.007759666876520431\n",
            "SCOPE mean: 0.1167941805196363, SCOPE var: 0.001169221054552784\n",
            "Total Loss: 0.008426775877720725\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.007720853759773746\n",
            "SCOPE mean: 0.11554456402355345, SCOPE var: 0.0011515404422226723\n",
            "Total Loss: 0.008380442428119106\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.007685676797457618\n",
            "SCOPE mean: 0.11439950873663551, SCOPE var: 0.0011334282661550077\n",
            "Total Loss: 0.008343843102122234\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.007654656082694976\n",
            "SCOPE mean: 0.1137352611986255, SCOPE var: 0.00111973395523087\n",
            "Total Loss: 0.008311895460945466\n",
            "----------------------------------------\n",
            "Epoch 11\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.007621772533953928\n",
            "SCOPE mean: 0.11376316733497333, SCOPE var: 0.001114400997632692\n",
            "Total Loss: 0.008276496085522077\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.007581544521994147\n",
            "SCOPE mean: 0.11433983495483414, SCOPE var: 0.0011107866166693988\n",
            "Total Loss: 0.008231125590912528\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.007537190824361304\n",
            "SCOPE mean: 0.11547220007788513, SCOPE var: 0.0011167260258329187\n",
            "Total Loss: 0.008180392271472785\n",
            "----------------------------------------\n",
            "Epoch 14\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.007494550625655385\n",
            "SCOPE mean: 0.11685044743846941, SCOPE var: 0.0011270066856737169\n",
            "Total Loss: 0.008131781030619432\n",
            "----------------------------------------\n",
            "Epoch 15\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.007457007972904669\n",
            "SCOPE mean: 0.11819452338256144, SCOPE var: 0.0011382730053276177\n",
            "Total Loss: 0.008089482373256043\n",
            "----------------------------------------\n",
            "Epoch 16\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.007423345814965873\n",
            "SCOPE mean: 0.11929874128056028, SCOPE var: 0.0011475993952037465\n",
            "Total Loss: 0.008052844225362146\n",
            "----------------------------------------\n",
            "Epoch 17\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.007389553345662418\n",
            "SCOPE mean: 0.11999527452162417, SCOPE var: 0.0011528171193096646\n",
            "Total Loss: 0.00801760376170688\n",
            "----------------------------------------\n",
            "Epoch 18\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0073527111711526585\n",
            "SCOPE mean: 0.12022960586836123, SCOPE var: 0.0011529734112841316\n",
            "Total Loss: 0.007980088531107531\n",
            "----------------------------------------\n",
            "Epoch 19\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0073132171732442856\n",
            "SCOPE mean: 0.12013572682193172, SCOPE var: 0.0011522281230335095\n",
            "Total Loss: 0.007940092218099467\n",
            "----------------------------------------\n",
            "Epoch 20\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.007272788535289423\n",
            "SCOPE mean: 0.11971310044037518, SCOPE var: 0.0011456486635592659\n",
            "Total Loss: 0.007898433817619746\n",
            "----------------------------------------\n",
            "Epoch 21\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.007233268373935128\n",
            "SCOPE mean: 0.1190784335849409, SCOPE var: 0.001133240491825727\n",
            "Total Loss: 0.007855915433411388\n",
            "----------------------------------------\n",
            "Epoch 22\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.007195866924616426\n",
            "SCOPE mean: 0.11843689294418434, SCOPE var: 0.0011212088588071858\n",
            "Total Loss: 0.007814314104298982\n",
            "----------------------------------------\n",
            "Epoch 23\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.00716068281290107\n",
            "SCOPE mean: 0.1179003082598098, SCOPE var: 0.0011128875782402002\n",
            "Total Loss: 0.007775104745287888\n",
            "----------------------------------------\n",
            "Epoch 24\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.007126647100976957\n",
            "SCOPE mean: 0.1175421835182991, SCOPE var: 0.0011068913592844538\n",
            "Total Loss: 0.0077379666104174195\n",
            "----------------------------------------\n",
            "Epoch 25\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.007093528261151065\n",
            "SCOPE mean: 0.11737548995665002, SCOPE var: 0.001102934167132901\n",
            "Total Loss: 0.007702663307373159\n",
            "----------------------------------------\n",
            "Epoch 26\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.007060442863258999\n",
            "SCOPE mean: 0.11734296209504398, SCOPE var: 0.0011004694101011106\n",
            "Total Loss: 0.007668234012605242\n",
            "----------------------------------------\n",
            "Epoch 27\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.007026790493413335\n",
            "SCOPE mean: 0.11737915926240866, SCOPE var: 0.0010987513187300326\n",
            "Total Loss: 0.007633278888137968\n",
            "----------------------------------------\n",
            "Epoch 28\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0069923056197031515\n",
            "SCOPE mean: 0.11746023631676149, SCOPE var: 0.0010974484966570928\n",
            "Total Loss: 0.0075969656737360225\n",
            "----------------------------------------\n",
            "Epoch 29\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.006957022245713827\n",
            "SCOPE mean: 0.11756057727494176, SCOPE var: 0.0010960262800616433\n",
            "Total Loss: 0.0075594979967627445\n",
            "----------------------------------------\n",
            "Epoch 30\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.006921467087829798\n",
            "SCOPE mean: 0.1177071074494605, SCOPE var: 0.0010958884387025612\n",
            "Total Loss: 0.007522860945005903\n",
            "----------------------------------------\n",
            "Epoch 31\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.006885945064335639\n",
            "SCOPE mean: 0.11780225954566895, SCOPE var: 0.0010900588827676774\n",
            "Total Loss: 0.00748677505307038\n",
            "----------------------------------------\n",
            "Epoch 32\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.006850876898648046\n",
            "SCOPE mean: 0.11784293953080155, SCOPE var: 0.001079024401370808\n",
            "Total Loss: 0.007450637631037206\n",
            "----------------------------------------\n",
            "Epoch 33\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.006817180058170639\n",
            "SCOPE mean: 0.11796755127944741, SCOPE var: 0.0010709437478957893\n",
            "Total Loss: 0.007415124958170253\n",
            "----------------------------------------\n",
            "Epoch 34\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.006784225063736083\n",
            "SCOPE mean: 0.11806498653276469, SCOPE var: 0.0010616220566334784\n",
            "Total Loss: 0.007379222350348678\n",
            "----------------------------------------\n",
            "Epoch 35\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.006752092630096508\n",
            "SCOPE mean: 0.11814128179716145, SCOPE var: 0.0010515667102701915\n",
            "Total Loss: 0.0073430841143848164\n",
            "----------------------------------------\n",
            "Epoch 36\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.006720443425216252\n",
            "SCOPE mean: 0.11815113652737477, SCOPE var: 0.0010392782769615026\n",
            "Total Loss: 0.007306773639209183\n",
            "----------------------------------------\n",
            "Epoch 37\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0066888641459991165\n",
            "SCOPE mean: 0.11813437136744633, SCOPE var: 0.0010278612974133619\n",
            "Total Loss: 0.007270884039307527\n",
            "----------------------------------------\n",
            "Epoch 38\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.006657121741985006\n",
            "SCOPE mean: 0.11800545843234872, SCOPE var: 0.0010128471126973145\n",
            "Total Loss: 0.007235161345526396\n",
            "----------------------------------------\n",
            "Epoch 39\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.006625471558798853\n",
            "SCOPE mean: 0.11784659145120695, SCOPE var: 0.0009990929248651459\n",
            "Total Loss: 0.007200024771954463\n",
            "----------------------------------------\n",
            "Epoch 40\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.006594078645330061\n",
            "SCOPE mean: 0.11765192088272532, SCOPE var: 0.0009839204373403557\n",
            "Total Loss: 0.007164981783759343\n",
            "----------------------------------------\n",
            "Epoch 41\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0065630250528090186\n",
            "SCOPE mean: 0.11752805487877777, SCOPE var: 0.0009700395374678437\n",
            "Total Loss: 0.007130594007102763\n",
            "----------------------------------------\n",
            "Epoch 42\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.006532114067347815\n",
            "SCOPE mean: 0.11754287071319763, SCOPE var: 0.0009575263696485406\n",
            "Total Loss: 0.007096408319901915\n",
            "----------------------------------------\n",
            "Epoch 43\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.006501130284686605\n",
            "SCOPE mean: 0.11769449021380597, SCOPE var: 0.0009463479141394305\n",
            "Total Loss: 0.0070620142745490356\n",
            "----------------------------------------\n",
            "Epoch 44\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.006470429153181109\n",
            "SCOPE mean: 0.1179642762312132, SCOPE var: 0.0009377844368905581\n",
            "Total Loss: 0.007027971647733829\n",
            "----------------------------------------\n",
            "Epoch 45\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.006439902699605019\n",
            "SCOPE mean: 0.11820656592762283, SCOPE var: 0.0009276486590209608\n",
            "Total Loss: 0.006994349419513239\n",
            "----------------------------------------\n",
            "Epoch 46\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.006409254722152267\n",
            "SCOPE mean: 0.11833911867670413, SCOPE var: 0.0009147414694190063\n",
            "Total Loss: 0.006961031603890956\n",
            "----------------------------------------\n",
            "Epoch 47\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0063782640488646925\n",
            "SCOPE mean: 0.11842616480045508, SCOPE var: 0.000903160883105373\n",
            "Total Loss: 0.0069281089039631176\n",
            "----------------------------------------\n",
            "Epoch 48\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.006346950099993336\n",
            "SCOPE mean: 0.11843948481944329, SCOPE var: 0.0008924151411338704\n",
            "Total Loss: 0.006895527745847311\n",
            "----------------------------------------\n",
            "Epoch 49\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.006315374619927228\n",
            "SCOPE mean: 0.1183247081882183, SCOPE var: 0.0008793253677183904\n",
            "Total Loss: 0.0068630555225697686\n",
            "----------------------------------------\n",
            "Epoch 50\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.00628403300318783\n",
            "SCOPE mean: 0.1181369563143415, SCOPE var: 0.0008652974195199626\n",
            "Total Loss: 0.006830697758237885\n",
            "----------------------------------------\n",
            "Epoch 51\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.006253205014918133\n",
            "SCOPE mean: 0.11798111241601687, SCOPE var: 0.000853264063037228\n",
            "Total Loss: 0.006798464041677157\n",
            "----------------------------------------\n",
            "Epoch 52\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.006222913155560218\n",
            "SCOPE mean: 0.1178808053997533, SCOPE var: 0.000843084366809599\n",
            "Total Loss: 0.006766407541029687\n",
            "----------------------------------------\n",
            "Epoch 53\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.006193190979088112\n",
            "SCOPE mean: 0.11778074195334805, SCOPE var: 0.0008324661268876624\n",
            "Total Loss: 0.00673469174626667\n",
            "----------------------------------------\n",
            "Epoch 54\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0061641509843707\n",
            "SCOPE mean: 0.11771972210107183, SCOPE var: 0.0008230494247904672\n",
            "Total Loss: 0.006703415741889726\n",
            "----------------------------------------\n",
            "Epoch 55\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.006135437953787612\n",
            "SCOPE mean: 0.11766698162237503, SCOPE var: 0.0008144531733225757\n",
            "Total Loss: 0.006672057030950092\n",
            "----------------------------------------\n",
            "Epoch 56\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0061069856489754685\n",
            "SCOPE mean: 0.11760986268607808, SCOPE var: 0.0008063132229409559\n",
            "Total Loss: 0.006640633455537462\n",
            "----------------------------------------\n",
            "Epoch 57\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.006078985942014901\n",
            "SCOPE mean: 0.11757658096850887, SCOPE var: 0.0007999360572139904\n",
            "Total Loss: 0.006609531518132072\n",
            "----------------------------------------\n",
            "Epoch 58\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.006051489750820026\n",
            "SCOPE mean: 0.11750630114323407, SCOPE var: 0.0007928281621551388\n",
            "Total Loss: 0.006578974667442706\n",
            "----------------------------------------\n",
            "Epoch 59\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.006024529890504702\n",
            "SCOPE mean: 0.11737228553544876, SCOPE var: 0.0007833661698282518\n",
            "Total Loss: 0.006549336168469618\n",
            "----------------------------------------\n",
            "Epoch 60\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.005998587954234358\n",
            "SCOPE mean: 0.11728108389809866, SCOPE var: 0.0007746475673013932\n",
            "Total Loss: 0.00651995920002502\n",
            "----------------------------------------\n",
            "Epoch 61\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.005973219104179911\n",
            "SCOPE mean: 0.11720213084464404, SCOPE var: 0.0007661053729434551\n",
            "Total Loss: 0.006490582509110978\n",
            "----------------------------------------\n",
            "Epoch 62\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.005947918453490078\n",
            "SCOPE mean: 0.11711760167203884, SCOPE var: 0.0007572648422777829\n",
            "Total Loss: 0.006461623569174509\n",
            "----------------------------------------\n",
            "Epoch 63\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.005922314593444466\n",
            "SCOPE mean: 0.11700752248946118, SCOPE var: 0.0007482955418753533\n",
            "Total Loss: 0.006432839721660982\n",
            "----------------------------------------\n",
            "Epoch 64\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.005896515013242896\n",
            "SCOPE mean: 0.11696539818827391, SCOPE var: 0.0007429911086308592\n",
            "Total Loss: 0.00640433956868709\n",
            "----------------------------------------\n",
            "Epoch 65\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.005870669742541217\n",
            "SCOPE mean: 0.11694752030070517, SCOPE var: 0.000736903422345624\n",
            "Total Loss: 0.006376131521106245\n",
            "----------------------------------------\n",
            "Epoch 66\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.005844733223433926\n",
            "SCOPE mean: 0.11699071999017265, SCOPE var: 0.0007302039461845512\n",
            "Total Loss: 0.00634810732712148\n",
            "----------------------------------------\n",
            "Epoch 67\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.005818555501493068\n",
            "SCOPE mean: 0.11713491195770996, SCOPE var: 0.00072349974288614\n",
            "Total Loss: 0.0063199606622803\n",
            "----------------------------------------\n",
            "Epoch 68\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.005792220429154021\n",
            "SCOPE mean: 0.11729983989970551, SCOPE var: 0.0007165312579590559\n",
            "Total Loss: 0.006291910345882747\n",
            "----------------------------------------\n",
            "Epoch 69\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.005765961494391749\n",
            "SCOPE mean: 0.11744931780640257, SCOPE var: 0.0007104827627479824\n",
            "Total Loss: 0.006264648875053524\n",
            "----------------------------------------\n",
            "Epoch 70\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.005739474231104673\n",
            "SCOPE mean: 0.11755609407696548, SCOPE var: 0.0007056401738699013\n",
            "Total Loss: 0.006237599008542067\n",
            "----------------------------------------\n",
            "Epoch 71\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.005712939449119328\n",
            "SCOPE mean: 0.1175939668849908, SCOPE var: 0.0007002863851812452\n",
            "Total Loss: 0.006210602828391853\n",
            "----------------------------------------\n",
            "Epoch 72\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.005686909655115232\n",
            "SCOPE mean: 0.11762420949548136, SCOPE var: 0.0006946605270084144\n",
            "Total Loss: 0.006183698432032449\n",
            "----------------------------------------\n",
            "Epoch 73\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.005661825182927477\n",
            "SCOPE mean: 0.1177591677882564, SCOPE var: 0.0006919542289565936\n",
            "Total Loss: 0.006157076673065268\n",
            "----------------------------------------\n",
            "Epoch 74\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.00563732223630283\n",
            "SCOPE mean: 0.1178495742177968, SCOPE var: 0.0006877852587651455\n",
            "Total Loss: 0.006131225341026128\n",
            "----------------------------------------\n",
            "Epoch 75\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.005613039991446236\n",
            "SCOPE mean: 0.11786130179346935, SCOPE var: 0.0006820586233897503\n",
            "Total Loss: 0.006105463054180216\n",
            "----------------------------------------\n",
            "Epoch 76\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.005588932148472809\n",
            "SCOPE mean: 0.11784422700292718, SCOPE var: 0.0006753420301599263\n",
            "Total Loss: 0.006079750889738376\n",
            "----------------------------------------\n",
            "Epoch 77\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.005564978093793295\n",
            "SCOPE mean: 0.11779529531985163, SCOPE var: 0.0006677951852029201\n",
            "Total Loss: 0.006054103299777058\n",
            "----------------------------------------\n",
            "Epoch 78\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0055414709215904625\n",
            "SCOPE mean: 0.11775691980367933, SCOPE var: 0.0006616073001496731\n",
            "Total Loss: 0.006028798239587334\n",
            "----------------------------------------\n",
            "Epoch 79\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.005518176980022403\n",
            "SCOPE mean: 0.11773065422067357, SCOPE var: 0.0006567357372639042\n",
            "Total Loss: 0.006003701575452427\n",
            "----------------------------------------\n",
            "Epoch 80\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.005494633690954871\n",
            "SCOPE mean: 0.11764766219461499, SCOPE var: 0.000651652911309579\n",
            "Total Loss: 0.005978491024157037\n",
            "----------------------------------------\n",
            "Epoch 81\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.005471217720679688\n",
            "SCOPE mean: 0.11759734561223541, SCOPE var: 0.0006470330087146963\n",
            "Total Loss: 0.005953798799922174\n",
            "----------------------------------------\n",
            "Epoch 82\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.005448465293885177\n",
            "SCOPE mean: 0.11761090275134131, SCOPE var: 0.0006442255732617993\n",
            "Total Loss: 0.005929390962018193\n",
            "----------------------------------------\n",
            "Epoch 83\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0054262671622692694\n",
            "SCOPE mean: 0.11758969472097906, SCOPE var: 0.0006411104896934771\n",
            "Total Loss: 0.005905162336394564\n",
            "----------------------------------------\n",
            "Epoch 84\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.005404384661410146\n",
            "SCOPE mean: 0.11754354227433057, SCOPE var: 0.0006372370205707191\n",
            "Total Loss: 0.00588107019793174\n",
            "----------------------------------------\n",
            "Epoch 85\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0053826558355503365\n",
            "SCOPE mean: 0.1174610181435301, SCOPE var: 0.0006326597048723261\n",
            "Total Loss: 0.005857020863613339\n",
            "----------------------------------------\n",
            "Epoch 86\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0053611375654392815\n",
            "SCOPE mean: 0.11741492629107547, SCOPE var: 0.0006279873310670319\n",
            "Total Loss: 0.005832998413003339\n",
            "----------------------------------------\n",
            "Epoch 87\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.005339730012338335\n",
            "SCOPE mean: 0.11741938206903828, SCOPE var: 0.0006234371902320946\n",
            "Total Loss: 0.0058095353719247525\n",
            "----------------------------------------\n",
            "Epoch 88\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.005318298302914109\n",
            "SCOPE mean: 0.11745197217844454, SCOPE var: 0.0006184539714316873\n",
            "Total Loss: 0.0057860533084111284\n",
            "----------------------------------------\n",
            "Epoch 89\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.005296620782539172\n",
            "SCOPE mean: 0.1174147217436981, SCOPE var: 0.0006148129090234413\n",
            "Total Loss: 0.005762827376234604\n",
            "----------------------------------------\n",
            "Epoch 90\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0052742591219628225\n",
            "SCOPE mean: 0.11734407271211802, SCOPE var: 0.0006123988975865666\n",
            "Total Loss: 0.005739562287567698\n",
            "----------------------------------------\n",
            "Epoch 91\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.005251763759997743\n",
            "SCOPE mean: 0.11729843978007325, SCOPE var: 0.0006103777490615159\n",
            "Total Loss: 0.005716970761179307\n",
            "----------------------------------------\n",
            "Epoch 92\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0052297974981224985\n",
            "SCOPE mean: 0.11722399955460187, SCOPE var: 0.0006091583911357338\n",
            "Total Loss: 0.005694533847842679\n",
            "----------------------------------------\n",
            "Epoch 93\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.005208614225789815\n",
            "SCOPE mean: 0.11706272509948326, SCOPE var: 0.0006069490151539968\n",
            "Total Loss: 0.005672301901846312\n",
            "----------------------------------------\n",
            "Epoch 94\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.005187857228732268\n",
            "SCOPE mean: 0.11691698173517809, SCOPE var: 0.000604004027941059\n",
            "Total Loss: 0.005650039182849106\n",
            "----------------------------------------\n",
            "Epoch 95\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.005167407532368506\n",
            "SCOPE mean: 0.11679606486901956, SCOPE var: 0.000600616346361684\n",
            "Total Loss: 0.005627761640763658\n",
            "----------------------------------------\n",
            "Epoch 96\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.005147318291179086\n",
            "SCOPE mean: 0.11670851835626138, SCOPE var: 0.000596969710668337\n",
            "Total Loss: 0.005605978074511784\n",
            "----------------------------------------\n",
            "Epoch 97\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0051270753280632285\n",
            "SCOPE mean: 0.11666439478986286, SCOPE var: 0.0005936563336318418\n",
            "Total Loss: 0.005584057768975843\n",
            "----------------------------------------\n",
            "Epoch 98\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.005106760844227341\n",
            "SCOPE mean: 0.11665162870227036, SCOPE var: 0.0005906029868303916\n",
            "Total Loss: 0.00556239006495725\n",
            "----------------------------------------\n",
            "Epoch 99\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.005086790309584867\n",
            "SCOPE mean: 0.11654999465907018, SCOPE var: 0.0005884141144285539\n",
            "Total Loss: 0.0055410125924736375\n",
            "----------------------------------------\n",
            "Epoch 100\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.005066929507167406\n",
            "SCOPE mean: 0.11631013391813895, SCOPE var: 0.0005854585574526801\n",
            "Total Loss: 0.005519879124669753\n",
            "----------------------------------------\n",
            "Epoch 101\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.005047259118184452\n",
            "SCOPE mean: 0.11610715037377708, SCOPE var: 0.0005823498238698268\n",
            "Total Loss: 0.005498736077703509\n",
            "----------------------------------------\n",
            "Epoch 102\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.005028041140731617\n",
            "SCOPE mean: 0.11599203863075447, SCOPE var: 0.0005805072770567645\n",
            "Total Loss: 0.005477805069942089\n",
            "----------------------------------------\n",
            "Epoch 103\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.005009590608222738\n",
            "SCOPE mean: 0.11585366804144091, SCOPE var: 0.0005786009456855745\n",
            "Total Loss: 0.0054571472921293605\n",
            "----------------------------------------\n",
            "Epoch 104\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.004991233736097004\n",
            "SCOPE mean: 0.11576474911657875, SCOPE var: 0.000576788421633121\n",
            "Total Loss: 0.005436634339152083\n",
            "----------------------------------------\n",
            "Epoch 105\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.00497287968264311\n",
            "SCOPE mean: 0.11572906033936976, SCOPE var: 0.000575183592309597\n",
            "Total Loss: 0.005416353001106934\n",
            "----------------------------------------\n",
            "Epoch 106\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.004954483595630425\n",
            "SCOPE mean: 0.11561419654314273, SCOPE var: 0.0005729441603093174\n",
            "Total Loss: 0.005396313289194448\n",
            "----------------------------------------\n",
            "Epoch 107\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.004936073375808467\n",
            "SCOPE mean: 0.11550805290490367, SCOPE var: 0.0005704919161063198\n",
            "Total Loss: 0.0053763558478100455\n",
            "----------------------------------------\n",
            "Epoch 108\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.004917582598851635\n",
            "SCOPE mean: 0.11542543754024294, SCOPE var: 0.0005681411256996989\n",
            "Total Loss: 0.005356458611569122\n",
            "----------------------------------------\n",
            "Epoch 109\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.004899448445091492\n",
            "SCOPE mean: 0.11526612699943892, SCOPE var: 0.0005649855806737791\n",
            "Total Loss: 0.005336694407991461\n",
            "----------------------------------------\n",
            "Epoch 110\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.004881377467265123\n",
            "SCOPE mean: 0.115135029941044, SCOPE var: 0.0005619803810525352\n",
            "Total Loss: 0.005317221115456316\n",
            "----------------------------------------\n",
            "Epoch 111\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.004863249222537274\n",
            "SCOPE mean: 0.11506045189614636, SCOPE var: 0.0005596482151157236\n",
            "Total Loss: 0.00529798453779029\n",
            "----------------------------------------\n",
            "Epoch 112\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.004845144898319855\n",
            "SCOPE mean: 0.11496255576850951, SCOPE var: 0.0005578424177935708\n",
            "Total Loss: 0.00527875677240716\n",
            "----------------------------------------\n",
            "Epoch 113\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0048270353620691\n",
            "SCOPE mean: 0.11491220811887916, SCOPE var: 0.0005566567759736361\n",
            "Total Loss: 0.005259639095492707\n",
            "----------------------------------------\n",
            "Epoch 114\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0048092993602734885\n",
            "SCOPE mean: 0.11488086487697481, SCOPE var: 0.0005552703451110726\n",
            "Total Loss: 0.005240779812816947\n",
            "----------------------------------------\n",
            "Epoch 115\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.004791774712560099\n",
            "SCOPE mean: 0.11476795183909466, SCOPE var: 0.0005533850326289295\n",
            "Total Loss: 0.005222075023239758\n",
            "----------------------------------------\n",
            "Epoch 116\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.00477437776804576\n",
            "SCOPE mean: 0.11472685871361725, SCOPE var: 0.000552716202317162\n",
            "Total Loss: 0.005203320880832339\n",
            "----------------------------------------\n",
            "Epoch 117\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0047568499406355335\n",
            "SCOPE mean: 0.11477938921365785, SCOPE var: 0.0005517865400810537\n",
            "Total Loss: 0.005184856313479823\n",
            "----------------------------------------\n",
            "Epoch 118\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.004739868319173199\n",
            "SCOPE mean: 0.1146534581465829, SCOPE var: 0.0005497618968275461\n",
            "Total Loss: 0.005166384707779376\n",
            "----------------------------------------\n",
            "Epoch 119\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.004723003638948818\n",
            "SCOPE mean: 0.11455822479019555, SCOPE var: 0.0005476141371314355\n",
            "Total Loss: 0.005148054533923598\n",
            "----------------------------------------\n",
            "Epoch 120\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.004706465909491783\n",
            "SCOPE mean: 0.1143572270267789, SCOPE var: 0.0005449888067075102\n",
            "Total Loss: 0.00512996363099853\n",
            "----------------------------------------\n",
            "Epoch 121\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.004689723364134145\n",
            "SCOPE mean: 0.11427951324701907, SCOPE var: 0.0005425761641876878\n",
            "Total Loss: 0.0051118532605820485\n",
            "----------------------------------------\n",
            "Epoch 122\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.004672798560755508\n",
            "SCOPE mean: 0.11430030023811853, SCOPE var: 0.000540350979429928\n",
            "Total Loss: 0.005093903950414632\n",
            "----------------------------------------\n",
            "Epoch 123\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0046560196571993695\n",
            "SCOPE mean: 0.11430648911216963, SCOPE var: 0.0005383098592841849\n",
            "Total Loss: 0.005076136713619704\n",
            "----------------------------------------\n",
            "Epoch 124\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.004639638341341646\n",
            "SCOPE mean: 0.11421605987360185, SCOPE var: 0.0005361797829752511\n",
            "Total Loss: 0.005058393876350188\n",
            "----------------------------------------\n",
            "Epoch 125\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0046238215411002\n",
            "SCOPE mean: 0.11411280901059949, SCOPE var: 0.0005357800671804721\n",
            "Total Loss: 0.005041361330418319\n",
            "----------------------------------------\n",
            "Epoch 126\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0046077449828452206\n",
            "SCOPE mean: 0.11426085524437385, SCOPE var: 0.0005373026268539971\n",
            "Total Loss: 0.005024319923199431\n",
            "----------------------------------------\n",
            "Epoch 127\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.004591405429020812\n",
            "SCOPE mean: 0.11456348161082679, SCOPE var: 0.0005388426063765015\n",
            "Total Loss: 0.005007330787813275\n",
            "----------------------------------------\n",
            "Epoch 128\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.00457533579687199\n",
            "SCOPE mean: 0.11483681157935434, SCOPE var: 0.0005397887034754203\n",
            "Total Loss: 0.004990508344134504\n",
            "----------------------------------------\n",
            "Epoch 129\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.004559854133871549\n",
            "SCOPE mean: 0.11500177685206066, SCOPE var: 0.0005399102066005421\n",
            "Total Loss: 0.004974039125960715\n",
            "----------------------------------------\n",
            "Epoch 130\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0045452469760783485\n",
            "SCOPE mean: 0.11486998494198174, SCOPE var: 0.0005382626186663621\n",
            "Total Loss: 0.004957473844213375\n",
            "----------------------------------------\n",
            "Epoch 131\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.004531281278071946\n",
            "SCOPE mean: 0.11459196116189478, SCOPE var: 0.0005366605479812886\n",
            "Total Loss: 0.004940921876629787\n",
            "----------------------------------------\n",
            "Epoch 132\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.004517572708879487\n",
            "SCOPE mean: 0.11426274649318975, SCOPE var: 0.0005351572992263696\n",
            "Total Loss: 0.004924763269584307\n",
            "----------------------------------------\n",
            "Epoch 133\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.004503728936853492\n",
            "SCOPE mean: 0.11407914221727547, SCOPE var: 0.0005353203285873023\n",
            "Total Loss: 0.0049087361068478235\n",
            "----------------------------------------\n",
            "Epoch 134\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0044893515335105\n",
            "SCOPE mean: 0.11411599948053663, SCOPE var: 0.0005362011798435957\n",
            "Total Loss: 0.004892715888976083\n",
            "----------------------------------------\n",
            "Epoch 135\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.004474524210613126\n",
            "SCOPE mean: 0.1143351863901216, SCOPE var: 0.0005372544931422806\n",
            "Total Loss: 0.004876553049878597\n",
            "----------------------------------------\n",
            "Epoch 136\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.004459900306984995\n",
            "SCOPE mean: 0.1145971496309282, SCOPE var: 0.0005386008352155381\n",
            "Total Loss: 0.0048607174209413994\n",
            "----------------------------------------\n",
            "Epoch 137\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.004445810443078524\n",
            "SCOPE mean: 0.11470567468170684, SCOPE var: 0.0005394180910799295\n",
            "Total Loss: 0.004845276579673417\n",
            "----------------------------------------\n",
            "Epoch 138\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.00443226685321305\n",
            "SCOPE mean: 0.11455024376311915, SCOPE var: 0.0005383758266063512\n",
            "Total Loss: 0.004829745623052554\n",
            "----------------------------------------\n",
            "Epoch 139\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.004418964179737087\n",
            "SCOPE mean: 0.114264783996499, SCOPE var: 0.0005360115992182285\n",
            "Total Loss: 0.004814403919139053\n",
            "----------------------------------------\n",
            "Epoch 140\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.00440549407864613\n",
            "SCOPE mean: 0.11409656320739486, SCOPE var: 0.000534747070932552\n",
            "Total Loss: 0.00479922909559806\n",
            "----------------------------------------\n",
            "Epoch 141\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.004391378925374992\n",
            "SCOPE mean: 0.11406717314049027, SCOPE var: 0.0005339974852452407\n",
            "Total Loss: 0.004783894664773147\n",
            "----------------------------------------\n",
            "Epoch 142\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.004377136819004509\n",
            "SCOPE mean: 0.11407606209845457, SCOPE var: 0.0005333909275325373\n",
            "Total Loss: 0.004768778653690667\n",
            "----------------------------------------\n",
            "Epoch 143\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.004362851113860735\n",
            "SCOPE mean: 0.11420994708571447, SCOPE var: 0.000535199205336065\n",
            "Total Loss: 0.004753798178595815\n",
            "----------------------------------------\n",
            "Epoch 144\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.004348872135735007\n",
            "SCOPE mean: 0.11425754838200687, SCOPE var: 0.0005362895355786135\n",
            "Total Loss: 0.004738704916979987\n",
            "----------------------------------------\n",
            "Epoch 145\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.004335329355709742\n",
            "SCOPE mean: 0.11425522656859716, SCOPE var: 0.0005373791344255869\n",
            "Total Loss: 0.004723852672211794\n",
            "----------------------------------------\n",
            "Epoch 146\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.004321762661368106\n",
            "SCOPE mean: 0.11434225785912686, SCOPE var: 0.0005385629646839549\n",
            "Total Loss: 0.004709319996496567\n",
            "----------------------------------------\n",
            "Epoch 147\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.004307810210008955\n",
            "SCOPE mean: 0.11456398829472342, SCOPE var: 0.0005395619924171254\n",
            "Total Loss: 0.004694708707750118\n",
            "----------------------------------------\n",
            "Epoch 148\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.004293808222630705\n",
            "SCOPE mean: 0.11470250732063973, SCOPE var: 0.0005397928639138621\n",
            "Total Loss: 0.004680042402136803\n",
            "----------------------------------------\n",
            "Epoch 149\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0042799669327969955\n",
            "SCOPE mean: 0.11472509788618344, SCOPE var: 0.0005392420712529883\n",
            "Total Loss: 0.004665643700163309\n",
            "----------------------------------------\n",
            "Epoch 150\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.004266391329720137\n",
            "SCOPE mean: 0.1146762923467244, SCOPE var: 0.0005376787770752169\n",
            "Total Loss: 0.0046515375626974605\n",
            "----------------------------------------\n",
            "Epoch 151\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0042536787845080725\n",
            "SCOPE mean: 0.1143561193009531, SCOPE var: 0.0005349081686047006\n",
            "Total Loss: 0.004637283038811866\n",
            "----------------------------------------\n",
            "Epoch 152\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.004241285256204668\n",
            "SCOPE mean: 0.1141062603697784, SCOPE var: 0.0005343117169929344\n",
            "Total Loss: 0.00462344251870049\n",
            "----------------------------------------\n",
            "Epoch 153\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.004228701113301399\n",
            "SCOPE mean: 0.11404822647566926, SCOPE var: 0.0005346232266220371\n",
            "Total Loss: 0.00460975370807969\n",
            "----------------------------------------\n",
            "Epoch 154\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.004215818633049136\n",
            "SCOPE mean: 0.11416509275773751, SCOPE var: 0.0005349689741651756\n",
            "Total Loss: 0.004596128245698061\n",
            "----------------------------------------\n",
            "Epoch 155\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.004203102275838071\n",
            "SCOPE mean: 0.11423227314647436, SCOPE var: 0.00053435133943447\n",
            "Total Loss: 0.004582525253927198\n",
            "----------------------------------------\n",
            "Epoch 156\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0041905378037818625\n",
            "SCOPE mean: 0.11423945562239142, SCOPE var: 0.0005335317534003118\n",
            "Total Loss: 0.00456895790877166\n",
            "----------------------------------------\n",
            "Epoch 157\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.004178323127229974\n",
            "SCOPE mean: 0.11407066508843762, SCOPE var: 0.0005322488829931697\n",
            "Total Loss: 0.004555643499598994\n",
            "----------------------------------------\n",
            "Epoch 158\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.004166240400167817\n",
            "SCOPE mean: 0.11408270508816319, SCOPE var: 0.000533163283266773\n",
            "Total Loss: 0.004542561843589761\n",
            "----------------------------------------\n",
            "Epoch 159\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.004154219447216335\n",
            "SCOPE mean: 0.11418012153699623, SCOPE var: 0.0005337406457637048\n",
            "Total Loss: 0.00452942150799725\n",
            "----------------------------------------\n",
            "Epoch 160\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.004142521283262926\n",
            "SCOPE mean: 0.11418506030103098, SCOPE var: 0.000533469447248295\n",
            "Total Loss: 0.004516358221357987\n",
            "----------------------------------------\n",
            "Epoch 161\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.00413090949849351\n",
            "SCOPE mean: 0.11415344841054344, SCOPE var: 0.0005323132216908827\n",
            "Total Loss: 0.004503195258444914\n",
            "----------------------------------------\n",
            "Epoch 162\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.004119161483929765\n",
            "SCOPE mean: 0.11418786803582225, SCOPE var: 0.0005305365190892346\n",
            "Total Loss: 0.004489921727482736\n",
            "----------------------------------------\n",
            "Epoch 163\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.00410738171323775\n",
            "SCOPE mean: 0.11430694948191417, SCOPE var: 0.0005293753577842946\n",
            "Total Loss: 0.004477026640245058\n",
            "----------------------------------------\n",
            "Epoch 164\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.004095898910909269\n",
            "SCOPE mean: 0.11429293209500699, SCOPE var: 0.0005283561844966849\n",
            "Total Loss: 0.004464300548217525\n",
            "----------------------------------------\n",
            "Epoch 165\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0040848442132416125\n",
            "SCOPE mean: 0.11414316296635611, SCOPE var: 0.0005274817804714939\n",
            "Total Loss: 0.004451501871686902\n",
            "----------------------------------------\n",
            "Epoch 166\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.004073774860578234\n",
            "SCOPE mean: 0.11404846746567392, SCOPE var: 0.0005276766264843095\n",
            "Total Loss: 0.00443872930637273\n",
            "----------------------------------------\n",
            "Epoch 167\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.004062100959822956\n",
            "SCOPE mean: 0.11419758626699013, SCOPE var: 0.0005278714276381378\n",
            "Total Loss: 0.004426107921753636\n",
            "----------------------------------------\n",
            "Epoch 168\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.004049869580112263\n",
            "SCOPE mean: 0.11455334369094433, SCOPE var: 0.000528065346805396\n",
            "Total Loss: 0.004413324087249806\n",
            "----------------------------------------\n",
            "Epoch 169\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.004037382016552487\n",
            "SCOPE mean: 0.11495302023162951, SCOPE var: 0.0005278730537628179\n",
            "Total Loss: 0.004400567481811704\n",
            "----------------------------------------\n",
            "Epoch 170\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.004025353248404517\n",
            "SCOPE mean: 0.1152138344484724, SCOPE var: 0.0005271500722648332\n",
            "Total Loss: 0.004387906838360933\n",
            "----------------------------------------\n",
            "Epoch 171\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.004013854481208254\n",
            "SCOPE mean: 0.11534441988891886, SCOPE var: 0.0005266995894741784\n",
            "Total Loss: 0.0043753529684159706\n",
            "----------------------------------------\n",
            "Epoch 172\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.004002459465236953\n",
            "SCOPE mean: 0.11544750673798451, SCOPE var: 0.0005260474079932982\n",
            "Total Loss: 0.004362943253364402\n",
            "----------------------------------------\n",
            "Epoch 173\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003991151621251736\n",
            "SCOPE mean: 0.11554551537072935, SCOPE var: 0.0005250320489034368\n",
            "Total Loss: 0.004350460375188757\n",
            "----------------------------------------\n",
            "Epoch 174\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0039800935865910115\n",
            "SCOPE mean: 0.11561265739463857, SCOPE var: 0.0005241141331425015\n",
            "Total Loss: 0.004338048172244537\n",
            "----------------------------------------\n",
            "Epoch 175\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003969283770974254\n",
            "SCOPE mean: 0.11570109076345259, SCOPE var: 0.0005246825758662626\n",
            "Total Loss: 0.0043260665860284505\n",
            "----------------------------------------\n",
            "Epoch 176\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003958506952865037\n",
            "SCOPE mean: 0.11579284048648428, SCOPE var: 0.000524871299460843\n",
            "Total Loss: 0.004314013015851562\n",
            "----------------------------------------\n",
            "Epoch 177\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0039477660402100516\n",
            "SCOPE mean: 0.11584998955222145, SCOPE var: 0.0005243369054029468\n",
            "Total Loss: 0.0043018156790485765\n",
            "----------------------------------------\n",
            "Epoch 178\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003937110118645815\n",
            "SCOPE mean: 0.11585524490272624, SCOPE var: 0.0005228768488605359\n",
            "Total Loss: 0.004289953313584786\n",
            "----------------------------------------\n",
            "Epoch 179\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.00392670673270185\n",
            "SCOPE mean: 0.11570733946418468, SCOPE var: 0.0005207623526717818\n",
            "Total Loss: 0.0042779807163565425\n",
            "----------------------------------------\n",
            "Epoch 180\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.00391643852952401\n",
            "SCOPE mean: 0.11554555442862381, SCOPE var: 0.0005199063967021036\n",
            "Total Loss: 0.004266340505983248\n",
            "----------------------------------------\n",
            "Epoch 181\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003905521937962358\n",
            "SCOPE mean: 0.11562640490081333, SCOPE var: 0.0005200596370348819\n",
            "Total Loss: 0.0042547144423891875\n",
            "----------------------------------------\n",
            "Epoch 182\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003894153321806543\n",
            "SCOPE mean: 0.11586962408243258, SCOPE var: 0.0005203588856452026\n",
            "Total Loss: 0.004243022077581513\n",
            "----------------------------------------\n",
            "Epoch 183\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003882656531925042\n",
            "SCOPE mean: 0.11612585486591347, SCOPE var: 0.0005200138216314106\n",
            "Total Loss: 0.00423143150342771\n",
            "----------------------------------------\n",
            "Epoch 184\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0038718378755254763\n",
            "SCOPE mean: 0.11615728828933752, SCOPE var: 0.0005205249692945378\n",
            "Total Loss: 0.00421997909364118\n",
            "----------------------------------------\n",
            "Epoch 185\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0038616825193879085\n",
            "SCOPE mean: 0.11591142924361618, SCOPE var: 0.000520313796892095\n",
            "Total Loss: 0.004208493358895321\n",
            "----------------------------------------\n",
            "Epoch 186\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0038517630654690137\n",
            "SCOPE mean: 0.1156232655596763, SCOPE var: 0.0005191364602020358\n",
            "Total Loss: 0.004197279396108159\n",
            "----------------------------------------\n",
            "Epoch 187\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0038415763589836555\n",
            "SCOPE mean: 0.11542903389832397, SCOPE var: 0.0005171322924300443\n",
            "Total Loss: 0.004186023120059118\n",
            "----------------------------------------\n",
            "Epoch 188\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003831081811401098\n",
            "SCOPE mean: 0.11538526261952889, SCOPE var: 0.0005149972934051101\n",
            "Total Loss: 0.004174810419512182\n",
            "----------------------------------------\n",
            "Epoch 189\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003820715561364861\n",
            "SCOPE mean: 0.11541978770751517, SCOPE var: 0.0005145363408950866\n",
            "Total Loss: 0.004163842806127943\n",
            "----------------------------------------\n",
            "Epoch 190\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003810601513275325\n",
            "SCOPE mean: 0.11538896039747626, SCOPE var: 0.0005139337305277606\n",
            "Total Loss: 0.004152821335547692\n",
            "----------------------------------------\n",
            "Epoch 191\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0038008050783618704\n",
            "SCOPE mean: 0.11528694748256874, SCOPE var: 0.0005134140975613258\n",
            "Total Loss: 0.004141945293947652\n",
            "----------------------------------------\n",
            "Epoch 192\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003791374821782334\n",
            "SCOPE mean: 0.11511239953813993, SCOPE var: 0.0005126306402438782\n",
            "Total Loss: 0.004131167261738804\n",
            "----------------------------------------\n",
            "Epoch 193\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0037820756963251215\n",
            "SCOPE mean: 0.11493451343462961, SCOPE var: 0.0005115809044319075\n",
            "Total Loss: 0.004120456952663988\n",
            "----------------------------------------\n",
            "Epoch 194\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0037730655506846974\n",
            "SCOPE mean: 0.114710926992542, SCOPE var: 0.000510778212201331\n",
            "Total Loss: 0.0041100701668686165\n",
            "----------------------------------------\n",
            "Epoch 195\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0037637056478372166\n",
            "SCOPE mean: 0.1146623927814968, SCOPE var: 0.0005104300793476568\n",
            "Total Loss: 0.004099603577616541\n",
            "----------------------------------------\n",
            "Epoch 196\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0037540132924717804\n",
            "SCOPE mean: 0.11476399341048996, SCOPE var: 0.0005100270857131985\n",
            "Total Loss: 0.004089126612335756\n",
            "----------------------------------------\n",
            "Epoch 197\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003744092370893932\n",
            "SCOPE mean: 0.11505487648010376, SCOPE var: 0.0005109436872345721\n",
            "Total Loss: 0.004078946166101238\n",
            "----------------------------------------\n",
            "Epoch 198\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0037347000647350013\n",
            "SCOPE mean: 0.11508754666835855, SCOPE var: 0.0005104035535603874\n",
            "Total Loss: 0.004068668812632026\n",
            "----------------------------------------\n",
            "Epoch 199\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0037257488472697874\n",
            "SCOPE mean: 0.11497708463598297, SCOPE var: 0.0005094097375254585\n",
            "Total Loss: 0.004058578103881437\n",
            "----------------------------------------\n",
            "Epoch 200\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0037169449799253304\n",
            "SCOPE mean: 0.11480695832859124, SCOPE var: 0.0005090498786486861\n",
            "Total Loss: 0.004048492874746688\n",
            "----------------------------------------\n",
            "Epoch 201\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0037089645790254733\n",
            "SCOPE mean: 0.11455486134870832, SCOPE var: 0.0005076344687968665\n",
            "Total Loss: 0.004038632156350226\n",
            "----------------------------------------\n",
            "Epoch 202\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003700626660657391\n",
            "SCOPE mean: 0.11444632525185908, SCOPE var: 0.0005075518364620552\n",
            "Total Loss: 0.004029010175536322\n",
            "----------------------------------------\n",
            "Epoch 203\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003692075598394077\n",
            "SCOPE mean: 0.11441194847772113, SCOPE var: 0.0005071988909747817\n",
            "Total Loss: 0.004019359270121135\n",
            "----------------------------------------\n",
            "Epoch 204\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0036833024136455153\n",
            "SCOPE mean: 0.11442125191858744, SCOPE var: 0.0005062901697527227\n",
            "Total Loss: 0.0040096404543144264\n",
            "----------------------------------------\n",
            "Epoch 205\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0036744964956590513\n",
            "SCOPE mean: 0.1144625090676489, SCOPE var: 0.0005057179891508552\n",
            "Total Loss: 0.0039999791293551515\n",
            "----------------------------------------\n",
            "Epoch 206\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003665617095156695\n",
            "SCOPE mean: 0.11449968465077895, SCOPE var: 0.000505971282974418\n",
            "Total Loss: 0.003990289229778813\n",
            "----------------------------------------\n",
            "Epoch 207\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003656738568175196\n",
            "SCOPE mean: 0.11440563303465526, SCOPE var: 0.0005057840443063353\n",
            "Total Loss: 0.003980600096311573\n",
            "----------------------------------------\n",
            "Epoch 208\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0036478613474858804\n",
            "SCOPE mean: 0.11427691462834445, SCOPE var: 0.000505478620014104\n",
            "Total Loss: 0.003970818509728017\n",
            "----------------------------------------\n",
            "Epoch 209\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0036389953861819405\n",
            "SCOPE mean: 0.11423360075223864, SCOPE var: 0.0005064218851998642\n",
            "Total Loss: 0.0039612096025168604\n",
            "----------------------------------------\n",
            "Epoch 210\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0036304330722178616\n",
            "SCOPE mean: 0.11406758723278049, SCOPE var: 0.0005061964172476528\n",
            "Total Loss: 0.0039515454054529185\n",
            "----------------------------------------\n",
            "Epoch 211\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0036221380725260694\n",
            "SCOPE mean: 0.11379634559569399, SCOPE var: 0.0005049416984031687\n",
            "Total Loss: 0.003941904932416128\n",
            "----------------------------------------\n",
            "Epoch 212\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0036139943732051297\n",
            "SCOPE mean: 0.11346391217443602, SCOPE var: 0.0005029212521752795\n",
            "Total Loss: 0.00393229431477194\n",
            "----------------------------------------\n",
            "Epoch 213\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003605929919104693\n",
            "SCOPE mean: 0.11318961208501646, SCOPE var: 0.0005024442157131281\n",
            "Total Loss: 0.003922907405808385\n",
            "----------------------------------------\n",
            "Epoch 214\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0035983819512767964\n",
            "SCOPE mean: 0.11294660631241829, SCOPE var: 0.0005019687596739552\n",
            "Total Loss: 0.003913555746613191\n",
            "----------------------------------------\n",
            "Epoch 215\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0035905278566260284\n",
            "SCOPE mean: 0.11275635187227344, SCOPE var: 0.0005015840460887167\n",
            "Total Loss: 0.0039042294246550346\n",
            "----------------------------------------\n",
            "Epoch 216\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0035823421727627317\n",
            "SCOPE mean: 0.112680217000547, SCOPE var: 0.0005012903776623307\n",
            "Total Loss: 0.003894912379495146\n",
            "----------------------------------------\n",
            "Epoch 217\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0035744115353653783\n",
            "SCOPE mean: 0.11259753334053803, SCOPE var: 0.0005014974517086493\n",
            "Total Loss: 0.003885809237985958\n",
            "----------------------------------------\n",
            "Epoch 218\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003566807712521205\n",
            "SCOPE mean: 0.1123714109098958, SCOPE var: 0.0005005005005945858\n",
            "Total Loss: 0.003876703549647433\n",
            "----------------------------------------\n",
            "Epoch 219\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003559349369635343\n",
            "SCOPE mean: 0.1120894999007132, SCOPE var: 0.0004994617588934743\n",
            "Total Loss: 0.003867522203621912\n",
            "----------------------------------------\n",
            "Epoch 220\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0035519194477429336\n",
            "SCOPE mean: 0.11179755569443532, SCOPE var: 0.0004985197805916795\n",
            "Total Loss: 0.003858509498347675\n",
            "----------------------------------------\n",
            "Epoch 221\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0035444201193574982\n",
            "SCOPE mean: 0.1115994387947162, SCOPE var: 0.0004989293427370487\n",
            "Total Loss: 0.003849632190576137\n",
            "----------------------------------------\n",
            "Epoch 222\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003536628020297409\n",
            "SCOPE mean: 0.11146452120343547, SCOPE var: 0.0004984222401684932\n",
            "Total Loss: 0.003840770874434393\n",
            "----------------------------------------\n",
            "Epoch 223\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0035287752796261686\n",
            "SCOPE mean: 0.11132906439078219, SCOPE var: 0.0004967779438875516\n",
            "Total Loss: 0.003831964086302159\n",
            "----------------------------------------\n",
            "Epoch 224\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0035208086781307506\n",
            "SCOPE mean: 0.11131763497670649, SCOPE var: 0.0004965060956262731\n",
            "Total Loss: 0.0038232557977384667\n",
            "----------------------------------------\n",
            "Epoch 225\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003512735775321308\n",
            "SCOPE mean: 0.11131057297336713, SCOPE var: 0.0004960379750898464\n",
            "Total Loss: 0.0038145050295923764\n",
            "----------------------------------------\n",
            "Epoch 226\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003504601671321963\n",
            "SCOPE mean: 0.11136313153818819, SCOPE var: 0.0004966188806611834\n",
            "Total Loss: 0.0038058263723023244\n",
            "----------------------------------------\n",
            "Epoch 227\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003496296902952608\n",
            "SCOPE mean: 0.1113755753183726, SCOPE var: 0.0004960035255674248\n",
            "Total Loss: 0.003798041123969554\n",
            "----------------------------------------\n",
            "Epoch 228\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003489207393489814\n",
            "SCOPE mean: 0.11132952918406902, SCOPE var: 0.0004945601186649349\n",
            "Total Loss: 0.0037890122375952083\n",
            "----------------------------------------\n",
            "Epoch 229\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0034822380273940834\n",
            "SCOPE mean: 0.11131078695919726, SCOPE var: 0.0004937765117496031\n",
            "Total Loss: 0.003781192947866886\n",
            "----------------------------------------\n",
            "Epoch 230\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0034751259060845758\n",
            "SCOPE mean: 0.11125518152099585, SCOPE var: 0.0004928576954111133\n",
            "Total Loss: 0.0037735046104241258\n",
            "----------------------------------------\n",
            "Epoch 231\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0034680476781597308\n",
            "SCOPE mean: 0.11118769389633017, SCOPE var: 0.0004919256066373882\n",
            "Total Loss: 0.0037658668889975285\n",
            "----------------------------------------\n",
            "Epoch 232\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0034608103790738382\n",
            "SCOPE mean: 0.11124678827813195, SCOPE var: 0.0004924876867569955\n",
            "Total Loss: 0.003758228938981532\n",
            "----------------------------------------\n",
            "Epoch 233\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003453415274103776\n",
            "SCOPE mean: 0.11129201409006655, SCOPE var: 0.000491927085453433\n",
            "Total Loss: 0.003750493565762601\n",
            "----------------------------------------\n",
            "Epoch 234\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0034461088819796714\n",
            "SCOPE mean: 0.11130911503917598, SCOPE var: 0.0004908696393482137\n",
            "Total Loss: 0.003742718287731717\n",
            "----------------------------------------\n",
            "Epoch 235\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0034389346138359346\n",
            "SCOPE mean: 0.11133613724910356, SCOPE var: 0.0004904060033257918\n",
            "Total Loss: 0.003734968229468264\n",
            "----------------------------------------\n",
            "Epoch 236\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0034318045390589855\n",
            "SCOPE mean: 0.11134442558527344, SCOPE var: 0.0004897027501427268\n",
            "Total Loss: 0.0037272949227774204\n",
            "----------------------------------------\n",
            "Epoch 237\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003424848193437104\n",
            "SCOPE mean: 0.11132938674246844, SCOPE var: 0.0004891335097340508\n",
            "Total Loss: 0.0037196315349971804\n",
            "----------------------------------------\n",
            "Epoch 238\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003417927278027008\n",
            "SCOPE mean: 0.11130741679667137, SCOPE var: 0.0004885444823698622\n",
            "Total Loss: 0.003712206680856404\n",
            "----------------------------------------\n",
            "Epoch 239\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003410635189112273\n",
            "SCOPE mean: 0.11135771559678379, SCOPE var: 0.0004892114541839431\n",
            "Total Loss: 0.003705951572397328\n",
            "----------------------------------------\n",
            "Epoch 240\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0034036041143461595\n",
            "SCOPE mean: 0.11138059856379501, SCOPE var: 0.0004884570628285333\n",
            "Total Loss: 0.0036990783453821514\n",
            "----------------------------------------\n",
            "Epoch 241\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0033973217528789103\n",
            "SCOPE mean: 0.11140834729387591, SCOPE var: 0.00048668910660541195\n",
            "Total Loss: 0.0036919325102866976\n",
            "----------------------------------------\n",
            "Epoch 242\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0033926299947161557\n",
            "SCOPE mean: 0.11111321032074174, SCOPE var: 0.0004851908008565171\n",
            "Total Loss: 0.0036843436147440908\n",
            "----------------------------------------\n",
            "Epoch 243\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0033876237821783978\n",
            "SCOPE mean: 0.11089753222679824, SCOPE var: 0.0004836434533764017\n",
            "Total Loss: 0.003677241550807619\n",
            "----------------------------------------\n",
            "Epoch 244\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0033816071773666878\n",
            "SCOPE mean: 0.11084820152127843, SCOPE var: 0.0004828200902376542\n",
            "Total Loss: 0.0036708193930577023\n",
            "----------------------------------------\n",
            "Epoch 245\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0033751186155838546\n",
            "SCOPE mean: 0.1109046532729768, SCOPE var: 0.00048234601712448524\n",
            "Total Loss: 0.003664381485270579\n",
            "----------------------------------------\n",
            "Epoch 246\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003368452294529122\n",
            "SCOPE mean: 0.11098387496555873, SCOPE var: 0.00048198216782525445\n",
            "Total Loss: 0.0036578971274542553\n",
            "----------------------------------------\n",
            "Epoch 247\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0033618939418424026\n",
            "SCOPE mean: 0.11101211864190591, SCOPE var: 0.0004815494074357658\n",
            "Total Loss: 0.003651421619332001\n",
            "----------------------------------------\n",
            "Epoch 248\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003356622053989295\n",
            "SCOPE mean: 0.11057397465194256, SCOPE var: 0.00048016580301992563\n",
            "Total Loss: 0.0036448283077642404\n",
            "----------------------------------------\n",
            "Epoch 249\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0033511654999372363\n",
            "SCOPE mean: 0.11022324896459886, SCOPE var: 0.0004781326343636653\n",
            "Total Loss: 0.0036382803806929245\n",
            "----------------------------------------\n",
            "Epoch 250\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0033452513908142434\n",
            "SCOPE mean: 0.11013243766135593, SCOPE var: 0.0004774221680654246\n",
            "Total Loss: 0.0036316940977920995\n",
            "----------------------------------------\n",
            "Epoch 251\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.00333893116522179\n",
            "SCOPE mean: 0.11022115258938682, SCOPE var: 0.00047702121577609984\n",
            "Total Loss: 0.0036251091192570214\n",
            "----------------------------------------\n",
            "Epoch 252\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0033335703457317302\n",
            "SCOPE mean: 0.1100800795492888, SCOPE var: 0.00047680495272259493\n",
            "Total Loss: 0.0036188782420919956\n",
            "----------------------------------------\n",
            "Epoch 253\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003327814708305514\n",
            "SCOPE mean: 0.11005091366760104, SCOPE var: 0.0004756194566598206\n",
            "Total Loss: 0.0036127457719491813\n",
            "----------------------------------------\n",
            "Epoch 254\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003322178246438999\n",
            "SCOPE mean: 0.10979009006329483, SCOPE var: 0.0004743048632708876\n",
            "Total Loss: 0.003607869527029904\n",
            "----------------------------------------\n",
            "Epoch 255\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0033160756587071747\n",
            "SCOPE mean: 0.10984176317359552, SCOPE var: 0.0004735742832689878\n",
            "Total Loss: 0.003601991228521159\n",
            "----------------------------------------\n",
            "Epoch 256\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0033096358824706677\n",
            "SCOPE mean: 0.11013575777293663, SCOPE var: 0.00047316297946679853\n",
            "Total Loss: 0.003596152470577346\n",
            "----------------------------------------\n",
            "Epoch 257\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003304616234030783\n",
            "SCOPE mean: 0.11000617201974801, SCOPE var: 0.0004718307467992579\n",
            "Total Loss: 0.0035899152408118643\n",
            "----------------------------------------\n",
            "Epoch 258\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0033010184980499417\n",
            "SCOPE mean: 0.10957808428418547, SCOPE var: 0.0004698534006413414\n",
            "Total Loss: 0.0035835383837307232\n",
            "----------------------------------------\n",
            "Epoch 259\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0032961731564724764\n",
            "SCOPE mean: 0.10946898779225869, SCOPE var: 0.00046917959833701726\n",
            "Total Loss: 0.003578236009450715\n",
            "----------------------------------------\n",
            "Epoch 260\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0032902371891839156\n",
            "SCOPE mean: 0.10965419723879032, SCOPE var: 0.00046910226260110356\n",
            "Total Loss: 0.003572912866634918\n",
            "----------------------------------------\n",
            "Epoch 261\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0032837421174130503\n",
            "SCOPE mean: 0.10990659473474411, SCOPE var: 0.0004674741662148682\n",
            "Total Loss: 0.003567486475065864\n",
            "----------------------------------------\n",
            "Epoch 262\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003278514819829715\n",
            "SCOPE mean: 0.10986331139174915, SCOPE var: 0.0004665930882718081\n",
            "Total Loss: 0.003562268055764728\n",
            "----------------------------------------\n",
            "Epoch 263\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003274268744462606\n",
            "SCOPE mean: 0.10948361297223515, SCOPE var: 0.0004648252288720512\n",
            "Total Loss: 0.0035568985863617844\n",
            "----------------------------------------\n",
            "Epoch 264\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003269446736010101\n",
            "SCOPE mean: 0.10927379844866963, SCOPE var: 0.0004634886832586353\n",
            "Total Loss: 0.003551451693970697\n",
            "----------------------------------------\n",
            "Epoch 265\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0032638437096935155\n",
            "SCOPE mean: 0.10928885261797014, SCOPE var: 0.00046271229056186845\n",
            "Total Loss: 0.0035457114889596232\n",
            "----------------------------------------\n",
            "Epoch 266\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0032577622221575835\n",
            "SCOPE mean: 0.10949396681901574, SCOPE var: 0.0004625301419378711\n",
            "Total Loss: 0.003540207326189779\n",
            "----------------------------------------\n",
            "Epoch 267\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0032527105241967422\n",
            "SCOPE mean: 0.10940153967409832, SCOPE var: 0.0004615613679753888\n",
            "Total Loss: 0.003534632122998022\n",
            "----------------------------------------\n",
            "Epoch 268\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0032486258190690277\n",
            "SCOPE mean: 0.10909319566071406, SCOPE var: 0.00046037825046824933\n",
            "Total Loss: 0.0035289704510119\n",
            "----------------------------------------\n",
            "Epoch 269\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0032437282890224062\n",
            "SCOPE mean: 0.10885860966089572, SCOPE var: 0.00046062884145950226\n",
            "Total Loss: 0.003524673730081479\n",
            "----------------------------------------\n",
            "Epoch 270\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003236913080560749\n",
            "SCOPE mean: 0.10917110163976519, SCOPE var: 0.00046084083365614017\n",
            "Total Loss: 0.003519382582904368\n",
            "----------------------------------------\n",
            "Epoch 271\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0032298318884218854\n",
            "SCOPE mean: 0.10982136902635943, SCOPE var: 0.00046050371201688357\n",
            "Total Loss: 0.003514445634034755\n",
            "----------------------------------------\n",
            "Epoch 272\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0032247971186454864\n",
            "SCOPE mean: 0.10993815993240302, SCOPE var: 0.00045826352914294836\n",
            "Total Loss: 0.003509413859195904\n",
            "----------------------------------------\n",
            "Epoch 273\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0032211387734305754\n",
            "SCOPE mean: 0.1095834159889871, SCOPE var: 0.00045625492492352044\n",
            "Total Loss: 0.0035040319968011164\n",
            "----------------------------------------\n",
            "Epoch 274\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003217405449340008\n",
            "SCOPE mean: 0.10934190693334403, SCOPE var: 0.0004547205920060871\n",
            "Total Loss: 0.0034991903407587954\n",
            "----------------------------------------\n",
            "Epoch 275\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0032129808853396586\n",
            "SCOPE mean: 0.10934999465394162, SCOPE var: 0.00045356230863756485\n",
            "Total Loss: 0.0034943184101685182\n",
            "----------------------------------------\n",
            "Epoch 276\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003207733649325763\n",
            "SCOPE mean: 0.1095865232790687, SCOPE var: 0.0004531458849672159\n",
            "Total Loss: 0.0034894752607520065\n",
            "----------------------------------------\n",
            "Epoch 277\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003202892134805878\n",
            "SCOPE mean: 0.10954794422343724, SCOPE var: 0.000451173664400251\n",
            "Total Loss: 0.0034846917432758764\n",
            "----------------------------------------\n",
            "Epoch 278\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0031971508561392968\n",
            "SCOPE mean: 0.10931107196263123, SCOPE var: 0.0004490144461088967\n",
            "Total Loss: 0.0034797180310631656\n",
            "----------------------------------------\n",
            "Epoch 279\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0031921688694955637\n",
            "SCOPE mean: 0.10891814104157452, SCOPE var: 0.00044603399660223355\n",
            "Total Loss: 0.003475538311355147\n",
            "----------------------------------------\n",
            "Epoch 280\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0031859466213652082\n",
            "SCOPE mean: 0.10897085068246974, SCOPE var: 0.0004438545700450543\n",
            "Total Loss: 0.0034706798284818603\n",
            "----------------------------------------\n",
            "Epoch 281\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0031793083459018285\n",
            "SCOPE mean: 0.10932880901223666, SCOPE var: 0.0004420201947170238\n",
            "Total Loss: 0.0034659809365336866\n",
            "----------------------------------------\n",
            "Epoch 282\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003174609008123857\n",
            "SCOPE mean: 0.10918475642272894, SCOPE var: 0.0004387761159112748\n",
            "Total Loss: 0.00346142243936004\n",
            "----------------------------------------\n",
            "Epoch 283\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0031716142120065205\n",
            "SCOPE mean: 0.10865965830500815, SCOPE var: 0.00043592719585610235\n",
            "Total Loss: 0.0034564926024816716\n",
            "----------------------------------------\n",
            "Epoch 284\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0031698806997014577\n",
            "SCOPE mean: 0.10790213910020777, SCOPE var: 0.00043178431101337103\n",
            "Total Loss: 0.0034523528288781177\n",
            "----------------------------------------\n",
            "Epoch 285\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0031660775511842204\n",
            "SCOPE mean: 0.10772824316812257, SCOPE var: 0.0004277397789931165\n",
            "Total Loss: 0.003447663013726553\n",
            "----------------------------------------\n",
            "Epoch 286\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0031604861998375993\n",
            "SCOPE mean: 0.10804506053282945, SCOPE var: 0.00042437113531258296\n",
            "Total Loss: 0.0034428142898696354\n",
            "----------------------------------------\n",
            "Epoch 287\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003155721846271564\n",
            "SCOPE mean: 0.10822407668360001, SCOPE var: 0.0004219552084739115\n",
            "Total Loss: 0.003438697989478186\n",
            "----------------------------------------\n",
            "Epoch 288\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0031519590373538897\n",
            "SCOPE mean: 0.10801860635093222, SCOPE var: 0.0004189498578038439\n",
            "Total Loss: 0.003434266374189119\n",
            "----------------------------------------\n",
            "Epoch 289\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003149113888533641\n",
            "SCOPE mean: 0.10748550285692286, SCOPE var: 0.0004151207273602356\n",
            "Total Loss: 0.0034296439811756486\n",
            "----------------------------------------\n",
            "Epoch 290\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0031465303891793136\n",
            "SCOPE mean: 0.10690687432495993, SCOPE var: 0.0004114358459345603\n",
            "Total Loss: 0.003425635745630474\n",
            "----------------------------------------\n",
            "Epoch 291\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003141697027275614\n",
            "SCOPE mean: 0.10695206785634484, SCOPE var: 0.00040927544432987944\n",
            "Total Loss: 0.0034209276103321583\n",
            "----------------------------------------\n",
            "Epoch 292\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0031359850150105974\n",
            "SCOPE mean: 0.10731822915341914, SCOPE var: 0.0004082307236400817\n",
            "Total Loss: 0.0034170715153243173\n",
            "----------------------------------------\n",
            "Epoch 293\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0031304832984235683\n",
            "SCOPE mean: 0.10735250151616733, SCOPE var: 0.0004069746505934338\n",
            "Total Loss: 0.0034124188472649335\n",
            "----------------------------------------\n",
            "Epoch 294\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0031263640638852183\n",
            "SCOPE mean: 0.10700663805016301, SCOPE var: 0.0004043013204994281\n",
            "Total Loss: 0.0034079421766915353\n",
            "----------------------------------------\n",
            "Epoch 295\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0031234786509992817\n",
            "SCOPE mean: 0.1064446107728887, SCOPE var: 0.0004007220250049498\n",
            "Total Loss: 0.003404069432304795\n",
            "----------------------------------------\n",
            "Epoch 296\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0031196524734891256\n",
            "SCOPE mean: 0.10624818434250706, SCOPE var: 0.00039817040866139465\n",
            "Total Loss: 0.0034001133996158584\n",
            "----------------------------------------\n",
            "Epoch 297\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0031141967650172727\n",
            "SCOPE mean: 0.10661256538512091, SCOPE var: 0.0003973077739936152\n",
            "Total Loss: 0.00339566173664373\n",
            "----------------------------------------\n",
            "Epoch 298\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0031089150758450623\n",
            "SCOPE mean: 0.10711522123448049, SCOPE var: 0.0003967202905846069\n",
            "Total Loss: 0.003391969502592861\n",
            "----------------------------------------\n",
            "Epoch 299\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003105520132431105\n",
            "SCOPE mean: 0.10717766164191846, SCOPE var: 0.0003960984054795584\n",
            "Total Loss: 0.003387937704849216\n",
            "----------------------------------------\n",
            "Epoch 300\n",
            "IS variance:  tensor(4.8629e-09, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003103802907982472\n",
            "SCOPE mean: 0.10673434170837459, SCOPE var: 0.0003937199902593215\n",
            "Total Loss: 0.0033835209443496936\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[-0.0877, -0.1790],\n",
            "        [-0.0263, -0.0670],\n",
            "        [ 0.6181,  0.2938],\n",
            "        [-0.6721,  0.1251],\n",
            "        [ 0.8347, -0.1682],\n",
            "        [-0.0077, -0.1497],\n",
            "        [-0.6120,  0.0066],\n",
            "        [-0.0453,  0.2553],\n",
            "        [ 0.7401,  0.1473],\n",
            "        [ 0.1039,  0.2418],\n",
            "        [-0.5825, -0.5235],\n",
            "        [-0.5225, -0.4385],\n",
            "        [-0.7701, -0.0069],\n",
            "        [ 0.3131, -0.3647],\n",
            "        [ 0.7306, -0.1804],\n",
            "        [ 0.2702,  0.0505]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([ 0.8951,  0.3808, -0.5925,  0.4947, -0.1630,  0.7495, -0.6856,  0.3197,\n",
            "        -0.3123, -0.6056, -0.1913, -0.3826,  0.3940,  0.6258,  0.1614, -0.7394],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[-1.6561e-01, -4.9582e-01, -2.1159e-01, -1.5096e-01,  1.5757e-01,\n",
            "         -2.2262e-01,  1.4583e-01,  1.5295e-01, -3.8207e-01, -5.4891e-02,\n",
            "          2.4297e-01, -1.3673e-01, -4.4588e-02, -2.1587e-01, -5.0986e-02,\n",
            "         -3.2025e-02],\n",
            "        [ 4.7171e-01, -3.2169e-01, -5.2778e-04, -2.1516e-01, -3.5009e-01,\n",
            "         -4.0657e-01, -1.4454e-01,  3.4643e-02, -1.7623e-01,  6.6261e-02,\n",
            "         -2.2206e-01, -2.4215e-01,  2.8475e-01, -1.4135e-01, -1.5923e-01,\n",
            "         -1.6243e-01],\n",
            "        [ 4.6153e-01,  7.3011e-01, -1.8013e-02, -6.0121e-02, -4.4696e-02,\n",
            "          2.9997e-01,  2.2910e-01,  4.1706e-02, -4.5291e-02, -4.7610e-02,\n",
            "          7.8982e-02, -9.0411e-02,  1.7150e-01,  1.6771e-01, -1.8214e-02,\n",
            "         -2.9280e-01],\n",
            "        [-8.6335e-02,  1.1694e-01, -6.2918e-02, -2.7560e-01, -2.8005e-01,\n",
            "          2.3557e-01, -1.4361e-01, -4.0142e-02, -2.2938e-01, -2.1906e-01,\n",
            "         -7.3527e-02, -1.6425e-01, -1.0430e-01,  3.5750e-02,  1.9500e-01,\n",
            "         -1.7599e-01],\n",
            "        [ 7.3969e-02,  3.0852e-01, -2.6388e-02, -1.2095e-01, -7.5499e-03,\n",
            "          1.8529e-02, -1.6649e-01,  8.0963e-04, -4.0672e-02, -4.6442e-02,\n",
            "          1.2140e-01, -1.0947e-02,  2.5067e-01,  7.9171e-02,  1.5540e-02,\n",
            "         -1.8668e-01],\n",
            "        [ 6.5403e-01,  5.7493e-01,  4.8159e-03,  1.8599e-01, -2.5408e-02,\n",
            "          4.3112e-01, -1.1532e-02,  9.0374e-03,  1.1662e-02, -2.2571e-02,\n",
            "          2.2387e-01,  1.0505e-01,  1.1700e-01, -1.7120e-01, -3.1277e-02,\n",
            "         -1.6742e-01],\n",
            "        [ 1.4644e-01, -3.7668e-03,  2.1390e-02,  6.6828e-02, -1.1666e-01,\n",
            "         -1.4534e-02, -2.3978e-01, -2.5528e-01,  4.9150e-02, -5.4667e-02,\n",
            "          2.0770e-01, -6.2762e-02,  2.4595e-01, -6.1009e-01, -1.4962e-01,\n",
            "         -8.6776e-02],\n",
            "        [ 6.4539e-02,  7.3758e-02,  8.3243e-03,  1.3023e-01, -5.3837e-02,\n",
            "          9.2122e-02,  1.0823e-01, -7.1207e-02, -1.4976e-02, -6.7318e-02,\n",
            "         -1.1448e-01, -2.7665e-02, -7.5748e-02,  1.7401e-01, -4.0851e-02,\n",
            "         -2.2969e-01],\n",
            "        [-2.9038e-01, -3.8443e-01, -4.1356e-01,  1.3129e-01, -3.8546e-02,\n",
            "         -7.7533e-01,  3.3424e-02,  1.3640e-01,  8.5833e-02, -1.1520e-01,\n",
            "         -2.0898e-01,  1.0012e-01, -1.6629e-01, -4.5634e-01,  2.6882e-01,\n",
            "          8.0638e-02],\n",
            "        [ 3.6873e-01,  2.2938e-01,  1.9040e-02, -5.4091e-02, -3.6043e-01,\n",
            "          5.2373e-01,  1.5495e-01,  4.4765e-02, -4.5602e-02,  1.5383e-01,\n",
            "         -1.1588e-01,  2.0708e-01,  3.1877e-01, -7.7033e-01, -3.1158e-01,\n",
            "         -5.0315e-01],\n",
            "        [-2.3802e-01, -2.2495e-01,  1.4086e-01, -4.5303e-01, -1.4097e-01,\n",
            "         -1.6973e-01,  1.4947e-02, -6.1115e-02, -2.5137e-01, -4.7358e-02,\n",
            "         -1.8084e-01,  1.7568e-01, -3.6769e-01, -1.8258e-01, -1.7821e-03,\n",
            "         -8.7789e-04],\n",
            "        [ 5.6525e-01,  1.8706e-01, -4.0367e-02,  1.8563e-02, -4.4220e-02,\n",
            "          6.4572e-01, -1.9286e-01,  1.3876e-02, -6.4903e-03,  5.2257e-02,\n",
            "         -2.1854e-02,  6.2092e-03,  3.1173e-01, -1.9014e-01, -6.3095e-02,\n",
            "         -3.9550e-01],\n",
            "        [-6.9680e-01, -4.3778e-01,  4.2209e-02,  2.2431e-02,  5.4967e-02,\n",
            "         -6.9264e-01, -2.0478e-01, -2.3165e-02,  7.2714e-02, -4.4005e-02,\n",
            "         -8.5319e-02,  1.7251e-01, -1.0983e-01, -3.2041e-01,  3.3659e-02,\n",
            "          1.1821e-01],\n",
            "        [-3.5867e-01, -3.7601e-01,  7.1954e-02,  5.3616e-03,  4.5305e-02,\n",
            "         -5.3541e-01, -1.5954e-01,  8.3633e-02, -4.2136e-01, -5.0920e-02,\n",
            "         -1.9452e-01,  1.6456e-01,  4.5148e-02, -5.3399e-02,  1.5514e-01,\n",
            "          1.5522e-01],\n",
            "        [ 2.4572e-01,  4.6240e-01, -3.4734e-02,  2.0392e-01,  2.5266e-02,\n",
            "          1.5208e-01,  1.3956e-01,  4.3363e-02, -1.9352e-02, -1.7897e-01,\n",
            "         -2.4190e-01,  2.4075e-01, -9.1337e-02,  1.6869e-01,  3.0908e-02,\n",
            "         -3.2930e-01],\n",
            "        [-3.7748e-02, -5.2424e-01, -1.7245e-01,  1.3329e-01,  1.1630e-01,\n",
            "         -1.1846e-01, -6.0918e-02, -5.6433e-02, -2.6627e-01, -2.2710e-01,\n",
            "          1.7257e-03,  8.1709e-02,  7.1921e-02, -1.7144e-01, -2.2043e-01,\n",
            "         -3.3642e-01]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([-0.0482, -0.1387,  0.3048, -0.0314,  0.2645,  0.0603,  0.0863,  0.4119,\n",
            "        -0.2643,  0.1872, -0.2422,  0.2689, -0.1611, -0.0052,  0.3076,  0.0811],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[-0.1535,  0.2736,  0.0669, -0.1567,  0.2036,  0.0881,  0.0843,  0.0951,\n",
            "         -0.0909,  0.0482, -0.2397,  0.0859, -0.2133, -0.0811,  0.0866, -0.2398]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([0.2796], dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomizableFeatureNet(\n",
              "  (hidden_layers): ModuleList(\n",
              "    (0): Linear(in_features=2, out_features=16, bias=True)\n",
              "    (1): Linear(in_features=16, out_features=16, bias=True)\n",
              "  )\n",
              "  (output_layer): Linear(in_features=16, out_features=1, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_600_random_pi_b.get_heatmap()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "3884afa8-d588-4260-fe9b-35481ea89c4a",
        "id": "qxCN1FxM8-7I"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"c3c24299-f964-4c27-8af7-44053bae0079\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"c3c24299-f964-4c27-8af7-44053bae0079\")) {                    Plotly.newPlot(                        \"c3c24299-f964-4c27-8af7-44053bae0079\",                        [{\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"z\":[[0.8858908164275113,0.7763566550925447,0.7314032283740581,0.67157376332682,0.5805711024235962,0.5037727628680565,0.44525573699577936,0.3980793399780433,0.35090017352644726,0.3286526089832684],[0.8208378017229481,0.7006961628719688,0.6520203298222498,0.5842765666688415,0.4916122427548182,0.4238015848473583,0.37591037646115616,0.3287339794434201,0.3155734207542048,0.30988336250862664],[0.756616207996441,0.6322209075075444,0.5698894828516128,0.490902368615006,0.4063467923806143,0.35374141294426903,0.31167876832317853,0.3044583694487271,0.2799374670040755,0.25423227212437366],[0.6686546969638634,0.5598308739215838,0.48276219293771844,0.3958607805949417,0.33157244942738184,0.28816042006362175,0.26245522518392,0.2373190204469896,0.2151206058929018,0.19292219133881391],[0.5827235905114474,0.4848589805042022,0.4007458107438606,0.29386062735470386,0.2449729833637645,0.22176358585564884,0.19988860311961476,0.1820188108795932,0.1641490186395717,0.1462792263995502],[0.4978584830675801,0.42294359324651276,0.33716113307565954,0.2326297635740599,0.1935979100559494,0.17686184860453166,0.16012578715311393,0.1433897257016963,0.12665366425027852,0.10991760279886081],[0.47782837774799947,0.4099518603277185,0.32066724812299796,0.228573545594032,0.19043944165115534,0.15253359228418503,0.13579753083276735,0.11906146938134968,0.10232540792993197,0.0855893464785143],[0.46873623374058315,0.4015523604842476,0.310220519392063,0.22916657985240255,0.19103247590952588,0.15289837196664918,0.11476426802377254,0.09473321306100307,0.0779971516095854,0.061261090158167664],[0.45964408973316684,0.3988043100595555,0.3128721191044219,0.22975961411077309,0.19162551016789645,0.15349140622501978,0.11535730228214308,0.07722319833926647,0.053668895289238766,0.03693283383782106],[0.45351897957081166,0.3985256474782122,0.3185832475290697,0.23035264836914363,0.19221854442626696,0.15408444048339026,0.11595033654051362,0.07781623259763701,0.03968212865476034,0.012604577517474513]],\"type\":\"heatmap\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"Values\"},\"ticks\":\"outside\",\"tickvals\":[0.012604577517474513,0.8858908164275113],\"ticktext\":[0.012604577517474513,0.8858908164275113]}},\"xaxis\":{\"tickvals\":[0,1,2,3,4,5,6,7,8,9],\"ticktext\":[0,1,2,3,4,5,6,7,8,9],\"title\":{\"text\":\"X\"}},\"yaxis\":{\"tickvals\":[9,8,7,6,5,4,3,2,1,0],\"ticktext\":[9,8,7,6,5,4,3,2,1,0],\"title\":{\"text\":\"Y\"},\"autorange\":\"reversed\"},\"title\":{\"text\":\"Heatmap\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('c3c24299-f964-4c27-8af7-44053bae0079');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calc_V_pi_e(pi_e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a5adf0e-2ddc-4156-e8ea-2a7847c9637d",
        "id": "fmUGc3Qa8-7J"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.15891747325670808"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_600_random_pi_b.evaluate_scope()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2136b70a-a896-4e6a-dad2-b3cb1ccaa447",
        "id": "clQP5lGU8-7J"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1061, dtype=torch.float64, grad_fn=<MeanBackward0>),\n",
              " tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test model with l2 reg\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "M7ibGqVUyQ3_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "class CustomizableFeatureNet(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dims, output_dim, dropout_prob=0.2, l2_lambda=0.01, dtype=torch.float32):\n",
        "        super(CustomizableFeatureNet, self).__init__()\n",
        "        self.hidden_layers = nn.ModuleList()\n",
        "\n",
        "        # Create the hidden layers based on the provided sizes\n",
        "        for in_dim, out_dim in zip([input_dim] + hidden_dims, hidden_dims):\n",
        "            layer = nn.Linear(in_dim, out_dim).to(dtype)\n",
        "            self.hidden_layers.append(layer)\n",
        "\n",
        "        self.output_layer = nn.Linear(hidden_dims[-1], output_dim).to(dtype)\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "        self.l2_lambda = l2_lambda\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.hidden_layers:\n",
        "            x = F.relu(layer(x))\n",
        "            x = self.dropout(x)\n",
        "        x = self.output_layer(x)\n",
        "        return x\n",
        "\n",
        "    def l2_regularization(self):\n",
        "        l2_reg = torch.tensor(0., device=self.output_layer.weight.device)\n",
        "        for layer in self.hidden_layers:\n",
        "            l2_reg += torch.norm(layer.weight)\n",
        "        l2_reg += torch.norm(self.output_layer.weight)\n",
        "        return self.l2_lambda * l2_reg\n"
      ],
      "metadata": {
        "id": "38YlzOUWyTgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test 800 pi_b top 2"
      ],
      "metadata": {
        "id": "ozpJbcWKSDp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b = action_probs_top_n_epsilon(q_table, 1, 0.4)\n",
        "pi_b = experiment_actions(800, env_50, P_pi_b)\n",
        "P_pi_e = action_probs_top_n_epsilon(q_table, 1, 0.05)\n",
        "pi_e = experiment_actions(1000, env_50, P_pi_e)\n",
        "model_800_random_pi_b = CustomizableFeatureNet(input_dim=2, hidden_dims=[10, 10], output_dim=1, dtype = torch.float64, l2_lambda=0.001)\n",
        "test_800_random_pi_b = SCOPE_straight(model_800_random_pi_b, 0.99, 10000, pi_b, P_pi_b, P_pi_e, 0.3, dtype = torch.float64)\n"
      ],
      "metadata": {
        "id": "leaujDCkSDqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_800_random_pi_b.IS_pipeline()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b161c2e9-42f8-436c-fcd3-f8e19afc5cb0",
        "id": "8KclL3PQSDqA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.5781, dtype=torch.float64), tensor(0.0772, dtype=torch.float64))"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_800_random_pi_b.get_state_visitation_heatmap()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "925d6c95-a236-477d-b18f-c24aff9fd864",
        "id": "EXPS_zUeSDqA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"91c45e49-6185-443c-953e-c9958bf92584\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"91c45e49-6185-443c-953e-c9958bf92584\")) {                    Plotly.newPlot(                        \"91c45e49-6185-443c-953e-c9958bf92584\",                        [{\"colorbar\":{\"title\":{\"text\":\"Visits\"}},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"x\":[0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9],\"y\":[9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0],\"z\":[0,9,26,215,1296,1353,1394,1442,1003,1159,0,24,167,1043,1199,0,436,806,566,1371,0,128,943,1107,302,0,114,216,327,1512,0,875,1040,371,112,0,24,76,117,378,0,1108,379,143,44,0,7,13,32,68,597,961,165,51,14,0,1,6,5,12,130,204,55,19,8,0,1,7,4,16,25,43,12,10,3,0,1,5,6,11,2,13,5,5,1,0,2,4,5,13,0,1,1,1,0,0,1,3,4,10],\"zmax\":1512,\"zmin\":0,\"type\":\"heatmap\"}],                        {\"title\":{\"text\":\"State Visitations Heatmap\"},\"xaxis\":{\"title\":{\"text\":\"X-axis\"}},\"yaxis\":{\"ticktext\":[9,8,7,6,5,4,3,2,1,0],\"tickvals\":[0,1,2,3,4,5,6,7,8,9],\"title\":{\"text\":\"Y-axis\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('91c45e49-6185-443c-953e-c9958bf92584');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_800_random_pi_b.train_var_scope(50, 0.0005)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "773939a1-fb4b-4e96-f261-88064287563e",
        "id": "d9aHaKyqSDqB"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "IS variance:  tensor(0.0772, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0044, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.004218989771201134\n",
            "SCOPE mean: 0.22285763285074944, SCOPE var: 0.016886603818618454\n",
            "Total Loss: 0.008665766088156722\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "IS variance:  tensor(0.0772, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.004043985329936416\n",
            "SCOPE mean: 0.21677965178133518, SCOPE var: 0.01643719341992325\n",
            "Total Loss: 0.004883264246003726\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "IS variance:  tensor(0.0772, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.004032811828319944\n",
            "SCOPE mean: 0.2141315282737515, SCOPE var: 0.016257919950321238\n",
            "Total Loss: 0.00487736908343905\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "IS variance:  tensor(0.0772, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0040190097982142955\n",
            "SCOPE mean: 0.21347469095999014, SCOPE var: 0.01622654360761761\n",
            "Total Loss: 0.0048701303764725895\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "IS variance:  tensor(0.0772, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.004007672329430603\n",
            "SCOPE mean: 0.21365403371635572, SCOPE var: 0.016258323140711194\n",
            "Total Loss: 0.004861727701200513\n",
            "----------------------------------------\n",
            "Epoch 6\n",
            "IS variance:  tensor(0.0772, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003998420692612137\n",
            "SCOPE mean: 0.2143371941730964, SCOPE var: 0.0163246239113178\n",
            "Total Loss: 0.004852084073530522\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "IS variance:  tensor(0.0772, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0039905149291199265\n",
            "SCOPE mean: 0.21538282470245057, SCOPE var: 0.01641750234169797\n",
            "Total Loss: 0.004841258337113035\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "IS variance:  tensor(0.0772, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.00398379913957755\n",
            "SCOPE mean: 0.21668231306337257, SCOPE var: 0.016531344326348292\n",
            "Total Loss: 0.004829905305720856\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "IS variance:  tensor(0.0772, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003976850269027913\n",
            "SCOPE mean: 0.21819346745026505, SCOPE var: 0.01666473950460398\n",
            "Total Loss: 0.0048187242718685\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "IS variance:  tensor(0.0772, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003968780023108742\n",
            "SCOPE mean: 0.219874191700736, SCOPE var: 0.016815586920519054\n",
            "Total Loss: 0.004807301628925931\n",
            "----------------------------------------\n",
            "Epoch 11\n",
            "IS variance:  tensor(0.0772, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003959963254802076\n",
            "SCOPE mean: 0.22160975192604415, SCOPE var: 0.016976224744427008\n",
            "Total Loss: 0.0047955670674282224\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "IS variance:  tensor(0.0772, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003950640329466868\n",
            "SCOPE mean: 0.2233086897135071, SCOPE var: 0.01713956433593889\n",
            "Total Loss: 0.004783918307200096\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "IS variance:  tensor(0.0772, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003941387545853619\n",
            "SCOPE mean: 0.224851870710785, SCOPE var: 0.01729596721980582\n",
            "Total Loss: 0.004772256641442606\n",
            "----------------------------------------\n",
            "Epoch 14\n",
            "IS variance:  tensor(0.0772, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0039322569270233585\n",
            "SCOPE mean: 0.22619122795805296, SCOPE var: 0.017440146162482517\n",
            "Total Loss: 0.004760579324187314\n",
            "----------------------------------------\n",
            "Epoch 15\n",
            "IS variance:  tensor(0.0772, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003923320178412601\n",
            "SCOPE mean: 0.22729823086940204, SCOPE var: 0.01756832831775872\n",
            "Total Loss: 0.004748928781912699\n",
            "----------------------------------------\n",
            "Epoch 16\n",
            "IS variance:  tensor(0.0772, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003914511813786572\n",
            "SCOPE mean: 0.22817365259286754, SCOPE var: 0.01767795716756328\n",
            "Total Loss: 0.004737346982908531\n",
            "----------------------------------------\n",
            "Epoch 17\n",
            "IS variance:  tensor(0.0772, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003905496760106183\n",
            "SCOPE mean: 0.2289201934525495, SCOPE var: 0.01777142023864361\n",
            "Total Loss: 0.004726039599191369\n",
            "----------------------------------------\n",
            "Epoch 18\n",
            "IS variance:  tensor(0.0772, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003896084836885273\n",
            "SCOPE mean: 0.22963100522277854, SCOPE var: 0.017850415453862567\n",
            "Total Loss: 0.004714872645496301\n",
            "----------------------------------------\n",
            "Epoch 19\n",
            "IS variance:  tensor(0.0772, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003885921892439823\n",
            "SCOPE mean: 0.2300550145810472, SCOPE var: 0.017896696588604006\n",
            "Total Loss: 0.004703548394087714\n",
            "----------------------------------------\n",
            "Epoch 20\n",
            "IS variance:  tensor(0.0772, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0038754532916501017\n",
            "SCOPE mean: 0.23030545985269377, SCOPE var: 0.01791521198204723\n",
            "Total Loss: 0.00469221547680657\n",
            "----------------------------------------\n",
            "Epoch 21\n",
            "IS variance:  tensor(0.0772, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003865147162408521\n",
            "SCOPE mean: 0.2303999744296794, SCOPE var: 0.01790683248478544\n",
            "Total Loss: 0.004681103227671362\n",
            "----------------------------------------\n",
            "Epoch 22\n",
            "IS variance:  tensor(0.0772, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0038551531138523803\n",
            "SCOPE mean: 0.23044886728360278, SCOPE var: 0.01788951217166084\n",
            "Total Loss: 0.004670258403642456\n",
            "----------------------------------------\n",
            "Epoch 23\n",
            "IS variance:  tensor(0.0772, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003845913347855735\n",
            "SCOPE mean: 0.23037471125891876, SCOPE var: 0.017860459211872067\n",
            "Total Loss: 0.004659360321660601\n",
            "----------------------------------------\n",
            "Epoch 24\n",
            "IS variance:  tensor(0.0772, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0038373940659905616\n",
            "SCOPE mean: 0.23018466440751512, SCOPE var: 0.01782151299312816\n",
            "Total Loss: 0.004648360772119251\n",
            "----------------------------------------\n",
            "Epoch 25\n",
            "IS variance:  tensor(0.0772, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0038295054490168575\n",
            "SCOPE mean: 0.22990980874625225, SCOPE var: 0.01777558901187161\n",
            "Total Loss: 0.004637308608896641\n",
            "----------------------------------------\n",
            "Epoch 26\n",
            "IS variance:  tensor(0.0772, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0038222010763517625\n",
            "SCOPE mean: 0.22959084035540664, SCOPE var: 0.01772616799861862\n",
            "Total Loss: 0.00462634812229896\n",
            "----------------------------------------\n",
            "Epoch 27\n",
            "IS variance:  tensor(0.0772, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0038151270239045764\n",
            "SCOPE mean: 0.2291349946508115, SCOPE var: 0.01766565848558661\n",
            "Total Loss: 0.004615593735790009\n",
            "----------------------------------------\n",
            "Epoch 28\n",
            "IS variance:  tensor(0.0772, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0038080157231529057\n",
            "SCOPE mean: 0.22861673363097598, SCOPE var: 0.017600454981004685\n",
            "Total Loss: 0.004604914414169203\n",
            "----------------------------------------\n",
            "Epoch 29\n",
            "IS variance:  tensor(0.0772, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003800431627432412\n",
            "SCOPE mean: 0.2282582060528699, SCOPE var: 0.017548352654507365\n",
            "Total Loss: 0.004594189425436751\n",
            "----------------------------------------\n",
            "Epoch 30\n",
            "IS variance:  tensor(0.0772, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0037925411298710934\n",
            "SCOPE mean: 0.22807957530824724, SCOPE var: 0.01750836323679968\n",
            "Total Loss: 0.004583472994349075\n",
            "----------------------------------------\n",
            "Epoch 31\n",
            "IS variance:  tensor(0.0772, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0037842815534426173\n",
            "SCOPE mean: 0.22793201382932435, SCOPE var: 0.017471856448754618\n",
            "Total Loss: 0.004572837652370811\n",
            "----------------------------------------\n",
            "Epoch 32\n",
            "IS variance:  tensor(0.0772, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0037760497077957964\n",
            "SCOPE mean: 0.22793998099953186, SCOPE var: 0.01744998845410008\n",
            "Total Loss: 0.004562463423380962\n",
            "----------------------------------------\n",
            "Epoch 33\n",
            "IS variance:  tensor(0.0772, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0037684404585538096\n",
            "SCOPE mean: 0.22808583049123854, SCOPE var: 0.017446116996570168\n",
            "Total Loss: 0.00455235438663873\n",
            "----------------------------------------\n",
            "Epoch 34\n",
            "IS variance:  tensor(0.0772, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003761288529232632\n",
            "SCOPE mean: 0.22821921097919717, SCOPE var: 0.017455516075272223\n",
            "Total Loss: 0.004542091418274273\n",
            "----------------------------------------\n",
            "Epoch 35\n",
            "IS variance:  tensor(0.0772, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003753551447878459\n",
            "SCOPE mean: 0.2285034567927583, SCOPE var: 0.017490111721523968\n",
            "Total Loss: 0.004531963090222761\n",
            "----------------------------------------\n",
            "Epoch 36\n",
            "IS variance:  tensor(0.0772, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003744993594231816\n",
            "SCOPE mean: 0.22879609578748236, SCOPE var: 0.01753784913129293\n",
            "Total Loss: 0.004521636602312158\n",
            "----------------------------------------\n",
            "Epoch 37\n",
            "IS variance:  tensor(0.0772, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003736066749635213\n",
            "SCOPE mean: 0.22924128292152696, SCOPE var: 0.0176062512843646\n",
            "Total Loss: 0.004511392187197997\n",
            "----------------------------------------\n",
            "Epoch 38\n",
            "IS variance:  tensor(0.0772, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0037268987982296254\n",
            "SCOPE mean: 0.22980453840870424, SCOPE var: 0.0176910662867737\n",
            "Total Loss: 0.004501375661340909\n",
            "----------------------------------------\n",
            "Epoch 39\n",
            "IS variance:  tensor(0.0772, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0037185128913487424\n",
            "SCOPE mean: 0.2303362025169938, SCOPE var: 0.017779690460959025\n",
            "Total Loss: 0.004491139739893264\n",
            "----------------------------------------\n",
            "Epoch 40\n",
            "IS variance:  tensor(0.0772, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0037108057412312038\n",
            "SCOPE mean: 0.23086242469807103, SCOPE var: 0.017872219171476245\n",
            "Total Loss: 0.004480938097129126\n",
            "----------------------------------------\n",
            "Epoch 41\n",
            "IS variance:  tensor(0.0772, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0037029866554114587\n",
            "SCOPE mean: 0.23141418284358378, SCOPE var: 0.01796838959081834\n",
            "Total Loss: 0.004470937094221566\n",
            "----------------------------------------\n",
            "Epoch 42\n",
            "IS variance:  tensor(0.0772, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0036947238455791514\n",
            "SCOPE mean: 0.23181826256354401, SCOPE var: 0.018048260109380865\n",
            "Total Loss: 0.004461100191631557\n",
            "----------------------------------------\n",
            "Epoch 43\n",
            "IS variance:  tensor(0.0772, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003685663975261432\n",
            "SCOPE mean: 0.23217462034614594, SCOPE var: 0.018113434437673298\n",
            "Total Loss: 0.004451201419246511\n",
            "----------------------------------------\n",
            "Epoch 44\n",
            "IS variance:  tensor(0.0772, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0036761369430387903\n",
            "SCOPE mean: 0.23259685620538512, SCOPE var: 0.018172890273813767\n",
            "Total Loss: 0.0044412236592985795\n",
            "----------------------------------------\n",
            "Epoch 45\n",
            "IS variance:  tensor(0.0772, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0036664236385728984\n",
            "SCOPE mean: 0.23304060467382046, SCOPE var: 0.01822486893209552\n",
            "Total Loss: 0.004431427242798605\n",
            "----------------------------------------\n",
            "Epoch 46\n",
            "IS variance:  tensor(0.0772, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0036573836603262886\n",
            "SCOPE mean: 0.23332111927417137, SCOPE var: 0.018260693755445534\n",
            "Total Loss: 0.004421718815886274\n",
            "----------------------------------------\n",
            "Epoch 47\n",
            "IS variance:  tensor(0.0772, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0036489940933725484\n",
            "SCOPE mean: 0.2334356407194654, SCOPE var: 0.018281407302041888\n",
            "Total Loss: 0.00441192237360017\n",
            "----------------------------------------\n",
            "Epoch 48\n",
            "IS variance:  tensor(0.0772, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003641016047292704\n",
            "SCOPE mean: 0.233513050991506, SCOPE var: 0.0182935817970373\n",
            "Total Loss: 0.004402356810689165\n",
            "----------------------------------------\n",
            "Epoch 49\n",
            "IS variance:  tensor(0.0772, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.0036323260220775767\n",
            "SCOPE mean: 0.23355418520768673, SCOPE var: 0.018296352023747516\n",
            "Total Loss: 0.004392755037584679\n",
            "----------------------------------------\n",
            "Epoch 50\n",
            "IS variance:  tensor(0.0772, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.003623236855669545\n",
            "SCOPE mean: 0.2337837208448738, SCOPE var: 0.018311651651489593\n",
            "Total Loss: 0.004383175308128767\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[-0.0612, -0.1346],\n",
            "        [ 0.4817, -0.5663],\n",
            "        [ 0.2014, -0.7416],\n",
            "        [-0.6795, -0.5101],\n",
            "        [ 0.2557, -0.8669],\n",
            "        [ 0.1575, -0.9013],\n",
            "        [-0.3675,  0.0699],\n",
            "        [ 0.1907, -0.8611],\n",
            "        [-0.0591, -0.0361],\n",
            "        [ 0.1867,  0.0654]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([ 0.6976, -0.3128, -0.0700, -0.2926, -0.2872, -0.3599, -0.1033, -0.4716,\n",
            "         0.3315,  0.1339], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[ 0.0478,  0.1619, -0.5250, -0.2989, -0.2221, -0.3277,  0.2590, -0.1465,\n",
            "          0.2154, -0.0704],\n",
            "        [ 0.1312,  0.0170, -0.3354,  0.0075, -0.2703,  0.0066,  0.1464, -0.0836,\n",
            "         -0.2829, -0.2884],\n",
            "        [ 0.1354,  0.0472,  0.4930, -0.0139,  0.2559,  0.7316, -0.0784,  0.5469,\n",
            "         -0.1280, -0.0878],\n",
            "        [-0.0214, -0.0741, -0.4346,  0.2888,  0.1128, -0.3162, -0.2182, -0.7672,\n",
            "         -0.5158,  0.2728],\n",
            "        [-0.0027, -0.0617,  0.2521,  0.1422,  0.4443,  0.1213, -0.2775,  0.7724,\n",
            "         -0.3448, -0.2898],\n",
            "        [ 0.0133,  0.1842, -0.3466,  0.2520, -0.0018, -0.2928, -0.0034,  0.0325,\n",
            "          0.1765, -0.1566],\n",
            "        [-0.2438,  0.0563, -0.2459, -0.2435, -0.0964, -0.3872, -0.2797, -0.1566,\n",
            "         -0.5999,  0.0699],\n",
            "        [ 0.0211,  0.0045, -0.2636,  0.0731, -0.2153, -0.0358, -0.0823, -0.5223,\n",
            "         -0.4867,  0.3853],\n",
            "        [-0.0263, -0.0219, -0.0988, -0.1116,  0.0721, -0.2424,  0.2299, -0.2484,\n",
            "          0.4078,  0.0660],\n",
            "        [ 0.3535, -0.0876, -0.1817, -0.1177,  0.1334, -0.1990, -0.2026,  0.1795,\n",
            "          0.2089,  0.0185]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([ 0.1265, -0.2448, -0.2949, -0.2758,  0.1437,  0.2573,  0.0275, -0.4261,\n",
            "         0.1329,  0.0246], dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[ 0.1810, -0.1317, -0.3003, -0.4834, -0.2319,  0.1839, -0.1618, -0.4326,\n",
            "          0.2241,  0.5599]], dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([0.3300], dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomizableFeatureNet(\n",
              "  (hidden_layers): ModuleList(\n",
              "    (0): Linear(in_features=2, out_features=10, bias=True)\n",
              "    (1): Linear(in_features=10, out_features=10, bias=True)\n",
              "  )\n",
              "  (output_layer): Linear(in_features=10, out_features=1, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_800_random_pi_b.get_heatmap()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "f0568bb5-bc68-4331-b6e4-0cdb52339d36",
        "id": "xLcm5WdvSDqB"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"6b197f79-adfe-47c9-b184-efb4b6c00d51\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"6b197f79-adfe-47c9-b184-efb4b6c00d51\")) {                    Plotly.newPlot(                        \"6b197f79-adfe-47c9-b184-efb4b6c00d51\",                        [{\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"z\":[[0.6760104019960433,0.6083830120929246,0.5200582100513629,0.31516317685886536,0.060003685899442716,-0.15983348333614844,-0.34567215022494113,-0.5177900198338858,-0.6899078894428303,-0.8620257590517748],[0.6374998541443884,0.605461887245633,0.5742021694596564,0.5466132024723995,0.5125986629634733,0.4404126686469562,0.42248662470843884,0.3608885454329949,0.2245073742111794,0.024631594535652945],[0.5984178913994906,0.566951339393978,0.5349133724952226,0.5028754055964673,0.46446068814443786,0.41749621108280605,0.3966480736199879,0.37401515693641274,0.3625342828141568,0.36464653856231066],[0.5588129220484035,0.5284407915423229,0.4964028246435676,0.4586416446835142,0.4131553517314275,0.35807799469985013,0.3278194420697342,0.304955707168464,0.28209197226719396,0.25922823736592376],[0.5192079526973163,0.4899302436906679,0.4528843457876549,0.4164880640341343,0.38417499309012815,0.3232431784367781,0.27292365189020856,0.23590172940431403,0.21303799450304398,0.19017425960177387],[0.4796029833462291,0.45600913653324227,0.42854374006898066,0.4096675194480403,0.3628300482068487,0.30189823355349854,0.2409664189001485,0.187769309080567,0.14398401673889394,0.12112028183762394],[0.4655496357474684,0.4405994161038271,0.41436863873782637,0.39922787642664087,0.3414851033235693,0.2805532886702191,0.2197234483011044,0.16462182824576577,0.1086346760388508,0.05806292836650867],[0.4647614611788284,0.4257412088315561,0.4125564550341225,0.38107197309363994,0.3201401584402898,0.2592083437869397,0.20026264109521902,0.14599410735084456,0.0928189483991439,0.037945213044259574],[0.4639732866101884,0.418539783300363,0.4081498570118643,0.3597270282103605,0.2987952135570104,0.23786339890366023,0.18080183388933374,0.12736638645592335,0.07419122750422252,0.021016068552521916],[0.4631851120415484,0.4187984933883074,0.39771021399046486,0.3383820833270811,0.2774502686737309,0.21689433469889646,0.16191382451270298,0.10873866556100217,0.05556350660930143,0.00238834765760082]],\"type\":\"heatmap\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"Values\"},\"ticks\":\"outside\",\"tickvals\":[-0.8620257590517748,0.6760104019960433],\"ticktext\":[-0.8620257590517748,0.6760104019960433]}},\"xaxis\":{\"tickvals\":[0,1,2,3,4,5,6,7,8,9],\"ticktext\":[0,1,2,3,4,5,6,7,8,9],\"title\":{\"text\":\"X\"}},\"yaxis\":{\"tickvals\":[9,8,7,6,5,4,3,2,1,0],\"ticktext\":[9,8,7,6,5,4,3,2,1,0],\"title\":{\"text\":\"Y\"},\"autorange\":\"reversed\"},\"title\":{\"text\":\"Heatmap\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('6b197f79-adfe-47c9-b184-efb4b6c00d51');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calc_V_pi_e(pi_e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f52cdfd-fa14-4ccc-a455-56ef2335e86c",
        "id": "4l9AhzcNSDqB"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15.720270087636253"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_800_random_pi_b.evaluate_scope()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9e626c4-9ada-4e50-e1c9-83b56be354af",
        "id": "NbARsqdFSDqB"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1058, dtype=torch.float64, grad_fn=<MeanBackward0>),\n",
              " tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test 800 pi_b weighted mse"
      ],
      "metadata": {
        "id": "ej6-ESaR1So0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b = action_probs_top_n_epsilon(q_table, 1, 0.4)\n",
        "pi_b = experiment_actions(800, env_50, P_pi_b)\n",
        "P_pi_e = action_probs_top_n_epsilon(q_table, 1, 0.05)\n",
        "pi_e = experiment_actions(1000, env_50, P_pi_e)\n",
        "model_800_random_pi_b = CustomizableFeatureNet(input_dim=2, hidden_dims=[16, 16], output_dim=1, dtype = torch.float64, l2_lambda=0.002)\n",
        "test_800_random_pi_b = SCOPE_straight(model_800_random_pi_b, 0.99, 10000, pi_b, P_pi_b, P_pi_e, 0.3, dtype = torch.float64)\n"
      ],
      "metadata": {
        "id": "yHebEV-d1So9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_800_random_pi_b = CustomizableFeatureNet(input_dim=2, hidden_dims=[16, 16], output_dim=1, dtype = torch.float64, l2_lambda=0.002)\n"
      ],
      "metadata": {
        "id": "mKtQgu_QN-zH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_800_random_pi_b.IS_pipeline()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7db7eb93-b82e-4844-ec41-21c7bb130b48",
        "id": "8CffL60Y1So9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.2171, dtype=torch.float64), tensor(0.0069, dtype=torch.float64))"
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_800_random_pi_b.get_state_visitation_heatmap()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "ef203b5c-cb05-459a-ba73-f8a876b14d11",
        "id": "TfL7Qrkk1So-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"c98d2fed-6d52-42c2-8d37-ec3f28a6f8fd\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"c98d2fed-6d52-42c2-8d37-ec3f28a6f8fd\")) {                    Plotly.newPlot(                        \"c98d2fed-6d52-42c2-8d37-ec3f28a6f8fd\",                        [{\"colorbar\":{\"title\":{\"text\":\"Visits\"}},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"x\":[0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9],\"y\":[9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0,9,8,7,6,5,4,3,2,1,0],\"z\":[0,0,38,214,1257,1427,1488,1416,970,1182,0,29,189,993,1104,0,485,844,515,1383,0,168,921,1112,328,0,146,242,316,1551,0,853,1021,373,123,0,45,73,121,345,0,1043,383,143,47,0,12,21,28,75,570,961,192,55,17,2,2,4,8,29,136,244,67,16,5,1,1,4,6,24,29,54,17,6,3,2,1,4,7,31,1,13,5,1,1,4,1,6,7,26,0,1,1,0,0,2,1,3,4,18],\"zmax\":1551,\"zmin\":0,\"type\":\"heatmap\"}],                        {\"title\":{\"text\":\"State Visitations Heatmap\"},\"xaxis\":{\"title\":{\"text\":\"X-axis\"}},\"yaxis\":{\"ticktext\":[9,8,7,6,5,4,3,2,1,0],\"tickvals\":[0,1,2,3,4,5,6,7,8,9],\"title\":{\"text\":\"Y-axis\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('c98d2fed-6d52-42c2-8d37-ec3f28a6f8fd');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_800_random_pi_b.train_var_scope(10, 0.001, 1, 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65caa397-8bec-4ef1-bfda-8d1a71eb625e",
        "id": "v2C_ZNpp1So-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "IS variance:  tensor(0.0069, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0014, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.634099954946919\n",
            "SCOPE mean: 0.17437900171241522, SCOPE var: 0.003946551824085135\n",
            "Total Loss: 0.0014133758367131921\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "IS variance:  tensor(0.0069, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6583666656390397\n",
            "SCOPE mean: 0.17819248489278255, SCOPE var: 0.00406334930797007\n",
            "Total Loss: 0.00047821039044280424\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "IS variance:  tensor(0.0069, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6769835730717948\n",
            "SCOPE mean: 0.18028760100370606, SCOPE var: 0.004121662484450746\n",
            "Total Loss: 0.00048106496886156304\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "IS variance:  tensor(0.0069, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6936482519788777\n",
            "SCOPE mean: 0.18167222092477195, SCOPE var: 0.004149620972114761\n",
            "Total Loss: 0.00048089274408397327\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "IS variance:  tensor(0.0069, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7082419783518359\n",
            "SCOPE mean: 0.18242009979722365, SCOPE var: 0.0041611887486439495\n",
            "Total Loss: 0.0004780593836415273\n",
            "----------------------------------------\n",
            "Epoch 6\n",
            "IS variance:  tensor(0.0069, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7204151322782572\n",
            "SCOPE mean: 0.18290008388288662, SCOPE var: 0.0041700708421646806\n",
            "Total Loss: 0.00047372152099642566\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "IS variance:  tensor(0.0069, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.730431866442183\n",
            "SCOPE mean: 0.18305946741745988, SCOPE var: 0.0041731432741280985\n",
            "Total Loss: 0.0004690516045707018\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "IS variance:  tensor(0.0069, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.739223420008507\n",
            "SCOPE mean: 0.1827720143401463, SCOPE var: 0.00416468098012006\n",
            "Total Loss: 0.00046419508411400654\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "IS variance:  tensor(0.0069, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.746626188689051\n",
            "SCOPE mean: 0.18218746404678587, SCOPE var: 0.0041483308208337295\n",
            "Total Loss: 0.00045936949880954955\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "IS variance:  tensor(0.0069, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7524510328144439\n",
            "SCOPE mean: 0.18146903204759293, SCOPE var: 0.004127923013507039\n",
            "Total Loss: 0.0004545985582303658\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[ 0.3475, -0.0780],\n",
            "        [ 0.4168, -0.6261],\n",
            "        [ 0.1427, -0.2536],\n",
            "        [-0.6795, -0.5101],\n",
            "        [ 0.3261, -0.4989],\n",
            "        [ 0.2113, -0.4052],\n",
            "        [-0.0943, -0.0490],\n",
            "        [ 0.0965, -0.5276],\n",
            "        [-0.1035, -0.1584],\n",
            "        [ 0.0549,  0.0371],\n",
            "        [ 0.2012,  0.0434],\n",
            "        [-0.2122, -0.2926],\n",
            "        [-0.1716, -0.4919],\n",
            "        [-0.2066, -0.5931],\n",
            "        [ 0.0409, -0.1333],\n",
            "        [-0.4428,  0.0496]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([-0.3780, -0.9607,  0.2454, -0.4146,  0.3704, -0.1599,  0.4540, -0.5357,\n",
            "         0.6250,  0.1294, -0.8181,  0.0168, -0.4960,  0.1372,  0.6547, -0.1266],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[ 0.1045, -0.1037, -0.0717,  0.1333,  0.0868, -0.1166,  0.0946,  0.2457,\n",
            "          0.3762,  0.0188, -0.1261, -0.1727, -0.1230, -0.2191, -0.0100,  0.0202],\n",
            "        [ 0.0961, -0.1410, -0.0236, -0.1953, -0.0204,  0.0894,  0.0886,  0.2109,\n",
            "          0.3192,  0.0134, -0.1269, -0.2232,  0.1200,  0.2395, -0.0566, -0.1866],\n",
            "        [ 0.0604,  0.0524, -0.1709,  0.1992,  0.0242, -0.1520,  0.1275,  0.1663,\n",
            "          0.2436, -0.0499, -0.1206,  0.1685, -0.2120, -0.1925,  0.1266, -0.3162],\n",
            "        [ 0.0755,  0.0549, -0.4751,  0.1861, -0.2768, -0.1060, -0.2535, -0.0205,\n",
            "         -0.2440,  0.2478,  0.0300, -0.1232, -0.0765,  0.2017, -0.0081, -0.0163],\n",
            "        [ 0.1059, -0.1310, -0.0215, -0.0274,  0.0790, -0.3323,  0.2255,  0.1090,\n",
            "          0.1827, -0.0859, -0.0739, -0.0931,  0.1759, -0.0908,  0.1826,  0.0860],\n",
            "        [ 0.0115,  0.0232,  0.1162, -0.1045, -0.0886, -0.0155,  0.2192,  0.1793,\n",
            "          0.4842, -0.1346,  0.0729, -0.0451,  0.0416, -0.1861, -0.0010, -0.0439],\n",
            "        [-0.0894,  0.3021,  0.0017, -0.2161,  0.0577,  0.1641, -0.4814, -0.0556,\n",
            "         -0.3400, -0.0618, -0.3122,  0.0260, -0.1448,  0.0232, -0.0650, -0.2884],\n",
            "        [ 0.0391, -0.0772, -0.1477,  0.1568, -0.0304, -0.2160,  0.0696,  0.1887,\n",
            "         -0.0959, -0.3994,  0.3060,  0.1421, -0.2307,  0.1671, -0.1490, -0.2438],\n",
            "        [-0.1513,  0.0365, -0.0303,  0.1350, -0.0245, -0.1388, -0.0334,  0.0172,\n",
            "          0.1272, -0.0265, -0.1136,  0.1062,  0.2066,  0.0431,  0.1240,  0.1250],\n",
            "        [ 0.0818, -0.0492, -0.0308,  0.2159, -0.1165,  0.0450, -0.2825, -0.1193,\n",
            "          0.4295,  0.0347, -0.0534,  0.2483,  0.0854, -0.0089,  0.1757,  0.1948],\n",
            "        [-0.2033,  0.1500,  0.0735,  0.0883, -0.0966,  0.1566, -0.0127, -0.1220,\n",
            "          0.1192,  0.1041,  0.0092,  0.0946,  0.2147, -0.1459, -0.1885,  0.0446],\n",
            "        [ 0.0321, -0.0977, -0.0888, -0.1682, -0.0380,  0.0283,  0.0561,  0.0480,\n",
            "          0.3430, -0.0747, -0.0663,  0.2195, -0.2329,  0.1855,  0.1177,  0.0633],\n",
            "        [-0.1092, -0.2306, -0.2322, -0.0164, -0.1863,  0.0544, -0.1892,  0.1185,\n",
            "         -0.3424,  0.0073, -0.1806,  0.1579,  0.0199,  0.0141, -0.1959,  0.0990],\n",
            "        [ 0.2019, -0.1766, -0.3349, -0.1432, -0.2250, -0.1679, -0.2639, -0.1027,\n",
            "         -0.4351,  0.1520,  0.1175,  0.1203,  0.1856, -0.0276,  0.1145,  0.0382],\n",
            "        [ 0.0450, -0.1722,  0.0774,  0.0664, -0.2021, -0.2892,  0.0347, -0.0900,\n",
            "          0.3325, -0.0635, -0.3239,  0.1396,  0.0472, -0.2465,  0.2580,  0.1148],\n",
            "        [ 0.0565,  0.0716, -0.1614,  0.0695, -0.0513,  0.0284, -0.0451, -0.0969,\n",
            "          0.2411, -0.1346, -0.1423,  0.2240, -0.1942,  0.0277, -0.0033, -0.0663]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([ 0.1548,  0.2125,  0.0880, -0.1085,  0.2331,  0.0920,  0.0336, -0.0058,\n",
            "         0.0754,  0.1479,  0.0390,  0.2074, -0.2107, -0.1646,  0.1826,  0.2049],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[ 0.1525,  0.0584,  0.1662, -0.1906,  0.1008,  0.1705, -0.2445, -0.3245,\n",
            "          0.1729,  0.0971,  0.0296,  0.1064, -0.1293, -0.1435,  0.0997,  0.1276]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([0.1736], dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomizableFeatureNet(\n",
              "  (hidden_layers): ModuleList(\n",
              "    (0): Linear(in_features=2, out_features=16, bias=True)\n",
              "    (1): Linear(in_features=16, out_features=16, bias=True)\n",
              "  )\n",
              "  (output_layer): Linear(in_features=16, out_features=1, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_800_random_pi_b.get_heatmap()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "c2b01aa9-6c16-48c9-e434-fa5c0a6121d9",
        "id": "i7kYxa001So-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"dca2349b-fab6-4ec0-8ef0-b72d7a101b58\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"dca2349b-fab6-4ec0-8ef0-b72d7a101b58\")) {                    Plotly.newPlot(                        \"dca2349b-fab6-4ec0-8ef0-b72d7a101b58\",                        [{\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"z\":[[0.6754387485613487,0.6139995287686788,0.5369899210105794,0.45273754634961705,0.33857112972265613,0.22713561876247518,0.14204938588035748,0.09928631095272877,0.07370808168904645,0.05170955379015743],[0.6335039774605329,0.5713674963456743,0.5141527816399721,0.4539115741479436,0.3853003127383346,0.28895531000749425,0.23740910831307077,0.18586290661864735,0.13815291335065183,0.10033540979425816],[0.5527576378047772,0.5057365479358414,0.46178923693016005,0.4098433226563114,0.3926595257800687,0.36792341458260974,0.3282860963544491,0.2966484638054967,0.24788943217889411,0.20186003273977882],[0.4720004439315073,0.4249902082800858,0.39782459655201585,0.4012105052886434,0.3881946049831454,0.3736013693858721,0.3590081337885986,0.3413187836433932,0.31207240998905617,0.28282603633471914],[0.39123012413159897,0.38338885391273025,0.37696063056731977,0.3767291136827325,0.35483193436487,0.33374436785483974,0.3367810346457727,0.32549684983033156,0.3238935058349828,0.3157562486526727],[0.37096990104888544,0.36460049220929447,0.358172268863884,0.35752539119551796,0.3324755149224789,0.31138794841244866,0.2903003819024185,0.27639568034026923,0.2891875177225313,0.2923226391489605],[0.3631051953097898,0.352828746233503,0.3394911326788616,0.3338969559283539,0.31040135926370904,0.2890315289700576,0.2679439624600274,0.24685608027267514,0.2141609868952337,0.20943751207598504],[0.35740245160581396,0.34714998267367986,0.33616706863483303,0.32173810161841454,0.2954181734828208,0.26993007544386544,0.2470597429534163,0.2258231424991023,0.19324875703775143,0.16067437157640052],[0.35169970790183813,0.33840782671305436,0.3328430045908044,0.31069637185374266,0.2836337120738651,0.2572669800000668,0.23641594157218224,0.21360444323968425,0.1774885505465457,0.14137265785340727],[0.34971905358899225,0.33508376266902584,0.3293699207745625,0.30113645704122594,0.2718492506649095,0.24548442324885028,0.22577214019094818,0.2045028203324039,0.1683869276392654,0.13369319218085032]],\"type\":\"heatmap\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"Values\"},\"ticks\":\"outside\",\"tickvals\":[0.05170955379015743,0.6754387485613487],\"ticktext\":[0.05170955379015743,0.6754387485613487]}},\"xaxis\":{\"tickvals\":[0,1,2,3,4,5,6,7,8,9],\"ticktext\":[0,1,2,3,4,5,6,7,8,9],\"title\":{\"text\":\"X\"}},\"yaxis\":{\"tickvals\":[9,8,7,6,5,4,3,2,1,0],\"ticktext\":[9,8,7,6,5,4,3,2,1,0],\"title\":{\"text\":\"Y\"},\"autorange\":\"reversed\"},\"title\":{\"text\":\"Heatmap\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('dca2349b-fab6-4ec0-8ef0-b72d7a101b58');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calc_V_pi_e(pi_e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66bfe651-29d9-4e66-c2f8-6a7c1a1e3588",
        "id": "caBnhqlX1So-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1603494445055814"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_800_random_pi_b.evaluate_scope()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a390fbc7-cf2f-4e45-a47f-707128b7e492",
        "id": "1wey9Vpy1So_"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(1.9744, dtype=torch.float64, grad_fn=<MeanBackward0>),\n",
              " tensor(1.6041, dtype=torch.float64, grad_fn=<VarBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RJEYTtlS8-Ny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r2WrUWX46wy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the state_dict of the model\n",
        "model_state_dict = test_200_0p99.model.state_dict()\n",
        "\n",
        "# Print the keys to see the structure of the state_dict\n",
        "print(model_state_dict.keys())\n",
        "\n",
        "# Extract and print the weights of each layer\n",
        "for name, param in model_state_dict.items():\n",
        "    if 'weight' in name:\n",
        "        print(f\"Layer: {name}\")\n",
        "        print(param)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rR01pJ4hQ-z",
        "outputId": "ea85e642-64fe-4767-c74a-4187ab9ae0d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['hidden_layers.0.weight', 'hidden_layers.0.bias', 'hidden_layers.1.weight', 'hidden_layers.1.bias', 'output_layer.weight', 'output_layer.bias'])\n",
            "Layer: hidden_layers.0.weight\n",
            "tensor([[-0.5992, -0.0774],\n",
            "        [ 0.4740, -0.2568],\n",
            "        [ 0.3057,  0.1028],\n",
            "        [ 0.1205, -0.2533],\n",
            "        [ 0.6123,  0.1611],\n",
            "        [-0.2607, -0.6321],\n",
            "        [-0.7033, -0.3404],\n",
            "        [-0.5834, -0.1342],\n",
            "        [ 0.1821, -0.5556],\n",
            "        [-0.4225,  0.3797],\n",
            "        [-0.4621, -0.6912],\n",
            "        [ 0.6232, -0.4203],\n",
            "        [ 0.2262, -0.6769],\n",
            "        [ 0.5225,  0.2460],\n",
            "        [ 0.6153, -0.0401],\n",
            "        [-0.1569, -0.2980]], dtype=torch.float64)\n",
            "Layer: hidden_layers.1.weight\n",
            "tensor([[ 1.0516e-01, -1.5570e-01, -8.9501e-02,  2.2105e-01,  2.2795e-01,\n",
            "          6.3637e-02,  3.5722e-02, -1.2352e-01, -1.2532e-01, -1.9321e-01,\n",
            "          1.7001e-01,  2.7690e-01,  5.0010e-02,  4.4123e-02, -1.7390e-01,\n",
            "         -3.3544e-02],\n",
            "        [ 2.9563e-02, -1.6539e-01,  1.8811e-01,  2.4416e-02, -2.0411e-01,\n",
            "         -2.2469e-01,  3.2124e-02, -1.1786e-01, -2.0997e-01, -2.9288e-03,\n",
            "         -1.8120e-01, -1.8996e-01,  2.2284e-01,  2.0928e-01,  3.6049e-02,\n",
            "          1.2501e-01],\n",
            "        [-1.2149e-01, -2.1002e-01, -9.7943e-02,  1.5191e-02,  2.5198e-01,\n",
            "         -8.9647e-02,  1.0802e-01,  8.8250e-02, -2.0667e-01, -6.7170e-02,\n",
            "         -2.4271e-02, -1.6559e-01, -2.0982e-01, -1.0798e-01,  1.0970e-01,\n",
            "          6.4986e-02],\n",
            "        [ 1.4588e-01,  1.0558e-01,  8.0609e-02,  1.3330e-01,  4.9129e-02,\n",
            "          1.6742e-02,  6.0140e-02,  1.6866e-01, -1.4508e-01, -1.5118e-01,\n",
            "         -2.2014e-01, -2.0411e-01, -1.6783e-02, -1.8986e-01,  6.8790e-02,\n",
            "          2.2454e-02],\n",
            "        [-1.0514e-02,  2.0386e-01,  2.2841e-01, -1.2321e-01, -1.4372e-01,\n",
            "         -2.4803e-01,  1.3377e-02, -4.9486e-02,  1.2915e-03, -1.9275e-01,\n",
            "          2.0011e-01,  2.5863e-01,  2.6719e-01, -2.4577e-01, -2.6740e-02,\n",
            "         -2.8935e-02],\n",
            "        [-2.3204e-02, -8.9060e-02, -1.4838e-01,  8.9374e-03, -7.6390e-02,\n",
            "          1.5483e-01,  1.3361e-01,  1.3709e-01, -2.2401e-01,  1.0198e-01,\n",
            "          1.0681e-01,  7.2959e-02,  1.7711e-01, -4.4961e-03, -2.2231e-01,\n",
            "          9.4986e-02],\n",
            "        [-2.7593e-01,  7.9180e-03, -4.1311e-02, -7.7472e-02, -3.1525e-01,\n",
            "          6.1380e-02, -2.0414e-01, -8.1497e-02,  1.6221e-01,  2.6618e-02,\n",
            "          2.4309e-01,  8.4607e-02,  1.8900e-01,  4.1116e-03,  1.3827e-01,\n",
            "         -2.4482e-01],\n",
            "        [ 2.6721e-02,  1.3537e-01, -8.0593e-02,  2.6549e-01,  6.6624e-02,\n",
            "         -1.6126e-01,  1.8163e-01, -1.7269e-01,  2.2547e-01, -7.9082e-02,\n",
            "         -5.8181e-02, -5.0510e-02, -3.5746e-02,  7.3083e-03, -4.3919e-02,\n",
            "          1.3159e-01],\n",
            "        [-1.3592e-01, -4.7488e-02, -1.4664e-01, -3.0966e-03,  1.7579e-01,\n",
            "         -1.2013e-01,  1.3873e-01,  1.5010e-01,  2.3158e-01, -2.1094e-01,\n",
            "         -1.8497e-01, -1.7136e-01, -6.6302e-02, -1.8402e-01,  1.7502e-01,\n",
            "          1.8137e-01],\n",
            "        [ 1.2734e-01, -2.7244e-01, -6.1841e-02,  2.5599e-01,  1.3099e-01,\n",
            "          1.6996e-01,  1.5586e-01, -1.0916e-01,  1.6139e-01, -6.0406e-02,\n",
            "         -2.4478e-01, -8.9742e-02, -2.4928e-01,  5.3839e-02, -1.9965e-01,\n",
            "         -3.2069e-02],\n",
            "        [-3.1707e-01, -1.4542e-01,  6.7969e-02,  1.0453e-01,  2.5124e-01,\n",
            "         -2.0614e-01,  2.1780e-01, -1.8906e-01,  2.2606e-01, -1.6723e-01,\n",
            "          2.2091e-01,  5.7679e-02, -1.1455e-01,  2.0786e-01,  1.1073e-01,\n",
            "         -9.5604e-02],\n",
            "        [ 2.6024e-01, -1.2099e-01,  2.0291e-01, -7.6303e-02,  3.9195e-02,\n",
            "          1.5864e-01,  1.8815e-01,  7.4287e-03,  9.7794e-02, -1.0302e-01,\n",
            "         -1.3912e-04,  2.1948e-01,  1.1797e-02,  4.6641e-02,  1.7714e-01,\n",
            "         -2.1003e-01],\n",
            "        [ 2.8777e-01, -9.0522e-02, -6.7675e-03, -2.7429e-01,  1.7504e-01,\n",
            "         -2.0078e-01, -9.1050e-02,  3.8632e-02, -2.2507e-01, -2.2281e-01,\n",
            "         -1.4911e-02, -8.6514e-02, -1.7430e-01,  6.1942e-02,  9.1970e-02,\n",
            "          3.2384e-02],\n",
            "        [ 2.6618e-01, -6.2434e-02, -2.8002e-01,  5.8639e-02,  1.6358e-02,\n",
            "         -9.3782e-02,  1.5367e-01, -8.0826e-02,  1.4841e-01,  1.1282e-01,\n",
            "         -1.3212e-01,  1.4293e-02, -9.5888e-02, -7.1260e-02,  7.8707e-02,\n",
            "          5.3369e-02],\n",
            "        [-1.8876e-01,  1.7914e-01,  1.7690e-01, -6.0962e-02, -1.1442e-01,\n",
            "          4.9254e-02, -2.2479e-02,  1.1894e-01, -3.4903e-02,  1.3051e-01,\n",
            "          7.3961e-02, -3.1765e-02, -5.4896e-02, -2.4755e-01, -7.3570e-02,\n",
            "          1.6345e-01],\n",
            "        [-2.4118e-01,  1.2800e-01,  1.3045e-01,  1.0121e-01,  1.7293e-02,\n",
            "          7.1479e-02, -1.6773e-01,  2.0375e-01, -2.9049e-02, -1.8083e-02,\n",
            "         -1.7433e-01,  2.3663e-01,  1.6658e-01,  1.0704e-01, -3.2912e-02,\n",
            "         -1.0926e-01]], dtype=torch.float64)\n",
            "Layer: output_layer.weight\n",
            "tensor([[-0.0364, -0.0046,  0.0472,  0.1042, -0.1400,  0.0453,  0.1236, -0.1070,\n",
            "         -0.1542,  0.0594, -0.0120,  0.0009,  0.0361, -0.1014,  0.0087, -0.0164]],\n",
            "       dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scope_testing = SCOPE_straight(model, 0.9, 10000, pi_b, P_pi_b, P_pi_e, dtype = torch.float64)"
      ],
      "metadata": {
        "id": "pmjnzbuDy9sE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors, padded_states_next_tensors, padded_states_current_tensors = scope_testing.prepare()\n",
        "timestep_bootstraps, rewards_bootstraps, weights_bootstraps, phi_states_next_bootstraps, phi_states_current_bootstraps = scope_testing.pass_then_boostraps(model, padded_states_next_tensors, padded_states_current_tensors, padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors)\n",
        "IS_variance, scope_variance = scope_testing.calc_variance_straight(timestep_bootstraps, weights_bootstraps, rewards_bootstraps, phi_states_next_bootstraps, phi_states_current_bootstraps)"
      ],
      "metadata": {
        "id": "hoOaF9W7zLoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment 1 (without mse)"
      ],
      "metadata": {
        "id": "WHVUF9_9f-OR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b_200 = action_probs_top_n_epsilon(q_table, 1, 0.4)\n",
        "pi_b_200 = experiment_actions(200, env_50, P_pi_b_200)\n",
        "P_pi_e_200 = action_probs_top_n_epsilon(q_table, 1, 0.05)\n",
        "pi_e_200 = experiment_actions(1000, env_50, P_pi_e_200)\n",
        "# model_200_random_pi_b_200 = CustomizableFeatureNet(input_dim=2, hidden_dims=[16, 16], output_dim=1, dtype = torch.float64, l2_lambda=0.002)\n",
        "model_200_random_pi_b_200 = NN_l1_l2_reg(input_dim=2, hidden_dims=[16, 16], output_dim=1, dtype = torch.float64, l1_lambda=0.0001, l2_lambda = 0.0001)\n",
        "test_200_random_pi_b_200 = SCOPE_straight(model_200_random_pi_b_200, 0.99, 10000, pi_b_200, P_pi_b_200, P_pi_e_200, 0.3, dtype = torch.float64)\n",
        "test_200_random_pi_b_200.train_var_scope(300, 0.001, 1, 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjKJVJjMgi2L",
        "outputId": "c0b1296b-e09b-44f1-b983-3118c32bfec4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(1.1927, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  27.441370946239815\n",
            "SCOPE mean: 0.7002709791760221, SCOPE var: 0.09223498645812357\n",
            "Total Loss: 1.19270345724481\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.7008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  25.891039921865286\n",
            "SCOPE mean: 0.6613629756193857, SCOPE var: 0.08769328295555842\n",
            "Total Loss: 0.700843741427873\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.6421, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  24.98436251935475\n",
            "SCOPE mean: 0.626444735604516, SCOPE var: 0.08371144524064618\n",
            "Total Loss: 0.6420935133411058\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.5839, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  24.084713044389744\n",
            "SCOPE mean: 0.5933725740457488, SCOPE var: 0.08024657259238996\n",
            "Total Loss: 0.5838985502906274\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.5285, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  23.1923748239503\n",
            "SCOPE mean: 0.5613714641066183, SCOPE var: 0.07705641059405173\n",
            "Total Loss: 0.5284965700795247\n",
            "----------------------------------------\n",
            "Epoch 6\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.4754, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.31435599894004\n",
            "SCOPE mean: 0.5294995142372382, SCOPE var: 0.07397630712293497\n",
            "Total Loss: 0.4754369247227464\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.4269, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.458670914189018\n",
            "SCOPE mean: 0.4944867812686913, SCOPE var: 0.0705301449530676\n",
            "Total Loss: 0.426859676813591\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.3836, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  20.629416144593232\n",
            "SCOPE mean: 0.4593314526274879, SCOPE var: 0.06714623368657437\n",
            "Total Loss: 0.38358449799012856\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.3456, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  19.828320484101635\n",
            "SCOPE mean: 0.42491898540075707, SCOPE var: 0.06411005918768582\n",
            "Total Loss: 0.34560164028717394\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.3139, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  19.070302145223536\n",
            "SCOPE mean: 0.39139618134760423, SCOPE var: 0.06132097552614595\n",
            "Total Loss: 0.31389965631809963\n",
            "----------------------------------------\n",
            "Epoch 11\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.2854, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  18.347423734982574\n",
            "SCOPE mean: 0.36052098802080806, SCOPE var: 0.058949164515364416\n",
            "Total Loss: 0.28538530908679355\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.2586, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  17.662876641664177\n",
            "SCOPE mean: 0.33172379701831284, SCOPE var: 0.056890042681550824\n",
            "Total Loss: 0.25856309984927967\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.2344, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  17.021486911346326\n",
            "SCOPE mean: 0.30500024106520407, SCOPE var: 0.05509740304894377\n",
            "Total Loss: 0.23444358600794643\n",
            "----------------------------------------\n",
            "Epoch 14\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.2118, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  16.42396980502829\n",
            "SCOPE mean: 0.27993030663432467, SCOPE var: 0.05345246378645107\n",
            "Total Loss: 0.21181200338593306\n",
            "----------------------------------------\n",
            "Epoch 15\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.1908, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  15.867800567811452\n",
            "SCOPE mean: 0.2564153725105067, SCOPE var: 0.05195696734076134\n",
            "Total Loss: 0.1908309238253673\n",
            "----------------------------------------\n",
            "Epoch 16\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.1739, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  15.352960583501616\n",
            "SCOPE mean: 0.2344843139954261, SCOPE var: 0.05061072431584794\n",
            "Total Loss: 0.17387707764843932\n",
            "----------------------------------------\n",
            "Epoch 17\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.1600, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.880196769407926\n",
            "SCOPE mean: 0.21311813099038018, SCOPE var: 0.049408431386936034\n",
            "Total Loss: 0.16000823169147035\n",
            "----------------------------------------\n",
            "Epoch 18\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.1467, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.44154704344378\n",
            "SCOPE mean: 0.19291183521278404, SCOPE var: 0.0483018411018956\n",
            "Total Loss: 0.14665458096793524\n",
            "----------------------------------------\n",
            "Epoch 19\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.1344, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.037240107839198\n",
            "SCOPE mean: 0.1787607476320969, SCOPE var: 0.04731852881527354\n",
            "Total Loss: 0.13443284016017426\n",
            "----------------------------------------\n",
            "Epoch 20\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.1230, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.664597835850373\n",
            "SCOPE mean: 0.1677425178352028, SCOPE var: 0.04645680481246188\n",
            "Total Loss: 0.12303959931693595\n",
            "----------------------------------------\n",
            "Epoch 21\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.1124, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.323179841714374\n",
            "SCOPE mean: 0.15822274098222847, SCOPE var: 0.04570489732745431\n",
            "Total Loss: 0.11236013163078723\n",
            "----------------------------------------\n",
            "Epoch 22\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.1023, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.009266617049962\n",
            "SCOPE mean: 0.14995885780980348, SCOPE var: 0.04505774948760915\n",
            "Total Loss: 0.10232780150466858\n",
            "----------------------------------------\n",
            "Epoch 23\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0930, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.719308503589332\n",
            "SCOPE mean: 0.1428153645148676, SCOPE var: 0.044502687487893516\n",
            "Total Loss: 0.09303213953625969\n",
            "----------------------------------------\n",
            "Epoch 24\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0848, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.451287728100246\n",
            "SCOPE mean: 0.13673582607629878, SCOPE var: 0.04403363460128949\n",
            "Total Loss: 0.08477241139737052\n",
            "----------------------------------------\n",
            "Epoch 25\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0771, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.207454698842936\n",
            "SCOPE mean: 0.13203143910651466, SCOPE var: 0.04366758574802289\n",
            "Total Loss: 0.07713592469558057\n",
            "----------------------------------------\n",
            "Epoch 26\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0701, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.985922917888763\n",
            "SCOPE mean: 0.12870805151507833, SCOPE var: 0.04343115932655786\n",
            "Total Loss: 0.07013361946319324\n",
            "----------------------------------------\n",
            "Epoch 27\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0637, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.782560902496746\n",
            "SCOPE mean: 0.12648142274637952, SCOPE var: 0.0432562719969758\n",
            "Total Loss: 0.06372058388351054\n",
            "----------------------------------------\n",
            "Epoch 28\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0580, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.596149659211484\n",
            "SCOPE mean: 0.12533904978290286, SCOPE var: 0.04314203973007708\n",
            "Total Loss: 0.057987180540084886\n",
            "----------------------------------------\n",
            "Epoch 29\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0528, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.425372761570646\n",
            "SCOPE mean: 0.12537623959575867, SCOPE var: 0.04310341278487294\n",
            "Total Loss: 0.0528159082772075\n",
            "----------------------------------------\n",
            "Epoch 30\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0482, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.268966177825027\n",
            "SCOPE mean: 0.1264173940402998, SCOPE var: 0.04312465801190941\n",
            "Total Loss: 0.04815900164355429\n",
            "----------------------------------------\n",
            "Epoch 31\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0440, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.12587824469961\n",
            "SCOPE mean: 0.12797453973005898, SCOPE var: 0.04325905524537177\n",
            "Total Loss: 0.04404878331775851\n",
            "----------------------------------------\n",
            "Epoch 32\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0404, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.994967342606234\n",
            "SCOPE mean: 0.13002553501849828, SCOPE var: 0.04353637997297155\n",
            "Total Loss: 0.04043860962118038\n",
            "----------------------------------------\n",
            "Epoch 33\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0372, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.875136730093676\n",
            "SCOPE mean: 0.1315575575351151, SCOPE var: 0.04374204672661738\n",
            "Total Loss: 0.03724223630783659\n",
            "----------------------------------------\n",
            "Epoch 34\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0344, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.766225008700205\n",
            "SCOPE mean: 0.1329828168863337, SCOPE var: 0.04390012591049084\n",
            "Total Loss: 0.034410534029532064\n",
            "----------------------------------------\n",
            "Epoch 35\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0319, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.666372116003163\n",
            "SCOPE mean: 0.13513959749505894, SCOPE var: 0.04410017089434142\n",
            "Total Loss: 0.031911586587630034\n",
            "----------------------------------------\n",
            "Epoch 36\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0297, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.574474977518024\n",
            "SCOPE mean: 0.13793282716596078, SCOPE var: 0.04433997424769851\n",
            "Total Loss: 0.029724439465195138\n",
            "----------------------------------------\n",
            "Epoch 37\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0278, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.490483030457476\n",
            "SCOPE mean: 0.14126996489323182, SCOPE var: 0.044613370591854294\n",
            "Total Loss: 0.027818250082812607\n",
            "----------------------------------------\n",
            "Epoch 38\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0262, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.413470123622911\n",
            "SCOPE mean: 0.1447483026067287, SCOPE var: 0.04490380196777243\n",
            "Total Loss: 0.0261798681512716\n",
            "----------------------------------------\n",
            "Epoch 39\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0247, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.342036671420157\n",
            "SCOPE mean: 0.14790238030093197, SCOPE var: 0.04522865852848748\n",
            "Total Loss: 0.024737115006794933\n",
            "----------------------------------------\n",
            "Epoch 40\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0234, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.27723542816624\n",
            "SCOPE mean: 0.15165177097071741, SCOPE var: 0.045591316389156714\n",
            "Total Loss: 0.023359984536604934\n",
            "----------------------------------------\n",
            "Epoch 41\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0221, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.218710339410146\n",
            "SCOPE mean: 0.15595036288759068, SCOPE var: 0.04599228503566924\n",
            "Total Loss: 0.022132008562652006\n",
            "----------------------------------------\n",
            "Epoch 42\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0210, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.166255448061646\n",
            "SCOPE mean: 0.16081411775869103, SCOPE var: 0.04643575084180313\n",
            "Total Loss: 0.021014157994034874\n",
            "----------------------------------------\n",
            "Epoch 43\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0200, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.11898440567038\n",
            "SCOPE mean: 0.16614751610048106, SCOPE var: 0.046919505389034125\n",
            "Total Loss: 0.019983163783517388\n",
            "----------------------------------------\n",
            "Epoch 44\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0190, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.076582896033331\n",
            "SCOPE mean: 0.17186749250238664, SCOPE var: 0.04744144444270717\n",
            "Total Loss: 0.019000021884039722\n",
            "----------------------------------------\n",
            "Epoch 45\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0181, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.037870217838302\n",
            "SCOPE mean: 0.1778834772039885, SCOPE var: 0.04799846727089724\n",
            "Total Loss: 0.018061582541433075\n",
            "----------------------------------------\n",
            "Epoch 46\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0172, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.002974310812514\n",
            "SCOPE mean: 0.18428141802034367, SCOPE var: 0.04856049852628824\n",
            "Total Loss: 0.01717058107371204\n",
            "----------------------------------------\n",
            "Epoch 47\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0163, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.970938582075581\n",
            "SCOPE mean: 0.1908442962453168, SCOPE var: 0.049144399528542396\n",
            "Total Loss: 0.016344454342287942\n",
            "----------------------------------------\n",
            "Epoch 48\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0156, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.941474989060596\n",
            "SCOPE mean: 0.19746326742809384, SCOPE var: 0.049751890165761835\n",
            "Total Loss: 0.015551921993463912\n",
            "----------------------------------------\n",
            "Epoch 49\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0148, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.914706573123174\n",
            "SCOPE mean: 0.20408112128616596, SCOPE var: 0.05037893657648456\n",
            "Total Loss: 0.014769318634134313\n",
            "----------------------------------------\n",
            "Epoch 50\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0140, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.889622467200077\n",
            "SCOPE mean: 0.21061988377249072, SCOPE var: 0.05102040631922214\n",
            "Total Loss: 0.014031928787575339\n",
            "----------------------------------------\n",
            "Epoch 51\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0134, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.865487553674651\n",
            "SCOPE mean: 0.21700501398329017, SCOPE var: 0.05166910080953289\n",
            "Total Loss: 0.01336013392703293\n",
            "----------------------------------------\n",
            "Epoch 52\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0127, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.841763208199643\n",
            "SCOPE mean: 0.22315054255229383, SCOPE var: 0.052318212870058584\n",
            "Total Loss: 0.012726432513762244\n",
            "----------------------------------------\n",
            "Epoch 53\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0121, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.818236547876245\n",
            "SCOPE mean: 0.22900851941812872, SCOPE var: 0.0529620822749381\n",
            "Total Loss: 0.012128158253910558\n",
            "----------------------------------------\n",
            "Epoch 54\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0116, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.79475143810326\n",
            "SCOPE mean: 0.23454191036097746, SCOPE var: 0.05359527051948007\n",
            "Total Loss: 0.011561469245794207\n",
            "----------------------------------------\n",
            "Epoch 55\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0110, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.770994620832845\n",
            "SCOPE mean: 0.2395861605477821, SCOPE var: 0.05420241528272633\n",
            "Total Loss: 0.011031037561030726\n",
            "----------------------------------------\n",
            "Epoch 56\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0105, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.746876201095331\n",
            "SCOPE mean: 0.2442727261993279, SCOPE var: 0.05479110335514075\n",
            "Total Loss: 0.010542054348004664\n",
            "----------------------------------------\n",
            "Epoch 57\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0101, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.721902488634358\n",
            "SCOPE mean: 0.24854979424150742, SCOPE var: 0.05535351350944523\n",
            "Total Loss: 0.010106668620113057\n",
            "----------------------------------------\n",
            "Epoch 58\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0097, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.696689852233169\n",
            "SCOPE mean: 0.25245183978348834, SCOPE var: 0.055888670991532594\n",
            "Total Loss: 0.00969455197725651\n",
            "----------------------------------------\n",
            "Epoch 59\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0093, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.671126115959364\n",
            "SCOPE mean: 0.2559567564616041, SCOPE var: 0.056391610509249866\n",
            "Total Loss: 0.009324223123296364\n",
            "----------------------------------------\n",
            "Epoch 60\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0090, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.645013995105588\n",
            "SCOPE mean: 0.25841480535141836, SCOPE var: 0.05674674045408867\n",
            "Total Loss: 0.008999687631065354\n",
            "----------------------------------------\n",
            "Epoch 61\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0087, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.618264170513411\n",
            "SCOPE mean: 0.26014867514082235, SCOPE var: 0.0570057872257039\n",
            "Total Loss: 0.008711373394760087\n",
            "----------------------------------------\n",
            "Epoch 62\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0085, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.59065832863212\n",
            "SCOPE mean: 0.26155772750385203, SCOPE var: 0.057235641299466906\n",
            "Total Loss: 0.008451813432269762\n",
            "----------------------------------------\n",
            "Epoch 63\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0082, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.562256218083215\n",
            "SCOPE mean: 0.26267314257383545, SCOPE var: 0.05743846877109058\n",
            "Total Loss: 0.008214442722751052\n",
            "----------------------------------------\n",
            "Epoch 64\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0080, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.533187693563166\n",
            "SCOPE mean: 0.26350722331536697, SCOPE var: 0.05761311413458741\n",
            "Total Loss: 0.007994035574067042\n",
            "----------------------------------------\n",
            "Epoch 65\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0078, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.503674724977346\n",
            "SCOPE mean: 0.2640852235977681, SCOPE var: 0.05776056358440321\n",
            "Total Loss: 0.007783862124028515\n",
            "----------------------------------------\n",
            "Epoch 66\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0076, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.474162205586802\n",
            "SCOPE mean: 0.26444182942922273, SCOPE var: 0.057883104619042995\n",
            "Total Loss: 0.007579659259669167\n",
            "----------------------------------------\n",
            "Epoch 67\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0074, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.44497426437456\n",
            "SCOPE mean: 0.26462161536777024, SCOPE var: 0.05798427096827247\n",
            "Total Loss: 0.0073841149998079\n",
            "----------------------------------------\n",
            "Epoch 68\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0072, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.416833951498786\n",
            "SCOPE mean: 0.26466851367467437, SCOPE var: 0.058067350744702075\n",
            "Total Loss: 0.007200623001722859\n",
            "----------------------------------------\n",
            "Epoch 69\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0070, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.389881291263144\n",
            "SCOPE mean: 0.26462911958831437, SCOPE var: 0.05813595225242821\n",
            "Total Loss: 0.007029966110832413\n",
            "----------------------------------------\n",
            "Epoch 70\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0069, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.364447658326092\n",
            "SCOPE mean: 0.2645512227648727, SCOPE var: 0.05819386689604327\n",
            "Total Loss: 0.006872650452635014\n",
            "----------------------------------------\n",
            "Epoch 71\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0067, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.340951659792392\n",
            "SCOPE mean: 0.2644833685518811, SCOPE var: 0.05824502230834481\n",
            "Total Loss: 0.006723847563031341\n",
            "----------------------------------------\n",
            "Epoch 72\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0066, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.319889391607834\n",
            "SCOPE mean: 0.26446118622539405, SCOPE var: 0.05829226917501668\n",
            "Total Loss: 0.006589135212887898\n",
            "----------------------------------------\n",
            "Epoch 73\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0065, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.301339211065795\n",
            "SCOPE mean: 0.26451913073195843, SCOPE var: 0.05833861505708462\n",
            "Total Loss: 0.006466825629297316\n",
            "----------------------------------------\n",
            "Epoch 74\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0064, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.285321313925435\n",
            "SCOPE mean: 0.264691494944584, SCOPE var: 0.05838704281537603\n",
            "Total Loss: 0.006366231494468438\n",
            "----------------------------------------\n",
            "Epoch 75\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0063, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.272061478241774\n",
            "SCOPE mean: 0.2650240448405577, SCOPE var: 0.05844162134554528\n",
            "Total Loss: 0.0062799808936831545\n",
            "----------------------------------------\n",
            "Epoch 76\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0062, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.262007227989873\n",
            "SCOPE mean: 0.26553107304930174, SCOPE var: 0.05850377310168746\n",
            "Total Loss: 0.006201987797962881\n",
            "----------------------------------------\n",
            "Epoch 77\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0061, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.254891286642813\n",
            "SCOPE mean: 0.2662395681304514, SCOPE var: 0.05857541850213019\n",
            "Total Loss: 0.006128052810920397\n",
            "----------------------------------------\n",
            "Epoch 78\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0061, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.250577215846707\n",
            "SCOPE mean: 0.2671291870763044, SCOPE var: 0.05865651065930982\n",
            "Total Loss: 0.006055460956053306\n",
            "----------------------------------------\n",
            "Epoch 79\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0060, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.248918143162898\n",
            "SCOPE mean: 0.2682293719912877, SCOPE var: 0.05874826635149446\n",
            "Total Loss: 0.005981860474210279\n",
            "----------------------------------------\n",
            "Epoch 80\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0059, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.249883432380916\n",
            "SCOPE mean: 0.26955181382812604, SCOPE var: 0.058851268200613295\n",
            "Total Loss: 0.005907578232982849\n",
            "----------------------------------------\n",
            "Epoch 81\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0058, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.253429408301315\n",
            "SCOPE mean: 0.2711014649795873, SCOPE var: 0.05896633500347569\n",
            "Total Loss: 0.005826807995076055\n",
            "----------------------------------------\n",
            "Epoch 82\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0057, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.25940780743652\n",
            "SCOPE mean: 0.27287003840683766, SCOPE var: 0.05909342818150003\n",
            "Total Loss: 0.005742734089821034\n",
            "----------------------------------------\n",
            "Epoch 83\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0057, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.26751260155346\n",
            "SCOPE mean: 0.2748421559394137, SCOPE var: 0.05923183952036176\n",
            "Total Loss: 0.005655201923674973\n",
            "----------------------------------------\n",
            "Epoch 84\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0056, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.277625207916971\n",
            "SCOPE mean: 0.2770038834274393, SCOPE var: 0.05938118104716412\n",
            "Total Loss: 0.005564505285467603\n",
            "----------------------------------------\n",
            "Epoch 85\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0055, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.289511440783263\n",
            "SCOPE mean: 0.2793125579805105, SCOPE var: 0.059538808107262885\n",
            "Total Loss: 0.005472185729558658\n",
            "----------------------------------------\n",
            "Epoch 86\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0054, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.302894537823995\n",
            "SCOPE mean: 0.2817212373413955, SCOPE var: 0.05970165539585988\n",
            "Total Loss: 0.005379685474605648\n",
            "----------------------------------------\n",
            "Epoch 87\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0053, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.317576223418941\n",
            "SCOPE mean: 0.28421807346390726, SCOPE var: 0.059869355215401154\n",
            "Total Loss: 0.005289481727855011\n",
            "----------------------------------------\n",
            "Epoch 88\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0052, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.333192216183267\n",
            "SCOPE mean: 0.2867649888269486, SCOPE var: 0.0600392739281193\n",
            "Total Loss: 0.005204910627523726\n",
            "----------------------------------------\n",
            "Epoch 89\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0051, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.348779327583985\n",
            "SCOPE mean: 0.2892917937541377, SCOPE var: 0.06020606633325696\n",
            "Total Loss: 0.0051274738647633464\n",
            "----------------------------------------\n",
            "Epoch 90\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0051, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.364246659242985\n",
            "SCOPE mean: 0.29176485822327086, SCOPE var: 0.06036873667597976\n",
            "Total Loss: 0.005054821885415648\n",
            "----------------------------------------\n",
            "Epoch 91\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0050, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.37950135974326\n",
            "SCOPE mean: 0.2941564250590028, SCOPE var: 0.06052556448888998\n",
            "Total Loss: 0.004985066166432754\n",
            "----------------------------------------\n",
            "Epoch 92\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0049, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.394450491401255\n",
            "SCOPE mean: 0.29645563970454136, SCOPE var: 0.06067570818452809\n",
            "Total Loss: 0.004916860143548652\n",
            "----------------------------------------\n",
            "Epoch 93\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0049, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.408945549452737\n",
            "SCOPE mean: 0.29853804491214425, SCOPE var: 0.06081806353492327\n",
            "Total Loss: 0.004850510208529241\n",
            "----------------------------------------\n",
            "Epoch 94\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0048, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.42298816618069\n",
            "SCOPE mean: 0.30037111716127934, SCOPE var: 0.06094319903752608\n",
            "Total Loss: 0.004786309945519931\n",
            "----------------------------------------\n",
            "Epoch 95\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0047, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.436577781065912\n",
            "SCOPE mean: 0.3020221951449731, SCOPE var: 0.06104913549808851\n",
            "Total Loss: 0.004722650592516596\n",
            "----------------------------------------\n",
            "Epoch 96\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0047, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.44999299862373\n",
            "SCOPE mean: 0.3035810773469717, SCOPE var: 0.06114812247210516\n",
            "Total Loss: 0.004657601099243643\n",
            "----------------------------------------\n",
            "Epoch 97\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.463125733112921\n",
            "SCOPE mean: 0.30505231951666567, SCOPE var: 0.06124047826466184\n",
            "Total Loss: 0.004594244505639833\n",
            "----------------------------------------\n",
            "Epoch 98\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0045, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.475948561582243\n",
            "SCOPE mean: 0.3064316183809902, SCOPE var: 0.06132617738459692\n",
            "Total Loss: 0.004530598622547044\n",
            "----------------------------------------\n",
            "Epoch 99\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0045, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.48855546858309\n",
            "SCOPE mean: 0.30772300279733483, SCOPE var: 0.061405548616780194\n",
            "Total Loss: 0.004466812615568357\n",
            "----------------------------------------\n",
            "Epoch 100\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0044, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.500965874507893\n",
            "SCOPE mean: 0.30894403841126244, SCOPE var: 0.061479851771062966\n",
            "Total Loss: 0.004403936421615963\n",
            "----------------------------------------\n",
            "Epoch 101\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0043, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.513188674840546\n",
            "SCOPE mean: 0.31010686626694267, SCOPE var: 0.06155005372167101\n",
            "Total Loss: 0.004341232479904843\n",
            "----------------------------------------\n",
            "Epoch 102\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0043, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.5252654824196\n",
            "SCOPE mean: 0.3112303098815288, SCOPE var: 0.06161732970068928\n",
            "Total Loss: 0.0042793904318688784\n",
            "----------------------------------------\n",
            "Epoch 103\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0042, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.537173834515666\n",
            "SCOPE mean: 0.31231685448918844, SCOPE var: 0.061681917281065576\n",
            "Total Loss: 0.004216389773660486\n",
            "----------------------------------------\n",
            "Epoch 104\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0042, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.549362440684014\n",
            "SCOPE mean: 0.31337883866797794, SCOPE var: 0.061741935310490104\n",
            "Total Loss: 0.004154243463508927\n",
            "----------------------------------------\n",
            "Epoch 105\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0041, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.561715551400779\n",
            "SCOPE mean: 0.3143909425401329, SCOPE var: 0.061789236510536236\n",
            "Total Loss: 0.004094482449111872\n",
            "----------------------------------------\n",
            "Epoch 106\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0040, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.57426286067752\n",
            "SCOPE mean: 0.31538738791546905, SCOPE var: 0.06183529863723218\n",
            "Total Loss: 0.004036533748132311\n",
            "----------------------------------------\n",
            "Epoch 107\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0040, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.586941106226904\n",
            "SCOPE mean: 0.31638814047956265, SCOPE var: 0.0618816818474462\n",
            "Total Loss: 0.003978558959149307\n",
            "----------------------------------------\n",
            "Epoch 108\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0039, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.599880747548418\n",
            "SCOPE mean: 0.3174024727034534, SCOPE var: 0.06192718245469352\n",
            "Total Loss: 0.003920725652315763\n",
            "----------------------------------------\n",
            "Epoch 109\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0039, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.61320552188408\n",
            "SCOPE mean: 0.3184569119370116, SCOPE var: 0.061973848570222444\n",
            "Total Loss: 0.0038641236306034897\n",
            "----------------------------------------\n",
            "Epoch 110\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0038, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.627002351525485\n",
            "SCOPE mean: 0.31954800462972777, SCOPE var: 0.062022087090983974\n",
            "Total Loss: 0.003808633916722382\n",
            "----------------------------------------\n",
            "Epoch 111\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0038, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.641393551372088\n",
            "SCOPE mean: 0.3206743632648042, SCOPE var: 0.062071829168516605\n",
            "Total Loss: 0.0037544854846244275\n",
            "----------------------------------------\n",
            "Epoch 112\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0037, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.65613109507022\n",
            "SCOPE mean: 0.32183977820626586, SCOPE var: 0.0621240050369056\n",
            "Total Loss: 0.003701181304154657\n",
            "----------------------------------------\n",
            "Epoch 113\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.671589163846606\n",
            "SCOPE mean: 0.3230789305303726, SCOPE var: 0.06218036423972485\n",
            "Total Loss: 0.003647556449023739\n",
            "----------------------------------------\n",
            "Epoch 114\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.687871801171688\n",
            "SCOPE mean: 0.3243995123870003, SCOPE var: 0.062239159372625086\n",
            "Total Loss: 0.003595617666581048\n",
            "----------------------------------------\n",
            "Epoch 115\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0035, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.70504181601212\n",
            "SCOPE mean: 0.32575849381497834, SCOPE var: 0.06230161701547086\n",
            "Total Loss: 0.0035461941383287507\n",
            "----------------------------------------\n",
            "Epoch 116\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0035, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.723009636420224\n",
            "SCOPE mean: 0.32718153252077947, SCOPE var: 0.06236797065456891\n",
            "Total Loss: 0.003497263565287381\n",
            "----------------------------------------\n",
            "Epoch 117\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0035, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.741617482743266\n",
            "SCOPE mean: 0.32866513146171356, SCOPE var: 0.06243822978663717\n",
            "Total Loss: 0.0034503407750140487\n",
            "----------------------------------------\n",
            "Epoch 118\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0034, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.760716223240742\n",
            "SCOPE mean: 0.33020685759753443, SCOPE var: 0.06251270218560921\n",
            "Total Loss: 0.0034050966638269763\n",
            "----------------------------------------\n",
            "Epoch 119\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0034, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.780390207936433\n",
            "SCOPE mean: 0.3318114242944308, SCOPE var: 0.06259185699881183\n",
            "Total Loss: 0.0033601045681537723\n",
            "----------------------------------------\n",
            "Epoch 120\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0033, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.80033982530807\n",
            "SCOPE mean: 0.3334358290128445, SCOPE var: 0.06266759336377495\n",
            "Total Loss: 0.003317122163550763\n",
            "----------------------------------------\n",
            "Epoch 121\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0033, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.82029328850985\n",
            "SCOPE mean: 0.33499838460766346, SCOPE var: 0.06272716178557708\n",
            "Total Loss: 0.003275391700098241\n",
            "----------------------------------------\n",
            "Epoch 122\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0032, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.840593055249231\n",
            "SCOPE mean: 0.33661464719906914, SCOPE var: 0.06279073752554536\n",
            "Total Loss: 0.00323069025361716\n",
            "----------------------------------------\n",
            "Epoch 123\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0032, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.861213380709193\n",
            "SCOPE mean: 0.33827357357414883, SCOPE var: 0.06285771427017275\n",
            "Total Loss: 0.003186537757678635\n",
            "----------------------------------------\n",
            "Epoch 124\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0031, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.88175112576542\n",
            "SCOPE mean: 0.3399531458236772, SCOPE var: 0.06292653018918307\n",
            "Total Loss: 0.003143585494379755\n",
            "----------------------------------------\n",
            "Epoch 125\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0031, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.901964040169066\n",
            "SCOPE mean: 0.34164424409990346, SCOPE var: 0.06299576767761196\n",
            "Total Loss: 0.003103978451360744\n",
            "----------------------------------------\n",
            "Epoch 126\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0031, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.921640041850857\n",
            "SCOPE mean: 0.3432001001897298, SCOPE var: 0.06306409078069883\n",
            "Total Loss: 0.0030614003547250117\n",
            "----------------------------------------\n",
            "Epoch 127\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0030, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.94183331508489\n",
            "SCOPE mean: 0.34412241615228184, SCOPE var: 0.06312902917514543\n",
            "Total Loss: 0.0030171990047521634\n",
            "----------------------------------------\n",
            "Epoch 128\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0030, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.962115625247016\n",
            "SCOPE mean: 0.345016782582658, SCOPE var: 0.06319074911756511\n",
            "Total Loss: 0.002975706939089914\n",
            "----------------------------------------\n",
            "Epoch 129\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0029, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.983201492401172\n",
            "SCOPE mean: 0.3458910461065616, SCOPE var: 0.06324899981222071\n",
            "Total Loss: 0.0029339617900744283\n",
            "----------------------------------------\n",
            "Epoch 130\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0029, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.005013397546872\n",
            "SCOPE mean: 0.34674824863446685, SCOPE var: 0.06330334232113001\n",
            "Total Loss: 0.0028956867643072466\n",
            "----------------------------------------\n",
            "Epoch 131\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0029, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.02759906767154\n",
            "SCOPE mean: 0.34758014027102707, SCOPE var: 0.06335199455405394\n",
            "Total Loss: 0.0028547152373490526\n",
            "----------------------------------------\n",
            "Epoch 132\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0028, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.052031809008499\n",
            "SCOPE mean: 0.34838962136736706, SCOPE var: 0.06339037135771372\n",
            "Total Loss: 0.002817804482321049\n",
            "----------------------------------------\n",
            "Epoch 133\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0028, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.076544500627671\n",
            "SCOPE mean: 0.34918718416861194, SCOPE var: 0.06342471610218997\n",
            "Total Loss: 0.0027725964158780026\n",
            "----------------------------------------\n",
            "Epoch 134\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0027, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.10304767267179\n",
            "SCOPE mean: 0.3499722480902287, SCOPE var: 0.06345496564076027\n",
            "Total Loss: 0.002727992379430109\n",
            "----------------------------------------\n",
            "Epoch 135\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0027, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.12802479745245\n",
            "SCOPE mean: 0.35073668880748804, SCOPE var: 0.06348052068435903\n",
            "Total Loss: 0.002691027655935692\n",
            "----------------------------------------\n",
            "Epoch 136\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0027, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.149880272952917\n",
            "SCOPE mean: 0.35147619487251175, SCOPE var: 0.06350078688903689\n",
            "Total Loss: 0.002659163967646498\n",
            "----------------------------------------\n",
            "Epoch 137\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0026, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.167553874801472\n",
            "SCOPE mean: 0.3521791780861515, SCOPE var: 0.06351513778589944\n",
            "Total Loss: 0.002629488948335899\n",
            "----------------------------------------\n",
            "Epoch 138\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0026, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.181187429934546\n",
            "SCOPE mean: 0.3528442582043513, SCOPE var: 0.06352392719151434\n",
            "Total Loss: 0.0025963876690784943\n",
            "----------------------------------------\n",
            "Epoch 139\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0026, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.193537237861893\n",
            "SCOPE mean: 0.3534375240032963, SCOPE var: 0.0635272105604683\n",
            "Total Loss: 0.002564117191490699\n",
            "----------------------------------------\n",
            "Epoch 140\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0025, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.204279428604627\n",
            "SCOPE mean: 0.35380676015977786, SCOPE var: 0.063524442655393\n",
            "Total Loss: 0.0025338887680892985\n",
            "----------------------------------------\n",
            "Epoch 141\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0025, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.213484200223043\n",
            "SCOPE mean: 0.3541010367866507, SCOPE var: 0.06351548446500571\n",
            "Total Loss: 0.002506422865751806\n",
            "----------------------------------------\n",
            "Epoch 142\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0025, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.221240935264564\n",
            "SCOPE mean: 0.3543178714242015, SCOPE var: 0.06350041137296697\n",
            "Total Loss: 0.0024800532676229814\n",
            "----------------------------------------\n",
            "Epoch 143\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0025, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.227564898836048\n",
            "SCOPE mean: 0.3544621932713195, SCOPE var: 0.06347981771044924\n",
            "Total Loss: 0.0024535149113705953\n",
            "----------------------------------------\n",
            "Epoch 144\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0024, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.231864702479527\n",
            "SCOPE mean: 0.35453516455931466, SCOPE var: 0.06345427604677752\n",
            "Total Loss: 0.0024264261649333016\n",
            "----------------------------------------\n",
            "Epoch 145\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0024, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.234627827746165\n",
            "SCOPE mean: 0.35455576419511997, SCOPE var: 0.0634255884324054\n",
            "Total Loss: 0.002399110770087375\n",
            "----------------------------------------\n",
            "Epoch 146\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0024, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.236295205934775\n",
            "SCOPE mean: 0.3545479289107617, SCOPE var: 0.06339547507572953\n",
            "Total Loss: 0.0023726817082365377\n",
            "----------------------------------------\n",
            "Epoch 147\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0023, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.237560484003573\n",
            "SCOPE mean: 0.3545312442676949, SCOPE var: 0.06336604788715341\n",
            "Total Loss: 0.0023489881017878193\n",
            "----------------------------------------\n",
            "Epoch 148\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0023, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.238946805514782\n",
            "SCOPE mean: 0.35452737663086475, SCOPE var: 0.0633392910106507\n",
            "Total Loss: 0.002326932144286974\n",
            "----------------------------------------\n",
            "Epoch 149\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0023, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.240689312456317\n",
            "SCOPE mean: 0.3545497189828181, SCOPE var: 0.06331666311516697\n",
            "Total Loss: 0.002304848491589267\n",
            "----------------------------------------\n",
            "Epoch 150\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0023, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.24284835830773\n",
            "SCOPE mean: 0.3546222733365965, SCOPE var: 0.0632998786432368\n",
            "Total Loss: 0.0022836387289950255\n",
            "----------------------------------------\n",
            "Epoch 151\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0023, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.246518668027074\n",
            "SCOPE mean: 0.3547648395554686, SCOPE var: 0.06329051289280106\n",
            "Total Loss: 0.0022636694123636444\n",
            "----------------------------------------\n",
            "Epoch 152\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0022, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.25001321960117\n",
            "SCOPE mean: 0.35498538416981085, SCOPE var: 0.06328943607800719\n",
            "Total Loss: 0.0022412299378019016\n",
            "----------------------------------------\n",
            "Epoch 153\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0022, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.254203611232027\n",
            "SCOPE mean: 0.35530729631798935, SCOPE var: 0.06329764277818575\n",
            "Total Loss: 0.0022205639752961967\n",
            "----------------------------------------\n",
            "Epoch 154\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0022, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.260703576046714\n",
            "SCOPE mean: 0.35572826824740605, SCOPE var: 0.06331513343764439\n",
            "Total Loss: 0.002201309213615714\n",
            "----------------------------------------\n",
            "Epoch 155\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0022, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.269086134067356\n",
            "SCOPE mean: 0.3562475563377417, SCOPE var: 0.06334199212541601\n",
            "Total Loss: 0.002181404334854052\n",
            "----------------------------------------\n",
            "Epoch 156\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0022, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.279102890436997\n",
            "SCOPE mean: 0.3568644462348068, SCOPE var: 0.06337775464123141\n",
            "Total Loss: 0.00216106871120165\n",
            "----------------------------------------\n",
            "Epoch 157\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0021, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.290339610492946\n",
            "SCOPE mean: 0.3575663086037111, SCOPE var: 0.06342113641163755\n",
            "Total Loss: 0.0021405649273376257\n",
            "----------------------------------------\n",
            "Epoch 158\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0021, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.302386953592663\n",
            "SCOPE mean: 0.3583440341149246, SCOPE var: 0.0634709316675188\n",
            "Total Loss: 0.002120232357939429\n",
            "----------------------------------------\n",
            "Epoch 159\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0021, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.31488895109734\n",
            "SCOPE mean: 0.35918710896147266, SCOPE var: 0.0635251566242288\n",
            "Total Loss: 0.0021001445245380484\n",
            "----------------------------------------\n",
            "Epoch 160\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0021, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.327444495943459\n",
            "SCOPE mean: 0.36006952284938354, SCOPE var: 0.06357874278928619\n",
            "Total Loss: 0.002080432259718798\n",
            "----------------------------------------\n",
            "Epoch 161\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0021, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.339474054760505\n",
            "SCOPE mean: 0.3609709139838305, SCOPE var: 0.06363343112671058\n",
            "Total Loss: 0.0020612386902692866\n",
            "----------------------------------------\n",
            "Epoch 162\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0020, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.350422281733044\n",
            "SCOPE mean: 0.3618681608709801, SCOPE var: 0.0636872761664152\n",
            "Total Loss: 0.002042315283270474\n",
            "----------------------------------------\n",
            "Epoch 163\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0020, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.360063206358433\n",
            "SCOPE mean: 0.36274791862572703, SCOPE var: 0.0637389861799343\n",
            "Total Loss: 0.002023790064832765\n",
            "----------------------------------------\n",
            "Epoch 164\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0020, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.368242620685429\n",
            "SCOPE mean: 0.36359481331882293, SCOPE var: 0.06378726043704014\n",
            "Total Loss: 0.002005693408333471\n",
            "----------------------------------------\n",
            "Epoch 165\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0020, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.374909029909384\n",
            "SCOPE mean: 0.36440081195289065, SCOPE var: 0.06383033171007085\n",
            "Total Loss: 0.0019875149420781895\n",
            "----------------------------------------\n",
            "Epoch 166\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0020, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.380001141856528\n",
            "SCOPE mean: 0.36514979038977863, SCOPE var: 0.06386797935414076\n",
            "Total Loss: 0.001969425353644597\n",
            "----------------------------------------\n",
            "Epoch 167\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0020, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.383773479717133\n",
            "SCOPE mean: 0.36583977328526707, SCOPE var: 0.0639004771038063\n",
            "Total Loss: 0.0019515953966579797\n",
            "----------------------------------------\n",
            "Epoch 168\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0019, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.38636281681097\n",
            "SCOPE mean: 0.3664736553601997, SCOPE var: 0.06392768325685436\n",
            "Total Loss: 0.0019339676256926591\n",
            "----------------------------------------\n",
            "Epoch 169\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0019, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.388461417083763\n",
            "SCOPE mean: 0.36705058371827654, SCOPE var: 0.06394946121155475\n",
            "Total Loss: 0.0019168704014125772\n",
            "----------------------------------------\n",
            "Epoch 170\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0019, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.39032851123911\n",
            "SCOPE mean: 0.36756861415583364, SCOPE var: 0.06396617850277174\n",
            "Total Loss: 0.001900004419510952\n",
            "----------------------------------------\n",
            "Epoch 171\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0019, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.392143052099376\n",
            "SCOPE mean: 0.36803064540890584, SCOPE var: 0.06397816107941329\n",
            "Total Loss: 0.0018827030779355913\n",
            "----------------------------------------\n",
            "Epoch 172\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0019, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.393907228944242\n",
            "SCOPE mean: 0.3684374713727394, SCOPE var: 0.06398547175983023\n",
            "Total Loss: 0.001864824703574747\n",
            "----------------------------------------\n",
            "Epoch 173\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0018, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.395777718658158\n",
            "SCOPE mean: 0.36879297351158113, SCOPE var: 0.06398853610269573\n",
            "Total Loss: 0.001847146813919838\n",
            "----------------------------------------\n",
            "Epoch 174\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0018, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.397738398286124\n",
            "SCOPE mean: 0.36909846853827555, SCOPE var: 0.06398768406096444\n",
            "Total Loss: 0.0018294874093469663\n",
            "----------------------------------------\n",
            "Epoch 175\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0018, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.399704795457145\n",
            "SCOPE mean: 0.36936064702833915, SCOPE var: 0.06398218374821041\n",
            "Total Loss: 0.0018119250136335449\n",
            "----------------------------------------\n",
            "Epoch 176\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0018, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.401564296889322\n",
            "SCOPE mean: 0.36958443064038204, SCOPE var: 0.06397315671412594\n",
            "Total Loss: 0.0017943869648013146\n",
            "----------------------------------------\n",
            "Epoch 177\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0018, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.403179131398941\n",
            "SCOPE mean: 0.3697808016763845, SCOPE var: 0.0639617292209723\n",
            "Total Loss: 0.0017766209991919965\n",
            "----------------------------------------\n",
            "Epoch 178\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0018, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.404385899365478\n",
            "SCOPE mean: 0.3699536729942142, SCOPE var: 0.06394835849611173\n",
            "Total Loss: 0.001759033082468156\n",
            "----------------------------------------\n",
            "Epoch 179\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0017, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.405030021007756\n",
            "SCOPE mean: 0.37010351039659234, SCOPE var: 0.06393322260909616\n",
            "Total Loss: 0.001742169871090297\n",
            "----------------------------------------\n",
            "Epoch 180\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0017, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.402784452904287\n",
            "SCOPE mean: 0.3702252704254925, SCOPE var: 0.06391631412217263\n",
            "Total Loss: 0.0017243397821993863\n",
            "----------------------------------------\n",
            "Epoch 181\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0017, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.398409636993998\n",
            "SCOPE mean: 0.3703270818639889, SCOPE var: 0.06389835775562638\n",
            "Total Loss: 0.0017071567429142395\n",
            "----------------------------------------\n",
            "Epoch 182\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0017, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.394725674827033\n",
            "SCOPE mean: 0.37043558321543024, SCOPE var: 0.06388088079224225\n",
            "Total Loss: 0.0016900282550608725\n",
            "----------------------------------------\n",
            "Epoch 183\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0017, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.39093475350386\n",
            "SCOPE mean: 0.37055059426760734, SCOPE var: 0.06386473196682528\n",
            "Total Loss: 0.001673039282067009\n",
            "----------------------------------------\n",
            "Epoch 184\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0017, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.387443342076383\n",
            "SCOPE mean: 0.3706734422264766, SCOPE var: 0.06384780816090789\n",
            "Total Loss: 0.0016564157188264476\n",
            "----------------------------------------\n",
            "Epoch 185\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0016, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.385220883810206\n",
            "SCOPE mean: 0.3708075379320858, SCOPE var: 0.06383051562438218\n",
            "Total Loss: 0.0016402573146004097\n",
            "----------------------------------------\n",
            "Epoch 186\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0016, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.384057352522314\n",
            "SCOPE mean: 0.370956214667825, SCOPE var: 0.06381573318336528\n",
            "Total Loss: 0.0016242016836180968\n",
            "----------------------------------------\n",
            "Epoch 187\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0016, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.38378129192589\n",
            "SCOPE mean: 0.371117914124698, SCOPE var: 0.06380340445442584\n",
            "Total Loss: 0.0016082042205905177\n",
            "----------------------------------------\n",
            "Epoch 188\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0016, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.384203845139234\n",
            "SCOPE mean: 0.37128926939321477, SCOPE var: 0.06379316667702736\n",
            "Total Loss: 0.001592318077453069\n",
            "----------------------------------------\n",
            "Epoch 189\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0016, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.385056984611687\n",
            "SCOPE mean: 0.3714822481892189, SCOPE var: 0.06378500942468622\n",
            "Total Loss: 0.0015766812462755361\n",
            "----------------------------------------\n",
            "Epoch 190\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0016, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.386043109136498\n",
            "SCOPE mean: 0.37170338284220816, SCOPE var: 0.06377889722594261\n",
            "Total Loss: 0.0015621687883428813\n",
            "----------------------------------------\n",
            "Epoch 191\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0015, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.384423094357722\n",
            "SCOPE mean: 0.37192999828827394, SCOPE var: 0.06377357950904441\n",
            "Total Loss: 0.001547456885580005\n",
            "----------------------------------------\n",
            "Epoch 192\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0015, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.380229649966896\n",
            "SCOPE mean: 0.37215061507482944, SCOPE var: 0.06376809126346222\n",
            "Total Loss: 0.0015313969902493885\n",
            "----------------------------------------\n",
            "Epoch 193\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0015, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.373731951678831\n",
            "SCOPE mean: 0.3723825375667845, SCOPE var: 0.06376202612744794\n",
            "Total Loss: 0.001515054013150636\n",
            "----------------------------------------\n",
            "Epoch 194\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0015, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.367868299531763\n",
            "SCOPE mean: 0.37255734729584916, SCOPE var: 0.06375567014031329\n",
            "Total Loss: 0.0014998994089789844\n",
            "----------------------------------------\n",
            "Epoch 195\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0015, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.362974038346655\n",
            "SCOPE mean: 0.3725157843022418, SCOPE var: 0.06374893412400524\n",
            "Total Loss: 0.001485325954089322\n",
            "----------------------------------------\n",
            "Epoch 196\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0015, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.359158383085218\n",
            "SCOPE mean: 0.37249117815363886, SCOPE var: 0.06374349560571485\n",
            "Total Loss: 0.0014707437169512627\n",
            "----------------------------------------\n",
            "Epoch 197\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0015, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.356322973137244\n",
            "SCOPE mean: 0.3724822321969302, SCOPE var: 0.06373920753103812\n",
            "Total Loss: 0.0014562226410094411\n",
            "----------------------------------------\n",
            "Epoch 198\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0014, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.351690567576895\n",
            "SCOPE mean: 0.3724655566803135, SCOPE var: 0.06373443644571254\n",
            "Total Loss: 0.001441927498157758\n",
            "----------------------------------------\n",
            "Epoch 199\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0014, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.345389727345053\n",
            "SCOPE mean: 0.3724420348125922, SCOPE var: 0.0637286897346671\n",
            "Total Loss: 0.0014274765868654287\n",
            "----------------------------------------\n",
            "Epoch 200\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0014, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.339759163174941\n",
            "SCOPE mean: 0.3724205551594012, SCOPE var: 0.06371948630683351\n",
            "Total Loss: 0.0014131155770208505\n",
            "----------------------------------------\n",
            "Epoch 201\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0014, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.33264454571699\n",
            "SCOPE mean: 0.3723962956501858, SCOPE var: 0.06371052816675489\n",
            "Total Loss: 0.0013991045155106162\n",
            "----------------------------------------\n",
            "Epoch 202\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0014, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.326446578055682\n",
            "SCOPE mean: 0.3723954087171835, SCOPE var: 0.06370343099993535\n",
            "Total Loss: 0.0013850658583826466\n",
            "----------------------------------------\n",
            "Epoch 203\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0014, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.32112814078605\n",
            "SCOPE mean: 0.37241118848704363, SCOPE var: 0.0636977540702092\n",
            "Total Loss: 0.001371335089361505\n",
            "----------------------------------------\n",
            "Epoch 204\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0014, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.314325722315962\n",
            "SCOPE mean: 0.37242410271140913, SCOPE var: 0.06369230334974525\n",
            "Total Loss: 0.001357838006532483\n",
            "----------------------------------------\n",
            "Epoch 205\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.306234942805345\n",
            "SCOPE mean: 0.37242574343052937, SCOPE var: 0.0636861000544016\n",
            "Total Loss: 0.0013444997811424052\n",
            "----------------------------------------\n",
            "Epoch 206\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.299770084803841\n",
            "SCOPE mean: 0.37241965979364644, SCOPE var: 0.06367873399992147\n",
            "Total Loss: 0.001331578846979401\n",
            "----------------------------------------\n",
            "Epoch 207\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.292863508378982\n",
            "SCOPE mean: 0.3724066147747793, SCOPE var: 0.0636702515573422\n",
            "Total Loss: 0.0013183778919724813\n",
            "----------------------------------------\n",
            "Epoch 208\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.287499549637236\n",
            "SCOPE mean: 0.3723710654434839, SCOPE var: 0.06366282014081803\n",
            "Total Loss: 0.0013055238528554937\n",
            "----------------------------------------\n",
            "Epoch 209\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.281228134489957\n",
            "SCOPE mean: 0.3723055915436648, SCOPE var: 0.06365857534187624\n",
            "Total Loss: 0.0012919778827101074\n",
            "----------------------------------------\n",
            "Epoch 210\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.274191398455594\n",
            "SCOPE mean: 0.3722276206963853, SCOPE var: 0.06365458800289633\n",
            "Total Loss: 0.001278812046861649\n",
            "----------------------------------------\n",
            "Epoch 211\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.266637606398778\n",
            "SCOPE mean: 0.372140529388904, SCOPE var: 0.06365161337267808\n",
            "Total Loss: 0.0012664654037454358\n",
            "----------------------------------------\n",
            "Epoch 212\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.26074157446847\n",
            "SCOPE mean: 0.37204413006065873, SCOPE var: 0.06364933844997896\n",
            "Total Loss: 0.0012538376347713816\n",
            "----------------------------------------\n",
            "Epoch 213\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.256409011183807\n",
            "SCOPE mean: 0.371936685533709, SCOPE var: 0.06364753437207885\n",
            "Total Loss: 0.0012410760219790475\n",
            "----------------------------------------\n",
            "Epoch 214\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.253255125036908\n",
            "SCOPE mean: 0.37181803154288307, SCOPE var: 0.06364608886724309\n",
            "Total Loss: 0.0012287283652841592\n",
            "----------------------------------------\n",
            "Epoch 215\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.24869214045365\n",
            "SCOPE mean: 0.37168526408837377, SCOPE var: 0.06364516977886683\n",
            "Total Loss: 0.001216171592958339\n",
            "----------------------------------------\n",
            "Epoch 216\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.242676599476967\n",
            "SCOPE mean: 0.371535729347874, SCOPE var: 0.06364448121259984\n",
            "Total Loss: 0.001203208432405904\n",
            "----------------------------------------\n",
            "Epoch 217\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.235665139299376\n",
            "SCOPE mean: 0.37137028115347037, SCOPE var: 0.06364390178588113\n",
            "Total Loss: 0.0011903733424146665\n",
            "----------------------------------------\n",
            "Epoch 218\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.226866383458061\n",
            "SCOPE mean: 0.3711907559754299, SCOPE var: 0.06364407987401521\n",
            "Total Loss: 0.0011781108917132222\n",
            "----------------------------------------\n",
            "Epoch 219\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.220939727061257\n",
            "SCOPE mean: 0.37101088855988057, SCOPE var: 0.06364494220620986\n",
            "Total Loss: 0.001166269796023094\n",
            "----------------------------------------\n",
            "Epoch 220\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.216684075612939\n",
            "SCOPE mean: 0.370833433604275, SCOPE var: 0.0636470780488087\n",
            "Total Loss: 0.001154025785727933\n",
            "----------------------------------------\n",
            "Epoch 221\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.213899371423283\n",
            "SCOPE mean: 0.3706575399878209, SCOPE var: 0.06365026905318534\n",
            "Total Loss: 0.0011414070581419707\n",
            "----------------------------------------\n",
            "Epoch 222\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.212312886039252\n",
            "SCOPE mean: 0.3704812418538535, SCOPE var: 0.0636540589009376\n",
            "Total Loss: 0.001128605915944466\n",
            "----------------------------------------\n",
            "Epoch 223\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.21153232778457\n",
            "SCOPE mean: 0.3702992013158597, SCOPE var: 0.06365742546790625\n",
            "Total Loss: 0.0011160458816041698\n",
            "----------------------------------------\n",
            "Epoch 224\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.209457713067387\n",
            "SCOPE mean: 0.3701107668359852, SCOPE var: 0.06366023645554074\n",
            "Total Loss: 0.0011043939088845756\n",
            "----------------------------------------\n",
            "Epoch 225\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.207350941257152\n",
            "SCOPE mean: 0.3699152330737629, SCOPE var: 0.06366168019820351\n",
            "Total Loss: 0.001093068886240749\n",
            "----------------------------------------\n",
            "Epoch 226\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.205331642037773\n",
            "SCOPE mean: 0.36972567610620877, SCOPE var: 0.06366199466084949\n",
            "Total Loss: 0.0010817444342502132\n",
            "----------------------------------------\n",
            "Epoch 227\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.203340548624965\n",
            "SCOPE mean: 0.36953097313489947, SCOPE var: 0.0636611706830482\n",
            "Total Loss: 0.0010704274652743118\n",
            "----------------------------------------\n",
            "Epoch 228\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.201333489485759\n",
            "SCOPE mean: 0.3693344219339036, SCOPE var: 0.06365961794701246\n",
            "Total Loss: 0.0010594695320016142\n",
            "----------------------------------------\n",
            "Epoch 229\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.200802340329691\n",
            "SCOPE mean: 0.3691417481549429, SCOPE var: 0.06365759817725583\n",
            "Total Loss: 0.001048264280395501\n",
            "----------------------------------------\n",
            "Epoch 230\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.201393507699372\n",
            "SCOPE mean: 0.36894961521330116, SCOPE var: 0.0636549350507567\n",
            "Total Loss: 0.0010375842630034628\n",
            "----------------------------------------\n",
            "Epoch 231\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.200750680386836\n",
            "SCOPE mean: 0.3687592768158023, SCOPE var: 0.06365187124238869\n",
            "Total Loss: 0.0010270063477899251\n",
            "----------------------------------------\n",
            "Epoch 232\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.198789305772129\n",
            "SCOPE mean: 0.36856754960706867, SCOPE var: 0.06364840378106952\n",
            "Total Loss: 0.0010165349119320272\n",
            "----------------------------------------\n",
            "Epoch 233\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.195653585572833\n",
            "SCOPE mean: 0.36837127098374667, SCOPE var: 0.06364486227753281\n",
            "Total Loss: 0.0010061760750210177\n",
            "----------------------------------------\n",
            "Epoch 234\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.191748467752525\n",
            "SCOPE mean: 0.3681917457915854, SCOPE var: 0.06363992300842188\n",
            "Total Loss: 0.0009959710023179672\n",
            "----------------------------------------\n",
            "Epoch 235\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.187626206324211\n",
            "SCOPE mean: 0.36803717554658616, SCOPE var: 0.06363307372645974\n",
            "Total Loss: 0.0009861881615531474\n",
            "----------------------------------------\n",
            "Epoch 236\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.185456812565796\n",
            "SCOPE mean: 0.36789173801626185, SCOPE var: 0.06362708200561047\n",
            "Total Loss: 0.0009766100879130804\n",
            "----------------------------------------\n",
            "Epoch 237\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.185059595237117\n",
            "SCOPE mean: 0.3677450484179608, SCOPE var: 0.0636206167026949\n",
            "Total Loss: 0.0009676117567653944\n",
            "----------------------------------------\n",
            "Epoch 238\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.184133821431194\n",
            "SCOPE mean: 0.36762446626256423, SCOPE var: 0.06361281670441632\n",
            "Total Loss: 0.0009589635175839891\n",
            "----------------------------------------\n",
            "Epoch 239\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.18153962064927\n",
            "SCOPE mean: 0.3675008801131913, SCOPE var: 0.06360565853217576\n",
            "Total Loss: 0.0009507772652662422\n",
            "----------------------------------------\n",
            "Epoch 240\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.17831321716887\n",
            "SCOPE mean: 0.3673762788473571, SCOPE var: 0.06359929135823876\n",
            "Total Loss: 0.00094290571509126\n",
            "----------------------------------------\n",
            "Epoch 241\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.176791178562565\n",
            "SCOPE mean: 0.36722867117636915, SCOPE var: 0.06359140293222997\n",
            "Total Loss: 0.0009349252863256278\n",
            "----------------------------------------\n",
            "Epoch 242\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.176714675464869\n",
            "SCOPE mean: 0.3670780207982828, SCOPE var: 0.06358346573148409\n",
            "Total Loss: 0.0009267876093854804\n",
            "----------------------------------------\n",
            "Epoch 243\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.17778127460207\n",
            "SCOPE mean: 0.36692924595658205, SCOPE var: 0.06357581636729916\n",
            "Total Loss: 0.0009188704775665796\n",
            "----------------------------------------\n",
            "Epoch 244\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.178616702972283\n",
            "SCOPE mean: 0.36679356844436384, SCOPE var: 0.06356993604611644\n",
            "Total Loss: 0.0009113476242844505\n",
            "----------------------------------------\n",
            "Epoch 245\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.177952173631924\n",
            "SCOPE mean: 0.3666695145307867, SCOPE var: 0.06356583681948234\n",
            "Total Loss: 0.0009032665512222704\n",
            "----------------------------------------\n",
            "Epoch 246\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.176591233153188\n",
            "SCOPE mean: 0.3665562057114911, SCOPE var: 0.06356281857064432\n",
            "Total Loss: 0.0008953353581062134\n",
            "----------------------------------------\n",
            "Epoch 247\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.174728182743957\n",
            "SCOPE mean: 0.36629997782621715, SCOPE var: 0.06355936009750897\n",
            "Total Loss: 0.0008877763125156028\n",
            "----------------------------------------\n",
            "Epoch 248\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.175759669750335\n",
            "SCOPE mean: 0.36607837416645805, SCOPE var: 0.06355866527735834\n",
            "Total Loss: 0.0008800151704434655\n",
            "----------------------------------------\n",
            "Epoch 249\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.17950265167279\n",
            "SCOPE mean: 0.3658917624852282, SCOPE var: 0.06356005294815528\n",
            "Total Loss: 0.0008723960794597328\n",
            "----------------------------------------\n",
            "Epoch 250\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.18192471939395\n",
            "SCOPE mean: 0.3657611507145003, SCOPE var: 0.06356405682405088\n",
            "Total Loss: 0.0008644974119012324\n",
            "----------------------------------------\n",
            "Epoch 251\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.183987367474318\n",
            "SCOPE mean: 0.3656626284489622, SCOPE var: 0.06356988609742491\n",
            "Total Loss: 0.0008565281850552356\n",
            "----------------------------------------\n",
            "Epoch 252\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.18582925750768\n",
            "SCOPE mean: 0.3655804541825997, SCOPE var: 0.06357735442600419\n",
            "Total Loss: 0.0008490837504116982\n",
            "----------------------------------------\n",
            "Epoch 253\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.190234785925664\n",
            "SCOPE mean: 0.3655302411659316, SCOPE var: 0.06358740332777174\n",
            "Total Loss: 0.0008417606155942545\n",
            "----------------------------------------\n",
            "Epoch 254\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.19669002167175\n",
            "SCOPE mean: 0.3655155516929444, SCOPE var: 0.0636002258453294\n",
            "Total Loss: 0.0008346674757789715\n",
            "----------------------------------------\n",
            "Epoch 255\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.202066515062768\n",
            "SCOPE mean: 0.3655435827332171, SCOPE var: 0.06361568328827032\n",
            "Total Loss: 0.0008279219187743835\n",
            "----------------------------------------\n",
            "Epoch 256\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.205595938304203\n",
            "SCOPE mean: 0.36559624032770255, SCOPE var: 0.06363241123106679\n",
            "Total Loss: 0.0008208804601532535\n",
            "----------------------------------------\n",
            "Epoch 257\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.209715913044677\n",
            "SCOPE mean: 0.36566484531537974, SCOPE var: 0.0636502317253002\n",
            "Total Loss: 0.0008141267153334008\n",
            "----------------------------------------\n",
            "Epoch 258\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.214472528870571\n",
            "SCOPE mean: 0.36574383535821225, SCOPE var: 0.06366860961301878\n",
            "Total Loss: 0.000807417545107576\n",
            "----------------------------------------\n",
            "Epoch 259\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.21903650714075\n",
            "SCOPE mean: 0.3658148522778927, SCOPE var: 0.06368552131763915\n",
            "Total Loss: 0.0008005776639587472\n",
            "----------------------------------------\n",
            "Epoch 260\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.223442345037284\n",
            "SCOPE mean: 0.36586228642639784, SCOPE var: 0.06369966144112642\n",
            "Total Loss: 0.0007937509339039936\n",
            "----------------------------------------\n",
            "Epoch 261\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.227783212803283\n",
            "SCOPE mean: 0.3658910444930577, SCOPE var: 0.06371140404105362\n",
            "Total Loss: 0.0007870980661552682\n",
            "----------------------------------------\n",
            "Epoch 262\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.23269766255138\n",
            "SCOPE mean: 0.36589323156822656, SCOPE var: 0.06372046479205058\n",
            "Total Loss: 0.0007804882076985078\n",
            "----------------------------------------\n",
            "Epoch 263\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.23812512668942\n",
            "SCOPE mean: 0.36587217425012275, SCOPE var: 0.06372605229182259\n",
            "Total Loss: 0.0007740055257305978\n",
            "----------------------------------------\n",
            "Epoch 264\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.242703907309059\n",
            "SCOPE mean: 0.3658388937622075, SCOPE var: 0.06372977601391468\n",
            "Total Loss: 0.0007676810796546532\n",
            "----------------------------------------\n",
            "Epoch 265\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.245868246664505\n",
            "SCOPE mean: 0.36579397238073325, SCOPE var: 0.06373021560400795\n",
            "Total Loss: 0.000761367808252277\n",
            "----------------------------------------\n",
            "Epoch 266\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.248670804403904\n",
            "SCOPE mean: 0.3657364174145757, SCOPE var: 0.06372779075883343\n",
            "Total Loss: 0.0007557211430366218\n",
            "----------------------------------------\n",
            "Epoch 267\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.254066467946863\n",
            "SCOPE mean: 0.36567351554561317, SCOPE var: 0.06372524656096533\n",
            "Total Loss: 0.00074993979590307\n",
            "----------------------------------------\n",
            "Epoch 268\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.259127169602486\n",
            "SCOPE mean: 0.3656231237591438, SCOPE var: 0.0637233314699451\n",
            "Total Loss: 0.0007445594449388057\n",
            "----------------------------------------\n",
            "Epoch 269\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.263762411075303\n",
            "SCOPE mean: 0.365587961596846, SCOPE var: 0.0637221428636787\n",
            "Total Loss: 0.0007393315056125469\n",
            "----------------------------------------\n",
            "Epoch 270\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.267434155454113\n",
            "SCOPE mean: 0.365575840937702, SCOPE var: 0.06372226121738928\n",
            "Total Loss: 0.0007340816125693395\n",
            "----------------------------------------\n",
            "Epoch 271\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.270945120904177\n",
            "SCOPE mean: 0.3655902281174077, SCOPE var: 0.06372415374722581\n",
            "Total Loss: 0.0007291080721612834\n",
            "----------------------------------------\n",
            "Epoch 272\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.275500363943713\n",
            "SCOPE mean: 0.3656289360910717, SCOPE var: 0.06372797105902524\n",
            "Total Loss: 0.0007241988809812468\n",
            "----------------------------------------\n",
            "Epoch 273\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.280958246449302\n",
            "SCOPE mean: 0.36569146794102225, SCOPE var: 0.06373364057137615\n",
            "Total Loss: 0.0007193551794503262\n",
            "----------------------------------------\n",
            "Epoch 274\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.287033196608608\n",
            "SCOPE mean: 0.3657845325886867, SCOPE var: 0.06374125507699265\n",
            "Total Loss: 0.0007147996247546668\n",
            "----------------------------------------\n",
            "Epoch 275\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.29166433083816\n",
            "SCOPE mean: 0.3658887701669772, SCOPE var: 0.06374967876137692\n",
            "Total Loss: 0.0007105090502023975\n",
            "----------------------------------------\n",
            "Epoch 276\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.295869284776582\n",
            "SCOPE mean: 0.36600044854339253, SCOPE var: 0.06375804505759797\n",
            "Total Loss: 0.0007064611365610776\n",
            "----------------------------------------\n",
            "Epoch 277\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.30011076920433\n",
            "SCOPE mean: 0.3661210522398404, SCOPE var: 0.06376541138085644\n",
            "Total Loss: 0.000702515752629999\n",
            "----------------------------------------\n",
            "Epoch 278\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.304284253166323\n",
            "SCOPE mean: 0.3662323582508535, SCOPE var: 0.06377203497186056\n",
            "Total Loss: 0.0006986011700452377\n",
            "----------------------------------------\n",
            "Epoch 279\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.308256200214222\n",
            "SCOPE mean: 0.3663338336934368, SCOPE var: 0.06377788272425401\n",
            "Total Loss: 0.0006947945554019831\n",
            "----------------------------------------\n",
            "Epoch 280\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.31180302405579\n",
            "SCOPE mean: 0.3664216102273554, SCOPE var: 0.06378255757469893\n",
            "Total Loss: 0.000691034162096405\n",
            "----------------------------------------\n",
            "Epoch 281\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.314203048423275\n",
            "SCOPE mean: 0.3665221049904926, SCOPE var: 0.06378766822166013\n",
            "Total Loss: 0.0006873207086821526\n",
            "----------------------------------------\n",
            "Epoch 282\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.31612892853654\n",
            "SCOPE mean: 0.3666078109553192, SCOPE var: 0.06379155011814955\n",
            "Total Loss: 0.0006836028651133134\n",
            "----------------------------------------\n",
            "Epoch 283\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.317622262535917\n",
            "SCOPE mean: 0.36667311987602585, SCOPE var: 0.06379417257839151\n",
            "Total Loss: 0.0006799192194671801\n",
            "----------------------------------------\n",
            "Epoch 284\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.318702113635892\n",
            "SCOPE mean: 0.3666871855157735, SCOPE var: 0.0637951685825955\n",
            "Total Loss: 0.0006763648220266429\n",
            "----------------------------------------\n",
            "Epoch 285\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.320291541457932\n",
            "SCOPE mean: 0.3666916909208818, SCOPE var: 0.06379457682492\n",
            "Total Loss: 0.0006728051830606302\n",
            "----------------------------------------\n",
            "Epoch 286\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.32249330645448\n",
            "SCOPE mean: 0.3666917937691362, SCOPE var: 0.06379270465681386\n",
            "Total Loss: 0.0006693980659780435\n",
            "----------------------------------------\n",
            "Epoch 287\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.323443577492393\n",
            "SCOPE mean: 0.36668517731427414, SCOPE var: 0.0637895910057823\n",
            "Total Loss: 0.0006660441032233375\n",
            "----------------------------------------\n",
            "Epoch 288\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.325642294565997\n",
            "SCOPE mean: 0.3666511520361312, SCOPE var: 0.06378501066965248\n",
            "Total Loss: 0.0006627289921075937\n",
            "----------------------------------------\n",
            "Epoch 289\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.327196342948842\n",
            "SCOPE mean: 0.36661168795512633, SCOPE var: 0.06378047440724098\n",
            "Total Loss: 0.0006595697473319924\n",
            "----------------------------------------\n",
            "Epoch 290\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.328100563938168\n",
            "SCOPE mean: 0.36657800738858964, SCOPE var: 0.06377624296074971\n",
            "Total Loss: 0.000656467366781894\n",
            "----------------------------------------\n",
            "Epoch 291\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.33013810528937\n",
            "SCOPE mean: 0.36654098308142974, SCOPE var: 0.06377217369302544\n",
            "Total Loss: 0.0006533209026447615\n",
            "----------------------------------------\n",
            "Epoch 292\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.332020789632587\n",
            "SCOPE mean: 0.3665048662879781, SCOPE var: 0.06376843788662617\n",
            "Total Loss: 0.000650289508705984\n",
            "----------------------------------------\n",
            "Epoch 293\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.331972096536614\n",
            "SCOPE mean: 0.3664849436718719, SCOPE var: 0.06376582641427939\n",
            "Total Loss: 0.0006473395543968389\n",
            "----------------------------------------\n",
            "Epoch 294\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.333174033531032\n",
            "SCOPE mean: 0.36646841831165794, SCOPE var: 0.06376388954494812\n",
            "Total Loss: 0.0006443847790711533\n",
            "----------------------------------------\n",
            "Epoch 295\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.335564924015175\n",
            "SCOPE mean: 0.366451127418787, SCOPE var: 0.06376214707204625\n",
            "Total Loss: 0.0006414892397070734\n",
            "----------------------------------------\n",
            "Epoch 296\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.337236161918197\n",
            "SCOPE mean: 0.366437588404855, SCOPE var: 0.06376041700375823\n",
            "Total Loss: 0.0006385755716677886\n",
            "----------------------------------------\n",
            "Epoch 297\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.338244735196094\n",
            "SCOPE mean: 0.3664246841625535, SCOPE var: 0.06375846141763734\n",
            "Total Loss: 0.0006356528439578101\n",
            "----------------------------------------\n",
            "Epoch 298\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.340434446854522\n",
            "SCOPE mean: 0.36640425479310695, SCOPE var: 0.0637561402416741\n",
            "Total Loss: 0.0006328136761507235\n",
            "----------------------------------------\n",
            "Epoch 299\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.342618481326038\n",
            "SCOPE mean: 0.36638823339771565, SCOPE var: 0.06375438914476396\n",
            "Total Loss: 0.0006300510539829017\n",
            "----------------------------------------\n",
            "Epoch 300\n",
            "IS mean: 0.5079378512789022,IS variance: 0.07086930484469886\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.342846487622321\n",
            "SCOPE mean: 0.36637744368310515, SCOPE var: 0.06375294966329942\n",
            "Total Loss: 0.0006272240032216123\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[ 0.0835, -0.3921],\n",
            "        [ 0.6596,  0.6254],\n",
            "        [ 0.1929,  0.2114],\n",
            "        [-0.4935,  0.0814],\n",
            "        [-0.7224,  0.2942],\n",
            "        [-0.2404,  0.1889],\n",
            "        [ 0.2143, -0.3222],\n",
            "        [ 0.6186,  0.2123],\n",
            "        [ 0.6034, -0.5077],\n",
            "        [-0.0528,  0.5687],\n",
            "        [-0.2079,  0.1971],\n",
            "        [ 0.6827,  0.2998],\n",
            "        [-0.1136,  0.1752],\n",
            "        [ 0.5364, -0.3096],\n",
            "        [-0.4542, -0.5580],\n",
            "        [ 0.5397, -0.5596]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([ 0.6803,  0.5143, -0.2061,  0.2658,  0.4450,  0.0175, -0.3148,  0.6688,\n",
            "         0.6689,  0.4066,  0.6191, -0.1288,  0.1200,  0.4052,  0.1458,  0.5111],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[-0.0171, -0.2420,  0.1718,  0.2219, -0.1210,  0.0137, -0.1424, -0.2227,\n",
            "          0.0986, -0.0231,  0.0235,  0.0468,  0.1766, -0.1048, -0.0814,  0.2342],\n",
            "        [ 0.2692,  0.0677,  0.2145, -0.1980, -0.0408,  0.1611, -0.3102, -0.0012,\n",
            "         -0.1259, -0.0275,  0.1671, -0.1891, -0.1002, -0.0182, -0.1259, -0.0589],\n",
            "        [ 0.2099,  0.2058,  0.1408, -0.0093, -0.0362, -0.0360, -0.1193, -0.1161,\n",
            "          0.2075, -0.2330, -0.0796, -0.0748,  0.2586,  0.1635,  0.0552,  0.2694],\n",
            "        [ 0.1863,  0.0590,  0.1387,  0.0879, -0.2118,  0.1697, -0.1947, -0.0145,\n",
            "         -0.0686,  0.1087, -0.1879,  0.1069, -0.1878, -0.1222, -0.2227,  0.0051],\n",
            "        [-0.1643, -0.1127, -0.0934,  0.2210, -0.2500,  0.0963, -0.1302,  0.0803,\n",
            "          0.1122, -0.0609, -0.0205, -0.1677, -0.1331,  0.1083,  0.1072, -0.1621],\n",
            "        [-0.1079, -0.1673, -0.1302, -0.2470,  0.1872, -0.0672, -0.1368,  0.0801,\n",
            "          0.0585,  0.0241, -0.0237, -0.1004, -0.0120,  0.2229, -0.1159,  0.2241],\n",
            "        [ 0.0451,  0.1797, -0.1321, -0.2681,  0.1788,  0.0431,  0.2221, -0.0697,\n",
            "         -0.2474, -0.1868, -0.0938, -0.0949,  0.2599,  0.0088, -0.1035,  0.0332],\n",
            "        [ 0.2174,  0.1086, -0.1263, -0.0039,  0.2612, -0.2774,  0.2607, -0.1822,\n",
            "         -0.1054,  0.0022, -0.1802,  0.1418,  0.1077, -0.0409,  0.1650,  0.0127],\n",
            "        [-0.0719, -0.1127, -0.1129,  0.1372, -0.1809, -0.2977,  0.0483, -0.2721,\n",
            "          0.2466, -0.1511,  0.0276, -0.0797,  0.1024,  0.0007,  0.1503,  0.2460],\n",
            "        [ 0.1794,  0.1400, -0.0500, -0.0990,  0.1086, -0.0752, -0.1198, -0.1675,\n",
            "         -0.0463, -0.0123,  0.0423, -0.2292,  0.0055,  0.1342,  0.1119, -0.1072],\n",
            "        [-0.1370,  0.2155, -0.1595,  0.0126, -0.0856,  0.1536, -0.1867, -0.1316,\n",
            "         -0.1612, -0.0629, -0.1104,  0.1849, -0.1961,  0.1900,  0.2456, -0.2629],\n",
            "        [-0.2352, -0.1309, -0.2083, -0.0624, -0.2587, -0.1504,  0.2266, -0.2020,\n",
            "         -0.0315, -0.0477,  0.0465,  0.1790,  0.0102, -0.1102, -0.0392,  0.1488],\n",
            "        [-0.1119, -0.2594,  0.0623,  0.3188,  0.1356,  0.1006,  0.2708,  0.1998,\n",
            "         -0.0142, -0.0542, -0.2762, -0.0494, -0.2562, -0.1391, -0.0462,  0.2480],\n",
            "        [-0.0121, -0.0016, -0.4183,  0.1952, -0.0868,  0.0467, -0.3144, -0.4424,\n",
            "          0.1344, -0.0594,  0.3387,  0.0252,  0.1462, -0.1410, -0.0465,  0.0835],\n",
            "        [ 0.0978,  0.1492, -0.1510, -0.4146,  0.1473, -0.0333,  0.0291, -0.0109,\n",
            "         -0.0629, -0.0256, -0.0416, -0.0045,  0.0053,  0.2302, -0.0045,  0.2455],\n",
            "        [-0.0954, -0.0170,  0.0237, -0.2007,  0.1142,  0.0108,  0.2015,  0.2097,\n",
            "          0.1212,  0.0374, -0.0839, -0.3591,  0.2429, -0.0574, -0.1534, -0.1538]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([ 0.0247, -0.0642, -0.0807, -0.0478,  0.1287, -0.1980, -0.0695,  0.2221,\n",
            "         0.2353, -0.0281, -0.1459,  0.1613, -0.0224,  0.0774,  0.1318, -0.0747],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[-0.0948,  0.0858,  0.0633,  0.1590,  0.2164, -0.2281,  0.0984,  0.1026,\n",
            "          0.1204, -0.2102, -0.1762, -0.1924, -0.0625, -0.2665, -0.1089,  0.0494]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([-0.0653], dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NN_l1_l2_reg(\n",
              "  (hidden_layers): ModuleList(\n",
              "    (0): Linear(in_features=2, out_features=16, bias=True)\n",
              "    (1): Linear(in_features=16, out_features=16, bias=True)\n",
              "  )\n",
              "  (output_layer): Linear(in_features=16, out_features=1, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b_400 = action_probs_top_n_epsilon(q_table, 1, 0.4)\n",
        "pi_b_400 = experiment_actions(400, env_50, P_pi_b_400)\n",
        "P_pi_e_400 = action_probs_top_n_epsilon(q_table, 1, 0.05)\n",
        "pi_e_400 = experiment_actions(1000, env_50, P_pi_e_400)\n",
        "# model_400_random_pi_b_400 = CustomizableFeatureNet(input_dim=2, hidden_dims=[16, 16], output_dim=1, dtype = torch.float64, l2_lambda=0.002)\n",
        "model_400_random_pi_b_400 = NN_l1_l2_reg(input_dim=2, hidden_dims=[16, 16], output_dim=1, dtype = torch.float64, l1_lambda=0.0001, l2_lambda = 0.0001)\n",
        "test_400_random_pi_b_400 = SCOPE_straight(model_400_random_pi_b_400, 0.99, 10000, pi_b_400, P_pi_b_400, P_pi_e_400, 0.3, dtype = torch.float64)\n",
        "test_400_random_pi_b_400.train_var_scope(400, 0.001, 1, 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-O0SfP2vggd3",
        "outputId": "eb9c834e-0078-45a8-d63a-5106a1365e7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0538, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.879882049994008\n",
            "SCOPE mean: 0.2813944638295345, SCOPE var: 0.03804615043113175\n",
            "Total Loss: 0.05384612892349079\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0205, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.64835634280359\n",
            "SCOPE mean: 0.2771221231141596, SCOPE var: 0.037947585553909785\n",
            "Total Loss: 0.020525783240966614\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0196, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.600753818380567\n",
            "SCOPE mean: 0.27897801446152903, SCOPE var: 0.03797091717547304\n",
            "Total Loss: 0.019638155283731886\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0186, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.582750305290279\n",
            "SCOPE mean: 0.28231881386406193, SCOPE var: 0.037978481890781665\n",
            "Total Loss: 0.018643988000599056\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0177, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.58865709435286\n",
            "SCOPE mean: 0.2864181591636185, SCOPE var: 0.03797829586215583\n",
            "Total Loss: 0.017677854138337154\n",
            "----------------------------------------\n",
            "Epoch 6\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0167, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.617321702120291\n",
            "SCOPE mean: 0.2910491632245716, SCOPE var: 0.03796895367656432\n",
            "Total Loss: 0.016742758320021797\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0158, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.667503453349912\n",
            "SCOPE mean: 0.29603691032463214, SCOPE var: 0.03794418562116097\n",
            "Total Loss: 0.01584057739779159\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0150, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.737185648764583\n",
            "SCOPE mean: 0.30130875164442705, SCOPE var: 0.037904186194777645\n",
            "Total Loss: 0.01497206149365926\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0141, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.823742516580691\n",
            "SCOPE mean: 0.30667276658619147, SCOPE var: 0.0378231172425168\n",
            "Total Loss: 0.014134761669872065\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0133, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.9262763814915616\n",
            "SCOPE mean: 0.3120969071981274, SCOPE var: 0.03772582577735007\n",
            "Total Loss: 0.013333198703668349\n",
            "----------------------------------------\n",
            "Epoch 11\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0126, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.04221129916977\n",
            "SCOPE mean: 0.3175720729338818, SCOPE var: 0.0376179253920245\n",
            "Total Loss: 0.012572212516650073\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0119, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.168964029558559\n",
            "SCOPE mean: 0.3230590290634479, SCOPE var: 0.03749698780683302\n",
            "Total Loss: 0.01185380621465516\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0112, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.304390043957822\n",
            "SCOPE mean: 0.3285714329783453, SCOPE var: 0.03736728104877898\n",
            "Total Loss: 0.011183471539452873\n",
            "----------------------------------------\n",
            "Epoch 14\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0106, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.44586564905445\n",
            "SCOPE mean: 0.33408412131436005, SCOPE var: 0.03722817618788714\n",
            "Total Loss: 0.010559593244082033\n",
            "----------------------------------------\n",
            "Epoch 15\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0100, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.591466171400343\n",
            "SCOPE mean: 0.339519257373425, SCOPE var: 0.037079011768074696\n",
            "Total Loss: 0.009976071843122868\n",
            "----------------------------------------\n",
            "Epoch 16\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0094, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.73901116088764\n",
            "SCOPE mean: 0.34477917445311507, SCOPE var: 0.03692253231344406\n",
            "Total Loss: 0.009439294306527499\n",
            "----------------------------------------\n",
            "Epoch 17\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0089, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.886101688759314\n",
            "SCOPE mean: 0.34973701986912875, SCOPE var: 0.03674987511252093\n",
            "Total Loss: 0.008948315595477633\n",
            "----------------------------------------\n",
            "Epoch 18\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0085, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.032305017552066\n",
            "SCOPE mean: 0.3543616039299462, SCOPE var: 0.03657085041643409\n",
            "Total Loss: 0.008500203443021558\n",
            "----------------------------------------\n",
            "Epoch 19\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0081, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.175297424294694\n",
            "SCOPE mean: 0.35867634707598556, SCOPE var: 0.036385813283336\n",
            "Total Loss: 0.008092453477073972\n",
            "----------------------------------------\n",
            "Epoch 20\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0077, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.31316000431308\n",
            "SCOPE mean: 0.362561454633227, SCOPE var: 0.036190506597469856\n",
            "Total Loss: 0.00772478843644224\n",
            "----------------------------------------\n",
            "Epoch 21\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0074, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.443025194964445\n",
            "SCOPE mean: 0.3661041997264006, SCOPE var: 0.035995909244774006\n",
            "Total Loss: 0.007392742366292496\n",
            "----------------------------------------\n",
            "Epoch 22\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0071, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.564179493776555\n",
            "SCOPE mean: 0.3696947611297698, SCOPE var: 0.0358743971472568\n",
            "Total Loss: 0.007082268679694625\n",
            "----------------------------------------\n",
            "Epoch 23\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0068, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.676956044550307\n",
            "SCOPE mean: 0.37242716061216813, SCOPE var: 0.035763757076326064\n",
            "Total Loss: 0.006797619863456522\n",
            "----------------------------------------\n",
            "Epoch 24\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0065, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.78093898809508\n",
            "SCOPE mean: 0.3739213348484584, SCOPE var: 0.03565010255971402\n",
            "Total Loss: 0.0065349590636538495\n",
            "----------------------------------------\n",
            "Epoch 25\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0063, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.875581931052661\n",
            "SCOPE mean: 0.37508022052342094, SCOPE var: 0.0355483484883637\n",
            "Total Loss: 0.006291165846935884\n",
            "----------------------------------------\n",
            "Epoch 26\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0061, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.962523435799207\n",
            "SCOPE mean: 0.37602384695370616, SCOPE var: 0.035449296768382196\n",
            "Total Loss: 0.006063955207991017\n",
            "----------------------------------------\n",
            "Epoch 27\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0059, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.042356532811285\n",
            "SCOPE mean: 0.37680197530739346, SCOPE var: 0.03535434363350475\n",
            "Total Loss: 0.005855883864779161\n",
            "----------------------------------------\n",
            "Epoch 28\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0057, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.11601655210851\n",
            "SCOPE mean: 0.3773629414321115, SCOPE var: 0.035261060467950744\n",
            "Total Loss: 0.005661161034518433\n",
            "----------------------------------------\n",
            "Epoch 29\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0055, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.184617787353945\n",
            "SCOPE mean: 0.3777469604739302, SCOPE var: 0.03517417270367467\n",
            "Total Loss: 0.005477873385375674\n",
            "----------------------------------------\n",
            "Epoch 30\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0053, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.248773203626955\n",
            "SCOPE mean: 0.3780316500526102, SCOPE var: 0.03509477515519142\n",
            "Total Loss: 0.005306524114610603\n",
            "----------------------------------------\n",
            "Epoch 31\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0051, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.309721453615861\n",
            "SCOPE mean: 0.37823499957298307, SCOPE var: 0.03501613410645268\n",
            "Total Loss: 0.005144324183590083\n",
            "----------------------------------------\n",
            "Epoch 32\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0050, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.367815613389329\n",
            "SCOPE mean: 0.3783801723098583, SCOPE var: 0.034939328699265595\n",
            "Total Loss: 0.004991000025790858\n",
            "----------------------------------------\n",
            "Epoch 33\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0048, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.423580725548065\n",
            "SCOPE mean: 0.37848970747608973, SCOPE var: 0.034864848292731065\n",
            "Total Loss: 0.004846309351724808\n",
            "----------------------------------------\n",
            "Epoch 34\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0047, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.477268766488717\n",
            "SCOPE mean: 0.3785235609419805, SCOPE var: 0.03479777370898984\n",
            "Total Loss: 0.004704500337202964\n",
            "----------------------------------------\n",
            "Epoch 35\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.52942289764895\n",
            "SCOPE mean: 0.378539495302159, SCOPE var: 0.034734591743456486\n",
            "Total Loss: 0.00456637509791779\n",
            "----------------------------------------\n",
            "Epoch 36\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0044, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.579487272719243\n",
            "SCOPE mean: 0.37854395895979703, SCOPE var: 0.03467437922991218\n",
            "Total Loss: 0.004439673096168213\n",
            "----------------------------------------\n",
            "Epoch 37\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0043, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.626882556969422\n",
            "SCOPE mean: 0.3785856758432237, SCOPE var: 0.03461956027321488\n",
            "Total Loss: 0.004319136771024824\n",
            "----------------------------------------\n",
            "Epoch 38\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0042, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.671168126408512\n",
            "SCOPE mean: 0.37863838413291173, SCOPE var: 0.03456760839354757\n",
            "Total Loss: 0.004201931361156707\n",
            "----------------------------------------\n",
            "Epoch 39\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0041, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.71218624765885\n",
            "SCOPE mean: 0.37867949105699056, SCOPE var: 0.034519275156783595\n",
            "Total Loss: 0.004085804849674415\n",
            "----------------------------------------\n",
            "Epoch 40\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0040, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.749705494613542\n",
            "SCOPE mean: 0.37869550513991185, SCOPE var: 0.034474566877436566\n",
            "Total Loss: 0.003970806220054955\n",
            "----------------------------------------\n",
            "Epoch 41\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0039, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.783802379478969\n",
            "SCOPE mean: 0.37869554305692865, SCOPE var: 0.03443399997743054\n",
            "Total Loss: 0.003858268200764757\n",
            "----------------------------------------\n",
            "Epoch 42\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0038, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.813902057163268\n",
            "SCOPE mean: 0.3786806724482392, SCOPE var: 0.03439727898933355\n",
            "Total Loss: 0.003752061519300712\n",
            "----------------------------------------\n",
            "Epoch 43\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0037, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.840767200908958\n",
            "SCOPE mean: 0.3786115985755351, SCOPE var: 0.034369623302413756\n",
            "Total Loss: 0.0036510087053753873\n",
            "----------------------------------------\n",
            "Epoch 44\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.864619052227908\n",
            "SCOPE mean: 0.37849162319680835, SCOPE var: 0.03435309071148398\n",
            "Total Loss: 0.0035543619180556972\n",
            "----------------------------------------\n",
            "Epoch 45\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0035, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.885698669029393\n",
            "SCOPE mean: 0.3783501498791145, SCOPE var: 0.034340273963746025\n",
            "Total Loss: 0.003460763667166105\n",
            "----------------------------------------\n",
            "Epoch 46\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0034, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.90490490291154\n",
            "SCOPE mean: 0.37822725419141057, SCOPE var: 0.0343304118115539\n",
            "Total Loss: 0.0033714572107811716\n",
            "----------------------------------------\n",
            "Epoch 47\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0033, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.922345104752544\n",
            "SCOPE mean: 0.37812517837250964, SCOPE var: 0.034322421918468946\n",
            "Total Loss: 0.003286409274268991\n",
            "----------------------------------------\n",
            "Epoch 48\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0032, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.939090282903228\n",
            "SCOPE mean: 0.37799840235768617, SCOPE var: 0.034315086995992256\n",
            "Total Loss: 0.0032052165742405725\n",
            "----------------------------------------\n",
            "Epoch 49\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0031, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.956130300303494\n",
            "SCOPE mean: 0.3779025154204008, SCOPE var: 0.034307920374831824\n",
            "Total Loss: 0.0031277822163535214\n",
            "----------------------------------------\n",
            "Epoch 50\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0031, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.97417368374562\n",
            "SCOPE mean: 0.37785959744655195, SCOPE var: 0.03430127502604206\n",
            "Total Loss: 0.003053616726176196\n",
            "----------------------------------------\n",
            "Epoch 51\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0030, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.993868188478666\n",
            "SCOPE mean: 0.37784926454011725, SCOPE var: 0.03429387637467697\n",
            "Total Loss: 0.002981846102339828\n",
            "----------------------------------------\n",
            "Epoch 52\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0029, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.015241126390746\n",
            "SCOPE mean: 0.3778689868797547, SCOPE var: 0.03428801654510341\n",
            "Total Loss: 0.002912316238998548\n",
            "----------------------------------------\n",
            "Epoch 53\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0028, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.038279461993605\n",
            "SCOPE mean: 0.3779343379157394, SCOPE var: 0.03428428954849055\n",
            "Total Loss: 0.0028450272814130213\n",
            "----------------------------------------\n",
            "Epoch 54\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0028, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.062253614447089\n",
            "SCOPE mean: 0.37804792299885914, SCOPE var: 0.034287798113156076\n",
            "Total Loss: 0.002779789011600805\n",
            "----------------------------------------\n",
            "Epoch 55\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0027, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.087309433126077\n",
            "SCOPE mean: 0.37836588361882106, SCOPE var: 0.03432562787527492\n",
            "Total Loss: 0.00271658697800258\n",
            "----------------------------------------\n",
            "Epoch 56\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0027, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.112781659112224\n",
            "SCOPE mean: 0.37872249743344566, SCOPE var: 0.034366211357550476\n",
            "Total Loss: 0.002655570878349512\n",
            "----------------------------------------\n",
            "Epoch 57\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0026, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.137915137002738\n",
            "SCOPE mean: 0.37908736292684897, SCOPE var: 0.03440879306187464\n",
            "Total Loss: 0.002596691564882775\n",
            "----------------------------------------\n",
            "Epoch 58\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0025, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.162042309768973\n",
            "SCOPE mean: 0.37944229558572334, SCOPE var: 0.03445279817852128\n",
            "Total Loss: 0.002540162688534226\n",
            "----------------------------------------\n",
            "Epoch 59\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0025, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.184358706623437\n",
            "SCOPE mean: 0.37976209590582233, SCOPE var: 0.03449744792398691\n",
            "Total Loss: 0.002485810643070206\n",
            "----------------------------------------\n",
            "Epoch 60\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0024, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.204640295798336\n",
            "SCOPE mean: 0.3800312513459272, SCOPE var: 0.034542568730910266\n",
            "Total Loss: 0.002433787257312214\n",
            "----------------------------------------\n",
            "Epoch 61\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0024, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.222641885682954\n",
            "SCOPE mean: 0.3803154323986648, SCOPE var: 0.03460664749576094\n",
            "Total Loss: 0.0023832943462956183\n",
            "----------------------------------------\n",
            "Epoch 62\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0023, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.237995850829924\n",
            "SCOPE mean: 0.38055853592758226, SCOPE var: 0.03467247360592582\n",
            "Total Loss: 0.0023343189235915146\n",
            "----------------------------------------\n",
            "Epoch 63\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0023, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.250919921801271\n",
            "SCOPE mean: 0.3812877895799457, SCOPE var: 0.03473871575265981\n",
            "Total Loss: 0.002287032572627214\n",
            "----------------------------------------\n",
            "Epoch 64\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0022, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.261809106843566\n",
            "SCOPE mean: 0.38237100369577837, SCOPE var: 0.03481908805221491\n",
            "Total Loss: 0.002241393958444255\n",
            "----------------------------------------\n",
            "Epoch 65\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0022, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.270324713928783\n",
            "SCOPE mean: 0.38338491076630743, SCOPE var: 0.034900653469915145\n",
            "Total Loss: 0.002196782706792315\n",
            "----------------------------------------\n",
            "Epoch 66\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0022, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.276936671393981\n",
            "SCOPE mean: 0.3843220800910619, SCOPE var: 0.03498069915463379\n",
            "Total Loss: 0.0021535023605011062\n",
            "----------------------------------------\n",
            "Epoch 67\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0021, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.282382817538885\n",
            "SCOPE mean: 0.3851929050768247, SCOPE var: 0.03506027651183404\n",
            "Total Loss: 0.002112794037901691\n",
            "----------------------------------------\n",
            "Epoch 68\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0021, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.287241682482472\n",
            "SCOPE mean: 0.38601611792303475, SCOPE var: 0.03514005891498095\n",
            "Total Loss: 0.002073645472632387\n",
            "----------------------------------------\n",
            "Epoch 69\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0020, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.292033712199324\n",
            "SCOPE mean: 0.38669313613582945, SCOPE var: 0.03520069503951945\n",
            "Total Loss: 0.0020362819369285014\n",
            "----------------------------------------\n",
            "Epoch 70\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0020, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.29717142468984\n",
            "SCOPE mean: 0.387254624182083, SCOPE var: 0.03524420220777447\n",
            "Total Loss: 0.0020001319837625424\n",
            "----------------------------------------\n",
            "Epoch 71\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0020, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.302933147859402\n",
            "SCOPE mean: 0.38779015157720176, SCOPE var: 0.03528685970816079\n",
            "Total Loss: 0.0019656933540641744\n",
            "----------------------------------------\n",
            "Epoch 72\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0019, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.309639375017435\n",
            "SCOPE mean: 0.388296169712004, SCOPE var: 0.03532821276503172\n",
            "Total Loss: 0.0019326576344828377\n",
            "----------------------------------------\n",
            "Epoch 73\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0019, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.31751911391049\n",
            "SCOPE mean: 0.3887828738592667, SCOPE var: 0.0353685132491286\n",
            "Total Loss: 0.0019006831560968347\n",
            "----------------------------------------\n",
            "Epoch 74\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0019, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.326537170079913\n",
            "SCOPE mean: 0.38926399499670605, SCOPE var: 0.0354077150828753\n",
            "Total Loss: 0.0018696507181968267\n",
            "----------------------------------------\n",
            "Epoch 75\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0018, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.33651948269523\n",
            "SCOPE mean: 0.3897431274446921, SCOPE var: 0.035445665538414675\n",
            "Total Loss: 0.0018395366146649733\n",
            "----------------------------------------\n",
            "Epoch 76\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0018, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.347252880227483\n",
            "SCOPE mean: 0.39019870144114477, SCOPE var: 0.03548252289764072\n",
            "Total Loss: 0.0018103702328408696\n",
            "----------------------------------------\n",
            "Epoch 77\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0018, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.358358540936784\n",
            "SCOPE mean: 0.390626684593354, SCOPE var: 0.03551827956304316\n",
            "Total Loss: 0.0017821779050182505\n",
            "----------------------------------------\n",
            "Epoch 78\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0018, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.369303696168622\n",
            "SCOPE mean: 0.39099118783552, SCOPE var: 0.03555325031662101\n",
            "Total Loss: 0.0017548868206970064\n",
            "----------------------------------------\n",
            "Epoch 79\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0017, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.379312707390401\n",
            "SCOPE mean: 0.39130155665864685, SCOPE var: 0.035587071587147336\n",
            "Total Loss: 0.0017277483563675736\n",
            "----------------------------------------\n",
            "Epoch 80\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0017, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.388415031531057\n",
            "SCOPE mean: 0.3915630481391674, SCOPE var: 0.03561976627186956\n",
            "Total Loss: 0.0017012988046834305\n",
            "----------------------------------------\n",
            "Epoch 81\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0017, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.39637413754753\n",
            "SCOPE mean: 0.39177694785616307, SCOPE var: 0.03565130794757324\n",
            "Total Loss: 0.0016755589350264568\n",
            "----------------------------------------\n",
            "Epoch 82\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0017, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.403058995258084\n",
            "SCOPE mean: 0.3919463583554923, SCOPE var: 0.035681725824442644\n",
            "Total Loss: 0.001650490590618593\n",
            "----------------------------------------\n",
            "Epoch 83\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0016, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.408628556820625\n",
            "SCOPE mean: 0.3920846066272337, SCOPE var: 0.035711445435451725\n",
            "Total Loss: 0.001625858306876061\n",
            "----------------------------------------\n",
            "Epoch 84\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0016, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.413232050158268\n",
            "SCOPE mean: 0.39219669108349897, SCOPE var: 0.035740617821825006\n",
            "Total Loss: 0.0016018700886802249\n",
            "----------------------------------------\n",
            "Epoch 85\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0016, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.417029381420257\n",
            "SCOPE mean: 0.3922874028330188, SCOPE var: 0.035769370107303\n",
            "Total Loss: 0.0015785311796283523\n",
            "----------------------------------------\n",
            "Epoch 86\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0016, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.420247229303705\n",
            "SCOPE mean: 0.39236263275171457, SCOPE var: 0.03579782892034419\n",
            "Total Loss: 0.0015560183213634894\n",
            "----------------------------------------\n",
            "Epoch 87\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0015, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.423160242396536\n",
            "SCOPE mean: 0.3924277767735729, SCOPE var: 0.03582617715131039\n",
            "Total Loss: 0.001534094026104605\n",
            "----------------------------------------\n",
            "Epoch 88\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0015, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.426016680483487\n",
            "SCOPE mean: 0.39249076719577586, SCOPE var: 0.0358545541562812\n",
            "Total Loss: 0.0015127739946341641\n",
            "----------------------------------------\n",
            "Epoch 89\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0015, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.429004992675903\n",
            "SCOPE mean: 0.39255886391414413, SCOPE var: 0.03588306030796312\n",
            "Total Loss: 0.001492118577488687\n",
            "----------------------------------------\n",
            "Epoch 90\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0015, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.43225651850185\n",
            "SCOPE mean: 0.3926335296851412, SCOPE var: 0.03591154021067696\n",
            "Total Loss: 0.001472318676962845\n",
            "----------------------------------------\n",
            "Epoch 91\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0015, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.43610562106788\n",
            "SCOPE mean: 0.3927218754267979, SCOPE var: 0.035940103136589255\n",
            "Total Loss: 0.0014532100680955424\n",
            "----------------------------------------\n",
            "Epoch 92\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0014, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.440584972630953\n",
            "SCOPE mean: 0.3928250097707446, SCOPE var: 0.03596872735500939\n",
            "Total Loss: 0.0014347052411406189\n",
            "----------------------------------------\n",
            "Epoch 93\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0014, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.445630767843989\n",
            "SCOPE mean: 0.39294272456836915, SCOPE var: 0.03599735673121363\n",
            "Total Loss: 0.0014166694329743313\n",
            "----------------------------------------\n",
            "Epoch 94\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0014, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.451124638985204\n",
            "SCOPE mean: 0.3930727773040227, SCOPE var: 0.03602600001661309\n",
            "Total Loss: 0.001399082075185759\n",
            "----------------------------------------\n",
            "Epoch 95\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0014, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.456796919389848\n",
            "SCOPE mean: 0.393215421655193, SCOPE var: 0.03605496578911638\n",
            "Total Loss: 0.001382012189484029\n",
            "----------------------------------------\n",
            "Epoch 96\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0014, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.462487021251702\n",
            "SCOPE mean: 0.3933947906560424, SCOPE var: 0.03608577600172919\n",
            "Total Loss: 0.0013653549382717468\n",
            "----------------------------------------\n",
            "Epoch 97\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.467981388599942\n",
            "SCOPE mean: 0.393569484071654, SCOPE var: 0.036116207724466824\n",
            "Total Loss: 0.0013491139887589717\n",
            "----------------------------------------\n",
            "Epoch 98\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.473116838515192\n",
            "SCOPE mean: 0.3937356941754762, SCOPE var: 0.036146259927317355\n",
            "Total Loss: 0.001333206462116245\n",
            "----------------------------------------\n",
            "Epoch 99\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.478065355264642\n",
            "SCOPE mean: 0.39391041813323546, SCOPE var: 0.03617669600906621\n",
            "Total Loss: 0.0013174517044676215\n",
            "----------------------------------------\n",
            "Epoch 100\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.482787286336661\n",
            "SCOPE mean: 0.39409231634525643, SCOPE var: 0.03620742781732509\n",
            "Total Loss: 0.0013020407268779495\n",
            "----------------------------------------\n",
            "Epoch 101\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.4872749319222\n",
            "SCOPE mean: 0.3942756049931901, SCOPE var: 0.03623824044957923\n",
            "Total Loss: 0.0012869887024479288\n",
            "----------------------------------------\n",
            "Epoch 102\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.491473764766381\n",
            "SCOPE mean: 0.3944591780100656, SCOPE var: 0.03626906834467671\n",
            "Total Loss: 0.0012722551338125133\n",
            "----------------------------------------\n",
            "Epoch 103\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.495459470076801\n",
            "SCOPE mean: 0.39464371133870435, SCOPE var: 0.036299918908440656\n",
            "Total Loss: 0.0012578485663446558\n",
            "----------------------------------------\n",
            "Epoch 104\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.499111868432383\n",
            "SCOPE mean: 0.3948292949258865, SCOPE var: 0.03633077230103543\n",
            "Total Loss: 0.0012437097398337316\n",
            "----------------------------------------\n",
            "Epoch 105\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.50276143858527\n",
            "SCOPE mean: 0.3950281901427913, SCOPE var: 0.03636214214494216\n",
            "Total Loss: 0.0012298745606906178\n",
            "----------------------------------------\n",
            "Epoch 106\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.50667796544743\n",
            "SCOPE mean: 0.3952458852162686, SCOPE var: 0.036393863338896104\n",
            "Total Loss: 0.0012162186363115731\n",
            "----------------------------------------\n",
            "Epoch 107\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.510799282657036\n",
            "SCOPE mean: 0.3954804302815973, SCOPE var: 0.036425734631749605\n",
            "Total Loss: 0.001202819581996694\n",
            "----------------------------------------\n",
            "Epoch 108\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.515140167412698\n",
            "SCOPE mean: 0.3957274666207586, SCOPE var: 0.036457864455716735\n",
            "Total Loss: 0.0011894806157849028\n",
            "----------------------------------------\n",
            "Epoch 109\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.51963767674837\n",
            "SCOPE mean: 0.39598749849775167, SCOPE var: 0.03649041582616257\n",
            "Total Loss: 0.0011762363997751563\n",
            "----------------------------------------\n",
            "Epoch 110\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.52423724998008\n",
            "SCOPE mean: 0.39624745264437256, SCOPE var: 0.036524587716473815\n",
            "Total Loss: 0.0011632075178953185\n",
            "----------------------------------------\n",
            "Epoch 111\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.528864366009563\n",
            "SCOPE mean: 0.39651477601823487, SCOPE var: 0.036558945378769366\n",
            "Total Loss: 0.0011503473976737441\n",
            "----------------------------------------\n",
            "Epoch 112\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.533450225467364\n",
            "SCOPE mean: 0.39678863291451816, SCOPE var: 0.03659349349899175\n",
            "Total Loss: 0.00113763509144086\n",
            "----------------------------------------\n",
            "Epoch 113\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.537874597208058\n",
            "SCOPE mean: 0.39706581254842194, SCOPE var: 0.03662820618212085\n",
            "Total Loss: 0.0011250016111349493\n",
            "----------------------------------------\n",
            "Epoch 114\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.54174721202099\n",
            "SCOPE mean: 0.39733873340650555, SCOPE var: 0.03666301538326299\n",
            "Total Loss: 0.0011124126819888037\n",
            "----------------------------------------\n",
            "Epoch 115\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.544910109145876\n",
            "SCOPE mean: 0.3976241279501981, SCOPE var: 0.03669867774909714\n",
            "Total Loss: 0.001099638804107061\n",
            "----------------------------------------\n",
            "Epoch 116\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.547564276101305\n",
            "SCOPE mean: 0.39791576996353223, SCOPE var: 0.03673506513235009\n",
            "Total Loss: 0.0010870401812397323\n",
            "----------------------------------------\n",
            "Epoch 117\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.549577523746839\n",
            "SCOPE mean: 0.3982088595417781, SCOPE var: 0.036772061321678755\n",
            "Total Loss: 0.0010746420618085134\n",
            "----------------------------------------\n",
            "Epoch 118\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.550872190184377\n",
            "SCOPE mean: 0.39849920907211833, SCOPE var: 0.036809552763474196\n",
            "Total Loss: 0.0010624577517853178\n",
            "----------------------------------------\n",
            "Epoch 119\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.55145068871517\n",
            "SCOPE mean: 0.3987121557949218, SCOPE var: 0.036847396022580414\n",
            "Total Loss: 0.0010505250594753427\n",
            "----------------------------------------\n",
            "Epoch 120\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.550946591986905\n",
            "SCOPE mean: 0.3984035375463762, SCOPE var: 0.036885463665245845\n",
            "Total Loss: 0.0010391248852774594\n",
            "----------------------------------------\n",
            "Epoch 121\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.549462004863594\n",
            "SCOPE mean: 0.3980884849759836, SCOPE var: 0.03692286107061771\n",
            "Total Loss: 0.0010281474154880427\n",
            "----------------------------------------\n",
            "Epoch 122\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.54728567094587\n",
            "SCOPE mean: 0.3977669002483288, SCOPE var: 0.03695964469883482\n",
            "Total Loss: 0.0010173998744095406\n",
            "----------------------------------------\n",
            "Epoch 123\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.54447555821714\n",
            "SCOPE mean: 0.39744520647503584, SCOPE var: 0.03699617103052702\n",
            "Total Loss: 0.0010068562606509377\n",
            "----------------------------------------\n",
            "Epoch 124\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.541177256655207\n",
            "SCOPE mean: 0.39712053468460773, SCOPE var: 0.03703194336138189\n",
            "Total Loss: 0.0009965162828848256\n",
            "----------------------------------------\n",
            "Epoch 125\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.537627047083909\n",
            "SCOPE mean: 0.39679628849153326, SCOPE var: 0.03706701069756232\n",
            "Total Loss: 0.00098641906390039\n",
            "----------------------------------------\n",
            "Epoch 126\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.53391422593051\n",
            "SCOPE mean: 0.3964754070458459, SCOPE var: 0.0371013936281143\n",
            "Total Loss: 0.0009764556103545416\n",
            "----------------------------------------\n",
            "Epoch 127\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.529886016000315\n",
            "SCOPE mean: 0.39615699201331384, SCOPE var: 0.03713657129663496\n",
            "Total Loss: 0.0009656596942145308\n",
            "----------------------------------------\n",
            "Epoch 128\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.526621055082213\n",
            "SCOPE mean: 0.395844190432682, SCOPE var: 0.03717539745166519\n",
            "Total Loss: 0.0009538355271857465\n",
            "----------------------------------------\n",
            "Epoch 129\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.524216999386523\n",
            "SCOPE mean: 0.39553636980004747, SCOPE var: 0.037217036920723125\n",
            "Total Loss: 0.0009418169192210282\n",
            "----------------------------------------\n",
            "Epoch 130\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.522529082911912\n",
            "SCOPE mean: 0.39516040046685097, SCOPE var: 0.037258213115773306\n",
            "Total Loss: 0.0009295677451459058\n",
            "----------------------------------------\n",
            "Epoch 131\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.521212495459212\n",
            "SCOPE mean: 0.3947597476849912, SCOPE var: 0.03730089897793121\n",
            "Total Loss: 0.0009169005563230327\n",
            "----------------------------------------\n",
            "Epoch 132\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.519620068019984\n",
            "SCOPE mean: 0.39434171053457884, SCOPE var: 0.037345023051386914\n",
            "Total Loss: 0.0009040646140495779\n",
            "----------------------------------------\n",
            "Epoch 133\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.517482852980645\n",
            "SCOPE mean: 0.3939630570194609, SCOPE var: 0.037391267707231064\n",
            "Total Loss: 0.0008915968421049825\n",
            "----------------------------------------\n",
            "Epoch 134\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.514130568143779\n",
            "SCOPE mean: 0.3935841490273112, SCOPE var: 0.037437435300281915\n",
            "Total Loss: 0.0008805957902064479\n",
            "----------------------------------------\n",
            "Epoch 135\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.509727387282359\n",
            "SCOPE mean: 0.3931879575506966, SCOPE var: 0.03747958337790154\n",
            "Total Loss: 0.0008700886594313384\n",
            "----------------------------------------\n",
            "Epoch 136\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.504427797173609\n",
            "SCOPE mean: 0.39276533023736593, SCOPE var: 0.03751942122614139\n",
            "Total Loss: 0.0008597866197608272\n",
            "----------------------------------------\n",
            "Epoch 137\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.49834537747585\n",
            "SCOPE mean: 0.3923211364181641, SCOPE var: 0.03755788598451068\n",
            "Total Loss: 0.0008497538384825518\n",
            "----------------------------------------\n",
            "Epoch 138\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.492119926589377\n",
            "SCOPE mean: 0.39184332286790585, SCOPE var: 0.03759275975231277\n",
            "Total Loss: 0.0008402037673717856\n",
            "----------------------------------------\n",
            "Epoch 139\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.485679472164009\n",
            "SCOPE mean: 0.3913629705729297, SCOPE var: 0.03762625985174265\n",
            "Total Loss: 0.0008309456676688538\n",
            "----------------------------------------\n",
            "Epoch 140\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.479138796465026\n",
            "SCOPE mean: 0.3909396969875319, SCOPE var: 0.037656491672360626\n",
            "Total Loss: 0.00082198261938846\n",
            "----------------------------------------\n",
            "Epoch 141\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.472368610530198\n",
            "SCOPE mean: 0.39052661044419057, SCOPE var: 0.03768523772064695\n",
            "Total Loss: 0.0008132116110174439\n",
            "----------------------------------------\n",
            "Epoch 142\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.465633468089612\n",
            "SCOPE mean: 0.39015451594186795, SCOPE var: 0.03770879123737678\n",
            "Total Loss: 0.0008045507109049261\n",
            "----------------------------------------\n",
            "Epoch 143\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.459484284211003\n",
            "SCOPE mean: 0.3898152162427449, SCOPE var: 0.037728931569435145\n",
            "Total Loss: 0.0007961551732717281\n",
            "----------------------------------------\n",
            "Epoch 144\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.453848641014892\n",
            "SCOPE mean: 0.3894896219508498, SCOPE var: 0.037748487203797886\n",
            "Total Loss: 0.0007880538068836039\n",
            "----------------------------------------\n",
            "Epoch 145\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.448720464117203\n",
            "SCOPE mean: 0.3891829995477355, SCOPE var: 0.037767786120411845\n",
            "Total Loss: 0.0007802928897351882\n",
            "----------------------------------------\n",
            "Epoch 146\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.444176867002689\n",
            "SCOPE mean: 0.3888982465045083, SCOPE var: 0.03778695601644626\n",
            "Total Loss: 0.0007727261124595542\n",
            "----------------------------------------\n",
            "Epoch 147\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.440296646019497\n",
            "SCOPE mean: 0.3886546015980195, SCOPE var: 0.0378038914167099\n",
            "Total Loss: 0.0007652794330446669\n",
            "----------------------------------------\n",
            "Epoch 148\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.437297880724834\n",
            "SCOPE mean: 0.3884455393302695, SCOPE var: 0.03781941686510907\n",
            "Total Loss: 0.0007581031360775616\n",
            "----------------------------------------\n",
            "Epoch 149\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.435212661869253\n",
            "SCOPE mean: 0.3882658797738533, SCOPE var: 0.037835139974612735\n",
            "Total Loss: 0.0007511921578428567\n",
            "----------------------------------------\n",
            "Epoch 150\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.433822033810133\n",
            "SCOPE mean: 0.3881144179163319, SCOPE var: 0.037851153203123565\n",
            "Total Loss: 0.0007444405786108289\n",
            "----------------------------------------\n",
            "Epoch 151\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.432997172238531\n",
            "SCOPE mean: 0.3879896365498614, SCOPE var: 0.03786748033441919\n",
            "Total Loss: 0.0007378258415158648\n",
            "----------------------------------------\n",
            "Epoch 152\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.432319698079896\n",
            "SCOPE mean: 0.38789009993118445, SCOPE var: 0.03788411576176869\n",
            "Total Loss: 0.000731514165345533\n",
            "----------------------------------------\n",
            "Epoch 153\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.431791688997981\n",
            "SCOPE mean: 0.38781043601134496, SCOPE var: 0.03790102234941159\n",
            "Total Loss: 0.0007254092806176991\n",
            "----------------------------------------\n",
            "Epoch 154\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.431208791740904\n",
            "SCOPE mean: 0.38774707709032513, SCOPE var: 0.037918177632961694\n",
            "Total Loss: 0.0007197052414161889\n",
            "----------------------------------------\n",
            "Epoch 155\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.430671890078367\n",
            "SCOPE mean: 0.3876983516419141, SCOPE var: 0.03793543350397006\n",
            "Total Loss: 0.0007141495422931727\n",
            "----------------------------------------\n",
            "Epoch 156\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.4302370285559\n",
            "SCOPE mean: 0.38767488162424935, SCOPE var: 0.03795276038424992\n",
            "Total Loss: 0.0007086994588172591\n",
            "----------------------------------------\n",
            "Epoch 157\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.429941706577862\n",
            "SCOPE mean: 0.3876646730284278, SCOPE var: 0.03797024739610581\n",
            "Total Loss: 0.0007033393735032606\n",
            "----------------------------------------\n",
            "Epoch 158\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.4298158494049\n",
            "SCOPE mean: 0.38764164959007075, SCOPE var: 0.03798617035700448\n",
            "Total Loss: 0.0006980603245013127\n",
            "----------------------------------------\n",
            "Epoch 159\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.429927130334011\n",
            "SCOPE mean: 0.3875885372149728, SCOPE var: 0.037998651617190356\n",
            "Total Loss: 0.000692872913305353\n",
            "----------------------------------------\n",
            "Epoch 160\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.430315217441603\n",
            "SCOPE mean: 0.387554136201759, SCOPE var: 0.03801046216672981\n",
            "Total Loss: 0.0006877989179276923\n",
            "----------------------------------------\n",
            "Epoch 161\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.431133941230563\n",
            "SCOPE mean: 0.38753667534974423, SCOPE var: 0.038022478349409694\n",
            "Total Loss: 0.0006828599473608315\n",
            "----------------------------------------\n",
            "Epoch 162\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.43246313168085\n",
            "SCOPE mean: 0.38753646236037037, SCOPE var: 0.03803464721733626\n",
            "Total Loss: 0.0006779962495918064\n",
            "----------------------------------------\n",
            "Epoch 163\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.434266298179049\n",
            "SCOPE mean: 0.38755342121064196, SCOPE var: 0.03804693713467452\n",
            "Total Loss: 0.0006731823582039564\n",
            "----------------------------------------\n",
            "Epoch 164\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.436525313923957\n",
            "SCOPE mean: 0.38758638268512385, SCOPE var: 0.03805931628321475\n",
            "Total Loss: 0.0006684181475926961\n",
            "----------------------------------------\n",
            "Epoch 165\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.439154900843732\n",
            "SCOPE mean: 0.3876350041165015, SCOPE var: 0.0380718520607679\n",
            "Total Loss: 0.0006637042681308724\n",
            "----------------------------------------\n",
            "Epoch 166\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.44207577845379\n",
            "SCOPE mean: 0.38769220359505635, SCOPE var: 0.03808517018220578\n",
            "Total Loss: 0.0006590852669096872\n",
            "----------------------------------------\n",
            "Epoch 167\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.445147460804538\n",
            "SCOPE mean: 0.3877588075933295, SCOPE var: 0.038098614362816544\n",
            "Total Loss: 0.0006545782025576386\n",
            "----------------------------------------\n",
            "Epoch 168\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.448158800081902\n",
            "SCOPE mean: 0.38783081316170265, SCOPE var: 0.038112126015254356\n",
            "Total Loss: 0.000650145170197248\n",
            "----------------------------------------\n",
            "Epoch 169\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.450916879860602\n",
            "SCOPE mean: 0.38790434537337876, SCOPE var: 0.03812566756892368\n",
            "Total Loss: 0.0006457885159017234\n",
            "----------------------------------------\n",
            "Epoch 170\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.453259599219914\n",
            "SCOPE mean: 0.3879763331587334, SCOPE var: 0.03813919922391736\n",
            "Total Loss: 0.0006415086228676585\n",
            "----------------------------------------\n",
            "Epoch 171\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.455092613708036\n",
            "SCOPE mean: 0.38804470870850805, SCOPE var: 0.0381526880513998\n",
            "Total Loss: 0.0006372981979205315\n",
            "----------------------------------------\n",
            "Epoch 172\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.456479115357327\n",
            "SCOPE mean: 0.3881099912525476, SCOPE var: 0.03816613587468918\n",
            "Total Loss: 0.0006331555231077194\n",
            "----------------------------------------\n",
            "Epoch 173\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.45746573049679\n",
            "SCOPE mean: 0.3881726927243486, SCOPE var: 0.03817949362269908\n",
            "Total Loss: 0.0006290726738862909\n",
            "----------------------------------------\n",
            "Epoch 174\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.458139394880202\n",
            "SCOPE mean: 0.3882340050581896, SCOPE var: 0.03819272581162665\n",
            "Total Loss: 0.0006250503188650996\n",
            "----------------------------------------\n",
            "Epoch 175\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.458577797524327\n",
            "SCOPE mean: 0.3882941781209467, SCOPE var: 0.03820570919389252\n",
            "Total Loss: 0.0006210780747100108\n",
            "----------------------------------------\n",
            "Epoch 176\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.458921828564396\n",
            "SCOPE mean: 0.3883551077636979, SCOPE var: 0.03821844199150953\n",
            "Total Loss: 0.0006171304101370825\n",
            "----------------------------------------\n",
            "Epoch 177\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.45930236444408\n",
            "SCOPE mean: 0.38841905093162965, SCOPE var: 0.0382309483835097\n",
            "Total Loss: 0.000613214994757077\n",
            "----------------------------------------\n",
            "Epoch 178\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.459794821377034\n",
            "SCOPE mean: 0.38848728981074115, SCOPE var: 0.038243241281227046\n",
            "Total Loss: 0.000609348981019225\n",
            "----------------------------------------\n",
            "Epoch 179\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.4604463444117\n",
            "SCOPE mean: 0.38855706617357566, SCOPE var: 0.038255387453278986\n",
            "Total Loss: 0.0006054894959535307\n",
            "----------------------------------------\n",
            "Epoch 180\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.461205078745058\n",
            "SCOPE mean: 0.3886276003274649, SCOPE var: 0.03826727934568845\n",
            "Total Loss: 0.0006016187127504326\n",
            "----------------------------------------\n",
            "Epoch 181\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.462035765727109\n",
            "SCOPE mean: 0.38870232294507284, SCOPE var: 0.03827897266566198\n",
            "Total Loss: 0.0005977735020082096\n",
            "----------------------------------------\n",
            "Epoch 182\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.46288047473842\n",
            "SCOPE mean: 0.3887787275597196, SCOPE var: 0.03829058631497876\n",
            "Total Loss: 0.0005939670448381065\n",
            "----------------------------------------\n",
            "Epoch 183\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.463729694150924\n",
            "SCOPE mean: 0.3888574905801335, SCOPE var: 0.03830214392470363\n",
            "Total Loss: 0.0005902068660641145\n",
            "----------------------------------------\n",
            "Epoch 184\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.464551432195243\n",
            "SCOPE mean: 0.38896496369152633, SCOPE var: 0.038313159061276865\n",
            "Total Loss: 0.0005864946509581238\n",
            "----------------------------------------\n",
            "Epoch 185\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.465320240782093\n",
            "SCOPE mean: 0.3890845918220982, SCOPE var: 0.038323998752453195\n",
            "Total Loss: 0.0005828581364707451\n",
            "----------------------------------------\n",
            "Epoch 186\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.466038928897744\n",
            "SCOPE mean: 0.38920654442161073, SCOPE var: 0.03833480663363664\n",
            "Total Loss: 0.0005792656035841763\n",
            "----------------------------------------\n",
            "Epoch 187\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.466665918462418\n",
            "SCOPE mean: 0.3893309675440144, SCOPE var: 0.03834567365946283\n",
            "Total Loss: 0.0005757363583331516\n",
            "----------------------------------------\n",
            "Epoch 188\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.46718135822943\n",
            "SCOPE mean: 0.3894586816709345, SCOPE var: 0.038356644504033574\n",
            "Total Loss: 0.0005722577729667011\n",
            "----------------------------------------\n",
            "Epoch 189\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.467663892738825\n",
            "SCOPE mean: 0.3895915233784577, SCOPE var: 0.03836768010163447\n",
            "Total Loss: 0.0005688221396052212\n",
            "----------------------------------------\n",
            "Epoch 190\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.468157714133646\n",
            "SCOPE mean: 0.38973934882432787, SCOPE var: 0.038377908628131965\n",
            "Total Loss: 0.0005654089796531536\n",
            "----------------------------------------\n",
            "Epoch 191\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.468703278589611\n",
            "SCOPE mean: 0.3898927345535103, SCOPE var: 0.03838834606998964\n",
            "Total Loss: 0.0005620294041325493\n",
            "----------------------------------------\n",
            "Epoch 192\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.469304568207166\n",
            "SCOPE mean: 0.39005178784722355, SCOPE var: 0.03839907273021158\n",
            "Total Loss: 0.0005587099181739079\n",
            "----------------------------------------\n",
            "Epoch 193\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.470013594709602\n",
            "SCOPE mean: 0.39021258447221263, SCOPE var: 0.03840972729430128\n",
            "Total Loss: 0.0005554409372163661\n",
            "----------------------------------------\n",
            "Epoch 194\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.470865350376618\n",
            "SCOPE mean: 0.3903811678681916, SCOPE var: 0.03842277293265755\n",
            "Total Loss: 0.0005522228668833239\n",
            "----------------------------------------\n",
            "Epoch 195\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.471796778364702\n",
            "SCOPE mean: 0.39055182955141643, SCOPE var: 0.03843623390026887\n",
            "Total Loss: 0.000549051609070545\n",
            "----------------------------------------\n",
            "Epoch 196\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.472791136755822\n",
            "SCOPE mean: 0.39072044167803816, SCOPE var: 0.03844959995967305\n",
            "Total Loss: 0.0005459220465340955\n",
            "----------------------------------------\n",
            "Epoch 197\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.473853390067507\n",
            "SCOPE mean: 0.3908866328677626, SCOPE var: 0.03846284284383154\n",
            "Total Loss: 0.000542826062226086\n",
            "----------------------------------------\n",
            "Epoch 198\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.474905619406591\n",
            "SCOPE mean: 0.3910541700804126, SCOPE var: 0.038476283974804126\n",
            "Total Loss: 0.0005397644738057574\n",
            "----------------------------------------\n",
            "Epoch 199\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.475908805288807\n",
            "SCOPE mean: 0.3912221086223838, SCOPE var: 0.03848985908431832\n",
            "Total Loss: 0.0005367349553361783\n",
            "----------------------------------------\n",
            "Epoch 200\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.476829882982116\n",
            "SCOPE mean: 0.39138949135981455, SCOPE var: 0.03850349823714216\n",
            "Total Loss: 0.0005337382090646086\n",
            "----------------------------------------\n",
            "Epoch 201\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.477676245955463\n",
            "SCOPE mean: 0.39155020518887, SCOPE var: 0.03851660725152071\n",
            "Total Loss: 0.0005307762364879678\n",
            "----------------------------------------\n",
            "Epoch 202\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.47842960459595\n",
            "SCOPE mean: 0.3917048099429929, SCOPE var: 0.038529331609596214\n",
            "Total Loss: 0.0005278476321666756\n",
            "----------------------------------------\n",
            "Epoch 203\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.47903489519736\n",
            "SCOPE mean: 0.39185739378713497, SCOPE var: 0.038542008675431574\n",
            "Total Loss: 0.0005249468582879272\n",
            "----------------------------------------\n",
            "Epoch 204\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.479512606342082\n",
            "SCOPE mean: 0.39200759788482353, SCOPE var: 0.03855459405577324\n",
            "Total Loss: 0.0005220809335956615\n",
            "----------------------------------------\n",
            "Epoch 205\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.479887936101537\n",
            "SCOPE mean: 0.3921523977638572, SCOPE var: 0.03856678584953313\n",
            "Total Loss: 0.0005192645099234131\n",
            "----------------------------------------\n",
            "Epoch 206\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.480098803136505\n",
            "SCOPE mean: 0.3922909678495326, SCOPE var: 0.03857853948064065\n",
            "Total Loss: 0.0005167052882541909\n",
            "----------------------------------------\n",
            "Epoch 207\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.480239986496569\n",
            "SCOPE mean: 0.39242486597113685, SCOPE var: 0.03858988057769964\n",
            "Total Loss: 0.0005141827204270316\n",
            "----------------------------------------\n",
            "Epoch 208\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.480298809938809\n",
            "SCOPE mean: 0.3925593098636665, SCOPE var: 0.03860118658574164\n",
            "Total Loss: 0.0005116943171108968\n",
            "----------------------------------------\n",
            "Epoch 209\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.480303337561297\n",
            "SCOPE mean: 0.3926944030673917, SCOPE var: 0.03861243598849221\n",
            "Total Loss: 0.000509238656039788\n",
            "----------------------------------------\n",
            "Epoch 210\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.480317963029693\n",
            "SCOPE mean: 0.39282581545768835, SCOPE var: 0.03862323920521586\n",
            "Total Loss: 0.0005068222657478859\n",
            "----------------------------------------\n",
            "Epoch 211\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.480366827673183\n",
            "SCOPE mean: 0.3929561817608292, SCOPE var: 0.03863360884995055\n",
            "Total Loss: 0.0005044664583907352\n",
            "----------------------------------------\n",
            "Epoch 212\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.48050410079236\n",
            "SCOPE mean: 0.39308593534855174, SCOPE var: 0.03864357542722675\n",
            "Total Loss: 0.0005021396372866164\n",
            "----------------------------------------\n",
            "Epoch 213\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.48075995417856\n",
            "SCOPE mean: 0.3932125656832092, SCOPE var: 0.03865305553239959\n",
            "Total Loss: 0.0004997962294431721\n",
            "----------------------------------------\n",
            "Epoch 214\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.481114202024795\n",
            "SCOPE mean: 0.3933412342701273, SCOPE var: 0.03866245327578034\n",
            "Total Loss: 0.0004974437472692435\n",
            "----------------------------------------\n",
            "Epoch 215\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.48153910883314\n",
            "SCOPE mean: 0.3934713541756741, SCOPE var: 0.038671759003737545\n",
            "Total Loss: 0.0004951111080666316\n",
            "----------------------------------------\n",
            "Epoch 216\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.481984780634443\n",
            "SCOPE mean: 0.39360201606136963, SCOPE var: 0.038680959809057516\n",
            "Total Loss: 0.0004927988952050868\n",
            "----------------------------------------\n",
            "Epoch 217\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.482422315368497\n",
            "SCOPE mean: 0.3937275760503132, SCOPE var: 0.03868966049459161\n",
            "Total Loss: 0.0004905056937417292\n",
            "----------------------------------------\n",
            "Epoch 218\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.4828004767264\n",
            "SCOPE mean: 0.3938474617744712, SCOPE var: 0.038697826808316696\n",
            "Total Loss: 0.0004882323632749129\n",
            "----------------------------------------\n",
            "Epoch 219\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.483019085494849\n",
            "SCOPE mean: 0.3939659211547288, SCOPE var: 0.03870587997876069\n",
            "Total Loss: 0.00048597781306648633\n",
            "----------------------------------------\n",
            "Epoch 220\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.483061131386858\n",
            "SCOPE mean: 0.394082496314235, SCOPE var: 0.03871382737845808\n",
            "Total Loss: 0.0004837418039123275\n",
            "----------------------------------------\n",
            "Epoch 221\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.482927315284444\n",
            "SCOPE mean: 0.3941968960533182, SCOPE var: 0.03872167811649118\n",
            "Total Loss: 0.00048152337983976406\n",
            "----------------------------------------\n",
            "Epoch 222\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.482591211006598\n",
            "SCOPE mean: 0.3943118218079507, SCOPE var: 0.03872946139472174\n",
            "Total Loss: 0.0004793210848186683\n",
            "----------------------------------------\n",
            "Epoch 223\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.482138191373371\n",
            "SCOPE mean: 0.394426237220672, SCOPE var: 0.03873682217297935\n",
            "Total Loss: 0.00047713250159734066\n",
            "----------------------------------------\n",
            "Epoch 224\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.481574185597871\n",
            "SCOPE mean: 0.39453526330642447, SCOPE var: 0.03874387463250465\n",
            "Total Loss: 0.00047494951650869005\n",
            "----------------------------------------\n",
            "Epoch 225\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.48088443891576\n",
            "SCOPE mean: 0.3946440159440566, SCOPE var: 0.03875112984986032\n",
            "Total Loss: 0.0004727742537056569\n",
            "----------------------------------------\n",
            "Epoch 226\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.480118132637097\n",
            "SCOPE mean: 0.39475325949222534, SCOPE var: 0.038758633350928155\n",
            "Total Loss: 0.0004706116552532087\n",
            "----------------------------------------\n",
            "Epoch 227\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.47934242761331\n",
            "SCOPE mean: 0.394857373964892, SCOPE var: 0.03876601886818394\n",
            "Total Loss: 0.00046846333022056494\n",
            "----------------------------------------\n",
            "Epoch 228\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.478576039785802\n",
            "SCOPE mean: 0.39495937218836197, SCOPE var: 0.03877333108241144\n",
            "Total Loss: 0.00046632808685273736\n",
            "----------------------------------------\n",
            "Epoch 229\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.47778133192467\n",
            "SCOPE mean: 0.3950648388851328, SCOPE var: 0.03878102848032659\n",
            "Total Loss: 0.00046420573211744596\n",
            "----------------------------------------\n",
            "Epoch 230\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.477004247702572\n",
            "SCOPE mean: 0.395168731806787, SCOPE var: 0.03878869917354934\n",
            "Total Loss: 0.0004620909739464083\n",
            "----------------------------------------\n",
            "Epoch 231\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.476223217994619\n",
            "SCOPE mean: 0.3952712457271669, SCOPE var: 0.03879637402735319\n",
            "Total Loss: 0.0004599848499833388\n",
            "----------------------------------------\n",
            "Epoch 232\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.475382880333958\n",
            "SCOPE mean: 0.39537629287153747, SCOPE var: 0.03880446715203775\n",
            "Total Loss: 0.0004578917907474891\n",
            "----------------------------------------\n",
            "Epoch 233\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.474489844894652\n",
            "SCOPE mean: 0.3954789397102515, SCOPE var: 0.038812536697193076\n",
            "Total Loss: 0.00045578849756799196\n",
            "----------------------------------------\n",
            "Epoch 234\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.473558430393142\n",
            "SCOPE mean: 0.3955798048875623, SCOPE var: 0.03882058210360962\n",
            "Total Loss: 0.00045369147953458456\n",
            "----------------------------------------\n",
            "Epoch 235\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.472579466128241\n",
            "SCOPE mean: 0.39567887753577147, SCOPE var: 0.03882859387444117\n",
            "Total Loss: 0.0004516058402898493\n",
            "----------------------------------------\n",
            "Epoch 236\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.471509561245224\n",
            "SCOPE mean: 0.39578118440414817, SCOPE var: 0.038836975917625735\n",
            "Total Loss: 0.0004495319330549223\n",
            "----------------------------------------\n",
            "Epoch 237\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.470401085577487\n",
            "SCOPE mean: 0.3958812202095152, SCOPE var: 0.03884526267297991\n",
            "Total Loss: 0.00044747251940417074\n",
            "----------------------------------------\n",
            "Epoch 238\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.469270957534247\n",
            "SCOPE mean: 0.39597881105897537, SCOPE var: 0.03885340776565439\n",
            "Total Loss: 0.0004454248366927625\n",
            "----------------------------------------\n",
            "Epoch 239\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.468132411054983\n",
            "SCOPE mean: 0.39606694070141923, SCOPE var: 0.038861465695765374\n",
            "Total Loss: 0.00044338600466579606\n",
            "----------------------------------------\n",
            "Epoch 240\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.466937593543793\n",
            "SCOPE mean: 0.39615804008552674, SCOPE var: 0.038869750585822795\n",
            "Total Loss: 0.00044134376513470507\n",
            "----------------------------------------\n",
            "Epoch 241\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.465634803331655\n",
            "SCOPE mean: 0.3962578824837315, SCOPE var: 0.03887839742793495\n",
            "Total Loss: 0.0004392861537847458\n",
            "----------------------------------------\n",
            "Epoch 242\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.46426972578925\n",
            "SCOPE mean: 0.39635852703993835, SCOPE var: 0.038886931507405596\n",
            "Total Loss: 0.00043723565684887185\n",
            "----------------------------------------\n",
            "Epoch 243\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.46287630921754\n",
            "SCOPE mean: 0.3964600197225749, SCOPE var: 0.038895332444085794\n",
            "Total Loss: 0.0004351984187183519\n",
            "----------------------------------------\n",
            "Epoch 244\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.461488701420699\n",
            "SCOPE mean: 0.396562041287472, SCOPE var: 0.0389035744094887\n",
            "Total Loss: 0.0004331726867478266\n",
            "----------------------------------------\n",
            "Epoch 245\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.460151663490917\n",
            "SCOPE mean: 0.3966650533977904, SCOPE var: 0.03891162607273194\n",
            "Total Loss: 0.00043116499422571775\n",
            "----------------------------------------\n",
            "Epoch 246\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.458871523111869\n",
            "SCOPE mean: 0.3967689096277516, SCOPE var: 0.03891947805206718\n",
            "Total Loss: 0.00042916759365841593\n",
            "----------------------------------------\n",
            "Epoch 247\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.45764021517078\n",
            "SCOPE mean: 0.396873233945594, SCOPE var: 0.03892712047905973\n",
            "Total Loss: 0.0004271811001607797\n",
            "----------------------------------------\n",
            "Epoch 248\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.456393639477774\n",
            "SCOPE mean: 0.3969827225316723, SCOPE var: 0.03893497907084673\n",
            "Total Loss: 0.0004252041629649558\n",
            "----------------------------------------\n",
            "Epoch 249\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.455071054977143\n",
            "SCOPE mean: 0.39709608946446573, SCOPE var: 0.03894300048509279\n",
            "Total Loss: 0.00042323879433993225\n",
            "----------------------------------------\n",
            "Epoch 250\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.453709703104396\n",
            "SCOPE mean: 0.397219299135764, SCOPE var: 0.03894940144238391\n",
            "Total Loss: 0.0004212854908281217\n",
            "----------------------------------------\n",
            "Epoch 251\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.452287788864291\n",
            "SCOPE mean: 0.39734530264013856, SCOPE var: 0.03895480863655347\n",
            "Total Loss: 0.0004193438334593141\n",
            "----------------------------------------\n",
            "Epoch 252\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.45077813333574\n",
            "SCOPE mean: 0.3974670203509501, SCOPE var: 0.0389598763818665\n",
            "Total Loss: 0.00041741362301547937\n",
            "----------------------------------------\n",
            "Epoch 253\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.449166612173574\n",
            "SCOPE mean: 0.3975841766045645, SCOPE var: 0.03896461255549616\n",
            "Total Loss: 0.000415498547392098\n",
            "----------------------------------------\n",
            "Epoch 254\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.447393938388833\n",
            "SCOPE mean: 0.3977018933207987, SCOPE var: 0.03896947332133112\n",
            "Total Loss: 0.00041360368254150527\n",
            "----------------------------------------\n",
            "Epoch 255\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.445470142368045\n",
            "SCOPE mean: 0.39781968258209954, SCOPE var: 0.03897441665447989\n",
            "Total Loss: 0.0004117228120482136\n",
            "----------------------------------------\n",
            "Epoch 256\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.443413616826424\n",
            "SCOPE mean: 0.3979372524033584, SCOPE var: 0.03897939751540122\n",
            "Total Loss: 0.0004098527629234954\n",
            "----------------------------------------\n",
            "Epoch 257\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.44125852206755\n",
            "SCOPE mean: 0.3980490698716829, SCOPE var: 0.03898382876235819\n",
            "Total Loss: 0.000407995240133896\n",
            "----------------------------------------\n",
            "Epoch 258\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.439027137477867\n",
            "SCOPE mean: 0.3981556713034711, SCOPE var: 0.038987732938791715\n",
            "Total Loss: 0.0004061488489543441\n",
            "----------------------------------------\n",
            "Epoch 259\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.436681579055866\n",
            "SCOPE mean: 0.39825553267871705, SCOPE var: 0.03899110479649732\n",
            "Total Loss: 0.0004042692418005919\n",
            "----------------------------------------\n",
            "Epoch 260\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.434328643830419\n",
            "SCOPE mean: 0.3983509928569943, SCOPE var: 0.03899414467699069\n",
            "Total Loss: 0.0004023673686124479\n",
            "----------------------------------------\n",
            "Epoch 261\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.432011370453468\n",
            "SCOPE mean: 0.3984430167775359, SCOPE var: 0.038996912486802024\n",
            "Total Loss: 0.0004004771220125679\n",
            "----------------------------------------\n",
            "Epoch 262\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.429688059626455\n",
            "SCOPE mean: 0.3985376035160821, SCOPE var: 0.03899989449973664\n",
            "Total Loss: 0.00039859177193818075\n",
            "----------------------------------------\n",
            "Epoch 263\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.427359003659273\n",
            "SCOPE mean: 0.39863439349249563, SCOPE var: 0.03900306502669758\n",
            "Total Loss: 0.0003967120190111847\n",
            "----------------------------------------\n",
            "Epoch 264\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.425012273367424\n",
            "SCOPE mean: 0.398732865533584, SCOPE var: 0.03900639569229634\n",
            "Total Loss: 0.0003948401012847687\n",
            "----------------------------------------\n",
            "Epoch 265\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.42260157362744\n",
            "SCOPE mean: 0.3988325204892844, SCOPE var: 0.03900975324409312\n",
            "Total Loss: 0.0003929775361832118\n",
            "----------------------------------------\n",
            "Epoch 266\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.42017767504302\n",
            "SCOPE mean: 0.398927223596536, SCOPE var: 0.03901265112991014\n",
            "Total Loss: 0.0003911199326548494\n",
            "----------------------------------------\n",
            "Epoch 267\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.417776406440252\n",
            "SCOPE mean: 0.39901824584664947, SCOPE var: 0.03901520396679614\n",
            "Total Loss: 0.0003892682613420556\n",
            "----------------------------------------\n",
            "Epoch 268\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.41542703867236\n",
            "SCOPE mean: 0.3991059013779609, SCOPE var: 0.03901754896815865\n",
            "Total Loss: 0.00038742511046262467\n",
            "----------------------------------------\n",
            "Epoch 269\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.413136233235598\n",
            "SCOPE mean: 0.3991907582226133, SCOPE var: 0.03901972260401501\n",
            "Total Loss: 0.00038559100739364073\n",
            "----------------------------------------\n",
            "Epoch 270\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.41088558891629\n",
            "SCOPE mean: 0.3992742251872058, SCOPE var: 0.0390218474589163\n",
            "Total Loss: 0.0003837836371333536\n",
            "----------------------------------------\n",
            "Epoch 271\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.408680480339001\n",
            "SCOPE mean: 0.39935679269412383, SCOPE var: 0.039023953270233364\n",
            "Total Loss: 0.00038198835463067876\n",
            "----------------------------------------\n",
            "Epoch 272\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.406474980432195\n",
            "SCOPE mean: 0.3994446811775411, SCOPE var: 0.03902655170844314\n",
            "Total Loss: 0.0003802030981288282\n",
            "----------------------------------------\n",
            "Epoch 273\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.404268182737189\n",
            "SCOPE mean: 0.39953753221768296, SCOPE var: 0.03902961442480496\n",
            "Total Loss: 0.0003784266456479323\n",
            "----------------------------------------\n",
            "Epoch 274\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.402013824011895\n",
            "SCOPE mean: 0.39963517377901336, SCOPE var: 0.03903298205456913\n",
            "Total Loss: 0.0003766528154674651\n",
            "----------------------------------------\n",
            "Epoch 275\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.399707689979971\n",
            "SCOPE mean: 0.3997416449308782, SCOPE var: 0.039036228109924714\n",
            "Total Loss: 0.00037488971455103086\n",
            "----------------------------------------\n",
            "Epoch 276\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.39740262138859\n",
            "SCOPE mean: 0.3998453643513631, SCOPE var: 0.039039269424101665\n",
            "Total Loss: 0.00037313754798449096\n",
            "----------------------------------------\n",
            "Epoch 277\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.395036218754885\n",
            "SCOPE mean: 0.3999445330332146, SCOPE var: 0.03904180221883651\n",
            "Total Loss: 0.0003713801611071707\n",
            "----------------------------------------\n",
            "Epoch 278\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.392636683243616\n",
            "SCOPE mean: 0.40003942782069846, SCOPE var: 0.03904399704038094\n",
            "Total Loss: 0.00036962580191073774\n",
            "----------------------------------------\n",
            "Epoch 279\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.390184193579397\n",
            "SCOPE mean: 0.4001309300891856, SCOPE var: 0.03904593954307994\n",
            "Total Loss: 0.0003678740990659119\n",
            "----------------------------------------\n",
            "Epoch 280\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.387694002443515\n",
            "SCOPE mean: 0.4002194580663965, SCOPE var: 0.03904769951961329\n",
            "Total Loss: 0.00036613158681583096\n",
            "----------------------------------------\n",
            "Epoch 281\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.385120335478904\n",
            "SCOPE mean: 0.4003053603893791, SCOPE var: 0.039049338655570746\n",
            "Total Loss: 0.000364394711707802\n",
            "----------------------------------------\n",
            "Epoch 282\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.382414528622641\n",
            "SCOPE mean: 0.40038912686554723, SCOPE var: 0.03905209031701615\n",
            "Total Loss: 0.00036266817256061875\n",
            "----------------------------------------\n",
            "Epoch 283\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.379597312327594\n",
            "SCOPE mean: 0.4004741104591721, SCOPE var: 0.03905545178070261\n",
            "Total Loss: 0.00036094757589092053\n",
            "----------------------------------------\n",
            "Epoch 284\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.376685682623524\n",
            "SCOPE mean: 0.4005632370992868, SCOPE var: 0.03905915836172988\n",
            "Total Loss: 0.00035923359082738645\n",
            "----------------------------------------\n",
            "Epoch 285\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.37373918729827\n",
            "SCOPE mean: 0.40064983115150093, SCOPE var: 0.03906268239902279\n",
            "Total Loss: 0.00035752933638821344\n",
            "----------------------------------------\n",
            "Epoch 286\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.370781593141404\n",
            "SCOPE mean: 0.4007340695457341, SCOPE var: 0.03906615303624577\n",
            "Total Loss: 0.0003558520605172474\n",
            "----------------------------------------\n",
            "Epoch 287\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.367780845159633\n",
            "SCOPE mean: 0.40081584608515375, SCOPE var: 0.039069559228877\n",
            "Total Loss: 0.0003542739916453171\n",
            "----------------------------------------\n",
            "Epoch 288\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.364734831201549\n",
            "SCOPE mean: 0.4008951800755173, SCOPE var: 0.03907291318526873\n",
            "Total Loss: 0.000352709598491838\n",
            "----------------------------------------\n",
            "Epoch 289\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.3616432800083\n",
            "SCOPE mean: 0.4009720660451421, SCOPE var: 0.03907622055211935\n",
            "Total Loss: 0.0003511684811209739\n",
            "----------------------------------------\n",
            "Epoch 290\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.358531397773417\n",
            "SCOPE mean: 0.40104501816175286, SCOPE var: 0.03907941700148967\n",
            "Total Loss: 0.00034965933750354084\n",
            "----------------------------------------\n",
            "Epoch 291\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.355335144533905\n",
            "SCOPE mean: 0.40111402313744593, SCOPE var: 0.039082406536382154\n",
            "Total Loss: 0.0003481717649755335\n",
            "----------------------------------------\n",
            "Epoch 292\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.352003253449016\n",
            "SCOPE mean: 0.4011788524778312, SCOPE var: 0.03908519415402758\n",
            "Total Loss: 0.00034667805336814357\n",
            "----------------------------------------\n",
            "Epoch 293\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.348591778609949\n",
            "SCOPE mean: 0.4012452346856767, SCOPE var: 0.03908672012725056\n",
            "Total Loss: 0.000345183951430219\n",
            "----------------------------------------\n",
            "Epoch 294\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.345043497039132\n",
            "SCOPE mean: 0.4013188953351509, SCOPE var: 0.0390875942002111\n",
            "Total Loss: 0.00034369884192437085\n",
            "----------------------------------------\n",
            "Epoch 295\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.341374171646352\n",
            "SCOPE mean: 0.4013961807619254, SCOPE var: 0.03908892664121939\n",
            "Total Loss: 0.00034222461447327296\n",
            "----------------------------------------\n",
            "Epoch 296\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.337610611122047\n",
            "SCOPE mean: 0.40146989796837446, SCOPE var: 0.039090123600653656\n",
            "Total Loss: 0.0003407560037196149\n",
            "----------------------------------------\n",
            "Epoch 297\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.333759213586578\n",
            "SCOPE mean: 0.40153939741637285, SCOPE var: 0.03909125049807453\n",
            "Total Loss: 0.00033928847604383297\n",
            "----------------------------------------\n",
            "Epoch 298\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.329834439237713\n",
            "SCOPE mean: 0.4016049802467236, SCOPE var: 0.039092280459707245\n",
            "Total Loss: 0.00033782933174626\n",
            "----------------------------------------\n",
            "Epoch 299\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.325855049031311\n",
            "SCOPE mean: 0.401667115066195, SCOPE var: 0.039093189839008745\n",
            "Total Loss: 0.0003363793698895118\n",
            "----------------------------------------\n",
            "Epoch 300\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.321838463960061\n",
            "SCOPE mean: 0.4017253856433445, SCOPE var: 0.039093657768324803\n",
            "Total Loss: 0.0003349393956235971\n",
            "----------------------------------------\n",
            "Epoch 301\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.317810325643736\n",
            "SCOPE mean: 0.4017802519346967, SCOPE var: 0.03909361666358454\n",
            "Total Loss: 0.00033350182220774697\n",
            "----------------------------------------\n",
            "Epoch 302\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.313682875642591\n",
            "SCOPE mean: 0.40183280943807337, SCOPE var: 0.03909302637825947\n",
            "Total Loss: 0.0003320494698513912\n",
            "----------------------------------------\n",
            "Epoch 303\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.309474788037665\n",
            "SCOPE mean: 0.40188326556526255, SCOPE var: 0.03909191256670192\n",
            "Total Loss: 0.0003306023877382338\n",
            "----------------------------------------\n",
            "Epoch 304\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.305135769476552\n",
            "SCOPE mean: 0.40193809213257903, SCOPE var: 0.03909083887952037\n",
            "Total Loss: 0.00032916002250464024\n",
            "----------------------------------------\n",
            "Epoch 305\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.30069246336825\n",
            "SCOPE mean: 0.40199610638150907, SCOPE var: 0.03908986730044133\n",
            "Total Loss: 0.0003277234389664947\n",
            "----------------------------------------\n",
            "Epoch 306\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.296186913451693\n",
            "SCOPE mean: 0.40204872491082444, SCOPE var: 0.03908842583888999\n",
            "Total Loss: 0.0003262924420697429\n",
            "----------------------------------------\n",
            "Epoch 307\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.29161074095763\n",
            "SCOPE mean: 0.40209697386491505, SCOPE var: 0.039086537363317936\n",
            "Total Loss: 0.0003248683591542807\n",
            "----------------------------------------\n",
            "Epoch 308\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.286945611246532\n",
            "SCOPE mean: 0.4021405945698247, SCOPE var: 0.039084226950610215\n",
            "Total Loss: 0.0003234617321198576\n",
            "----------------------------------------\n",
            "Epoch 309\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.282250284421425\n",
            "SCOPE mean: 0.4021797671027858, SCOPE var: 0.03908169325950947\n",
            "Total Loss: 0.0003220809032628828\n",
            "----------------------------------------\n",
            "Epoch 310\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.277508631447606\n",
            "SCOPE mean: 0.40222167193207203, SCOPE var: 0.03907950085284204\n",
            "Total Loss: 0.0003207064157705305\n",
            "----------------------------------------\n",
            "Epoch 311\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.272724741876964\n",
            "SCOPE mean: 0.40229270501854997, SCOPE var: 0.03908309211134227\n",
            "Total Loss: 0.00031933826998617584\n",
            "----------------------------------------\n",
            "Epoch 312\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.26796150669124\n",
            "SCOPE mean: 0.402367679779901, SCOPE var: 0.03908700436860536\n",
            "Total Loss: 0.00031798016728946775\n",
            "----------------------------------------\n",
            "Epoch 313\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.263290146642218\n",
            "SCOPE mean: 0.40243919490727803, SCOPE var: 0.03909050954767367\n",
            "Total Loss: 0.00031663041281198326\n",
            "----------------------------------------\n",
            "Epoch 314\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.258694198377547\n",
            "SCOPE mean: 0.4025081207596526, SCOPE var: 0.039093526217811835\n",
            "Total Loss: 0.000315287607122562\n",
            "----------------------------------------\n",
            "Epoch 315\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.254179884899257\n",
            "SCOPE mean: 0.4025749288226485, SCOPE var: 0.0390960835415134\n",
            "Total Loss: 0.00031395302562357277\n",
            "----------------------------------------\n",
            "Epoch 316\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.249780857039726\n",
            "SCOPE mean: 0.4026391394821318, SCOPE var: 0.039098273771407364\n",
            "Total Loss: 0.0003126274750877643\n",
            "----------------------------------------\n",
            "Epoch 317\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.245463086023175\n",
            "SCOPE mean: 0.4027007118401452, SCOPE var: 0.0391001336883698\n",
            "Total Loss: 0.00031130958638410665\n",
            "----------------------------------------\n",
            "Epoch 318\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.241211317059852\n",
            "SCOPE mean: 0.4027672971844743, SCOPE var: 0.039098300159910344\n",
            "Total Loss: 0.000310001521752069\n",
            "----------------------------------------\n",
            "Epoch 319\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.236950197327026\n",
            "SCOPE mean: 0.4028322286027541, SCOPE var: 0.03909546542392924\n",
            "Total Loss: 0.00030870368868574403\n",
            "----------------------------------------\n",
            "Epoch 320\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.232672376799371\n",
            "SCOPE mean: 0.40289317871977604, SCOPE var: 0.03909241650044695\n",
            "Total Loss: 0.0003074156305401615\n",
            "----------------------------------------\n",
            "Epoch 321\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.228263212961874\n",
            "SCOPE mean: 0.4029568118704236, SCOPE var: 0.03908965959193937\n",
            "Total Loss: 0.00030613522789183607\n",
            "----------------------------------------\n",
            "Epoch 322\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.223676484217657\n",
            "SCOPE mean: 0.4030221973513792, SCOPE var: 0.03908716666202057\n",
            "Total Loss: 0.0003048061795741145\n",
            "----------------------------------------\n",
            "Epoch 323\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.218972982935746\n",
            "SCOPE mean: 0.4030890863902909, SCOPE var: 0.03908486943741837\n",
            "Total Loss: 0.00030350530714472505\n",
            "----------------------------------------\n",
            "Epoch 324\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.214133560668069\n",
            "SCOPE mean: 0.40314837978928036, SCOPE var: 0.03908170490611243\n",
            "Total Loss: 0.00030219752357186293\n",
            "----------------------------------------\n",
            "Epoch 325\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.209207495163911\n",
            "SCOPE mean: 0.4032012078958671, SCOPE var: 0.03907772574940936\n",
            "Total Loss: 0.00030088073855624346\n",
            "----------------------------------------\n",
            "Epoch 326\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.204203321743863\n",
            "SCOPE mean: 0.40324805135242003, SCOPE var: 0.039072985432601924\n",
            "Total Loss: 0.0002995653270918084\n",
            "----------------------------------------\n",
            "Epoch 327\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.19912560772499\n",
            "SCOPE mean: 0.40328936613804456, SCOPE var: 0.039067535873119334\n",
            "Total Loss: 0.00029825248680988954\n",
            "----------------------------------------\n",
            "Epoch 328\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.193975754303752\n",
            "SCOPE mean: 0.40336643173016173, SCOPE var: 0.03907027890725369\n",
            "Total Loss: 0.00029695031153843435\n",
            "----------------------------------------\n",
            "Epoch 329\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.188683360342177\n",
            "SCOPE mean: 0.40351718574610024, SCOPE var: 0.03908962145086296\n",
            "Total Loss: 0.0002956603045421895\n",
            "----------------------------------------\n",
            "Epoch 330\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.183209981762078\n",
            "SCOPE mean: 0.4036644285609297, SCOPE var: 0.03910895769423818\n",
            "Total Loss: 0.00029437465612422865\n",
            "----------------------------------------\n",
            "Epoch 331\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.177474978668661\n",
            "SCOPE mean: 0.40381479397415027, SCOPE var: 0.03912893787520232\n",
            "Total Loss: 0.0002930947766950004\n",
            "----------------------------------------\n",
            "Epoch 332\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.171458967468622\n",
            "SCOPE mean: 0.4039670175620141, SCOPE var: 0.03914948975376621\n",
            "Total Loss: 0.00029182095461285164\n",
            "----------------------------------------\n",
            "Epoch 333\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.165214163457431\n",
            "SCOPE mean: 0.4041127285169889, SCOPE var: 0.03916988539917714\n",
            "Total Loss: 0.0002905548796579456\n",
            "----------------------------------------\n",
            "Epoch 334\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.158798921987692\n",
            "SCOPE mean: 0.4042521803888571, SCOPE var: 0.039190215509266206\n",
            "Total Loss: 0.0002892955340614319\n",
            "----------------------------------------\n",
            "Epoch 335\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.152237838978397\n",
            "SCOPE mean: 0.4043861688404927, SCOPE var: 0.039210479218666855\n",
            "Total Loss: 0.0002880424736913904\n",
            "----------------------------------------\n",
            "Epoch 336\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.145561556063551\n",
            "SCOPE mean: 0.40451573474197766, SCOPE var: 0.03923068039564624\n",
            "Total Loss: 0.0002867955655460679\n",
            "----------------------------------------\n",
            "Epoch 337\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.138720594659812\n",
            "SCOPE mean: 0.40464864194001526, SCOPE var: 0.039251456998135995\n",
            "Total Loss: 0.00028555115895565657\n",
            "----------------------------------------\n",
            "Epoch 338\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.131738374886469\n",
            "SCOPE mean: 0.4047848899803242, SCOPE var: 0.039272610388318405\n",
            "Total Loss: 0.00028431328894090886\n",
            "----------------------------------------\n",
            "Epoch 339\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.124677782150275\n",
            "SCOPE mean: 0.4049161962093748, SCOPE var: 0.03929339358418536\n",
            "Total Loss: 0.0002830865218575018\n",
            "----------------------------------------\n",
            "Epoch 340\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.117585181402273\n",
            "SCOPE mean: 0.405043812291853, SCOPE var: 0.0393139782698843\n",
            "Total Loss: 0.0002818643622790006\n",
            "----------------------------------------\n",
            "Epoch 341\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.110461126643266\n",
            "SCOPE mean: 0.4051685026832208, SCOPE var: 0.039334276368948984\n",
            "Total Loss: 0.00028064843231447387\n",
            "----------------------------------------\n",
            "Epoch 342\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.10330454935787\n",
            "SCOPE mean: 0.40529068416106284, SCOPE var: 0.039354292550065936\n",
            "Total Loss: 0.0002794413912418395\n",
            "----------------------------------------\n",
            "Epoch 343\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.096186880599094\n",
            "SCOPE mean: 0.4054104340675864, SCOPE var: 0.039374107676203494\n",
            "Total Loss: 0.0002782411289550464\n",
            "----------------------------------------\n",
            "Epoch 344\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.089105866927069\n",
            "SCOPE mean: 0.4055280685231501, SCOPE var: 0.039393735562923735\n",
            "Total Loss: 0.0002770461985882357\n",
            "----------------------------------------\n",
            "Epoch 345\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.082023568508712\n",
            "SCOPE mean: 0.40564327883055024, SCOPE var: 0.03941318321973861\n",
            "Total Loss: 0.00027585442891519136\n",
            "----------------------------------------\n",
            "Epoch 346\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.074862954925857\n",
            "SCOPE mean: 0.405763315691711, SCOPE var: 0.039433051286131074\n",
            "Total Loss: 0.000274677516581741\n",
            "----------------------------------------\n",
            "Epoch 347\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.067641821867921\n",
            "SCOPE mean: 0.4059041203954039, SCOPE var: 0.039451324188342005\n",
            "Total Loss: 0.0002734972221050993\n",
            "----------------------------------------\n",
            "Epoch 348\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.060360080584125\n",
            "SCOPE mean: 0.40608078235975487, SCOPE var: 0.039466090099043644\n",
            "Total Loss: 0.0002723098303788569\n",
            "----------------------------------------\n",
            "Epoch 349\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.053196740625973\n",
            "SCOPE mean: 0.4062560429640105, SCOPE var: 0.03948034481602931\n",
            "Total Loss: 0.00027113233045102363\n",
            "----------------------------------------\n",
            "Epoch 350\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.046189681142884\n",
            "SCOPE mean: 0.4064316334924174, SCOPE var: 0.039494087060612124\n",
            "Total Loss: 0.00026996831617410457\n",
            "----------------------------------------\n",
            "Epoch 351\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.039338866888679\n",
            "SCOPE mean: 0.406609844953195, SCOPE var: 0.0395075301197954\n",
            "Total Loss: 0.0002688125217187122\n",
            "----------------------------------------\n",
            "Epoch 352\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.03265822009154\n",
            "SCOPE mean: 0.4067912795238515, SCOPE var: 0.03952067910930889\n",
            "Total Loss: 0.0002676633211318709\n",
            "----------------------------------------\n",
            "Epoch 353\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.026143684097084\n",
            "SCOPE mean: 0.4069761621033943, SCOPE var: 0.039533541302347895\n",
            "Total Loss: 0.00026652344954754715\n",
            "----------------------------------------\n",
            "Epoch 354\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.019727948366187\n",
            "SCOPE mean: 0.407166832671426, SCOPE var: 0.039546264769544905\n",
            "Total Loss: 0.0002653793336257082\n",
            "----------------------------------------\n",
            "Epoch 355\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.013319532323141\n",
            "SCOPE mean: 0.4073695642113595, SCOPE var: 0.03955953642238378\n",
            "Total Loss: 0.0002642423540341455\n",
            "----------------------------------------\n",
            "Epoch 356\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.006888810151342\n",
            "SCOPE mean: 0.40757882774779436, SCOPE var: 0.03957306486067447\n",
            "Total Loss: 0.00026312655654240025\n",
            "----------------------------------------\n",
            "Epoch 357\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.000385046913369\n",
            "SCOPE mean: 0.40779008558188384, SCOPE var: 0.0395868098335814\n",
            "Total Loss: 0.0002620181983270944\n",
            "----------------------------------------\n",
            "Epoch 358\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.993824300203906\n",
            "SCOPE mean: 0.40799470131260157, SCOPE var: 0.03960003045193256\n",
            "Total Loss: 0.0002609171052623392\n",
            "----------------------------------------\n",
            "Epoch 359\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.987183082469038\n",
            "SCOPE mean: 0.40819153157429316, SCOPE var: 0.03961270060308292\n",
            "Total Loss: 0.00025982350195562876\n",
            "----------------------------------------\n",
            "Epoch 360\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.980340516247288\n",
            "SCOPE mean: 0.408387364231823, SCOPE var: 0.03962555173411071\n",
            "Total Loss: 0.00025873639686991993\n",
            "----------------------------------------\n",
            "Epoch 361\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.973322551531993\n",
            "SCOPE mean: 0.40858293431661574, SCOPE var: 0.0396386219516192\n",
            "Total Loss: 0.00025765530870338845\n",
            "----------------------------------------\n",
            "Epoch 362\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.966224862136537\n",
            "SCOPE mean: 0.40877117368533045, SCOPE var: 0.03965122284846284\n",
            "Total Loss: 0.00025657929450413863\n",
            "----------------------------------------\n",
            "Epoch 363\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.959078486090512\n",
            "SCOPE mean: 0.4089540819529402, SCOPE var: 0.03966341456758106\n",
            "Total Loss: 0.00025550958334585\n",
            "----------------------------------------\n",
            "Epoch 364\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.951900685678412\n",
            "SCOPE mean: 0.40913380547272005, SCOPE var: 0.03967527707295374\n",
            "Total Loss: 0.00025444755151147504\n",
            "----------------------------------------\n",
            "Epoch 365\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.94462339237599\n",
            "SCOPE mean: 0.4093229660737241, SCOPE var: 0.03968758957339133\n",
            "Total Loss: 0.00025339482901491655\n",
            "----------------------------------------\n",
            "Epoch 366\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.937255930483081\n",
            "SCOPE mean: 0.40953135467958496, SCOPE var: 0.03970024197886206\n",
            "Total Loss: 0.0002523362527552583\n",
            "----------------------------------------\n",
            "Epoch 367\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.930094891919005\n",
            "SCOPE mean: 0.4097482599007802, SCOPE var: 0.039712486716527336\n",
            "Total Loss: 0.0002512958900623777\n",
            "----------------------------------------\n",
            "Epoch 368\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.923193294058205\n",
            "SCOPE mean: 0.4099642055484914, SCOPE var: 0.03972334257883168\n",
            "Total Loss: 0.00025026427636851064\n",
            "----------------------------------------\n",
            "Epoch 369\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.916476260202007\n",
            "SCOPE mean: 0.41018029401635997, SCOPE var: 0.03973352289411556\n",
            "Total Loss: 0.0002492485755980984\n",
            "----------------------------------------\n",
            "Epoch 370\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.909771015299356\n",
            "SCOPE mean: 0.4104002077284796, SCOPE var: 0.03974373701070133\n",
            "Total Loss: 0.0002482792804254\n",
            "----------------------------------------\n",
            "Epoch 371\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.903002365815713\n",
            "SCOPE mean: 0.41062082968970515, SCOPE var: 0.039753937114175804\n",
            "Total Loss: 0.0002473156072790231\n",
            "----------------------------------------\n",
            "Epoch 372\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.896190750531726\n",
            "SCOPE mean: 0.410832161110898, SCOPE var: 0.03976339772577094\n",
            "Total Loss: 0.00024635268146748756\n",
            "----------------------------------------\n",
            "Epoch 373\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.889241403706203\n",
            "SCOPE mean: 0.41104199497434385, SCOPE var: 0.03977286872826298\n",
            "Total Loss: 0.00024539474695613986\n",
            "----------------------------------------\n",
            "Epoch 374\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.882210612194847\n",
            "SCOPE mean: 0.4112413573923147, SCOPE var: 0.039781627465504676\n",
            "Total Loss: 0.00024444236774242857\n",
            "----------------------------------------\n",
            "Epoch 375\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.87500841078062\n",
            "SCOPE mean: 0.4114422199502723, SCOPE var: 0.0397901925124533\n",
            "Total Loss: 0.00024349605673106142\n",
            "----------------------------------------\n",
            "Epoch 376\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.867659361263627\n",
            "SCOPE mean: 0.41164595257794373, SCOPE var: 0.039798508048005506\n",
            "Total Loss: 0.00024255000807632768\n",
            "----------------------------------------\n",
            "Epoch 377\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.860355868589703\n",
            "SCOPE mean: 0.4118451443854109, SCOPE var: 0.039806204166533694\n",
            "Total Loss: 0.0002415998967156844\n",
            "----------------------------------------\n",
            "Epoch 378\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.85307363297589\n",
            "SCOPE mean: 0.41204055334198275, SCOPE var: 0.03981336189826801\n",
            "Total Loss: 0.00024065467556695796\n",
            "----------------------------------------\n",
            "Epoch 379\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.84572796716751\n",
            "SCOPE mean: 0.41224049106399724, SCOPE var: 0.0398207489885268\n",
            "Total Loss: 0.00023971371625471655\n",
            "----------------------------------------\n",
            "Epoch 380\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.838277677821539\n",
            "SCOPE mean: 0.41244332767815534, SCOPE var: 0.039828331328066596\n",
            "Total Loss: 0.00023878811898484168\n",
            "----------------------------------------\n",
            "Epoch 381\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.830691957238786\n",
            "SCOPE mean: 0.41264232658138955, SCOPE var: 0.039835439685996815\n",
            "Total Loss: 0.0002378861540776462\n",
            "----------------------------------------\n",
            "Epoch 382\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.822982611079473\n",
            "SCOPE mean: 0.41284083360093593, SCOPE var: 0.039842305908943255\n",
            "Total Loss: 0.00023698743770413476\n",
            "----------------------------------------\n",
            "Epoch 383\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.815148334581231\n",
            "SCOPE mean: 0.4130391125669016, SCOPE var: 0.03984896129632622\n",
            "Total Loss: 0.00023609173063010377\n",
            "----------------------------------------\n",
            "Epoch 384\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.80711221942812\n",
            "SCOPE mean: 0.4132442845549373, SCOPE var: 0.039856128595911026\n",
            "Total Loss: 0.00023520020003738867\n",
            "----------------------------------------\n",
            "Epoch 385\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.79891456174242\n",
            "SCOPE mean: 0.4134467671931851, SCOPE var: 0.03986372875066676\n",
            "Total Loss: 0.0002343206598055133\n",
            "----------------------------------------\n",
            "Epoch 386\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.790635919633754\n",
            "SCOPE mean: 0.41364686380033616, SCOPE var: 0.0398749213339654\n",
            "Total Loss: 0.00023345434644530177\n",
            "----------------------------------------\n",
            "Epoch 387\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.782214490515647\n",
            "SCOPE mean: 0.4138311035841024, SCOPE var: 0.03988522437924621\n",
            "Total Loss: 0.00023259544319788322\n",
            "----------------------------------------\n",
            "Epoch 388\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.77359659886216\n",
            "SCOPE mean: 0.41400871512785015, SCOPE var: 0.0398954110886178\n",
            "Total Loss: 0.00023174110307670184\n",
            "----------------------------------------\n",
            "Epoch 389\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.764817057781805\n",
            "SCOPE mean: 0.414180184332473, SCOPE var: 0.03990547739709163\n",
            "Total Loss: 0.00023089208688613187\n",
            "----------------------------------------\n",
            "Epoch 390\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.75599062927028\n",
            "SCOPE mean: 0.41433852925349746, SCOPE var: 0.03991471447388563\n",
            "Total Loss: 0.00023004839457533085\n",
            "----------------------------------------\n",
            "Epoch 391\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.747173895194825\n",
            "SCOPE mean: 0.4144532408119616, SCOPE var: 0.03992316533342156\n",
            "Total Loss: 0.00022921031409347316\n",
            "----------------------------------------\n",
            "Epoch 392\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.73842181105424\n",
            "SCOPE mean: 0.414527711570187, SCOPE var: 0.03993093762100326\n",
            "Total Loss: 0.00022838230851351197\n",
            "----------------------------------------\n",
            "Epoch 393\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.729656721664066\n",
            "SCOPE mean: 0.41460691454263604, SCOPE var: 0.03993909720267336\n",
            "Total Loss: 0.00022756181885530717\n",
            "----------------------------------------\n",
            "Epoch 394\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.720915389563553\n",
            "SCOPE mean: 0.41469167972602683, SCOPE var: 0.03994763112022826\n",
            "Total Loss: 0.00022674527928421277\n",
            "----------------------------------------\n",
            "Epoch 395\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.712159649679613\n",
            "SCOPE mean: 0.4147899516751482, SCOPE var: 0.039957214412646984\n",
            "Total Loss: 0.00022593292892979192\n",
            "----------------------------------------\n",
            "Epoch 396\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.703470853224895\n",
            "SCOPE mean: 0.41489108249045187, SCOPE var: 0.03996698117588333\n",
            "Total Loss: 0.00022512760518422388\n",
            "----------------------------------------\n",
            "Epoch 397\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.694947911519888\n",
            "SCOPE mean: 0.41498461355031113, SCOPE var: 0.03997593011543286\n",
            "Total Loss: 0.0002243389922529195\n",
            "----------------------------------------\n",
            "Epoch 398\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.686643085437868\n",
            "SCOPE mean: 0.41506596615670494, SCOPE var: 0.03998367669445801\n",
            "Total Loss: 0.00022355554221725122\n",
            "----------------------------------------\n",
            "Epoch 399\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.678570088267623\n",
            "SCOPE mean: 0.4151346849302454, SCOPE var: 0.03999015083122663\n",
            "Total Loss: 0.00022277759729071432\n",
            "----------------------------------------\n",
            "Epoch 400\n",
            "IS mean: 0.22463288236461731,IS variance: 0.020959556927272208\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.670538611594907\n",
            "SCOPE mean: 0.41520874553052617, SCOPE var: 0.03999701481591218\n",
            "Total Loss: 0.000222008048193562\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[-0.5256, -0.1631],\n",
            "        [ 0.5539, -0.1635],\n",
            "        [ 0.2253,  0.2147],\n",
            "        [ 0.0932, -0.3154],\n",
            "        [ 0.5977,  0.1847],\n",
            "        [-0.2607, -0.6321],\n",
            "        [-0.7033, -0.3404],\n",
            "        [-0.5834, -0.1342],\n",
            "        [ 0.1086, -0.6161],\n",
            "        [-0.3992,  0.4275],\n",
            "        [-0.4621, -0.6912],\n",
            "        [ 0.7302, -0.2929],\n",
            "        [ 0.1857, -0.7066],\n",
            "        [ 0.4859,  0.2450],\n",
            "        [ 0.6891, -0.0064],\n",
            "        [-0.1647, -0.2935]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([ 0.6095,  0.6376,  0.7054,  0.1926,  0.3410,  0.1721,  0.3640,  0.2282,\n",
            "         0.4713,  0.0421,  0.2460, -0.5443,  0.6494, -0.5493, -0.2934,  0.5826],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[ 2.4797e-01, -2.0882e-01, -4.3719e-02,  1.8300e-01,  2.6016e-01,\n",
            "          6.3637e-02,  3.5722e-02, -1.2352e-01, -2.9330e-01, -8.7810e-02,\n",
            "          1.7001e-01,  2.1120e-01, -8.4382e-02,  3.9436e-02, -1.2686e-01,\n",
            "         -4.2019e-02],\n",
            "        [-1.2837e-01, -1.6142e-01,  2.2366e-01,  1.0384e-01, -1.6543e-01,\n",
            "         -2.2469e-01,  3.2124e-02, -1.1786e-01, -2.4678e-01, -8.1221e-02,\n",
            "         -1.8120e-01, -1.3505e-01,  1.8047e-01,  1.9425e-01,  4.0304e-02,\n",
            "          1.1745e-01],\n",
            "        [-2.4990e-03, -7.3743e-02, -1.5407e-01,  1.3530e-01,  2.4585e-01,\n",
            "         -8.9647e-02,  1.0802e-01,  8.8250e-02, -1.5156e-01,  5.1128e-02,\n",
            "         -2.4271e-02, -4.5914e-02, -4.1484e-02, -1.0590e-01,  5.7482e-02,\n",
            "          6.2563e-02],\n",
            "        [-1.5197e-01,  1.1664e-01,  1.8899e-02,  2.1835e-01,  8.4416e-02,\n",
            "          1.6742e-02,  6.0140e-02,  1.6866e-01, -6.9380e-02, -1.5838e-01,\n",
            "         -2.2014e-01, -1.8939e-01,  3.8562e-02, -2.3733e-01,  1.1530e-01,\n",
            "          3.1476e-02],\n",
            "        [ 2.0522e-01,  6.5242e-02,  1.6567e-01, -2.7579e-01, -2.0365e-01,\n",
            "         -2.4803e-01,  1.3377e-02, -4.9486e-02, -9.1489e-04, -2.0718e-01,\n",
            "          2.0011e-01,  2.0808e-01,  2.3944e-01, -2.2547e-01, -2.9367e-02,\n",
            "         -1.5608e-01],\n",
            "        [ 1.6780e-01, -5.4773e-02, -1.7136e-01,  5.4954e-02, -7.1318e-03,\n",
            "          1.5483e-01,  1.3361e-01,  1.3709e-01, -1.9410e-01,  1.3733e-01,\n",
            "          1.0681e-01,  1.4250e-01,  1.7590e-01,  5.0537e-02, -1.5567e-01,\n",
            "          1.0971e-01],\n",
            "        [-1.0095e-01,  1.2631e-01, -7.9460e-02,  3.6431e-02, -2.1201e-01,\n",
            "          6.1380e-02, -2.0414e-01, -8.1497e-02,  1.5256e-01,  8.1446e-02,\n",
            "          2.4309e-01,  1.2688e-01,  1.8820e-01,  4.2585e-02,  2.3095e-01,\n",
            "         -2.2987e-01],\n",
            "        [ 5.7457e-02,  4.2042e-02, -6.9074e-02,  2.1981e-01,  5.6941e-02,\n",
            "         -1.6126e-01,  1.8163e-01, -1.7269e-01,  1.5760e-01, -6.1590e-02,\n",
            "         -5.8181e-02, -7.1735e-02, -9.7409e-02, -1.1893e-01, -8.4112e-02,\n",
            "          9.0992e-02],\n",
            "        [ 1.1340e-01, -1.2867e-01, -1.6927e-01,  6.6524e-03,  2.1548e-01,\n",
            "         -1.2013e-01,  1.3873e-01,  1.5010e-01,  2.1587e-01, -1.8086e-01,\n",
            "         -1.8497e-01, -1.3901e-01, -9.9578e-02, -1.4294e-01,  2.4862e-01,\n",
            "          1.5794e-01],\n",
            "        [ 1.3778e-01, -2.1815e-01, -1.2678e-01,  1.4385e-01,  1.3755e-01,\n",
            "          1.6996e-01,  1.5586e-01, -1.0916e-01,  1.9971e-01, -1.2622e-01,\n",
            "         -2.4478e-01, -1.8950e-01, -1.8927e-01,  1.2247e-02, -2.9096e-01,\n",
            "          2.1652e-02],\n",
            "        [-1.0614e-01, -2.2041e-01,  6.2181e-02, -4.7631e-02,  2.1720e-01,\n",
            "         -2.0614e-01,  2.1780e-01, -1.8906e-01,  1.9857e-01, -2.0828e-01,\n",
            "          2.2091e-01,  7.8512e-02, -1.5159e-01,  1.1862e-01,  1.8825e-01,\n",
            "         -1.4617e-01],\n",
            "        [ 1.8295e-01, -1.7134e-01,  2.3596e-01, -1.1125e-01,  7.5870e-02,\n",
            "          1.5864e-01,  1.8815e-01,  7.4287e-03,  1.1909e-01,  2.0143e-02,\n",
            "         -1.3912e-04,  1.8500e-01,  3.6911e-02,  1.2307e-01,  2.0120e-01,\n",
            "         -2.2730e-01],\n",
            "        [ 8.1884e-02, -1.3930e-01,  1.4295e-01, -2.6403e-01,  9.5420e-02,\n",
            "         -2.0078e-01, -9.1050e-02,  3.8632e-02, -2.0435e-01, -2.7533e-01,\n",
            "         -1.4911e-02, -1.0264e-01, -1.4084e-01,  1.5521e-01, -4.2904e-02,\n",
            "          5.1817e-02],\n",
            "        [ 1.5955e-02, -6.4412e-02, -1.8394e-01,  3.4413e-02, -1.3460e-02,\n",
            "         -9.3782e-02,  1.5367e-01, -8.0826e-02,  1.2909e-01,  1.9939e-01,\n",
            "         -1.3212e-01, -2.1571e-02, -1.5455e-01, -8.8907e-02,  5.0580e-02,\n",
            "          3.8359e-02],\n",
            "        [-1.6532e-01,  2.3514e-01,  2.2315e-01, -1.2726e-02, -2.4827e-02,\n",
            "          4.9254e-02, -2.2479e-02,  1.1894e-01, -2.6212e-02,  1.4073e-01,\n",
            "          7.3961e-02, -1.3190e-02, -3.5406e-02, -1.9442e-01,  6.9211e-02,\n",
            "          1.9688e-01],\n",
            "        [-1.0289e-01,  4.5230e-02,  1.7921e-01,  8.7815e-02,  5.8670e-03,\n",
            "          7.1479e-02, -1.6773e-01,  2.0375e-01, -8.8320e-02,  1.0978e-01,\n",
            "         -1.7433e-01,  2.1738e-01,  1.0312e-01,  7.8564e-02, -2.8707e-02,\n",
            "         -1.0759e-01]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([ 0.2409, -0.1192,  0.0596,  0.0135,  0.1717,  0.1622,  0.1443,  0.0310,\n",
            "        -0.0308,  0.1323, -0.3254,  0.1199,  0.0114,  0.0009,  0.0658,  0.2420],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[ 0.0586,  0.0159,  0.0652,  0.1530, -0.1452,  0.0923,  0.1296, -0.1304,\n",
            "         -0.1951,  0.1619, -0.0839, -0.0270,  0.0926, -0.1085,  0.0382,  0.0124]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([-0.1693], dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NN_l1_l2_reg(\n",
              "  (hidden_layers): ModuleList(\n",
              "    (0): Linear(in_features=2, out_features=16, bias=True)\n",
              "    (1): Linear(in_features=16, out_features=16, bias=True)\n",
              "  )\n",
              "  (output_layer): Linear(in_features=16, out_features=1, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b_600 = action_probs_top_n_epsilon(q_table, 1, 0.4)\n",
        "pi_b_600 = experiment_actions(600, env_50, P_pi_b_600)\n",
        "P_pi_e_600 = action_probs_top_n_epsilon(q_table, 1, 0.05)\n",
        "pi_e_600 = experiment_actions(1000, env_50, P_pi_e_600)\n",
        "# model_600_random_pi_b_600 = CustomizableFeatureNet(input_dim=2, hidden_dims=[8, 8], output_dim=1, dtype = torch.float64, l2_lambda=0.002)\n",
        "# model_600_random_pi_b_600 = NN_l1_reg(input_dim=2, hidden_dims=[16, 16], output_dim=1, dtype = torch.float64, l1_lambda=0.001)\n",
        "model_600_random_pi_b_600 = NN_l1_l2_reg(input_dim=2, hidden_dims=[16, 16], output_dim=1, dtype = torch.float64, l1_lambda=0.0001, l2_lambda = 0.0001)\n",
        "test_600_random_pi_b_600 = SCOPE_straight(model_600_random_pi_b_600, 0.99, 10000, pi_b_600, P_pi_b_600, P_pi_e_600, 0.3, dtype = torch.float64)\n",
        "test_600_random_pi_b_600.train_var_scope(400, 0.001, 1, 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0bz2Zjugam2",
        "outputId": "0a5aa858-fb7c-493f-a1dd-e4c87be7e1ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.3839, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  17.549395655377467\n",
            "SCOPE mean: 0.523331442128463, SCOPE var: 0.01740940735402775\n",
            "Total Loss: 0.38393649853529094\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.6394, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  17.42150262673749\n",
            "SCOPE mean: 0.5181575529268448, SCOPE var: 0.01714722937961731\n",
            "Total Loss: 0.639440108041088\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.6074, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  17.332147204681455\n",
            "SCOPE mean: 0.5129178096276976, SCOPE var: 0.016856468346866972\n",
            "Total Loss: 0.6074116654510248\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.5723, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  17.245887471346496\n",
            "SCOPE mean: 0.5076091001400777, SCOPE var: 0.016555292437733665\n",
            "Total Loss: 0.5723342280415744\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.5363, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  17.1592634053272\n",
            "SCOPE mean: 0.50255544617639, SCOPE var: 0.016258536198326564\n",
            "Total Loss: 0.536289634036607\n",
            "----------------------------------------\n",
            "Epoch 6\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.5013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  17.068615135840844\n",
            "SCOPE mean: 0.4971824202938359, SCOPE var: 0.015966317182448366\n",
            "Total Loss: 0.5013045845215758\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.4691, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  16.97566977447712\n",
            "SCOPE mean: 0.48877834208076604, SCOPE var: 0.01568272165743913\n",
            "Total Loss: 0.46908973590180836\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.4389, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  16.8837759968204\n",
            "SCOPE mean: 0.4801255971610819, SCOPE var: 0.015416743715699963\n",
            "Total Loss: 0.4389114039164268\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.4103, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  16.79411233217546\n",
            "SCOPE mean: 0.4718007526469819, SCOPE var: 0.015163494217771259\n",
            "Total Loss: 0.4103285943120252\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.3828, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  16.69896584948753\n",
            "SCOPE mean: 0.46343648901419493, SCOPE var: 0.014915401221332461\n",
            "Total Loss: 0.38284366916429774\n",
            "----------------------------------------\n",
            "Epoch 11\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.3561, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  16.601105211887504\n",
            "SCOPE mean: 0.45508119090182664, SCOPE var: 0.014674384153705576\n",
            "Total Loss: 0.3561252985013075\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.3314, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  16.506208665857287\n",
            "SCOPE mean: 0.4467429478022252, SCOPE var: 0.014442951691652283\n",
            "Total Loss: 0.3313622006181243\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.3094, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  16.41159581808035\n",
            "SCOPE mean: 0.43962006780833324, SCOPE var: 0.01422473335122977\n",
            "Total Loss: 0.3093715327487819\n",
            "----------------------------------------\n",
            "Epoch 14\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.2883, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  16.318971091336174\n",
            "SCOPE mean: 0.4342787474478775, SCOPE var: 0.014013794019705709\n",
            "Total Loss: 0.28832364688742385\n",
            "----------------------------------------\n",
            "Epoch 15\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.2683, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  16.226747833803252\n",
            "SCOPE mean: 0.4290957140608424, SCOPE var: 0.013814760638545993\n",
            "Total Loss: 0.2682885677577935\n",
            "----------------------------------------\n",
            "Epoch 16\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.2505, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  16.134932029560378\n",
            "SCOPE mean: 0.4241405408589043, SCOPE var: 0.013629667677651036\n",
            "Total Loss: 0.250531986196884\n",
            "----------------------------------------\n",
            "Epoch 17\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.2339, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  16.042592745876483\n",
            "SCOPE mean: 0.4192193779940491, SCOPE var: 0.013452730041804877\n",
            "Total Loss: 0.2339327173607868\n",
            "----------------------------------------\n",
            "Epoch 18\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.2186, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  15.950735601425423\n",
            "SCOPE mean: 0.41427643573900985, SCOPE var: 0.013281130912396433\n",
            "Total Loss: 0.21864314866369575\n",
            "----------------------------------------\n",
            "Epoch 19\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.2050, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  15.86336341684729\n",
            "SCOPE mean: 0.409494019642065, SCOPE var: 0.013119601585316446\n",
            "Total Loss: 0.20504317603230712\n",
            "----------------------------------------\n",
            "Epoch 20\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.1924, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  15.777978075799053\n",
            "SCOPE mean: 0.4048768906450419, SCOPE var: 0.012968348890497947\n",
            "Total Loss: 0.1923945720899428\n",
            "----------------------------------------\n",
            "Epoch 21\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.1809, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  15.695802504792471\n",
            "SCOPE mean: 0.4004620808908627, SCOPE var: 0.012827937789646802\n",
            "Total Loss: 0.1809143654338581\n",
            "----------------------------------------\n",
            "Epoch 22\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.1701, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  15.61593741346854\n",
            "SCOPE mean: 0.3962001766320602, SCOPE var: 0.012699448928400366\n",
            "Total Loss: 0.17014965679974925\n",
            "----------------------------------------\n",
            "Epoch 23\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.1602, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  15.538285578018197\n",
            "SCOPE mean: 0.39213128421070975, SCOPE var: 0.012581532045019364\n",
            "Total Loss: 0.16017757061504906\n",
            "----------------------------------------\n",
            "Epoch 24\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.1507, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  15.463533948044326\n",
            "SCOPE mean: 0.3882205389560172, SCOPE var: 0.012474352014569368\n",
            "Total Loss: 0.15073554305520817\n",
            "----------------------------------------\n",
            "Epoch 25\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.1416, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  15.38862257928537\n",
            "SCOPE mean: 0.38446637742482576, SCOPE var: 0.012376426743622475\n",
            "Total Loss: 0.141561278120727\n",
            "----------------------------------------\n",
            "Epoch 26\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.1331, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  15.315680137130082\n",
            "SCOPE mean: 0.38084746071042874, SCOPE var: 0.012286668283881634\n",
            "Total Loss: 0.13311251270673058\n",
            "----------------------------------------\n",
            "Epoch 27\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.1253, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  15.24313249029063\n",
            "SCOPE mean: 0.37733068863731706, SCOPE var: 0.012204020420086099\n",
            "Total Loss: 0.1252528327241036\n",
            "----------------------------------------\n",
            "Epoch 28\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.1178, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  15.170822979503697\n",
            "SCOPE mean: 0.3737094102566815, SCOPE var: 0.012127634668741134\n",
            "Total Loss: 0.11780706729689312\n",
            "----------------------------------------\n",
            "Epoch 29\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.1108, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  15.101723485208181\n",
            "SCOPE mean: 0.36739787445617084, SCOPE var: 0.01205644595603806\n",
            "Total Loss: 0.1108392040278423\n",
            "----------------------------------------\n",
            "Epoch 30\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.1044, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  15.034957949174315\n",
            "SCOPE mean: 0.36128035534466973, SCOPE var: 0.0119915964952573\n",
            "Total Loss: 0.10443978955156732\n",
            "----------------------------------------\n",
            "Epoch 31\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0985, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.971480231641037\n",
            "SCOPE mean: 0.3553625218862312, SCOPE var: 0.011932098256840228\n",
            "Total Loss: 0.09854960002129354\n",
            "----------------------------------------\n",
            "Epoch 32\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0931, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.911825436000818\n",
            "SCOPE mean: 0.3496547404905953, SCOPE var: 0.011877364407156872\n",
            "Total Loss: 0.09314882384395312\n",
            "----------------------------------------\n",
            "Epoch 33\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0882, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.858056279955036\n",
            "SCOPE mean: 0.34414833908958037, SCOPE var: 0.011827002541816666\n",
            "Total Loss: 0.08817519646536807\n",
            "----------------------------------------\n",
            "Epoch 34\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0835, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.809244916717645\n",
            "SCOPE mean: 0.33886711034386086, SCOPE var: 0.011780314227474161\n",
            "Total Loss: 0.08345539677899284\n",
            "----------------------------------------\n",
            "Epoch 35\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0792, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.765162729408415\n",
            "SCOPE mean: 0.33377480074509935, SCOPE var: 0.011736998510255527\n",
            "Total Loss: 0.07919375338197168\n",
            "----------------------------------------\n",
            "Epoch 36\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0755, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.724561440704047\n",
            "SCOPE mean: 0.32895666524819994, SCOPE var: 0.011698320183753766\n",
            "Total Loss: 0.07550610269579586\n",
            "----------------------------------------\n",
            "Epoch 37\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0722, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.686046997238453\n",
            "SCOPE mean: 0.3243810171145093, SCOPE var: 0.011663010915702137\n",
            "Total Loss: 0.07220224863825876\n",
            "----------------------------------------\n",
            "Epoch 38\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0692, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.649935014391215\n",
            "SCOPE mean: 0.32012631675640285, SCOPE var: 0.011628695822956383\n",
            "Total Loss: 0.06923250592585593\n",
            "----------------------------------------\n",
            "Epoch 39\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0665, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.614718480208156\n",
            "SCOPE mean: 0.31606060426405147, SCOPE var: 0.01159619696069244\n",
            "Total Loss: 0.06652032665412091\n",
            "----------------------------------------\n",
            "Epoch 40\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0640, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.580054090870307\n",
            "SCOPE mean: 0.31219589683907323, SCOPE var: 0.011559954205704878\n",
            "Total Loss: 0.06401470617780285\n",
            "----------------------------------------\n",
            "Epoch 41\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0618, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.546192492642037\n",
            "SCOPE mean: 0.3085469716369434, SCOPE var: 0.011521228266164907\n",
            "Total Loss: 0.06178934649716198\n",
            "----------------------------------------\n",
            "Epoch 42\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0598, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.514442680091005\n",
            "SCOPE mean: 0.30533178236177433, SCOPE var: 0.011489320811112091\n",
            "Total Loss: 0.05981380876791291\n",
            "----------------------------------------\n",
            "Epoch 43\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0580, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.483758282846175\n",
            "SCOPE mean: 0.3023345532213085, SCOPE var: 0.011456460674880308\n",
            "Total Loss: 0.058034191753611575\n",
            "----------------------------------------\n",
            "Epoch 44\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0565, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.454053914979351\n",
            "SCOPE mean: 0.29963321001962867, SCOPE var: 0.01143125376467349\n",
            "Total Loss: 0.05646071606227821\n",
            "----------------------------------------\n",
            "Epoch 45\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0550, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.425771037904674\n",
            "SCOPE mean: 0.29735028062426133, SCOPE var: 0.011420961105446504\n",
            "Total Loss: 0.05503553608773777\n",
            "----------------------------------------\n",
            "Epoch 46\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0538, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.39926653354581\n",
            "SCOPE mean: 0.2954729230828312, SCOPE var: 0.011410981140339546\n",
            "Total Loss: 0.05375530690805763\n",
            "----------------------------------------\n",
            "Epoch 47\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0526, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.373601992325856\n",
            "SCOPE mean: 0.29423108086852384, SCOPE var: 0.011402790059532405\n",
            "Total Loss: 0.0526468758831031\n",
            "----------------------------------------\n",
            "Epoch 48\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0517, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.349483826930701\n",
            "SCOPE mean: 0.29301112251008365, SCOPE var: 0.011394288664701055\n",
            "Total Loss: 0.051682646515026284\n",
            "----------------------------------------\n",
            "Epoch 49\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0508, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.327036280658861\n",
            "SCOPE mean: 0.2919326273538174, SCOPE var: 0.011379637265077411\n",
            "Total Loss: 0.05077422504094267\n",
            "----------------------------------------\n",
            "Epoch 50\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0500, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.306092590445605\n",
            "SCOPE mean: 0.29094351469515695, SCOPE var: 0.011364160602357815\n",
            "Total Loss: 0.04998050149063086\n",
            "----------------------------------------\n",
            "Epoch 51\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0493, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.28869441909746\n",
            "SCOPE mean: 0.2901037296686379, SCOPE var: 0.011351904826198885\n",
            "Total Loss: 0.0493320421044991\n",
            "----------------------------------------\n",
            "Epoch 52\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0487, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.274340790771584\n",
            "SCOPE mean: 0.28952057603473497, SCOPE var: 0.01135471084647375\n",
            "Total Loss: 0.04873983895313477\n",
            "----------------------------------------\n",
            "Epoch 53\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0482, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.261307655903705\n",
            "SCOPE mean: 0.2890054752837477, SCOPE var: 0.011355841512059067\n",
            "Total Loss: 0.04822513481232972\n",
            "----------------------------------------\n",
            "Epoch 54\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0478, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.249137717461306\n",
            "SCOPE mean: 0.2885560692515451, SCOPE var: 0.01135523011556836\n",
            "Total Loss: 0.04776894070728471\n",
            "----------------------------------------\n",
            "Epoch 55\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0473, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.237498385859634\n",
            "SCOPE mean: 0.2881607611863512, SCOPE var: 0.011352352004940485\n",
            "Total Loss: 0.04731291533986885\n",
            "----------------------------------------\n",
            "Epoch 56\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0469, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.226404397481655\n",
            "SCOPE mean: 0.2878053447608245, SCOPE var: 0.011347001732375487\n",
            "Total Loss: 0.04686932073792917\n",
            "----------------------------------------\n",
            "Epoch 57\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0464, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.216090348538831\n",
            "SCOPE mean: 0.2875073971963907, SCOPE var: 0.01134046661180853\n",
            "Total Loss: 0.04643974371619923\n",
            "----------------------------------------\n",
            "Epoch 58\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0460, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.206237495121345\n",
            "SCOPE mean: 0.28729834509158414, SCOPE var: 0.01133294615761728\n",
            "Total Loss: 0.046016549908283744\n",
            "----------------------------------------\n",
            "Epoch 59\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0456, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.196331452045085\n",
            "SCOPE mean: 0.2870295301010757, SCOPE var: 0.011324001173982847\n",
            "Total Loss: 0.04559016232596384\n",
            "----------------------------------------\n",
            "Epoch 60\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0452, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.186468515747306\n",
            "SCOPE mean: 0.28672248859456156, SCOPE var: 0.011314111357506491\n",
            "Total Loss: 0.04517042464184316\n",
            "----------------------------------------\n",
            "Epoch 61\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0448, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.176558376354432\n",
            "SCOPE mean: 0.2863809026463428, SCOPE var: 0.01130345024630864\n",
            "Total Loss: 0.0447562973820443\n",
            "----------------------------------------\n",
            "Epoch 62\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0443, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.166563503689305\n",
            "SCOPE mean: 0.2859369073296386, SCOPE var: 0.01129097090965812\n",
            "Total Loss: 0.04434670423494414\n",
            "----------------------------------------\n",
            "Epoch 63\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0440, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.156366600202164\n",
            "SCOPE mean: 0.28540834665687187, SCOPE var: 0.011276527259043321\n",
            "Total Loss: 0.0439532044215112\n",
            "----------------------------------------\n",
            "Epoch 64\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0436, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.145028941642762\n",
            "SCOPE mean: 0.28486638302163364, SCOPE var: 0.011262920785281934\n",
            "Total Loss: 0.04360773581261517\n",
            "----------------------------------------\n",
            "Epoch 65\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0433, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.132455099047952\n",
            "SCOPE mean: 0.28430260742996283, SCOPE var: 0.011249979929258209\n",
            "Total Loss: 0.04326819809287635\n",
            "----------------------------------------\n",
            "Epoch 66\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0429, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.118250470990981\n",
            "SCOPE mean: 0.28370456984947, SCOPE var: 0.011237602044987348\n",
            "Total Loss: 0.042924516117701726\n",
            "----------------------------------------\n",
            "Epoch 67\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0426, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.10269843300601\n",
            "SCOPE mean: 0.2830690609951687, SCOPE var: 0.011225717016168247\n",
            "Total Loss: 0.0425829917395019\n",
            "----------------------------------------\n",
            "Epoch 68\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0422, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.086321133748768\n",
            "SCOPE mean: 0.28239256407598057, SCOPE var: 0.01121427539795462\n",
            "Total Loss: 0.04224484433298398\n",
            "----------------------------------------\n",
            "Epoch 69\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0419, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.069100351581136\n",
            "SCOPE mean: 0.28168022853375624, SCOPE var: 0.01120338157723206\n",
            "Total Loss: 0.04190680266397187\n",
            "----------------------------------------\n",
            "Epoch 70\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0416, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.050844781563947\n",
            "SCOPE mean: 0.2809311355456023, SCOPE var: 0.01119294330203848\n",
            "Total Loss: 0.041567209236489315\n",
            "----------------------------------------\n",
            "Epoch 71\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0412, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.031479405848327\n",
            "SCOPE mean: 0.28013749207447264, SCOPE var: 0.011182833820475796\n",
            "Total Loss: 0.0412300273585893\n",
            "----------------------------------------\n",
            "Epoch 72\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0409, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.012340799565017\n",
            "SCOPE mean: 0.2793562970653841, SCOPE var: 0.01117338976007744\n",
            "Total Loss: 0.040904259925944216\n",
            "----------------------------------------\n",
            "Epoch 73\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0406, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.993424891192985\n",
            "SCOPE mean: 0.27858271183103395, SCOPE var: 0.01116450291547281\n",
            "Total Loss: 0.04057855510035801\n",
            "----------------------------------------\n",
            "Epoch 74\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0403, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.974937452669206\n",
            "SCOPE mean: 0.27783887561777365, SCOPE var: 0.011156258101875675\n",
            "Total Loss: 0.04025495745504276\n",
            "----------------------------------------\n",
            "Epoch 75\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0399, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.957327968256259\n",
            "SCOPE mean: 0.27713020800532395, SCOPE var: 0.01114862465428215\n",
            "Total Loss: 0.03993160604328204\n",
            "----------------------------------------\n",
            "Epoch 76\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0396, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.940516330314999\n",
            "SCOPE mean: 0.27645444269724023, SCOPE var: 0.011141530517404585\n",
            "Total Loss: 0.0396170156209164\n",
            "----------------------------------------\n",
            "Epoch 77\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0393, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.926804189231744\n",
            "SCOPE mean: 0.2759421517870809, SCOPE var: 0.011135153351745244\n",
            "Total Loss: 0.03929511740457601\n",
            "----------------------------------------\n",
            "Epoch 78\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0390, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.91585748886536\n",
            "SCOPE mean: 0.275571623133487, SCOPE var: 0.011129932171983506\n",
            "Total Loss: 0.03896286891785124\n",
            "----------------------------------------\n",
            "Epoch 79\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0386, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.907330478604356\n",
            "SCOPE mean: 0.2753053750163192, SCOPE var: 0.011125582160512888\n",
            "Total Loss: 0.03863697336024781\n",
            "----------------------------------------\n",
            "Epoch 80\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0383, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.898841270034781\n",
            "SCOPE mean: 0.2750384690883905, SCOPE var: 0.01112129193382622\n",
            "Total Loss: 0.03831937746199638\n",
            "----------------------------------------\n",
            "Epoch 81\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0380, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.890182057922448\n",
            "SCOPE mean: 0.27477152737291, SCOPE var: 0.011117023198348236\n",
            "Total Loss: 0.03798536262515139\n",
            "----------------------------------------\n",
            "Epoch 82\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0377, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.881124537769097\n",
            "SCOPE mean: 0.2744671011594506, SCOPE var: 0.011112637241262692\n",
            "Total Loss: 0.03765138938205431\n",
            "----------------------------------------\n",
            "Epoch 83\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0373, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.872129781417549\n",
            "SCOPE mean: 0.2741291628645109, SCOPE var: 0.011108133734489007\n",
            "Total Loss: 0.03731148304465338\n",
            "----------------------------------------\n",
            "Epoch 84\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0370, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.863236392553588\n",
            "SCOPE mean: 0.27376142723122104, SCOPE var: 0.011103502595383482\n",
            "Total Loss: 0.03696730577487803\n",
            "----------------------------------------\n",
            "Epoch 85\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0366, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.854448111175673\n",
            "SCOPE mean: 0.27336683888002317, SCOPE var: 0.011098730426252715\n",
            "Total Loss: 0.03662137773800848\n",
            "----------------------------------------\n",
            "Epoch 86\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0363, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.845971984478943\n",
            "SCOPE mean: 0.2729461498894955, SCOPE var: 0.011093848373664016\n",
            "Total Loss: 0.036272891951199975\n",
            "----------------------------------------\n",
            "Epoch 87\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0359, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.83782105782082\n",
            "SCOPE mean: 0.2725078128853933, SCOPE var: 0.011088879427037488\n",
            "Total Loss: 0.03592264948420717\n",
            "----------------------------------------\n",
            "Epoch 88\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0356, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.830082175452002\n",
            "SCOPE mean: 0.27205607788645014, SCOPE var: 0.011083807612421087\n",
            "Total Loss: 0.035571565432391296\n",
            "----------------------------------------\n",
            "Epoch 89\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0352, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.822937737784454\n",
            "SCOPE mean: 0.2715962093098859, SCOPE var: 0.011078634872600034\n",
            "Total Loss: 0.0352200208326319\n",
            "----------------------------------------\n",
            "Epoch 90\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0349, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.815488026013547\n",
            "SCOPE mean: 0.27108860598952234, SCOPE var: 0.01107306356282791\n",
            "Total Loss: 0.034871058074284485\n",
            "----------------------------------------\n",
            "Epoch 91\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0345, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.80793753744219\n",
            "SCOPE mean: 0.27054147454951294, SCOPE var: 0.011067102942399501\n",
            "Total Loss: 0.03452635026797858\n",
            "----------------------------------------\n",
            "Epoch 92\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0342, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.801272159989246\n",
            "SCOPE mean: 0.269884147163913, SCOPE var: 0.01105852135886764\n",
            "Total Loss: 0.03417492179991584\n",
            "----------------------------------------\n",
            "Epoch 93\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0338, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.795295906054283\n",
            "SCOPE mean: 0.26913237775778837, SCOPE var: 0.011047577373900115\n",
            "Total Loss: 0.03381764121314133\n",
            "----------------------------------------\n",
            "Epoch 94\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0335, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.789193202058545\n",
            "SCOPE mean: 0.268379282829752, SCOPE var: 0.011036758316896407\n",
            "Total Loss: 0.03346158107484617\n",
            "----------------------------------------\n",
            "Epoch 95\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0331, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.78254350577566\n",
            "SCOPE mean: 0.26762973572893195, SCOPE var: 0.011026048108309214\n",
            "Total Loss: 0.0330897882098207\n",
            "----------------------------------------\n",
            "Epoch 96\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0327, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.775636919912504\n",
            "SCOPE mean: 0.2668881402798774, SCOPE var: 0.011015442938575532\n",
            "Total Loss: 0.032707534067031155\n",
            "----------------------------------------\n",
            "Epoch 97\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0323, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.76852250132622\n",
            "SCOPE mean: 0.2661577483526091, SCOPE var: 0.011004934328180989\n",
            "Total Loss: 0.03232062660260648\n",
            "----------------------------------------\n",
            "Epoch 98\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0319, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.761969162182721\n",
            "SCOPE mean: 0.26548949533215643, SCOPE var: 0.01099481628803557\n",
            "Total Loss: 0.03192403233149005\n",
            "----------------------------------------\n",
            "Epoch 99\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0315, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.756128193853288\n",
            "SCOPE mean: 0.2648800999038403, SCOPE var: 0.010985047545342448\n",
            "Total Loss: 0.03152302905715767\n",
            "----------------------------------------\n",
            "Epoch 100\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0311, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.750979697887498\n",
            "SCOPE mean: 0.26433898350786583, SCOPE var: 0.010975502382699811\n",
            "Total Loss: 0.031114766090008832\n",
            "----------------------------------------\n",
            "Epoch 101\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0307, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.745346589543402\n",
            "SCOPE mean: 0.2638197956063797, SCOPE var: 0.010965733258395529\n",
            "Total Loss: 0.030703816880634636\n",
            "----------------------------------------\n",
            "Epoch 102\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0303, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.739230938188939\n",
            "SCOPE mean: 0.2632936312252238, SCOPE var: 0.010955896012430981\n",
            "Total Loss: 0.030292761702886094\n",
            "----------------------------------------\n",
            "Epoch 103\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0299, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.73214895651217\n",
            "SCOPE mean: 0.2627593705355253, SCOPE var: 0.01094598334436716\n",
            "Total Loss: 0.029881761600203057\n",
            "----------------------------------------\n",
            "Epoch 104\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0294, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.722919267303839\n",
            "SCOPE mean: 0.26221291639341165, SCOPE var: 0.01093594809363985\n",
            "Total Loss: 0.029424733537821723\n",
            "----------------------------------------\n",
            "Epoch 105\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0295, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.710776926169375\n",
            "SCOPE mean: 0.261631401344796, SCOPE var: 0.010925650545582009\n",
            "Total Loss: 0.02952090822755629\n",
            "----------------------------------------\n",
            "Epoch 106\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0292, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.708360391173635\n",
            "SCOPE mean: 0.26100796236228596, SCOPE var: 0.010915093184512234\n",
            "Total Loss: 0.029157356906464288\n",
            "----------------------------------------\n",
            "Epoch 107\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0286, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.710325125670968\n",
            "SCOPE mean: 0.26034455292290426, SCOPE var: 0.010904298680044106\n",
            "Total Loss: 0.028626356813625613\n",
            "----------------------------------------\n",
            "Epoch 108\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0280, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.714990445308898\n",
            "SCOPE mean: 0.2596458265025584, SCOPE var: 0.010893300315984476\n",
            "Total Loss: 0.02799948536916006\n",
            "----------------------------------------\n",
            "Epoch 109\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0277, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.720688095104355\n",
            "SCOPE mean: 0.258921662330716, SCOPE var: 0.010882163673919787\n",
            "Total Loss: 0.027711119035208818\n",
            "----------------------------------------\n",
            "Epoch 110\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0274, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.724609191800482\n",
            "SCOPE mean: 0.2582346798899418, SCOPE var: 0.010871204143512125\n",
            "Total Loss: 0.02740169071055105\n",
            "----------------------------------------\n",
            "Epoch 111\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0271, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.727998358216006\n",
            "SCOPE mean: 0.25758294434903845, SCOPE var: 0.01086042703526341\n",
            "Total Loss: 0.02708679529252309\n",
            "----------------------------------------\n",
            "Epoch 112\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0268, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.731099950500177\n",
            "SCOPE mean: 0.25696294143228116, SCOPE var: 0.010849802842022964\n",
            "Total Loss: 0.026768394542578445\n",
            "----------------------------------------\n",
            "Epoch 113\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0264, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.733912100325263\n",
            "SCOPE mean: 0.25637096851561275, SCOPE var: 0.010839310980594255\n",
            "Total Loss: 0.02644860524279781\n",
            "----------------------------------------\n",
            "Epoch 114\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0261, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.736400227864562\n",
            "SCOPE mean: 0.2558049576801106, SCOPE var: 0.010828940008933006\n",
            "Total Loss: 0.026125516462780732\n",
            "----------------------------------------\n",
            "Epoch 115\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0258, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.73856391928021\n",
            "SCOPE mean: 0.25526042155510204, SCOPE var: 0.010818667532978664\n",
            "Total Loss: 0.02580088709704358\n",
            "----------------------------------------\n",
            "Epoch 116\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0255, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.73935256463068\n",
            "SCOPE mean: 0.2546830847440663, SCOPE var: 0.010808171349367186\n",
            "Total Loss: 0.025474052567647922\n",
            "----------------------------------------\n",
            "Epoch 117\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0251, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.73889096572025\n",
            "SCOPE mean: 0.25407583625217856, SCOPE var: 0.010797473982083135\n",
            "Total Loss: 0.025145237797147234\n",
            "----------------------------------------\n",
            "Epoch 118\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0248, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.737252273046172\n",
            "SCOPE mean: 0.25344176267092783, SCOPE var: 0.010786598146848883\n",
            "Total Loss: 0.024814726755210275\n",
            "----------------------------------------\n",
            "Epoch 119\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0245, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.734629727331294\n",
            "SCOPE mean: 0.2527838566547675, SCOPE var: 0.010775569757415402\n",
            "Total Loss: 0.02448291463283732\n",
            "----------------------------------------\n",
            "Epoch 120\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0242, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.731194738657468\n",
            "SCOPE mean: 0.25210927579968767, SCOPE var: 0.010764446134024299\n",
            "Total Loss: 0.02415038094237094\n",
            "----------------------------------------\n",
            "Epoch 121\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0238, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.727014589758925\n",
            "SCOPE mean: 0.25141963262353567, SCOPE var: 0.01075325559669439\n",
            "Total Loss: 0.02382710648772763\n",
            "----------------------------------------\n",
            "Epoch 122\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0235, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.722117506318662\n",
            "SCOPE mean: 0.2507160205959651, SCOPE var: 0.010742008524363515\n",
            "Total Loss: 0.02350532196528584\n",
            "----------------------------------------\n",
            "Epoch 123\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0232, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.71648548857522\n",
            "SCOPE mean: 0.2499990761798914, SCOPE var: 0.010730715751961542\n",
            "Total Loss: 0.023187452962200795\n",
            "----------------------------------------\n",
            "Epoch 124\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0229, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.710187799044636\n",
            "SCOPE mean: 0.24926766428428246, SCOPE var: 0.010719380951907647\n",
            "Total Loss: 0.022873040053893207\n",
            "----------------------------------------\n",
            "Epoch 125\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0226, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.703152080428357\n",
            "SCOPE mean: 0.24852232993530696, SCOPE var: 0.010708016967619808\n",
            "Total Loss: 0.02255981503925241\n",
            "----------------------------------------\n",
            "Epoch 126\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0222, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.695269122377562\n",
            "SCOPE mean: 0.24776331513585942, SCOPE var: 0.01069663550884584\n",
            "Total Loss: 0.022249380652802818\n",
            "----------------------------------------\n",
            "Epoch 127\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0219, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.690639691112008\n",
            "SCOPE mean: 0.24718371067921638, SCOPE var: 0.010686317055628334\n",
            "Total Loss: 0.021943786847491365\n",
            "----------------------------------------\n",
            "Epoch 128\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0216, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.684692952715643\n",
            "SCOPE mean: 0.24657139316795032, SCOPE var: 0.010675883994844981\n",
            "Total Loss: 0.021645778841518797\n",
            "----------------------------------------\n",
            "Epoch 129\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0214, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.67727887655328\n",
            "SCOPE mean: 0.24592398325639692, SCOPE var: 0.010665359697504756\n",
            "Total Loss: 0.021363745669165737\n",
            "----------------------------------------\n",
            "Epoch 130\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0211, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.668705746999844\n",
            "SCOPE mean: 0.24524025940058156, SCOPE var: 0.010654762498356918\n",
            "Total Loss: 0.021077231466624408\n",
            "----------------------------------------\n",
            "Epoch 131\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0208, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.658147190209856\n",
            "SCOPE mean: 0.24451968209322208, SCOPE var: 0.010644091184350495\n",
            "Total Loss: 0.02082709330321934\n",
            "----------------------------------------\n",
            "Epoch 132\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0206, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.651338985167303\n",
            "SCOPE mean: 0.243758302774225, SCOPE var: 0.01063339137477913\n",
            "Total Loss: 0.020610550497877866\n",
            "----------------------------------------\n",
            "Epoch 133\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0203, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.647617609815232\n",
            "SCOPE mean: 0.24296057677434638, SCOPE var: 0.010622690556976755\n",
            "Total Loss: 0.02034138475786363\n",
            "----------------------------------------\n",
            "Epoch 134\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0201, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.641353904733766\n",
            "SCOPE mean: 0.24212856218492143, SCOPE var: 0.010611967897541005\n",
            "Total Loss: 0.020130606262328904\n",
            "----------------------------------------\n",
            "Epoch 135\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0199, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.636746764707983\n",
            "SCOPE mean: 0.2414550633353376, SCOPE var: 0.010602261544522868\n",
            "Total Loss: 0.019906020963175196\n",
            "----------------------------------------\n",
            "Epoch 136\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0197, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.63354422094113\n",
            "SCOPE mean: 0.24092139330180148, SCOPE var: 0.010593468224307864\n",
            "Total Loss: 0.01968354348622589\n",
            "----------------------------------------\n",
            "Epoch 137\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0195, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.627454614919706\n",
            "SCOPE mean: 0.24031291162473317, SCOPE var: 0.010584444634062003\n",
            "Total Loss: 0.019465386377647862\n",
            "----------------------------------------\n",
            "Epoch 138\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0192, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.619462681524672\n",
            "SCOPE mean: 0.2395604051876986, SCOPE var: 0.010573354503246517\n",
            "Total Loss: 0.019238800953595675\n",
            "----------------------------------------\n",
            "Epoch 139\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0190, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.609618233038752\n",
            "SCOPE mean: 0.23867344510549474, SCOPE var: 0.010560422404275096\n",
            "Total Loss: 0.019025150563034998\n",
            "----------------------------------------\n",
            "Epoch 140\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0188, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.603368012748806\n",
            "SCOPE mean: 0.2376822397850242, SCOPE var: 0.010546013656878541\n",
            "Total Loss: 0.018798195859365516\n",
            "----------------------------------------\n",
            "Epoch 141\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0186, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.59463046898695\n",
            "SCOPE mean: 0.23666260988117788, SCOPE var: 0.01053208295385805\n",
            "Total Loss: 0.01858881155905752\n",
            "----------------------------------------\n",
            "Epoch 142\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0184, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.583667253627189\n",
            "SCOPE mean: 0.23561703510438, SCOPE var: 0.010518601788479002\n",
            "Total Loss: 0.018375640059514958\n",
            "----------------------------------------\n",
            "Epoch 143\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0182, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.570654226685154\n",
            "SCOPE mean: 0.2345478148867222, SCOPE var: 0.010505546580564773\n",
            "Total Loss: 0.018159092650790066\n",
            "----------------------------------------\n",
            "Epoch 144\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0180, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.555763086839479\n",
            "SCOPE mean: 0.233458348574194, SCOPE var: 0.010492896145049847\n",
            "Total Loss: 0.017975399020755442\n",
            "----------------------------------------\n",
            "Epoch 145\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0177, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.54426559235624\n",
            "SCOPE mean: 0.23236043581382554, SCOPE var: 0.010480617659695594\n",
            "Total Loss: 0.01774477012648193\n",
            "----------------------------------------\n",
            "Epoch 146\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0175, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.532092125430763\n",
            "SCOPE mean: 0.23131401481979982, SCOPE var: 0.010469014807384087\n",
            "Total Loss: 0.017547440410389557\n",
            "----------------------------------------\n",
            "Epoch 147\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0173, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.519385177567097\n",
            "SCOPE mean: 0.2303175749213025, SCOPE var: 0.010458055065268033\n",
            "Total Loss: 0.017345983046752236\n",
            "----------------------------------------\n",
            "Epoch 148\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0171, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.506114644161189\n",
            "SCOPE mean: 0.22936156337783403, SCOPE var: 0.010447654775371441\n",
            "Total Loss: 0.017140680022464654\n",
            "----------------------------------------\n",
            "Epoch 149\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0169, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.492317493176925\n",
            "SCOPE mean: 0.22844185888974225, SCOPE var: 0.010437844007849561\n",
            "Total Loss: 0.01693303013178133\n",
            "----------------------------------------\n",
            "Epoch 150\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0168, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.477532911524037\n",
            "SCOPE mean: 0.22754227102373353, SCOPE var: 0.01042845137130442\n",
            "Total Loss: 0.0167754314162047\n",
            "----------------------------------------\n",
            "Epoch 151\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0166, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.47046413774434\n",
            "SCOPE mean: 0.2268649347185522, SCOPE var: 0.010420440970487745\n",
            "Total Loss: 0.016553374968194347\n",
            "----------------------------------------\n",
            "Epoch 152\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0164, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.466511163944265\n",
            "SCOPE mean: 0.22611659887285454, SCOPE var: 0.010411000657126357\n",
            "Total Loss: 0.016376671410033412\n",
            "----------------------------------------\n",
            "Epoch 153\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0162, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.461152451291728\n",
            "SCOPE mean: 0.22530446474675633, SCOPE var: 0.010400259299472537\n",
            "Total Loss: 0.01620629614337577\n",
            "----------------------------------------\n",
            "Epoch 154\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0160, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.45448040674004\n",
            "SCOPE mean: 0.22443222829149376, SCOPE var: 0.01038835186432585\n",
            "Total Loss: 0.01602359637923247\n",
            "----------------------------------------\n",
            "Epoch 155\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0158, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.4466530956786\n",
            "SCOPE mean: 0.2235701974068641, SCOPE var: 0.010377081271734558\n",
            "Total Loss: 0.015844425356905216\n",
            "----------------------------------------\n",
            "Epoch 156\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0157, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.43676483230051\n",
            "SCOPE mean: 0.22266597658418927, SCOPE var: 0.010366156816062823\n",
            "Total Loss: 0.015665384017232265\n",
            "----------------------------------------\n",
            "Epoch 157\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0155, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.425237349873745\n",
            "SCOPE mean: 0.2217222378846066, SCOPE var: 0.010355540364541128\n",
            "Total Loss: 0.01548637563117775\n",
            "----------------------------------------\n",
            "Epoch 158\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0153, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.412224482607549\n",
            "SCOPE mean: 0.2207435184291724, SCOPE var: 0.010345214096519399\n",
            "Total Loss: 0.015307372474556763\n",
            "----------------------------------------\n",
            "Epoch 159\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0151, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.39792993350894\n",
            "SCOPE mean: 0.21973667218681311, SCOPE var: 0.0103351704944172\n",
            "Total Loss: 0.015129195415779981\n",
            "----------------------------------------\n",
            "Epoch 160\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0150, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.383315939469544\n",
            "SCOPE mean: 0.21874493636626663, SCOPE var: 0.01032557145593995\n",
            "Total Loss: 0.014952091543086826\n",
            "----------------------------------------\n",
            "Epoch 161\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0148, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.368407712902414\n",
            "SCOPE mean: 0.21776410383737752, SCOPE var: 0.010316364086397706\n",
            "Total Loss: 0.014775897667841672\n",
            "----------------------------------------\n",
            "Epoch 162\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0146, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.353136428939688\n",
            "SCOPE mean: 0.21679585668139745, SCOPE var: 0.010307525910496723\n",
            "Total Loss: 0.014598362602956974\n",
            "----------------------------------------\n",
            "Epoch 163\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0144, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.33674871698584\n",
            "SCOPE mean: 0.21583620901233044, SCOPE var: 0.01029898840126857\n",
            "Total Loss: 0.014419520636619951\n",
            "----------------------------------------\n",
            "Epoch 164\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0142, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.320032661505707\n",
            "SCOPE mean: 0.21483009661540067, SCOPE var: 0.010289346355013655\n",
            "Total Loss: 0.014235006777994948\n",
            "----------------------------------------\n",
            "Epoch 165\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0140, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.303030004039378\n",
            "SCOPE mean: 0.21378076235573118, SCOPE var: 0.010278730500404678\n",
            "Total Loss: 0.014046072245532865\n",
            "----------------------------------------\n",
            "Epoch 166\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0139, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.285507236730144\n",
            "SCOPE mean: 0.21269275223041267, SCOPE var: 0.010267281309308205\n",
            "Total Loss: 0.01394675202584292\n",
            "----------------------------------------\n",
            "Epoch 167\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0138, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.270964144586024\n",
            "SCOPE mean: 0.2116349417547855, SCOPE var: 0.01025661847015399\n",
            "Total Loss: 0.0137965165505616\n",
            "----------------------------------------\n",
            "Epoch 168\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0136, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.259115005497339\n",
            "SCOPE mean: 0.21060368038822289, SCOPE var: 0.010246664557406042\n",
            "Total Loss: 0.013599377752162927\n",
            "----------------------------------------\n",
            "Epoch 169\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0134, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.249639132799292\n",
            "SCOPE mean: 0.20961057414708767, SCOPE var: 0.010237415987465177\n",
            "Total Loss: 0.013406708089701716\n",
            "----------------------------------------\n",
            "Epoch 170\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0133, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.238686743475657\n",
            "SCOPE mean: 0.2086545686087707, SCOPE var: 0.010228797271796672\n",
            "Total Loss: 0.013266769634674214\n",
            "----------------------------------------\n",
            "Epoch 171\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0131, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.22647051042435\n",
            "SCOPE mean: 0.20773184492837546, SCOPE var: 0.010220738012388826\n",
            "Total Loss: 0.013121323846184169\n",
            "----------------------------------------\n",
            "Epoch 172\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0130, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.213069586347302\n",
            "SCOPE mean: 0.20684142979727907, SCOPE var: 0.010213192206202046\n",
            "Total Loss: 0.012970933031636248\n",
            "----------------------------------------\n",
            "Epoch 173\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0128, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.198786733043521\n",
            "SCOPE mean: 0.20598719698493015, SCOPE var: 0.010206202751764381\n",
            "Total Loss: 0.012821969529327602\n",
            "----------------------------------------\n",
            "Epoch 174\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0127, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.188427121578176\n",
            "SCOPE mean: 0.20530209160584867, SCOPE var: 0.01019904960050509\n",
            "Total Loss: 0.012665706771113151\n",
            "----------------------------------------\n",
            "Epoch 175\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0125, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.17768391503955\n",
            "SCOPE mean: 0.20456421779048164, SCOPE var: 0.010190933464772702\n",
            "Total Loss: 0.012508082076512224\n",
            "----------------------------------------\n",
            "Epoch 176\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0123, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.165782396794025\n",
            "SCOPE mean: 0.20374345820085626, SCOPE var: 0.010181847341436982\n",
            "Total Loss: 0.012349005094451481\n",
            "----------------------------------------\n",
            "Epoch 177\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0122, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.15205437580502\n",
            "SCOPE mean: 0.20289924864611691, SCOPE var: 0.010173283630949633\n",
            "Total Loss: 0.01219370999802137\n",
            "----------------------------------------\n",
            "Epoch 178\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0121, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.139533238734398\n",
            "SCOPE mean: 0.20202855581526327, SCOPE var: 0.010165208504673\n",
            "Total Loss: 0.01205540764529366\n",
            "----------------------------------------\n",
            "Epoch 179\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0119, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.128005120608439\n",
            "SCOPE mean: 0.2011304161970373, SCOPE var: 0.010157577731910701\n",
            "Total Loss: 0.011921320685007777\n",
            "----------------------------------------\n",
            "Epoch 180\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0118, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.114561413585246\n",
            "SCOPE mean: 0.20021059787000012, SCOPE var: 0.01015037310161502\n",
            "Total Loss: 0.011789082224988813\n",
            "----------------------------------------\n",
            "Epoch 181\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0117, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.099529639409168\n",
            "SCOPE mean: 0.19927222719443244, SCOPE var: 0.010143562063919923\n",
            "Total Loss: 0.011654964309888752\n",
            "----------------------------------------\n",
            "Epoch 182\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0115, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.08375603419484\n",
            "SCOPE mean: 0.19825881977655416, SCOPE var: 0.010135800999038318\n",
            "Total Loss: 0.011518402802105499\n",
            "----------------------------------------\n",
            "Epoch 183\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0114, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.067230064616105\n",
            "SCOPE mean: 0.19717924412781812, SCOPE var: 0.010127196593831798\n",
            "Total Loss: 0.01138080579111795\n",
            "----------------------------------------\n",
            "Epoch 184\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0112, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.051287687795421\n",
            "SCOPE mean: 0.1960790625559866, SCOPE var: 0.010118022347571715\n",
            "Total Loss: 0.011240912020834937\n",
            "----------------------------------------\n",
            "Epoch 185\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0111, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.035284988306941\n",
            "SCOPE mean: 0.1950221160230598, SCOPE var: 0.010109686056801324\n",
            "Total Loss: 0.0111208359596135\n",
            "----------------------------------------\n",
            "Epoch 186\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0110, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.022232030889198\n",
            "SCOPE mean: 0.19400621533151333, SCOPE var: 0.010102111271454309\n",
            "Total Loss: 0.010975400555829054\n",
            "----------------------------------------\n",
            "Epoch 187\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0108, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.015712348039864\n",
            "SCOPE mean: 0.19323267173187156, SCOPE var: 0.010095937593085587\n",
            "Total Loss: 0.010846206872519432\n",
            "----------------------------------------\n",
            "Epoch 188\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0107, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.008290074106274\n",
            "SCOPE mean: 0.19247596969511502, SCOPE var: 0.010090278069367303\n",
            "Total Loss: 0.010721770116478194\n",
            "----------------------------------------\n",
            "Epoch 189\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0106, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.000146721382908\n",
            "SCOPE mean: 0.19173571148019725, SCOPE var: 0.010085084491910448\n",
            "Total Loss: 0.010596867632801703\n",
            "----------------------------------------\n",
            "Epoch 190\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0105, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.991404480083965\n",
            "SCOPE mean: 0.1910103717455566, SCOPE var: 0.01008030365595987\n",
            "Total Loss: 0.010471026559847992\n",
            "----------------------------------------\n",
            "Epoch 191\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0103, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.98296134799228\n",
            "SCOPE mean: 0.19025997642470957, SCOPE var: 0.010074738807423511\n",
            "Total Loss: 0.010344070188925823\n",
            "----------------------------------------\n",
            "Epoch 192\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0102, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.974650790118979\n",
            "SCOPE mean: 0.18948728786832245, SCOPE var: 0.010068481022976975\n",
            "Total Loss: 0.010213720973774891\n",
            "----------------------------------------\n",
            "Epoch 193\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0101, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.966325210746678\n",
            "SCOPE mean: 0.18868037038924285, SCOPE var: 0.010061570190549351\n",
            "Total Loss: 0.010083110801990675\n",
            "----------------------------------------\n",
            "Epoch 194\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0100, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.95757754217824\n",
            "SCOPE mean: 0.18790979660900997, SCOPE var: 0.010055433173128705\n",
            "Total Loss: 0.009953580391970456\n",
            "----------------------------------------\n",
            "Epoch 195\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0098, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.948385451081407\n",
            "SCOPE mean: 0.1871580894117626, SCOPE var: 0.010049839644604708\n",
            "Total Loss: 0.009833126530131806\n",
            "----------------------------------------\n",
            "Epoch 196\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0097, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.941488054881166\n",
            "SCOPE mean: 0.18681239292303106, SCOPE var: 0.010044789327589893\n",
            "Total Loss: 0.009715017397939417\n",
            "----------------------------------------\n",
            "Epoch 197\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0096, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.936389878767594\n",
            "SCOPE mean: 0.18648275902161268, SCOPE var: 0.010040335778872561\n",
            "Total Loss: 0.009595088464248449\n",
            "----------------------------------------\n",
            "Epoch 198\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0095, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.93031822942105\n",
            "SCOPE mean: 0.18615781385726946, SCOPE var: 0.010036288503522952\n",
            "Total Loss: 0.00948319247816456\n",
            "----------------------------------------\n",
            "Epoch 199\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0094, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.923538176696681\n",
            "SCOPE mean: 0.1858252681226425, SCOPE var: 0.010032580445931673\n",
            "Total Loss: 0.009370370696682786\n",
            "----------------------------------------\n",
            "Epoch 200\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0093, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.916898317854937\n",
            "SCOPE mean: 0.18546787388812042, SCOPE var: 0.010028144365777278\n",
            "Total Loss: 0.009256720159910886\n",
            "----------------------------------------\n",
            "Epoch 201\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0091, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.910285991765567\n",
            "SCOPE mean: 0.1850966629228442, SCOPE var: 0.010023052509277115\n",
            "Total Loss: 0.009141017341308963\n",
            "----------------------------------------\n",
            "Epoch 202\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0090, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.90328952458128\n",
            "SCOPE mean: 0.18475644164910604, SCOPE var: 0.01001848608118872\n",
            "Total Loss: 0.009026499855001403\n",
            "----------------------------------------\n",
            "Epoch 203\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0089, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.896114086144161\n",
            "SCOPE mean: 0.18443782236241343, SCOPE var: 0.010014416531782965\n",
            "Total Loss: 0.00893979249877113\n",
            "----------------------------------------\n",
            "Epoch 204\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0088, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.890906988690935\n",
            "SCOPE mean: 0.18413616427457888, SCOPE var: 0.01001076330788735\n",
            "Total Loss: 0.008835030654529012\n",
            "----------------------------------------\n",
            "Epoch 205\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0087, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.887550495561415\n",
            "SCOPE mean: 0.18385504273913633, SCOPE var: 0.010007500087100257\n",
            "Total Loss: 0.008714010655523857\n",
            "----------------------------------------\n",
            "Epoch 206\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0086, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.886296103715853\n",
            "SCOPE mean: 0.18350629348346484, SCOPE var: 0.01000377607427338\n",
            "Total Loss: 0.008624224235112542\n",
            "----------------------------------------\n",
            "Epoch 207\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0085, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.885540351299818\n",
            "SCOPE mean: 0.18311613769121865, SCOPE var: 0.009995072015429667\n",
            "Total Loss: 0.008533262525106684\n",
            "----------------------------------------\n",
            "Epoch 208\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0084, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.884301843549894\n",
            "SCOPE mean: 0.18250943016647775, SCOPE var: 0.009977826557323495\n",
            "Total Loss: 0.00843854265813019\n",
            "----------------------------------------\n",
            "Epoch 209\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0083, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.882817483553607\n",
            "SCOPE mean: 0.1819386193481651, SCOPE var: 0.009960973739765866\n",
            "Total Loss: 0.008340340574329972\n",
            "----------------------------------------\n",
            "Epoch 210\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0082, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.881236162144488\n",
            "SCOPE mean: 0.18138547719767575, SCOPE var: 0.00994316520271474\n",
            "Total Loss: 0.008239055697147998\n",
            "----------------------------------------\n",
            "Epoch 211\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0081, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.879520263157021\n",
            "SCOPE mean: 0.18084822390657415, SCOPE var: 0.009924250684245009\n",
            "Total Loss: 0.008135689885412975\n",
            "----------------------------------------\n",
            "Epoch 212\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0080, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.877733624283476\n",
            "SCOPE mean: 0.18033702558933723, SCOPE var: 0.009905883250586174\n",
            "Total Loss: 0.008029703768147422\n",
            "----------------------------------------\n",
            "Epoch 213\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0079, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.87596145938805\n",
            "SCOPE mean: 0.17985084146458072, SCOPE var: 0.009889431066018842\n",
            "Total Loss: 0.007916714448797203\n",
            "----------------------------------------\n",
            "Epoch 214\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0078, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.874200165223733\n",
            "SCOPE mean: 0.17937302321495885, SCOPE var: 0.00987281374017501\n",
            "Total Loss: 0.00780785428585087\n",
            "----------------------------------------\n",
            "Epoch 215\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0077, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.874241377571499\n",
            "SCOPE mean: 0.1789130207175613, SCOPE var: 0.009859203075377916\n",
            "Total Loss: 0.007712809373920431\n",
            "----------------------------------------\n",
            "Epoch 216\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0076, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.876853179610418\n",
            "SCOPE mean: 0.17840878871298663, SCOPE var: 0.009846231771960055\n",
            "Total Loss: 0.007604138469451352\n",
            "----------------------------------------\n",
            "Epoch 217\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0075, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.881530419684413\n",
            "SCOPE mean: 0.17780429190144256, SCOPE var: 0.009832473031860078\n",
            "Total Loss: 0.007509180140323527\n",
            "----------------------------------------\n",
            "Epoch 218\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0074, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.886009938327524\n",
            "SCOPE mean: 0.17721214548032194, SCOPE var: 0.00981892216685091\n",
            "Total Loss: 0.007417003529795699\n",
            "----------------------------------------\n",
            "Epoch 219\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0073, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.889976647674086\n",
            "SCOPE mean: 0.17662069419443616, SCOPE var: 0.009805428175131916\n",
            "Total Loss: 0.007323372818127754\n",
            "----------------------------------------\n",
            "Epoch 220\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0072, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.893479694317396\n",
            "SCOPE mean: 0.1760208315792793, SCOPE var: 0.009792899840611486\n",
            "Total Loss: 0.007227776825219988\n",
            "----------------------------------------\n",
            "Epoch 221\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0071, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.89641467261727\n",
            "SCOPE mean: 0.17540852773252463, SCOPE var: 0.009780333030265329\n",
            "Total Loss: 0.007130824223741813\n",
            "----------------------------------------\n",
            "Epoch 222\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0070, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.898705725421133\n",
            "SCOPE mean: 0.17479363883549148, SCOPE var: 0.009767752218022145\n",
            "Total Loss: 0.0070340236799924\n",
            "----------------------------------------\n",
            "Epoch 223\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0069, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.900472402628369\n",
            "SCOPE mean: 0.17417845223857178, SCOPE var: 0.009755227719813096\n",
            "Total Loss: 0.006949172612221521\n",
            "----------------------------------------\n",
            "Epoch 224\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0069, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.904417060496915\n",
            "SCOPE mean: 0.1735976641807703, SCOPE var: 0.009742828793356756\n",
            "Total Loss: 0.006863384543560696\n",
            "----------------------------------------\n",
            "Epoch 225\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0068, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.910439221062418\n",
            "SCOPE mean: 0.17304198973450508, SCOPE var: 0.009730452130016365\n",
            "Total Loss: 0.006765911105083331\n",
            "----------------------------------------\n",
            "Epoch 226\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0067, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.918199126470153\n",
            "SCOPE mean: 0.17251528401913566, SCOPE var: 0.009718104505728168\n",
            "Total Loss: 0.006688048536130726\n",
            "----------------------------------------\n",
            "Epoch 227\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0066, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.926073621992922\n",
            "SCOPE mean: 0.17202819751472484, SCOPE var: 0.009705860110853778\n",
            "Total Loss: 0.006609961125487177\n",
            "----------------------------------------\n",
            "Epoch 228\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0065, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.933448693198768\n",
            "SCOPE mean: 0.17154929692616208, SCOPE var: 0.009693621424248856\n",
            "Total Loss: 0.006533490274232329\n",
            "----------------------------------------\n",
            "Epoch 229\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0065, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.93997676681483\n",
            "SCOPE mean: 0.17110899271427185, SCOPE var: 0.009681769752793076\n",
            "Total Loss: 0.006464905476046747\n",
            "----------------------------------------\n",
            "Epoch 230\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0064, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.945564564699302\n",
            "SCOPE mean: 0.1707186489774262, SCOPE var: 0.009670434281371092\n",
            "Total Loss: 0.006398239329515294\n",
            "----------------------------------------\n",
            "Epoch 231\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0063, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.950306518966949\n",
            "SCOPE mean: 0.17037289749525522, SCOPE var: 0.009659535743923989\n",
            "Total Loss: 0.006330893000669091\n",
            "----------------------------------------\n",
            "Epoch 232\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0063, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.954295624461722\n",
            "SCOPE mean: 0.17006568618142442, SCOPE var: 0.009649016263899489\n",
            "Total Loss: 0.006262838040824956\n",
            "----------------------------------------\n",
            "Epoch 233\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0062, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.95742825788497\n",
            "SCOPE mean: 0.1697846644802246, SCOPE var: 0.009638811162257118\n",
            "Total Loss: 0.006195762840654093\n",
            "----------------------------------------\n",
            "Epoch 234\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0062, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.958232385011568\n",
            "SCOPE mean: 0.16944664598572523, SCOPE var: 0.009628705986651815\n",
            "Total Loss: 0.0061520429778937485\n",
            "----------------------------------------\n",
            "Epoch 235\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0061, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.958617645279235\n",
            "SCOPE mean: 0.1690472825033732, SCOPE var: 0.009618732982988999\n",
            "Total Loss: 0.0060996519286948365\n",
            "----------------------------------------\n",
            "Epoch 236\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0060, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.958656464068794\n",
            "SCOPE mean: 0.16858942843560717, SCOPE var: 0.009608854968116786\n",
            "Total Loss: 0.006034817978824718\n",
            "----------------------------------------\n",
            "Epoch 237\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0060, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.95822638439815\n",
            "SCOPE mean: 0.16807542212489357, SCOPE var: 0.009599060067789291\n",
            "Total Loss: 0.0059634598724431\n",
            "----------------------------------------\n",
            "Epoch 238\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0059, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.955735948714038\n",
            "SCOPE mean: 0.1675338014783906, SCOPE var: 0.009589487639454945\n",
            "Total Loss: 0.005910501531956673\n",
            "----------------------------------------\n",
            "Epoch 239\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0059, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.951626677622903\n",
            "SCOPE mean: 0.16697945351570195, SCOPE var: 0.009580124001529692\n",
            "Total Loss: 0.005855966702155355\n",
            "----------------------------------------\n",
            "Epoch 240\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0058, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.9468425412304\n",
            "SCOPE mean: 0.16644847382481348, SCOPE var: 0.0095710989408859\n",
            "Total Loss: 0.00580085653474647\n",
            "----------------------------------------\n",
            "Epoch 241\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0057, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.941587774579542\n",
            "SCOPE mean: 0.16595067310827166, SCOPE var: 0.009562363714620145\n",
            "Total Loss: 0.005744090522143631\n",
            "----------------------------------------\n",
            "Epoch 242\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0057, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.935927443740361\n",
            "SCOPE mean: 0.1654893596987369, SCOPE var: 0.00955389907537359\n",
            "Total Loss: 0.005685976507878649\n",
            "----------------------------------------\n",
            "Epoch 243\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0056, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.931012642355482\n",
            "SCOPE mean: 0.1651275154963193, SCOPE var: 0.00954582437952794\n",
            "Total Loss: 0.005632686409859227\n",
            "----------------------------------------\n",
            "Epoch 244\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0056, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.92900864248173\n",
            "SCOPE mean: 0.16487594609048947, SCOPE var: 0.009538096217355777\n",
            "Total Loss: 0.005577942449548004\n",
            "----------------------------------------\n",
            "Epoch 245\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0055, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.929584406214188\n",
            "SCOPE mean: 0.1647167928507624, SCOPE var: 0.009530670730865791\n",
            "Total Loss: 0.005523621609501\n",
            "----------------------------------------\n",
            "Epoch 246\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0055, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.929378546714686\n",
            "SCOPE mean: 0.1645714311152982, SCOPE var: 0.009523446290856148\n",
            "Total Loss: 0.00547283718847185\n",
            "----------------------------------------\n",
            "Epoch 247\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0054, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.927884205052669\n",
            "SCOPE mean: 0.16440681668853374, SCOPE var: 0.009516351595164004\n",
            "Total Loss: 0.005420095326902155\n",
            "----------------------------------------\n",
            "Epoch 248\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0054, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.925109528277176\n",
            "SCOPE mean: 0.1642161280485659, SCOPE var: 0.009509362567832738\n",
            "Total Loss: 0.005366737142166354\n",
            "----------------------------------------\n",
            "Epoch 249\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0053, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.921093864683204\n",
            "SCOPE mean: 0.1639923162353276, SCOPE var: 0.009502464811236169\n",
            "Total Loss: 0.0053133693163479505\n",
            "----------------------------------------\n",
            "Epoch 250\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0053, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.915518677806032\n",
            "SCOPE mean: 0.16371326088828952, SCOPE var: 0.009495615739979165\n",
            "Total Loss: 0.005260048394669679\n",
            "----------------------------------------\n",
            "Epoch 251\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0052, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.908336730806422\n",
            "SCOPE mean: 0.1633756787881525, SCOPE var: 0.009488808753321606\n",
            "Total Loss: 0.005214048634772739\n",
            "----------------------------------------\n",
            "Epoch 252\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0052, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.9017484723244\n",
            "SCOPE mean: 0.1629401463921443, SCOPE var: 0.009481378670994233\n",
            "Total Loss: 0.005157175665070236\n",
            "----------------------------------------\n",
            "Epoch 253\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0051, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.895615413023345\n",
            "SCOPE mean: 0.16241691416483986, SCOPE var: 0.009473435353838615\n",
            "Total Loss: 0.005098405394747113\n",
            "----------------------------------------\n",
            "Epoch 254\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0050, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.889192944750178\n",
            "SCOPE mean: 0.16179841665604394, SCOPE var: 0.00946450319036276\n",
            "Total Loss: 0.0050419677045647196\n",
            "----------------------------------------\n",
            "Epoch 255\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0050, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.883931567212194\n",
            "SCOPE mean: 0.16116643871681727, SCOPE var: 0.009454847706597732\n",
            "Total Loss: 0.0049842028139562376\n",
            "----------------------------------------\n",
            "Epoch 256\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0049, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.87974587633775\n",
            "SCOPE mean: 0.160529701614642, SCOPE var: 0.009444600932295898\n",
            "Total Loss: 0.00492598856460002\n",
            "----------------------------------------\n",
            "Epoch 257\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0049, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.876399995706217\n",
            "SCOPE mean: 0.15991525907919577, SCOPE var: 0.009434057874802247\n",
            "Total Loss: 0.00486894079271789\n",
            "----------------------------------------\n",
            "Epoch 258\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0048, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.874338566225104\n",
            "SCOPE mean: 0.1593548729541655, SCOPE var: 0.00942333559373325\n",
            "Total Loss: 0.004810442422503999\n",
            "----------------------------------------\n",
            "Epoch 259\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0048, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.873412191609473\n",
            "SCOPE mean: 0.15885336490160015, SCOPE var: 0.009412555550035912\n",
            "Total Loss: 0.004750574888512942\n",
            "----------------------------------------\n",
            "Epoch 260\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0047, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.873552597060595\n",
            "SCOPE mean: 0.1584054087855502, SCOPE var: 0.009401703183015989\n",
            "Total Loss: 0.004688783301625608\n",
            "----------------------------------------\n",
            "Epoch 261\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.874578676815425\n",
            "SCOPE mean: 0.15800204578808008, SCOPE var: 0.009390739312462726\n",
            "Total Loss: 0.004634011311111033\n",
            "----------------------------------------\n",
            "Epoch 262\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.877503100889362\n",
            "SCOPE mean: 0.15762484287866155, SCOPE var: 0.009379605906207103\n",
            "Total Loss: 0.0045762035683392386\n",
            "----------------------------------------\n",
            "Epoch 263\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0045, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.882154195364874\n",
            "SCOPE mean: 0.15727172615094367, SCOPE var: 0.009368382160128521\n",
            "Total Loss: 0.004512894366330327\n",
            "----------------------------------------\n",
            "Epoch 264\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0045, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.88825004480121\n",
            "SCOPE mean: 0.15695142817368807, SCOPE var: 0.009357151137531314\n",
            "Total Loss: 0.004458153655852016\n",
            "----------------------------------------\n",
            "Epoch 265\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0044, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.89358392595163\n",
            "SCOPE mean: 0.15662447067026344, SCOPE var: 0.009345930931484222\n",
            "Total Loss: 0.004408897773684779\n",
            "----------------------------------------\n",
            "Epoch 266\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0044, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.898099434580425\n",
            "SCOPE mean: 0.1563156289447383, SCOPE var: 0.009334985151118538\n",
            "Total Loss: 0.004360891521025694\n",
            "----------------------------------------\n",
            "Epoch 267\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0043, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.901507661326956\n",
            "SCOPE mean: 0.15600475193098232, SCOPE var: 0.009324291737815632\n",
            "Total Loss: 0.004313128840979692\n",
            "----------------------------------------\n",
            "Epoch 268\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0043, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.90397102667772\n",
            "SCOPE mean: 0.15569461974680185, SCOPE var: 0.009313850769809938\n",
            "Total Loss: 0.004265373811933922\n",
            "----------------------------------------\n",
            "Epoch 269\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0042, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.905534969044584\n",
            "SCOPE mean: 0.15538715420490096, SCOPE var: 0.009303670230990008\n",
            "Total Loss: 0.004217956490821963\n",
            "----------------------------------------\n",
            "Epoch 270\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0042, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.906285584119441\n",
            "SCOPE mean: 0.15508295105352432, SCOPE var: 0.009293758038149504\n",
            "Total Loss: 0.004171147798819406\n",
            "----------------------------------------\n",
            "Epoch 271\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0041, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.906238368870211\n",
            "SCOPE mean: 0.1547816429603183, SCOPE var: 0.009284119841080725\n",
            "Total Loss: 0.00412491845833926\n",
            "----------------------------------------\n",
            "Epoch 272\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0041, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.905337729529917\n",
            "SCOPE mean: 0.15448327926869837, SCOPE var: 0.009274760775717253\n",
            "Total Loss: 0.00408515475467643\n",
            "----------------------------------------\n",
            "Epoch 273\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0040, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.905174052067\n",
            "SCOPE mean: 0.1542066203349461, SCOPE var: 0.009265657637909167\n",
            "Total Loss: 0.004046138064375708\n",
            "----------------------------------------\n",
            "Epoch 274\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0040, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.905676969249766\n",
            "SCOPE mean: 0.15395467516287645, SCOPE var: 0.009256830170850178\n",
            "Total Loss: 0.004004716725565218\n",
            "----------------------------------------\n",
            "Epoch 275\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0040, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.906803908248541\n",
            "SCOPE mean: 0.15372854493609303, SCOPE var: 0.009248262468889396\n",
            "Total Loss: 0.003961650150691986\n",
            "----------------------------------------\n",
            "Epoch 276\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0039, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.908492715385824\n",
            "SCOPE mean: 0.15353687943182096, SCOPE var: 0.009239977849287513\n",
            "Total Loss: 0.003924675279951174\n",
            "----------------------------------------\n",
            "Epoch 277\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0039, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.90993717396134\n",
            "SCOPE mean: 0.15339143815974526, SCOPE var: 0.009232019392605765\n",
            "Total Loss: 0.0038891268715026133\n",
            "----------------------------------------\n",
            "Epoch 278\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0039, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.911293356046862\n",
            "SCOPE mean: 0.15329503680381168, SCOPE var: 0.009224380127565915\n",
            "Total Loss: 0.003853615369300165\n",
            "----------------------------------------\n",
            "Epoch 279\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0038, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.912597757559954\n",
            "SCOPE mean: 0.15324534473256995, SCOPE var: 0.009217051692658044\n",
            "Total Loss: 0.0038180973947699484\n",
            "----------------------------------------\n",
            "Epoch 280\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0038, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.91381732812696\n",
            "SCOPE mean: 0.1532431773125994, SCOPE var: 0.009210029877093245\n",
            "Total Loss: 0.0037829751486856806\n",
            "----------------------------------------\n",
            "Epoch 281\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0037, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.914970749990168\n",
            "SCOPE mean: 0.15328557407951462, SCOPE var: 0.009203310760769693\n",
            "Total Loss: 0.0037483276165593306\n",
            "----------------------------------------\n",
            "Epoch 282\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0037, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.916019588809387\n",
            "SCOPE mean: 0.15336654762112883, SCOPE var: 0.009196885248895071\n",
            "Total Loss: 0.003714266168930384\n",
            "----------------------------------------\n",
            "Epoch 283\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0037, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.91696029813323\n",
            "SCOPE mean: 0.15347702669831936, SCOPE var: 0.009190740480406029\n",
            "Total Loss: 0.003681069673109888\n",
            "----------------------------------------\n",
            "Epoch 284\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.917813211880166\n",
            "SCOPE mean: 0.15360588515915413, SCOPE var: 0.009184862310627873\n",
            "Total Loss: 0.0036488373586036024\n",
            "----------------------------------------\n",
            "Epoch 285\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.918347180838204\n",
            "SCOPE mean: 0.1537427104415348, SCOPE var: 0.009179234459636797\n",
            "Total Loss: 0.0036173490597322167\n",
            "----------------------------------------\n",
            "Epoch 286\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.9179285750745\n",
            "SCOPE mean: 0.1538484688887016, SCOPE var: 0.009173812251785164\n",
            "Total Loss: 0.0035904889677690556\n",
            "----------------------------------------\n",
            "Epoch 287\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.917273157027704\n",
            "SCOPE mean: 0.15391078054960594, SCOPE var: 0.009168537330441939\n",
            "Total Loss: 0.003562568188650468\n",
            "----------------------------------------\n",
            "Epoch 288\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0035, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.916319431386846\n",
            "SCOPE mean: 0.15392654576015355, SCOPE var: 0.009163400118286246\n",
            "Total Loss: 0.0035326269610408616\n",
            "----------------------------------------\n",
            "Epoch 289\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0035, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.91502833570049\n",
            "SCOPE mean: 0.15389990095179631, SCOPE var: 0.00915840969256265\n",
            "Total Loss: 0.0035030122409130363\n",
            "----------------------------------------\n",
            "Epoch 290\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0035, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.913218354366245\n",
            "SCOPE mean: 0.1538661010866934, SCOPE var: 0.009153629938422562\n",
            "Total Loss: 0.0034774778328155683\n",
            "----------------------------------------\n",
            "Epoch 291\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0035, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.910811919822118\n",
            "SCOPE mean: 0.15382891539114493, SCOPE var: 0.009149059426997386\n",
            "Total Loss: 0.0034522115656300256\n",
            "----------------------------------------\n",
            "Epoch 292\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0034, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.90784973286526\n",
            "SCOPE mean: 0.15379174912816665, SCOPE var: 0.009144700913055286\n",
            "Total Loss: 0.0034267459506022117\n",
            "----------------------------------------\n",
            "Epoch 293\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0034, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.904407457409027\n",
            "SCOPE mean: 0.15375786459275181, SCOPE var: 0.00914053096748897\n",
            "Total Loss: 0.0034011191871390744\n",
            "----------------------------------------\n",
            "Epoch 294\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0034, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.900549106293719\n",
            "SCOPE mean: 0.1537216662584394, SCOPE var: 0.009136542295797936\n",
            "Total Loss: 0.003375466040501754\n",
            "----------------------------------------\n",
            "Epoch 295\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0034, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.89626973222654\n",
            "SCOPE mean: 0.153682209095229, SCOPE var: 0.009132722183083069\n",
            "Total Loss: 0.003351309001750921\n",
            "----------------------------------------\n",
            "Epoch 296\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0033, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.892271207877666\n",
            "SCOPE mean: 0.15363582812165014, SCOPE var: 0.009129026500834607\n",
            "Total Loss: 0.0033284343749261274\n",
            "----------------------------------------\n",
            "Epoch 297\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0033, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.888727110517998\n",
            "SCOPE mean: 0.1535895878068762, SCOPE var: 0.009125428618166669\n",
            "Total Loss: 0.0033044975973424697\n",
            "----------------------------------------\n",
            "Epoch 298\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0033, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.885654215267945\n",
            "SCOPE mean: 0.15354776372410425, SCOPE var: 0.009121929369186191\n",
            "Total Loss: 0.0032808250920211535\n",
            "----------------------------------------\n",
            "Epoch 299\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0033, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.882274694834463\n",
            "SCOPE mean: 0.15351562181885214, SCOPE var: 0.009118573025363655\n",
            "Total Loss: 0.0032589283820325704\n",
            "----------------------------------------\n",
            "Epoch 300\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0032, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.878749676355257\n",
            "SCOPE mean: 0.15349769214726164, SCOPE var: 0.009115349110885346\n",
            "Total Loss: 0.003236830522494074\n",
            "----------------------------------------\n",
            "Epoch 301\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0032, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.875324008537723\n",
            "SCOPE mean: 0.1534973216710931, SCOPE var: 0.009112238106587544\n",
            "Total Loss: 0.003215109117206819\n",
            "----------------------------------------\n",
            "Epoch 302\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0032, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.872041717146214\n",
            "SCOPE mean: 0.153516580471931, SCOPE var: 0.009109230642924173\n",
            "Total Loss: 0.0031931685343739736\n",
            "----------------------------------------\n",
            "Epoch 303\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0032, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.868808280236\n",
            "SCOPE mean: 0.1535613198215909, SCOPE var: 0.00910633112870613\n",
            "Total Loss: 0.0031714023267988586\n",
            "----------------------------------------\n",
            "Epoch 304\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0031, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.866264015784026\n",
            "SCOPE mean: 0.15363158359649778, SCOPE var: 0.009103532758588181\n",
            "Total Loss: 0.0031491841427949215\n",
            "----------------------------------------\n",
            "Epoch 305\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0031, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.864358837929188\n",
            "SCOPE mean: 0.15372669487686233, SCOPE var: 0.009100813093886377\n",
            "Total Loss: 0.0031275388035225523\n",
            "----------------------------------------\n",
            "Epoch 306\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0031, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.86250283504965\n",
            "SCOPE mean: 0.1538482511356819, SCOPE var: 0.009098192600536601\n",
            "Total Loss: 0.0031062831893874563\n",
            "----------------------------------------\n",
            "Epoch 307\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0031, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.860731211973189\n",
            "SCOPE mean: 0.15399693335882134, SCOPE var: 0.009095650600045368\n",
            "Total Loss: 0.0030850948696668733\n",
            "----------------------------------------\n",
            "Epoch 308\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0031, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.858872364362004\n",
            "SCOPE mean: 0.15416940369963064, SCOPE var: 0.009093178260250136\n",
            "Total Loss: 0.0030635278040964647\n",
            "----------------------------------------\n",
            "Epoch 309\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0030, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.856919109539113\n",
            "SCOPE mean: 0.1543599002183619, SCOPE var: 0.009090761999683162\n",
            "Total Loss: 0.0030418500446673068\n",
            "----------------------------------------\n",
            "Epoch 310\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0030, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.855016833018404\n",
            "SCOPE mean: 0.15456088996712486, SCOPE var: 0.009088377519318413\n",
            "Total Loss: 0.0030214492252801555\n",
            "----------------------------------------\n",
            "Epoch 311\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0030, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.853696292312375\n",
            "SCOPE mean: 0.1547628951017242, SCOPE var: 0.009085986234786446\n",
            "Total Loss: 0.003000880543549667\n",
            "----------------------------------------\n",
            "Epoch 312\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0030, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.852851243279646\n",
            "SCOPE mean: 0.15496229616639773, SCOPE var: 0.00908357744733519\n",
            "Total Loss: 0.00297990486781276\n",
            "----------------------------------------\n",
            "Epoch 313\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0030, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.85156164302377\n",
            "SCOPE mean: 0.15516324388652483, SCOPE var: 0.009081185691891211\n",
            "Total Loss: 0.0029593587374650157\n",
            "----------------------------------------\n",
            "Epoch 314\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0029, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.849810697822363\n",
            "SCOPE mean: 0.15536220349287747, SCOPE var: 0.00907879967078041\n",
            "Total Loss: 0.0029382201850545533\n",
            "----------------------------------------\n",
            "Epoch 315\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0029, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.847546426565774\n",
            "SCOPE mean: 0.1555542335883466, SCOPE var: 0.009076411178059\n",
            "Total Loss: 0.0029171994270904963\n",
            "----------------------------------------\n",
            "Epoch 316\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0029, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.845496850539659\n",
            "SCOPE mean: 0.155730586260518, SCOPE var: 0.009073974876443312\n",
            "Total Loss: 0.0028967627848144797\n",
            "----------------------------------------\n",
            "Epoch 317\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0029, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.843085196694616\n",
            "SCOPE mean: 0.15589063142010529, SCOPE var: 0.009071510414787005\n",
            "Total Loss: 0.002876373952934878\n",
            "----------------------------------------\n",
            "Epoch 318\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0029, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.840358178710694\n",
            "SCOPE mean: 0.15603389906231424, SCOPE var: 0.009069011029963301\n",
            "Total Loss: 0.0028560643531178698\n",
            "----------------------------------------\n",
            "Epoch 319\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0028, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.837180330981983\n",
            "SCOPE mean: 0.15615141948499092, SCOPE var: 0.009066467318297411\n",
            "Total Loss: 0.0028358282646325436\n",
            "----------------------------------------\n",
            "Epoch 320\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0028, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.834192145342795\n",
            "SCOPE mean: 0.15634019607025268, SCOPE var: 0.009063867729487805\n",
            "Total Loss: 0.0028162121789609006\n",
            "----------------------------------------\n",
            "Epoch 321\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0028, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.83072916623641\n",
            "SCOPE mean: 0.1565478884437898, SCOPE var: 0.009061243772443715\n",
            "Total Loss: 0.0027967656017033726\n",
            "----------------------------------------\n",
            "Epoch 322\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0028, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.826949898537057\n",
            "SCOPE mean: 0.15674594701511088, SCOPE var: 0.009058591731422719\n",
            "Total Loss: 0.0027772146082795397\n",
            "----------------------------------------\n",
            "Epoch 323\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0028, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.822894742134414\n",
            "SCOPE mean: 0.15694420558067376, SCOPE var: 0.009056003059301378\n",
            "Total Loss: 0.002758361405358498\n",
            "----------------------------------------\n",
            "Epoch 324\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0027, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.819443498569909\n",
            "SCOPE mean: 0.15714622922493768, SCOPE var: 0.009053433133673057\n",
            "Total Loss: 0.002739376179551935\n",
            "----------------------------------------\n",
            "Epoch 325\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0027, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.816103781440042\n",
            "SCOPE mean: 0.15735745792452907, SCOPE var: 0.009050907264994556\n",
            "Total Loss: 0.002721005722956013\n",
            "----------------------------------------\n",
            "Epoch 326\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0027, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.813031776726442\n",
            "SCOPE mean: 0.15758058271004155, SCOPE var: 0.009048420427492723\n",
            "Total Loss: 0.0027029378037517183\n",
            "----------------------------------------\n",
            "Epoch 327\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0027, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.810085028632143\n",
            "SCOPE mean: 0.15781775679163576, SCOPE var: 0.009045976149494518\n",
            "Total Loss: 0.0026858373306811174\n",
            "----------------------------------------\n",
            "Epoch 328\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0027, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.808050550813983\n",
            "SCOPE mean: 0.15806850203417, SCOPE var: 0.009043524735906142\n",
            "Total Loss: 0.002667775676391398\n",
            "----------------------------------------\n",
            "Epoch 329\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0027, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.80608677353896\n",
            "SCOPE mean: 0.1583339112758898, SCOPE var: 0.009041098091366915\n",
            "Total Loss: 0.002650590907309105\n",
            "----------------------------------------\n",
            "Epoch 330\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0026, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.804193390406644\n",
            "SCOPE mean: 0.15860835563551753, SCOPE var: 0.009038697082910895\n",
            "Total Loss: 0.002633712567887534\n",
            "----------------------------------------\n",
            "Epoch 331\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0026, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.803058850741634\n",
            "SCOPE mean: 0.15888816000610378, SCOPE var: 0.00903627768141081\n",
            "Total Loss: 0.0026169781644673194\n",
            "----------------------------------------\n",
            "Epoch 332\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0026, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.801840747467079\n",
            "SCOPE mean: 0.15916939346579037, SCOPE var: 0.009033869115373832\n",
            "Total Loss: 0.0026005551095170227\n",
            "----------------------------------------\n",
            "Epoch 333\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0026, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.800488711027644\n",
            "SCOPE mean: 0.1594489811159467, SCOPE var: 0.009031458083344261\n",
            "Total Loss: 0.0025843312130987466\n",
            "----------------------------------------\n",
            "Epoch 334\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0026, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.799129475408202\n",
            "SCOPE mean: 0.15972074440375858, SCOPE var: 0.00902903350737623\n",
            "Total Loss: 0.002568330887749204\n",
            "----------------------------------------\n",
            "Epoch 335\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0026, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.79780664259732\n",
            "SCOPE mean: 0.1599854943629426, SCOPE var: 0.009026593742755561\n",
            "Total Loss: 0.002552904708418737\n",
            "----------------------------------------\n",
            "Epoch 336\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0025, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.797081908444893\n",
            "SCOPE mean: 0.16024102718505834, SCOPE var: 0.009024108089555031\n",
            "Total Loss: 0.0025370670488646854\n",
            "----------------------------------------\n",
            "Epoch 337\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0025, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.796331703256076\n",
            "SCOPE mean: 0.16048761098793612, SCOPE var: 0.00902160469934164\n",
            "Total Loss: 0.0025217403807338123\n",
            "----------------------------------------\n",
            "Epoch 338\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0025, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.79547716512334\n",
            "SCOPE mean: 0.1607225440735978, SCOPE var: 0.009019083062879742\n",
            "Total Loss: 0.002506731688647711\n",
            "----------------------------------------\n",
            "Epoch 339\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0025, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.794393095917693\n",
            "SCOPE mean: 0.1609470392498513, SCOPE var: 0.009016551120609277\n",
            "Total Loss: 0.0024916562392038447\n",
            "----------------------------------------\n",
            "Epoch 340\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0025, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.793156107713958\n",
            "SCOPE mean: 0.16116245362861764, SCOPE var: 0.009014008117940432\n",
            "Total Loss: 0.002476449721170406\n",
            "----------------------------------------\n",
            "Epoch 341\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0025, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.791771678439947\n",
            "SCOPE mean: 0.16137122459441988, SCOPE var: 0.009011454807108587\n",
            "Total Loss: 0.0024619567974041\n",
            "----------------------------------------\n",
            "Epoch 342\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0024, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.791033353081\n",
            "SCOPE mean: 0.16157543968909713, SCOPE var: 0.009008857143189886\n",
            "Total Loss: 0.0024470179975140424\n",
            "----------------------------------------\n",
            "Epoch 343\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0024, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.790742243492913\n",
            "SCOPE mean: 0.16177931216494934, SCOPE var: 0.009006231250881134\n",
            "Total Loss: 0.0024327432617662578\n",
            "----------------------------------------\n",
            "Epoch 344\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0024, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.79042050434727\n",
            "SCOPE mean: 0.16198706237991642, SCOPE var: 0.009003604532296162\n",
            "Total Loss: 0.0024187523212149875\n",
            "----------------------------------------\n",
            "Epoch 345\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0024, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.790177193790742\n",
            "SCOPE mean: 0.16220167718750547, SCOPE var: 0.009000977905809376\n",
            "Total Loss: 0.00240487195089832\n",
            "----------------------------------------\n",
            "Epoch 346\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0024, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.790095232426523\n",
            "SCOPE mean: 0.16242295797852158, SCOPE var: 0.008998346444649698\n",
            "Total Loss: 0.0023914629871729307\n",
            "----------------------------------------\n",
            "Epoch 347\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0024, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.790326147541368\n",
            "SCOPE mean: 0.16265077837565278, SCOPE var: 0.008995700594212858\n",
            "Total Loss: 0.0023783278082066574\n",
            "----------------------------------------\n",
            "Epoch 348\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0024, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.790839250674006\n",
            "SCOPE mean: 0.1628844073738247, SCOPE var: 0.008993039260242813\n",
            "Total Loss: 0.0023652853092113\n",
            "----------------------------------------\n",
            "Epoch 349\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0024, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.791618344038003\n",
            "SCOPE mean: 0.16312291175551039, SCOPE var: 0.008990362452392146\n",
            "Total Loss: 0.002352610752339686\n",
            "----------------------------------------\n",
            "Epoch 350\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0023, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.793106609315313\n",
            "SCOPE mean: 0.16336632621644043, SCOPE var: 0.008987648147393893\n",
            "Total Loss: 0.002339478854967814\n",
            "----------------------------------------\n",
            "Epoch 351\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0023, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.794770283953621\n",
            "SCOPE mean: 0.16361558038962049, SCOPE var: 0.008984924877596348\n",
            "Total Loss: 0.0023267249628269645\n",
            "----------------------------------------\n",
            "Epoch 352\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0023, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.796622708976148\n",
            "SCOPE mean: 0.16387104062660626, SCOPE var: 0.00898219555609896\n",
            "Total Loss: 0.002314170461329084\n",
            "----------------------------------------\n",
            "Epoch 353\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0023, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.798508152662292\n",
            "SCOPE mean: 0.16413171102901933, SCOPE var: 0.008979470570765813\n",
            "Total Loss: 0.0023018585636798935\n",
            "----------------------------------------\n",
            "Epoch 354\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0023, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.800405505491725\n",
            "SCOPE mean: 0.16439529469011807, SCOPE var: 0.008976748727083237\n",
            "Total Loss: 0.0022895073863087316\n",
            "----------------------------------------\n",
            "Epoch 355\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0023, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.801848866546923\n",
            "SCOPE mean: 0.16463775639310416, SCOPE var: 0.008974008614666625\n",
            "Total Loss: 0.002278777319034242\n",
            "----------------------------------------\n",
            "Epoch 356\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0023, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.803510770416743\n",
            "SCOPE mean: 0.16485679565300987, SCOPE var: 0.008971212260405153\n",
            "Total Loss: 0.0022669578769872155\n",
            "----------------------------------------\n",
            "Epoch 357\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0023, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.805214010554222\n",
            "SCOPE mean: 0.1650479673220989, SCOPE var: 0.008968361549671433\n",
            "Total Loss: 0.00225515903586531\n",
            "----------------------------------------\n",
            "Epoch 358\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0022, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.806350098514077\n",
            "SCOPE mean: 0.16521145307885454, SCOPE var: 0.008965427551974919\n",
            "Total Loss: 0.002244203307237102\n",
            "----------------------------------------\n",
            "Epoch 359\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0022, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.807063660088513\n",
            "SCOPE mean: 0.16534158984315026, SCOPE var: 0.008962276766640622\n",
            "Total Loss: 0.0022331297132590767\n",
            "----------------------------------------\n",
            "Epoch 360\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0022, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.807463482123886\n",
            "SCOPE mean: 0.16546204988844593, SCOPE var: 0.008959153062211364\n",
            "Total Loss: 0.0022219702271694813\n",
            "----------------------------------------\n",
            "Epoch 361\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0022, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.807618232054743\n",
            "SCOPE mean: 0.16557723360016366, SCOPE var: 0.008956064038998984\n",
            "Total Loss: 0.0022109347664971747\n",
            "----------------------------------------\n",
            "Epoch 362\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0022, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.80774626260711\n",
            "SCOPE mean: 0.16568884991185096, SCOPE var: 0.008952996338916988\n",
            "Total Loss: 0.0022000579722482355\n",
            "----------------------------------------\n",
            "Epoch 363\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0022, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.807823251493886\n",
            "SCOPE mean: 0.1657976149616063, SCOPE var: 0.008949928506183548\n",
            "Total Loss: 0.002189991690354037\n",
            "----------------------------------------\n",
            "Epoch 364\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0022, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.808364204539393\n",
            "SCOPE mean: 0.1659041715343901, SCOPE var: 0.008946836575409766\n",
            "Total Loss: 0.002178972079574185\n",
            "----------------------------------------\n",
            "Epoch 365\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0022, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.809378955634285\n",
            "SCOPE mean: 0.16601304643286677, SCOPE var: 0.00894373230684131\n",
            "Total Loss: 0.0021680406752176435\n",
            "----------------------------------------\n",
            "Epoch 366\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0022, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.810465653468064\n",
            "SCOPE mean: 0.16613231085816985, SCOPE var: 0.008940696875085257\n",
            "Total Loss: 0.002158171294989448\n",
            "----------------------------------------\n",
            "Epoch 367\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0021, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.81154905981212\n",
            "SCOPE mean: 0.16626697720249867, SCOPE var: 0.008937751743396012\n",
            "Total Loss: 0.002148416406688923\n",
            "----------------------------------------\n",
            "Epoch 368\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0021, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.81267915108543\n",
            "SCOPE mean: 0.16641733831781125, SCOPE var: 0.008934894984152003\n",
            "Total Loss: 0.0021385739394842655\n",
            "----------------------------------------\n",
            "Epoch 369\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0021, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.813945983340114\n",
            "SCOPE mean: 0.16658886681390328, SCOPE var: 0.008932125350573987\n",
            "Total Loss: 0.002128531366917928\n",
            "----------------------------------------\n",
            "Epoch 370\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0021, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.8153016965296\n",
            "SCOPE mean: 0.16677956538493452, SCOPE var: 0.008929439958682894\n",
            "Total Loss: 0.0021185302665831154\n",
            "----------------------------------------\n",
            "Epoch 371\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0021, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.81685597593623\n",
            "SCOPE mean: 0.16698554678517902, SCOPE var: 0.008926822306050691\n",
            "Total Loss: 0.002109573018128219\n",
            "----------------------------------------\n",
            "Epoch 372\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0021, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.818984611393667\n",
            "SCOPE mean: 0.16720173031780383, SCOPE var: 0.008924240227364216\n",
            "Total Loss: 0.002100261060994715\n",
            "----------------------------------------\n",
            "Epoch 373\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0021, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.821613836999381\n",
            "SCOPE mean: 0.16742559530182097, SCOPE var: 0.008921691429837751\n",
            "Total Loss: 0.0020906296152682826\n",
            "----------------------------------------\n",
            "Epoch 374\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0021, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.824370068027925\n",
            "SCOPE mean: 0.16765391245083847, SCOPE var: 0.008919184706207667\n",
            "Total Loss: 0.002082120121618134\n",
            "----------------------------------------\n",
            "Epoch 375\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0021, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.827098606527633\n",
            "SCOPE mean: 0.16788592122703985, SCOPE var: 0.00891672846657006\n",
            "Total Loss: 0.002073708003753503\n",
            "----------------------------------------\n",
            "Epoch 376\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0021, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.829790581885707\n",
            "SCOPE mean: 0.16811823803040743, SCOPE var: 0.00891429233884739\n",
            "Total Loss: 0.0020652972549695444\n",
            "----------------------------------------\n",
            "Epoch 377\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0021, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.832577228443501\n",
            "SCOPE mean: 0.16834841297849368, SCOPE var: 0.008911864380838096\n",
            "Total Loss: 0.0020572081167572654\n",
            "----------------------------------------\n",
            "Epoch 378\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0020, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.835852015863367\n",
            "SCOPE mean: 0.1685756171189053, SCOPE var: 0.008909438245311478\n",
            "Total Loss: 0.002048875963742383\n",
            "----------------------------------------\n",
            "Epoch 379\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0020, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.839149285088853\n",
            "SCOPE mean: 0.16880004328594658, SCOPE var: 0.008907034373430843\n",
            "Total Loss: 0.002040916320231186\n",
            "----------------------------------------\n",
            "Epoch 380\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0020, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.842296578544751\n",
            "SCOPE mean: 0.16902196650860318, SCOPE var: 0.00890466271307265\n",
            "Total Loss: 0.002032860642225138\n",
            "----------------------------------------\n",
            "Epoch 381\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0020, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.845713725078618\n",
            "SCOPE mean: 0.16924108720425357, SCOPE var: 0.008902303119422155\n",
            "Total Loss: 0.0020250989155833742\n",
            "----------------------------------------\n",
            "Epoch 382\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0020, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.848953568588126\n",
            "SCOPE mean: 0.1694570421318204, SCOPE var: 0.008899971843782915\n",
            "Total Loss: 0.002017286562664783\n",
            "----------------------------------------\n",
            "Epoch 383\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0020, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.852200304370824\n",
            "SCOPE mean: 0.16966888514419434, SCOPE var: 0.008897652960341642\n",
            "Total Loss: 0.002009829336078647\n",
            "----------------------------------------\n",
            "Epoch 384\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0020, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.855833281814057\n",
            "SCOPE mean: 0.16987155780889535, SCOPE var: 0.008895324699039024\n",
            "Total Loss: 0.0020020984463906964\n",
            "----------------------------------------\n",
            "Epoch 385\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0020, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.859395311206686\n",
            "SCOPE mean: 0.1700672135011296, SCOPE var: 0.008893010799686773\n",
            "Total Loss: 0.0019947562034117543\n",
            "----------------------------------------\n",
            "Epoch 386\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0020, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.862738275096717\n",
            "SCOPE mean: 0.17025735339031417, SCOPE var: 0.008890723435925113\n",
            "Total Loss: 0.001987217808899241\n",
            "----------------------------------------\n",
            "Epoch 387\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0020, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.865895072145596\n",
            "SCOPE mean: 0.17044232573512796, SCOPE var: 0.008888522295619573\n",
            "Total Loss: 0.001979522091545643\n",
            "----------------------------------------\n",
            "Epoch 388\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0020, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.869024899188652\n",
            "SCOPE mean: 0.17061759576377053, SCOPE var: 0.008886310454757839\n",
            "Total Loss: 0.0019725362363536914\n",
            "----------------------------------------\n",
            "Epoch 389\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0020, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.87254895900662\n",
            "SCOPE mean: 0.17078293146983323, SCOPE var: 0.008884056299659927\n",
            "Total Loss: 0.001964729414045955\n",
            "----------------------------------------\n",
            "Epoch 390\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0020, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.876213901273264\n",
            "SCOPE mean: 0.17094203814671163, SCOPE var: 0.008881798995617871\n",
            "Total Loss: 0.00195772131823916\n",
            "----------------------------------------\n",
            "Epoch 391\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0020, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.879605855220927\n",
            "SCOPE mean: 0.1710962711080987, SCOPE var: 0.008879567556557475\n",
            "Total Loss: 0.0019505845932419148\n",
            "----------------------------------------\n",
            "Epoch 392\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0019, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.88275245087958\n",
            "SCOPE mean: 0.17124590523443767, SCOPE var: 0.00887736060626783\n",
            "Total Loss: 0.0019431985571831672\n",
            "----------------------------------------\n",
            "Epoch 393\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0019, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.885857035656668\n",
            "SCOPE mean: 0.17139105419966166, SCOPE var: 0.008875169402489726\n",
            "Total Loss: 0.0019360455426078913\n",
            "----------------------------------------\n",
            "Epoch 394\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0019, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.888898123666806\n",
            "SCOPE mean: 0.17153028713648433, SCOPE var: 0.008872991063792387\n",
            "Total Loss: 0.001928844511562504\n",
            "----------------------------------------\n",
            "Epoch 395\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0019, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.891855860083833\n",
            "SCOPE mean: 0.17166273457963704, SCOPE var: 0.008870824102087813\n",
            "Total Loss: 0.001921780562613642\n",
            "----------------------------------------\n",
            "Epoch 396\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0019, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.895127750486633\n",
            "SCOPE mean: 0.17178802351650357, SCOPE var: 0.008868642068850295\n",
            "Total Loss: 0.0019147454673358938\n",
            "----------------------------------------\n",
            "Epoch 397\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0019, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.897805472430612\n",
            "SCOPE mean: 0.17189228742548351, SCOPE var: 0.008866475136005287\n",
            "Total Loss: 0.00190786943126985\n",
            "----------------------------------------\n",
            "Epoch 398\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0019, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.89995435254719\n",
            "SCOPE mean: 0.17197824528727967, SCOPE var: 0.008864324169911137\n",
            "Total Loss: 0.0019010296964510807\n",
            "----------------------------------------\n",
            "Epoch 399\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0019, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.902042417926413\n",
            "SCOPE mean: 0.17204785323852326, SCOPE var: 0.008862162991663517\n",
            "Total Loss: 0.0018940274295253428\n",
            "----------------------------------------\n",
            "Epoch 400\n",
            "IS mean: 0.29707760471436423,IS variance: 0.009117349795339989\n",
            "SCOPE Var loss:  tensor(0.0019, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.903831028195846\n",
            "SCOPE mean: 0.17210475775306194, SCOPE var: 0.008860015618870417\n",
            "Total Loss: 0.0018872457108499532\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[-0.1445, -0.3486],\n",
            "        [ 0.0288, -0.1645],\n",
            "        [ 0.6106,  0.6361],\n",
            "        [-0.5312,  0.2210],\n",
            "        [ 0.6264, -0.4697],\n",
            "        [ 0.3071, -0.3266],\n",
            "        [-0.6120,  0.0066],\n",
            "        [ 0.2473,  0.4616],\n",
            "        [ 0.6379,  0.4001],\n",
            "        [ 0.3229,  0.5033],\n",
            "        [-0.5825, -0.5235],\n",
            "        [-0.5225, -0.4385],\n",
            "        [-0.7067, -0.0011],\n",
            "        [ 0.3752, -0.4416],\n",
            "        [ 0.5312, -0.2840],\n",
            "        [ 0.4589, -0.0804]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([ 0.6773,  0.0242, -0.1240,  0.5331,  0.0111,  0.3691, -0.6856,  0.2713,\n",
            "        -0.1127, -0.2128, -0.1913, -0.3826,  0.3791,  0.1219,  0.3977, -0.4081],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[ 1.8927e-01, -2.4525e-01, -9.6269e-02, -8.4502e-02, -1.0496e-01,\n",
            "          2.6888e-02,  1.4583e-01,  1.7280e-01, -1.8449e-01, -3.7651e-02,\n",
            "          2.4297e-01, -1.3673e-01,  1.5344e-02,  1.0436e-01, -1.2142e-01,\n",
            "         -2.3646e-01],\n",
            "        [ 1.8610e-01, -2.4166e-01, -5.2523e-02, -1.8135e-01, -2.2385e-01,\n",
            "         -2.8170e-01, -1.4454e-01,  7.4342e-02, -2.5932e-01,  2.1015e-01,\n",
            "         -2.2206e-01, -2.4215e-01, -4.4928e-02,  8.1119e-02,  3.2361e-02,\n",
            "          1.0057e-01],\n",
            "        [ 3.6579e-02,  1.5038e-01,  4.0940e-02, -2.4007e-01,  1.6176e-01,\n",
            "         -7.7883e-02,  2.2910e-01,  1.3815e-01, -6.1729e-02, -2.6866e-01,\n",
            "          7.8982e-02, -9.0411e-02,  2.9882e-02,  1.1204e-01, -7.6711e-02,\n",
            "         -1.4085e-01],\n",
            "        [-9.9634e-02,  1.5775e-01,  4.8661e-02, -1.5194e-01, -2.8026e-01,\n",
            "          1.6379e-01, -1.4361e-01, -2.4474e-01,  1.4329e-02, -2.2796e-01,\n",
            "         -7.3527e-02, -1.6425e-01, -2.1108e-01, -7.7145e-02,  1.9500e-01,\n",
            "         -1.3105e-01],\n",
            "        [-3.0562e-02,  3.7968e-02, -9.0779e-02, -7.2830e-02,  4.6829e-02,\n",
            "         -5.4149e-03, -1.6649e-01,  3.5053e-02, -1.1435e-05, -1.2617e-01,\n",
            "          1.2140e-01, -1.0947e-02,  3.4297e-01,  1.9337e-01,  7.7084e-02,\n",
            "         -1.3546e-01],\n",
            "        [ 1.0857e-01, -6.1958e-02, -1.2956e-01,  9.4901e-02,  2.2383e-01,\n",
            "         -3.9782e-02, -1.1532e-02,  1.5927e-01,  4.7869e-02,  1.6061e-01,\n",
            "          2.2387e-01,  1.0505e-01, -6.9242e-02, -1.7793e-01, -1.1224e-01,\n",
            "          8.5300e-02],\n",
            "        [-3.0893e-01, -1.1373e-01, -2.2601e-01, -1.5067e-01, -7.6840e-02,\n",
            "         -2.8322e-02, -2.3978e-01, -2.8653e-01,  1.9284e-01,  4.2201e-02,\n",
            "          2.0770e-01, -6.2762e-02, -1.5692e-01, -1.0012e-01,  5.3330e-02,\n",
            "          2.0381e-01],\n",
            "        [ 2.1545e-01, -1.2119e-01, -1.6084e-01,  1.2195e-01, -1.3416e-01,\n",
            "          6.1338e-04,  1.0823e-01, -3.1241e-02, -1.9726e-01, -9.2478e-02,\n",
            "         -1.1448e-01, -2.7665e-02, -2.9057e-02, -3.9692e-02, -1.3007e-01,\n",
            "          1.7757e-01],\n",
            "        [ 1.3430e-01,  5.2682e-02, -2.2560e-01,  6.0630e-02, -1.1852e-01,\n",
            "         -3.8627e-02,  3.3424e-02,  9.2974e-02,  1.2349e-01, -2.4427e-01,\n",
            "         -2.0898e-01,  1.0012e-01, -1.6341e-01, -1.5053e-01,  9.7641e-02,\n",
            "         -5.3290e-02],\n",
            "        [ 2.0844e-02, -1.9477e-01,  7.8692e-03, -2.2904e-01, -1.2688e-01,\n",
            "         -1.0619e-01,  1.5495e-01,  1.5784e-01, -2.5994e-01,  7.3025e-02,\n",
            "         -1.1588e-01,  2.0708e-01,  7.9100e-02, -1.4247e-01, -8.1005e-02,\n",
            "         -1.0932e-01],\n",
            "        [-1.0558e-01, -1.5956e-01,  2.0008e-01, -1.3182e-01, -2.6111e-01,\n",
            "          2.3833e-02,  1.4947e-02, -1.1752e-01, -1.6658e-01,  9.6721e-02,\n",
            "         -1.8084e-01,  1.7568e-01, -1.5778e-01, -1.0442e-01, -2.0932e-01,\n",
            "         -2.0982e-01],\n",
            "        [ 1.7479e-01, -2.8080e-01, -9.1998e-02, -5.6231e-02, -1.1102e-01,\n",
            "          1.8080e-01, -1.9286e-01,  8.6171e-02,  6.7854e-03,  1.7067e-01,\n",
            "         -2.1854e-02,  6.2092e-03,  4.8453e-01, -1.6403e-01, -2.1502e-01,\n",
            "         -1.2689e-01],\n",
            "        [-1.3089e-01,  3.8727e-01, -4.6876e-02, -5.8173e-02,  1.9424e-01,\n",
            "          9.4832e-02, -2.0478e-01,  8.3982e-02, -7.6521e-02, -8.1841e-02,\n",
            "         -8.5319e-02,  1.7251e-01, -5.5993e-02,  1.0287e-02,  8.1800e-02,\n",
            "          3.4710e-01],\n",
            "        [ 1.7114e-01,  3.9238e-01,  1.1640e-01,  2.4026e-02,  8.4698e-02,\n",
            "          4.4314e-04, -1.5954e-01,  7.1432e-02, -2.7675e-01, -4.2535e-02,\n",
            "         -1.9452e-01,  1.6456e-01, -1.7009e-01,  1.3030e-01,  1.7633e-02,\n",
            "          2.2110e-01],\n",
            "        [-3.6971e-02, -3.7015e-02, -1.2899e-01,  3.0485e-01,  6.2505e-02,\n",
            "         -2.3912e-01,  1.3956e-01,  1.5746e-01, -5.0274e-03, -2.2083e-01,\n",
            "         -2.4190e-01,  2.4075e-01,  6.0244e-02, -1.1825e-01,  1.9222e-01,\n",
            "         -2.3927e-02],\n",
            "        [-1.4395e-02, -1.0676e-01, -6.5892e-02,  1.7053e-01,  1.2680e-01,\n",
            "         -2.3370e-01, -6.0918e-02,  3.1737e-02, -1.0326e-01, -2.7899e-02,\n",
            "          1.7257e-03,  8.1709e-02,  2.6456e-01,  2.9684e-01, -2.0494e-01,\n",
            "          5.2526e-02]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([ 0.1637, -0.1032,  0.1079, -0.0361,  0.1305, -0.1991, -0.0685,  0.2167,\n",
            "        -0.2401,  0.0428, -0.2197,  0.0885,  0.1136,  0.1561,  0.1003,  0.1979],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[-0.1804,  0.2590,  0.1520, -0.1207,  0.2414, -0.0248,  0.3749, -0.0276,\n",
            "         -0.0235, -0.0022, -0.1083,  0.0933, -0.0879, -0.1226,  0.1312, -0.0875]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([-0.1561], dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NN_l1_l2_reg(\n",
              "  (hidden_layers): ModuleList(\n",
              "    (0): Linear(in_features=2, out_features=16, bias=True)\n",
              "    (1): Linear(in_features=16, out_features=16, bias=True)\n",
              "  )\n",
              "  (output_layer): Linear(in_features=16, out_features=1, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_600_random_pi_b_600.get_heatmap()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "2GDLKiM967Ml",
        "outputId": "ac157944-d91f-4ac8-fd66-7d3d987df168"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"88df6985-1c82-4191-86e0-6d73f3923996\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"88df6985-1c82-4191-86e0-6d73f3923996\")) {                    Plotly.newPlot(                        \"88df6985-1c82-4191-86e0-6d73f3923996\",                        [{\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"z\":[[-0.14276939749341458,-0.1396453177203452,-0.1832426480458663,-0.23092147204737118,-0.2796696531057488,-0.3264074441001755,-0.37035722555646533,-0.4143070070127551,-0.45825678846904483,-0.5022065699253346],[-0.13399901228478062,-0.15682218139356624,-0.20702690458229295,-0.24767694326846612,-0.2895715553979792,-0.3317119555130534,-0.3756617369693432,-0.41961151842563293,-0.4635325007414548,-0.5056957602325634],[-0.12897682258334434,-0.14514212392066608,-0.17507273904095033,-0.2206254415729138,-0.2604699750803376,-0.3003145085877614,-0.3401590420951852,-0.38000357560260906,-0.41984810911003284,-0.45969264261745657],[-0.1289232584275148,-0.14110365454918064,-0.14357503080204512,-0.181875707296426,-0.224019069445187,-0.26386360295261085,-0.3037081364600346,-0.3435526699674584,-0.3833972034748822,-0.423241736982306],[-0.1272707761160315,-0.1345999523846225,-0.13502996943773296,-0.14686300966971147,-0.18867867555190163,-0.22741269731746022,-0.26725723082488406,-0.3071017643323078,-0.34694629783973163,-0.38679083134715536],[-0.1256182938045482,-0.1295899865877132,-0.1264218011675007,-0.13672942423351284,-0.15344917674180072,-0.19448783033480213,-0.23080632518973346,-0.2706508586971572,-0.31049539220458106,-0.35033992571200484],[-0.12396581149306489,-0.12691303098843604,-0.1220284010396887,-0.12812125596328056,-0.1404464208235891,-0.16317105641550947,-0.20181382878937043,-0.23419995306200664,-0.27404448656943037,-0.31388902007685415],[-0.12231332918158158,-0.12433188818297945,-0.12007406198494776,-0.12076693112746587,-0.13015935122587904,-0.14450195533575114,-0.17289293608921824,-0.20913982724393876,-0.23759358093427982,-0.27743811444170363],[-0.11504248038711971,-0.12175074537752285,-0.1203027900849345,-0.12171894537359511,-0.12121254248882812,-0.13421488573804108,-0.14875032444462308,-0.18261481576292699,-0.21646582569850706,-0.24396640879097642],[-0.10855579477178673,-0.11916960257206625,-0.12053151818492128,-0.12265369272983143,-0.12290014712927305,-0.12392781614033102,-0.1382704202502031,-0.15529772876199574,-0.19233669543663573,-0.22379182415307536]],\"type\":\"heatmap\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"Values\"},\"ticks\":\"outside\",\"tickvals\":[-0.5056957602325634,-0.10855579477178673],\"ticktext\":[-0.5056957602325634,-0.10855579477178673]}},\"xaxis\":{\"tickvals\":[0,1,2,3,4,5,6,7,8,9],\"ticktext\":[0,1,2,3,4,5,6,7,8,9],\"title\":{\"text\":\"X\"}},\"yaxis\":{\"tickvals\":[9,8,7,6,5,4,3,2,1,0],\"ticktext\":[9,8,7,6,5,4,3,2,1,0],\"title\":{\"text\":\"Y\"},\"autorange\":\"reversed\"},\"title\":{\"text\":\"Heatmap\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('88df6985-1c82-4191-86e0-6d73f3923996');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b_800 = action_probs_top_n_epsilon(q_table, 1, 0.4)\n",
        "pi_b_800 = experiment_actions(800, env_50, P_pi_b_800)\n",
        "P_pi_e_800 = action_probs_top_n_epsilon(q_table, 1, 0.05)\n",
        "pi_e_800 = experiment_actions(1000, env_50, P_pi_e_800)\n",
        "# model_800_random_pi_b_800 = CustomizableFeatureNet(input_dim=2, hidden_dims=[10, 10], output_dim=1, dtype = torch.float64, l2_lambda=0.002)\n",
        "# model_800_random_pi_b_800 = NN_l1_reg(input_dim=2, hidden_dims=[10, 10], output_dim=1, dtype = torch.float64, l1_lambda=0.0001)\n",
        "model_800_random_pi_b_800 = NN_l1_l2_reg(input_dim=2, hidden_dims=[16, 16], output_dim=1, dtype = torch.float64, l1_lambda=0.0001, l2_lambda = 0.0001)\n",
        "test_800_random_pi_b_800 = SCOPE_straight(model_800_random_pi_b_800, 0.99, 10000, pi_b_800, P_pi_b_800, P_pi_e_800, 0.3, dtype = torch.float64)\n",
        "test_800_random_pi_b_800.train_var_scope(500, 0.001, 1, 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ub1eeDQ_gBCY",
        "outputId": "7fc2f293-e432-4c50-ea67-bd08ed9d566c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0458, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  17.37958175927478\n",
            "SCOPE mean: 0.48076314709695417, SCOPE var: 0.014904131022434408\n",
            "Total Loss: 0.04575112640269493\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0854, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  17.31908477727003\n",
            "SCOPE mean: 0.4703620959062186, SCOPE var: 0.014648459593509848\n",
            "Total Loss: 0.08538300643807667\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0827, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  16.965231508387408\n",
            "SCOPE mean: 0.46285641303280634, SCOPE var: 0.0143920540816015\n",
            "Total Loss: 0.08270453477739553\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0797, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  16.63387771820627\n",
            "SCOPE mean: 0.45635988531244803, SCOPE var: 0.014160387141974366\n",
            "Total Loss: 0.07974690331611202\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0767, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  16.31655644005212\n",
            "SCOPE mean: 0.450332664407827, SCOPE var: 0.01394277390725589\n",
            "Total Loss: 0.07674682238924868\n",
            "----------------------------------------\n",
            "Epoch 6\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0738, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  16.006005950460416\n",
            "SCOPE mean: 0.4443759466009441, SCOPE var: 0.013717934105440352\n",
            "Total Loss: 0.07384265486742662\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0710, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  15.703620362638851\n",
            "SCOPE mean: 0.4381642374843526, SCOPE var: 0.013480235636422958\n",
            "Total Loss: 0.0709764077498357\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0681, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  15.411266288788507\n",
            "SCOPE mean: 0.4320601495512745, SCOPE var: 0.01325292914835308\n",
            "Total Loss: 0.06812733865098791\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0652, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  15.122269400234805\n",
            "SCOPE mean: 0.42574634829634067, SCOPE var: 0.013034821428379143\n",
            "Total Loss: 0.06523721177579386\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0624, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.839468804388588\n",
            "SCOPE mean: 0.419380566943934, SCOPE var: 0.012822205872931897\n",
            "Total Loss: 0.06241859037672891\n",
            "----------------------------------------\n",
            "Epoch 11\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0597, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.562349546839933\n",
            "SCOPE mean: 0.41293935900615997, SCOPE var: 0.012615149247708776\n",
            "Total Loss: 0.05970229741443505\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0571, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.291401151448463\n",
            "SCOPE mean: 0.40683340003780244, SCOPE var: 0.012438893587238677\n",
            "Total Loss: 0.05708275678475765\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0546, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.027952324215496\n",
            "SCOPE mean: 0.4008047979775242, SCOPE var: 0.012279506894946982\n",
            "Total Loss: 0.05461082590799968\n",
            "----------------------------------------\n",
            "Epoch 14\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0523, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.771243081013388\n",
            "SCOPE mean: 0.3948190110699329, SCOPE var: 0.012125195256755771\n",
            "Total Loss: 0.05228040236164787\n",
            "----------------------------------------\n",
            "Epoch 15\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0502, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.521676899087357\n",
            "SCOPE mean: 0.38892436677114894, SCOPE var: 0.011977455465366646\n",
            "Total Loss: 0.0501995214442444\n",
            "----------------------------------------\n",
            "Epoch 16\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0482, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.268950027629902\n",
            "SCOPE mean: 0.38265339205213234, SCOPE var: 0.011826678369286484\n",
            "Total Loss: 0.04823097526789115\n",
            "----------------------------------------\n",
            "Epoch 17\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0463, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.017347500085132\n",
            "SCOPE mean: 0.3762128772374764, SCOPE var: 0.011674173503398359\n",
            "Total Loss: 0.046290498107580305\n",
            "----------------------------------------\n",
            "Epoch 18\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0445, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.77155221298886\n",
            "SCOPE mean: 0.36963155817300447, SCOPE var: 0.011522067614902917\n",
            "Total Loss: 0.044450859328164255\n",
            "----------------------------------------\n",
            "Epoch 19\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0427, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.533593461865676\n",
            "SCOPE mean: 0.36311799331625555, SCOPE var: 0.011374175718372424\n",
            "Total Loss: 0.04266123448198165\n",
            "----------------------------------------\n",
            "Epoch 20\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0410, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.302560790618951\n",
            "SCOPE mean: 0.3566292896635723, SCOPE var: 0.011233932158241986\n",
            "Total Loss: 0.04096981128614715\n",
            "----------------------------------------\n",
            "Epoch 21\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0394, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.081573095609054\n",
            "SCOPE mean: 0.34936403330813826, SCOPE var: 0.011097608311961178\n",
            "Total Loss: 0.03937950090297195\n",
            "----------------------------------------\n",
            "Epoch 22\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0379, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.870558250592223\n",
            "SCOPE mean: 0.3421299697950355, SCOPE var: 0.010964734417489096\n",
            "Total Loss: 0.03788678205842291\n",
            "----------------------------------------\n",
            "Epoch 23\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0365, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.669457232309188\n",
            "SCOPE mean: 0.3350836800734156, SCOPE var: 0.01084142303123277\n",
            "Total Loss: 0.03652531493318722\n",
            "----------------------------------------\n",
            "Epoch 24\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0353, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.476862064088863\n",
            "SCOPE mean: 0.3286197786676672, SCOPE var: 0.010758340820872006\n",
            "Total Loss: 0.03529479837590955\n",
            "----------------------------------------\n",
            "Epoch 25\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0342, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.292596731556936\n",
            "SCOPE mean: 0.3222990868228741, SCOPE var: 0.010680996231422019\n",
            "Total Loss: 0.03422620729400365\n",
            "----------------------------------------\n",
            "Epoch 26\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0332, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.118953762817547\n",
            "SCOPE mean: 0.31778418641739464, SCOPE var: 0.01060962598756102\n",
            "Total Loss: 0.03321609099262321\n",
            "----------------------------------------\n",
            "Epoch 27\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0323, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.95630020568609\n",
            "SCOPE mean: 0.31375344342074724, SCOPE var: 0.010543681300687028\n",
            "Total Loss: 0.03225650422369063\n",
            "----------------------------------------\n",
            "Epoch 28\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0314, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.80491005885134\n",
            "SCOPE mean: 0.3098213564295071, SCOPE var: 0.010481724517400731\n",
            "Total Loss: 0.031360549300745624\n",
            "----------------------------------------\n",
            "Epoch 29\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0305, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.663369564841279\n",
            "SCOPE mean: 0.30602524674918696, SCOPE var: 0.010423581579029034\n",
            "Total Loss: 0.03049819286279595\n",
            "----------------------------------------\n",
            "Epoch 30\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0297, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.531134528849753\n",
            "SCOPE mean: 0.3023739765791084, SCOPE var: 0.010368855717362974\n",
            "Total Loss: 0.02967552182002376\n",
            "----------------------------------------\n",
            "Epoch 31\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0289, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.406862493893076\n",
            "SCOPE mean: 0.2988521012658539, SCOPE var: 0.010316832489498159\n",
            "Total Loss: 0.028897443501362655\n",
            "----------------------------------------\n",
            "Epoch 32\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0281, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.289793627876598\n",
            "SCOPE mean: 0.2954520300333229, SCOPE var: 0.010267074134231948\n",
            "Total Loss: 0.028145277610841683\n",
            "----------------------------------------\n",
            "Epoch 33\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0274, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.17947379772956\n",
            "SCOPE mean: 0.2921991032631523, SCOPE var: 0.010219552741693682\n",
            "Total Loss: 0.027411689434505875\n",
            "----------------------------------------\n",
            "Epoch 34\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0267, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.076405211400726\n",
            "SCOPE mean: 0.28904568945426884, SCOPE var: 0.010173805213725597\n",
            "Total Loss: 0.026698728731967356\n",
            "----------------------------------------\n",
            "Epoch 35\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0260, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.980531697062881\n",
            "SCOPE mean: 0.28599461889688166, SCOPE var: 0.010129690261891018\n",
            "Total Loss: 0.02602587316738486\n",
            "----------------------------------------\n",
            "Epoch 36\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0254, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.890348808895931\n",
            "SCOPE mean: 0.2830566146113379, SCOPE var: 0.010087180299190047\n",
            "Total Loss: 0.02537646332052055\n",
            "----------------------------------------\n",
            "Epoch 37\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0248, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.805658363108943\n",
            "SCOPE mean: 0.2802319562866829, SCOPE var: 0.010046134151932194\n",
            "Total Loss: 0.02475987775607039\n",
            "----------------------------------------\n",
            "Epoch 38\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0242, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.726821314163555\n",
            "SCOPE mean: 0.27752526149290146, SCOPE var: 0.010006423986775799\n",
            "Total Loss: 0.02417064728039577\n",
            "----------------------------------------\n",
            "Epoch 39\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0236, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.654078999233267\n",
            "SCOPE mean: 0.2749608113197092, SCOPE var: 0.009968189064131374\n",
            "Total Loss: 0.023615214320402894\n",
            "----------------------------------------\n",
            "Epoch 40\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0231, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.585736742823375\n",
            "SCOPE mean: 0.2725047552258133, SCOPE var: 0.009931274769378835\n",
            "Total Loss: 0.02307146535965033\n",
            "----------------------------------------\n",
            "Epoch 41\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0225, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.521489647727892\n",
            "SCOPE mean: 0.2702043259695557, SCOPE var: 0.009895458746635824\n",
            "Total Loss: 0.02254444684662931\n",
            "----------------------------------------\n",
            "Epoch 42\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0220, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.461084349574143\n",
            "SCOPE mean: 0.26809163222610166, SCOPE var: 0.009860564309899887\n",
            "Total Loss: 0.022029425511243306\n",
            "----------------------------------------\n",
            "Epoch 43\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0215, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.404433256002687\n",
            "SCOPE mean: 0.26612513460645093, SCOPE var: 0.009827194570125845\n",
            "Total Loss: 0.021524121951955612\n",
            "----------------------------------------\n",
            "Epoch 44\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0210, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.35108295923117\n",
            "SCOPE mean: 0.26427965065532305, SCOPE var: 0.009794241764127987\n",
            "Total Loss: 0.021038390785426554\n",
            "----------------------------------------\n",
            "Epoch 45\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0206, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.301550842591386\n",
            "SCOPE mean: 0.26252710803708373, SCOPE var: 0.009762183464322357\n",
            "Total Loss: 0.020573852224819035\n",
            "----------------------------------------\n",
            "Epoch 46\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0201, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.255552117348342\n",
            "SCOPE mean: 0.26086072127258836, SCOPE var: 0.00973096727795394\n",
            "Total Loss: 0.020124912288264494\n",
            "----------------------------------------\n",
            "Epoch 47\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0197, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.211949208005539\n",
            "SCOPE mean: 0.25924490066250266, SCOPE var: 0.009700168716270247\n",
            "Total Loss: 0.019683710447414314\n",
            "----------------------------------------\n",
            "Epoch 48\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0193, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.17102402054973\n",
            "SCOPE mean: 0.25770612330519055, SCOPE var: 0.009669642859155756\n",
            "Total Loss: 0.019251913493193044\n",
            "----------------------------------------\n",
            "Epoch 49\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0188, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.132809393266248\n",
            "SCOPE mean: 0.2562285610477917, SCOPE var: 0.009639308164763296\n",
            "Total Loss: 0.01884002167390505\n",
            "----------------------------------------\n",
            "Epoch 50\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0184, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.09678295268668\n",
            "SCOPE mean: 0.25473473340304026, SCOPE var: 0.009609122583650643\n",
            "Total Loss: 0.018436831944800534\n",
            "----------------------------------------\n",
            "Epoch 51\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0180, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.062569091775487\n",
            "SCOPE mean: 0.25321599530357597, SCOPE var: 0.009579023534758015\n",
            "Total Loss: 0.018041189587099517\n",
            "----------------------------------------\n",
            "Epoch 52\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0177, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.029925486392198\n",
            "SCOPE mean: 0.2516932096133203, SCOPE var: 0.009549359496884704\n",
            "Total Loss: 0.017653140326873453\n",
            "----------------------------------------\n",
            "Epoch 53\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0173, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.998692883089324\n",
            "SCOPE mean: 0.25019035525528477, SCOPE var: 0.009518827107514588\n",
            "Total Loss: 0.017274263331334926\n",
            "----------------------------------------\n",
            "Epoch 54\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0169, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.968823226740414\n",
            "SCOPE mean: 0.2486938448203387, SCOPE var: 0.009487577076290296\n",
            "Total Loss: 0.01690517787049542\n",
            "----------------------------------------\n",
            "Epoch 55\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0165, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.939416418604447\n",
            "SCOPE mean: 0.24716231447901135, SCOPE var: 0.00945652291923559\n",
            "Total Loss: 0.01653542574053173\n",
            "----------------------------------------\n",
            "Epoch 56\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0162, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.910575425422675\n",
            "SCOPE mean: 0.24559873043919342, SCOPE var: 0.009425671064451501\n",
            "Total Loss: 0.016178534431332544\n",
            "----------------------------------------\n",
            "Epoch 57\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0158, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.882149019891498\n",
            "SCOPE mean: 0.2439681751910648, SCOPE var: 0.009394885324227853\n",
            "Total Loss: 0.015831765544177062\n",
            "----------------------------------------\n",
            "Epoch 58\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0155, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.854031179169272\n",
            "SCOPE mean: 0.24228343355609244, SCOPE var: 0.009364145545107746\n",
            "Total Loss: 0.015499387410229794\n",
            "----------------------------------------\n",
            "Epoch 59\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0152, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.82660559754809\n",
            "SCOPE mean: 0.2405721777546411, SCOPE var: 0.009333603823831471\n",
            "Total Loss: 0.015180157679568445\n",
            "----------------------------------------\n",
            "Epoch 60\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0149, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.79914598221722\n",
            "SCOPE mean: 0.2388283457761412, SCOPE var: 0.009303191953975604\n",
            "Total Loss: 0.014876887576717925\n",
            "----------------------------------------\n",
            "Epoch 61\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0146, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.772081947186043\n",
            "SCOPE mean: 0.23706183481178328, SCOPE var: 0.009274076206583921\n",
            "Total Loss: 0.01458483552161612\n",
            "----------------------------------------\n",
            "Epoch 62\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0143, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.746690268765708\n",
            "SCOPE mean: 0.23537839674581673, SCOPE var: 0.009247134729680698\n",
            "Total Loss: 0.014303690668525862\n",
            "----------------------------------------\n",
            "Epoch 63\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0140, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.72282931197765\n",
            "SCOPE mean: 0.23378914229691794, SCOPE var: 0.009220810914390769\n",
            "Total Loss: 0.014028808281019926\n",
            "----------------------------------------\n",
            "Epoch 64\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0138, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.700911050643263\n",
            "SCOPE mean: 0.2323301380806225, SCOPE var: 0.009195199651027285\n",
            "Total Loss: 0.013761373003441692\n",
            "----------------------------------------\n",
            "Epoch 65\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0135, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.681152253568099\n",
            "SCOPE mean: 0.23099665945839806, SCOPE var: 0.009170103205173726\n",
            "Total Loss: 0.013502505753694608\n",
            "----------------------------------------\n",
            "Epoch 66\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0133, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.663525045785564\n",
            "SCOPE mean: 0.22978316211129513, SCOPE var: 0.009145644666920746\n",
            "Total Loss: 0.01325145659240134\n",
            "----------------------------------------\n",
            "Epoch 67\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0130, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.647569729880395\n",
            "SCOPE mean: 0.22829691007989814, SCOPE var: 0.009121987635922134\n",
            "Total Loss: 0.013006488993552365\n",
            "----------------------------------------\n",
            "Epoch 68\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0128, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.633779590819673\n",
            "SCOPE mean: 0.22688670550214746, SCOPE var: 0.009099160996570753\n",
            "Total Loss: 0.012769156047867252\n",
            "----------------------------------------\n",
            "Epoch 69\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0125, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.622083491104933\n",
            "SCOPE mean: 0.2255705455321526, SCOPE var: 0.009076411986111291\n",
            "Total Loss: 0.012537949572936568\n",
            "----------------------------------------\n",
            "Epoch 70\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0123, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.612047354999515\n",
            "SCOPE mean: 0.2243589905569569, SCOPE var: 0.009054325952365931\n",
            "Total Loss: 0.012312806469065726\n",
            "----------------------------------------\n",
            "Epoch 71\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0121, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.603914457150818\n",
            "SCOPE mean: 0.22323246252642648, SCOPE var: 0.009033296971217403\n",
            "Total Loss: 0.012095127133780782\n",
            "----------------------------------------\n",
            "Epoch 72\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0119, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.59749866463756\n",
            "SCOPE mean: 0.22215801395790677, SCOPE var: 0.009013052087905041\n",
            "Total Loss: 0.011885115922773687\n",
            "----------------------------------------\n",
            "Epoch 73\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0117, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.592949900440447\n",
            "SCOPE mean: 0.22116878400286813, SCOPE var: 0.008993225676440429\n",
            "Total Loss: 0.011679440132291576\n",
            "----------------------------------------\n",
            "Epoch 74\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0115, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.58976868894745\n",
            "SCOPE mean: 0.22024472774268802, SCOPE var: 0.008973727466389919\n",
            "Total Loss: 0.011476904987507046\n",
            "----------------------------------------\n",
            "Epoch 75\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0113, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.588104568851117\n",
            "SCOPE mean: 0.21939081580156558, SCOPE var: 0.008955049430027734\n",
            "Total Loss: 0.011281607349086342\n",
            "----------------------------------------\n",
            "Epoch 76\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0111, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.587339514388328\n",
            "SCOPE mean: 0.21859940785437043, SCOPE var: 0.008937112234554217\n",
            "Total Loss: 0.01109195110658349\n",
            "----------------------------------------\n",
            "Epoch 77\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0109, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.58755990550427\n",
            "SCOPE mean: 0.2178718217279135, SCOPE var: 0.008919567472461589\n",
            "Total Loss: 0.010907019664920371\n",
            "----------------------------------------\n",
            "Epoch 78\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0107, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.588517906480082\n",
            "SCOPE mean: 0.21720774081982386, SCOPE var: 0.008902450613923234\n",
            "Total Loss: 0.010727417068147019\n",
            "----------------------------------------\n",
            "Epoch 79\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0106, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.590192437111527\n",
            "SCOPE mean: 0.2165970209296117, SCOPE var: 0.008885698465230529\n",
            "Total Loss: 0.010552381106249582\n",
            "----------------------------------------\n",
            "Epoch 80\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0104, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.592124248926813\n",
            "SCOPE mean: 0.2159396102540646, SCOPE var: 0.008870287756534619\n",
            "Total Loss: 0.010382043533328337\n",
            "----------------------------------------\n",
            "Epoch 81\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0102, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.594853075623654\n",
            "SCOPE mean: 0.21531608670162627, SCOPE var: 0.008855469292007558\n",
            "Total Loss: 0.01021514797139315\n",
            "----------------------------------------\n",
            "Epoch 82\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0101, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.59811132781552\n",
            "SCOPE mean: 0.2147216715614578, SCOPE var: 0.00884085130710875\n",
            "Total Loss: 0.010052408531952217\n",
            "----------------------------------------\n",
            "Epoch 83\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0099, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.601925526819459\n",
            "SCOPE mean: 0.21415121916090993, SCOPE var: 0.008826356967710999\n",
            "Total Loss: 0.009895449123003797\n",
            "----------------------------------------\n",
            "Epoch 84\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0097, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.605600482959899\n",
            "SCOPE mean: 0.21357391147582017, SCOPE var: 0.008811672094598851\n",
            "Total Loss: 0.009742358642764843\n",
            "----------------------------------------\n",
            "Epoch 85\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0096, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.608953622682465\n",
            "SCOPE mean: 0.21296983370169914, SCOPE var: 0.008797006507498146\n",
            "Total Loss: 0.009594137809003853\n",
            "----------------------------------------\n",
            "Epoch 86\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0095, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.610555511464712\n",
            "SCOPE mean: 0.2122615493441227, SCOPE var: 0.008781267508853143\n",
            "Total Loss: 0.00945170992400769\n",
            "----------------------------------------\n",
            "Epoch 87\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0093, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.611011834639594\n",
            "SCOPE mean: 0.21147117580225222, SCOPE var: 0.008764438214692437\n",
            "Total Loss: 0.00931188484991396\n",
            "----------------------------------------\n",
            "Epoch 88\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0092, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.611225930555147\n",
            "SCOPE mean: 0.21063876046895047, SCOPE var: 0.008746918694526854\n",
            "Total Loss: 0.009174386275629168\n",
            "----------------------------------------\n",
            "Epoch 89\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0090, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.611161608186372\n",
            "SCOPE mean: 0.2097621785295184, SCOPE var: 0.008728711473432592\n",
            "Total Loss: 0.00904006822602654\n",
            "----------------------------------------\n",
            "Epoch 90\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0089, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.61050830573089\n",
            "SCOPE mean: 0.20884153673945421, SCOPE var: 0.00871006425530759\n",
            "Total Loss: 0.008908662379960611\n",
            "----------------------------------------\n",
            "Epoch 91\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0088, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.609362626241431\n",
            "SCOPE mean: 0.20792020172688244, SCOPE var: 0.008691358537157055\n",
            "Total Loss: 0.00877957434329024\n",
            "----------------------------------------\n",
            "Epoch 92\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0087, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.607852456124553\n",
            "SCOPE mean: 0.20698297753254818, SCOPE var: 0.008672159212190991\n",
            "Total Loss: 0.008652868427270609\n",
            "----------------------------------------\n",
            "Epoch 93\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0085, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.606095736998247\n",
            "SCOPE mean: 0.20600706351254194, SCOPE var: 0.008652940537090271\n",
            "Total Loss: 0.008528801097633511\n",
            "----------------------------------------\n",
            "Epoch 94\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0084, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.604999253739239\n",
            "SCOPE mean: 0.2051029704285502, SCOPE var: 0.00863405729934757\n",
            "Total Loss: 0.008406456157225599\n",
            "----------------------------------------\n",
            "Epoch 95\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0083, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.604496055665306\n",
            "SCOPE mean: 0.2042760032744462, SCOPE var: 0.008615310048691465\n",
            "Total Loss: 0.008286474358780375\n",
            "----------------------------------------\n",
            "Epoch 96\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0082, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.604684270739376\n",
            "SCOPE mean: 0.2035663540729747, SCOPE var: 0.008596663969814124\n",
            "Total Loss: 0.008168164930429348\n",
            "----------------------------------------\n",
            "Epoch 97\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0081, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.605558903464502\n",
            "SCOPE mean: 0.2029665252422072, SCOPE var: 0.008578119327568898\n",
            "Total Loss: 0.008051946839368095\n",
            "----------------------------------------\n",
            "Epoch 98\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0079, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.607334949058702\n",
            "SCOPE mean: 0.20246024008628938, SCOPE var: 0.00855956749506595\n",
            "Total Loss: 0.007937506420393264\n",
            "----------------------------------------\n",
            "Epoch 99\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0078, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.61011666075599\n",
            "SCOPE mean: 0.2020444007011946, SCOPE var: 0.00854101618257578\n",
            "Total Loss: 0.00782409407550904\n",
            "----------------------------------------\n",
            "Epoch 100\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0077, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.613775456119205\n",
            "SCOPE mean: 0.2017034453002757, SCOPE var: 0.008522463554999719\n",
            "Total Loss: 0.00771194960877233\n",
            "----------------------------------------\n",
            "Epoch 101\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0076, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.617164386311966\n",
            "SCOPE mean: 0.2013388198350376, SCOPE var: 0.008503456494464242\n",
            "Total Loss: 0.007603146686128357\n",
            "----------------------------------------\n",
            "Epoch 102\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0075, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.620187407887379\n",
            "SCOPE mean: 0.20095794299901526, SCOPE var: 0.00848401822293047\n",
            "Total Loss: 0.007497005381906846\n",
            "----------------------------------------\n",
            "Epoch 103\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0074, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.622807167899476\n",
            "SCOPE mean: 0.2005512988215674, SCOPE var: 0.008464116447855257\n",
            "Total Loss: 0.007392162472599003\n",
            "----------------------------------------\n",
            "Epoch 104\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0073, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.625028271747896\n",
            "SCOPE mean: 0.20011156973005087, SCOPE var: 0.008443721948064895\n",
            "Total Loss: 0.007288936663896307\n",
            "----------------------------------------\n",
            "Epoch 105\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0072, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.627026478261984\n",
            "SCOPE mean: 0.1996310541828522, SCOPE var: 0.008423070044033405\n",
            "Total Loss: 0.007188341929013942\n",
            "----------------------------------------\n",
            "Epoch 106\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0071, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.630161238371441\n",
            "SCOPE mean: 0.1991928565043759, SCOPE var: 0.008402491099006327\n",
            "Total Loss: 0.007089360966584961\n",
            "----------------------------------------\n",
            "Epoch 107\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0070, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.634372067402012\n",
            "SCOPE mean: 0.19878918469842285, SCOPE var: 0.008381919988005455\n",
            "Total Loss: 0.006991701517895878\n",
            "----------------------------------------\n",
            "Epoch 108\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0069, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.639454673639564\n",
            "SCOPE mean: 0.19841817764346895, SCOPE var: 0.008361441111501758\n",
            "Total Loss: 0.0068962709757153465\n",
            "----------------------------------------\n",
            "Epoch 109\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0068, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.645107903564842\n",
            "SCOPE mean: 0.19806722170585336, SCOPE var: 0.008341215410230278\n",
            "Total Loss: 0.006801496703005179\n",
            "----------------------------------------\n",
            "Epoch 110\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0067, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.651136320308742\n",
            "SCOPE mean: 0.1977129198310412, SCOPE var: 0.008320889527442511\n",
            "Total Loss: 0.006708276992445402\n",
            "----------------------------------------\n",
            "Epoch 111\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0066, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.658001108539944\n",
            "SCOPE mean: 0.19739250483830548, SCOPE var: 0.008300574208856411\n",
            "Total Loss: 0.0066167844263476504\n",
            "----------------------------------------\n",
            "Epoch 112\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0065, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.664748334769891\n",
            "SCOPE mean: 0.19701937118105606, SCOPE var: 0.00827986636815022\n",
            "Total Loss: 0.006527180042595347\n",
            "----------------------------------------\n",
            "Epoch 113\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0064, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.671545571446952\n",
            "SCOPE mean: 0.1966012408940214, SCOPE var: 0.00825883760253291\n",
            "Total Loss: 0.006439894414750581\n",
            "----------------------------------------\n",
            "Epoch 114\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0064, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.678577600212936\n",
            "SCOPE mean: 0.19613653332217174, SCOPE var: 0.008237481156784405\n",
            "Total Loss: 0.0063546112969839075\n",
            "----------------------------------------\n",
            "Epoch 115\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0063, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.685548872403018\n",
            "SCOPE mean: 0.19559503910094286, SCOPE var: 0.008215675244481533\n",
            "Total Loss: 0.006270428538178305\n",
            "----------------------------------------\n",
            "Epoch 116\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0062, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.69251025483754\n",
            "SCOPE mean: 0.1949917391168114, SCOPE var: 0.008193493086494143\n",
            "Total Loss: 0.006187557615335493\n",
            "----------------------------------------\n",
            "Epoch 117\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0061, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.699017468330172\n",
            "SCOPE mean: 0.19432464628651713, SCOPE var: 0.00817095697168496\n",
            "Total Loss: 0.006105769720051848\n",
            "----------------------------------------\n",
            "Epoch 118\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0060, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.705207266269543\n",
            "SCOPE mean: 0.19359705663537902, SCOPE var: 0.008148099042471029\n",
            "Total Loss: 0.006025898413461401\n",
            "----------------------------------------\n",
            "Epoch 119\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0059, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.711791155620855\n",
            "SCOPE mean: 0.19289682875133513, SCOPE var: 0.008125194132003681\n",
            "Total Loss: 0.00594768244982544\n",
            "----------------------------------------\n",
            "Epoch 120\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0059, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.718819619750942\n",
            "SCOPE mean: 0.1922194912098155, SCOPE var: 0.00810224693878429\n",
            "Total Loss: 0.005870535669714849\n",
            "----------------------------------------\n",
            "Epoch 121\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0058, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.72614333152954\n",
            "SCOPE mean: 0.19156374953307967, SCOPE var: 0.008079845836241039\n",
            "Total Loss: 0.005794550251781687\n",
            "----------------------------------------\n",
            "Epoch 122\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0057, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.734107437653744\n",
            "SCOPE mean: 0.1909554325363599, SCOPE var: 0.008057600145496708\n",
            "Total Loss: 0.005719408388862546\n",
            "----------------------------------------\n",
            "Epoch 123\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0056, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.742735721896548\n",
            "SCOPE mean: 0.19039586268473677, SCOPE var: 0.008035348319542241\n",
            "Total Loss: 0.00564549061171105\n",
            "----------------------------------------\n",
            "Epoch 124\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0056, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.75204991265732\n",
            "SCOPE mean: 0.1898760972653899, SCOPE var: 0.008013198479062842\n",
            "Total Loss: 0.005572276998129195\n",
            "----------------------------------------\n",
            "Epoch 125\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0055, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.761902711381357\n",
            "SCOPE mean: 0.18938124158844777, SCOPE var: 0.00799128642354753\n",
            "Total Loss: 0.005500187152468151\n",
            "----------------------------------------\n",
            "Epoch 126\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0054, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.773042737108309\n",
            "SCOPE mean: 0.18897450624604803, SCOPE var: 0.007969363131614752\n",
            "Total Loss: 0.00543008327792476\n",
            "----------------------------------------\n",
            "Epoch 127\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0054, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.785644999010465\n",
            "SCOPE mean: 0.18866544715567377, SCOPE var: 0.00794747344840766\n",
            "Total Loss: 0.005360190018942074\n",
            "----------------------------------------\n",
            "Epoch 128\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0053, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.799747391083823\n",
            "SCOPE mean: 0.1884213593753147, SCOPE var: 0.007925368148313312\n",
            "Total Loss: 0.005290342010640468\n",
            "----------------------------------------\n",
            "Epoch 129\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0052, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.815085605972326\n",
            "SCOPE mean: 0.18822049486799525, SCOPE var: 0.007903037118217658\n",
            "Total Loss: 0.005221253118418741\n",
            "----------------------------------------\n",
            "Epoch 130\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0052, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.831126762416943\n",
            "SCOPE mean: 0.18805519202087298, SCOPE var: 0.007880387838857153\n",
            "Total Loss: 0.00515250466179367\n",
            "----------------------------------------\n",
            "Epoch 131\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0051, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.847738110886997\n",
            "SCOPE mean: 0.18791000598996407, SCOPE var: 0.007857433520852478\n",
            "Total Loss: 0.005084202553913028\n",
            "----------------------------------------\n",
            "Epoch 132\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0050, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.864774634657643\n",
            "SCOPE mean: 0.18777338788330514, SCOPE var: 0.007834197752961717\n",
            "Total Loss: 0.00501659907996233\n",
            "----------------------------------------\n",
            "Epoch 133\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0050, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.882328563812601\n",
            "SCOPE mean: 0.1876304449371988, SCOPE var: 0.007810822249319704\n",
            "Total Loss: 0.004950036570678036\n",
            "----------------------------------------\n",
            "Epoch 134\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0049, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.899978623774915\n",
            "SCOPE mean: 0.1874643820063664, SCOPE var: 0.007787319296587405\n",
            "Total Loss: 0.004884461319108294\n",
            "----------------------------------------\n",
            "Epoch 135\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0048, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.917630513520185\n",
            "SCOPE mean: 0.18726881473179732, SCOPE var: 0.007763688161081046\n",
            "Total Loss: 0.004819603216211625\n",
            "----------------------------------------\n",
            "Epoch 136\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0048, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.93508856136609\n",
            "SCOPE mean: 0.18704018613490594, SCOPE var: 0.007739958555614836\n",
            "Total Loss: 0.004756319780816671\n",
            "----------------------------------------\n",
            "Epoch 137\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0047, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.952342697673123\n",
            "SCOPE mean: 0.18677907941554026, SCOPE var: 0.0077161536889560805\n",
            "Total Loss: 0.004695607326683482\n",
            "----------------------------------------\n",
            "Epoch 138\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.967387308228279\n",
            "SCOPE mean: 0.18635603249784793, SCOPE var: 0.0076922485464766596\n",
            "Total Loss: 0.004635617250989672\n",
            "----------------------------------------\n",
            "Epoch 139\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.980774172479308\n",
            "SCOPE mean: 0.18582827915117836, SCOPE var: 0.007668273193265053\n",
            "Total Loss: 0.004575667633922925\n",
            "----------------------------------------\n",
            "Epoch 140\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0045, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.992622900854748\n",
            "SCOPE mean: 0.1852038830625964, SCOPE var: 0.007644246358760497\n",
            "Total Loss: 0.00451560551944316\n",
            "----------------------------------------\n",
            "Epoch 141\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0045, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.00300194401525\n",
            "SCOPE mean: 0.1844747259630057, SCOPE var: 0.007620161589410081\n",
            "Total Loss: 0.00445636413265788\n",
            "----------------------------------------\n",
            "Epoch 142\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0044, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.013059370881003\n",
            "SCOPE mean: 0.18371226742801844, SCOPE var: 0.007596017674966484\n",
            "Total Loss: 0.004398402766611401\n",
            "----------------------------------------\n",
            "Epoch 143\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0043, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.023293245462567\n",
            "SCOPE mean: 0.18295093364369241, SCOPE var: 0.0075718081006406765\n",
            "Total Loss: 0.004340962705790546\n",
            "----------------------------------------\n",
            "Epoch 144\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0043, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.033751430571275\n",
            "SCOPE mean: 0.18219406422979906, SCOPE var: 0.007547543615716293\n",
            "Total Loss: 0.0042843451468130645\n",
            "----------------------------------------\n",
            "Epoch 145\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0042, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.044306447156279\n",
            "SCOPE mean: 0.18144064733360923, SCOPE var: 0.007523248187384036\n",
            "Total Loss: 0.004229047427431529\n",
            "----------------------------------------\n",
            "Epoch 146\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0042, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.05565063033362\n",
            "SCOPE mean: 0.18071791824002903, SCOPE var: 0.007498977466521634\n",
            "Total Loss: 0.004175105562622651\n",
            "----------------------------------------\n",
            "Epoch 147\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0041, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.068147926558355\n",
            "SCOPE mean: 0.1800639537332242, SCOPE var: 0.007474696720230002\n",
            "Total Loss: 0.004122148105497191\n",
            "----------------------------------------\n",
            "Epoch 148\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0041, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.08163436288252\n",
            "SCOPE mean: 0.1794750118709674, SCOPE var: 0.007450456622103446\n",
            "Total Loss: 0.004069897013641013\n",
            "----------------------------------------\n",
            "Epoch 149\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0040, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.095883132034805\n",
            "SCOPE mean: 0.17893890132519868, SCOPE var: 0.007426261431408634\n",
            "Total Loss: 0.004018952284425737\n",
            "----------------------------------------\n",
            "Epoch 150\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0040, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.109989783607704\n",
            "SCOPE mean: 0.17838007523426042, SCOPE var: 0.007402105418097985\n",
            "Total Loss: 0.0039692292402796195\n",
            "----------------------------------------\n",
            "Epoch 151\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0039, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.124101572263639\n",
            "SCOPE mean: 0.17779724810060324, SCOPE var: 0.007377968991891271\n",
            "Total Loss: 0.0039203081441681\n",
            "----------------------------------------\n",
            "Epoch 152\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0039, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.138833677356896\n",
            "SCOPE mean: 0.17725456335549447, SCOPE var: 0.007353875198508728\n",
            "Total Loss: 0.003872719064570335\n",
            "----------------------------------------\n",
            "Epoch 153\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0038, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.154449940230162\n",
            "SCOPE mean: 0.17677754060529333, SCOPE var: 0.00732987445971756\n",
            "Total Loss: 0.0038276169045959193\n",
            "----------------------------------------\n",
            "Epoch 154\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0038, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.170178583346857\n",
            "SCOPE mean: 0.1763448943008378, SCOPE var: 0.007306197563803185\n",
            "Total Loss: 0.0037834834348143683\n",
            "----------------------------------------\n",
            "Epoch 155\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0037, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.186168424200591\n",
            "SCOPE mean: 0.17593243605654443, SCOPE var: 0.007282871641980917\n",
            "Total Loss: 0.003737776821047462\n",
            "----------------------------------------\n",
            "Epoch 156\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0037, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.203046838615682\n",
            "SCOPE mean: 0.17556373101061976, SCOPE var: 0.007259915131062783\n",
            "Total Loss: 0.0036920039668299357\n",
            "----------------------------------------\n",
            "Epoch 157\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.220777271353995\n",
            "SCOPE mean: 0.17524784019447284, SCOPE var: 0.007236946766559267\n",
            "Total Loss: 0.0036464268923701846\n",
            "----------------------------------------\n",
            "Epoch 158\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.239574773583552\n",
            "SCOPE mean: 0.1749911053537505, SCOPE var: 0.007214085908778222\n",
            "Total Loss: 0.0036015697941398825\n",
            "----------------------------------------\n",
            "Epoch 159\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.260234254637105\n",
            "SCOPE mean: 0.17486310824946327, SCOPE var: 0.007191576625212042\n",
            "Total Loss: 0.0035578196662246035\n",
            "----------------------------------------\n",
            "Epoch 160\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0035, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.28118814877673\n",
            "SCOPE mean: 0.17476374715040532, SCOPE var: 0.007169354263622978\n",
            "Total Loss: 0.0035147198039730417\n",
            "----------------------------------------\n",
            "Epoch 161\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0035, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.302425176466624\n",
            "SCOPE mean: 0.17469002425102872, SCOPE var: 0.0071474034337256605\n",
            "Total Loss: 0.0034727885359789558\n",
            "----------------------------------------\n",
            "Epoch 162\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0034, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.323978239267566\n",
            "SCOPE mean: 0.1746362246271555, SCOPE var: 0.007125694651945167\n",
            "Total Loss: 0.0034315163448254225\n",
            "----------------------------------------\n",
            "Epoch 163\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0034, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.346067776016422\n",
            "SCOPE mean: 0.17461636948986767, SCOPE var: 0.007104270749054254\n",
            "Total Loss: 0.0033909037822720815\n",
            "----------------------------------------\n",
            "Epoch 164\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0034, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.368708234558635\n",
            "SCOPE mean: 0.1746273446383494, SCOPE var: 0.007083143176322335\n",
            "Total Loss: 0.0033508351433033105\n",
            "----------------------------------------\n",
            "Epoch 165\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0033, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.392078463838404\n",
            "SCOPE mean: 0.1746797278229171, SCOPE var: 0.007062334147516268\n",
            "Total Loss: 0.003311112609308278\n",
            "----------------------------------------\n",
            "Epoch 166\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0033, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.41612776376201\n",
            "SCOPE mean: 0.17473644250870712, SCOPE var: 0.007042145246979258\n",
            "Total Loss: 0.003272056913025125\n",
            "----------------------------------------\n",
            "Epoch 167\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0032, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.440572661748167\n",
            "SCOPE mean: 0.17480292389117374, SCOPE var: 0.007022213364901638\n",
            "Total Loss: 0.0032336620549912763\n",
            "----------------------------------------\n",
            "Epoch 168\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0032, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.465290718863669\n",
            "SCOPE mean: 0.17487121142750192, SCOPE var: 0.007003315664198898\n",
            "Total Loss: 0.0031959842202999664\n",
            "----------------------------------------\n",
            "Epoch 169\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0032, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.489937642847343\n",
            "SCOPE mean: 0.17489301993334552, SCOPE var: 0.006984695182966027\n",
            "Total Loss: 0.0031587019427174374\n",
            "----------------------------------------\n",
            "Epoch 170\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0031, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.51457617773594\n",
            "SCOPE mean: 0.17487141696851977, SCOPE var: 0.006966145713643218\n",
            "Total Loss: 0.003122073921657423\n",
            "----------------------------------------\n",
            "Epoch 171\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0031, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.539010754998888\n",
            "SCOPE mean: 0.17478743606876784, SCOPE var: 0.00694807386920762\n",
            "Total Loss: 0.003086002322562124\n",
            "----------------------------------------\n",
            "Epoch 172\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0031, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.563345042935158\n",
            "SCOPE mean: 0.17466972264939423, SCOPE var: 0.006930088345600679\n",
            "Total Loss: 0.003050517409976937\n",
            "----------------------------------------\n",
            "Epoch 173\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0030, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.587955035371289\n",
            "SCOPE mean: 0.17451621181370458, SCOPE var: 0.0069123654801216475\n",
            "Total Loss: 0.0030146279557552625\n",
            "----------------------------------------\n",
            "Epoch 174\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0030, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.612550840207945\n",
            "SCOPE mean: 0.17433199775570646, SCOPE var: 0.006894806412293105\n",
            "Total Loss: 0.0029791100377287026\n",
            "----------------------------------------\n",
            "Epoch 175\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0029, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.63715653559049\n",
            "SCOPE mean: 0.17411612978733318, SCOPE var: 0.006877481504765149\n",
            "Total Loss: 0.0029442902809965164\n",
            "----------------------------------------\n",
            "Epoch 176\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0029, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.662779042754856\n",
            "SCOPE mean: 0.17394122106225102, SCOPE var: 0.006860604549030317\n",
            "Total Loss: 0.0029098842406407362\n",
            "----------------------------------------\n",
            "Epoch 177\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0029, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.68949161932876\n",
            "SCOPE mean: 0.17382334100589328, SCOPE var: 0.006844142588793992\n",
            "Total Loss: 0.0028757208161035875\n",
            "----------------------------------------\n",
            "Epoch 178\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0028, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.71609016153147\n",
            "SCOPE mean: 0.173697481802497, SCOPE var: 0.006827834717658722\n",
            "Total Loss: 0.002842055768273324\n",
            "----------------------------------------\n",
            "Epoch 179\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0028, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.742411294046478\n",
            "SCOPE mean: 0.17354757491236228, SCOPE var: 0.006811634260147292\n",
            "Total Loss: 0.002808925093569825\n",
            "----------------------------------------\n",
            "Epoch 180\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0028, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.768883579523122\n",
            "SCOPE mean: 0.17341499919701459, SCOPE var: 0.006795705285250943\n",
            "Total Loss: 0.0027764247206662576\n",
            "----------------------------------------\n",
            "Epoch 181\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0027, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.795495561135688\n",
            "SCOPE mean: 0.1732984529727772, SCOPE var: 0.006780032421768931\n",
            "Total Loss: 0.0027441359731284146\n",
            "----------------------------------------\n",
            "Epoch 182\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0027, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.82193766994002\n",
            "SCOPE mean: 0.17318925149496922, SCOPE var: 0.006764497337211857\n",
            "Total Loss: 0.0027120101498605076\n",
            "----------------------------------------\n",
            "Epoch 183\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0027, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.846971483608298\n",
            "SCOPE mean: 0.1730062140513262, SCOPE var: 0.006748888720035212\n",
            "Total Loss: 0.00268010353273063\n",
            "----------------------------------------\n",
            "Epoch 184\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0026, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.871695354002616\n",
            "SCOPE mean: 0.17281894278217588, SCOPE var: 0.006733424898362158\n",
            "Total Loss: 0.0026488152028078097\n",
            "----------------------------------------\n",
            "Epoch 185\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0026, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.89622405234869\n",
            "SCOPE mean: 0.1726217318962947, SCOPE var: 0.006718071126627498\n",
            "Total Loss: 0.002617954964893361\n",
            "----------------------------------------\n",
            "Epoch 186\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0026, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.921915827073958\n",
            "SCOPE mean: 0.17249061976266838, SCOPE var: 0.006703064136234747\n",
            "Total Loss: 0.00258767807547823\n",
            "----------------------------------------\n",
            "Epoch 187\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0026, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.946874576284328\n",
            "SCOPE mean: 0.17230563341585003, SCOPE var: 0.006687813509114092\n",
            "Total Loss: 0.0025582689740119274\n",
            "----------------------------------------\n",
            "Epoch 188\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0025, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.970901493676024\n",
            "SCOPE mean: 0.17208167857292977, SCOPE var: 0.006672499759387733\n",
            "Total Loss: 0.0025289695338065374\n",
            "----------------------------------------\n",
            "Epoch 189\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0025, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.99563040943902\n",
            "SCOPE mean: 0.17189135217387297, SCOPE var: 0.006657341704802302\n",
            "Total Loss: 0.0024997900692670084\n",
            "----------------------------------------\n",
            "Epoch 190\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0025, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.018731448879091\n",
            "SCOPE mean: 0.1716015205257258, SCOPE var: 0.006641962541637838\n",
            "Total Loss: 0.0024709910629596267\n",
            "----------------------------------------\n",
            "Epoch 191\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0024, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.04029897029167\n",
            "SCOPE mean: 0.1712220909949247, SCOPE var: 0.00662641726791224\n",
            "Total Loss: 0.002442347984979291\n",
            "----------------------------------------\n",
            "Epoch 192\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0024, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.06068036018126\n",
            "SCOPE mean: 0.1707734106204769, SCOPE var: 0.006610784395656392\n",
            "Total Loss: 0.0024139796212540826\n",
            "----------------------------------------\n",
            "Epoch 193\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0024, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.081533399328176\n",
            "SCOPE mean: 0.17034985077283749, SCOPE var: 0.006595410412992802\n",
            "Total Loss: 0.0023853902693945087\n",
            "----------------------------------------\n",
            "Epoch 194\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0024, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.10310232599892\n",
            "SCOPE mean: 0.16994342649377187, SCOPE var: 0.006580236113077357\n",
            "Total Loss: 0.0023569060451901374\n",
            "----------------------------------------\n",
            "Epoch 195\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0023, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.123463622527698\n",
            "SCOPE mean: 0.16943262947072268, SCOPE var: 0.006564777939135193\n",
            "Total Loss: 0.0023288638352640576\n",
            "----------------------------------------\n",
            "Epoch 196\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0023, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.14251642075821\n",
            "SCOPE mean: 0.16882648545050152, SCOPE var: 0.006549091725529727\n",
            "Total Loss: 0.002300289239678548\n",
            "----------------------------------------\n",
            "Epoch 197\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0023, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.159691380596728\n",
            "SCOPE mean: 0.16810249045116876, SCOPE var: 0.006533133391955125\n",
            "Total Loss: 0.002270684476608852\n",
            "----------------------------------------\n",
            "Epoch 198\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0022, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.175028996277279\n",
            "SCOPE mean: 0.16727511139332374, SCOPE var: 0.006516953586870816\n",
            "Total Loss: 0.0022415264620708492\n",
            "----------------------------------------\n",
            "Epoch 199\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0022, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.189102901521487\n",
            "SCOPE mean: 0.16639943469158472, SCOPE var: 0.006500741937439684\n",
            "Total Loss: 0.002213046757059566\n",
            "----------------------------------------\n",
            "Epoch 200\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0022, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.204340976077928\n",
            "SCOPE mean: 0.16562579527610088, SCOPE var: 0.006485166926571622\n",
            "Total Loss: 0.0021842301657493427\n",
            "----------------------------------------\n",
            "Epoch 201\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0022, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.220258983073581\n",
            "SCOPE mean: 0.16492566454528068, SCOPE var: 0.006470099314176604\n",
            "Total Loss: 0.0021556772177889895\n",
            "----------------------------------------\n",
            "Epoch 202\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0021, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.235257104867234\n",
            "SCOPE mean: 0.1642058908511062, SCOPE var: 0.006455081248573755\n",
            "Total Loss: 0.002127711541401157\n",
            "----------------------------------------\n",
            "Epoch 203\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0021, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.249594853811718\n",
            "SCOPE mean: 0.16345594491856041, SCOPE var: 0.0064400373404410105\n",
            "Total Loss: 0.002100017353835473\n",
            "----------------------------------------\n",
            "Epoch 204\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0021, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.263091075855082\n",
            "SCOPE mean: 0.16267988891051904, SCOPE var: 0.00642499547540371\n",
            "Total Loss: 0.002072558548455422\n",
            "----------------------------------------\n",
            "Epoch 205\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0020, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.275881262458057\n",
            "SCOPE mean: 0.16182738197395768, SCOPE var: 0.00641009657740397\n",
            "Total Loss: 0.0020448667540527766\n",
            "----------------------------------------\n",
            "Epoch 206\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0020, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.287398044292212\n",
            "SCOPE mean: 0.16089304363295875, SCOPE var: 0.006394978167000495\n",
            "Total Loss: 0.0020173478502963295\n",
            "----------------------------------------\n",
            "Epoch 207\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0020, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.298236805892907\n",
            "SCOPE mean: 0.15989122029009153, SCOPE var: 0.006379689605688173\n",
            "Total Loss: 0.001990408675649901\n",
            "----------------------------------------\n",
            "Epoch 208\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0020, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.30821141936478\n",
            "SCOPE mean: 0.1588098861648088, SCOPE var: 0.006364780288328501\n",
            "Total Loss: 0.0019634403084403448\n",
            "----------------------------------------\n",
            "Epoch 209\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0019, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.318539783897958\n",
            "SCOPE mean: 0.15774480276576588, SCOPE var: 0.006350056710828044\n",
            "Total Loss: 0.0019369151916385466\n",
            "----------------------------------------\n",
            "Epoch 210\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0019, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.329660076423478\n",
            "SCOPE mean: 0.15673273409905716, SCOPE var: 0.006335756761509518\n",
            "Total Loss: 0.0019102368126059169\n",
            "----------------------------------------\n",
            "Epoch 211\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0019, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.339398478922842\n",
            "SCOPE mean: 0.15562550019124333, SCOPE var: 0.006321237605399199\n",
            "Total Loss: 0.001883971014701727\n",
            "----------------------------------------\n",
            "Epoch 212\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0019, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.347834404921855\n",
            "SCOPE mean: 0.15443387511912857, SCOPE var: 0.00630923728092078\n",
            "Total Loss: 0.001859249983982686\n",
            "----------------------------------------\n",
            "Epoch 213\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0018, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.355284073596021\n",
            "SCOPE mean: 0.15318579521720918, SCOPE var: 0.006297301343087826\n",
            "Total Loss: 0.0018355098576021325\n",
            "----------------------------------------\n",
            "Epoch 214\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0018, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.362861428971774\n",
            "SCOPE mean: 0.1519896345753913, SCOPE var: 0.006285243482304446\n",
            "Total Loss: 0.0018126956751291898\n",
            "----------------------------------------\n",
            "Epoch 215\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0018, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.370746160366675\n",
            "SCOPE mean: 0.15082367996579485, SCOPE var: 0.006273257729177161\n",
            "Total Loss: 0.0017897278221196777\n",
            "----------------------------------------\n",
            "Epoch 216\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0018, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.377331386082192\n",
            "SCOPE mean: 0.14957754775664586, SCOPE var: 0.006261183244284224\n",
            "Total Loss: 0.00176708866676872\n",
            "----------------------------------------\n",
            "Epoch 217\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0017, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.383233728998187\n",
            "SCOPE mean: 0.14826277003781424, SCOPE var: 0.0062494537196394855\n",
            "Total Loss: 0.0017449665554389608\n",
            "----------------------------------------\n",
            "Epoch 218\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0017, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.38966822562293\n",
            "SCOPE mean: 0.14696205289395697, SCOPE var: 0.006238192534975683\n",
            "Total Loss: 0.0017233279055852738\n",
            "----------------------------------------\n",
            "Epoch 219\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0017, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.39654039368421\n",
            "SCOPE mean: 0.14565710475039337, SCOPE var: 0.00622759556707928\n",
            "Total Loss: 0.0017025730486867386\n",
            "----------------------------------------\n",
            "Epoch 220\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0017, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.402603385375427\n",
            "SCOPE mean: 0.14429731540100393, SCOPE var: 0.0062168196244795524\n",
            "Total Loss: 0.0016823481272491168\n",
            "----------------------------------------\n",
            "Epoch 221\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0017, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.407818210903553\n",
            "SCOPE mean: 0.1428747715643682, SCOPE var: 0.006205902676337056\n",
            "Total Loss: 0.0016626886246378899\n",
            "----------------------------------------\n",
            "Epoch 222\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0016, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.412725280467487\n",
            "SCOPE mean: 0.14145639051248685, SCOPE var: 0.006195270146661488\n",
            "Total Loss: 0.0016437330979820971\n",
            "----------------------------------------\n",
            "Epoch 223\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0016, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.417409752146815\n",
            "SCOPE mean: 0.14004871570031419, SCOPE var: 0.006184871005703111\n",
            "Total Loss: 0.0016256987684673714\n",
            "----------------------------------------\n",
            "Epoch 224\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0016, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.423358077369652\n",
            "SCOPE mean: 0.1387664586933233, SCOPE var: 0.006174718503057279\n",
            "Total Loss: 0.00160800944232064\n",
            "----------------------------------------\n",
            "Epoch 225\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0016, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.430269030697422\n",
            "SCOPE mean: 0.13757110693481459, SCOPE var: 0.006164934787037438\n",
            "Total Loss: 0.0015901685096285606\n",
            "----------------------------------------\n",
            "Epoch 226\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0016, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.436779418625132\n",
            "SCOPE mean: 0.1364014073615645, SCOPE var: 0.006154860714627433\n",
            "Total Loss: 0.0015727421282033058\n",
            "----------------------------------------\n",
            "Epoch 227\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0016, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.442908301722538\n",
            "SCOPE mean: 0.1352452926191333, SCOPE var: 0.006144586338999372\n",
            "Total Loss: 0.0015556375278324263\n",
            "----------------------------------------\n",
            "Epoch 228\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0015, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.448586741135832\n",
            "SCOPE mean: 0.13407826021393499, SCOPE var: 0.006134301974319065\n",
            "Total Loss: 0.0015386394719274956\n",
            "----------------------------------------\n",
            "Epoch 229\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0015, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.454195179523548\n",
            "SCOPE mean: 0.13319343257261626, SCOPE var: 0.006123996983052371\n",
            "Total Loss: 0.0015219291018183144\n",
            "----------------------------------------\n",
            "Epoch 230\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0015, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.45966077023894\n",
            "SCOPE mean: 0.13273998064274642, SCOPE var: 0.006113705667236108\n",
            "Total Loss: 0.001505501776753559\n",
            "----------------------------------------\n",
            "Epoch 231\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0015, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.46522386442635\n",
            "SCOPE mean: 0.13227897128846122, SCOPE var: 0.006103371308690606\n",
            "Total Loss: 0.0014897765478308973\n",
            "----------------------------------------\n",
            "Epoch 232\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0015, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.472077510196007\n",
            "SCOPE mean: 0.13190274258544776, SCOPE var: 0.006093052441398857\n",
            "Total Loss: 0.001474097202468687\n",
            "----------------------------------------\n",
            "Epoch 233\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0015, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.480124490364732\n",
            "SCOPE mean: 0.13160671203081725, SCOPE var: 0.0060827383113096585\n",
            "Total Loss: 0.0014585579148647264\n",
            "----------------------------------------\n",
            "Epoch 234\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0014, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.488219000442136\n",
            "SCOPE mean: 0.1312954372000312, SCOPE var: 0.006072337743462041\n",
            "Total Loss: 0.0014435806202006904\n",
            "----------------------------------------\n",
            "Epoch 235\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0014, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.496119952628343\n",
            "SCOPE mean: 0.13097032834055589, SCOPE var: 0.006061859672195828\n",
            "Total Loss: 0.0014289457289991968\n",
            "----------------------------------------\n",
            "Epoch 236\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0014, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.503860675070461\n",
            "SCOPE mean: 0.13063745875218083, SCOPE var: 0.006051384430181669\n",
            "Total Loss: 0.0014145486467277732\n",
            "----------------------------------------\n",
            "Epoch 237\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0014, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.510707979821683\n",
            "SCOPE mean: 0.13021853473330366, SCOPE var: 0.006041051058710124\n",
            "Total Loss: 0.0014002022192143593\n",
            "----------------------------------------\n",
            "Epoch 238\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0014, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.516718773694189\n",
            "SCOPE mean: 0.12972359249798002, SCOPE var: 0.006030766447055324\n",
            "Total Loss: 0.0013860599795177122\n",
            "----------------------------------------\n",
            "Epoch 239\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0014, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.521918322263927\n",
            "SCOPE mean: 0.12915023149139981, SCOPE var: 0.006020467668668808\n",
            "Total Loss: 0.001372292833415458\n",
            "----------------------------------------\n",
            "Epoch 240\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0014, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.527449766514925\n",
            "SCOPE mean: 0.1285986012111203, SCOPE var: 0.006010306357806764\n",
            "Total Loss: 0.0013585899484506777\n",
            "----------------------------------------\n",
            "Epoch 241\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.533402785311013\n",
            "SCOPE mean: 0.12806811569748947, SCOPE var: 0.006000098429010236\n",
            "Total Loss: 0.0013450482389277321\n",
            "----------------------------------------\n",
            "Epoch 242\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.53962796028336\n",
            "SCOPE mean: 0.1275684891255657, SCOPE var: 0.005989845272872764\n",
            "Total Loss: 0.0013317482089235358\n",
            "----------------------------------------\n",
            "Epoch 243\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.545268977302651\n",
            "SCOPE mean: 0.12704561094822892, SCOPE var: 0.005979654249445675\n",
            "Total Loss: 0.001318341805644814\n",
            "----------------------------------------\n",
            "Epoch 244\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.550545507411133\n",
            "SCOPE mean: 0.12650457017510303, SCOPE var: 0.005969545876664341\n",
            "Total Loss: 0.001305478249031124\n",
            "----------------------------------------\n",
            "Epoch 245\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.55545464781128\n",
            "SCOPE mean: 0.1259632427850217, SCOPE var: 0.005959446970502761\n",
            "Total Loss: 0.0012928435510722559\n",
            "----------------------------------------\n",
            "Epoch 246\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.560096166919996\n",
            "SCOPE mean: 0.12540698624823252, SCOPE var: 0.005949726956696045\n",
            "Total Loss: 0.0012803231772049442\n",
            "----------------------------------------\n",
            "Epoch 247\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.564391206728704\n",
            "SCOPE mean: 0.12484278852803941, SCOPE var: 0.005940141704742701\n",
            "Total Loss: 0.00126801387504205\n",
            "----------------------------------------\n",
            "Epoch 248\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.568495604027438\n",
            "SCOPE mean: 0.1242778261556635, SCOPE var: 0.005930630580110133\n",
            "Total Loss: 0.0012559450728758298\n",
            "----------------------------------------\n",
            "Epoch 249\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.572569009649392\n",
            "SCOPE mean: 0.12369120336399228, SCOPE var: 0.005920907853718855\n",
            "Total Loss: 0.0012441948815982394\n",
            "----------------------------------------\n",
            "Epoch 250\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.57687662632244\n",
            "SCOPE mean: 0.12312546965968922, SCOPE var: 0.005911290173531033\n",
            "Total Loss: 0.001232755608285169\n",
            "----------------------------------------\n",
            "Epoch 251\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.581579531932324\n",
            "SCOPE mean: 0.12259945518569655, SCOPE var: 0.00590176906271605\n",
            "Total Loss: 0.00122156266260274\n",
            "----------------------------------------\n",
            "Epoch 252\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.586701122659797\n",
            "SCOPE mean: 0.12212092735378965, SCOPE var: 0.0058922984450615265\n",
            "Total Loss: 0.001210598013055418\n",
            "----------------------------------------\n",
            "Epoch 253\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.592239218537262\n",
            "SCOPE mean: 0.12169562320468996, SCOPE var: 0.0058827604049445335\n",
            "Total Loss: 0.0011998451082018554\n",
            "----------------------------------------\n",
            "Epoch 254\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.598312429187779\n",
            "SCOPE mean: 0.12133213902178666, SCOPE var: 0.005873202198911556\n",
            "Total Loss: 0.0011893842679567995\n",
            "----------------------------------------\n",
            "Epoch 255\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.604924423803759\n",
            "SCOPE mean: 0.12101010187555424, SCOPE var: 0.005863686989267711\n",
            "Total Loss: 0.0011791095460580814\n",
            "----------------------------------------\n",
            "Epoch 256\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.612051012919412\n",
            "SCOPE mean: 0.12072340054485446, SCOPE var: 0.005854276788261213\n",
            "Total Loss: 0.001168881862900742\n",
            "----------------------------------------\n",
            "Epoch 257\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.619549880858903\n",
            "SCOPE mean: 0.12046844079969492, SCOPE var: 0.005844969845916885\n",
            "Total Loss: 0.0011588653333222912\n",
            "----------------------------------------\n",
            "Epoch 258\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.627596701192216\n",
            "SCOPE mean: 0.12024494964984488, SCOPE var: 0.005835737812773618\n",
            "Total Loss: 0.001148846926855207\n",
            "----------------------------------------\n",
            "Epoch 259\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.636106665483814\n",
            "SCOPE mean: 0.12005146349751346, SCOPE var: 0.005826591439939441\n",
            "Total Loss: 0.0011389593852801098\n",
            "----------------------------------------\n",
            "Epoch 260\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.644979451879863\n",
            "SCOPE mean: 0.119883362407195, SCOPE var: 0.00581753096567414\n",
            "Total Loss: 0.0011292346299233693\n",
            "----------------------------------------\n",
            "Epoch 261\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.654135169994662\n",
            "SCOPE mean: 0.11973999962027423, SCOPE var: 0.005808554797880105\n",
            "Total Loss: 0.0011195717359441504\n",
            "----------------------------------------\n",
            "Epoch 262\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.663371260048859\n",
            "SCOPE mean: 0.11962107407632032, SCOPE var: 0.0057996907280352525\n",
            "Total Loss: 0.0011100020625745472\n",
            "----------------------------------------\n",
            "Epoch 263\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.67258175890846\n",
            "SCOPE mean: 0.11952154203724176, SCOPE var: 0.0057909341906513855\n",
            "Total Loss: 0.001100448523425733\n",
            "----------------------------------------\n",
            "Epoch 264\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.681766934613588\n",
            "SCOPE mean: 0.11943159072700449, SCOPE var: 0.005782285483863238\n",
            "Total Loss: 0.001091036037682214\n",
            "----------------------------------------\n",
            "Epoch 265\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.690920319393038\n",
            "SCOPE mean: 0.1193423957924349, SCOPE var: 0.0057737281833666445\n",
            "Total Loss: 0.0010817701781981703\n",
            "----------------------------------------\n",
            "Epoch 266\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.699997393067806\n",
            "SCOPE mean: 0.11925127757349996, SCOPE var: 0.00576525520834804\n",
            "Total Loss: 0.001072636363035577\n",
            "----------------------------------------\n",
            "Epoch 267\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.708932672170816\n",
            "SCOPE mean: 0.11915338608738565, SCOPE var: 0.005756866745638196\n",
            "Total Loss: 0.0010636646470437675\n",
            "----------------------------------------\n",
            "Epoch 268\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.717695901352766\n",
            "SCOPE mean: 0.11904524927355603, SCOPE var: 0.005748552275478274\n",
            "Total Loss: 0.0010548755784467768\n",
            "----------------------------------------\n",
            "Epoch 269\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.726273391450718\n",
            "SCOPE mean: 0.11892528128601788, SCOPE var: 0.005740307933922262\n",
            "Total Loss: 0.0010462349623617682\n",
            "----------------------------------------\n",
            "Epoch 270\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.734654223412576\n",
            "SCOPE mean: 0.11879413474942899, SCOPE var: 0.005732129942732793\n",
            "Total Loss: 0.0010377440701919078\n",
            "----------------------------------------\n",
            "Epoch 271\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.742882369185509\n",
            "SCOPE mean: 0.11865361435035272, SCOPE var: 0.005723996965210326\n",
            "Total Loss: 0.001029170047884581\n",
            "----------------------------------------\n",
            "Epoch 272\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.749710117517262\n",
            "SCOPE mean: 0.11835350838158604, SCOPE var: 0.005716038224508549\n",
            "Total Loss: 0.0010205690015518403\n",
            "----------------------------------------\n",
            "Epoch 273\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.75535140931823\n",
            "SCOPE mean: 0.1179134295365907, SCOPE var: 0.005708245077988565\n",
            "Total Loss: 0.0010119487946098273\n",
            "----------------------------------------\n",
            "Epoch 274\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.760208393790185\n",
            "SCOPE mean: 0.11736066693171533, SCOPE var: 0.005700600520654274\n",
            "Total Loss: 0.0010032262586757042\n",
            "----------------------------------------\n",
            "Epoch 275\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.764226993181701\n",
            "SCOPE mean: 0.11671933023525276, SCOPE var: 0.005692868869515772\n",
            "Total Loss: 0.000994000642583192\n",
            "----------------------------------------\n",
            "Epoch 276\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.767588717522777\n",
            "SCOPE mean: 0.11599754509185273, SCOPE var: 0.005685248454784559\n",
            "Total Loss: 0.000984785452456596\n",
            "----------------------------------------\n",
            "Epoch 277\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.771151387191434\n",
            "SCOPE mean: 0.11529343276645132, SCOPE var: 0.005677430265303437\n",
            "Total Loss: 0.0009756708954040168\n",
            "----------------------------------------\n",
            "Epoch 278\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.77495419467828\n",
            "SCOPE mean: 0.11460237480448875, SCOPE var: 0.005669644514431792\n",
            "Total Loss: 0.0009666869854112063\n",
            "----------------------------------------\n",
            "Epoch 279\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.779384010921957\n",
            "SCOPE mean: 0.11395070104973465, SCOPE var: 0.005661906093180765\n",
            "Total Loss: 0.0009582400837563538\n",
            "----------------------------------------\n",
            "Epoch 280\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.784274444361012\n",
            "SCOPE mean: 0.11334429106174405, SCOPE var: 0.005654211830916634\n",
            "Total Loss: 0.000949925044449496\n",
            "----------------------------------------\n",
            "Epoch 281\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.789816990401187\n",
            "SCOPE mean: 0.11275954674075805, SCOPE var: 0.005646564123901563\n",
            "Total Loss: 0.000941768747908657\n",
            "----------------------------------------\n",
            "Epoch 282\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.79564041717421\n",
            "SCOPE mean: 0.11250276395386363, SCOPE var: 0.005638997388195483\n",
            "Total Loss: 0.0009338805754769778\n",
            "----------------------------------------\n",
            "Epoch 283\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.801733897674035\n",
            "SCOPE mean: 0.11263939534050192, SCOPE var: 0.005631542070773583\n",
            "Total Loss: 0.0009261190085268491\n",
            "----------------------------------------\n",
            "Epoch 284\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.808159090420311\n",
            "SCOPE mean: 0.11278047051469448, SCOPE var: 0.005624129502262132\n",
            "Total Loss: 0.0009184302776200403\n",
            "----------------------------------------\n",
            "Epoch 285\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.814739089187174\n",
            "SCOPE mean: 0.11292471771474485, SCOPE var: 0.005616750542137036\n",
            "Total Loss: 0.0009108377175726122\n",
            "----------------------------------------\n",
            "Epoch 286\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.821501420435842\n",
            "SCOPE mean: 0.11307063634659899, SCOPE var: 0.005609402090879702\n",
            "Total Loss: 0.0009033515874765868\n",
            "----------------------------------------\n",
            "Epoch 287\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.828424444819708\n",
            "SCOPE mean: 0.11321763583806364, SCOPE var: 0.005602081661551742\n",
            "Total Loss: 0.0008959718608653882\n",
            "----------------------------------------\n",
            "Epoch 288\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.835529353004222\n",
            "SCOPE mean: 0.11336593880978411, SCOPE var: 0.005594776869761362\n",
            "Total Loss: 0.0008885364106330374\n",
            "----------------------------------------\n",
            "Epoch 289\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.842467806359615\n",
            "SCOPE mean: 0.11351877106206343, SCOPE var: 0.00558752905598119\n",
            "Total Loss: 0.0008811402760920676\n",
            "----------------------------------------\n",
            "Epoch 290\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.84910326364715\n",
            "SCOPE mean: 0.11367278930856985, SCOPE var: 0.005580354436857291\n",
            "Total Loss: 0.0008738592494856956\n",
            "----------------------------------------\n",
            "Epoch 291\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.855543400949086\n",
            "SCOPE mean: 0.11382623038367633, SCOPE var: 0.005573247589579548\n",
            "Total Loss: 0.0008666998714264085\n",
            "----------------------------------------\n",
            "Epoch 292\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.86174558297891\n",
            "SCOPE mean: 0.11397319300355835, SCOPE var: 0.005566201942988194\n",
            "Total Loss: 0.0008597543234889743\n",
            "----------------------------------------\n",
            "Epoch 293\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.86786626090897\n",
            "SCOPE mean: 0.11411245772301144, SCOPE var: 0.005559216212968229\n",
            "Total Loss: 0.0008530523339536887\n",
            "----------------------------------------\n",
            "Epoch 294\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.874023515696251\n",
            "SCOPE mean: 0.11421698478968086, SCOPE var: 0.005551851991590655\n",
            "Total Loss: 0.0008466365846177605\n",
            "----------------------------------------\n",
            "Epoch 295\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.880254990993357\n",
            "SCOPE mean: 0.11430319586822703, SCOPE var: 0.005544514587701619\n",
            "Total Loss: 0.0008403733512251345\n",
            "----------------------------------------\n",
            "Epoch 296\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.886590141985566\n",
            "SCOPE mean: 0.11437098287563072, SCOPE var: 0.0055372131943699\n",
            "Total Loss: 0.0008342274475300394\n",
            "----------------------------------------\n",
            "Epoch 297\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.893099541140362\n",
            "SCOPE mean: 0.1144256591424281, SCOPE var: 0.0055299607758840415\n",
            "Total Loss: 0.0008282784337229777\n",
            "----------------------------------------\n",
            "Epoch 298\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.899829403932124\n",
            "SCOPE mean: 0.114468318594721, SCOPE var: 0.005522761382274412\n",
            "Total Loss: 0.0008224786743893063\n",
            "----------------------------------------\n",
            "Epoch 299\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.906791289571537\n",
            "SCOPE mean: 0.11449864708782959, SCOPE var: 0.005515614551443284\n",
            "Total Loss: 0.0008167881664055207\n",
            "----------------------------------------\n",
            "Epoch 300\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.913927069952864\n",
            "SCOPE mean: 0.11451731274226187, SCOPE var: 0.00550852305657033\n",
            "Total Loss: 0.0008112304283097104\n",
            "----------------------------------------\n",
            "Epoch 301\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.92119237335957\n",
            "SCOPE mean: 0.11452312265670717, SCOPE var: 0.005501476314632579\n",
            "Total Loss: 0.000805782918646889\n",
            "----------------------------------------\n",
            "Epoch 302\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.928588928920714\n",
            "SCOPE mean: 0.11451787568418442, SCOPE var: 0.005494478520195584\n",
            "Total Loss: 0.0008004206225516863\n",
            "----------------------------------------\n",
            "Epoch 303\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.93607789194488\n",
            "SCOPE mean: 0.11450327758867636, SCOPE var: 0.005487533296789278\n",
            "Total Loss: 0.0007951431458086641\n",
            "----------------------------------------\n",
            "Epoch 304\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.943629826691884\n",
            "SCOPE mean: 0.11448156660507691, SCOPE var: 0.005480641223757712\n",
            "Total Loss: 0.0007899446211381231\n",
            "----------------------------------------\n",
            "Epoch 305\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.951245145417337\n",
            "SCOPE mean: 0.11445440538381013, SCOPE var: 0.005473803804861525\n",
            "Total Loss: 0.0007847957848362445\n",
            "----------------------------------------\n",
            "Epoch 306\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.958838061813067\n",
            "SCOPE mean: 0.1144220981235117, SCOPE var: 0.005467021595351619\n",
            "Total Loss: 0.0007797050567055319\n",
            "----------------------------------------\n",
            "Epoch 307\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.966379540069095\n",
            "SCOPE mean: 0.11438610437918903, SCOPE var: 0.005460297112828898\n",
            "Total Loss: 0.0007746863057159142\n",
            "----------------------------------------\n",
            "Epoch 308\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.973818592210357\n",
            "SCOPE mean: 0.11434397548826933, SCOPE var: 0.0054536719427709926\n",
            "Total Loss: 0.0007697385777885796\n",
            "----------------------------------------\n",
            "Epoch 309\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.981215522449903\n",
            "SCOPE mean: 0.114292188644591, SCOPE var: 0.005447190874695214\n",
            "Total Loss: 0.0007648590380897659\n",
            "----------------------------------------\n",
            "Epoch 310\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.988668885656734\n",
            "SCOPE mean: 0.11424155239354138, SCOPE var: 0.005440755404806908\n",
            "Total Loss: 0.000760047919304647\n",
            "----------------------------------------\n",
            "Epoch 311\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.996022825458377\n",
            "SCOPE mean: 0.1141921129603437, SCOPE var: 0.005434377532768253\n",
            "Total Loss: 0.0007552756291953386\n",
            "----------------------------------------\n",
            "Epoch 312\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.003282351294255\n",
            "SCOPE mean: 0.11414415150610882, SCOPE var: 0.005428060160266322\n",
            "Total Loss: 0.0007505356120852185\n",
            "----------------------------------------\n",
            "Epoch 313\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.010406378104992\n",
            "SCOPE mean: 0.11409762645505166, SCOPE var: 0.00542180689163692\n",
            "Total Loss: 0.0007458440874236294\n",
            "----------------------------------------\n",
            "Epoch 314\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.017399758817074\n",
            "SCOPE mean: 0.11405079081797134, SCOPE var: 0.005415620697931607\n",
            "Total Loss: 0.0007412087804360718\n",
            "----------------------------------------\n",
            "Epoch 315\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.024200838403926\n",
            "SCOPE mean: 0.11400368676977682, SCOPE var: 0.005409505483207992\n",
            "Total Loss: 0.0007366062664947017\n",
            "----------------------------------------\n",
            "Epoch 316\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.030822192346777\n",
            "SCOPE mean: 0.1139592736923679, SCOPE var: 0.005403475171736289\n",
            "Total Loss: 0.0007320049957022369\n",
            "----------------------------------------\n",
            "Epoch 317\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.037298398645337\n",
            "SCOPE mean: 0.11391929290927692, SCOPE var: 0.005397525795648246\n",
            "Total Loss: 0.0007274820118839439\n",
            "----------------------------------------\n",
            "Epoch 318\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.043758424717327\n",
            "SCOPE mean: 0.11388230487026993, SCOPE var: 0.005391656936218299\n",
            "Total Loss: 0.0007230379509731297\n",
            "----------------------------------------\n",
            "Epoch 319\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.050051238280899\n",
            "SCOPE mean: 0.11384512648325576, SCOPE var: 0.005385851004855778\n",
            "Total Loss: 0.0007186674571913367\n",
            "----------------------------------------\n",
            "Epoch 320\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.056216619851131\n",
            "SCOPE mean: 0.11380671494466, SCOPE var: 0.005380099157156046\n",
            "Total Loss: 0.0007143432964368313\n",
            "----------------------------------------\n",
            "Epoch 321\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.062300454824639\n",
            "SCOPE mean: 0.11375471651276019, SCOPE var: 0.005374313863880304\n",
            "Total Loss: 0.0007100660631548167\n",
            "----------------------------------------\n",
            "Epoch 322\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.068273030266852\n",
            "SCOPE mean: 0.11368301686881255, SCOPE var: 0.005368456865911009\n",
            "Total Loss: 0.0007058289705171675\n",
            "----------------------------------------\n",
            "Epoch 323\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.074133657409428\n",
            "SCOPE mean: 0.1136107386577406, SCOPE var: 0.005362653247923636\n",
            "Total Loss: 0.0007016314694933979\n",
            "----------------------------------------\n",
            "Epoch 324\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.079868187195249\n",
            "SCOPE mean: 0.11353786933531698, SCOPE var: 0.005356900903001619\n",
            "Total Loss: 0.0006974720321102742\n",
            "----------------------------------------\n",
            "Epoch 325\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.085452333719912\n",
            "SCOPE mean: 0.11346482175927493, SCOPE var: 0.005351197814658051\n",
            "Total Loss: 0.0006933526762260799\n",
            "----------------------------------------\n",
            "Epoch 326\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.090870263715791\n",
            "SCOPE mean: 0.11339144767013895, SCOPE var: 0.005345541533345628\n",
            "Total Loss: 0.0006892733728393058\n",
            "----------------------------------------\n",
            "Epoch 327\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.096124022200419\n",
            "SCOPE mean: 0.1133176580124652, SCOPE var: 0.005339929877497057\n",
            "Total Loss: 0.0006852253481160263\n",
            "----------------------------------------\n",
            "Epoch 328\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.101170402185046\n",
            "SCOPE mean: 0.11324452861061964, SCOPE var: 0.005334367612361053\n",
            "Total Loss: 0.0006812132281355421\n",
            "----------------------------------------\n",
            "Epoch 329\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.106116657486787\n",
            "SCOPE mean: 0.11317220866415732, SCOPE var: 0.0053288534383995985\n",
            "Total Loss: 0.0006772998069003884\n",
            "----------------------------------------\n",
            "Epoch 330\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.111151384242268\n",
            "SCOPE mean: 0.11310181598362312, SCOPE var: 0.005323381703970097\n",
            "Total Loss: 0.0006733953036565377\n",
            "----------------------------------------\n",
            "Epoch 331\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.11590422450116\n",
            "SCOPE mean: 0.11303322468356805, SCOPE var: 0.005317950288480228\n",
            "Total Loss: 0.0006695103540250342\n",
            "----------------------------------------\n",
            "Epoch 332\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.120393986762775\n",
            "SCOPE mean: 0.1129659991564823, SCOPE var: 0.005312559927045017\n",
            "Total Loss: 0.0006656498276082364\n",
            "----------------------------------------\n",
            "Epoch 333\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.124594508622446\n",
            "SCOPE mean: 0.11289967965474147, SCOPE var: 0.005307213347199133\n",
            "Total Loss: 0.0006618042187671766\n",
            "----------------------------------------\n",
            "Epoch 334\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.128554330755332\n",
            "SCOPE mean: 0.1128344354653997, SCOPE var: 0.005301905389700843\n",
            "Total Loss: 0.0006579622866214046\n",
            "----------------------------------------\n",
            "Epoch 335\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.132203760444384\n",
            "SCOPE mean: 0.1127697280585071, SCOPE var: 0.00529663967276316\n",
            "Total Loss: 0.0006541418863635844\n",
            "----------------------------------------\n",
            "Epoch 336\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.135546204865022\n",
            "SCOPE mean: 0.11270502762970164, SCOPE var: 0.005291418114700265\n",
            "Total Loss: 0.000650373268805069\n",
            "----------------------------------------\n",
            "Epoch 337\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.138774814111363\n",
            "SCOPE mean: 0.1126407325665208, SCOPE var: 0.005286240405357637\n",
            "Total Loss: 0.0006467799521242734\n",
            "----------------------------------------\n",
            "Epoch 338\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.142125484925222\n",
            "SCOPE mean: 0.11257645683658055, SCOPE var: 0.0052811031181698356\n",
            "Total Loss: 0.0006432679465097269\n",
            "----------------------------------------\n",
            "Epoch 339\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.145549250474472\n",
            "SCOPE mean: 0.11251126372857448, SCOPE var: 0.00527600269865683\n",
            "Total Loss: 0.0006397946343591696\n",
            "----------------------------------------\n",
            "Epoch 340\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.14899774831789\n",
            "SCOPE mean: 0.11244604400758483, SCOPE var: 0.0052709540517174875\n",
            "Total Loss: 0.0006363587064041043\n",
            "----------------------------------------\n",
            "Epoch 341\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.152470946045193\n",
            "SCOPE mean: 0.11238070822992399, SCOPE var: 0.0052659579399258255\n",
            "Total Loss: 0.0006329689246777122\n",
            "----------------------------------------\n",
            "Epoch 342\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.156091492376799\n",
            "SCOPE mean: 0.11231573559234334, SCOPE var: 0.005261018648145379\n",
            "Total Loss: 0.0006295852614254473\n",
            "----------------------------------------\n",
            "Epoch 343\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.159801892337954\n",
            "SCOPE mean: 0.11225143444376275, SCOPE var: 0.00525613532935675\n",
            "Total Loss: 0.0006262328338755321\n",
            "----------------------------------------\n",
            "Epoch 344\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.163461909748436\n",
            "SCOPE mean: 0.11217840941800242, SCOPE var: 0.005251093055371966\n",
            "Total Loss: 0.0006229205700924782\n",
            "----------------------------------------\n",
            "Epoch 345\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.167079367479785\n",
            "SCOPE mean: 0.11210176751583777, SCOPE var: 0.005246069270689751\n",
            "Total Loss: 0.0006196383352751764\n",
            "----------------------------------------\n",
            "Epoch 346\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.170752176541312\n",
            "SCOPE mean: 0.1120266226791477, SCOPE var: 0.0052411772758779495\n",
            "Total Loss: 0.0006164031815483004\n",
            "----------------------------------------\n",
            "Epoch 347\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.174393556466878\n",
            "SCOPE mean: 0.11195204006779717, SCOPE var: 0.005236344430582299\n",
            "Total Loss: 0.000613223045619161\n",
            "----------------------------------------\n",
            "Epoch 348\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.177747760348392\n",
            "SCOPE mean: 0.11187837643599603, SCOPE var: 0.005231557440151592\n",
            "Total Loss: 0.0006101257619393375\n",
            "----------------------------------------\n",
            "Epoch 349\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.180990529061864\n",
            "SCOPE mean: 0.11180612586176353, SCOPE var: 0.0052268180641876615\n",
            "Total Loss: 0.0006070347622192608\n",
            "----------------------------------------\n",
            "Epoch 350\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.1840969094521\n",
            "SCOPE mean: 0.11173406485087012, SCOPE var: 0.005222131910796711\n",
            "Total Loss: 0.0006039548131867996\n",
            "----------------------------------------\n",
            "Epoch 351\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.187090258879165\n",
            "SCOPE mean: 0.11166288619199399, SCOPE var: 0.005217497884290039\n",
            "Total Loss: 0.0006008775088614356\n",
            "----------------------------------------\n",
            "Epoch 352\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.189955731732377\n",
            "SCOPE mean: 0.11159394995288248, SCOPE var: 0.005212913326832031\n",
            "Total Loss: 0.000597826709571782\n",
            "----------------------------------------\n",
            "Epoch 353\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.192841238683895\n",
            "SCOPE mean: 0.11152948284234815, SCOPE var: 0.005208380378702498\n",
            "Total Loss: 0.0005948325285121953\n",
            "----------------------------------------\n",
            "Epoch 354\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.19581112375302\n",
            "SCOPE mean: 0.11146938400740274, SCOPE var: 0.005203896930239149\n",
            "Total Loss: 0.000591862426720852\n",
            "----------------------------------------\n",
            "Epoch 355\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.19891548810257\n",
            "SCOPE mean: 0.11141356275722526, SCOPE var: 0.005199472194278719\n",
            "Total Loss: 0.0005889191531628768\n",
            "----------------------------------------\n",
            "Epoch 356\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.20223082332464\n",
            "SCOPE mean: 0.11135895582741646, SCOPE var: 0.005195145008521455\n",
            "Total Loss: 0.0005860092543908008\n",
            "----------------------------------------\n",
            "Epoch 357\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.20571185531221\n",
            "SCOPE mean: 0.1113070017240198, SCOPE var: 0.005190906837488989\n",
            "Total Loss: 0.0005831248934040054\n",
            "----------------------------------------\n",
            "Epoch 358\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.209498932083388\n",
            "SCOPE mean: 0.1112575390264073, SCOPE var: 0.005186747870180984\n",
            "Total Loss: 0.0005802901138606636\n",
            "----------------------------------------\n",
            "Epoch 359\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.21320706766313\n",
            "SCOPE mean: 0.11120848423698558, SCOPE var: 0.005182652501534198\n",
            "Total Loss: 0.0005774729010660267\n",
            "----------------------------------------\n",
            "Epoch 360\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.21685989410253\n",
            "SCOPE mean: 0.11116078897167946, SCOPE var: 0.005178621372668996\n",
            "Total Loss: 0.0005746486157411293\n",
            "----------------------------------------\n",
            "Epoch 361\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.220471776075213\n",
            "SCOPE mean: 0.11111407195083779, SCOPE var: 0.005174646964585657\n",
            "Total Loss: 0.0005718368009157179\n",
            "----------------------------------------\n",
            "Epoch 362\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.224094060826308\n",
            "SCOPE mean: 0.1110676643426292, SCOPE var: 0.0051707332959222375\n",
            "Total Loss: 0.0005690799983719566\n",
            "----------------------------------------\n",
            "Epoch 363\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.22778005434662\n",
            "SCOPE mean: 0.11102172095799401, SCOPE var: 0.005166872720581158\n",
            "Total Loss: 0.0005663711115046999\n",
            "----------------------------------------\n",
            "Epoch 364\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.231678254893723\n",
            "SCOPE mean: 0.11097744233006814, SCOPE var: 0.005163067134334691\n",
            "Total Loss: 0.0005636962860770084\n",
            "----------------------------------------\n",
            "Epoch 365\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.235720173084774\n",
            "SCOPE mean: 0.11093529027419498, SCOPE var: 0.005159306019275123\n",
            "Total Loss: 0.0005610305051515613\n",
            "----------------------------------------\n",
            "Epoch 366\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.239877111444596\n",
            "SCOPE mean: 0.1108950105354978, SCOPE var: 0.005155585804043672\n",
            "Total Loss: 0.000558376653345053\n",
            "----------------------------------------\n",
            "Epoch 367\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.244139869188842\n",
            "SCOPE mean: 0.11085492962104163, SCOPE var: 0.005151903187088532\n",
            "Total Loss: 0.0005557496458401571\n",
            "----------------------------------------\n",
            "Epoch 368\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.248336119280342\n",
            "SCOPE mean: 0.11081396959748167, SCOPE var: 0.005148248903688375\n",
            "Total Loss: 0.000553154460986805\n",
            "----------------------------------------\n",
            "Epoch 369\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.25245698837555\n",
            "SCOPE mean: 0.11077220352486147, SCOPE var: 0.005144621309298318\n",
            "Total Loss: 0.000550572104695699\n",
            "----------------------------------------\n",
            "Epoch 370\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.256682274183056\n",
            "SCOPE mean: 0.11073048718975614, SCOPE var: 0.005141022768762065\n",
            "Total Loss: 0.0005480284230074778\n",
            "----------------------------------------\n",
            "Epoch 371\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.260889164314742\n",
            "SCOPE mean: 0.11069149443260391, SCOPE var: 0.005137469228085319\n",
            "Total Loss: 0.0005455307598243909\n",
            "----------------------------------------\n",
            "Epoch 372\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.265086180272723\n",
            "SCOPE mean: 0.11065542601235079, SCOPE var: 0.005133961702766969\n",
            "Total Loss: 0.0005430731177735358\n",
            "----------------------------------------\n",
            "Epoch 373\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.269337318575944\n",
            "SCOPE mean: 0.11062201828094119, SCOPE var: 0.00513049908592429\n",
            "Total Loss: 0.0005406365619498223\n",
            "----------------------------------------\n",
            "Epoch 374\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.273602952421927\n",
            "SCOPE mean: 0.11059132513498011, SCOPE var: 0.005127082730105758\n",
            "Total Loss: 0.0005382453361600699\n",
            "----------------------------------------\n",
            "Epoch 375\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.277724795347053\n",
            "SCOPE mean: 0.11056235731453541, SCOPE var: 0.0051237082521402326\n",
            "Total Loss: 0.0005358590710315391\n",
            "----------------------------------------\n",
            "Epoch 376\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.281665028706186\n",
            "SCOPE mean: 0.11053650943016521, SCOPE var: 0.005120375709392158\n",
            "Total Loss: 0.0005334777368803745\n",
            "----------------------------------------\n",
            "Epoch 377\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.285451339060542\n",
            "SCOPE mean: 0.1105125734965345, SCOPE var: 0.005117088721881986\n",
            "Total Loss: 0.0005311159052025491\n",
            "----------------------------------------\n",
            "Epoch 378\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.289253406963178\n",
            "SCOPE mean: 0.11049249456329978, SCOPE var: 0.005113854532894203\n",
            "Total Loss: 0.0005287594371383852\n",
            "----------------------------------------\n",
            "Epoch 379\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.293083277606707\n",
            "SCOPE mean: 0.11047634594618255, SCOPE var: 0.005110673596573723\n",
            "Total Loss: 0.0005264074356703368\n",
            "----------------------------------------\n",
            "Epoch 380\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.29700227531095\n",
            "SCOPE mean: 0.11046395742564483, SCOPE var: 0.005107547059802575\n",
            "Total Loss: 0.0005240648479565224\n",
            "----------------------------------------\n",
            "Epoch 381\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.300929335337782\n",
            "SCOPE mean: 0.11045490314310875, SCOPE var: 0.005104471936262363\n",
            "Total Loss: 0.0005217198809744481\n",
            "----------------------------------------\n",
            "Epoch 382\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.30469125109547\n",
            "SCOPE mean: 0.11044753934247892, SCOPE var: 0.005101440456236249\n",
            "Total Loss: 0.0005193941131748\n",
            "----------------------------------------\n",
            "Epoch 383\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.308268042580483\n",
            "SCOPE mean: 0.11044173704583718, SCOPE var: 0.005098453154258769\n",
            "Total Loss: 0.0005170519841656432\n",
            "----------------------------------------\n",
            "Epoch 384\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.311640065368538\n",
            "SCOPE mean: 0.11043674552380085, SCOPE var: 0.005095506569170226\n",
            "Total Loss: 0.0005147451499025394\n",
            "----------------------------------------\n",
            "Epoch 385\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.31497442394852\n",
            "SCOPE mean: 0.11043284475191222, SCOPE var: 0.005092601775411695\n",
            "Total Loss: 0.0005124619884425314\n",
            "----------------------------------------\n",
            "Epoch 386\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.318333223480744\n",
            "SCOPE mean: 0.11042839162526157, SCOPE var: 0.0050897292685133455\n",
            "Total Loss: 0.0005101648769557163\n",
            "----------------------------------------\n",
            "Epoch 387\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.321734895502804\n",
            "SCOPE mean: 0.11042361028818459, SCOPE var: 0.005086888482642526\n",
            "Total Loss: 0.0005078467276164774\n",
            "----------------------------------------\n",
            "Epoch 388\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.325172601590499\n",
            "SCOPE mean: 0.11041804870839922, SCOPE var: 0.005084077024177901\n",
            "Total Loss: 0.0005055441964996368\n",
            "----------------------------------------\n",
            "Epoch 389\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.32850858998218\n",
            "SCOPE mean: 0.11041055459466802, SCOPE var: 0.0050812881540085045\n",
            "Total Loss: 0.0005032719135199807\n",
            "----------------------------------------\n",
            "Epoch 390\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.331716175081457\n",
            "SCOPE mean: 0.11040302820985728, SCOPE var: 0.005078531648884443\n",
            "Total Loss: 0.000501005812234189\n",
            "----------------------------------------\n",
            "Epoch 391\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.334812438377552\n",
            "SCOPE mean: 0.1103961099053844, SCOPE var: 0.005075811105899196\n",
            "Total Loss: 0.0004988207697956358\n",
            "----------------------------------------\n",
            "Epoch 392\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.337779771232208\n",
            "SCOPE mean: 0.11038937351526866, SCOPE var: 0.005073128359469791\n",
            "Total Loss: 0.0004966676918080358\n",
            "----------------------------------------\n",
            "Epoch 393\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.340532994074692\n",
            "SCOPE mean: 0.1103847258538304, SCOPE var: 0.005070455117860363\n",
            "Total Loss: 0.0004945603338860798\n",
            "----------------------------------------\n",
            "Epoch 394\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.34306650332646\n",
            "SCOPE mean: 0.1103836014453253, SCOPE var: 0.0050678008533063396\n",
            "Total Loss: 0.0004924499899910274\n",
            "----------------------------------------\n",
            "Epoch 395\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.345439371478225\n",
            "SCOPE mean: 0.11038645162039397, SCOPE var: 0.005065168526826519\n",
            "Total Loss: 0.0004903322915891965\n",
            "----------------------------------------\n",
            "Epoch 396\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.348093295816547\n",
            "SCOPE mean: 0.1103937245707726, SCOPE var: 0.005062560380102947\n",
            "Total Loss: 0.00048823561593571726\n",
            "----------------------------------------\n",
            "Epoch 397\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.35101531341442\n",
            "SCOPE mean: 0.11040511809713434, SCOPE var: 0.005059978943321701\n",
            "Total Loss: 0.00048614053651887564\n",
            "----------------------------------------\n",
            "Epoch 398\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.353810405600147\n",
            "SCOPE mean: 0.11041902344099021, SCOPE var: 0.005057424332382995\n",
            "Total Loss: 0.0004840453352398128\n",
            "----------------------------------------\n",
            "Epoch 399\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.356452274207085\n",
            "SCOPE mean: 0.11043466400567349, SCOPE var: 0.005054897466621976\n",
            "Total Loss: 0.0004819756883111844\n",
            "----------------------------------------\n",
            "Epoch 400\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.358748257714263\n",
            "SCOPE mean: 0.11044923545044485, SCOPE var: 0.00505239196112373\n",
            "Total Loss: 0.00047987132423343067\n",
            "----------------------------------------\n",
            "Epoch 401\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.36093391935594\n",
            "SCOPE mean: 0.11046267351915462, SCOPE var: 0.005049909053847521\n",
            "Total Loss: 0.0004777642812527673\n",
            "----------------------------------------\n",
            "Epoch 402\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.362878416161147\n",
            "SCOPE mean: 0.1104743910487965, SCOPE var: 0.005047448974391097\n",
            "Total Loss: 0.0004756642853652151\n",
            "----------------------------------------\n",
            "Epoch 403\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.364422791195974\n",
            "SCOPE mean: 0.11048328615579353, SCOPE var: 0.00504501046482628\n",
            "Total Loss: 0.000473557550831918\n",
            "----------------------------------------\n",
            "Epoch 404\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.365727825134218\n",
            "SCOPE mean: 0.11049206632950877, SCOPE var: 0.005042596588382815\n",
            "Total Loss: 0.0004714997481099399\n",
            "----------------------------------------\n",
            "Epoch 405\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.367043478979042\n",
            "SCOPE mean: 0.11050008228401716, SCOPE var: 0.005040215721817403\n",
            "Total Loss: 0.00046945600433668627\n",
            "----------------------------------------\n",
            "Epoch 406\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.36837516246812\n",
            "SCOPE mean: 0.11050715009686274, SCOPE var: 0.005037865056800623\n",
            "Total Loss: 0.00046740531807800236\n",
            "----------------------------------------\n",
            "Epoch 407\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.369797324497524\n",
            "SCOPE mean: 0.11051296822561503, SCOPE var: 0.0050355700313345535\n",
            "Total Loss: 0.0004653629507165145\n",
            "----------------------------------------\n",
            "Epoch 408\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.371361327064191\n",
            "SCOPE mean: 0.11051526536179142, SCOPE var: 0.005033312135961636\n",
            "Total Loss: 0.0004633346959185878\n",
            "----------------------------------------\n",
            "Epoch 409\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.372989878692076\n",
            "SCOPE mean: 0.11051449646110077, SCOPE var: 0.005031074546793583\n",
            "Total Loss: 0.0004613291242449732\n",
            "----------------------------------------\n",
            "Epoch 410\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.374292618774609\n",
            "SCOPE mean: 0.11050989871487445, SCOPE var: 0.005028847527691581\n",
            "Total Loss: 0.00045934753238872076\n",
            "----------------------------------------\n",
            "Epoch 411\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.375280930132107\n",
            "SCOPE mean: 0.11050281876654167, SCOPE var: 0.0050266274058714585\n",
            "Total Loss: 0.00045738856833636433\n",
            "----------------------------------------\n",
            "Epoch 412\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.376200871528393\n",
            "SCOPE mean: 0.11049271374527257, SCOPE var: 0.005024443239536285\n",
            "Total Loss: 0.0004554559366322004\n",
            "----------------------------------------\n",
            "Epoch 413\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.377338313589231\n",
            "SCOPE mean: 0.1104772443749993, SCOPE var: 0.005022324039350146\n",
            "Total Loss: 0.0004535628269772917\n",
            "----------------------------------------\n",
            "Epoch 414\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.37888815964297\n",
            "SCOPE mean: 0.11046386364378284, SCOPE var: 0.005020235187265079\n",
            "Total Loss: 0.0004516534090080015\n",
            "----------------------------------------\n",
            "Epoch 415\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.380465592878952\n",
            "SCOPE mean: 0.11045100045983827, SCOPE var: 0.005018172547218654\n",
            "Total Loss: 0.0004497598127244708\n",
            "----------------------------------------\n",
            "Epoch 416\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.382142528356331\n",
            "SCOPE mean: 0.1104369597550595, SCOPE var: 0.005016127753870085\n",
            "Total Loss: 0.0004479016810730816\n",
            "----------------------------------------\n",
            "Epoch 417\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.383886400666876\n",
            "SCOPE mean: 0.11042292972296314, SCOPE var: 0.005014107271364977\n",
            "Total Loss: 0.00044604924173052054\n",
            "----------------------------------------\n",
            "Epoch 418\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.385708360847987\n",
            "SCOPE mean: 0.1104095920670865, SCOPE var: 0.005012111519464481\n",
            "Total Loss: 0.00044415107912205206\n",
            "----------------------------------------\n",
            "Epoch 419\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.387467022315866\n",
            "SCOPE mean: 0.1103981879318881, SCOPE var: 0.00501014466537948\n",
            "Total Loss: 0.00044227434241940765\n",
            "----------------------------------------\n",
            "Epoch 420\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.389064019056551\n",
            "SCOPE mean: 0.11038966170640113, SCOPE var: 0.005008211879562039\n",
            "Total Loss: 0.00044031941945402533\n",
            "----------------------------------------\n",
            "Epoch 421\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.390358732084179\n",
            "SCOPE mean: 0.11039440644047618, SCOPE var: 0.005006162444984092\n",
            "Total Loss: 0.00043830368298760595\n",
            "----------------------------------------\n",
            "Epoch 422\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.39117564620516\n",
            "SCOPE mean: 0.11041055652425014, SCOPE var: 0.0050040106406884464\n",
            "Total Loss: 0.00043625217750597773\n",
            "----------------------------------------\n",
            "Epoch 423\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.391705486428606\n",
            "SCOPE mean: 0.11043731257924053, SCOPE var: 0.005001775476942826\n",
            "Total Loss: 0.00043417429686171073\n",
            "----------------------------------------\n",
            "Epoch 424\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.391833558943329\n",
            "SCOPE mean: 0.11047265541099134, SCOPE var: 0.004999469530426834\n",
            "Total Loss: 0.0004320778634010834\n",
            "----------------------------------------\n",
            "Epoch 425\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.391575645068178\n",
            "SCOPE mean: 0.11051493669572499, SCOPE var: 0.004997105817841105\n",
            "Total Loss: 0.00042997715717203337\n",
            "----------------------------------------\n",
            "Epoch 426\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.39101094627481\n",
            "SCOPE mean: 0.1105583001370178, SCOPE var: 0.004994672801002819\n",
            "Total Loss: 0.00042785104319718973\n",
            "----------------------------------------\n",
            "Epoch 427\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.390256259518985\n",
            "SCOPE mean: 0.11060266319649768, SCOPE var: 0.004992177248735323\n",
            "Total Loss: 0.00042572878144114346\n",
            "----------------------------------------\n",
            "Epoch 428\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.389515136267779\n",
            "SCOPE mean: 0.11064870551698908, SCOPE var: 0.004989641936118539\n",
            "Total Loss: 0.0004236354517509837\n",
            "----------------------------------------\n",
            "Epoch 429\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.388556710297147\n",
            "SCOPE mean: 0.11069753756650066, SCOPE var: 0.004987093996752062\n",
            "Total Loss: 0.00042153802271029664\n",
            "----------------------------------------\n",
            "Epoch 430\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.387394099753532\n",
            "SCOPE mean: 0.11074973670397792, SCOPE var: 0.004984547457528136\n",
            "Total Loss: 0.0004194663567604579\n",
            "----------------------------------------\n",
            "Epoch 431\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.386100628772974\n",
            "SCOPE mean: 0.11080443785020905, SCOPE var: 0.00498200931446975\n",
            "Total Loss: 0.0004174016581178409\n",
            "----------------------------------------\n",
            "Epoch 432\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.384771060166349\n",
            "SCOPE mean: 0.11086138665236302, SCOPE var: 0.004979488456785127\n",
            "Total Loss: 0.00041535783405985215\n",
            "----------------------------------------\n",
            "Epoch 433\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.38362153580344\n",
            "SCOPE mean: 0.11092056081517858, SCOPE var: 0.004977003178316559\n",
            "Total Loss: 0.0004133531311094259\n",
            "----------------------------------------\n",
            "Epoch 434\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.3826423814914\n",
            "SCOPE mean: 0.11098164784801413, SCOPE var: 0.004974559505867251\n",
            "Total Loss: 0.0004113657952474996\n",
            "----------------------------------------\n",
            "Epoch 435\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.381645190102176\n",
            "SCOPE mean: 0.11104414518102994, SCOPE var: 0.0049721614898957\n",
            "Total Loss: 0.0004094157779249754\n",
            "----------------------------------------\n",
            "Epoch 436\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.380655927492619\n",
            "SCOPE mean: 0.11108869508378812, SCOPE var: 0.004968894089068094\n",
            "Total Loss: 0.0004074732988909478\n",
            "----------------------------------------\n",
            "Epoch 437\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.379815153296326\n",
            "SCOPE mean: 0.11112161767505808, SCOPE var: 0.0049650537483004135\n",
            "Total Loss: 0.00040555555256578874\n",
            "----------------------------------------\n",
            "Epoch 438\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.3791831065317\n",
            "SCOPE mean: 0.111154768726181, SCOPE var: 0.004961267737314569\n",
            "Total Loss: 0.0004036754259423652\n",
            "----------------------------------------\n",
            "Epoch 439\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.378756600807623\n",
            "SCOPE mean: 0.11118503807423086, SCOPE var: 0.004957522312186208\n",
            "Total Loss: 0.00040181244335651565\n",
            "----------------------------------------\n",
            "Epoch 440\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.37891045782564\n",
            "SCOPE mean: 0.11121660752845627, SCOPE var: 0.0049538720261599\n",
            "Total Loss: 0.0003999633052038791\n",
            "----------------------------------------\n",
            "Epoch 441\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.379257686135675\n",
            "SCOPE mean: 0.11124696104851023, SCOPE var: 0.004950291521891817\n",
            "Total Loss: 0.000398148241513724\n",
            "----------------------------------------\n",
            "Epoch 442\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.37967692222237\n",
            "SCOPE mean: 0.11127687253446049, SCOPE var: 0.0049467708876319875\n",
            "Total Loss: 0.0003963651809633636\n",
            "----------------------------------------\n",
            "Epoch 443\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.38035261933021\n",
            "SCOPE mean: 0.11130553335079175, SCOPE var: 0.004943298618890219\n",
            "Total Loss: 0.0003946261702615432\n",
            "----------------------------------------\n",
            "Epoch 444\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.38152012129575\n",
            "SCOPE mean: 0.11132916740549154, SCOPE var: 0.004939896665364532\n",
            "Total Loss: 0.00039294198638624667\n",
            "----------------------------------------\n",
            "Epoch 445\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.382354265191372\n",
            "SCOPE mean: 0.11136430600357385, SCOPE var: 0.0049363655231583585\n",
            "Total Loss: 0.00039071272431985484\n",
            "----------------------------------------\n",
            "Epoch 446\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.38255911579766\n",
            "SCOPE mean: 0.11140766606719753, SCOPE var: 0.0049327395586972154\n",
            "Total Loss: 0.00038847164109408975\n",
            "----------------------------------------\n",
            "Epoch 447\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.381819420166957\n",
            "SCOPE mean: 0.11148366123270634, SCOPE var: 0.0049292698198978475\n",
            "Total Loss: 0.0003860165960782434\n",
            "----------------------------------------\n",
            "Epoch 448\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.37984830312632\n",
            "SCOPE mean: 0.11158042476394076, SCOPE var: 0.004925947025855096\n",
            "Total Loss: 0.00038347384701203723\n",
            "----------------------------------------\n",
            "Epoch 449\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.376765746530152\n",
            "SCOPE mean: 0.11168919181675117, SCOPE var: 0.004922766720230942\n",
            "Total Loss: 0.00038085696004686487\n",
            "----------------------------------------\n",
            "Epoch 450\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.37296243602979\n",
            "SCOPE mean: 0.1118142827585064, SCOPE var: 0.004919757689537463\n",
            "Total Loss: 0.00037819119633133064\n",
            "----------------------------------------\n",
            "Epoch 451\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.368471448536143\n",
            "SCOPE mean: 0.11195034144711069, SCOPE var: 0.004916907400127916\n",
            "Total Loss: 0.00037554058739149644\n",
            "----------------------------------------\n",
            "Epoch 452\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.363581449800657\n",
            "SCOPE mean: 0.11209760676659766, SCOPE var: 0.004914224497250606\n",
            "Total Loss: 0.0003729201539084657\n",
            "----------------------------------------\n",
            "Epoch 453\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.358400360264662\n",
            "SCOPE mean: 0.11225275725784631, SCOPE var: 0.004911702354910597\n",
            "Total Loss: 0.00037031943340574194\n",
            "----------------------------------------\n",
            "Epoch 454\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.353297060423747\n",
            "SCOPE mean: 0.11241598824708242, SCOPE var: 0.004909346925763553\n",
            "Total Loss: 0.00036772977255022726\n",
            "----------------------------------------\n",
            "Epoch 455\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.348319555902993\n",
            "SCOPE mean: 0.11258590156980287, SCOPE var: 0.004907144238490641\n",
            "Total Loss: 0.0003651617712130406\n",
            "----------------------------------------\n",
            "Epoch 456\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.343290105600945\n",
            "SCOPE mean: 0.11276044961878325, SCOPE var: 0.004905066641015942\n",
            "Total Loss: 0.00036262764253159956\n",
            "----------------------------------------\n",
            "Epoch 457\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.33814725137729\n",
            "SCOPE mean: 0.112936906143737, SCOPE var: 0.004903086584415449\n",
            "Total Loss: 0.0003601681410153626\n",
            "----------------------------------------\n",
            "Epoch 458\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.33303888804824\n",
            "SCOPE mean: 0.11311413187841908, SCOPE var: 0.004901192894335785\n",
            "Total Loss: 0.0003577673888148579\n",
            "----------------------------------------\n",
            "Epoch 459\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.327759457724751\n",
            "SCOPE mean: 0.1132901994391608, SCOPE var: 0.004899368442674255\n",
            "Total Loss: 0.000355429652616439\n",
            "----------------------------------------\n",
            "Epoch 460\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.322493725487542\n",
            "SCOPE mean: 0.11346479814976779, SCOPE var: 0.0048976015335582025\n",
            "Total Loss: 0.000353169124821732\n",
            "----------------------------------------\n",
            "Epoch 461\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.317560669187479\n",
            "SCOPE mean: 0.11364009053741116, SCOPE var: 0.00489582388059785\n",
            "Total Loss: 0.00035102681801616923\n",
            "----------------------------------------\n",
            "Epoch 462\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.314002452344726\n",
            "SCOPE mean: 0.1138077821061139, SCOPE var: 0.004894177140516252\n",
            "Total Loss: 0.0003492855580148201\n",
            "----------------------------------------\n",
            "Epoch 463\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.311228632116533\n",
            "SCOPE mean: 0.113962363248061, SCOPE var: 0.004892425730704111\n",
            "Total Loss: 0.00034757504426979885\n",
            "----------------------------------------\n",
            "Epoch 464\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.308831795440643\n",
            "SCOPE mean: 0.11410058206314434, SCOPE var: 0.004890522254328828\n",
            "Total Loss: 0.00034590130173087246\n",
            "----------------------------------------\n",
            "Epoch 465\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.306903852312603\n",
            "SCOPE mean: 0.1142220256681866, SCOPE var: 0.004888444724630502\n",
            "Total Loss: 0.00034426175989708786\n",
            "----------------------------------------\n",
            "Epoch 466\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.305345149700761\n",
            "SCOPE mean: 0.1143227899448078, SCOPE var: 0.004886179093758202\n",
            "Total Loss: 0.00034268847831541495\n",
            "----------------------------------------\n",
            "Epoch 467\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.304475814581611\n",
            "SCOPE mean: 0.11440454904062787, SCOPE var: 0.004883737063637013\n",
            "Total Loss: 0.00034115510566223845\n",
            "----------------------------------------\n",
            "Epoch 468\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.303804944607657\n",
            "SCOPE mean: 0.11446929436594445, SCOPE var: 0.004881123296148642\n",
            "Total Loss: 0.0003396359497544199\n",
            "----------------------------------------\n",
            "Epoch 469\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.303688375253525\n",
            "SCOPE mean: 0.11451688505314096, SCOPE var: 0.004878346835730087\n",
            "Total Loss: 0.000338158291565671\n",
            "----------------------------------------\n",
            "Epoch 470\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.30366725257404\n",
            "SCOPE mean: 0.1145444677434995, SCOPE var: 0.0048755070368926385\n",
            "Total Loss: 0.00033672468904804524\n",
            "----------------------------------------\n",
            "Epoch 471\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.303654625269129\n",
            "SCOPE mean: 0.11454987356053063, SCOPE var: 0.004872617543367999\n",
            "Total Loss: 0.00033529320124843726\n",
            "----------------------------------------\n",
            "Epoch 472\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.303712904717838\n",
            "SCOPE mean: 0.11453927247534336, SCOPE var: 0.0048696266900028415\n",
            "Total Loss: 0.0003338649257039572\n",
            "----------------------------------------\n",
            "Epoch 473\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.304038894701073\n",
            "SCOPE mean: 0.11451460331987219, SCOPE var: 0.004866569846855825\n",
            "Total Loss: 0.0003324447094617412\n",
            "----------------------------------------\n",
            "Epoch 474\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.30428199931586\n",
            "SCOPE mean: 0.11447525843303137, SCOPE var: 0.004863491932925507\n",
            "Total Loss: 0.00033103190951018637\n",
            "----------------------------------------\n",
            "Epoch 475\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.30475198655136\n",
            "SCOPE mean: 0.1144244970373338, SCOPE var: 0.004860408737827448\n",
            "Total Loss: 0.00032963623907496427\n",
            "----------------------------------------\n",
            "Epoch 476\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.30573468708942\n",
            "SCOPE mean: 0.1143671884170745, SCOPE var: 0.004857258617626381\n",
            "Total Loss: 0.00032825770949390545\n",
            "----------------------------------------\n",
            "Epoch 477\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.307209085025606\n",
            "SCOPE mean: 0.11430471135266801, SCOPE var: 0.004854074724124169\n",
            "Total Loss: 0.0003269014670030571\n",
            "----------------------------------------\n",
            "Epoch 478\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.308998807213106\n",
            "SCOPE mean: 0.1142372328619586, SCOPE var: 0.004850879741044122\n",
            "Total Loss: 0.0003255482780752605\n",
            "----------------------------------------\n",
            "Epoch 479\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.311012503101614\n",
            "SCOPE mean: 0.11416243032019188, SCOPE var: 0.004847688474679552\n",
            "Total Loss: 0.0003242162506523078\n",
            "----------------------------------------\n",
            "Epoch 480\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.3131553996248\n",
            "SCOPE mean: 0.11408409175510355, SCOPE var: 0.004844603143515194\n",
            "Total Loss: 0.00032290126786903577\n",
            "----------------------------------------\n",
            "Epoch 481\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.315591923407755\n",
            "SCOPE mean: 0.11400215749252357, SCOPE var: 0.004841618607015536\n",
            "Total Loss: 0.00032161537090812716\n",
            "----------------------------------------\n",
            "Epoch 482\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.31781087100115\n",
            "SCOPE mean: 0.1139182188219646, SCOPE var: 0.004838729863043665\n",
            "Total Loss: 0.00032031419481834644\n",
            "----------------------------------------\n",
            "Epoch 483\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.32027488760161\n",
            "SCOPE mean: 0.11383255245930746, SCOPE var: 0.004835924966606748\n",
            "Total Loss: 0.00031903549065543724\n",
            "----------------------------------------\n",
            "Epoch 484\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.322867343409436\n",
            "SCOPE mean: 0.11374716926189794, SCOPE var: 0.004833194551428274\n",
            "Total Loss: 0.00031776624150084827\n",
            "----------------------------------------\n",
            "Epoch 485\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.325783613589108\n",
            "SCOPE mean: 0.11366118321255572, SCOPE var: 0.004830454398885752\n",
            "Total Loss: 0.0003165322571920941\n",
            "----------------------------------------\n",
            "Epoch 486\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.328897888342128\n",
            "SCOPE mean: 0.11357815166833347, SCOPE var: 0.004827718067087341\n",
            "Total Loss: 0.00031533086919642757\n",
            "----------------------------------------\n",
            "Epoch 487\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.332137466983655\n",
            "SCOPE mean: 0.11349732253906977, SCOPE var: 0.004824994985150435\n",
            "Total Loss: 0.0003141635349613417\n",
            "----------------------------------------\n",
            "Epoch 488\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.335411956163568\n",
            "SCOPE mean: 0.11341696749279923, SCOPE var: 0.004822368935480636\n",
            "Total Loss: 0.0003129841789178803\n",
            "----------------------------------------\n",
            "Epoch 489\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.338467068874115\n",
            "SCOPE mean: 0.11333866724385606, SCOPE var: 0.0048198343225808425\n",
            "Total Loss: 0.0003118332893500329\n",
            "----------------------------------------\n",
            "Epoch 490\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.341631949899154\n",
            "SCOPE mean: 0.11326410249659148, SCOPE var: 0.004817390866610964\n",
            "Total Loss: 0.0003106980987699922\n",
            "----------------------------------------\n",
            "Epoch 491\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.34490577730091\n",
            "SCOPE mean: 0.11319367170466116, SCOPE var: 0.004815033884539329\n",
            "Total Loss: 0.0003095558361310519\n",
            "----------------------------------------\n",
            "Epoch 492\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.34829318919014\n",
            "SCOPE mean: 0.11312735942083031, SCOPE var: 0.004812757489176527\n",
            "Total Loss: 0.00030841810485399644\n",
            "----------------------------------------\n",
            "Epoch 493\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.35204554532619\n",
            "SCOPE mean: 0.11306706727617602, SCOPE var: 0.004810477775274091\n",
            "Total Loss: 0.0003072755475446328\n",
            "----------------------------------------\n",
            "Epoch 494\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.35570078848983\n",
            "SCOPE mean: 0.11301238727955115, SCOPE var: 0.004808188740466981\n",
            "Total Loss: 0.0003061510563571056\n",
            "----------------------------------------\n",
            "Epoch 495\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.359535370079607\n",
            "SCOPE mean: 0.1129567178100785, SCOPE var: 0.004805879764558991\n",
            "Total Loss: 0.0003050347242106882\n",
            "----------------------------------------\n",
            "Epoch 496\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.363282386958804\n",
            "SCOPE mean: 0.11290213670094301, SCOPE var: 0.004803656815967687\n",
            "Total Loss: 0.00030394453339093727\n",
            "----------------------------------------\n",
            "Epoch 497\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.36661858557903\n",
            "SCOPE mean: 0.11284917575093552, SCOPE var: 0.004801506389986176\n",
            "Total Loss: 0.00030284533102340096\n",
            "----------------------------------------\n",
            "Epoch 498\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.370033332843159\n",
            "SCOPE mean: 0.11279686331327375, SCOPE var: 0.0047994105627696855\n",
            "Total Loss: 0.0003017634778469986\n",
            "----------------------------------------\n",
            "Epoch 499\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.373437364780255\n",
            "SCOPE mean: 0.11274598660099844, SCOPE var: 0.004797357985743349\n",
            "Total Loss: 0.0003006941398188797\n",
            "----------------------------------------\n",
            "Epoch 500\n",
            "IS mean: 0.3141882937476792,IS variance: 0.008870786239980513\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.376724951164068\n",
            "SCOPE mean: 0.11269513184215711, SCOPE var: 0.0047953413781093215\n",
            "Total Loss: 0.0002996320717346622\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[-0.1458, -0.3947],\n",
            "        [ 0.1232, -0.2385],\n",
            "        [ 0.4609,  0.5946],\n",
            "        [-0.4500,  0.2395],\n",
            "        [ 0.7054, -0.4928],\n",
            "        [ 0.2608, -0.3924],\n",
            "        [-0.6120,  0.0066],\n",
            "        [ 0.2728,  0.3312],\n",
            "        [ 0.7716,  0.2189],\n",
            "        [ 0.3521,  0.4645],\n",
            "        [-0.5825, -0.5235],\n",
            "        [-0.5225, -0.4385],\n",
            "        [-0.7067,  0.0335],\n",
            "        [ 0.3536, -0.6286],\n",
            "        [ 0.6502, -0.1257],\n",
            "        [ 0.4512, -0.1115]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([ 0.6721,  0.0995, -0.2287,  0.6084,  0.1130,  0.3049, -0.6856,  0.1750,\n",
            "        -0.1604, -0.2459, -0.1913, -0.3826,  0.3842,  0.1165,  0.5906, -0.4117],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[ 1.8992e-01, -3.3924e-01, -1.1242e-01, -1.0328e-01, -1.9094e-01,\n",
            "         -1.9948e-02,  1.4583e-01,  1.5838e-01, -1.1774e-01, -6.0004e-02,\n",
            "          2.4297e-01, -1.3673e-01, -1.1189e-01,  7.9614e-04, -1.4644e-01,\n",
            "         -2.1476e-01],\n",
            "        [ 1.8893e-01, -3.4803e-01, -4.5009e-02, -7.6027e-02, -1.7492e-01,\n",
            "         -2.9821e-01, -1.4454e-01, -2.9215e-02, -3.8264e-01,  1.9488e-01,\n",
            "         -2.2206e-01, -2.4215e-01,  1.5100e-01,  8.8941e-02,  1.1805e-01,\n",
            "          1.4158e-01],\n",
            "        [ 4.3911e-02,  9.8338e-02,  5.3927e-02, -2.9537e-01,  1.0973e-01,\n",
            "         -1.9050e-02,  2.2910e-01,  1.1262e-01, -8.3465e-08, -1.4582e-01,\n",
            "          7.8982e-02, -9.0411e-02,  1.9741e-01,  2.6844e-02, -7.0307e-04,\n",
            "         -6.7757e-02],\n",
            "        [-1.0240e-01,  3.1350e-01, -1.1244e-02, -3.0192e-01,  3.7732e-02,\n",
            "          1.5878e-01, -1.4361e-01, -1.9821e-01, -8.6501e-02, -1.6614e-01,\n",
            "         -7.3527e-02, -1.6425e-01, -7.4712e-02,  1.0380e-03,  1.8345e-01,\n",
            "         -1.5603e-01],\n",
            "        [-1.0149e-02,  7.0127e-02, -1.0620e-01, -1.5056e-02, -2.3462e-02,\n",
            "         -4.8141e-02, -1.6649e-01,  1.0591e-01, -1.3121e-02, -1.4467e-01,\n",
            "          1.2140e-01, -1.0947e-02,  1.3882e-01,  6.6775e-02,  4.8759e-02,\n",
            "         -7.6847e-02],\n",
            "        [ 1.0611e-01, -2.1218e-01, -7.3585e-02,  2.1728e-02,  2.2367e-01,\n",
            "          5.6522e-02, -1.1532e-02,  9.9059e-02,  1.4091e-01,  1.8624e-01,\n",
            "          2.2387e-01,  1.0505e-01, -4.1488e-01, -3.7160e-01,  6.9706e-02,\n",
            "          2.9371e-01],\n",
            "        [ 2.1008e-02, -3.4169e-01, -3.1737e-02, -1.0784e-01, -2.5962e-01,\n",
            "          2.9879e-02, -2.3978e-01, -8.0244e-02,  2.1576e-01, -2.6228e-01,\n",
            "          2.0770e-01, -6.2762e-02,  1.6394e-01, -3.8245e-01,  5.6855e-02,\n",
            "          2.3152e-01],\n",
            "        [ 2.0571e-01,  2.1797e-01, -2.4013e-01,  1.0190e-01, -2.8877e-01,\n",
            "         -5.9907e-02,  1.0823e-01,  1.2927e-02, -1.1340e-01,  9.4804e-02,\n",
            "         -1.1448e-01, -2.7665e-02, -1.1956e-01, -1.4430e-01, -1.2044e-01,\n",
            "          1.6587e-02],\n",
            "        [ 1.3569e-01,  1.1918e-01, -3.5042e-01,  7.4587e-02, -1.7397e-01,\n",
            "          2.9130e-01,  3.3424e-02,  1.1827e-01,  6.5127e-02, -5.0438e-01,\n",
            "         -2.0898e-01,  1.0012e-01,  4.9268e-02,  1.5070e-01,  8.6681e-02,\n",
            "          2.9861e-01],\n",
            "        [ 2.4980e-02, -2.5043e-01,  5.6695e-02, -2.1522e-01, -2.4147e-01,\n",
            "         -1.0356e-01,  1.5495e-01,  1.1318e-01, -3.3783e-01,  7.6876e-02,\n",
            "         -1.1588e-01,  2.0708e-01,  4.4543e-02, -2.1149e-01, -4.1845e-02,\n",
            "         -1.9666e-01],\n",
            "        [-9.6753e-02, -2.4301e-02,  1.7342e-01, -2.0968e-01, -1.5442e-01,\n",
            "         -4.6191e-02,  1.4947e-02, -1.3430e-01, -2.5002e-01,  4.2735e-02,\n",
            "         -1.8084e-01,  1.7568e-01, -1.5823e-01, -5.9011e-02, -1.6161e-01,\n",
            "         -1.9406e-02],\n",
            "        [ 1.7574e-01, -1.3096e-01, -2.8627e-02, -1.9630e-01,  4.0594e-02,\n",
            "          1.3952e-01, -1.9286e-01, -5.2877e-02,  2.8751e-01, -1.1575e-01,\n",
            "         -2.1854e-02,  6.2092e-03,  1.1428e-01,  3.3395e-02, -3.9210e-01,\n",
            "          1.9262e-02],\n",
            "        [-1.3601e-01,  3.6996e-01, -1.2313e-01, -7.5175e-02,  1.0620e-01,\n",
            "         -1.7140e-02, -2.0478e-01,  1.6507e-01,  1.6992e-01, -1.8710e-01,\n",
            "         -8.5319e-02,  1.7251e-01, -1.3043e-01, -7.8692e-02,  8.7993e-02,\n",
            "          3.2997e-01],\n",
            "        [ 1.4066e-01,  2.7039e-01,  7.8345e-02,  4.3560e-03, -8.9926e-02,\n",
            "         -2.1856e-01, -1.5954e-01,  9.6989e-02, -1.8004e-01, -4.8655e-02,\n",
            "         -1.9452e-01,  1.6456e-01, -1.2805e-01, -2.8299e-02, -9.5108e-02,\n",
            "          9.8697e-02],\n",
            "        [-3.3657e-02, -1.2991e-01, -5.1254e-02,  2.4758e-01, -2.8556e-02,\n",
            "         -2.0687e-01,  1.3956e-01,  1.0492e-01, -5.6674e-03, -1.7589e-01,\n",
            "         -2.4190e-01,  2.4075e-01,  5.9054e-02, -2.6787e-01,  2.9471e-01,\n",
            "          2.7603e-03],\n",
            "        [-1.1087e-02,  6.0314e-04, -6.3459e-02,  1.4180e-01,  2.3976e-01,\n",
            "         -1.4449e-01, -6.0918e-02,  4.3531e-02, -1.1258e-01, -8.8200e-02,\n",
            "          1.7257e-03,  8.1709e-02,  3.0304e-03,  3.1408e-01, -1.0981e-01,\n",
            "          1.3432e-01]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([ 0.1601, -0.1017,  0.0862, -0.0541,  0.1236, -0.1477, -0.0966,  0.2217,\n",
            "        -0.2286, -0.0527, -0.2226,  0.1589,  0.1350,  0.1693,  0.1621,  0.2473],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[-0.1687,  0.2205,  0.0510, -0.1119,  0.2066,  0.0715,  0.2615, -0.1029,\n",
            "          0.0814,  0.0293, -0.0884, -0.1351, -0.1532, -0.0740,  0.1433, -0.2127]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([-0.1084], dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NN_l1_l2_reg(\n",
              "  (hidden_layers): ModuleList(\n",
              "    (0): Linear(in_features=2, out_features=16, bias=True)\n",
              "    (1): Linear(in_features=16, out_features=16, bias=True)\n",
              "  )\n",
              "  (output_layer): Linear(in_features=16, out_features=1, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b_1000 = action_probs_top_n_epsilon(q_table, 1, 0.4)\n",
        "pi_b_1000 = experiment_actions(1000, env_50, P_pi_b_1000)\n",
        "P_pi_e_1000 = action_probs_top_n_epsilon(q_table, 1, 0.05)\n",
        "pi_e_1000 = experiment_actions(1000, env_50, P_pi_e_1000)\n",
        "# model_1000_random_pi_b_1000 = CustomizableFeatureNet(input_dim=2, hidden_dims=[16, 16], output_dim=1, dtype = torch.float64, l2_lambda=0.002)\n",
        "model_1000_random_pi_b_1000 = NN_l1_l2_reg(input_dim=2, hidden_dims=[16, 16], output_dim=1, dtype = torch.float64, l1_lambda=0.0001, l2_lambda = 0.0001)\n",
        "test_1000_random_pi_b_1000 = SCOPE_straight(model_1000_random_pi_b_1000, 0.99, 10000, pi_b_1000, P_pi_b_1000, P_pi_e_1000, 0.3, dtype = torch.float64)\n",
        "test_1000_random_pi_b_1000.train_var_scope(300, 0.001, 1, 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2L-zB_Vgv_G",
        "outputId": "3dbf37cb-d0e7-45d9-e22f-4fe74b28b8b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0077, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.532842730124387\n",
            "SCOPE mean: 0.26637211052973625, SCOPE var: 0.01961388496049461\n",
            "Total Loss: 0.007724452937809946\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0062, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.66889178570887\n",
            "SCOPE mean: 0.2779599594741044, SCOPE var: 0.01972888639278707\n",
            "Total Loss: 0.006216754765374113\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0058, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.756625176817343\n",
            "SCOPE mean: 0.28679747731278044, SCOPE var: 0.01980254514010637\n",
            "Total Loss: 0.005833856841163596\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0055, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.841736123092013\n",
            "SCOPE mean: 0.29437847098774195, SCOPE var: 0.019857874002145243\n",
            "Total Loss: 0.005481698879474354\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0051, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.925202758105729\n",
            "SCOPE mean: 0.3011548168133417, SCOPE var: 0.019901458595439743\n",
            "Total Loss: 0.005148286826669336\n",
            "----------------------------------------\n",
            "Epoch 6\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0048, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.00817675237755\n",
            "SCOPE mean: 0.3074662278170667, SCOPE var: 0.019944749970638335\n",
            "Total Loss: 0.004837665699760614\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0045, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.089708154740016\n",
            "SCOPE mean: 0.3132465080377543, SCOPE var: 0.019983021212192992\n",
            "Total Loss: 0.004549107989028794\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0043, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.169934651084091\n",
            "SCOPE mean: 0.31862059814955174, SCOPE var: 0.020010089515523886\n",
            "Total Loss: 0.004274248624759886\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0040, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.250257172033944\n",
            "SCOPE mean: 0.32361237538934423, SCOPE var: 0.020024309394262665\n",
            "Total Loss: 0.004020619049663116\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0038, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.332111050078819\n",
            "SCOPE mean: 0.32793597606376707, SCOPE var: 0.0199996350498183\n",
            "Total Loss: 0.0037903829120921463\n",
            "----------------------------------------\n",
            "Epoch 11\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.414595352463161\n",
            "SCOPE mean: 0.33179311448827625, SCOPE var: 0.019960732547598132\n",
            "Total Loss: 0.0035757629974478844\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0034, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.497945396600967\n",
            "SCOPE mean: 0.33521879580209396, SCOPE var: 0.01990806246252412\n",
            "Total Loss: 0.003377755100927692\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0032, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.581457020206592\n",
            "SCOPE mean: 0.3382903111661224, SCOPE var: 0.019842891659150538\n",
            "Total Loss: 0.0031946721532874933\n",
            "----------------------------------------\n",
            "Epoch 14\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0030, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.665124002858756\n",
            "SCOPE mean: 0.3410125947113537, SCOPE var: 0.019764251983574434\n",
            "Total Loss: 0.0030283122850631797\n",
            "----------------------------------------\n",
            "Epoch 15\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0029, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.748421404723189\n",
            "SCOPE mean: 0.34337620184054046, SCOPE var: 0.01967225475341742\n",
            "Total Loss: 0.002877423062453008\n",
            "----------------------------------------\n",
            "Epoch 16\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0027, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.831664422547979\n",
            "SCOPE mean: 0.34534945796510347, SCOPE var: 0.019567461989329016\n",
            "Total Loss: 0.0027403987562111243\n",
            "----------------------------------------\n",
            "Epoch 17\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0026, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.914382410199979\n",
            "SCOPE mean: 0.34691694402007517, SCOPE var: 0.019446837977195174\n",
            "Total Loss: 0.0026166780948338165\n",
            "----------------------------------------\n",
            "Epoch 18\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0025, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.99645505805779\n",
            "SCOPE mean: 0.34803004519811565, SCOPE var: 0.019314177025303646\n",
            "Total Loss: 0.002503870300338885\n",
            "----------------------------------------\n",
            "Epoch 19\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0024, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.077773849895536\n",
            "SCOPE mean: 0.3487820032605753, SCOPE var: 0.019173070782895662\n",
            "Total Loss: 0.0024010663180383898\n",
            "----------------------------------------\n",
            "Epoch 20\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0023, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.158238236728897\n",
            "SCOPE mean: 0.34920054036858994, SCOPE var: 0.019024221492997064\n",
            "Total Loss: 0.002306159448520123\n",
            "----------------------------------------\n",
            "Epoch 21\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0022, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.237481542615162\n",
            "SCOPE mean: 0.34930930982804287, SCOPE var: 0.01886769591688255\n",
            "Total Loss: 0.002219219651566412\n",
            "----------------------------------------\n",
            "Epoch 22\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0021, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.3149133763331\n",
            "SCOPE mean: 0.3490898662083534, SCOPE var: 0.018704669026658755\n",
            "Total Loss: 0.002138323152540898\n",
            "----------------------------------------\n",
            "Epoch 23\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0021, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.390078940952563\n",
            "SCOPE mean: 0.34860705583151125, SCOPE var: 0.018537004949591467\n",
            "Total Loss: 0.0020624951205383477\n",
            "----------------------------------------\n",
            "Epoch 24\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0020, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.462689178746595\n",
            "SCOPE mean: 0.3478913211486036, SCOPE var: 0.018367081630741716\n",
            "Total Loss: 0.001991177752250327\n",
            "----------------------------------------\n",
            "Epoch 25\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0019, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.53255285799365\n",
            "SCOPE mean: 0.34695289645133276, SCOPE var: 0.018195823845062443\n",
            "Total Loss: 0.0019235936758781507\n",
            "----------------------------------------\n",
            "Epoch 26\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0019, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.600113080742775\n",
            "SCOPE mean: 0.3456392240433748, SCOPE var: 0.018020563535590815\n",
            "Total Loss: 0.0018579932800219764\n",
            "----------------------------------------\n",
            "Epoch 27\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0018, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.664585169337336\n",
            "SCOPE mean: 0.34412346663505644, SCOPE var: 0.01784435384735637\n",
            "Total Loss: 0.001795427766257168\n",
            "----------------------------------------\n",
            "Epoch 28\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0017, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.725745033555015\n",
            "SCOPE mean: 0.34241400301418073, SCOPE var: 0.01766799602768988\n",
            "Total Loss: 0.0017354088814550209\n",
            "----------------------------------------\n",
            "Epoch 29\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0017, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.783535117764025\n",
            "SCOPE mean: 0.3405268495060624, SCOPE var: 0.01749183368221607\n",
            "Total Loss: 0.0016776614780626097\n",
            "----------------------------------------\n",
            "Epoch 30\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0016, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.837646535101568\n",
            "SCOPE mean: 0.33849075663152056, SCOPE var: 0.017316835099858117\n",
            "Total Loss: 0.0016221655008095057\n",
            "----------------------------------------\n",
            "Epoch 31\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0016, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.888091571388795\n",
            "SCOPE mean: 0.33634305190695934, SCOPE var: 0.01714367704127139\n",
            "Total Loss: 0.0015693855216097204\n",
            "----------------------------------------\n",
            "Epoch 32\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0015, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.935301314878224\n",
            "SCOPE mean: 0.33405056796276383, SCOPE var: 0.016971110518671104\n",
            "Total Loss: 0.00151888817564911\n",
            "----------------------------------------\n",
            "Epoch 33\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0015, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.979017717497108\n",
            "SCOPE mean: 0.3316307085590556, SCOPE var: 0.0168002489190409\n",
            "Total Loss: 0.0014713842009702691\n",
            "----------------------------------------\n",
            "Epoch 34\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0014, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.019381276801596\n",
            "SCOPE mean: 0.32909673170250414, SCOPE var: 0.01663222908472022\n",
            "Total Loss: 0.0014263113435623574\n",
            "----------------------------------------\n",
            "Epoch 35\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0014, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.056408269443434\n",
            "SCOPE mean: 0.32656206431355933, SCOPE var: 0.016472017131427586\n",
            "Total Loss: 0.0013840057577521215\n",
            "----------------------------------------\n",
            "Epoch 36\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.090514199287222\n",
            "SCOPE mean: 0.3242686586730822, SCOPE var: 0.016339173403144558\n",
            "Total Loss: 0.0013443345378627177\n",
            "----------------------------------------\n",
            "Epoch 37\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.121986343561247\n",
            "SCOPE mean: 0.32194884623464787, SCOPE var: 0.01620903836844728\n",
            "Total Loss: 0.0013065817893595888\n",
            "----------------------------------------\n",
            "Epoch 38\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.150982635890184\n",
            "SCOPE mean: 0.31962936728090263, SCOPE var: 0.01607659045773608\n",
            "Total Loss: 0.0012705323706646077\n",
            "----------------------------------------\n",
            "Epoch 39\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.177650796710871\n",
            "SCOPE mean: 0.3173393863436806, SCOPE var: 0.015943802083156326\n",
            "Total Loss: 0.0012362824465441877\n",
            "----------------------------------------\n",
            "Epoch 40\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.202098459537286\n",
            "SCOPE mean: 0.3150475391544167, SCOPE var: 0.015815175265068582\n",
            "Total Loss: 0.0012035397595366252\n",
            "----------------------------------------\n",
            "Epoch 41\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.22435395461217\n",
            "SCOPE mean: 0.31276982154712174, SCOPE var: 0.015690319295016943\n",
            "Total Loss: 0.0011728924080751082\n",
            "----------------------------------------\n",
            "Epoch 42\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.244728475160816\n",
            "SCOPE mean: 0.3105469945142156, SCOPE var: 0.015569617592247023\n",
            "Total Loss: 0.0011442131088721503\n",
            "----------------------------------------\n",
            "Epoch 43\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.263704517072721\n",
            "SCOPE mean: 0.30838945621380215, SCOPE var: 0.015453216332895661\n",
            "Total Loss: 0.001117793177809209\n",
            "----------------------------------------\n",
            "Epoch 44\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.28136010063693\n",
            "SCOPE mean: 0.30631417945649564, SCOPE var: 0.015341057091727757\n",
            "Total Loss: 0.0010930701946824796\n",
            "----------------------------------------\n",
            "Epoch 45\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.29803441148287\n",
            "SCOPE mean: 0.3042944235142531, SCOPE var: 0.015232798720619677\n",
            "Total Loss: 0.0010697224652228105\n",
            "----------------------------------------\n",
            "Epoch 46\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.314127468025786\n",
            "SCOPE mean: 0.3023650399056866, SCOPE var: 0.015128143215216841\n",
            "Total Loss: 0.00104766246679651\n",
            "----------------------------------------\n",
            "Epoch 47\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.3298281349859\n",
            "SCOPE mean: 0.30052658636792356, SCOPE var: 0.015027051343742761\n",
            "Total Loss: 0.0010267845913042354\n",
            "----------------------------------------\n",
            "Epoch 48\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.345066697316534\n",
            "SCOPE mean: 0.298779379686587, SCOPE var: 0.014929392767972886\n",
            "Total Loss: 0.001007262568838796\n",
            "----------------------------------------\n",
            "Epoch 49\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.360560294959408\n",
            "SCOPE mean: 0.29710218321844606, SCOPE var: 0.014834928160192207\n",
            "Total Loss: 0.0009885260656215538\n",
            "----------------------------------------\n",
            "Epoch 50\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.376652261608081\n",
            "SCOPE mean: 0.2954717476810455, SCOPE var: 0.014742409315289372\n",
            "Total Loss: 0.0009706029387688266\n",
            "----------------------------------------\n",
            "Epoch 51\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.3934589646035\n",
            "SCOPE mean: 0.2938885749821533, SCOPE var: 0.014654932690857098\n",
            "Total Loss: 0.0009532536926549148\n",
            "----------------------------------------\n",
            "Epoch 52\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.410564714811695\n",
            "SCOPE mean: 0.2923600337930066, SCOPE var: 0.014569250498514902\n",
            "Total Loss: 0.000936826812074776\n",
            "----------------------------------------\n",
            "Epoch 53\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.427825199582676\n",
            "SCOPE mean: 0.29088936420171074, SCOPE var: 0.014485312163055836\n",
            "Total Loss: 0.0009209583323333354\n",
            "----------------------------------------\n",
            "Epoch 54\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.445105641420442\n",
            "SCOPE mean: 0.289475268560354, SCOPE var: 0.014403130406441\n",
            "Total Loss: 0.0009054554958838949\n",
            "----------------------------------------\n",
            "Epoch 55\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.462488541313682\n",
            "SCOPE mean: 0.2881123397057918, SCOPE var: 0.014322762994275472\n",
            "Total Loss: 0.0008903302070073347\n",
            "----------------------------------------\n",
            "Epoch 56\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.479980431905828\n",
            "SCOPE mean: 0.2868021588904755, SCOPE var: 0.014244123090458046\n",
            "Total Loss: 0.0008756755071086463\n",
            "----------------------------------------\n",
            "Epoch 57\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.497688020968068\n",
            "SCOPE mean: 0.28553288317764863, SCOPE var: 0.014167186524054185\n",
            "Total Loss: 0.0008614846592286817\n",
            "----------------------------------------\n",
            "Epoch 58\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.51565900446093\n",
            "SCOPE mean: 0.28430348636306557, SCOPE var: 0.014091965059203206\n",
            "Total Loss: 0.0008476991823849236\n",
            "----------------------------------------\n",
            "Epoch 59\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.533859854843772\n",
            "SCOPE mean: 0.28311185648066356, SCOPE var: 0.014018385814747082\n",
            "Total Loss: 0.000834121775219199\n",
            "----------------------------------------\n",
            "Epoch 60\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.55215149667331\n",
            "SCOPE mean: 0.28195321557000974, SCOPE var: 0.013946308507096532\n",
            "Total Loss: 0.0008208992907556161\n",
            "----------------------------------------\n",
            "Epoch 61\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.57072284540384\n",
            "SCOPE mean: 0.2808104175620723, SCOPE var: 0.013874884449276462\n",
            "Total Loss: 0.0008080047980080957\n",
            "----------------------------------------\n",
            "Epoch 62\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.589524688426872\n",
            "SCOPE mean: 0.279683403897832, SCOPE var: 0.01380417530301233\n",
            "Total Loss: 0.0007953888104321636\n",
            "----------------------------------------\n",
            "Epoch 63\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.60848392909624\n",
            "SCOPE mean: 0.2785751492303853, SCOPE var: 0.01373417509899874\n",
            "Total Loss: 0.0007830803652687093\n",
            "----------------------------------------\n",
            "Epoch 64\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.627553497559829\n",
            "SCOPE mean: 0.27748279981880897, SCOPE var: 0.01366494486599389\n",
            "Total Loss: 0.0007710869955882991\n",
            "----------------------------------------\n",
            "Epoch 65\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.64661895825108\n",
            "SCOPE mean: 0.27640896611015336, SCOPE var: 0.013596560114399617\n",
            "Total Loss: 0.0007596620241902782\n",
            "----------------------------------------\n",
            "Epoch 66\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.665756196464057\n",
            "SCOPE mean: 0.27535818928227873, SCOPE var: 0.013529107273207828\n",
            "Total Loss: 0.0007486213786981659\n",
            "----------------------------------------\n",
            "Epoch 67\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.6848004989946\n",
            "SCOPE mean: 0.27435121342822144, SCOPE var: 0.013462221319705392\n",
            "Total Loss: 0.0007379114931532187\n",
            "----------------------------------------\n",
            "Epoch 68\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.703695140158036\n",
            "SCOPE mean: 0.27337308258918575, SCOPE var: 0.013396271885138509\n",
            "Total Loss: 0.0007275457223248017\n",
            "----------------------------------------\n",
            "Epoch 69\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.72247710072112\n",
            "SCOPE mean: 0.272408916477984, SCOPE var: 0.013331650833984068\n",
            "Total Loss: 0.0007177876908608927\n",
            "----------------------------------------\n",
            "Epoch 70\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.741226813116239\n",
            "SCOPE mean: 0.2714469930587486, SCOPE var: 0.01326850316328805\n",
            "Total Loss: 0.0007082725944454392\n",
            "----------------------------------------\n",
            "Epoch 71\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.759638776756317\n",
            "SCOPE mean: 0.2704360655561803, SCOPE var: 0.013208311963364043\n",
            "Total Loss: 0.0006989024655312685\n",
            "----------------------------------------\n",
            "Epoch 72\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.777558097167713\n",
            "SCOPE mean: 0.2694619539911354, SCOPE var: 0.013150969770216712\n",
            "Total Loss: 0.0006895783277494997\n",
            "----------------------------------------\n",
            "Epoch 73\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.794871086985918\n",
            "SCOPE mean: 0.26856935721004116, SCOPE var: 0.013095443340711702\n",
            "Total Loss: 0.0006802539587432203\n",
            "----------------------------------------\n",
            "Epoch 74\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.811653150745114\n",
            "SCOPE mean: 0.267714777824609, SCOPE var: 0.013041570505228946\n",
            "Total Loss: 0.0006710198640484653\n",
            "----------------------------------------\n",
            "Epoch 75\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.827877867164917\n",
            "SCOPE mean: 0.266894311497125, SCOPE var: 0.012989199263665124\n",
            "Total Loss: 0.0006618900629954999\n",
            "----------------------------------------\n",
            "Epoch 76\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.843628841451137\n",
            "SCOPE mean: 0.266102865075085, SCOPE var: 0.012938219559593409\n",
            "Total Loss: 0.0006532274732304353\n",
            "----------------------------------------\n",
            "Epoch 77\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.858795658545548\n",
            "SCOPE mean: 0.26532899862173487, SCOPE var: 0.012888290150455695\n",
            "Total Loss: 0.0006447318196686526\n",
            "----------------------------------------\n",
            "Epoch 78\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.87339867860696\n",
            "SCOPE mean: 0.2645653190498459, SCOPE var: 0.01283929216604609\n",
            "Total Loss: 0.0006364138244095278\n",
            "----------------------------------------\n",
            "Epoch 79\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.887712041427172\n",
            "SCOPE mean: 0.26379290301985225, SCOPE var: 0.012790441552983657\n",
            "Total Loss: 0.0006283795205076522\n",
            "----------------------------------------\n",
            "Epoch 80\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.901797675944803\n",
            "SCOPE mean: 0.2630050102500645, SCOPE var: 0.012741664960040476\n",
            "Total Loss: 0.0006204876522103877\n",
            "----------------------------------------\n",
            "Epoch 81\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.91560057850136\n",
            "SCOPE mean: 0.2622112921485064, SCOPE var: 0.012693338732045034\n",
            "Total Loss: 0.0006128455421859303\n",
            "----------------------------------------\n",
            "Epoch 82\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.929163172122536\n",
            "SCOPE mean: 0.2614145171745666, SCOPE var: 0.012645434013753896\n",
            "Total Loss: 0.0006054476344865624\n",
            "----------------------------------------\n",
            "Epoch 83\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.94242347043985\n",
            "SCOPE mean: 0.26061703445278384, SCOPE var: 0.012598074200574497\n",
            "Total Loss: 0.0005982484525301818\n",
            "----------------------------------------\n",
            "Epoch 84\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.955330127653927\n",
            "SCOPE mean: 0.2598199714069318, SCOPE var: 0.012551352074092314\n",
            "Total Loss: 0.0005911788098430702\n",
            "----------------------------------------\n",
            "Epoch 85\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.968081494698804\n",
            "SCOPE mean: 0.2590200035084922, SCOPE var: 0.012504824419405342\n",
            "Total Loss: 0.0005841720599929842\n",
            "----------------------------------------\n",
            "Epoch 86\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.980846579315926\n",
            "SCOPE mean: 0.2581993302255017, SCOPE var: 0.012457918763995811\n",
            "Total Loss: 0.0005773163537441064\n",
            "----------------------------------------\n",
            "Epoch 87\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.993746412793852\n",
            "SCOPE mean: 0.2573666567318422, SCOPE var: 0.012410842336076018\n",
            "Total Loss: 0.0005705640674446269\n",
            "----------------------------------------\n",
            "Epoch 88\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.006807345336304\n",
            "SCOPE mean: 0.25652317563584986, SCOPE var: 0.01236365474768873\n",
            "Total Loss: 0.0005639184518677803\n",
            "----------------------------------------\n",
            "Epoch 89\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.0198910826009\n",
            "SCOPE mean: 0.255752500528988, SCOPE var: 0.012317095971088555\n",
            "Total Loss: 0.0005573857060419217\n",
            "----------------------------------------\n",
            "Epoch 90\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.03298833418527\n",
            "SCOPE mean: 0.2550176936581327, SCOPE var: 0.012271382767396652\n",
            "Total Loss: 0.000550956832002427\n",
            "----------------------------------------\n",
            "Epoch 91\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.046193053531722\n",
            "SCOPE mean: 0.25428750570489117, SCOPE var: 0.012226405548249672\n",
            "Total Loss: 0.0005446275254114706\n",
            "----------------------------------------\n",
            "Epoch 92\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.05952546216882\n",
            "SCOPE mean: 0.2535593725501777, SCOPE var: 0.012182026518473577\n",
            "Total Loss: 0.0005383943555819563\n",
            "----------------------------------------\n",
            "Epoch 93\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.072971410743524\n",
            "SCOPE mean: 0.252838282306041, SCOPE var: 0.012138352071805717\n",
            "Total Loss: 0.0005322821189980937\n",
            "----------------------------------------\n",
            "Epoch 94\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.086550084844003\n",
            "SCOPE mean: 0.25212381090539737, SCOPE var: 0.012095261301942741\n",
            "Total Loss: 0.000526251572927109\n",
            "----------------------------------------\n",
            "Epoch 95\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.100321450959594\n",
            "SCOPE mean: 0.25140936907451694, SCOPE var: 0.012052555803019189\n",
            "Total Loss: 0.0005202220512284169\n",
            "----------------------------------------\n",
            "Epoch 96\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.114261418978497\n",
            "SCOPE mean: 0.25067479187872505, SCOPE var: 0.0120099376474106\n",
            "Total Loss: 0.0005142480360709055\n",
            "----------------------------------------\n",
            "Epoch 97\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.128239052215603\n",
            "SCOPE mean: 0.24986171028747914, SCOPE var: 0.011967348085343997\n",
            "Total Loss: 0.000508334985409771\n",
            "----------------------------------------\n",
            "Epoch 98\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.142445615538726\n",
            "SCOPE mean: 0.24901914101981826, SCOPE var: 0.011924043813280214\n",
            "Total Loss: 0.000502527298204602\n",
            "----------------------------------------\n",
            "Epoch 99\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.156947994173692\n",
            "SCOPE mean: 0.24814201088172025, SCOPE var: 0.011879838431611271\n",
            "Total Loss: 0.0004970081409500349\n",
            "----------------------------------------\n",
            "Epoch 100\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.17142943056542\n",
            "SCOPE mean: 0.24724406205597332, SCOPE var: 0.011834992509185939\n",
            "Total Loss: 0.0004916202005714088\n",
            "----------------------------------------\n",
            "Epoch 101\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.185861427378741\n",
            "SCOPE mean: 0.24635192617727333, SCOPE var: 0.011790087981065175\n",
            "Total Loss: 0.00048626188324880877\n",
            "----------------------------------------\n",
            "Epoch 102\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.199944978034345\n",
            "SCOPE mean: 0.2454693742377103, SCOPE var: 0.01174553434598531\n",
            "Total Loss: 0.00048093212718034747\n",
            "----------------------------------------\n",
            "Epoch 103\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.213677267949087\n",
            "SCOPE mean: 0.24459776933439958, SCOPE var: 0.011700252671703888\n",
            "Total Loss: 0.00047564658186976177\n",
            "----------------------------------------\n",
            "Epoch 104\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.227076321827589\n",
            "SCOPE mean: 0.24374288582592898, SCOPE var: 0.011655459026580734\n",
            "Total Loss: 0.0004703561282125067\n",
            "----------------------------------------\n",
            "Epoch 105\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.240189933743423\n",
            "SCOPE mean: 0.2428963269094097, SCOPE var: 0.011611191666397703\n",
            "Total Loss: 0.0004651340131458716\n",
            "----------------------------------------\n",
            "Epoch 106\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.25315194515043\n",
            "SCOPE mean: 0.2420606443517043, SCOPE var: 0.011567595072379025\n",
            "Total Loss: 0.0004599912683281109\n",
            "----------------------------------------\n",
            "Epoch 107\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.265933584433709\n",
            "SCOPE mean: 0.24124151672813945, SCOPE var: 0.011524757826002563\n",
            "Total Loss: 0.00045494456225939067\n",
            "----------------------------------------\n",
            "Epoch 108\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.278837389586906\n",
            "SCOPE mean: 0.24035484214296784, SCOPE var: 0.01148282466827701\n",
            "Total Loss: 0.0004500273131148163\n",
            "----------------------------------------\n",
            "Epoch 109\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.291894481696264\n",
            "SCOPE mean: 0.23943129208406336, SCOPE var: 0.011441811621997694\n",
            "Total Loss: 0.0004451406138358404\n",
            "----------------------------------------\n",
            "Epoch 110\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.30502603901099\n",
            "SCOPE mean: 0.23852383936920604, SCOPE var: 0.011401740928828653\n",
            "Total Loss: 0.00044025029127044363\n",
            "----------------------------------------\n",
            "Epoch 111\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.318210803765483\n",
            "SCOPE mean: 0.23763240929248805, SCOPE var: 0.01136258000172001\n",
            "Total Loss: 0.00043542235368987717\n",
            "----------------------------------------\n",
            "Epoch 112\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.331721466903637\n",
            "SCOPE mean: 0.23675062166641242, SCOPE var: 0.011323971268646787\n",
            "Total Loss: 0.00043067646080465513\n",
            "----------------------------------------\n",
            "Epoch 113\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.345077648865587\n",
            "SCOPE mean: 0.2358725184328937, SCOPE var: 0.011285600341207763\n",
            "Total Loss: 0.00042605825150273963\n",
            "----------------------------------------\n",
            "Epoch 114\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.35818726786822\n",
            "SCOPE mean: 0.23500160092786845, SCOPE var: 0.01124745818985856\n",
            "Total Loss: 0.00042151872901577213\n",
            "----------------------------------------\n",
            "Epoch 115\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.371065511608576\n",
            "SCOPE mean: 0.23413976721718377, SCOPE var: 0.01120962127938465\n",
            "Total Loss: 0.00041703394666255133\n",
            "----------------------------------------\n",
            "Epoch 116\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.383716126973896\n",
            "SCOPE mean: 0.23328914585036414, SCOPE var: 0.01117224004016129\n",
            "Total Loss: 0.0004125776840663724\n",
            "----------------------------------------\n",
            "Epoch 117\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.396123915229385\n",
            "SCOPE mean: 0.23245252296891258, SCOPE var: 0.011135416155930453\n",
            "Total Loss: 0.0004081937864847242\n",
            "----------------------------------------\n",
            "Epoch 118\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.408207141909616\n",
            "SCOPE mean: 0.2316315707790004, SCOPE var: 0.011099252060934931\n",
            "Total Loss: 0.00040387110809592846\n",
            "----------------------------------------\n",
            "Epoch 119\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.420120281758527\n",
            "SCOPE mean: 0.23082449904533786, SCOPE var: 0.011063777484846993\n",
            "Total Loss: 0.00039964137615371056\n",
            "----------------------------------------\n",
            "Epoch 120\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.432397301770626\n",
            "SCOPE mean: 0.23004912422500626, SCOPE var: 0.011030219837460813\n",
            "Total Loss: 0.00039545430565755867\n",
            "----------------------------------------\n",
            "Epoch 121\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.444819877183338\n",
            "SCOPE mean: 0.2292996798137163, SCOPE var: 0.010998826222681663\n",
            "Total Loss: 0.00039133907387079787\n",
            "----------------------------------------\n",
            "Epoch 122\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.45748502215642\n",
            "SCOPE mean: 0.22854716702547206, SCOPE var: 0.010967695002560783\n",
            "Total Loss: 0.000387238293714366\n",
            "----------------------------------------\n",
            "Epoch 123\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.470021062245255\n",
            "SCOPE mean: 0.22779132424408613, SCOPE var: 0.010936696873236274\n",
            "Total Loss: 0.00038324781193409767\n",
            "----------------------------------------\n",
            "Epoch 124\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.482233448465172\n",
            "SCOPE mean: 0.22704302582437164, SCOPE var: 0.010906187305448768\n",
            "Total Loss: 0.00037938259806184575\n",
            "----------------------------------------\n",
            "Epoch 125\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.494067937980594\n",
            "SCOPE mean: 0.22630410506363652, SCOPE var: 0.01087608987139497\n",
            "Total Loss: 0.00037557306794192653\n",
            "----------------------------------------\n",
            "Epoch 126\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.505723546485862\n",
            "SCOPE mean: 0.22556576444841198, SCOPE var: 0.010847668550244589\n",
            "Total Loss: 0.00037176187145287256\n",
            "----------------------------------------\n",
            "Epoch 127\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.517203980813607\n",
            "SCOPE mean: 0.2248214896451119, SCOPE var: 0.010819911935533543\n",
            "Total Loss: 0.00036801855906837375\n",
            "----------------------------------------\n",
            "Epoch 128\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.528834573772825\n",
            "SCOPE mean: 0.2240712868289352, SCOPE var: 0.01079217912612868\n",
            "Total Loss: 0.000364305519958391\n",
            "----------------------------------------\n",
            "Epoch 129\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.540465024599579\n",
            "SCOPE mean: 0.22330961507445996, SCOPE var: 0.010764478150491781\n",
            "Total Loss: 0.0003607193456220284\n",
            "----------------------------------------\n",
            "Epoch 130\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.55219321509274\n",
            "SCOPE mean: 0.22253844370552597, SCOPE var: 0.01073680506822766\n",
            "Total Loss: 0.0003572345801338723\n",
            "----------------------------------------\n",
            "Epoch 131\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.563979218529926\n",
            "SCOPE mean: 0.22176036522619041, SCOPE var: 0.01070921603925241\n",
            "Total Loss: 0.00035381239578279256\n",
            "----------------------------------------\n",
            "Epoch 132\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.575714974514561\n",
            "SCOPE mean: 0.22098903145538198, SCOPE var: 0.010682249607795721\n",
            "Total Loss: 0.0003504428775900698\n",
            "----------------------------------------\n",
            "Epoch 133\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.587404881292008\n",
            "SCOPE mean: 0.22022952293518452, SCOPE var: 0.010655899225883027\n",
            "Total Loss: 0.0003471403408699485\n",
            "----------------------------------------\n",
            "Epoch 134\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.599416589774968\n",
            "SCOPE mean: 0.21949049006814061, SCOPE var: 0.010630328867265471\n",
            "Total Loss: 0.000343857182025591\n",
            "----------------------------------------\n",
            "Epoch 135\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.611245665569815\n",
            "SCOPE mean: 0.21876854769614237, SCOPE var: 0.010605306511473775\n",
            "Total Loss: 0.00034066758350817365\n",
            "----------------------------------------\n",
            "Epoch 136\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.622899999137651\n",
            "SCOPE mean: 0.21806389091005968, SCOPE var: 0.01058074538092218\n",
            "Total Loss: 0.0003375261679725185\n",
            "----------------------------------------\n",
            "Epoch 137\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.634275069280157\n",
            "SCOPE mean: 0.2173775103066127, SCOPE var: 0.010556682336596583\n",
            "Total Loss: 0.00033443906206178883\n",
            "----------------------------------------\n",
            "Epoch 138\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.645327581400998\n",
            "SCOPE mean: 0.21671872053538419, SCOPE var: 0.010533149609154852\n",
            "Total Loss: 0.00033140645366005886\n",
            "----------------------------------------\n",
            "Epoch 139\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.656188638016566\n",
            "SCOPE mean: 0.21608402607910512, SCOPE var: 0.010510093620811251\n",
            "Total Loss: 0.0003284309498614266\n",
            "----------------------------------------\n",
            "Epoch 140\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.666874142868897\n",
            "SCOPE mean: 0.21547203146692176, SCOPE var: 0.010487592688542203\n",
            "Total Loss: 0.000325516263504154\n",
            "----------------------------------------\n",
            "Epoch 141\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.677725185592175\n",
            "SCOPE mean: 0.2148733053394491, SCOPE var: 0.010465429691380042\n",
            "Total Loss: 0.0003226603758443502\n",
            "----------------------------------------\n",
            "Epoch 142\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.688456739921692\n",
            "SCOPE mean: 0.21429857271959418, SCOPE var: 0.010443689169456523\n",
            "Total Loss: 0.000319834085962968\n",
            "----------------------------------------\n",
            "Epoch 143\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.699083748327332\n",
            "SCOPE mean: 0.21374691584221772, SCOPE var: 0.01042203096874522\n",
            "Total Loss: 0.0003170684258678984\n",
            "----------------------------------------\n",
            "Epoch 144\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.709619619727727\n",
            "SCOPE mean: 0.2132083061732246, SCOPE var: 0.010400037689705634\n",
            "Total Loss: 0.00031435012105497293\n",
            "----------------------------------------\n",
            "Epoch 145\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.720091481432052\n",
            "SCOPE mean: 0.21267747717465318, SCOPE var: 0.0103779288393126\n",
            "Total Loss: 0.00031166872522315385\n",
            "----------------------------------------\n",
            "Epoch 146\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.73041606098799\n",
            "SCOPE mean: 0.2121510016135152, SCOPE var: 0.010355809820375298\n",
            "Total Loss: 0.000309060514923397\n",
            "----------------------------------------\n",
            "Epoch 147\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.740848648940974\n",
            "SCOPE mean: 0.2116260151934184, SCOPE var: 0.010333735265734532\n",
            "Total Loss: 0.0003064835090542152\n",
            "----------------------------------------\n",
            "Epoch 148\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.751318589377833\n",
            "SCOPE mean: 0.21110405172275745, SCOPE var: 0.010312096637249739\n",
            "Total Loss: 0.0003039561717484568\n",
            "----------------------------------------\n",
            "Epoch 149\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.762172625747217\n",
            "SCOPE mean: 0.21054691054555133, SCOPE var: 0.010290329663106485\n",
            "Total Loss: 0.0003015086061042565\n",
            "----------------------------------------\n",
            "Epoch 150\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.773247475092408\n",
            "SCOPE mean: 0.2099583948448261, SCOPE var: 0.010267884171300774\n",
            "Total Loss: 0.000299090416288571\n",
            "----------------------------------------\n",
            "Epoch 151\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.784310739952755\n",
            "SCOPE mean: 0.20934877754817793, SCOPE var: 0.010244930353099282\n",
            "Total Loss: 0.0002966824563115052\n",
            "----------------------------------------\n",
            "Epoch 152\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.795027854310792\n",
            "SCOPE mean: 0.20872914884702176, SCOPE var: 0.010221624550456825\n",
            "Total Loss: 0.0002942667950490483\n",
            "----------------------------------------\n",
            "Epoch 153\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.805664912861573\n",
            "SCOPE mean: 0.20810104289419223, SCOPE var: 0.010198094790785801\n",
            "Total Loss: 0.00029189857254089703\n",
            "----------------------------------------\n",
            "Epoch 154\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.81619492677441\n",
            "SCOPE mean: 0.20746716574670196, SCOPE var: 0.01017442617735155\n",
            "Total Loss: 0.0002895777294820825\n",
            "----------------------------------------\n",
            "Epoch 155\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.826403681239075\n",
            "SCOPE mean: 0.20686385932297338, SCOPE var: 0.010151413383426535\n",
            "Total Loss: 0.00028728426798812763\n",
            "----------------------------------------\n",
            "Epoch 156\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.836284495098498\n",
            "SCOPE mean: 0.20629168474891127, SCOPE var: 0.010129048564291556\n",
            "Total Loss: 0.00028503201149445063\n",
            "----------------------------------------\n",
            "Epoch 157\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.846066671048693\n",
            "SCOPE mean: 0.20574196884787552, SCOPE var: 0.01010714970409182\n",
            "Total Loss: 0.0002828126420337229\n",
            "----------------------------------------\n",
            "Epoch 158\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.855647402962008\n",
            "SCOPE mean: 0.20520858347896337, SCOPE var: 0.010085601513424504\n",
            "Total Loss: 0.0002806295993529656\n",
            "----------------------------------------\n",
            "Epoch 159\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.86515135442456\n",
            "SCOPE mean: 0.2046880428944395, SCOPE var: 0.010064398251494218\n",
            "Total Loss: 0.0002784787558959462\n",
            "----------------------------------------\n",
            "Epoch 160\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.874470417914765\n",
            "SCOPE mean: 0.20418098399669402, SCOPE var: 0.010043506309976542\n",
            "Total Loss: 0.0002763521227985875\n",
            "----------------------------------------\n",
            "Epoch 161\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.883634910799202\n",
            "SCOPE mean: 0.20368470811982992, SCOPE var: 0.01002289009488119\n",
            "Total Loss: 0.00027424323485642323\n",
            "----------------------------------------\n",
            "Epoch 162\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.892697168332807\n",
            "SCOPE mean: 0.20319741178279208, SCOPE var: 0.010002516036639597\n",
            "Total Loss: 0.00027215925666933575\n",
            "----------------------------------------\n",
            "Epoch 163\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.901556925702032\n",
            "SCOPE mean: 0.20272509099558672, SCOPE var: 0.009982471557565358\n",
            "Total Loss: 0.0002700972505366208\n",
            "----------------------------------------\n",
            "Epoch 164\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.910245360934738\n",
            "SCOPE mean: 0.20226375598000754, SCOPE var: 0.009962686143350526\n",
            "Total Loss: 0.0002680780831123279\n",
            "----------------------------------------\n",
            "Epoch 165\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.919026871217829\n",
            "SCOPE mean: 0.2018135757624099, SCOPE var: 0.009943174908880444\n",
            "Total Loss: 0.00026609341750336973\n",
            "----------------------------------------\n",
            "Epoch 166\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.92815192252451\n",
            "SCOPE mean: 0.2013466363703602, SCOPE var: 0.009923301624009315\n",
            "Total Loss: 0.0002641247394568174\n",
            "----------------------------------------\n",
            "Epoch 167\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.937492088171235\n",
            "SCOPE mean: 0.20085831884452168, SCOPE var: 0.00990289930502821\n",
            "Total Loss: 0.0002621779032134004\n",
            "----------------------------------------\n",
            "Epoch 168\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.94690638893009\n",
            "SCOPE mean: 0.20035104863851516, SCOPE var: 0.009882023117696797\n",
            "Total Loss: 0.00026025458942182604\n",
            "----------------------------------------\n",
            "Epoch 169\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.956352894858648\n",
            "SCOPE mean: 0.19982760309706346, SCOPE var: 0.009860723773376328\n",
            "Total Loss: 0.00025837152979783627\n",
            "----------------------------------------\n",
            "Epoch 170\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.965594924607377\n",
            "SCOPE mean: 0.19931878530832453, SCOPE var: 0.009839680365701636\n",
            "Total Loss: 0.00025650060189240674\n",
            "----------------------------------------\n",
            "Epoch 171\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.974670961640653\n",
            "SCOPE mean: 0.19881764142683095, SCOPE var: 0.009818778044825572\n",
            "Total Loss: 0.0002546977422642193\n",
            "----------------------------------------\n",
            "Epoch 172\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.983358988771448\n",
            "SCOPE mean: 0.1983172194933383, SCOPE var: 0.009797973189469917\n",
            "Total Loss: 0.0002528982086408787\n",
            "----------------------------------------\n",
            "Epoch 173\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.991695242251703\n",
            "SCOPE mean: 0.19781699666869548, SCOPE var: 0.009777250035255702\n",
            "Total Loss: 0.0002511126613731517\n",
            "----------------------------------------\n",
            "Epoch 174\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.000013896956162\n",
            "SCOPE mean: 0.19731652109729553, SCOPE var: 0.009756616595053896\n",
            "Total Loss: 0.00024934763034574513\n",
            "----------------------------------------\n",
            "Epoch 175\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.008258414707868\n",
            "SCOPE mean: 0.1968135042899445, SCOPE var: 0.009735982585620135\n",
            "Total Loss: 0.0002476053081309932\n",
            "----------------------------------------\n",
            "Epoch 176\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.016431556352858\n",
            "SCOPE mean: 0.19630792468687347, SCOPE var: 0.00971534285596676\n",
            "Total Loss: 0.0002458842508273788\n",
            "----------------------------------------\n",
            "Epoch 177\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.024647424884755\n",
            "SCOPE mean: 0.19581319582749196, SCOPE var: 0.009694879815603413\n",
            "Total Loss: 0.0002441860108165254\n",
            "----------------------------------------\n",
            "Epoch 178\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.032870226279334\n",
            "SCOPE mean: 0.19532571378580166, SCOPE var: 0.009674486683560121\n",
            "Total Loss: 0.00024249928981629916\n",
            "----------------------------------------\n",
            "Epoch 179\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.041078376940513\n",
            "SCOPE mean: 0.1948443598943637, SCOPE var: 0.00965407628627757\n",
            "Total Loss: 0.0002408185448644786\n",
            "----------------------------------------\n",
            "Epoch 180\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.049273624907242\n",
            "SCOPE mean: 0.19437648356435183, SCOPE var: 0.009633857935992944\n",
            "Total Loss: 0.0002391506354491363\n",
            "----------------------------------------\n",
            "Epoch 181\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.057552407857315\n",
            "SCOPE mean: 0.19391880303963085, SCOPE var: 0.009613801141593844\n",
            "Total Loss: 0.00023750035802941362\n",
            "----------------------------------------\n",
            "Epoch 182\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.065924811482446\n",
            "SCOPE mean: 0.19346005364305935, SCOPE var: 0.009593772820604555\n",
            "Total Loss: 0.00023587706167031017\n",
            "----------------------------------------\n",
            "Epoch 183\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.074210671821483\n",
            "SCOPE mean: 0.19300185569051134, SCOPE var: 0.00957378161574907\n",
            "Total Loss: 0.00023427113579480426\n",
            "----------------------------------------\n",
            "Epoch 184\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.08245739774653\n",
            "SCOPE mean: 0.19254301569517332, SCOPE var: 0.009553812011446412\n",
            "Total Loss: 0.00023267552647777018\n",
            "----------------------------------------\n",
            "Epoch 185\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.090686044132884\n",
            "SCOPE mean: 0.19208245063674012, SCOPE var: 0.00953385700742282\n",
            "Total Loss: 0.00023110289122849406\n",
            "----------------------------------------\n",
            "Epoch 186\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.098926687645509\n",
            "SCOPE mean: 0.1916196297511633, SCOPE var: 0.009513985101672956\n",
            "Total Loss: 0.00022954565151813236\n",
            "----------------------------------------\n",
            "Epoch 187\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.107100684128634\n",
            "SCOPE mean: 0.1911608159704689, SCOPE var: 0.00949430120960841\n",
            "Total Loss: 0.000228017915792795\n",
            "----------------------------------------\n",
            "Epoch 188\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.115394986737678\n",
            "SCOPE mean: 0.19070404074281783, SCOPE var: 0.009474442223767997\n",
            "Total Loss: 0.00022652319159459808\n",
            "----------------------------------------\n",
            "Epoch 189\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.123370672231745\n",
            "SCOPE mean: 0.19025837495722608, SCOPE var: 0.009454892868533977\n",
            "Total Loss: 0.00022502654244525074\n",
            "----------------------------------------\n",
            "Epoch 190\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.13104358825839\n",
            "SCOPE mean: 0.18982220313292378, SCOPE var: 0.009435676339644124\n",
            "Total Loss: 0.00022356389863159356\n",
            "----------------------------------------\n",
            "Epoch 191\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.138812391237666\n",
            "SCOPE mean: 0.1893953053778192, SCOPE var: 0.009416529251747721\n",
            "Total Loss: 0.00022216554066438186\n",
            "----------------------------------------\n",
            "Epoch 192\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.146679020084294\n",
            "SCOPE mean: 0.18897891165058736, SCOPE var: 0.00939765444778406\n",
            "Total Loss: 0.00022077629379703363\n",
            "----------------------------------------\n",
            "Epoch 193\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.154637770413052\n",
            "SCOPE mean: 0.18855735953998354, SCOPE var: 0.009378712842238322\n",
            "Total Loss: 0.00021940419999265465\n",
            "----------------------------------------\n",
            "Epoch 194\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.16243773475072\n",
            "SCOPE mean: 0.18813325030356892, SCOPE var: 0.009359781983539189\n",
            "Total Loss: 0.00021805264089203578\n",
            "----------------------------------------\n",
            "Epoch 195\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.170050231008064\n",
            "SCOPE mean: 0.18774316689102422, SCOPE var: 0.009340884327632349\n",
            "Total Loss: 0.00021670849547728832\n",
            "----------------------------------------\n",
            "Epoch 196\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.177371892699169\n",
            "SCOPE mean: 0.18738141730674424, SCOPE var: 0.0093220335466322\n",
            "Total Loss: 0.00021538047979503255\n",
            "----------------------------------------\n",
            "Epoch 197\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.18422456728959\n",
            "SCOPE mean: 0.18702926144072, SCOPE var: 0.009303424545857586\n",
            "Total Loss: 0.00021405461881519538\n",
            "----------------------------------------\n",
            "Epoch 198\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.190927418608837\n",
            "SCOPE mean: 0.1866645518327437, SCOPE var: 0.009284698253773505\n",
            "Total Loss: 0.00021275489086363753\n",
            "----------------------------------------\n",
            "Epoch 199\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.197972035783456\n",
            "SCOPE mean: 0.18627427805944813, SCOPE var: 0.00926572120131269\n",
            "Total Loss: 0.00021145670071354077\n",
            "----------------------------------------\n",
            "Epoch 200\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.205041595604202\n",
            "SCOPE mean: 0.18588251428951466, SCOPE var: 0.009246858232205534\n",
            "Total Loss: 0.00021017260175489446\n",
            "----------------------------------------\n",
            "Epoch 201\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.212244973900166\n",
            "SCOPE mean: 0.18549035334552066, SCOPE var: 0.009228085295128311\n",
            "Total Loss: 0.0002089087301926109\n",
            "----------------------------------------\n",
            "Epoch 202\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.219566971769247\n",
            "SCOPE mean: 0.18508987128991503, SCOPE var: 0.009209353966102824\n",
            "Total Loss: 0.00020764789786994057\n",
            "----------------------------------------\n",
            "Epoch 203\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.227045286936299\n",
            "SCOPE mean: 0.1846893841608925, SCOPE var: 0.009190860933398638\n",
            "Total Loss: 0.00020638992529386352\n",
            "----------------------------------------\n",
            "Epoch 204\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.234587709156951\n",
            "SCOPE mean: 0.18429911117326397, SCOPE var: 0.00917262055938636\n",
            "Total Loss: 0.0002051575019090872\n",
            "----------------------------------------\n",
            "Epoch 205\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.242054175249297\n",
            "SCOPE mean: 0.18392373906321927, SCOPE var: 0.009154708285692693\n",
            "Total Loss: 0.00020394075768363553\n",
            "----------------------------------------\n",
            "Epoch 206\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.24924269001387\n",
            "SCOPE mean: 0.18354901863857834, SCOPE var: 0.009136995150638514\n",
            "Total Loss: 0.00020269454035375242\n",
            "----------------------------------------\n",
            "Epoch 207\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.256274668403798\n",
            "SCOPE mean: 0.1831697594343403, SCOPE var: 0.009119346514580575\n",
            "Total Loss: 0.00020143952235109514\n",
            "----------------------------------------\n",
            "Epoch 208\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.263195232812892\n",
            "SCOPE mean: 0.18279330792644746, SCOPE var: 0.009101862927171028\n",
            "Total Loss: 0.0002001857044146246\n",
            "----------------------------------------\n",
            "Epoch 209\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.27006877999771\n",
            "SCOPE mean: 0.18242449755199622, SCOPE var: 0.009084580607942481\n",
            "Total Loss: 0.00019895384883287753\n",
            "----------------------------------------\n",
            "Epoch 210\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.277112063114615\n",
            "SCOPE mean: 0.18205431114291856, SCOPE var: 0.009067309139682464\n",
            "Total Loss: 0.0001977528294268773\n",
            "----------------------------------------\n",
            "Epoch 211\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.284151659222138\n",
            "SCOPE mean: 0.18170441772404533, SCOPE var: 0.009050503179597992\n",
            "Total Loss: 0.000196565773811577\n",
            "----------------------------------------\n",
            "Epoch 212\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.291257039522621\n",
            "SCOPE mean: 0.18138433314325061, SCOPE var: 0.009034226724206616\n",
            "Total Loss: 0.00019538073044092385\n",
            "----------------------------------------\n",
            "Epoch 213\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.29830216528923\n",
            "SCOPE mean: 0.18109136579451843, SCOPE var: 0.009018369270286767\n",
            "Total Loss: 0.0001941887714465\n",
            "----------------------------------------\n",
            "Epoch 214\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.305281446526342\n",
            "SCOPE mean: 0.1808162679626717, SCOPE var: 0.009002782529865966\n",
            "Total Loss: 0.00019300288216021356\n",
            "----------------------------------------\n",
            "Epoch 215\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.312050444833591\n",
            "SCOPE mean: 0.1805511200687608, SCOPE var: 0.008987488574114402\n",
            "Total Loss: 0.00019181168277660078\n",
            "----------------------------------------\n",
            "Epoch 216\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.318732434609261\n",
            "SCOPE mean: 0.18029907977954532, SCOPE var: 0.008972551326972455\n",
            "Total Loss: 0.00019061909531274557\n",
            "----------------------------------------\n",
            "Epoch 217\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.325267190184618\n",
            "SCOPE mean: 0.1800663529079724, SCOPE var: 0.008957880490070817\n",
            "Total Loss: 0.00018943940412066102\n",
            "----------------------------------------\n",
            "Epoch 218\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.331871355573382\n",
            "SCOPE mean: 0.17983383262704564, SCOPE var: 0.00894314632635735\n",
            "Total Loss: 0.0001882428178666038\n",
            "----------------------------------------\n",
            "Epoch 219\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.338672190985962\n",
            "SCOPE mean: 0.179598321727422, SCOPE var: 0.008928358827485635\n",
            "Total Loss: 0.00018704898888603316\n",
            "----------------------------------------\n",
            "Epoch 220\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.345706429454982\n",
            "SCOPE mean: 0.17936857230466133, SCOPE var: 0.008913536777325929\n",
            "Total Loss: 0.00018587335773928012\n",
            "----------------------------------------\n",
            "Epoch 221\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.352809371533825\n",
            "SCOPE mean: 0.1791280985065613, SCOPE var: 0.008898517298833253\n",
            "Total Loss: 0.0001847621942938464\n",
            "----------------------------------------\n",
            "Epoch 222\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.359709296363697\n",
            "SCOPE mean: 0.17887169439622944, SCOPE var: 0.008883390494951236\n",
            "Total Loss: 0.00018366630845520655\n",
            "----------------------------------------\n",
            "Epoch 223\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.366440997565293\n",
            "SCOPE mean: 0.17859906477427415, SCOPE var: 0.008868204523754964\n",
            "Total Loss: 0.0001825789689814188\n",
            "----------------------------------------\n",
            "Epoch 224\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.373089340252545\n",
            "SCOPE mean: 0.17832187397719332, SCOPE var: 0.00885298932278762\n",
            "Total Loss: 0.00018151027357802359\n",
            "----------------------------------------\n",
            "Epoch 225\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.379792269454517\n",
            "SCOPE mean: 0.1780327572895147, SCOPE var: 0.008837561134459687\n",
            "Total Loss: 0.00018045813321827475\n",
            "----------------------------------------\n",
            "Epoch 226\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.386505220464123\n",
            "SCOPE mean: 0.17773375221325616, SCOPE var: 0.008821949356239136\n",
            "Total Loss: 0.00017941480778305263\n",
            "----------------------------------------\n",
            "Epoch 227\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.393213148161998\n",
            "SCOPE mean: 0.17743456403185406, SCOPE var: 0.008806257362103826\n",
            "Total Loss: 0.00017837841757909297\n",
            "----------------------------------------\n",
            "Epoch 228\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.399885682887174\n",
            "SCOPE mean: 0.17712724837727095, SCOPE var: 0.008790423926135672\n",
            "Total Loss: 0.00017735556935805373\n",
            "----------------------------------------\n",
            "Epoch 229\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.406265636627166\n",
            "SCOPE mean: 0.17681806601775707, SCOPE var: 0.008774653176430516\n",
            "Total Loss: 0.0001763570611561778\n",
            "----------------------------------------\n",
            "Epoch 230\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.412323323761592\n",
            "SCOPE mean: 0.17649871660632946, SCOPE var: 0.00875888535180967\n",
            "Total Loss: 0.00017537990557879682\n",
            "----------------------------------------\n",
            "Epoch 231\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.418268190155702\n",
            "SCOPE mean: 0.17617718807902322, SCOPE var: 0.008743059158349937\n",
            "Total Loss: 0.00017441074577944263\n",
            "----------------------------------------\n",
            "Epoch 232\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.42417271596537\n",
            "SCOPE mean: 0.1758564024292502, SCOPE var: 0.008727261840262375\n",
            "Total Loss: 0.00017344453519654626\n",
            "----------------------------------------\n",
            "Epoch 233\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.430035879897018\n",
            "SCOPE mean: 0.1755450172155976, SCOPE var: 0.008711593863953496\n",
            "Total Loss: 0.0001724772668847237\n",
            "----------------------------------------\n",
            "Epoch 234\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.435622085698837\n",
            "SCOPE mean: 0.1752315285380922, SCOPE var: 0.0086960103717772\n",
            "Total Loss: 0.00017151822254576522\n",
            "----------------------------------------\n",
            "Epoch 235\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.441107577187454\n",
            "SCOPE mean: 0.17497627108692326, SCOPE var: 0.008680395460103251\n",
            "Total Loss: 0.00017055502583757445\n",
            "----------------------------------------\n",
            "Epoch 236\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.446510563265168\n",
            "SCOPE mean: 0.17474252194480197, SCOPE var: 0.008664823449141858\n",
            "Total Loss: 0.00016959990047265186\n",
            "----------------------------------------\n",
            "Epoch 237\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.451638013144377\n",
            "SCOPE mean: 0.17450633592183673, SCOPE var: 0.008649314820980076\n",
            "Total Loss: 0.00016863784408066373\n",
            "----------------------------------------\n",
            "Epoch 238\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.456612452141297\n",
            "SCOPE mean: 0.17427907810235302, SCOPE var: 0.008633818061293541\n",
            "Total Loss: 0.00016768302238962706\n",
            "----------------------------------------\n",
            "Epoch 239\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.461549022251798\n",
            "SCOPE mean: 0.1740688042204293, SCOPE var: 0.008618437744011529\n",
            "Total Loss: 0.00016673513962714887\n",
            "----------------------------------------\n",
            "Epoch 240\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.466336106764835\n",
            "SCOPE mean: 0.17385677474827102, SCOPE var: 0.008603174987888741\n",
            "Total Loss: 0.00016579122319754452\n",
            "----------------------------------------\n",
            "Epoch 241\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.471147237231323\n",
            "SCOPE mean: 0.17364795259478502, SCOPE var: 0.008587930097231303\n",
            "Total Loss: 0.0001648496351421014\n",
            "----------------------------------------\n",
            "Epoch 242\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.475909179207111\n",
            "SCOPE mean: 0.17344236045983974, SCOPE var: 0.008572636612943935\n",
            "Total Loss: 0.00016392671114050895\n",
            "----------------------------------------\n",
            "Epoch 243\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.480457234743545\n",
            "SCOPE mean: 0.1732320342957545, SCOPE var: 0.008557262510867464\n",
            "Total Loss: 0.0001630150687727439\n",
            "----------------------------------------\n",
            "Epoch 244\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.484740607477157\n",
            "SCOPE mean: 0.1730065891233985, SCOPE var: 0.008541771706601808\n",
            "Total Loss: 0.00016214315118416502\n",
            "----------------------------------------\n",
            "Epoch 245\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.488951857471053\n",
            "SCOPE mean: 0.17278019543609505, SCOPE var: 0.008526180683227578\n",
            "Total Loss: 0.00016129317067588487\n",
            "----------------------------------------\n",
            "Epoch 246\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.49304937691898\n",
            "SCOPE mean: 0.17254648562449587, SCOPE var: 0.00851043053898739\n",
            "Total Loss: 0.00016048652390024577\n",
            "----------------------------------------\n",
            "Epoch 247\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.496999019205361\n",
            "SCOPE mean: 0.1723081009992451, SCOPE var: 0.008494575663881523\n",
            "Total Loss: 0.0001596823731793064\n",
            "----------------------------------------\n",
            "Epoch 248\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.500827720442322\n",
            "SCOPE mean: 0.17206518947604355, SCOPE var: 0.008478650109838951\n",
            "Total Loss: 0.00015886860109405634\n",
            "----------------------------------------\n",
            "Epoch 249\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.5043736598585\n",
            "SCOPE mean: 0.17183978153615523, SCOPE var: 0.008463005676633502\n",
            "Total Loss: 0.0001580674810238232\n",
            "----------------------------------------\n",
            "Epoch 250\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.507432866913815\n",
            "SCOPE mean: 0.17162213850180005, SCOPE var: 0.008447751259405641\n",
            "Total Loss: 0.0001572660785981454\n",
            "----------------------------------------\n",
            "Epoch 251\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.510112076778443\n",
            "SCOPE mean: 0.17136541019596532, SCOPE var: 0.008432711483407124\n",
            "Total Loss: 0.00015646753154981236\n",
            "----------------------------------------\n",
            "Epoch 252\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.5125156484732\n",
            "SCOPE mean: 0.1711088682815159, SCOPE var: 0.008417861720699152\n",
            "Total Loss: 0.0001556742831761831\n",
            "----------------------------------------\n",
            "Epoch 253\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.51488524878166\n",
            "SCOPE mean: 0.17085551737006058, SCOPE var: 0.008403134523117183\n",
            "Total Loss: 0.0001548508771868671\n",
            "----------------------------------------\n",
            "Epoch 254\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.51737207064611\n",
            "SCOPE mean: 0.17061093840331723, SCOPE var: 0.008388394492469324\n",
            "Total Loss: 0.00015400700961829163\n",
            "----------------------------------------\n",
            "Epoch 255\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.519989873826859\n",
            "SCOPE mean: 0.17037297545454794, SCOPE var: 0.008373614257987242\n",
            "Total Loss: 0.00015316066151966297\n",
            "----------------------------------------\n",
            "Epoch 256\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.522787746005875\n",
            "SCOPE mean: 0.17013049055814886, SCOPE var: 0.008358805027176714\n",
            "Total Loss: 0.0001523165406061097\n",
            "----------------------------------------\n",
            "Epoch 257\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.525727868802175\n",
            "SCOPE mean: 0.1698850407910488, SCOPE var: 0.00834398835248043\n",
            "Total Loss: 0.00015146020459010347\n",
            "----------------------------------------\n",
            "Epoch 258\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.528786007088458\n",
            "SCOPE mean: 0.1696232989412766, SCOPE var: 0.008329165054944684\n",
            "Total Loss: 0.00015060452236517763\n",
            "----------------------------------------\n",
            "Epoch 259\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.531962487781698\n",
            "SCOPE mean: 0.16932612782628323, SCOPE var: 0.008314357146560914\n",
            "Total Loss: 0.00014974881883937638\n",
            "----------------------------------------\n",
            "Epoch 260\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.53516580763814\n",
            "SCOPE mean: 0.16904093336561896, SCOPE var: 0.008299753798812731\n",
            "Total Loss: 0.0001489091144994957\n",
            "----------------------------------------\n",
            "Epoch 261\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.538424535747165\n",
            "SCOPE mean: 0.16876790942869738, SCOPE var: 0.008285286217856387\n",
            "Total Loss: 0.0001480840858272117\n",
            "----------------------------------------\n",
            "Epoch 262\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.541780563830045\n",
            "SCOPE mean: 0.16849644933082947, SCOPE var: 0.008270973576669059\n",
            "Total Loss: 0.00014727379498246257\n",
            "----------------------------------------\n",
            "Epoch 263\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.545370953228103\n",
            "SCOPE mean: 0.16822729845290238, SCOPE var: 0.008256895763096484\n",
            "Total Loss: 0.000146471982027516\n",
            "----------------------------------------\n",
            "Epoch 264\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.549209843548958\n",
            "SCOPE mean: 0.1679548802653161, SCOPE var: 0.008242925270450048\n",
            "Total Loss: 0.00014567445982037046\n",
            "----------------------------------------\n",
            "Epoch 265\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.55333906341647\n",
            "SCOPE mean: 0.16767572395562552, SCOPE var: 0.008228939307795636\n",
            "Total Loss: 0.00014488732022732874\n",
            "----------------------------------------\n",
            "Epoch 266\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.557722513364027\n",
            "SCOPE mean: 0.1673953442834566, SCOPE var: 0.008214980307678733\n",
            "Total Loss: 0.00014410481542773297\n",
            "----------------------------------------\n",
            "Epoch 267\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.562256300978362\n",
            "SCOPE mean: 0.16711305604930976, SCOPE var: 0.008201119297124228\n",
            "Total Loss: 0.00014332764735271476\n",
            "----------------------------------------\n",
            "Epoch 268\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.566914861859583\n",
            "SCOPE mean: 0.16682563903676312, SCOPE var: 0.008187306744293101\n",
            "Total Loss: 0.0001425722297721616\n",
            "----------------------------------------\n",
            "Epoch 269\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.571802558345102\n",
            "SCOPE mean: 0.16651226334572092, SCOPE var: 0.008173268017539297\n",
            "Total Loss: 0.00014183214922242805\n",
            "----------------------------------------\n",
            "Epoch 270\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.576994020580011\n",
            "SCOPE mean: 0.16617264349891217, SCOPE var: 0.008158953853130455\n",
            "Total Loss: 0.00014109830371854452\n",
            "----------------------------------------\n",
            "Epoch 271\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.582539850507473\n",
            "SCOPE mean: 0.16580966637049455, SCOPE var: 0.008144489364844814\n",
            "Total Loss: 0.0001403740478467637\n",
            "----------------------------------------\n",
            "Epoch 272\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.58834532922535\n",
            "SCOPE mean: 0.16542661357023453, SCOPE var: 0.008129906578369768\n",
            "Total Loss: 0.00013965896501294282\n",
            "----------------------------------------\n",
            "Epoch 273\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.594398093133908\n",
            "SCOPE mean: 0.16503228365670247, SCOPE var: 0.008115332359140552\n",
            "Total Loss: 0.00013895145542958467\n",
            "----------------------------------------\n",
            "Epoch 274\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.600666757677033\n",
            "SCOPE mean: 0.1646290927451499, SCOPE var: 0.00810078493249828\n",
            "Total Loss: 0.00013824406026335416\n",
            "----------------------------------------\n",
            "Epoch 275\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.607104607285821\n",
            "SCOPE mean: 0.16421975870215677, SCOPE var: 0.008086269700555768\n",
            "Total Loss: 0.00013753799383191576\n",
            "----------------------------------------\n",
            "Epoch 276\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.613639368008716\n",
            "SCOPE mean: 0.16380760251062662, SCOPE var: 0.008071759657946827\n",
            "Total Loss: 0.0001368382801786378\n",
            "----------------------------------------\n",
            "Epoch 277\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.620215065894481\n",
            "SCOPE mean: 0.1633890484373864, SCOPE var: 0.008057248190898815\n",
            "Total Loss: 0.0001361435598852325\n",
            "----------------------------------------\n",
            "Epoch 278\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.626825981533864\n",
            "SCOPE mean: 0.16296575209525482, SCOPE var: 0.008042768941646539\n",
            "Total Loss: 0.00013545356242078435\n",
            "----------------------------------------\n",
            "Epoch 279\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.63337017506314\n",
            "SCOPE mean: 0.16254070660288988, SCOPE var: 0.008028413992651648\n",
            "Total Loss: 0.00013476104794074432\n",
            "----------------------------------------\n",
            "Epoch 280\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.639789156270933\n",
            "SCOPE mean: 0.16211672382328335, SCOPE var: 0.008014193150495879\n",
            "Total Loss: 0.0001340760541228902\n",
            "----------------------------------------\n",
            "Epoch 281\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.64610507862044\n",
            "SCOPE mean: 0.16170408009402285, SCOPE var: 0.00800009722234285\n",
            "Total Loss: 0.0001333972206049444\n",
            "----------------------------------------\n",
            "Epoch 282\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.652328723696526\n",
            "SCOPE mean: 0.16130393560666056, SCOPE var: 0.007986139294135955\n",
            "Total Loss: 0.00013272397345948228\n",
            "----------------------------------------\n",
            "Epoch 283\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.6584720564055\n",
            "SCOPE mean: 0.16091691072519293, SCOPE var: 0.007972312595575437\n",
            "Total Loss: 0.0001320632774717326\n",
            "----------------------------------------\n",
            "Epoch 284\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.664617735608632\n",
            "SCOPE mean: 0.16053760033083905, SCOPE var: 0.007958621699405834\n",
            "Total Loss: 0.00013140924706361713\n",
            "----------------------------------------\n",
            "Epoch 285\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.670756306543408\n",
            "SCOPE mean: 0.16016468223842348, SCOPE var: 0.007945088120694842\n",
            "Total Loss: 0.0001307674045779577\n",
            "----------------------------------------\n",
            "Epoch 286\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.676630633388397\n",
            "SCOPE mean: 0.1597967644755759, SCOPE var: 0.007931820079057867\n",
            "Total Loss: 0.00013012845217742097\n",
            "----------------------------------------\n",
            "Epoch 287\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.682511960037225\n",
            "SCOPE mean: 0.15943942388100063, SCOPE var: 0.007918706230216933\n",
            "Total Loss: 0.0001295016180197738\n",
            "----------------------------------------\n",
            "Epoch 288\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.688353911158488\n",
            "SCOPE mean: 0.1591004424234466, SCOPE var: 0.007905742998805153\n",
            "Total Loss: 0.00012887752763871961\n",
            "----------------------------------------\n",
            "Epoch 289\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.694160342637353\n",
            "SCOPE mean: 0.15877970741868275, SCOPE var: 0.007892929279824767\n",
            "Total Loss: 0.00012826033385495857\n",
            "----------------------------------------\n",
            "Epoch 290\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.699988920930148\n",
            "SCOPE mean: 0.15846894330474456, SCOPE var: 0.007880205379627674\n",
            "Total Loss: 0.00012764920298997297\n",
            "----------------------------------------\n",
            "Epoch 291\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.705768823722938\n",
            "SCOPE mean: 0.15816856577363314, SCOPE var: 0.007867578580072254\n",
            "Total Loss: 0.00012703536323737302\n",
            "----------------------------------------\n",
            "Epoch 292\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.711577371950414\n",
            "SCOPE mean: 0.15787737884697317, SCOPE var: 0.007855091959846745\n",
            "Total Loss: 0.00012642358882862135\n",
            "----------------------------------------\n",
            "Epoch 293\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.717416047185893\n",
            "SCOPE mean: 0.1575934223770283, SCOPE var: 0.007842733649568029\n",
            "Total Loss: 0.00012581621084208072\n",
            "----------------------------------------\n",
            "Epoch 294\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.723335620137496\n",
            "SCOPE mean: 0.15732107061800865, SCOPE var: 0.00783052049734454\n",
            "Total Loss: 0.00012523462925879755\n",
            "----------------------------------------\n",
            "Epoch 295\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.729231124439286\n",
            "SCOPE mean: 0.15705078082134274, SCOPE var: 0.007818421429061067\n",
            "Total Loss: 0.00012466159352782154\n",
            "----------------------------------------\n",
            "Epoch 296\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.73510168404752\n",
            "SCOPE mean: 0.15678258607948212, SCOPE var: 0.007806427872104724\n",
            "Total Loss: 0.0001240904252601303\n",
            "----------------------------------------\n",
            "Epoch 297\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.740951394443437\n",
            "SCOPE mean: 0.15651570041607876, SCOPE var: 0.007794526237764398\n",
            "Total Loss: 0.00012352762938603037\n",
            "----------------------------------------\n",
            "Epoch 298\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.746575972914968\n",
            "SCOPE mean: 0.15624576919647426, SCOPE var: 0.007782789387543681\n",
            "Total Loss: 0.00012300297505153\n",
            "----------------------------------------\n",
            "Epoch 299\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.752230220230864\n",
            "SCOPE mean: 0.15597911800006675, SCOPE var: 0.007771105448351787\n",
            "Total Loss: 0.00012248490094854625\n",
            "----------------------------------------\n",
            "Epoch 300\n",
            "IS mean: 0.3306886857857864,IS variance: 0.009833739625625476\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.75785872918002\n",
            "SCOPE mean: 0.1557106213082311, SCOPE var: 0.007759454943699067\n",
            "Total Loss: 0.00012196399190409384\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[ 0.2813, -0.1519],\n",
            "        [ 0.6762, -0.5215],\n",
            "        [ 0.1513, -0.4857],\n",
            "        [-0.6795, -0.5101],\n",
            "        [ 0.4305, -0.6684],\n",
            "        [ 0.2041, -0.5345],\n",
            "        [-0.1332,  0.0576],\n",
            "        [ 0.3457, -0.4814],\n",
            "        [-0.0526, -0.2591],\n",
            "        [ 0.1056,  0.0894],\n",
            "        [ 0.2363, -0.2185],\n",
            "        [-0.2122, -0.2926],\n",
            "        [-0.1716, -0.4919],\n",
            "        [-0.2066, -0.5931],\n",
            "        [ 0.2572,  0.0078],\n",
            "        [-0.4010,  0.1463]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([-0.5254, -0.7341,  0.0315, -0.4146,  0.2533, -0.0295,  0.2762, -0.2888,\n",
            "         0.4908,  0.2461, -0.6104,  0.0168, -0.4960,  0.1372,  0.6324, -0.1454],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[-0.0761, -0.1561,  0.1796,  0.1333,  0.1408, -0.0105, -0.0071,  0.2491,\n",
            "          0.0706,  0.0606, -0.1147, -0.1727, -0.1230, -0.2191, -0.2325,  0.1817],\n",
            "        [ 0.3047, -0.1078, -0.1030, -0.1953, -0.0279, -0.1307, -0.0172,  0.0147,\n",
            "          0.0516,  0.1668,  0.0792, -0.2232,  0.1200,  0.2395, -0.1829, -0.3335],\n",
            "        [-0.0315,  0.1376, -0.1983,  0.1992,  0.1389, -0.1065,  0.0884,  0.0034,\n",
            "          0.0305, -0.0202, -0.1994,  0.1685, -0.2120, -0.1925, -0.1667, -0.2273],\n",
            "        [-0.0200,  0.0416, -0.1606,  0.1861, -0.1697,  0.1229, -0.2228,  0.2510,\n",
            "         -0.0143,  0.1996,  0.1484, -0.1232, -0.0765,  0.2017, -0.1146, -0.0444],\n",
            "        [ 0.0441, -0.0035,  0.3528, -0.0274,  0.1973,  0.0628,  0.1829,  0.3148,\n",
            "          0.0028, -0.2286, -0.0518, -0.0931,  0.1759, -0.0908, -0.0749,  0.1263],\n",
            "        [ 0.1577, -0.0631,  0.0580, -0.1045, -0.0813, -0.1535,  0.2785,  0.1146,\n",
            "          0.2005, -0.2454, -0.1227, -0.0451,  0.0416, -0.1861, -0.0188, -0.1480],\n",
            "        [-0.0609,  0.3370, -0.0205, -0.2161,  0.2602,  0.3944, -0.1754,  0.3078,\n",
            "          0.0765, -0.0761, -0.1491,  0.0260, -0.1448,  0.0232,  0.0832, -0.0833],\n",
            "        [ 0.1793, -0.2409, -0.2314,  0.1568,  0.0494, -0.1567,  0.0501,  0.2171,\n",
            "          0.0918, -0.2437,  0.1686,  0.1421, -0.2307,  0.1671, -0.1029, -0.2036],\n",
            "        [-0.2157,  0.1076, -0.0111,  0.1350,  0.0172, -0.2501, -0.1557, -0.0573,\n",
            "         -0.2163,  0.0785,  0.0321,  0.1062,  0.2066,  0.0431,  0.1401,  0.0586],\n",
            "        [ 0.1790, -0.0321, -0.0715,  0.2159,  0.0188, -0.0462, -0.1524, -0.1732,\n",
            "          0.0914, -0.2501,  0.0362,  0.2483,  0.0854, -0.0089,  0.0746,  0.1658],\n",
            "        [-0.1629,  0.2117,  0.2252,  0.0883, -0.0764,  0.4278,  0.0221,  0.0998,\n",
            "          0.1036,  0.0312,  0.1171,  0.0946,  0.2147, -0.1459, -0.1651,  0.0736],\n",
            "        [-0.0127, -0.0956,  0.0428, -0.1682,  0.0270, -0.0483,  0.0333, -0.0737,\n",
            "          0.0239, -0.1274, -0.1376,  0.2195, -0.2329,  0.1855,  0.0235,  0.1518],\n",
            "        [-0.1217, -0.2306, -0.2322, -0.0164, -0.1863,  0.0741, -0.1625,  0.1479,\n",
            "         -0.2312,  0.0589, -0.1685,  0.1579,  0.0199,  0.0141, -0.2195,  0.1986],\n",
            "        [ 0.1667, -0.1967, -0.0333, -0.1432, -0.0242,  0.1326, -0.1139, -0.0575,\n",
            "         -0.1378,  0.1490, -0.0013,  0.1203,  0.1856, -0.0276,  0.1210,  0.1865],\n",
            "        [ 0.0770, -0.1949, -0.0872,  0.0664, -0.2633, -0.2029,  0.0187, -0.1805,\n",
            "          0.0026,  0.1273, -0.2366,  0.1396,  0.0472, -0.2465,  0.1933,  0.1710],\n",
            "        [ 0.0371,  0.2551, -0.2304,  0.0695,  0.0527, -0.1193, -0.0236, -0.1221,\n",
            "         -0.0520, -0.0867, -0.0146,  0.2240, -0.1942,  0.0277, -0.0065, -0.0174]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([ 0.0114,  0.1359, -0.0566, -0.1059,  0.1734, -0.1132,  0.1461, -0.1720,\n",
            "        -0.0508, -0.0770,  0.0057,  0.0312, -0.1351, -0.0227,  0.0180,  0.1641],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[ 0.1788,  0.0845,  0.1612, -0.1068, -0.0512,  0.1726, -0.1653, -0.2173,\n",
            "          0.1507,  0.0539, -0.1218,  0.0772, -0.3017, -0.0478,  0.0071,  0.1414]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([-0.1190], dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NN_l1_l2_reg(\n",
              "  (hidden_layers): ModuleList(\n",
              "    (0): Linear(in_features=2, out_features=16, bias=True)\n",
              "    (1): Linear(in_features=16, out_features=16, bias=True)\n",
              "  )\n",
              "  (output_layer): Linear(in_features=16, out_features=1, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_1000_random_pi_b_1000.get_heatmap()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "eT_dT0e76eU1",
        "outputId": "c3347f00-2e15-4e40-dafc-366a66350506"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"b635ca72-fa0d-471a-b003-821187fbed7b\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"b635ca72-fa0d-471a-b003-821187fbed7b\")) {                    Plotly.newPlot(                        \"b635ca72-fa0d-471a-b003-821187fbed7b\",                        [{\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"z\":[[-0.13528915154382468,-0.20026310720828833,-0.30587758352345995,-0.4107537056850279,-0.5113029762979662,-0.6118522469109042,-0.7140701716010334,-0.8215039656184002,-0.9289377596357667,-1.0363715536531335],[-0.12288944081199984,-0.12661483848648492,-0.14384932571256168,-0.188396017255673,-0.2788484476416886,-0.37950315132208234,-0.4834871270319102,-0.5930922493911532,-0.7038803444360601,-0.8146684394809673],[-0.11884556582631968,-0.11641344714561604,-0.11697244145649208,-0.1253032568753183,-0.15393789492575558,-0.20042755849827842,-0.26979238384373516,-0.3725208790655289,-0.48330897411043594,-0.5940970691553431],[-0.11819092971915957,-0.11382632847028008,-0.114922755315686,-0.11709930426189347,-0.11907520553811649,-0.1352151148266197,-0.1758137704103312,-0.2199172198663606,-0.2757895213281183,-0.3772954970680795],[-0.11479167042606286,-0.112101220843405,-0.11287306917487992,-0.11504961812108738,-0.11685765032653117,-0.11984841681831393,-0.12797813991659993,-0.1562207175397337,-0.19390473227853666,-0.25109138615829574],[-0.11139241113296616,-0.11276529846043483,-0.11082338303407385,-0.11299993198028133,-0.1151764809264888,-0.11675013607431609,-0.12062162809851137,-0.12327671926149876,-0.13830558365393086,-0.17560973370072558],[-0.10717517185254087,-0.1124056243547319,-0.10877369689326778,-0.11095024583947524,-0.11312679478568272,-0.11461494904624384,-0.11694740918775012,-0.12100311842207712,-0.12404993054169622,-0.12534475951664148],[-0.10315337999259633,-0.10900636506163522,-0.10793146512671896,-0.10890055969866916,-0.11107710864487665,-0.11325365759108412,-0.1145601405861608,-0.11714468230118416,-0.12120039153551115,-0.1248231418218936],[-0.10067694471778639,-0.10788443541521382,-0.10818636475206149,-0.1068508735578631,-0.10902742250407058,-0.11120397145027804,-0.11237224776595647,-0.11406059598624499,-0.1173419554146182,-0.1213976646489452],[-0.0983053629680974,-0.10918521501860604,-0.10773846584907908,-0.10480118741705703,-0.10697773636326449,-0.10915428530947197,-0.11130152095571091,-0.1119077128237711,-0.11286247574868294,-0.11753922852805224]],\"type\":\"heatmap\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"Values\"},\"ticks\":\"outside\",\"tickvals\":[-1.0363715536531335,-0.0983053629680974],\"ticktext\":[-1.0363715536531335,-0.0983053629680974]}},\"xaxis\":{\"tickvals\":[0,1,2,3,4,5,6,7,8,9],\"ticktext\":[0,1,2,3,4,5,6,7,8,9],\"title\":{\"text\":\"X\"}},\"yaxis\":{\"tickvals\":[9,8,7,6,5,4,3,2,1,0],\"ticktext\":[9,8,7,6,5,4,3,2,1,0],\"title\":{\"text\":\"Y\"},\"autorange\":\"reversed\"},\"title\":{\"text\":\"Heatmap\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('b635ca72-fa0d-471a-b003-821187fbed7b');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment 2 (with mse)"
      ],
      "metadata": {
        "id": "ui5x6gSjF6G-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b_200_mse = action_probs_top_n_epsilon(q_table, 1, 0.4)\n",
        "pi_b_200_mse = experiment_actions(200, env_50, P_pi_b_200_mse)\n",
        "P_pi_e_200 = action_probs_top_n_epsilon(q_table, 1, 0.05)\n",
        "pi_e_200 = experiment_actions(1000, env_50, P_pi_e_200)\n",
        "# model_200_random_pi_b_200_mse = CustomizableFeatureNet(input_dim=2, hidden_dims=[16, 16], output_dim=1, dtype = torch.float64, l2_lambda=0.002)\n",
        "model_200_random_pi_b_200_mse = NN_l1_l2_reg(input_dim=2, hidden_dims=[16, 16], output_dim=1, dtype = torch.float64, l1_lambda=0.0001, l2_lambda = 0.0001)\n",
        "test_200_random_pi_b_200_mse = SCOPE_straight(model_200_random_pi_b_200_mse, 0.99, 10000, pi_b_200_mse, P_pi_b_200_mse, P_pi_e_200, 0.3, dtype = torch.float64)\n",
        "test_200_random_pi_b_200_mse.train_var_scope(300, 0.001, 1, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d07f708d-8d1c-4d2b-dcaa-b2f1ecbfb046",
        "id": "kN1SCM04GL20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.2611, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.9192405820903025\n",
            "SCOPE mean: 3.03623013914548, SCOPE var: 5.074455600234516\n",
            "Total Loss: 8.180356407581256\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.1700, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.172540383266576\n",
            "SCOPE mean: 3.095641933637867, SCOPE var: 5.167460307377982\n",
            "Total Loss: 7.342494274568023\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.1676, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.799803227779146\n",
            "SCOPE mean: 3.149987360695076, SCOPE var: 5.2514796584297985\n",
            "Total Loss: 6.9673979348802115\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.1651, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.4723539321855705\n",
            "SCOPE mean: 3.1986520752704917, SCOPE var: 5.318505684193118\n",
            "Total Loss: 6.637419166219916\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.1625, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.186099127683169\n",
            "SCOPE mean: 3.245414257177157, SCOPE var: 5.381818985789903\n",
            "Total Loss: 6.348644724020499\n",
            "----------------------------------------\n",
            "Epoch 6\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.1601, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.9368919648861915\n",
            "SCOPE mean: 3.2911824649900154, SCOPE var: 5.4455682806740695\n",
            "Total Loss: 6.0969635989318425\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.1578, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.72093307446879\n",
            "SCOPE mean: 3.33564183096714, SCOPE var: 5.509311100970278\n",
            "Total Loss: 5.878714808220128\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.1555, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.533797503368622\n",
            "SCOPE mean: 3.3783989873110296, SCOPE var: 5.572408583321402\n",
            "Total Loss: 5.689262230051372\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.1531, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.369862202986147\n",
            "SCOPE mean: 3.4182062010749403, SCOPE var: 5.634175092713106\n",
            "Total Loss: 5.52296638339695\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.1507, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.22404030500755\n",
            "SCOPE mean: 3.455732628491083, SCOPE var: 5.694094759260255\n",
            "Total Loss: 5.374784554664844\n",
            "----------------------------------------\n",
            "Epoch 11\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.1484, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.0931615045233745\n",
            "SCOPE mean: 3.4907864509094004, SCOPE var: 5.751757637088235\n",
            "Total Loss: 5.241601031321306\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.1461, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.973773206944847\n",
            "SCOPE mean: 3.5251336158328495, SCOPE var: 5.810813984137906\n",
            "Total Loss: 5.119895069286427\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.1438, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.862193599065792\n",
            "SCOPE mean: 3.55814965690475, SCOPE var: 5.869544121450909\n",
            "Total Loss: 5.006038074335785\n",
            "----------------------------------------\n",
            "Epoch 14\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.1415, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.755468361168194\n",
            "SCOPE mean: 3.592275017039781, SCOPE var: 5.93231985621296\n",
            "Total Loss: 4.896957195282362\n",
            "----------------------------------------\n",
            "Epoch 15\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.1391, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.65123972590373\n",
            "SCOPE mean: 3.623781224634309, SCOPE var: 5.992072079092211\n",
            "Total Loss: 4.790342314915289\n",
            "----------------------------------------\n",
            "Epoch 16\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.1367, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.549216416196038\n",
            "SCOPE mean: 3.652907883803978, SCOPE var: 6.048981950168708\n",
            "Total Loss: 4.685904651344449\n",
            "----------------------------------------\n",
            "Epoch 17\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.1343, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.448949052408589\n",
            "SCOPE mean: 3.679705938599893, SCOPE var: 6.102772647823516\n",
            "Total Loss: 4.583200992302244\n",
            "----------------------------------------\n",
            "Epoch 18\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.1318, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.350244932357929\n",
            "SCOPE mean: 3.704429000258341, SCOPE var: 6.1539097493325965\n",
            "Total Loss: 4.482033105254693\n",
            "----------------------------------------\n",
            "Epoch 19\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.1291, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.252344795453953\n",
            "SCOPE mean: 3.7272743770764443, SCOPE var: 6.202806907090246\n",
            "Total Loss: 4.381411886674748\n",
            "----------------------------------------\n",
            "Epoch 20\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.1260, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.155867636551427\n",
            "SCOPE mean: 3.7484502853364923, SCOPE var: 6.2495061535173075\n",
            "Total Loss: 4.28190969309404\n",
            "----------------------------------------\n",
            "Epoch 21\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.1229, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.061016248089265\n",
            "SCOPE mean: 3.7681598684103155, SCOPE var: 6.2942571593494225\n",
            "Total Loss: 4.183952895535113\n",
            "----------------------------------------\n",
            "Epoch 22\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.1199, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.9681577504329635\n",
            "SCOPE mean: 3.786356370275545, SCOPE var: 6.336724853595276\n",
            "Total Loss: 4.088074095718944\n",
            "----------------------------------------\n",
            "Epoch 23\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.1169, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.877833412469204\n",
            "SCOPE mean: 3.8030888709954445, SCOPE var: 6.3772668084309885\n",
            "Total Loss: 3.9947280855460727\n",
            "----------------------------------------\n",
            "Epoch 24\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.1138, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.7903039731527026\n",
            "SCOPE mean: 3.8196382657914576, SCOPE var: 6.417542272300131\n",
            "Total Loss: 3.9040717900800614\n",
            "----------------------------------------\n",
            "Epoch 25\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.1107, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.7055679089097917\n",
            "SCOPE mean: 3.8324698787409957, SCOPE var: 6.447455160355338\n",
            "Total Loss: 3.816277150972142\n",
            "----------------------------------------\n",
            "Epoch 26\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.1077, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.6239554108035077\n",
            "SCOPE mean: 3.8444044997124163, SCOPE var: 6.476092228338147\n",
            "Total Loss: 3.7316741852051027\n",
            "----------------------------------------\n",
            "Epoch 27\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.1048, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.545365346360215\n",
            "SCOPE mean: 3.856006834279639, SCOPE var: 6.504975144104592\n",
            "Total Loss: 3.6501712326994453\n",
            "----------------------------------------\n",
            "Epoch 28\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.1021, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.469983434678758\n",
            "SCOPE mean: 3.8675613300982468, SCOPE var: 6.534961875800695\n",
            "Total Loss: 3.5720371787140177\n",
            "----------------------------------------\n",
            "Epoch 29\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0994, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.397375561179263\n",
            "SCOPE mean: 3.8792848407760547, SCOPE var: 6.566406288757403\n",
            "Total Loss: 3.4967651630073195\n",
            "----------------------------------------\n",
            "Epoch 30\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0968, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.3275745092674565\n",
            "SCOPE mean: 3.890555567287664, SCOPE var: 6.597335696937556\n",
            "Total Loss: 3.4243532835672097\n",
            "----------------------------------------\n",
            "Epoch 31\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0942, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.260425451260467\n",
            "SCOPE mean: 3.9015515153245173, SCOPE var: 6.627854781678215\n",
            "Total Loss: 3.3546600657516934\n",
            "----------------------------------------\n",
            "Epoch 32\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0918, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.195759520083454\n",
            "SCOPE mean: 3.9129938138410565, SCOPE var: 6.65957000769689\n",
            "Total Loss: 3.2875130745984142\n",
            "----------------------------------------\n",
            "Epoch 33\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0893, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.1334880176101856\n",
            "SCOPE mean: 3.925024387010208, SCOPE var: 6.692806754971938\n",
            "Total Loss: 3.2228245246901452\n",
            "----------------------------------------\n",
            "Epoch 34\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0870, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.073458527220553\n",
            "SCOPE mean: 3.937115140216228, SCOPE var: 6.726146780128116\n",
            "Total Loss: 3.1604169082342684\n",
            "----------------------------------------\n",
            "Epoch 35\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0846, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.015471246493377\n",
            "SCOPE mean: 3.949286556722992, SCOPE var: 6.759471264533421\n",
            "Total Loss: 3.1000815428110036\n",
            "----------------------------------------\n",
            "Epoch 36\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0823, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.9591183484932295\n",
            "SCOPE mean: 3.961271304013276, SCOPE var: 6.792425670895311\n",
            "Total Loss: 3.041424932545303\n",
            "----------------------------------------\n",
            "Epoch 37\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0801, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.9043037657558193\n",
            "SCOPE mean: 3.973165938819464, SCOPE var: 6.825510904744245\n",
            "Total Loss: 2.984358038828076\n",
            "----------------------------------------\n",
            "Epoch 38\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0778, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.85107703409288\n",
            "SCOPE mean: 3.9854129536426495, SCOPE var: 6.859389971822203\n",
            "Total Loss: 2.9289241243025583\n",
            "----------------------------------------\n",
            "Epoch 39\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0757, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.7993465569770666\n",
            "SCOPE mean: 3.9975775917915795, SCOPE var: 6.892965027183365\n",
            "Total Loss: 2.875028080902916\n",
            "----------------------------------------\n",
            "Epoch 40\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0736, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.7488393752778864\n",
            "SCOPE mean: 4.009650419213236, SCOPE var: 6.926124269672594\n",
            "Total Loss: 2.822457663803981\n",
            "----------------------------------------\n",
            "Epoch 41\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0716, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.700190271375537\n",
            "SCOPE mean: 4.021682813307296, SCOPE var: 6.9578427964138845\n",
            "Total Loss: 2.7717957987915125\n",
            "----------------------------------------\n",
            "Epoch 42\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0696, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.6525586773639995\n",
            "SCOPE mean: 4.033810802027886, SCOPE var: 6.989524694132939\n",
            "Total Loss: 2.722186425341365\n",
            "----------------------------------------\n",
            "Epoch 43\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0677, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.6060241465206953\n",
            "SCOPE mean: 4.045931368398726, SCOPE var: 7.020652895616465\n",
            "Total Loss: 2.6737390477432457\n",
            "----------------------------------------\n",
            "Epoch 44\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0659, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.5605482647379554\n",
            "SCOPE mean: 4.058015599109786, SCOPE var: 7.051215765466145\n",
            "Total Loss: 2.626412386258039\n",
            "----------------------------------------\n",
            "Epoch 45\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0641, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.516129076259379\n",
            "SCOPE mean: 4.0700402431304505, SCOPE var: 7.0812245734833645\n",
            "Total Loss: 2.580189377527252\n",
            "----------------------------------------\n",
            "Epoch 46\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0623, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.472719912867286\n",
            "SCOPE mean: 4.081910090686675, SCOPE var: 7.110405920212925\n",
            "Total Loss: 2.535028683060253\n",
            "----------------------------------------\n",
            "Epoch 47\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0606, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.4302892147839024\n",
            "SCOPE mean: 4.093630257473291, SCOPE var: 7.138874893148887\n",
            "Total Loss: 2.4908669227095075\n",
            "----------------------------------------\n",
            "Epoch 48\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0589, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.3889714530802553\n",
            "SCOPE mean: 4.105205066740964, SCOPE var: 7.166739965064732\n",
            "Total Loss: 2.447889171759937\n",
            "----------------------------------------\n",
            "Epoch 49\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0573, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.3487138043376725\n",
            "SCOPE mean: 4.116653510878217, SCOPE var: 7.194076891937221\n",
            "Total Loss: 2.4060312082077253\n",
            "----------------------------------------\n",
            "Epoch 50\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0558, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.3095004100554553\n",
            "SCOPE mean: 4.128100370412134, SCOPE var: 7.221356508323265\n",
            "Total Loss: 2.365276790422874\n",
            "----------------------------------------\n",
            "Epoch 51\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0543, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.2713796301630036\n",
            "SCOPE mean: 4.139300353162328, SCOPE var: 7.2478520030023\n",
            "Total Loss: 2.3256846927838386\n",
            "----------------------------------------\n",
            "Epoch 52\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0529, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.2341920773979043\n",
            "SCOPE mean: 4.150208832485205, SCOPE var: 7.273540253090384\n",
            "Total Loss: 2.2870827131616336\n",
            "----------------------------------------\n",
            "Epoch 53\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0515, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.197727153674966\n",
            "SCOPE mean: 4.1608865978455425, SCOPE var: 7.298583865075881\n",
            "Total Loss: 2.2492545877602534\n",
            "----------------------------------------\n",
            "Epoch 54\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0502, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.1621038995043826\n",
            "SCOPE mean: 4.171233905980419, SCOPE var: 7.322817641751189\n",
            "Total Loss: 2.2123146629562527\n",
            "----------------------------------------\n",
            "Epoch 55\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0490, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.127284685430216\n",
            "SCOPE mean: 4.181118865314034, SCOPE var: 7.345957618282749\n",
            "Total Loss: 2.176242851006765\n",
            "----------------------------------------\n",
            "Epoch 56\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0478, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.0933242525805382\n",
            "SCOPE mean: 4.190673758823166, SCOPE var: 7.368329180276681\n",
            "Total Loss: 2.1410945923252833\n",
            "----------------------------------------\n",
            "Epoch 57\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0466, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.0601847633372605\n",
            "SCOPE mean: 4.199882078208036, SCOPE var: 7.389895774144349\n",
            "Total Loss: 2.106817929682319\n",
            "----------------------------------------\n",
            "Epoch 58\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0455, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.0277488917741624\n",
            "SCOPE mean: 4.208736920172557, SCOPE var: 7.4106317211030985\n",
            "Total Loss: 2.073288649396214\n",
            "----------------------------------------\n",
            "Epoch 59\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0445, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.9961421971232014\n",
            "SCOPE mean: 4.21722017987725, SCOPE var: 7.430470364054716\n",
            "Total Loss: 2.040639303433915\n",
            "----------------------------------------\n",
            "Epoch 60\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0435, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.9652646950766721\n",
            "SCOPE mean: 4.2253171532691365, SCOPE var: 7.449376363643577\n",
            "Total Loss: 2.008772592279804\n",
            "----------------------------------------\n",
            "Epoch 61\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0425, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.9350899714904641\n",
            "SCOPE mean: 4.23303848777848, SCOPE var: 7.467161462355519\n",
            "Total Loss: 1.9776254529226112\n",
            "----------------------------------------\n",
            "Epoch 62\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0416, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.9057480872789454\n",
            "SCOPE mean: 4.240350203304748, SCOPE var: 7.483455256919799\n",
            "Total Loss: 1.947326837024389\n",
            "----------------------------------------\n",
            "Epoch 63\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0407, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.8770637283634812\n",
            "SCOPE mean: 4.247294698224935, SCOPE var: 7.4987671428539135\n",
            "Total Loss: 1.917722439901482\n",
            "----------------------------------------\n",
            "Epoch 64\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0398, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.8489995049369448\n",
            "SCOPE mean: 4.253891827204669, SCOPE var: 7.513100054765962\n",
            "Total Loss: 1.88877279592113\n",
            "----------------------------------------\n",
            "Epoch 65\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0389, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.821575610298541\n",
            "SCOPE mean: 4.260161789678961, SCOPE var: 7.52644099798796\n",
            "Total Loss: 1.860497584884515\n",
            "----------------------------------------\n",
            "Epoch 66\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0381, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.794796653990324\n",
            "SCOPE mean: 4.266128846840978, SCOPE var: 7.538801598924361\n",
            "Total Loss: 1.832905832758797\n",
            "----------------------------------------\n",
            "Epoch 67\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0373, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7683385814149835\n",
            "SCOPE mean: 4.271851156330296, SCOPE var: 7.550219566298199\n",
            "Total Loss: 1.805664587074151\n",
            "----------------------------------------\n",
            "Epoch 68\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0366, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7423761714175205\n",
            "SCOPE mean: 4.277346467884321, SCOPE var: 7.56065278077964\n",
            "Total Loss: 1.7789374870519632\n",
            "----------------------------------------\n",
            "Epoch 69\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0358, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7167424907289344\n",
            "SCOPE mean: 4.282519883329776, SCOPE var: 7.56968269539977\n",
            "Total Loss: 1.752572177358464\n",
            "----------------------------------------\n",
            "Epoch 70\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0351, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6912884567947846\n",
            "SCOPE mean: 4.287484400091477, SCOPE var: 7.57779399524147\n",
            "Total Loss: 1.726395502685123\n",
            "----------------------------------------\n",
            "Epoch 71\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0344, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6662112104342008\n",
            "SCOPE mean: 4.292259409123018, SCOPE var: 7.584971572785603\n",
            "Total Loss: 1.7006356921155676\n",
            "----------------------------------------\n",
            "Epoch 72\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0338, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.641652412384783\n",
            "SCOPE mean: 4.296811393071547, SCOPE var: 7.5911447398149745\n",
            "Total Loss: 1.6754665093227905\n",
            "----------------------------------------\n",
            "Epoch 73\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0332, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6174398197644984\n",
            "SCOPE mean: 4.301149675839266, SCOPE var: 7.596327833768389\n",
            "Total Loss: 1.6506463656317516\n",
            "----------------------------------------\n",
            "Epoch 74\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0326, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5934456720203527\n",
            "SCOPE mean: 4.305262628955452, SCOPE var: 7.600471836403253\n",
            "Total Loss: 1.6260811147435406\n",
            "----------------------------------------\n",
            "Epoch 75\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0320, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.569520740484766\n",
            "SCOPE mean: 4.309172292089254, SCOPE var: 7.603620046971679\n",
            "Total Loss: 1.6015700434399032\n",
            "----------------------------------------\n",
            "Epoch 76\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0315, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5460595259873777\n",
            "SCOPE mean: 4.3125927705732074, SCOPE var: 7.604868506355892\n",
            "Total Loss: 1.577521559596141\n",
            "----------------------------------------\n",
            "Epoch 77\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0309, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5231245762069805\n",
            "SCOPE mean: 4.315132851014515, SCOPE var: 7.6032999535787225\n",
            "Total Loss: 1.5540264131526131\n",
            "----------------------------------------\n",
            "Epoch 78\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0303, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5007672922657023\n",
            "SCOPE mean: 4.31733809324452, SCOPE var: 7.600657347839368\n",
            "Total Loss: 1.5311088829319335\n",
            "----------------------------------------\n",
            "Epoch 79\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0298, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.478863580377493\n",
            "SCOPE mean: 4.319372497973595, SCOPE var: 7.597180279457837\n",
            "Total Loss: 1.508684979301604\n",
            "----------------------------------------\n",
            "Epoch 80\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0293, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4574405675225017\n",
            "SCOPE mean: 4.3212059046289, SCOPE var: 7.592912125377038\n",
            "Total Loss: 1.4867703341845306\n",
            "----------------------------------------\n",
            "Epoch 81\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0289, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.436468716659299\n",
            "SCOPE mean: 4.322842744615531, SCOPE var: 7.58789662217019\n",
            "Total Loss: 1.4653284102584085\n",
            "----------------------------------------\n",
            "Epoch 82\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0284, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4159894304073757\n",
            "SCOPE mean: 4.324414563970308, SCOPE var: 7.581735658264395\n",
            "Total Loss: 1.4444060872938407\n",
            "----------------------------------------\n",
            "Epoch 83\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0280, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.3961153245552675\n",
            "SCOPE mean: 4.325820004777618, SCOPE var: 7.574752931016661\n",
            "Total Loss: 1.4241190374960448\n",
            "----------------------------------------\n",
            "Epoch 84\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0276, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.3766750108928931\n",
            "SCOPE mean: 4.327005762102696, SCOPE var: 7.566964912099676\n",
            "Total Loss: 1.4042886799058163\n",
            "----------------------------------------\n",
            "Epoch 85\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0270, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.3577014751737824\n",
            "SCOPE mean: 4.327891615801331, SCOPE var: 7.5582848009404815\n",
            "Total Loss: 1.3847491586479985\n",
            "----------------------------------------\n",
            "Epoch 86\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0265, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.3391075285758143\n",
            "SCOPE mean: 4.3284273749117474, SCOPE var: 7.549144304652866\n",
            "Total Loss: 1.3656093354234273\n",
            "----------------------------------------\n",
            "Epoch 87\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0260, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.3210655513604952\n",
            "SCOPE mean: 4.32801697464543, SCOPE var: 7.539230421294866\n",
            "Total Loss: 1.3470452372676367\n",
            "----------------------------------------\n",
            "Epoch 88\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0255, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.3035588137977885\n",
            "SCOPE mean: 4.325381617690369, SCOPE var: 7.528672553890874\n",
            "Total Loss: 1.329077383550845\n",
            "----------------------------------------\n",
            "Epoch 89\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0251, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.2865640754336567\n",
            "SCOPE mean: 4.323018805161125, SCOPE var: 7.517412155775867\n",
            "Total Loss: 1.311633583322961\n",
            "----------------------------------------\n",
            "Epoch 90\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0246, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.2701886531810942\n",
            "SCOPE mean: 4.320160627307108, SCOPE var: 7.505463177302051\n",
            "Total Loss: 1.2947635615070447\n",
            "----------------------------------------\n",
            "Epoch 91\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0241, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.2543957990514751\n",
            "SCOPE mean: 4.3167249236938074, SCOPE var: 7.49073669560836\n",
            "Total Loss: 1.2784597399952211\n",
            "----------------------------------------\n",
            "Epoch 92\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0236, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.2389012341208436\n",
            "SCOPE mean: 4.313476506651743, SCOPE var: 7.4757788975492465\n",
            "Total Loss: 1.262549963136803\n",
            "----------------------------------------\n",
            "Epoch 93\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0233, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.2237003710441547\n",
            "SCOPE mean: 4.310439392268473, SCOPE var: 7.460759115029265\n",
            "Total Loss: 1.2469657600287107\n",
            "----------------------------------------\n",
            "Epoch 94\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0229, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.2089146751648228\n",
            "SCOPE mean: 4.307609087845181, SCOPE var: 7.445703029746805\n",
            "Total Loss: 1.2318000678765537\n",
            "----------------------------------------\n",
            "Epoch 95\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0226, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.1944663290596056\n",
            "SCOPE mean: 4.30510686854242, SCOPE var: 7.4305836767497695\n",
            "Total Loss: 1.217055029049116\n",
            "----------------------------------------\n",
            "Epoch 96\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0223, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.1802478144232589\n",
            "SCOPE mean: 4.302892933807905, SCOPE var: 7.415534808229405\n",
            "Total Loss: 1.2025695343703848\n",
            "----------------------------------------\n",
            "Epoch 97\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0220, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.1660927390781002\n",
            "SCOPE mean: 4.30091115088293, SCOPE var: 7.400617672747961\n",
            "Total Loss: 1.1881283864931615\n",
            "----------------------------------------\n",
            "Epoch 98\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0217, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.1522072056970667\n",
            "SCOPE mean: 4.299206487342294, SCOPE var: 7.386189637652335\n",
            "Total Loss: 1.173937835635499\n",
            "----------------------------------------\n",
            "Epoch 99\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0214, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.1385992650445849\n",
            "SCOPE mean: 4.297758302423893, SCOPE var: 7.3722352449354185\n",
            "Total Loss: 1.1600139536218819\n",
            "----------------------------------------\n",
            "Epoch 100\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0211, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.1252342475400803\n",
            "SCOPE mean: 4.2964481083316075, SCOPE var: 7.358516190468168\n",
            "Total Loss: 1.1463319783432153\n",
            "----------------------------------------\n",
            "Epoch 101\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0208, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.1121415282475735\n",
            "SCOPE mean: 4.295220240550284, SCOPE var: 7.3450310845890705\n",
            "Total Loss: 1.1329349754789766\n",
            "----------------------------------------\n",
            "Epoch 102\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0205, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0992867112243014\n",
            "SCOPE mean: 4.2939606344327945, SCOPE var: 7.331775199865839\n",
            "Total Loss: 1.119783580088038\n",
            "----------------------------------------\n",
            "Epoch 103\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0202, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0867299133325619\n",
            "SCOPE mean: 4.292729977185744, SCOPE var: 7.318741835467176\n",
            "Total Loss: 1.1069413668635861\n",
            "----------------------------------------\n",
            "Epoch 104\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0199, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.074464985246239\n",
            "SCOPE mean: 4.291493375240369, SCOPE var: 7.305886556551005\n",
            "Total Loss: 1.0943948689577172\n",
            "----------------------------------------\n",
            "Epoch 105\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0197, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0624852862530687\n",
            "SCOPE mean: 4.290248368354827, SCOPE var: 7.293500558044851\n",
            "Total Loss: 1.0821423472825606\n",
            "----------------------------------------\n",
            "Epoch 106\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0194, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0506761330378231\n",
            "SCOPE mean: 4.289002289156619, SCOPE var: 7.281329059858491\n",
            "Total Loss: 1.070080659213818\n",
            "----------------------------------------\n",
            "Epoch 107\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0192, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0390821203551401\n",
            "SCOPE mean: 4.287745454762782, SCOPE var: 7.269342041847464\n",
            "Total Loss: 1.0582380427580347\n",
            "----------------------------------------\n",
            "Epoch 108\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0189, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0277600348286315\n",
            "SCOPE mean: 4.286490998120613, SCOPE var: 7.25754220409499\n",
            "Total Loss: 1.0466763767628628\n",
            "----------------------------------------\n",
            "Epoch 109\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0187, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0166825290653199\n",
            "SCOPE mean: 4.2852340109943725, SCOPE var: 7.245926346219827\n",
            "Total Loss: 1.035367455163276\n",
            "----------------------------------------\n",
            "Epoch 110\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0185, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0058502226069346\n",
            "SCOPE mean: 4.28397398959128, SCOPE var: 7.2344880181208575\n",
            "Total Loss: 1.0243110070277541\n",
            "----------------------------------------\n",
            "Epoch 111\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0182, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9952078212615034\n",
            "SCOPE mean: 4.282713988115549, SCOPE var: 7.223221307162541\n",
            "Total Loss: 1.0134553613681687\n",
            "----------------------------------------\n",
            "Epoch 112\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0181, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9847605720860522\n",
            "SCOPE mean: 4.281455649471679, SCOPE var: 7.212077190883732\n",
            "Total Loss: 1.002811887188075\n",
            "----------------------------------------\n",
            "Epoch 113\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0179, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9745184948107576\n",
            "SCOPE mean: 4.280138158877423, SCOPE var: 7.200978920903774\n",
            "Total Loss: 0.9923836453767492\n",
            "----------------------------------------\n",
            "Epoch 114\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0177, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9644742886869836\n",
            "SCOPE mean: 4.278549879488006, SCOPE var: 7.189142660413499\n",
            "Total Loss: 0.9821576998593474\n",
            "----------------------------------------\n",
            "Epoch 115\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0175, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.954541268151148\n",
            "SCOPE mean: 4.277088606563842, SCOPE var: 7.177605149235312\n",
            "Total Loss: 0.9720355446324475\n",
            "----------------------------------------\n",
            "Epoch 116\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0173, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9447961184829444\n",
            "SCOPE mean: 4.275704733658952, SCOPE var: 7.166243077542956\n",
            "Total Loss: 0.9621423326940801\n",
            "----------------------------------------\n",
            "Epoch 117\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0172, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9352573157147543\n",
            "SCOPE mean: 4.274386501752918, SCOPE var: 7.155057856883884\n",
            "Total Loss: 0.952462261325769\n",
            "----------------------------------------\n",
            "Epoch 118\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0171, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9259133018575021\n",
            "SCOPE mean: 4.273306045544449, SCOPE var: 7.1446290560679655\n",
            "Total Loss: 0.942981274725245\n",
            "----------------------------------------\n",
            "Epoch 119\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0169, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9167422580794512\n",
            "SCOPE mean: 4.272275198204095, SCOPE var: 7.134367813660145\n",
            "Total Loss: 0.9336848500947388\n",
            "----------------------------------------\n",
            "Epoch 120\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0168, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9077321563634736\n",
            "SCOPE mean: 4.271235857428514, SCOPE var: 7.124177426423498\n",
            "Total Loss: 0.9245599924143268\n",
            "----------------------------------------\n",
            "Epoch 121\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0167, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8988761238354865\n",
            "SCOPE mean: 4.270243641273235, SCOPE var: 7.1141378752232285\n",
            "Total Loss: 0.9155867335629162\n",
            "----------------------------------------\n",
            "Epoch 122\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0166, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8902058442322712\n",
            "SCOPE mean: 4.269384035381176, SCOPE var: 7.104238640917905\n",
            "Total Loss: 0.9067962848831935\n",
            "----------------------------------------\n",
            "Epoch 123\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0165, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8817463824601788\n",
            "SCOPE mean: 4.268468377332228, SCOPE var: 7.094383609689656\n",
            "Total Loss: 0.8982154578699186\n",
            "----------------------------------------\n",
            "Epoch 124\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0164, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8734349910890228\n",
            "SCOPE mean: 4.267517469631088, SCOPE var: 7.084589517197331\n",
            "Total Loss: 0.8897906034638382\n",
            "----------------------------------------\n",
            "Epoch 125\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0162, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8652447374732966\n",
            "SCOPE mean: 4.266472774129488, SCOPE var: 7.074761778107696\n",
            "Total Loss: 0.8814899157629374\n",
            "----------------------------------------\n",
            "Epoch 126\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0161, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8571571896520648\n",
            "SCOPE mean: 4.265203607716762, SCOPE var: 7.064414911210328\n",
            "Total Loss: 0.8732968940265292\n",
            "----------------------------------------\n",
            "Epoch 127\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0160, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8492204827358347\n",
            "SCOPE mean: 4.263921380250023, SCOPE var: 7.054163572956766\n",
            "Total Loss: 0.8652546999225795\n",
            "----------------------------------------\n",
            "Epoch 128\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0159, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8413993219009268\n",
            "SCOPE mean: 4.2626314984138105, SCOPE var: 7.044012421997395\n",
            "Total Loss: 0.8573301124907847\n",
            "----------------------------------------\n",
            "Epoch 129\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0158, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8336863175993704\n",
            "SCOPE mean: 4.261333476706522, SCOPE var: 7.034139675860974\n",
            "Total Loss: 0.849512676781327\n",
            "----------------------------------------\n",
            "Epoch 130\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0157, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.82605493749397\n",
            "SCOPE mean: 4.260041068445239, SCOPE var: 7.0243933235621965\n",
            "Total Loss: 0.8417781197545352\n",
            "----------------------------------------\n",
            "Epoch 131\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0156, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8185231865940464\n",
            "SCOPE mean: 4.258735979636371, SCOPE var: 7.014730726429139\n",
            "Total Loss: 0.8341463835839502\n",
            "----------------------------------------\n",
            "Epoch 132\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0155, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8111013137433967\n",
            "SCOPE mean: 4.257423833400348, SCOPE var: 7.005139461477257\n",
            "Total Loss: 0.8266277264743206\n",
            "----------------------------------------\n",
            "Epoch 133\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0154, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8038533346967486\n",
            "SCOPE mean: 4.256165664805637, SCOPE var: 6.995736804777032\n",
            "Total Loss: 0.8192830200739004\n",
            "----------------------------------------\n",
            "Epoch 134\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0153, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7967345338077417\n",
            "SCOPE mean: 4.254928047596854, SCOPE var: 6.98647403167193\n",
            "Total Loss: 0.8120688579819548\n",
            "----------------------------------------\n",
            "Epoch 135\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0152, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7897409032850876\n",
            "SCOPE mean: 4.253712462082739, SCOPE var: 6.977352721725379\n",
            "Total Loss: 0.8049799995964394\n",
            "----------------------------------------\n",
            "Epoch 136\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0151, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7828858126302346\n",
            "SCOPE mean: 4.252546730234641, SCOPE var: 6.968360986631106\n",
            "Total Loss: 0.7980281976832874\n",
            "----------------------------------------\n",
            "Epoch 137\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0150, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7761305116056346\n",
            "SCOPE mean: 4.25143219622255, SCOPE var: 6.95949564791469\n",
            "Total Loss: 0.7911753056409495\n",
            "----------------------------------------\n",
            "Epoch 138\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0149, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7694903201383855\n",
            "SCOPE mean: 4.251526569305162, SCOPE var: 6.953577352544574\n",
            "Total Loss: 0.7844368763554035\n",
            "----------------------------------------\n",
            "Epoch 139\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0148, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7629482999609292\n",
            "SCOPE mean: 4.251988981804273, SCOPE var: 6.948580116355057\n",
            "Total Loss: 0.7777965180716582\n",
            "----------------------------------------\n",
            "Epoch 140\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0148, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.756481807707419\n",
            "SCOPE mean: 4.252469423503539, SCOPE var: 6.94364433729221\n",
            "Total Loss: 0.7712319648629303\n",
            "----------------------------------------\n",
            "Epoch 141\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0146, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7501208851853617\n",
            "SCOPE mean: 4.252973229268645, SCOPE var: 6.938759662614218\n",
            "Total Loss: 0.7647705223044079\n",
            "----------------------------------------\n",
            "Epoch 142\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0145, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7438653288993876\n",
            "SCOPE mean: 4.253466809208792, SCOPE var: 6.933879524862836\n",
            "Total Loss: 0.7584135937552695\n",
            "----------------------------------------\n",
            "Epoch 143\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0144, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7376961705561416\n",
            "SCOPE mean: 4.253940056362693, SCOPE var: 6.928974548772493\n",
            "Total Loss: 0.7521446713101856\n",
            "----------------------------------------\n",
            "Epoch 144\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0144, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7316230634813888\n",
            "SCOPE mean: 4.254426276885033, SCOPE var: 6.924027995315424\n",
            "Total Loss: 0.7459749740396902\n",
            "----------------------------------------\n",
            "Epoch 145\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0143, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7256273475858913\n",
            "SCOPE mean: 4.2549123513014475, SCOPE var: 6.91903681229355\n",
            "Total Loss: 0.7398844268138056\n",
            "----------------------------------------\n",
            "Epoch 146\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0142, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.719712831619744\n",
            "SCOPE mean: 4.255086483956293, SCOPE var: 6.913004804405104\n",
            "Total Loss: 0.7338773190832869\n",
            "----------------------------------------\n",
            "Epoch 147\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0141, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7138757087532056\n",
            "SCOPE mean: 4.255223659230666, SCOPE var: 6.906885812250001\n",
            "Total Loss: 0.7279500362693334\n",
            "----------------------------------------\n",
            "Epoch 148\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0140, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7081188146873788\n",
            "SCOPE mean: 4.255346747498575, SCOPE var: 6.9007788893177375\n",
            "Total Loss: 0.7221049517019394\n",
            "----------------------------------------\n",
            "Epoch 149\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0139, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7024426895790598\n",
            "SCOPE mean: 4.255211026320611, SCOPE var: 6.894687683558607\n",
            "Total Loss: 0.716341665546837\n",
            "----------------------------------------\n",
            "Epoch 150\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0138, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6968549957228126\n",
            "SCOPE mean: 4.254580647697007, SCOPE var: 6.888619293525167\n",
            "Total Loss: 0.7106695681934543\n",
            "----------------------------------------\n",
            "Epoch 151\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0137, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6913484220930747\n",
            "SCOPE mean: 4.254820431900186, SCOPE var: 6.886363243730219\n",
            "Total Loss: 0.7050816289367382\n",
            "----------------------------------------\n",
            "Epoch 152\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0137, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6859080926591725\n",
            "SCOPE mean: 4.255372295923161, SCOPE var: 6.885607933273477\n",
            "Total Loss: 0.6995631711611223\n",
            "----------------------------------------\n",
            "Epoch 153\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0136, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6805554470676216\n",
            "SCOPE mean: 4.255772506690249, SCOPE var: 6.884811366239641\n",
            "Total Loss: 0.6941365988238033\n",
            "----------------------------------------\n",
            "Epoch 154\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0135, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6752870748993541\n",
            "SCOPE mean: 4.256053957919771, SCOPE var: 6.883983134134791\n",
            "Total Loss: 0.6887970758071498\n",
            "----------------------------------------\n",
            "Epoch 155\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0134, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6700988540330063\n",
            "SCOPE mean: 4.256259321785414, SCOPE var: 6.883012609375817\n",
            "Total Loss: 0.6835398430978518\n",
            "----------------------------------------\n",
            "Epoch 156\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0134, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6649895311751823\n",
            "SCOPE mean: 4.25637430586762, SCOPE var: 6.881830313650465\n",
            "Total Loss: 0.6783635970938781\n",
            "----------------------------------------\n",
            "Epoch 157\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0133, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6599410824431139\n",
            "SCOPE mean: 4.256383349732872, SCOPE var: 6.880350664636711\n",
            "Total Loss: 0.6732505177214204\n",
            "----------------------------------------\n",
            "Epoch 158\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0132, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6549520433906089\n",
            "SCOPE mean: 4.256292238707028, SCOPE var: 6.878580668549503\n",
            "Total Loss: 0.6681983542079418\n",
            "----------------------------------------\n",
            "Epoch 159\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0132, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6500471895892512\n",
            "SCOPE mean: 4.256160376412408, SCOPE var: 6.876710623895802\n",
            "Total Loss: 0.6632318721419851\n",
            "----------------------------------------\n",
            "Epoch 160\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0131, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6452087786066312\n",
            "SCOPE mean: 4.255987136519934, SCOPE var: 6.874666867530772\n",
            "Total Loss: 0.658333108554122\n",
            "----------------------------------------\n",
            "Epoch 161\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0131, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6404397993652498\n",
            "SCOPE mean: 4.255760893759428, SCOPE var: 6.872431919236514\n",
            "Total Loss: 0.6535043669644505\n",
            "----------------------------------------\n",
            "Epoch 162\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0130, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6357507942055348\n",
            "SCOPE mean: 4.255463260348832, SCOPE var: 6.869959609418666\n",
            "Total Loss: 0.6487564265095321\n",
            "----------------------------------------\n",
            "Epoch 163\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0129, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6311342145274337\n",
            "SCOPE mean: 4.255104480308898, SCOPE var: 6.867255658981653\n",
            "Total Loss: 0.6440813865000597\n",
            "----------------------------------------\n",
            "Epoch 164\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0129, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6265819080401999\n",
            "SCOPE mean: 4.254651835834048, SCOPE var: 6.8641930746198705\n",
            "Total Loss: 0.6394710236639812\n",
            "----------------------------------------\n",
            "Epoch 165\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0128, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.622091395422267\n",
            "SCOPE mean: 4.254142269023528, SCOPE var: 6.860905711135447\n",
            "Total Loss: 0.634922878438376\n",
            "----------------------------------------\n",
            "Epoch 166\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0128, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6176673212342492\n",
            "SCOPE mean: 4.253599595557103, SCOPE var: 6.857471277330847\n",
            "Total Loss: 0.6304418531946966\n",
            "----------------------------------------\n",
            "Epoch 167\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0127, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6132960396452943\n",
            "SCOPE mean: 4.252902290095863, SCOPE var: 6.85331753603919\n",
            "Total Loss: 0.6260148212730625\n",
            "----------------------------------------\n",
            "Epoch 168\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0127, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6089745759513687\n",
            "SCOPE mean: 4.252073950386691, SCOPE var: 6.848670944290385\n",
            "Total Loss: 0.6216393809321646\n",
            "----------------------------------------\n",
            "Epoch 169\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0126, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6047055567976902\n",
            "SCOPE mean: 4.251232295928638, SCOPE var: 6.843993432815388\n",
            "Total Loss: 0.6173150698331226\n",
            "----------------------------------------\n",
            "Epoch 170\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0126, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6004778663319961\n",
            "SCOPE mean: 4.250386569350533, SCOPE var: 6.839291412121085\n",
            "Total Loss: 0.6130294065532906\n",
            "----------------------------------------\n",
            "Epoch 171\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0125, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5962931262334457\n",
            "SCOPE mean: 4.24951282572836, SCOPE var: 6.8346321111093795\n",
            "Total Loss: 0.6087870372825352\n",
            "----------------------------------------\n",
            "Epoch 172\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0124, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.592180595409472\n",
            "SCOPE mean: 4.248652819970453, SCOPE var: 6.830067053250825\n",
            "Total Loss: 0.6046186875993764\n",
            "----------------------------------------\n",
            "Epoch 173\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0124, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5881191678356129\n",
            "SCOPE mean: 4.24778655293837, SCOPE var: 6.825582641361997\n",
            "Total Loss: 0.600503201596216\n",
            "----------------------------------------\n",
            "Epoch 174\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0123, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.584108063255918\n",
            "SCOPE mean: 4.246916544074298, SCOPE var: 6.821186194281412\n",
            "Total Loss: 0.5964397727148721\n",
            "----------------------------------------\n",
            "Epoch 175\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0123, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5801466903129667\n",
            "SCOPE mean: 4.246042817435576, SCOPE var: 6.816863254411809\n",
            "Total Loss: 0.5924276848057899\n",
            "----------------------------------------\n",
            "Epoch 176\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0122, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5762309344462957\n",
            "SCOPE mean: 4.245169036798994, SCOPE var: 6.812621739887676\n",
            "Total Loss: 0.5884624757281361\n",
            "----------------------------------------\n",
            "Epoch 177\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0122, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5723723485845642\n",
            "SCOPE mean: 4.244296552837554, SCOPE var: 6.808481288806295\n",
            "Total Loss: 0.5845564172245226\n",
            "----------------------------------------\n",
            "Epoch 178\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0121, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5685639112098733\n",
            "SCOPE mean: 4.243465410023857, SCOPE var: 6.804385744645339\n",
            "Total Loss: 0.5807021106332283\n",
            "----------------------------------------\n",
            "Epoch 179\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0121, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5648026710969938\n",
            "SCOPE mean: 4.242660477839483, SCOPE var: 6.8003499416356\n",
            "Total Loss: 0.5768964509095886\n",
            "----------------------------------------\n",
            "Epoch 180\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0121, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5610936626186065\n",
            "SCOPE mean: 4.2418658410107, SCOPE var: 6.796384402746165\n",
            "Total Loss: 0.5731470430576403\n",
            "----------------------------------------\n",
            "Epoch 181\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0120, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.557432158858382\n",
            "SCOPE mean: 4.241031146811096, SCOPE var: 6.792303054313842\n",
            "Total Loss: 0.569445773434102\n",
            "----------------------------------------\n",
            "Epoch 182\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0120, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5538172759395085\n",
            "SCOPE mean: 4.240211520167251, SCOPE var: 6.788269568041253\n",
            "Total Loss: 0.5657906378775329\n",
            "----------------------------------------\n",
            "Epoch 183\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0119, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5502448817412181\n",
            "SCOPE mean: 4.239413967889263, SCOPE var: 6.78430239369989\n",
            "Total Loss: 0.5621781388333433\n",
            "----------------------------------------\n",
            "Epoch 184\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0119, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5466927563739176\n",
            "SCOPE mean: 4.238690793591735, SCOPE var: 6.780550046515812\n",
            "Total Loss: 0.5585847910099636\n",
            "----------------------------------------\n",
            "Epoch 185\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0118, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5431523471662255\n",
            "SCOPE mean: 4.238014789265039, SCOPE var: 6.776914657794389\n",
            "Total Loss: 0.5550020884778379\n",
            "----------------------------------------\n",
            "Epoch 186\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0118, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.539647532995817\n",
            "SCOPE mean: 4.237428480018411, SCOPE var: 6.773574735948059\n",
            "Total Loss: 0.5514551581993666\n",
            "----------------------------------------\n",
            "Epoch 187\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0118, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5361772299006773\n",
            "SCOPE mean: 4.236929084042061, SCOPE var: 6.770499532608863\n",
            "Total Loss: 0.5479421640836367\n",
            "----------------------------------------\n",
            "Epoch 188\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0117, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.532740656844343\n",
            "SCOPE mean: 4.236520373921131, SCOPE var: 6.767697666467639\n",
            "Total Loss: 0.5444618793614313\n",
            "----------------------------------------\n",
            "Epoch 189\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0117, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5293318335873122\n",
            "SCOPE mean: 4.236186679881772, SCOPE var: 6.7651240780194515\n",
            "Total Loss: 0.5410083815731377\n",
            "----------------------------------------\n",
            "Epoch 190\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0116, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5259560484509468\n",
            "SCOPE mean: 4.235913398284583, SCOPE var: 6.7627628877204895\n",
            "Total Loss: 0.5375862418977124\n",
            "----------------------------------------\n",
            "Epoch 191\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0116, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5226087102040087\n",
            "SCOPE mean: 4.235742120638658, SCOPE var: 6.7606859027042026\n",
            "Total Loss: 0.5341931458153841\n",
            "----------------------------------------\n",
            "Epoch 192\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0115, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5192871822785861\n",
            "SCOPE mean: 4.235643356655382, SCOPE var: 6.758756449114711\n",
            "Total Loss: 0.5308285679341701\n",
            "----------------------------------------\n",
            "Epoch 193\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0115, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5159952206653943\n",
            "SCOPE mean: 4.235597446916212, SCOPE var: 6.757007331331007\n",
            "Total Loss: 0.5274949151630834\n",
            "----------------------------------------\n",
            "Epoch 194\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0115, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5127362859618488\n",
            "SCOPE mean: 4.2355947708216, SCOPE var: 6.7554156618793195\n",
            "Total Loss: 0.5241942406577154\n",
            "----------------------------------------\n",
            "Epoch 195\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0114, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5095125100849975\n",
            "SCOPE mean: 4.235610759335806, SCOPE var: 6.753899155377785\n",
            "Total Loss: 0.5209289531324147\n",
            "----------------------------------------\n",
            "Epoch 196\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0114, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5063268847735888\n",
            "SCOPE mean: 4.235635659403956, SCOPE var: 6.7524584112272805\n",
            "Total Loss: 0.5177019511877519\n",
            "----------------------------------------\n",
            "Epoch 197\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0113, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5031803329146486\n",
            "SCOPE mean: 4.235672161125162, SCOPE var: 6.75109253768902\n",
            "Total Loss: 0.5145139627972077\n",
            "----------------------------------------\n",
            "Epoch 198\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0113, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5000762617855163\n",
            "SCOPE mean: 4.235686229055385, SCOPE var: 6.749774281787943\n",
            "Total Loss: 0.5113686259073515\n",
            "----------------------------------------\n",
            "Epoch 199\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0113, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4970122115944136\n",
            "SCOPE mean: 4.235674415780541, SCOPE var: 6.748452795952637\n",
            "Total Loss: 0.5082632345938763\n",
            "----------------------------------------\n",
            "Epoch 200\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0112, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4939875244156402\n",
            "SCOPE mean: 4.23562725872374, SCOPE var: 6.747093784568198\n",
            "Total Loss: 0.5051972515080217\n",
            "----------------------------------------\n",
            "Epoch 201\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0112, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4910003884188965\n",
            "SCOPE mean: 4.235537911635278, SCOPE var: 6.7456802834412946\n",
            "Total Loss: 0.5021692334949049\n",
            "----------------------------------------\n",
            "Epoch 202\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0111, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.48804955162244723\n",
            "SCOPE mean: 4.23543243217885, SCOPE var: 6.744193558581648\n",
            "Total Loss: 0.4991780168370464\n",
            "----------------------------------------\n",
            "Epoch 203\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0111, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4851343123601536\n",
            "SCOPE mean: 4.235323849727321, SCOPE var: 6.742600850254695\n",
            "Total Loss: 0.4962223161410968\n",
            "----------------------------------------\n",
            "Epoch 204\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0110, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4822666103171797\n",
            "SCOPE mean: 4.2351689247090665, SCOPE var: 6.740896051282873\n",
            "Total Loss: 0.49331437166653863\n",
            "----------------------------------------\n",
            "Epoch 205\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0110, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.47943067156450103\n",
            "SCOPE mean: 4.234963519802905, SCOPE var: 6.739062236775729\n",
            "Total Loss: 0.49043823738033043\n",
            "----------------------------------------\n",
            "Epoch 206\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0110, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.47662661961415254\n",
            "SCOPE mean: 4.234725597487608, SCOPE var: 6.737104590457307\n",
            "Total Loss: 0.4875928656543745\n",
            "----------------------------------------\n",
            "Epoch 207\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0109, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.47385970970133157\n",
            "SCOPE mean: 4.23445780636495, SCOPE var: 6.734996349602008\n",
            "Total Loss: 0.48478136468246785\n",
            "----------------------------------------\n",
            "Epoch 208\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0109, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4711161206668432\n",
            "SCOPE mean: 4.234157044152791, SCOPE var: 6.732739327992057\n",
            "Total Loss: 0.4819911376754945\n",
            "----------------------------------------\n",
            "Epoch 209\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0108, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.468404259808119\n",
            "SCOPE mean: 4.233808229101287, SCOPE var: 6.730328509001572\n",
            "Total Loss: 0.479230855382262\n",
            "----------------------------------------\n",
            "Epoch 210\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0108, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.46572820545336097\n",
            "SCOPE mean: 4.233429112437977, SCOPE var: 6.727814844067092\n",
            "Total Loss: 0.47650500603517937\n",
            "----------------------------------------\n",
            "Epoch 211\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0107, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.46308376026153286\n",
            "SCOPE mean: 4.233021765949697, SCOPE var: 6.725202418984339\n",
            "Total Loss: 0.47381010610242713\n",
            "----------------------------------------\n",
            "Epoch 212\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0107, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4604665461978892\n",
            "SCOPE mean: 4.2325855021847705, SCOPE var: 6.722497138381356\n",
            "Total Loss: 0.4711396576715076\n",
            "----------------------------------------\n",
            "Epoch 213\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0106, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.457878305610097\n",
            "SCOPE mean: 4.232111621010868, SCOPE var: 6.719661750575514\n",
            "Total Loss: 0.46849817296587276\n",
            "----------------------------------------\n",
            "Epoch 214\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0106, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.45531203490363514\n",
            "SCOPE mean: 4.231572545322005, SCOPE var: 6.716575718928932\n",
            "Total Loss: 0.46587724449709245\n",
            "----------------------------------------\n",
            "Epoch 215\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0105, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.45278304148083226\n",
            "SCOPE mean: 4.231002072177797, SCOPE var: 6.713437616608603\n",
            "Total Loss: 0.4632943971424224\n",
            "----------------------------------------\n",
            "Epoch 216\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0105, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4502909830733412\n",
            "SCOPE mean: 4.230425307210366, SCOPE var: 6.7103753216128945\n",
            "Total Loss: 0.46075162178944645\n",
            "----------------------------------------\n",
            "Epoch 217\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0104, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.44783770392818223\n",
            "SCOPE mean: 4.229863414885733, SCOPE var: 6.707405682368954\n",
            "Total Loss: 0.4582513108053505\n",
            "----------------------------------------\n",
            "Epoch 218\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0104, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.44541133949018175\n",
            "SCOPE mean: 4.229312667987329, SCOPE var: 6.704524797925819\n",
            "Total Loss: 0.45577961758856317\n",
            "----------------------------------------\n",
            "Epoch 219\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0103, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4430142456089375\n",
            "SCOPE mean: 4.228786042994582, SCOPE var: 6.701716394810626\n",
            "Total Loss: 0.45333725316526746\n",
            "----------------------------------------\n",
            "Epoch 220\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0103, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.44064429035173336\n",
            "SCOPE mean: 4.228284464540587, SCOPE var: 6.6989928383188895\n",
            "Total Loss: 0.45092249750669616\n",
            "----------------------------------------\n",
            "Epoch 221\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0102, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.43830140288378494\n",
            "SCOPE mean: 4.22780916312984, SCOPE var: 6.696360016851704\n",
            "Total Loss: 0.44853778917283377\n",
            "----------------------------------------\n",
            "Epoch 222\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0102, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4359864454922378\n",
            "SCOPE mean: 4.227351891125838, SCOPE var: 6.6937844095415295\n",
            "Total Loss: 0.44619057782241633\n",
            "----------------------------------------\n",
            "Epoch 223\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0102, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.43368619648625767\n",
            "SCOPE mean: 4.226917128964764, SCOPE var: 6.691279112162048\n",
            "Total Loss: 0.44385383742853557\n",
            "----------------------------------------\n",
            "Epoch 224\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0101, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.43140682206274256\n",
            "SCOPE mean: 4.22652120975109, SCOPE var: 6.688927098104963\n",
            "Total Loss: 0.4415398856449451\n",
            "----------------------------------------\n",
            "Epoch 225\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0101, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4291487451391862\n",
            "SCOPE mean: 4.226163977626794, SCOPE var: 6.686727045826376\n",
            "Total Loss: 0.4392490723974652\n",
            "----------------------------------------\n",
            "Epoch 226\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0101, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.42690826142978694\n",
            "SCOPE mean: 4.225847928015725, SCOPE var: 6.684688061680264\n",
            "Total Loss: 0.436978053451179\n",
            "----------------------------------------\n",
            "Epoch 227\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0100, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4246828135539961\n",
            "SCOPE mean: 4.22558735949743, SCOPE var: 6.682804926394036\n",
            "Total Loss: 0.4347242212122114\n",
            "----------------------------------------\n",
            "Epoch 228\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0100, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.42248090060748694\n",
            "SCOPE mean: 4.225375861159282, SCOPE var: 6.681063986558035\n",
            "Total Loss: 0.4324939692232671\n",
            "----------------------------------------\n",
            "Epoch 229\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0100, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.42030283465407053\n",
            "SCOPE mean: 4.225198146346962, SCOPE var: 6.679447505790359\n",
            "Total Loss: 0.43028809126681145\n",
            "----------------------------------------\n",
            "Epoch 230\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0100, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.41814441446228034\n",
            "SCOPE mean: 4.225050958500725, SCOPE var: 6.677952644335283\n",
            "Total Loss: 0.4281030846359941\n",
            "----------------------------------------\n",
            "Epoch 231\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0099, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.41600710381487194\n",
            "SCOPE mean: 4.224909385617896, SCOPE var: 6.676614360264069\n",
            "Total Loss: 0.42594247711362404\n",
            "----------------------------------------\n",
            "Epoch 232\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0099, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4138930123228977\n",
            "SCOPE mean: 4.224773249613497, SCOPE var: 6.675409866790865\n",
            "Total Loss: 0.42380704450815043\n",
            "----------------------------------------\n",
            "Epoch 233\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0099, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4118051061079036\n",
            "SCOPE mean: 4.224662323681101, SCOPE var: 6.674311624263632\n",
            "Total Loss: 0.4216983080043248\n",
            "----------------------------------------\n",
            "Epoch 234\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0099, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4097475583366744\n",
            "SCOPE mean: 4.224572501890197, SCOPE var: 6.673299912259543\n",
            "Total Loss: 0.41962005932852803\n",
            "----------------------------------------\n",
            "Epoch 235\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0098, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4077228278658192\n",
            "SCOPE mean: 4.224498691491705, SCOPE var: 6.6723497252680115\n",
            "Total Loss: 0.4175726554073088\n",
            "----------------------------------------\n",
            "Epoch 236\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0098, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.405719004209386\n",
            "SCOPE mean: 4.2244358726859685, SCOPE var: 6.671438041216563\n",
            "Total Loss: 0.41554549259404905\n",
            "----------------------------------------\n",
            "Epoch 237\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0098, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.40373964530228645\n",
            "SCOPE mean: 4.224375413492285, SCOPE var: 6.670515191632047\n",
            "Total Loss: 0.41354449924419057\n",
            "----------------------------------------\n",
            "Epoch 238\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0098, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.40178733475949785\n",
            "SCOPE mean: 4.2243107729664935, SCOPE var: 6.669667685325596\n",
            "Total Loss: 0.41156996063901036\n",
            "----------------------------------------\n",
            "Epoch 239\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0098, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.399859808301974\n",
            "SCOPE mean: 4.224241556405858, SCOPE var: 6.6688606302536915\n",
            "Total Loss: 0.4096193926564012\n",
            "----------------------------------------\n",
            "Epoch 240\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0097, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3979544167754239\n",
            "SCOPE mean: 4.224166543298452, SCOPE var: 6.668064049460991\n",
            "Total Loss: 0.40769012778621855\n",
            "----------------------------------------\n",
            "Epoch 241\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0097, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.39607285794430197\n",
            "SCOPE mean: 4.224084843587321, SCOPE var: 6.667252492579646\n",
            "Total Loss: 0.4057837819803568\n",
            "----------------------------------------\n",
            "Epoch 242\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0097, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3942169821775861\n",
            "SCOPE mean: 4.223996473465084, SCOPE var: 6.666402624927176\n",
            "Total Loss: 0.40390215955953573\n",
            "----------------------------------------\n",
            "Epoch 243\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0097, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.39238094361957915\n",
            "SCOPE mean: 4.223958429097396, SCOPE var: 6.665568647380738\n",
            "Total Loss: 0.4020386553944553\n",
            "----------------------------------------\n",
            "Epoch 244\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0096, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.390571363092112\n",
            "SCOPE mean: 4.22396268664347, SCOPE var: 6.6647350653141055\n",
            "Total Loss: 0.40020048830775296\n",
            "----------------------------------------\n",
            "Epoch 245\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0096, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.38878436876731176\n",
            "SCOPE mean: 4.22402443705433, SCOPE var: 6.663877544219394\n",
            "Total Loss: 0.3983825616208326\n",
            "----------------------------------------\n",
            "Epoch 246\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0096, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3870142525042789\n",
            "SCOPE mean: 4.224086729300473, SCOPE var: 6.66294382498774\n",
            "Total Loss: 0.3965779054251814\n",
            "----------------------------------------\n",
            "Epoch 247\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0095, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.38526116344868105\n",
            "SCOPE mean: 4.22411296800369, SCOPE var: 6.661938725080817\n",
            "Total Loss: 0.3947872771712134\n",
            "----------------------------------------\n",
            "Epoch 248\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0095, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.38352329058410833\n",
            "SCOPE mean: 4.224110188376345, SCOPE var: 6.660930834087072\n",
            "Total Loss: 0.393009536082115\n",
            "----------------------------------------\n",
            "Epoch 249\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0094, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3817992558280908\n",
            "SCOPE mean: 4.224078032803326, SCOPE var: 6.659889343610398\n",
            "Total Loss: 0.3912462542322959\n",
            "----------------------------------------\n",
            "Epoch 250\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0094, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3800915908817244\n",
            "SCOPE mean: 4.224013410943197, SCOPE var: 6.6588155080182805\n",
            "Total Loss: 0.389499989632866\n",
            "----------------------------------------\n",
            "Epoch 251\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0094, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.37840094041008354\n",
            "SCOPE mean: 4.2239243249547425, SCOPE var: 6.657725740375363\n",
            "Total Loss: 0.3877712515950598\n",
            "----------------------------------------\n",
            "Epoch 252\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0093, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.37672174783917595\n",
            "SCOPE mean: 4.223816033187404, SCOPE var: 6.65664549748444\n",
            "Total Loss: 0.3860543632392567\n",
            "----------------------------------------\n",
            "Epoch 253\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0093, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.37505672660641154\n",
            "SCOPE mean: 4.223689667023415, SCOPE var: 6.6555552613657\n",
            "Total Loss: 0.3843519544960216\n",
            "----------------------------------------\n",
            "Epoch 254\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0093, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3734092998684948\n",
            "SCOPE mean: 4.223548385859738, SCOPE var: 6.654475754669899\n",
            "Total Loss: 0.3826670432133016\n",
            "----------------------------------------\n",
            "Epoch 255\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0092, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3717758800353888\n",
            "SCOPE mean: 4.223388684802362, SCOPE var: 6.653406855107759\n",
            "Total Loss: 0.38099630348727137\n",
            "----------------------------------------\n",
            "Epoch 256\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0092, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3701618750521364\n",
            "SCOPE mean: 4.223206955579178, SCOPE var: 6.652324928158583\n",
            "Total Loss: 0.3793445278469585\n",
            "----------------------------------------\n",
            "Epoch 257\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0091, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.36856935271306807\n",
            "SCOPE mean: 4.223009944322713, SCOPE var: 6.651231673830367\n",
            "Total Loss: 0.37771336027861463\n",
            "----------------------------------------\n",
            "Epoch 258\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0091, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.36699296834897843\n",
            "SCOPE mean: 4.222803092927965, SCOPE var: 6.650138392430946\n",
            "Total Loss: 0.3760975064912064\n",
            "----------------------------------------\n",
            "Epoch 259\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0091, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3654313429248254\n",
            "SCOPE mean: 4.22258750591966, SCOPE var: 6.649032612767876\n",
            "Total Loss: 0.37449576561217085\n",
            "----------------------------------------\n",
            "Epoch 260\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0090, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3638859703038949\n",
            "SCOPE mean: 4.222438833686854, SCOPE var: 6.64813437604904\n",
            "Total Loss: 0.37291021139220665\n",
            "----------------------------------------\n",
            "Epoch 261\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0090, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3623704587316149\n",
            "SCOPE mean: 4.222362219802255, SCOPE var: 6.647441342542699\n",
            "Total Loss: 0.37135273778361555\n",
            "----------------------------------------\n",
            "Epoch 262\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0089, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3608861035308878\n",
            "SCOPE mean: 4.222308735663181, SCOPE var: 6.646738690643641\n",
            "Total Loss: 0.36981772590943196\n",
            "----------------------------------------\n",
            "Epoch 263\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0089, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.35941783209275474\n",
            "SCOPE mean: 4.222263479406518, SCOPE var: 6.646123296292819\n",
            "Total Loss: 0.3682951644691844\n",
            "----------------------------------------\n",
            "Epoch 264\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0088, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3579671866201323\n",
            "SCOPE mean: 4.222223448391192, SCOPE var: 6.645541229152787\n",
            "Total Loss: 0.3667879373873821\n",
            "----------------------------------------\n",
            "Epoch 265\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0088, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3565305347445238\n",
            "SCOPE mean: 4.222198469116667, SCOPE var: 6.6449578101674645\n",
            "Total Loss: 0.36529251267833657\n",
            "----------------------------------------\n",
            "Epoch 266\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0087, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.35509785674864447\n",
            "SCOPE mean: 4.222181364900671, SCOPE var: 6.644369757985829\n",
            "Total Loss: 0.3638001884959207\n",
            "----------------------------------------\n",
            "Epoch 267\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0086, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.35367572496508176\n",
            "SCOPE mean: 4.2221560326741585, SCOPE var: 6.643691728630068\n",
            "Total Loss: 0.36232172434421916\n",
            "----------------------------------------\n",
            "Epoch 268\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0086, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.35226704169551964\n",
            "SCOPE mean: 4.222222878525817, SCOPE var: 6.64318825807383\n",
            "Total Loss: 0.3608576909690035\n",
            "----------------------------------------\n",
            "Epoch 269\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0085, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.35086775792554564\n",
            "SCOPE mean: 4.222289276804311, SCOPE var: 6.642615389579193\n",
            "Total Loss: 0.3594045226288108\n",
            "----------------------------------------\n",
            "Epoch 270\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0085, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3494748797596627\n",
            "SCOPE mean: 4.222330371153293, SCOPE var: 6.641933133547401\n",
            "Total Loss: 0.35795846392420755\n",
            "----------------------------------------\n",
            "Epoch 271\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0084, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.34809211008291285\n",
            "SCOPE mean: 4.222332347626296, SCOPE var: 6.641189421427227\n",
            "Total Loss: 0.35652454116793186\n",
            "----------------------------------------\n",
            "Epoch 272\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0084, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.34671834567875864\n",
            "SCOPE mean: 4.222304684919822, SCOPE var: 6.6404151270360074\n",
            "Total Loss: 0.3551015117086637\n",
            "----------------------------------------\n",
            "Epoch 273\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0083, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3453563090546021\n",
            "SCOPE mean: 4.222257932938813, SCOPE var: 6.639647682530575\n",
            "Total Loss: 0.353691894018561\n",
            "----------------------------------------\n",
            "Epoch 274\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0083, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.34400121974808673\n",
            "SCOPE mean: 4.222202926022532, SCOPE var: 6.638915440302044\n",
            "Total Loss: 0.35229068261717156\n",
            "----------------------------------------\n",
            "Epoch 275\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0082, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3426585830375803\n",
            "SCOPE mean: 4.222131206806763, SCOPE var: 6.63820578722011\n",
            "Total Loss: 0.3509025641847039\n",
            "----------------------------------------\n",
            "Epoch 276\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0082, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3413253456331797\n",
            "SCOPE mean: 4.22211697183221, SCOPE var: 6.637758336343288\n",
            "Total Loss: 0.34952602872312716\n",
            "----------------------------------------\n",
            "Epoch 277\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0082, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3400003591316518\n",
            "SCOPE mean: 4.2221488393284226, SCOPE var: 6.637530429803495\n",
            "Total Loss: 0.3481602624907647\n",
            "----------------------------------------\n",
            "Epoch 278\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0081, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3386854122470245\n",
            "SCOPE mean: 4.222165059334517, SCOPE var: 6.637292265025421\n",
            "Total Loss: 0.3468063148871368\n",
            "----------------------------------------\n",
            "Epoch 279\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0081, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.33737798914601247\n",
            "SCOPE mean: 4.2219707212746025, SCOPE var: 6.636606919431359\n",
            "Total Loss: 0.34546056745764947\n",
            "----------------------------------------\n",
            "Epoch 280\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0080, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3360804809339014\n",
            "SCOPE mean: 4.221795381004517, SCOPE var: 6.6360100623811515\n",
            "Total Loss: 0.34412541746907893\n",
            "----------------------------------------\n",
            "Epoch 281\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0080, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3348057021055493\n",
            "SCOPE mean: 4.221636326278276, SCOPE var: 6.635477852989263\n",
            "Total Loss: 0.34281317368328085\n",
            "----------------------------------------\n",
            "Epoch 282\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0080, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3335414144049761\n",
            "SCOPE mean: 4.221426003696283, SCOPE var: 6.63478414634162\n",
            "Total Loss: 0.34151094152642164\n",
            "----------------------------------------\n",
            "Epoch 283\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0079, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3322900278540953\n",
            "SCOPE mean: 4.221151999967289, SCOPE var: 6.633901335372111\n",
            "Total Loss: 0.340221542300585\n",
            "----------------------------------------\n",
            "Epoch 284\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0079, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.33105212935294476\n",
            "SCOPE mean: 4.220821108583384, SCOPE var: 6.632851685677879\n",
            "Total Loss: 0.338947168727184\n",
            "----------------------------------------\n",
            "Epoch 285\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0079, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.32982449362307725\n",
            "SCOPE mean: 4.220440252168971, SCOPE var: 6.631644589193384\n",
            "Total Loss: 0.33768337971528295\n",
            "----------------------------------------\n",
            "Epoch 286\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0078, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.32860897664356337\n",
            "SCOPE mean: 4.22000943671238, SCOPE var: 6.630287273156466\n",
            "Total Loss: 0.33643210629265685\n",
            "----------------------------------------\n",
            "Epoch 287\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0078, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3274049471796827\n",
            "SCOPE mean: 4.219531990241376, SCOPE var: 6.628786160375825\n",
            "Total Loss: 0.33519260908477727\n",
            "----------------------------------------\n",
            "Epoch 288\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0078, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.32621213698220936\n",
            "SCOPE mean: 4.218965003855533, SCOPE var: 6.627153337404789\n",
            "Total Loss: 0.33396456792338763\n",
            "----------------------------------------\n",
            "Epoch 289\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0077, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3250324218162313\n",
            "SCOPE mean: 4.218333055038319, SCOPE var: 6.625424790974836\n",
            "Total Loss: 0.3327495803913651\n",
            "----------------------------------------\n",
            "Epoch 290\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0077, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.32386498782186707\n",
            "SCOPE mean: 4.217664637913664, SCOPE var: 6.6236160321544055\n",
            "Total Loss: 0.33154581800205146\n",
            "----------------------------------------\n",
            "Epoch 291\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0076, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.32271216114904594\n",
            "SCOPE mean: 4.216954763994737, SCOPE var: 6.621750175086501\n",
            "Total Loss: 0.33035586005073164\n",
            "----------------------------------------\n",
            "Epoch 292\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0076, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.32156704242455497\n",
            "SCOPE mean: 4.216221813193102, SCOPE var: 6.619852251132351\n",
            "Total Loss: 0.32917189212257775\n",
            "----------------------------------------\n",
            "Epoch 293\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0076, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.32043036200217856\n",
            "SCOPE mean: 4.2154662265097445, SCOPE var: 6.617937074207192\n",
            "Total Loss: 0.3279959909444778\n",
            "----------------------------------------\n",
            "Epoch 294\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0075, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.31930430630286477\n",
            "SCOPE mean: 4.214692574842156, SCOPE var: 6.616011221887329\n",
            "Total Loss: 0.32682973035698115\n",
            "----------------------------------------\n",
            "Epoch 295\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0075, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.31818125532535446\n",
            "SCOPE mean: 4.213880358289208, SCOPE var: 6.61404620760203\n",
            "Total Loss: 0.3256639917741041\n",
            "----------------------------------------\n",
            "Epoch 296\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0074, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3170694355523966\n",
            "SCOPE mean: 4.213041012143315, SCOPE var: 6.612059773143083\n",
            "Total Loss: 0.3245084864756277\n",
            "----------------------------------------\n",
            "Epoch 297\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0074, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3159625091563251\n",
            "SCOPE mean: 4.212240093182003, SCOPE var: 6.610214494639036\n",
            "Total Loss: 0.3233609333828804\n",
            "----------------------------------------\n",
            "Epoch 298\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0074, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.31486723662018185\n",
            "SCOPE mean: 4.211230553486861, SCOPE var: 6.607494146381001\n",
            "Total Loss: 0.3222263888354822\n",
            "----------------------------------------\n",
            "Epoch 299\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0073, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.31378064155637225\n",
            "SCOPE mean: 4.210164061853461, SCOPE var: 6.604574416275857\n",
            "Total Loss: 0.3210999677098613\n",
            "----------------------------------------\n",
            "Epoch 300\n",
            "IS mean: 2.9507531033554093,IS variance: 3.5003270241318494\n",
            "SCOPE Var loss:  tensor(0.0073, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3127020872602261\n",
            "SCOPE mean: 4.209040094293264, SCOPE var: 6.601461248789077\n",
            "Total Loss: 0.31998166989683846\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[-0.0186, -0.1972],\n",
            "        [-0.3706, -0.3068],\n",
            "        [ 0.1000, -0.1462],\n",
            "        [-0.5364, -0.5308],\n",
            "        [ 0.2475,  0.3392],\n",
            "        [ 0.4109, -0.4547],\n",
            "        [-0.3092, -0.5198],\n",
            "        [-0.7062,  0.5050],\n",
            "        [-0.3738, -0.4623],\n",
            "        [-0.3052, -0.0055],\n",
            "        [ 0.2245,  0.0519],\n",
            "        [-0.7138,  0.4720],\n",
            "        [ 0.1843,  0.1505],\n",
            "        [ 0.1673, -0.0806],\n",
            "        [ 0.0089,  0.2165],\n",
            "        [-0.2221, -0.4742]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([-0.0533, -0.3120, -0.4911, -0.5761,  0.2586,  0.3150, -0.2647, -0.4351,\n",
            "        -0.5832, -0.2371, -0.2653, -0.5819, -0.6700,  0.5082,  0.4087, -0.4199],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[-0.1177,  0.0552, -0.1272, -0.1992,  0.1355,  0.0674, -0.1609, -0.0090,\n",
            "         -0.1216,  0.1443, -0.1989,  0.1169, -0.0053, -0.0466, -0.1978, -0.0437],\n",
            "        [ 0.1405,  0.0375, -0.1717, -0.0944, -0.1968, -0.1396,  0.0098, -0.0300,\n",
            "         -0.0414, -0.0584, -0.0884, -0.0543,  0.1135, -0.1216, -0.0309, -0.1156],\n",
            "        [-0.1156, -0.2106, -0.1061, -0.1215, -0.0818, -0.0063,  0.1165,  0.0590,\n",
            "          0.0276,  0.0368, -0.0954, -0.1092,  0.0211,  0.0784,  0.0459,  0.0711],\n",
            "        [ 0.0458,  0.2251,  0.1422, -0.0038, -0.1818,  0.1602, -0.0106,  0.0182,\n",
            "         -0.0628, -0.0223, -0.2421, -0.0826, -0.0712,  0.1277, -0.2395, -0.1720],\n",
            "        [-0.0031, -0.2483,  0.1245,  0.1643,  0.0319, -0.0192,  0.0911, -0.1068,\n",
            "          0.1842, -0.2327,  0.1759,  0.0931, -0.0088,  0.0911,  0.1583, -0.2459],\n",
            "        [-0.2132,  0.2441,  0.1869, -0.1061,  0.0728, -0.2889,  0.2160,  0.1549,\n",
            "          0.0179, -0.1739,  0.1174, -0.0837, -0.0342, -0.2804,  0.1571, -0.0475],\n",
            "        [ 0.2275, -0.1066, -0.0503,  0.1472,  0.1353, -0.1771, -0.1157,  0.0330,\n",
            "          0.0511,  0.2034, -0.1906,  0.0689, -0.2303, -0.1641,  0.1435,  0.2126],\n",
            "        [ 0.0831,  0.1702,  0.0015,  0.2022, -0.0477, -0.1386,  0.1440,  0.1088,\n",
            "         -0.0738,  0.0414,  0.1556, -0.1171, -0.2864,  0.0841, -0.1009, -0.2164],\n",
            "        [ 0.2111, -0.0143,  0.0281,  0.0009, -0.2137, -0.0990, -0.0071, -0.1654,\n",
            "         -0.1809,  0.2044, -0.1286, -0.1565,  0.0500,  0.1399, -0.2498, -0.0017],\n",
            "        [ 0.1093, -0.1100,  0.2732, -0.1925,  0.0771,  0.1789,  0.0990, -0.1023,\n",
            "          0.0691,  0.2447,  0.0564,  0.1059, -0.0877, -0.0321,  0.1497,  0.0439],\n",
            "        [-0.1150, -0.0344,  0.1085,  0.0541, -0.0604,  0.1290,  0.0160,  0.0306,\n",
            "         -0.0168,  0.2171, -0.2543,  0.0901, -0.2779,  0.0997,  0.1065,  0.1476],\n",
            "        [ 0.0539, -0.2007, -0.0091, -0.2019,  0.1514,  0.0591,  0.2311,  0.0542,\n",
            "          0.0942, -0.1031,  0.1888, -0.0418, -0.0196, -0.1072,  0.0234, -0.2097],\n",
            "        [ 0.0199,  0.1871,  0.1476,  0.2301, -0.0083,  0.1016,  0.0172, -0.1509,\n",
            "         -0.2080, -0.2113,  0.0065,  0.0611, -0.2734, -0.0087,  0.1064,  0.1663],\n",
            "        [ 0.0864,  0.1208,  0.0491, -0.1497, -0.0831, -0.2781,  0.1436, -0.0360,\n",
            "          0.1342,  0.1814, -0.0037, -0.1737, -0.2558, -0.0280,  0.0233,  0.0246],\n",
            "        [ 0.0765,  0.0677,  0.2086, -0.0259,  0.1617, -0.0395,  0.2338, -0.0447,\n",
            "          0.0088, -0.0649, -0.1082, -0.2023, -0.1654,  0.0966, -0.0250,  0.0133],\n",
            "        [-0.2097,  0.1283, -0.0238, -0.0258,  0.0218,  0.1204,  0.0710,  0.1481,\n",
            "         -0.1164, -0.1588, -0.0186, -0.1106,  0.3011, -0.0915, -0.2457, -0.0748]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([ 0.1550, -0.1365,  0.3645, -0.0675, -0.3628, -0.1005,  0.0984,  0.3552,\n",
            "        -0.0637,  0.0910,  0.1327,  0.1575,  0.1338, -0.0208, -0.0060,  0.1369],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[ 0.1512, -0.2177,  0.1789, -0.1343, -0.2795, -0.0414,  0.0951,  0.2874,\n",
            "         -0.1857,  0.0787,  0.1388,  0.0037,  0.2107, -0.1793,  0.1226, -0.1272]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([0.2323], dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NN_l1_l2_reg(\n",
              "  (hidden_layers): ModuleList(\n",
              "    (0): Linear(in_features=2, out_features=16, bias=True)\n",
              "    (1): Linear(in_features=16, out_features=16, bias=True)\n",
              "  )\n",
              "  (output_layer): Linear(in_features=16, out_features=1, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b_400_mse = action_probs_top_n_epsilon(q_table, 1, 0.4)\n",
        "pi_b_400_mse = experiment_actions(400, env_50, P_pi_b_400_mse)\n",
        "P_pi_e_400 = action_probs_top_n_epsilon(q_table, 1, 0.05)\n",
        "pi_e_400 = experiment_actions(1000, env_50, P_pi_e_400)\n",
        "# model_400_random_pi_b_400_mse = CustomizableFeatureNet(input_dim=2, hidden_dims=[16, 16], output_dim=1, dtype = torch.float64, l2_lambda=0.002)\n",
        "model_400_random_pi_b_400_mse = NN_l1_l2_reg(input_dim=2, hidden_dims=[16, 16], output_dim=1, dtype = torch.float64, l1_lambda=0.0001, l2_lambda = 0.0005)\n",
        "test_400_random_pi_b_400_mse = SCOPE_straight(model_400_random_pi_b_400_mse, 0.99, 10000, pi_b_400_mse, P_pi_b_400_mse, P_pi_e_400, 0.3, dtype = torch.float64)\n",
        "test_400_random_pi_b_400_mse.train_var_scope(600, 0.001, 1, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f44f4ef-45f3-4286-a28a-14d343b6e46e",
        "id": "j_4qtxlfGL29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.3585, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.026483337294023\n",
            "SCOPE mean: -0.3274251616380668, SCOPE var: 0.018818881618883634\n",
            "Total Loss: 8.384968384201166\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.1559, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.740368690579542\n",
            "SCOPE mean: -0.3001916661651302, SCOPE var: 0.01861144103359731\n",
            "Total Loss: 7.896251552620683\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.1548, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.3163314681292\n",
            "SCOPE mean: -0.27308848557382137, SCOPE var: 0.018401832793966046\n",
            "Total Loss: 7.471105743491664\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.1542, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.939262358102072\n",
            "SCOPE mean: -0.2467067581613132, SCOPE var: 0.018188274750353343\n",
            "Total Loss: 7.093475849702674\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.1538, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.606017449224516\n",
            "SCOPE mean: -0.22102322343870165, SCOPE var: 0.018000412180621334\n",
            "Total Loss: 6.7598002972090345\n",
            "----------------------------------------\n",
            "Epoch 6\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.1534, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.313538024706658\n",
            "SCOPE mean: -0.19617372166500321, SCOPE var: 0.01784227333512784\n",
            "Total Loss: 6.466936055815047\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.1527, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.058113239003495\n",
            "SCOPE mean: -0.17228139520215618, SCOPE var: 0.01771273962662911\n",
            "Total Loss: 6.210825042112578\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.1520, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.835801462738884\n",
            "SCOPE mean: -0.14950288004013562, SCOPE var: 0.017610955700976753\n",
            "Total Loss: 5.987797155671017\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.1513, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.6421194539805954\n",
            "SCOPE mean: -0.1288476004882674, SCOPE var: 0.017535435535031497\n",
            "Total Loss: 5.79338854937893\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.1505, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.472244319406711\n",
            "SCOPE mean: -0.10951618658808183, SCOPE var: 0.017483411600454513\n",
            "Total Loss: 5.622742742549568\n",
            "----------------------------------------\n",
            "Epoch 11\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.1496, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.322443344005031\n",
            "SCOPE mean: -0.0914684499312182, SCOPE var: 0.01746632455878419\n",
            "Total Loss: 5.472072518816932\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.1487, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.188289057801382\n",
            "SCOPE mean: -0.07468251355365958, SCOPE var: 0.017489848579242545\n",
            "Total Loss: 5.336992149628169\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.1476, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.066135553406015\n",
            "SCOPE mean: -0.059300821223911705, SCOPE var: 0.017529274542008217\n",
            "Total Loss: 5.213713984971109\n",
            "----------------------------------------\n",
            "Epoch 14\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.1463, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.9526683019287425\n",
            "SCOPE mean: -0.04420815870721524, SCOPE var: 0.017581638399175325\n",
            "Total Loss: 5.099012507353079\n",
            "----------------------------------------\n",
            "Epoch 15\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.1451, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.84495170559742\n",
            "SCOPE mean: -0.029665874912425432, SCOPE var: 0.017645606384190098\n",
            "Total Loss: 4.990081214472812\n",
            "----------------------------------------\n",
            "Epoch 16\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.1438, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.741025059727192\n",
            "SCOPE mean: -0.016519785566904123, SCOPE var: 0.01771984065126293\n",
            "Total Loss: 4.884784234804913\n",
            "----------------------------------------\n",
            "Epoch 17\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.1424, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.640187163208526\n",
            "SCOPE mean: -0.0047033743066983245, SCOPE var: 0.017801934570880418\n",
            "Total Loss: 4.78258535590373\n",
            "----------------------------------------\n",
            "Epoch 18\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.1410, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.541433623399948\n",
            "SCOPE mean: 0.005831270444303763, SCOPE var: 0.017889913157164\n",
            "Total Loss: 4.682393978273124\n",
            "----------------------------------------\n",
            "Epoch 19\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.1396, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.444142525086331\n",
            "SCOPE mean: 0.01514109863256443, SCOPE var: 0.017981142033309857\n",
            "Total Loss: 4.583697748324068\n",
            "----------------------------------------\n",
            "Epoch 20\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.1381, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.347931123059514\n",
            "SCOPE mean: 0.0232630904870878, SCOPE var: 0.018075180259785124\n",
            "Total Loss: 4.4860371412430595\n",
            "----------------------------------------\n",
            "Epoch 21\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.1366, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.252175882392985\n",
            "SCOPE mean: 0.03033279341897491, SCOPE var: 0.018171682287411197\n",
            "Total Loss: 4.388768645328269\n",
            "----------------------------------------\n",
            "Epoch 22\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.1352, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.15735229439116\n",
            "SCOPE mean: 0.03657085129443074, SCOPE var: 0.01827044950051409\n",
            "Total Loss: 4.29259651906433\n",
            "----------------------------------------\n",
            "Epoch 23\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.1340, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.064442738149727\n",
            "SCOPE mean: 0.04211387395439899, SCOPE var: 0.018354957690404485\n",
            "Total Loss: 4.198487676040477\n",
            "----------------------------------------\n",
            "Epoch 24\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.1327, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.9735222321774355\n",
            "SCOPE mean: 0.047057256328366104, SCOPE var: 0.018433008483716044\n",
            "Total Loss: 4.10626063700206\n",
            "----------------------------------------\n",
            "Epoch 25\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.1313, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.884686412879672\n",
            "SCOPE mean: 0.051431514734782274, SCOPE var: 0.018509858411015\n",
            "Total Loss: 4.015991626973637\n",
            "----------------------------------------\n",
            "Epoch 26\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.1296, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.798470164228512\n",
            "SCOPE mean: 0.05536105424666981, SCOPE var: 0.01858467770302603\n",
            "Total Loss: 3.928073990038671\n",
            "----------------------------------------\n",
            "Epoch 27\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.1276, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.714811275433126\n",
            "SCOPE mean: 0.05895719168266367, SCOPE var: 0.018656656402607986\n",
            "Total Loss: 3.8424564844686313\n",
            "----------------------------------------\n",
            "Epoch 28\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.1257, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.6337409169150474\n",
            "SCOPE mean: 0.0619567670184764, SCOPE var: 0.018736614911794996\n",
            "Total Loss: 3.759403586410871\n",
            "----------------------------------------\n",
            "Epoch 29\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.1236, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.555353909003746\n",
            "SCOPE mean: 0.06462911464624986, SCOPE var: 0.018818025589400426\n",
            "Total Loss: 3.6789517076301563\n",
            "----------------------------------------\n",
            "Epoch 30\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.1215, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.4799915484021104\n",
            "SCOPE mean: 0.06709822214189931, SCOPE var: 0.018899915192456904\n",
            "Total Loss: 3.6015271301705685\n",
            "----------------------------------------\n",
            "Epoch 31\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.1195, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.4074531583613803\n",
            "SCOPE mean: 0.06917458273227646, SCOPE var: 0.018976143479690535\n",
            "Total Loss: 3.5269059319610174\n",
            "----------------------------------------\n",
            "Epoch 32\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.1174, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.337762226979104\n",
            "SCOPE mean: 0.07105686501833577, SCOPE var: 0.01905483361545619\n",
            "Total Loss: 3.455137736577478\n",
            "----------------------------------------\n",
            "Epoch 33\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.1153, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.270640862117507\n",
            "SCOPE mean: 0.07295663236025718, SCOPE var: 0.019133501616401573\n",
            "Total Loss: 3.3859538399662354\n",
            "----------------------------------------\n",
            "Epoch 34\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.1133, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.206041740860843\n",
            "SCOPE mean: 0.07488420580857796, SCOPE var: 0.019214698762207674\n",
            "Total Loss: 3.3193689120012295\n",
            "----------------------------------------\n",
            "Epoch 35\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.1112, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.1438696047835983\n",
            "SCOPE mean: 0.07680604490685196, SCOPE var: 0.019295577524298543\n",
            "Total Loss: 3.2550960700203544\n",
            "----------------------------------------\n",
            "Epoch 36\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.1091, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.0839191390744114\n",
            "SCOPE mean: 0.07892928965178761, SCOPE var: 0.019381414503183567\n",
            "Total Loss: 3.1930154381623534\n",
            "----------------------------------------\n",
            "Epoch 37\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.1070, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.025962879526555\n",
            "SCOPE mean: 0.08125415963876019, SCOPE var: 0.019470958315272475\n",
            "Total Loss: 3.132938028087742\n",
            "----------------------------------------\n",
            "Epoch 38\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.1049, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.9697710101265993\n",
            "SCOPE mean: 0.0838287308750811, SCOPE var: 0.019560208691038333\n",
            "Total Loss: 3.0746640702398484\n",
            "----------------------------------------\n",
            "Epoch 39\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.1028, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.9153300606208896\n",
            "SCOPE mean: 0.08659335522159942, SCOPE var: 0.019647413979349937\n",
            "Total Loss: 3.0181669810051956\n",
            "----------------------------------------\n",
            "Epoch 40\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.1008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.8624559883771883\n",
            "SCOPE mean: 0.08957615654756679, SCOPE var: 0.019735273981748874\n",
            "Total Loss: 2.9632346642049616\n",
            "----------------------------------------\n",
            "Epoch 41\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0988, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.8109639993749242\n",
            "SCOPE mean: 0.09280379754911988, SCOPE var: 0.019823021925661048\n",
            "Total Loss: 2.909715733042909\n",
            "----------------------------------------\n",
            "Epoch 42\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0968, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.7606583191371046\n",
            "SCOPE mean: 0.09580887891211648, SCOPE var: 0.019914348002343013\n",
            "Total Loss: 2.8574131628565977\n",
            "----------------------------------------\n",
            "Epoch 43\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0947, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.711510621614729\n",
            "SCOPE mean: 0.09885272549904334, SCOPE var: 0.020006592947200655\n",
            "Total Loss: 2.806161106429265\n",
            "----------------------------------------\n",
            "Epoch 44\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0925, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.6634274138363896\n",
            "SCOPE mean: 0.10204439638979272, SCOPE var: 0.020096275057745056\n",
            "Total Loss: 2.755917333651782\n",
            "----------------------------------------\n",
            "Epoch 45\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0904, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.6164985554746654\n",
            "SCOPE mean: 0.10535295931946348, SCOPE var: 0.02018570910663156\n",
            "Total Loss: 2.706885921943651\n",
            "----------------------------------------\n",
            "Epoch 46\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0883, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.5707371655278424\n",
            "SCOPE mean: 0.10881663747925986, SCOPE var: 0.020274999590968592\n",
            "Total Loss: 2.6590624578247612\n",
            "----------------------------------------\n",
            "Epoch 47\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0863, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.526029293446904\n",
            "SCOPE mean: 0.1124084839205724, SCOPE var: 0.020365661886040522\n",
            "Total Loss: 2.6123218034033537\n",
            "----------------------------------------\n",
            "Epoch 48\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0840, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.4823918357527592\n",
            "SCOPE mean: 0.11592258780222, SCOPE var: 0.02045577897824422\n",
            "Total Loss: 2.5664198523684005\n",
            "----------------------------------------\n",
            "Epoch 49\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0818, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.439551706387078\n",
            "SCOPE mean: 0.11932945459221517, SCOPE var: 0.020545532512454678\n",
            "Total Loss: 2.521377499302483\n",
            "----------------------------------------\n",
            "Epoch 50\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0798, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.3977112921253396\n",
            "SCOPE mean: 0.12282911363029066, SCOPE var: 0.020634057145434308\n",
            "Total Loss: 2.477497050739478\n",
            "----------------------------------------\n",
            "Epoch 51\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0778, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.356936282711748\n",
            "SCOPE mean: 0.12637745980083065, SCOPE var: 0.020721135007463722\n",
            "Total Loss: 2.4346952870028633\n",
            "----------------------------------------\n",
            "Epoch 52\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0758, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.3172039965266484\n",
            "SCOPE mean: 0.12997326659723052, SCOPE var: 0.020806809843208457\n",
            "Total Loss: 2.3929673650171854\n",
            "----------------------------------------\n",
            "Epoch 53\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0739, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.2784318030781017\n",
            "SCOPE mean: 0.1335847967283797, SCOPE var: 0.020892369774630267\n",
            "Total Loss: 2.352282338004975\n",
            "----------------------------------------\n",
            "Epoch 54\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0720, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.2407632670417073\n",
            "SCOPE mean: 0.13719633340898704, SCOPE var: 0.020976840410882422\n",
            "Total Loss: 2.312771073371822\n",
            "----------------------------------------\n",
            "Epoch 55\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0702, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.2041637154909752\n",
            "SCOPE mean: 0.14079118270752006, SCOPE var: 0.021059632431734435\n",
            "Total Loss: 2.2743927061123537\n",
            "----------------------------------------\n",
            "Epoch 56\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0685, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.1685053140838852\n",
            "SCOPE mean: 0.14434786109814854, SCOPE var: 0.021140454772081062\n",
            "Total Loss: 2.2370076078256167\n",
            "----------------------------------------\n",
            "Epoch 57\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0668, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.1337550364374573\n",
            "SCOPE mean: 0.14786347565458505, SCOPE var: 0.021217288925721882\n",
            "Total Loss: 2.200550718985659\n",
            "----------------------------------------\n",
            "Epoch 58\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0651, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.0997986749222126\n",
            "SCOPE mean: 0.15130403977302312, SCOPE var: 0.02129111712815279\n",
            "Total Loss: 2.1648976895888445\n",
            "----------------------------------------\n",
            "Epoch 59\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0634, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.0667032275871455\n",
            "SCOPE mean: 0.15464470459151194, SCOPE var: 0.02136254828936191\n",
            "Total Loss: 2.130119228436798\n",
            "----------------------------------------\n",
            "Epoch 60\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0618, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.034418759907727\n",
            "SCOPE mean: 0.15787593721747148, SCOPE var: 0.021431452600202013\n",
            "Total Loss: 2.096175278300676\n",
            "----------------------------------------\n",
            "Epoch 61\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0601, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.002910789311253\n",
            "SCOPE mean: 0.16099162361063807, SCOPE var: 0.021497677209369816\n",
            "Total Loss: 2.0630518376593314\n",
            "----------------------------------------\n",
            "Epoch 62\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0585, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.9719421643773676\n",
            "SCOPE mean: 0.16399472613205757, SCOPE var: 0.02156113916607615\n",
            "Total Loss: 2.0304494490188727\n",
            "----------------------------------------\n",
            "Epoch 63\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0569, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.9418807729605267\n",
            "SCOPE mean: 0.16684959776911623, SCOPE var: 0.02162093260132221\n",
            "Total Loss: 1.9987759319836178\n",
            "----------------------------------------\n",
            "Epoch 64\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0553, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.9127007109009744\n",
            "SCOPE mean: 0.16949595778971221, SCOPE var: 0.021675385834035082\n",
            "Total Loss: 1.9680106939361532\n",
            "----------------------------------------\n",
            "Epoch 65\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0538, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.8841168778264143\n",
            "SCOPE mean: 0.17203737777956246, SCOPE var: 0.02172668429966387\n",
            "Total Loss: 1.9378744943166133\n",
            "----------------------------------------\n",
            "Epoch 66\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0522, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.8557810215728712\n",
            "SCOPE mean: 0.1744887764590274, SCOPE var: 0.021774719003742053\n",
            "Total Loss: 1.908015966191094\n",
            "----------------------------------------\n",
            "Epoch 67\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0508, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.8280130276028963\n",
            "SCOPE mean: 0.17685736927879694, SCOPE var: 0.02181939481836961\n",
            "Total Loss: 1.8787795731458454\n",
            "----------------------------------------\n",
            "Epoch 68\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0493, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.8005796659761244\n",
            "SCOPE mean: 0.1791681949437309, SCOPE var: 0.02186059967959147\n",
            "Total Loss: 1.8499150718989201\n",
            "----------------------------------------\n",
            "Epoch 69\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0479, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7735792179247492\n",
            "SCOPE mean: 0.1814549767613727, SCOPE var: 0.02189843430215768\n",
            "Total Loss: 1.8214568078193458\n",
            "----------------------------------------\n",
            "Epoch 70\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0465, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7471153081430089\n",
            "SCOPE mean: 0.1837142955999697, SCOPE var: 0.021932937938288204\n",
            "Total Loss: 1.7936174642762357\n",
            "----------------------------------------\n",
            "Epoch 71\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0451, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7212706287697017\n",
            "SCOPE mean: 0.1859539757670975, SCOPE var: 0.021964100901658516\n",
            "Total Loss: 1.766417652331283\n",
            "----------------------------------------\n",
            "Epoch 72\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0438, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6960562129908112\n",
            "SCOPE mean: 0.18842660522998095, SCOPE var: 0.021986963036066842\n",
            "Total Loss: 1.739831649875957\n",
            "----------------------------------------\n",
            "Epoch 73\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0425, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6715750753888026\n",
            "SCOPE mean: 0.1912191311034888, SCOPE var: 0.0220002401792961\n",
            "Total Loss: 1.714032434545907\n",
            "----------------------------------------\n",
            "Epoch 74\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0412, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6476745204436487\n",
            "SCOPE mean: 0.19403669356699454, SCOPE var: 0.022010560090057592\n",
            "Total Loss: 1.6888436341390847\n",
            "----------------------------------------\n",
            "Epoch 75\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0399, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6244537210917103\n",
            "SCOPE mean: 0.19691042627847255, SCOPE var: 0.02201790871244514\n",
            "Total Loss: 1.6643118205593077\n",
            "----------------------------------------\n",
            "Epoch 76\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0386, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6018184192467508\n",
            "SCOPE mean: 0.19980895675003085, SCOPE var: 0.02202192791023722\n",
            "Total Loss: 1.6403978707619373\n",
            "----------------------------------------\n",
            "Epoch 77\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0374, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5796771531219533\n",
            "SCOPE mean: 0.2027029110546548, SCOPE var: 0.02202237084566447\n",
            "Total Loss: 1.617074375975868\n",
            "----------------------------------------\n",
            "Epoch 78\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0363, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5584427221558237\n",
            "SCOPE mean: 0.20563958093019036, SCOPE var: 0.021999741367839117\n",
            "Total Loss: 1.5947042804866398\n",
            "----------------------------------------\n",
            "Epoch 79\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0352, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5379221658500688\n",
            "SCOPE mean: 0.20847327429504886, SCOPE var: 0.02194986240382596\n",
            "Total Loss: 1.5731081057601513\n",
            "----------------------------------------\n",
            "Epoch 80\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0341, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5179884232793683\n",
            "SCOPE mean: 0.21136567648487747, SCOPE var: 0.0218970972473085\n",
            "Total Loss: 1.552135728848457\n",
            "----------------------------------------\n",
            "Epoch 81\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0331, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.498890283407863\n",
            "SCOPE mean: 0.2144967934524865, SCOPE var: 0.021840173333525097\n",
            "Total Loss: 1.5320055735702403\n",
            "----------------------------------------\n",
            "Epoch 82\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0323, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4799767402685768\n",
            "SCOPE mean: 0.21652443361176751, SCOPE var: 0.02178101309299755\n",
            "Total Loss: 1.5122416616728003\n",
            "----------------------------------------\n",
            "Epoch 83\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0315, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4617120169840954\n",
            "SCOPE mean: 0.21642726641712826, SCOPE var: 0.021726132829203267\n",
            "Total Loss: 1.4931886707021897\n",
            "----------------------------------------\n",
            "Epoch 84\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0308, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4440165426791036\n",
            "SCOPE mean: 0.21649871997141076, SCOPE var: 0.021667065018254127\n",
            "Total Loss: 1.474809027907969\n",
            "----------------------------------------\n",
            "Epoch 85\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0302, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4269222433499589\n",
            "SCOPE mean: 0.2165878394892745, SCOPE var: 0.021600875426054135\n",
            "Total Loss: 1.457105021517123\n",
            "----------------------------------------\n",
            "Epoch 86\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0296, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4103216292985126\n",
            "SCOPE mean: 0.21675912869075137, SCOPE var: 0.021532312462270397\n",
            "Total Loss: 1.4399526730730616\n",
            "----------------------------------------\n",
            "Epoch 87\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0291, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.394159595643514\n",
            "SCOPE mean: 0.2170555629482645, SCOPE var: 0.021462073260180063\n",
            "Total Loss: 1.423303444430231\n",
            "----------------------------------------\n",
            "Epoch 88\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0288, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.3785721374248903\n",
            "SCOPE mean: 0.21755503992536152, SCOPE var: 0.021390033230973972\n",
            "Total Loss: 1.407360621944994\n",
            "----------------------------------------\n",
            "Epoch 89\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0285, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.3633082825406844\n",
            "SCOPE mean: 0.21827470150649825, SCOPE var: 0.021317931681962127\n",
            "Total Loss: 1.391826473881242\n",
            "----------------------------------------\n",
            "Epoch 90\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0283, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.3483459378120013\n",
            "SCOPE mean: 0.21892577928450516, SCOPE var: 0.021245858944182523\n",
            "Total Loss: 1.37661240514173\n",
            "----------------------------------------\n",
            "Epoch 91\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0280, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.33369857929049\n",
            "SCOPE mean: 0.21953017403466374, SCOPE var: 0.02117381114336842\n",
            "Total Loss: 1.3617481220846737\n",
            "----------------------------------------\n",
            "Epoch 92\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0279, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.3193432692795688\n",
            "SCOPE mean: 0.22033869820469873, SCOPE var: 0.021102227682172327\n",
            "Total Loss: 1.3472057127920118\n",
            "----------------------------------------\n",
            "Epoch 93\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0277, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.3052520812696793\n",
            "SCOPE mean: 0.22132824447844424, SCOPE var: 0.02103139212205479\n",
            "Total Loss: 1.33295420132535\n",
            "----------------------------------------\n",
            "Epoch 94\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0276, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.2914035789767266\n",
            "SCOPE mean: 0.22246678111218288, SCOPE var: 0.020961459773748917\n",
            "Total Loss: 1.318968278125297\n",
            "----------------------------------------\n",
            "Epoch 95\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0274, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.2778340029295736\n",
            "SCOPE mean: 0.22371716345622125, SCOPE var: 0.020892499436002885\n",
            "Total Loss: 1.3052767986691516\n",
            "----------------------------------------\n",
            "Epoch 96\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0273, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.264522389183064\n",
            "SCOPE mean: 0.2250392014829676, SCOPE var: 0.02082451229189751\n",
            "Total Loss: 1.2918554491556105\n",
            "----------------------------------------\n",
            "Epoch 97\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0272, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.251462143783735\n",
            "SCOPE mean: 0.22639702690049207, SCOPE var: 0.020757825945514004\n",
            "Total Loss: 1.278696003976464\n",
            "----------------------------------------\n",
            "Epoch 98\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0272, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.2386212403206154\n",
            "SCOPE mean: 0.22779429533013845, SCOPE var: 0.020692074031598312\n",
            "Total Loss: 1.2657732967622366\n",
            "----------------------------------------\n",
            "Epoch 99\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0271, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.2260073816485355\n",
            "SCOPE mean: 0.2291765322173102, SCOPE var: 0.020628099810143727\n",
            "Total Loss: 1.2531187855494363\n",
            "----------------------------------------\n",
            "Epoch 100\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0271, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.213628179337872\n",
            "SCOPE mean: 0.23050757135004063, SCOPE var: 0.020566448105020466\n",
            "Total Loss: 1.2407025217938745\n",
            "----------------------------------------\n",
            "Epoch 101\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0270, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.2015240979401027\n",
            "SCOPE mean: 0.2318114261118689, SCOPE var: 0.020506149686777605\n",
            "Total Loss: 1.2285630387532032\n",
            "----------------------------------------\n",
            "Epoch 102\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0270, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.1896315414501766\n",
            "SCOPE mean: 0.23307599544950275, SCOPE var: 0.02044732635256049\n",
            "Total Loss: 1.2166374899217856\n",
            "----------------------------------------\n",
            "Epoch 103\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0270, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.1779774224930477\n",
            "SCOPE mean: 0.23428589749283002, SCOPE var: 0.020389990774675164\n",
            "Total Loss: 1.2049690868367826\n",
            "----------------------------------------\n",
            "Epoch 104\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0270, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.166573886375095\n",
            "SCOPE mean: 0.23545949059564772, SCOPE var: 0.020334220619538837\n",
            "Total Loss: 1.1935816283283895\n",
            "----------------------------------------\n",
            "Epoch 105\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0270, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.1554049961994293\n",
            "SCOPE mean: 0.23661220111104425, SCOPE var: 0.020279406646999468\n",
            "Total Loss: 1.1824241364572263\n",
            "----------------------------------------\n",
            "Epoch 106\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0271, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.1444623976202644\n",
            "SCOPE mean: 0.2377540479535723, SCOPE var: 0.020225547306520205\n",
            "Total Loss: 1.1715396637660371\n",
            "----------------------------------------\n",
            "Epoch 107\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0271, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.1337655497180517\n",
            "SCOPE mean: 0.23887440612180666, SCOPE var: 0.020172474001489294\n",
            "Total Loss: 1.1609145876234792\n",
            "----------------------------------------\n",
            "Epoch 108\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0272, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.1232521708971126\n",
            "SCOPE mean: 0.23998209608119156, SCOPE var: 0.020120241502906356\n",
            "Total Loss: 1.1504562764285702\n",
            "----------------------------------------\n",
            "Epoch 109\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0272, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.112929574584048\n",
            "SCOPE mean: 0.24107495517934213, SCOPE var: 0.020067555986762964\n",
            "Total Loss: 1.1401738536636032\n",
            "----------------------------------------\n",
            "Epoch 110\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0273, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.102797916233006\n",
            "SCOPE mean: 0.24216501851511066, SCOPE var: 0.020014360780155956\n",
            "Total Loss: 1.1300684509919925\n",
            "----------------------------------------\n",
            "Epoch 111\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0273, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0928508242164496\n",
            "SCOPE mean: 0.2432584413279878, SCOPE var: 0.01996213577938614\n",
            "Total Loss: 1.1201342646151295\n",
            "----------------------------------------\n",
            "Epoch 112\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0273, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0830727250132273\n",
            "SCOPE mean: 0.24433253440543007, SCOPE var: 0.01991144630504928\n",
            "Total Loss: 1.1103534658562246\n",
            "----------------------------------------\n",
            "Epoch 113\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0273, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.073434211042365\n",
            "SCOPE mean: 0.24535145060281624, SCOPE var: 0.019863700183887972\n",
            "Total Loss: 1.100737069981338\n",
            "----------------------------------------\n",
            "Epoch 114\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0273, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0639481934948996\n",
            "SCOPE mean: 0.24637158305341114, SCOPE var: 0.01981748334097232\n",
            "Total Loss: 1.091289031813088\n",
            "----------------------------------------\n",
            "Epoch 115\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0274, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0546170677625957\n",
            "SCOPE mean: 0.2473955297900496, SCOPE var: 0.01977275765641576\n",
            "Total Loss: 1.0820001173702505\n",
            "----------------------------------------\n",
            "Epoch 116\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0274, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.045417594005287\n",
            "SCOPE mean: 0.24843049572254977, SCOPE var: 0.01972948374300949\n",
            "Total Loss: 1.0728471607395154\n",
            "----------------------------------------\n",
            "Epoch 117\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0275, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0363330562493944\n",
            "SCOPE mean: 0.24948574990034023, SCOPE var: 0.019687735237461375\n",
            "Total Loss: 1.0638132316404878\n",
            "----------------------------------------\n",
            "Epoch 118\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0275, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0273555816006923\n",
            "SCOPE mean: 0.25052859308732295, SCOPE var: 0.019646706109361613\n",
            "Total Loss: 1.0548908937567192\n",
            "----------------------------------------\n",
            "Epoch 119\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0276, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0184842743636515\n",
            "SCOPE mean: 0.2514856435515834, SCOPE var: 0.019608150626288307\n",
            "Total Loss: 1.0460832292017699\n",
            "----------------------------------------\n",
            "Epoch 120\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0277, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.009725946564059\n",
            "SCOPE mean: 0.252447548158419, SCOPE var: 0.01957093191369811\n",
            "Total Loss: 1.0373785603639898\n",
            "----------------------------------------\n",
            "Epoch 121\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0277, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0011371120241448\n",
            "SCOPE mean: 0.25342480578251125, SCOPE var: 0.019535181460264988\n",
            "Total Loss: 1.0288584870345887\n",
            "----------------------------------------\n",
            "Epoch 122\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0278, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9926943165607918\n",
            "SCOPE mean: 0.25441431382421154, SCOPE var: 0.019500615807077477\n",
            "Total Loss: 1.0204746399196667\n",
            "----------------------------------------\n",
            "Epoch 123\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0278, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9843927983250361\n",
            "SCOPE mean: 0.2554172506556995, SCOPE var: 0.019466990815216228\n",
            "Total Loss: 1.012213941146136\n",
            "----------------------------------------\n",
            "Epoch 124\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0279, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9762276910193772\n",
            "SCOPE mean: 0.2564480303320008, SCOPE var: 0.019434398657152834\n",
            "Total Loss: 1.004080250740577\n",
            "----------------------------------------\n",
            "Epoch 125\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0279, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9681814054545694\n",
            "SCOPE mean: 0.25750287473034805, SCOPE var: 0.01940265373888092\n",
            "Total Loss: 0.9960440702099468\n",
            "----------------------------------------\n",
            "Epoch 126\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0279, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9602400817701106\n",
            "SCOPE mean: 0.25858408881046446, SCOPE var: 0.019371713025176516\n",
            "Total Loss: 0.9881312318123806\n",
            "----------------------------------------\n",
            "Epoch 127\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0279, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9524084530219141\n",
            "SCOPE mean: 0.25967637620287204, SCOPE var: 0.019342127198233087\n",
            "Total Loss: 0.9803235886038238\n",
            "----------------------------------------\n",
            "Epoch 128\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0279, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9446928997506127\n",
            "SCOPE mean: 0.26078423997912314, SCOPE var: 0.0193137542585197\n",
            "Total Loss: 0.9726226316248294\n",
            "----------------------------------------\n",
            "Epoch 129\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0279, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9370699699320656\n",
            "SCOPE mean: 0.2618998367809374, SCOPE var: 0.019286500939622687\n",
            "Total Loss: 0.9649900314010813\n",
            "----------------------------------------\n",
            "Epoch 130\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0279, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9295386856767304\n",
            "SCOPE mean: 0.26307277959177483, SCOPE var: 0.0192605759211982\n",
            "Total Loss: 0.9574301238123792\n",
            "----------------------------------------\n",
            "Epoch 131\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0279, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9221109311523432\n",
            "SCOPE mean: 0.2642932473962947, SCOPE var: 0.019235567351692625\n",
            "Total Loss: 0.9499665964033129\n",
            "----------------------------------------\n",
            "Epoch 132\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0278, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9147894986485144\n",
            "SCOPE mean: 0.26557391415611126, SCOPE var: 0.019211667107104955\n",
            "Total Loss: 0.9426152206463124\n",
            "----------------------------------------\n",
            "Epoch 133\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0278, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9075620539661107\n",
            "SCOPE mean: 0.2669016587965168, SCOPE var: 0.019188579710640516\n",
            "Total Loss: 0.9353529634644905\n",
            "----------------------------------------\n",
            "Epoch 134\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0278, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.900449109735058\n",
            "SCOPE mean: 0.26826434913346986, SCOPE var: 0.01916636883142142\n",
            "Total Loss: 0.92820104325617\n",
            "----------------------------------------\n",
            "Epoch 135\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0277, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8934402811861702\n",
            "SCOPE mean: 0.2696637478630445, SCOPE var: 0.019144867743745613\n",
            "Total Loss: 0.9211661396492284\n",
            "----------------------------------------\n",
            "Epoch 136\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0277, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8865024799859256\n",
            "SCOPE mean: 0.2710815300986074, SCOPE var: 0.019123711490465753\n",
            "Total Loss: 0.9142333618098729\n",
            "----------------------------------------\n",
            "Epoch 137\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0278, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8796216596782421\n",
            "SCOPE mean: 0.2725055962689881, SCOPE var: 0.019102448794075366\n",
            "Total Loss: 0.9073766709769072\n",
            "----------------------------------------\n",
            "Epoch 138\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0278, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8727947009746372\n",
            "SCOPE mean: 0.2739001280179379, SCOPE var: 0.0190809208953386\n",
            "Total Loss: 0.9005858395264869\n",
            "----------------------------------------\n",
            "Epoch 139\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0278, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8660432685525702\n",
            "SCOPE mean: 0.27525549809855737, SCOPE var: 0.01905897567562234\n",
            "Total Loss: 0.8938794134794843\n",
            "----------------------------------------\n",
            "Epoch 140\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0279, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8593662919170478\n",
            "SCOPE mean: 0.2765563604658797, SCOPE var: 0.019036782692241825\n",
            "Total Loss: 0.887217453228796\n",
            "----------------------------------------\n",
            "Epoch 141\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0279, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8527688143086267\n",
            "SCOPE mean: 0.27779863211263495, SCOPE var: 0.019011252233460275\n",
            "Total Loss: 0.8806213549381589\n",
            "----------------------------------------\n",
            "Epoch 142\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0278, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8462644252937551\n",
            "SCOPE mean: 0.27898823681063345, SCOPE var: 0.018982864147742553\n",
            "Total Loss: 0.8741118574559107\n",
            "----------------------------------------\n",
            "Epoch 143\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0279, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.839833612474559\n",
            "SCOPE mean: 0.2801157784259435, SCOPE var: 0.018952670577858814\n",
            "Total Loss: 0.8677270766361503\n",
            "----------------------------------------\n",
            "Epoch 144\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0280, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8334899675892903\n",
            "SCOPE mean: 0.28120057017239114, SCOPE var: 0.018923756106575554\n",
            "Total Loss: 0.861451097750242\n",
            "----------------------------------------\n",
            "Epoch 145\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0280, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8272649420689283\n",
            "SCOPE mean: 0.2822433105673413, SCOPE var: 0.018896301585425043\n",
            "Total Loss: 0.8552746280672379\n",
            "----------------------------------------\n",
            "Epoch 146\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0280, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8211195367649168\n",
            "SCOPE mean: 0.28325063006378925, SCOPE var: 0.01887022243824104\n",
            "Total Loss: 0.8491644216702425\n",
            "----------------------------------------\n",
            "Epoch 147\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0281, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8150443011355771\n",
            "SCOPE mean: 0.28423679566616983, SCOPE var: 0.018849953980057958\n",
            "Total Loss: 0.8431118909025928\n",
            "----------------------------------------\n",
            "Epoch 148\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0281, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8090399540074587\n",
            "SCOPE mean: 0.28519450213145353, SCOPE var: 0.018830932500269078\n",
            "Total Loss: 0.837122732194088\n",
            "----------------------------------------\n",
            "Epoch 149\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0281, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.803122738918352\n",
            "SCOPE mean: 0.28613396290809084, SCOPE var: 0.01881288429757048\n",
            "Total Loss: 0.8312189996698689\n",
            "----------------------------------------\n",
            "Epoch 150\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0281, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7972850815818628\n",
            "SCOPE mean: 0.2870673054865118, SCOPE var: 0.018795705229791185\n",
            "Total Loss: 0.8253901885654609\n",
            "----------------------------------------\n",
            "Epoch 151\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0281, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7915067114383696\n",
            "SCOPE mean: 0.2880152883986017, SCOPE var: 0.018779150441886498\n",
            "Total Loss: 0.8196224802847579\n",
            "----------------------------------------\n",
            "Epoch 152\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0281, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7857979010354911\n",
            "SCOPE mean: 0.28897818196345293, SCOPE var: 0.018763376871338437\n",
            "Total Loss: 0.8139346723559269\n",
            "----------------------------------------\n",
            "Epoch 153\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0282, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7801240975431692\n",
            "SCOPE mean: 0.2899595662580639, SCOPE var: 0.018747887100232237\n",
            "Total Loss: 0.8082997381397592\n",
            "----------------------------------------\n",
            "Epoch 154\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0282, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7744906310338399\n",
            "SCOPE mean: 0.29096324476994895, SCOPE var: 0.018732657731872823\n",
            "Total Loss: 0.8027293419395628\n",
            "----------------------------------------\n",
            "Epoch 155\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0283, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7688958026855472\n",
            "SCOPE mean: 0.29199197765619445, SCOPE var: 0.01871759870735823\n",
            "Total Loss: 0.7972080969728449\n",
            "----------------------------------------\n",
            "Epoch 156\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0284, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7633519892225649\n",
            "SCOPE mean: 0.2930669806757795, SCOPE var: 0.01870246278421592\n",
            "Total Loss: 0.791742165960904\n",
            "----------------------------------------\n",
            "Epoch 157\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0285, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7579146186760688\n",
            "SCOPE mean: 0.2941781981729353, SCOPE var: 0.018687918162825088\n",
            "Total Loss: 0.7863856961708156\n",
            "----------------------------------------\n",
            "Epoch 158\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0285, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7525495866689899\n",
            "SCOPE mean: 0.29505237699028136, SCOPE var: 0.018673863115815422\n",
            "Total Loss: 0.7810990962734748\n",
            "----------------------------------------\n",
            "Epoch 159\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0286, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7472560159191821\n",
            "SCOPE mean: 0.2956147709803734, SCOPE var: 0.01866013203300559\n",
            "Total Loss: 0.7758711493772684\n",
            "----------------------------------------\n",
            "Epoch 160\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0287, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7420350240985527\n",
            "SCOPE mean: 0.2961997894883591, SCOPE var: 0.018646947601903798\n",
            "Total Loss: 0.770705791694622\n",
            "----------------------------------------\n",
            "Epoch 161\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0287, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7368755603213585\n",
            "SCOPE mean: 0.29684129506870893, SCOPE var: 0.01863365815047077\n",
            "Total Loss: 0.7655958984453664\n",
            "----------------------------------------\n",
            "Epoch 162\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0288, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7317864608595812\n",
            "SCOPE mean: 0.2975124627275995, SCOPE var: 0.018620300147885592\n",
            "Total Loss: 0.7605536848565071\n",
            "----------------------------------------\n",
            "Epoch 163\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0288, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7267715492953403\n",
            "SCOPE mean: 0.2981835964201238, SCOPE var: 0.018607304429499365\n",
            "Total Loss: 0.7555789953403916\n",
            "----------------------------------------\n",
            "Epoch 164\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0288, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7218392269499176\n",
            "SCOPE mean: 0.29885404531243115, SCOPE var: 0.018594713080415125\n",
            "Total Loss: 0.7506808366319377\n",
            "----------------------------------------\n",
            "Epoch 165\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0289, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7169503677426974\n",
            "SCOPE mean: 0.2994913493320966, SCOPE var: 0.01858186517668034\n",
            "Total Loss: 0.745844079720055\n",
            "----------------------------------------\n",
            "Epoch 166\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0290, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7121015733441161\n",
            "SCOPE mean: 0.30009171269348345, SCOPE var: 0.018568702343001387\n",
            "Total Loss: 0.7410593416910001\n",
            "----------------------------------------\n",
            "Epoch 167\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0290, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7072995000860336\n",
            "SCOPE mean: 0.3006491414395484, SCOPE var: 0.018555061786180268\n",
            "Total Loss: 0.736325559493874\n",
            "----------------------------------------\n",
            "Epoch 168\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0291, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7025481055553262\n",
            "SCOPE mean: 0.30116645176761586, SCOPE var: 0.018541205961031506\n",
            "Total Loss: 0.7316537345358689\n",
            "----------------------------------------\n",
            "Epoch 169\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0292, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.697866691386336\n",
            "SCOPE mean: 0.3016552177579035, SCOPE var: 0.018527669885530906\n",
            "Total Loss: 0.7270429833379073\n",
            "----------------------------------------\n",
            "Epoch 170\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0292, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6932584856924933\n",
            "SCOPE mean: 0.3021081767128986, SCOPE var: 0.018514276493353927\n",
            "Total Loss: 0.7224956769502061\n",
            "----------------------------------------\n",
            "Epoch 171\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0293, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6887217670411547\n",
            "SCOPE mean: 0.3025831396207196, SCOPE var: 0.018501194186775507\n",
            "Total Loss: 0.7180137061674345\n",
            "----------------------------------------\n",
            "Epoch 172\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0293, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.684238260168354\n",
            "SCOPE mean: 0.30307332544791654, SCOPE var: 0.018488267403054506\n",
            "Total Loss: 0.713578802520751\n",
            "----------------------------------------\n",
            "Epoch 173\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0294, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6798168170478841\n",
            "SCOPE mean: 0.3035703541623454, SCOPE var: 0.01847580654875527\n",
            "Total Loss: 0.7092055313713085\n",
            "----------------------------------------\n",
            "Epoch 174\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0295, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6754241380955445\n",
            "SCOPE mean: 0.3040567993892811, SCOPE var: 0.018463272474644736\n",
            "Total Loss: 0.7048776357500233\n",
            "----------------------------------------\n",
            "Epoch 175\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0295, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6710610238941678\n",
            "SCOPE mean: 0.30454502414563084, SCOPE var: 0.01845060895328856\n",
            "Total Loss: 0.7005913500080071\n",
            "----------------------------------------\n",
            "Epoch 176\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0296, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6667250876287762\n",
            "SCOPE mean: 0.30502427761098333, SCOPE var: 0.018437857517537605\n",
            "Total Loss: 0.6963475677344296\n",
            "----------------------------------------\n",
            "Epoch 177\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0297, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6624487440992723\n",
            "SCOPE mean: 0.3055045225064376, SCOPE var: 0.01842554715613673\n",
            "Total Loss: 0.6921519487349538\n",
            "----------------------------------------\n",
            "Epoch 178\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0298, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6582337248165533\n",
            "SCOPE mean: 0.30598410715436053, SCOPE var: 0.01841357981279955\n",
            "Total Loss: 0.6880062429919007\n",
            "----------------------------------------\n",
            "Epoch 179\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0298, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6541020047136077\n",
            "SCOPE mean: 0.3064672278653455, SCOPE var: 0.018402085255436355\n",
            "Total Loss: 0.683928432875813\n",
            "----------------------------------------\n",
            "Epoch 180\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0299, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6500163463554396\n",
            "SCOPE mean: 0.3068978439638842, SCOPE var: 0.01839098136672199\n",
            "Total Loss: 0.6799096048236422\n",
            "----------------------------------------\n",
            "Epoch 181\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0300, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6459676706248632\n",
            "SCOPE mean: 0.30734622673862716, SCOPE var: 0.01837992264341441\n",
            "Total Loss: 0.6759482565478424\n",
            "----------------------------------------\n",
            "Epoch 182\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0301, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6419806429447961\n",
            "SCOPE mean: 0.3078196220348747, SCOPE var: 0.0183693717696001\n",
            "Total Loss: 0.6720310925379325\n",
            "----------------------------------------\n",
            "Epoch 183\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0301, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6380441406648264\n",
            "SCOPE mean: 0.308307927953039, SCOPE var: 0.01835931254785937\n",
            "Total Loss: 0.668146969132716\n",
            "----------------------------------------\n",
            "Epoch 184\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0302, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6341288280530798\n",
            "SCOPE mean: 0.30879295651437044, SCOPE var: 0.018348989640088142\n",
            "Total Loss: 0.664304526903834\n",
            "----------------------------------------\n",
            "Epoch 185\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0303, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6302527543961944\n",
            "SCOPE mean: 0.3092767422529087, SCOPE var: 0.0183385769000469\n",
            "Total Loss: 0.6605125046256787\n",
            "----------------------------------------\n",
            "Epoch 186\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0303, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6264299359714802\n",
            "SCOPE mean: 0.30977930203199455, SCOPE var: 0.01832867508173402\n",
            "Total Loss: 0.6567546590393848\n",
            "----------------------------------------\n",
            "Epoch 187\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0304, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6226652631949434\n",
            "SCOPE mean: 0.31027593895448324, SCOPE var: 0.018319438506935105\n",
            "Total Loss: 0.6530387457060132\n",
            "----------------------------------------\n",
            "Epoch 188\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0304, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6189306659461522\n",
            "SCOPE mean: 0.3107486321392519, SCOPE var: 0.018310077755948898\n",
            "Total Loss: 0.6493613291914098\n",
            "----------------------------------------\n",
            "Epoch 189\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0305, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6152311941525248\n",
            "SCOPE mean: 0.3111994690929333, SCOPE var: 0.018300613421823302\n",
            "Total Loss: 0.6457390211045504\n",
            "----------------------------------------\n",
            "Epoch 190\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0306, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6115657666907953\n",
            "SCOPE mean: 0.31162403806166356, SCOPE var: 0.018290921905170277\n",
            "Total Loss: 0.6421526538365295\n",
            "----------------------------------------\n",
            "Epoch 191\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0307, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6079471270747514\n",
            "SCOPE mean: 0.3120232062335013, SCOPE var: 0.01828127960007224\n",
            "Total Loss: 0.63861244465657\n",
            "----------------------------------------\n",
            "Epoch 192\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0307, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6044007221951382\n",
            "SCOPE mean: 0.31240867295084174, SCOPE var: 0.018273072306889154\n",
            "Total Loss: 0.6351404066632031\n",
            "----------------------------------------\n",
            "Epoch 193\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0308, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6008966466754697\n",
            "SCOPE mean: 0.3127935514444746, SCOPE var: 0.01826568457448844\n",
            "Total Loss: 0.6316998435810127\n",
            "----------------------------------------\n",
            "Epoch 194\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0309, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5974156419081039\n",
            "SCOPE mean: 0.31315761467176934, SCOPE var: 0.01825839228506821\n",
            "Total Loss: 0.6282888108215741\n",
            "----------------------------------------\n",
            "Epoch 195\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0309, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5939609479951926\n",
            "SCOPE mean: 0.31349865990361286, SCOPE var: 0.01825116652663998\n",
            "Total Loss: 0.6249079556743203\n",
            "----------------------------------------\n",
            "Epoch 196\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0310, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5905322498760001\n",
            "SCOPE mean: 0.31381949926244646, SCOPE var: 0.018244006598616545\n",
            "Total Loss: 0.621570545129359\n",
            "----------------------------------------\n",
            "Epoch 197\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0311, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.587135965288827\n",
            "SCOPE mean: 0.3141222463132651, SCOPE var: 0.018236773818330373\n",
            "Total Loss: 0.6182618631103675\n",
            "----------------------------------------\n",
            "Epoch 198\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0312, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.583783619553707\n",
            "SCOPE mean: 0.3144263323368784, SCOPE var: 0.01823024857092302\n",
            "Total Loss: 0.6149692029124747\n",
            "----------------------------------------\n",
            "Epoch 199\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0313, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.580418724048138\n",
            "SCOPE mean: 0.31472738546344764, SCOPE var: 0.018223564824016155\n",
            "Total Loss: 0.6116822895116142\n",
            "----------------------------------------\n",
            "Epoch 200\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0313, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5771012722311245\n",
            "SCOPE mean: 0.31506888468415584, SCOPE var: 0.01822106445609545\n",
            "Total Loss: 0.6084172511895867\n",
            "----------------------------------------\n",
            "Epoch 201\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0314, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5738071010040743\n",
            "SCOPE mean: 0.3154142523368096, SCOPE var: 0.01821967226920605\n",
            "Total Loss: 0.6051786057188391\n",
            "----------------------------------------\n",
            "Epoch 202\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0314, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5705382043735809\n",
            "SCOPE mean: 0.3157576753157817, SCOPE var: 0.018218426313834645\n",
            "Total Loss: 0.6019665510104363\n",
            "----------------------------------------\n",
            "Epoch 203\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0315, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5672908049334406\n",
            "SCOPE mean: 0.31609634640948725, SCOPE var: 0.018217375755162954\n",
            "Total Loss: 0.5987975941253091\n",
            "----------------------------------------\n",
            "Epoch 204\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0316, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.564072766067714\n",
            "SCOPE mean: 0.31643283337824146, SCOPE var: 0.01821665458456344\n",
            "Total Loss: 0.5956596270237815\n",
            "----------------------------------------\n",
            "Epoch 205\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0317, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5608784284081061\n",
            "SCOPE mean: 0.3167285980337892, SCOPE var: 0.01821586731175298\n",
            "Total Loss: 0.5925615038016843\n",
            "----------------------------------------\n",
            "Epoch 206\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0318, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5577351512759706\n",
            "SCOPE mean: 0.3169833659309464, SCOPE var: 0.018215004830544328\n",
            "Total Loss: 0.5895071634145403\n",
            "----------------------------------------\n",
            "Epoch 207\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0318, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.554659749478465\n",
            "SCOPE mean: 0.3172178217967783, SCOPE var: 0.018214843184286116\n",
            "Total Loss: 0.5864785062214196\n",
            "----------------------------------------\n",
            "Epoch 208\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0318, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5516470889945885\n",
            "SCOPE mean: 0.3174342941813517, SCOPE var: 0.018215494938985766\n",
            "Total Loss: 0.5834766870778134\n",
            "----------------------------------------\n",
            "Epoch 209\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0319, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.54866274279758\n",
            "SCOPE mean: 0.3176168431679384, SCOPE var: 0.018215614147043792\n",
            "Total Loss: 0.5805210221453835\n",
            "----------------------------------------\n",
            "Epoch 210\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0319, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5457107398493907\n",
            "SCOPE mean: 0.3177526492458859, SCOPE var: 0.018214761983319745\n",
            "Total Loss: 0.5776100563097136\n",
            "----------------------------------------\n",
            "Epoch 211\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0319, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.542799393510914\n",
            "SCOPE mean: 0.3178953178451387, SCOPE var: 0.018213900409773595\n",
            "Total Loss: 0.5747408349585466\n",
            "----------------------------------------\n",
            "Epoch 212\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0320, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5399230146427283\n",
            "SCOPE mean: 0.3180523397922035, SCOPE var: 0.01821400242149809\n",
            "Total Loss: 0.5718987815822267\n",
            "----------------------------------------\n",
            "Epoch 213\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0320, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5370798572951988\n",
            "SCOPE mean: 0.31822132194128355, SCOPE var: 0.018215043619386955\n",
            "Total Loss: 0.5690821136554884\n",
            "----------------------------------------\n",
            "Epoch 214\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0320, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5342718077370087\n",
            "SCOPE mean: 0.31840688411708507, SCOPE var: 0.01821598968626502\n",
            "Total Loss: 0.5662966019839036\n",
            "----------------------------------------\n",
            "Epoch 215\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0320, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.531499203710513\n",
            "SCOPE mean: 0.3186094672913219, SCOPE var: 0.018216877998387317\n",
            "Total Loss: 0.5635411381261745\n",
            "----------------------------------------\n",
            "Epoch 216\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0321, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5287592759950219\n",
            "SCOPE mean: 0.3188314872065639, SCOPE var: 0.018217835185874765\n",
            "Total Loss: 0.5608171699351078\n",
            "----------------------------------------\n",
            "Epoch 217\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0321, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5260501794720615\n",
            "SCOPE mean: 0.31906511516775854, SCOPE var: 0.0182186735529125\n",
            "Total Loss: 0.5581289393500393\n",
            "----------------------------------------\n",
            "Epoch 218\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0321, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5233724668401771\n",
            "SCOPE mean: 0.3193116701428803, SCOPE var: 0.01821943600582296\n",
            "Total Loss: 0.5554542872842826\n",
            "----------------------------------------\n",
            "Epoch 219\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0321, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5207194777748009\n",
            "SCOPE mean: 0.31956765716936847, SCOPE var: 0.018220114232934657\n",
            "Total Loss: 0.5528092092339508\n",
            "----------------------------------------\n",
            "Epoch 220\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0321, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5180969866096116\n",
            "SCOPE mean: 0.3198410520224758, SCOPE var: 0.018220966349631794\n",
            "Total Loss: 0.5501921693800709\n",
            "----------------------------------------\n",
            "Epoch 221\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0321, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5155020856032267\n",
            "SCOPE mean: 0.32013037498504265, SCOPE var: 0.01822184808358167\n",
            "Total Loss: 0.5476036119817009\n",
            "----------------------------------------\n",
            "Epoch 222\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0321, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5129368300575436\n",
            "SCOPE mean: 0.3204587583665424, SCOPE var: 0.01822224799511041\n",
            "Total Loss: 0.5450398420773428\n",
            "----------------------------------------\n",
            "Epoch 223\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0321, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.510397170540116\n",
            "SCOPE mean: 0.320813351075175, SCOPE var: 0.01822244805086714\n",
            "Total Loss: 0.5424957497849643\n",
            "----------------------------------------\n",
            "Epoch 224\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0321, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5078886611671437\n",
            "SCOPE mean: 0.32117517024085407, SCOPE var: 0.01822261716534523\n",
            "Total Loss: 0.5399772215666587\n",
            "----------------------------------------\n",
            "Epoch 225\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0321, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5054025273121183\n",
            "SCOPE mean: 0.3215420921925873, SCOPE var: 0.018222797190120366\n",
            "Total Loss: 0.537485460193685\n",
            "----------------------------------------\n",
            "Epoch 226\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0321, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5029356987498923\n",
            "SCOPE mean: 0.321907042862656, SCOPE var: 0.01822266645519534\n",
            "Total Loss: 0.5350079775973438\n",
            "----------------------------------------\n",
            "Epoch 227\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0320, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5004943372279181\n",
            "SCOPE mean: 0.322266763661385, SCOPE var: 0.01822230073864092\n",
            "Total Loss: 0.5325428266211709\n",
            "----------------------------------------\n",
            "Epoch 228\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0320, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.49808043021020393\n",
            "SCOPE mean: 0.3226205803121335, SCOPE var: 0.01822182380307382\n",
            "Total Loss: 0.530115747388477\n",
            "----------------------------------------\n",
            "Epoch 229\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0320, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4956922195492332\n",
            "SCOPE mean: 0.3229777097072757, SCOPE var: 0.01822170865272442\n",
            "Total Loss: 0.5277091554606618\n",
            "----------------------------------------\n",
            "Epoch 230\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0320, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.49332899326574087\n",
            "SCOPE mean: 0.32333801348571817, SCOPE var: 0.018221981708209607\n",
            "Total Loss: 0.5253207776275174\n",
            "----------------------------------------\n",
            "Epoch 231\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0320, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4909912552222602\n",
            "SCOPE mean: 0.32369795187512024, SCOPE var: 0.018222679884424563\n",
            "Total Loss: 0.5229515691384984\n",
            "----------------------------------------\n",
            "Epoch 232\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0319, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4886819857037852\n",
            "SCOPE mean: 0.3240515633231087, SCOPE var: 0.018224090764218014\n",
            "Total Loss: 0.5206047358293314\n",
            "----------------------------------------\n",
            "Epoch 233\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0319, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.48639796606361513\n",
            "SCOPE mean: 0.32438663308267435, SCOPE var: 0.018225781418420146\n",
            "Total Loss: 0.5182803695123357\n",
            "----------------------------------------\n",
            "Epoch 234\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0318, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4841357840053552\n",
            "SCOPE mean: 0.32470301392696665, SCOPE var: 0.018227377049286387\n",
            "Total Loss: 0.5159736103969667\n",
            "----------------------------------------\n",
            "Epoch 235\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0318, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.48189308666040437\n",
            "SCOPE mean: 0.32500122535071624, SCOPE var: 0.018228931487628303\n",
            "Total Loss: 0.5136985621472328\n",
            "----------------------------------------\n",
            "Epoch 236\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0318, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4796754934236248\n",
            "SCOPE mean: 0.3252774915062667, SCOPE var: 0.01823030770174516\n",
            "Total Loss: 0.5114431974752348\n",
            "----------------------------------------\n",
            "Epoch 237\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0317, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4774793773805766\n",
            "SCOPE mean: 0.3255430261963847, SCOPE var: 0.01823170126232425\n",
            "Total Loss: 0.5091977825105376\n",
            "----------------------------------------\n",
            "Epoch 238\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0317, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4753027264934989\n",
            "SCOPE mean: 0.3258002959701521, SCOPE var: 0.018233176229973145\n",
            "Total Loss: 0.5069672933945281\n",
            "----------------------------------------\n",
            "Epoch 239\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0316, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4731476013771585\n",
            "SCOPE mean: 0.32605678350913836, SCOPE var: 0.01823497300145691\n",
            "Total Loss: 0.5047718139756205\n",
            "----------------------------------------\n",
            "Epoch 240\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0316, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.471016294738263\n",
            "SCOPE mean: 0.32628556717378593, SCOPE var: 0.018236289928599176\n",
            "Total Loss: 0.5026005597381364\n",
            "----------------------------------------\n",
            "Epoch 241\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0315, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.46890660786685806\n",
            "SCOPE mean: 0.3265110541637426, SCOPE var: 0.018238016664220924\n",
            "Total Loss: 0.5004479013775267\n",
            "----------------------------------------\n",
            "Epoch 242\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0315, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.46681918430737135\n",
            "SCOPE mean: 0.32674786509919523, SCOPE var: 0.018240360578480448\n",
            "Total Loss: 0.4983136749845119\n",
            "----------------------------------------\n",
            "Epoch 243\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0315, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4647525931033806\n",
            "SCOPE mean: 0.32699359770884023, SCOPE var: 0.018243240753342792\n",
            "Total Loss: 0.4962109528038446\n",
            "----------------------------------------\n",
            "Epoch 244\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0314, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.46269409263615946\n",
            "SCOPE mean: 0.3272177106480533, SCOPE var: 0.018244233438096648\n",
            "Total Loss: 0.4941090847688315\n",
            "----------------------------------------\n",
            "Epoch 245\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0314, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4606509864929438\n",
            "SCOPE mean: 0.32742382049454444, SCOPE var: 0.018245197325273004\n",
            "Total Loss: 0.49201340592118536\n",
            "----------------------------------------\n",
            "Epoch 246\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0313, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4586236046933569\n",
            "SCOPE mean: 0.3276050425693249, SCOPE var: 0.01824598898006207\n",
            "Total Loss: 0.48994191031418166\n",
            "----------------------------------------\n",
            "Epoch 247\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0313, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.45661147295603166\n",
            "SCOPE mean: 0.32776759005395956, SCOPE var: 0.018247036255376735\n",
            "Total Loss: 0.48789578531791106\n",
            "----------------------------------------\n",
            "Epoch 248\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0312, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.45461765781579605\n",
            "SCOPE mean: 0.3279015704889718, SCOPE var: 0.01824780922463952\n",
            "Total Loss: 0.48586069046288205\n",
            "----------------------------------------\n",
            "Epoch 249\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0312, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.45263985963934084\n",
            "SCOPE mean: 0.32801028717098607, SCOPE var: 0.018248324548672187\n",
            "Total Loss: 0.48383389400933313\n",
            "----------------------------------------\n",
            "Epoch 250\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0311, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4506801142759599\n",
            "SCOPE mean: 0.3281012811115093, SCOPE var: 0.01824879047530935\n",
            "Total Loss: 0.48181788517719487\n",
            "----------------------------------------\n",
            "Epoch 251\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0311, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.44873939637359367\n",
            "SCOPE mean: 0.3281781013458844, SCOPE var: 0.018249271301229934\n",
            "Total Loss: 0.4798135794020223\n",
            "----------------------------------------\n",
            "Epoch 252\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0310, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.44681764017473447\n",
            "SCOPE mean: 0.3282489273175835, SCOPE var: 0.018249880964333953\n",
            "Total Loss: 0.47782764136038164\n",
            "----------------------------------------\n",
            "Epoch 253\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0310, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.44491190958299615\n",
            "SCOPE mean: 0.3283106343514102, SCOPE var: 0.01825044179108084\n",
            "Total Loss: 0.47586687789812765\n",
            "----------------------------------------\n",
            "Epoch 254\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0309, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.44306206602530107\n",
            "SCOPE mean: 0.3283206249924963, SCOPE var: 0.018244389981300364\n",
            "Total Loss: 0.4739172652892441\n",
            "----------------------------------------\n",
            "Epoch 255\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0308, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4412253807700915\n",
            "SCOPE mean: 0.3283515657917298, SCOPE var: 0.018239737331393308\n",
            "Total Loss: 0.4719960678992166\n",
            "----------------------------------------\n",
            "Epoch 256\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0307, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.43940107438310505\n",
            "SCOPE mean: 0.3284038092566878, SCOPE var: 0.018236439386926737\n",
            "Total Loss: 0.4700884187874873\n",
            "----------------------------------------\n",
            "Epoch 257\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0306, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.43758991413996134\n",
            "SCOPE mean: 0.3284717711375083, SCOPE var: 0.01823423726245122\n",
            "Total Loss: 0.46819432207822925\n",
            "----------------------------------------\n",
            "Epoch 258\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0305, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.43579268424099926\n",
            "SCOPE mean: 0.3285622812339281, SCOPE var: 0.0182333202796276\n",
            "Total Loss: 0.46631481425106464\n",
            "----------------------------------------\n",
            "Epoch 259\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0304, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4340091809459135\n",
            "SCOPE mean: 0.3286738747585222, SCOPE var: 0.018233660491709904\n",
            "Total Loss: 0.4644503387617184\n",
            "----------------------------------------\n",
            "Epoch 260\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0304, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4322409944327367\n",
            "SCOPE mean: 0.3288057648150841, SCOPE var: 0.018234966373498484\n",
            "Total Loss: 0.46260168742476215\n",
            "----------------------------------------\n",
            "Epoch 261\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0303, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.43048598073255645\n",
            "SCOPE mean: 0.3289751556870548, SCOPE var: 0.01823732087788128\n",
            "Total Loss: 0.46076735808104197\n",
            "----------------------------------------\n",
            "Epoch 262\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0302, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4287419972709753\n",
            "SCOPE mean: 0.32917027779324115, SCOPE var: 0.018240468013292585\n",
            "Total Loss: 0.4589622407710828\n",
            "----------------------------------------\n",
            "Epoch 263\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0301, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4270499227778673\n",
            "SCOPE mean: 0.32933974705227453, SCOPE var: 0.01823717218301796\n",
            "Total Loss: 0.4571533916807282\n",
            "----------------------------------------\n",
            "Epoch 264\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0300, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.42536930755809466\n",
            "SCOPE mean: 0.32955095104119975, SCOPE var: 0.018235610572834418\n",
            "Total Loss: 0.45536947837248026\n",
            "----------------------------------------\n",
            "Epoch 265\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0299, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.42370137179655093\n",
            "SCOPE mean: 0.3297980115008364, SCOPE var: 0.018235734868003874\n",
            "Total Loss: 0.453607345235616\n",
            "----------------------------------------\n",
            "Epoch 266\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0298, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.42204575155243007\n",
            "SCOPE mean: 0.33007470417568446, SCOPE var: 0.018237049302328487\n",
            "Total Loss: 0.45185762699838306\n",
            "----------------------------------------\n",
            "Epoch 267\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0297, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.42040149474311\n",
            "SCOPE mean: 0.33038084891696873, SCOPE var: 0.018239378348850185\n",
            "Total Loss: 0.45011971120737715\n",
            "----------------------------------------\n",
            "Epoch 268\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0296, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.41876813884561065\n",
            "SCOPE mean: 0.330714106203737, SCOPE var: 0.01824283764669203\n",
            "Total Loss: 0.4483955918383713\n",
            "----------------------------------------\n",
            "Epoch 269\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0295, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4171834273337992\n",
            "SCOPE mean: 0.3310031980191823, SCOPE var: 0.018239815531150914\n",
            "Total Loss: 0.44668255942708873\n",
            "----------------------------------------\n",
            "Epoch 270\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0294, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.41560391779881484\n",
            "SCOPE mean: 0.3313202279892162, SCOPE var: 0.018238931020997773\n",
            "Total Loss: 0.4449839639698377\n",
            "----------------------------------------\n",
            "Epoch 271\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0293, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4140298929629098\n",
            "SCOPE mean: 0.3316570430268445, SCOPE var: 0.018239981606892317\n",
            "Total Loss: 0.4433047273390992\n",
            "----------------------------------------\n",
            "Epoch 272\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0292, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.41246329132102055\n",
            "SCOPE mean: 0.33198617854164236, SCOPE var: 0.018242076365504747\n",
            "Total Loss: 0.44163456110922406\n",
            "----------------------------------------\n",
            "Epoch 273\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0291, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.41090385308163424\n",
            "SCOPE mean: 0.3322883454032487, SCOPE var: 0.018244985883337568\n",
            "Total Loss: 0.4399699710054926\n",
            "----------------------------------------\n",
            "Epoch 274\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0290, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.40934882152132057\n",
            "SCOPE mean: 0.3325631358920766, SCOPE var: 0.01824857194893301\n",
            "Total Loss: 0.43832137761493867\n",
            "----------------------------------------\n",
            "Epoch 275\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0289, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4078002646799718\n",
            "SCOPE mean: 0.3328174694223198, SCOPE var: 0.018252883993406726\n",
            "Total Loss: 0.4366836837528257\n",
            "----------------------------------------\n",
            "Epoch 276\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0288, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4062653484699885\n",
            "SCOPE mean: 0.3330626504258501, SCOPE var: 0.018258037569641835\n",
            "Total Loss: 0.43506107979118336\n",
            "----------------------------------------\n",
            "Epoch 277\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0287, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4047420916460178\n",
            "SCOPE mean: 0.3332953483928245, SCOPE var: 0.01826380883337723\n",
            "Total Loss: 0.4334791355404479\n",
            "----------------------------------------\n",
            "Epoch 278\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0286, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.40327320560646707\n",
            "SCOPE mean: 0.33345784518033705, SCOPE var: 0.018261557854660236\n",
            "Total Loss: 0.4318727386951692\n",
            "----------------------------------------\n",
            "Epoch 279\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0285, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.40184386078417234\n",
            "SCOPE mean: 0.33357651960435225, SCOPE var: 0.018253627663074232\n",
            "Total Loss: 0.4302995565433814\n",
            "----------------------------------------\n",
            "Epoch 280\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0283, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4004170740008726\n",
            "SCOPE mean: 0.3336994817360147, SCOPE var: 0.018247807901107627\n",
            "Total Loss: 0.42874800707792365\n",
            "----------------------------------------\n",
            "Epoch 281\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0282, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3989903558732847\n",
            "SCOPE mean: 0.3338316117778351, SCOPE var: 0.01824421315047359\n",
            "Total Loss: 0.4272000009126154\n",
            "----------------------------------------\n",
            "Epoch 282\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0281, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3975641529750896\n",
            "SCOPE mean: 0.3339611672456742, SCOPE var: 0.01824272135436173\n",
            "Total Loss: 0.42566477655852647\n",
            "----------------------------------------\n",
            "Epoch 283\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0280, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.39613526165459495\n",
            "SCOPE mean: 0.33407882423035895, SCOPE var: 0.018243119741300735\n",
            "Total Loss: 0.4241359147827627\n",
            "----------------------------------------\n",
            "Epoch 284\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0279, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3947075612761561\n",
            "SCOPE mean: 0.3341777264421788, SCOPE var: 0.018245075437445517\n",
            "Total Loss: 0.42261030436970926\n",
            "----------------------------------------\n",
            "Epoch 285\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0278, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3932816167462118\n",
            "SCOPE mean: 0.3342671055114253, SCOPE var: 0.018248765734663785\n",
            "Total Loss: 0.4210971021789496\n",
            "----------------------------------------\n",
            "Epoch 286\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0277, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.39187176769607535\n",
            "SCOPE mean: 0.33433606072255445, SCOPE var: 0.018253415114802815\n",
            "Total Loss: 0.4196063421885035\n",
            "----------------------------------------\n",
            "Epoch 287\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0277, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3904693887559139\n",
            "SCOPE mean: 0.334402364971694, SCOPE var: 0.018258920013277398\n",
            "Total Loss: 0.41812174270866115\n",
            "----------------------------------------\n",
            "Epoch 288\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0276, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3890750940139843\n",
            "SCOPE mean: 0.3344565116871527, SCOPE var: 0.01826509337726462\n",
            "Total Loss: 0.4166433479609454\n",
            "----------------------------------------\n",
            "Epoch 289\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0275, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3876912289112121\n",
            "SCOPE mean: 0.3344993518493952, SCOPE var: 0.018271837572612155\n",
            "Total Loss: 0.41518275776522495\n",
            "----------------------------------------\n",
            "Epoch 290\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0274, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3863265359318003\n",
            "SCOPE mean: 0.3345304449507148, SCOPE var: 0.018278913362919435\n",
            "Total Loss: 0.41373658693511767\n",
            "----------------------------------------\n",
            "Epoch 291\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0273, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.38497015687015984\n",
            "SCOPE mean: 0.3345680777699924, SCOPE var: 0.01828623471960653\n",
            "Total Loss: 0.4123036816529367\n",
            "----------------------------------------\n",
            "Epoch 292\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0273, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.38361856962898777\n",
            "SCOPE mean: 0.3346192724418434, SCOPE var: 0.018293955901643916\n",
            "Total Loss: 0.4108911962378121\n",
            "----------------------------------------\n",
            "Epoch 293\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0272, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.38231366037781733\n",
            "SCOPE mean: 0.33462019366699886, SCOPE var: 0.01829354003938382\n",
            "Total Loss: 0.40947593614485933\n",
            "----------------------------------------\n",
            "Epoch 294\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0270, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.381045393551479\n",
            "SCOPE mean: 0.3345678480761678, SCOPE var: 0.018285685927229196\n",
            "Total Loss: 0.4080695378518192\n",
            "----------------------------------------\n",
            "Epoch 295\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0269, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.37977699030217354\n",
            "SCOPE mean: 0.3345412742260512, SCOPE var: 0.018279873045930022\n",
            "Total Loss: 0.40668289903385996\n",
            "----------------------------------------\n",
            "Epoch 296\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0268, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3785111238683689\n",
            "SCOPE mean: 0.3345348261712681, SCOPE var: 0.01827595815948173\n",
            "Total Loss: 0.4053056538085426\n",
            "----------------------------------------\n",
            "Epoch 297\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0267, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3772521094115419\n",
            "SCOPE mean: 0.3345452737339326, SCOPE var: 0.018273314257183086\n",
            "Total Loss: 0.40393556858869756\n",
            "----------------------------------------\n",
            "Epoch 298\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0266, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3759979647689676\n",
            "SCOPE mean: 0.3345952659216749, SCOPE var: 0.018272386267431634\n",
            "Total Loss: 0.4025812109883251\n",
            "----------------------------------------\n",
            "Epoch 299\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0265, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3747490522556755\n",
            "SCOPE mean: 0.33468407634897845, SCOPE var: 0.018273163120587608\n",
            "Total Loss: 0.40123460535832123\n",
            "----------------------------------------\n",
            "Epoch 300\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0264, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3735035742505263\n",
            "SCOPE mean: 0.3348162793466242, SCOPE var: 0.0182759801538793\n",
            "Total Loss: 0.3999031735357531\n",
            "----------------------------------------\n",
            "Epoch 301\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0263, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.372261268051767\n",
            "SCOPE mean: 0.33497980978836356, SCOPE var: 0.018280169303231168\n",
            "Total Loss: 0.3985782209645399\n",
            "----------------------------------------\n",
            "Epoch 302\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0262, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3710259652562885\n",
            "SCOPE mean: 0.33515996693325706, SCOPE var: 0.018285056107063623\n",
            "Total Loss: 0.3972622858704089\n",
            "----------------------------------------\n",
            "Epoch 303\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0262, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.36979760309858933\n",
            "SCOPE mean: 0.3353516737334122, SCOPE var: 0.018290715310221795\n",
            "Total Loss: 0.39595612428215304\n",
            "----------------------------------------\n",
            "Epoch 304\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0261, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3685745493931258\n",
            "SCOPE mean: 0.3355569908095364, SCOPE var: 0.018297398894861643\n",
            "Total Loss: 0.3946589337714851\n",
            "----------------------------------------\n",
            "Epoch 305\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0260, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.36734880601747605\n",
            "SCOPE mean: 0.33575315422386587, SCOPE var: 0.018304408808511797\n",
            "Total Loss: 0.3933858950953785\n",
            "----------------------------------------\n",
            "Epoch 306\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0259, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.36616800091781876\n",
            "SCOPE mean: 0.33587173266924647, SCOPE var: 0.018302950732195983\n",
            "Total Loss: 0.39210713348359977\n",
            "----------------------------------------\n",
            "Epoch 307\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0258, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3650321789899137\n",
            "SCOPE mean: 0.3359162543525785, SCOPE var: 0.018293406434198134\n",
            "Total Loss: 0.39084074039137645\n",
            "----------------------------------------\n",
            "Epoch 308\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0257, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.36389159025677115\n",
            "SCOPE mean: 0.33596668419898934, SCOPE var: 0.01828547041360757\n",
            "Total Loss: 0.3895927782331849\n",
            "----------------------------------------\n",
            "Epoch 309\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0256, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3627529822041866\n",
            "SCOPE mean: 0.3360477706273363, SCOPE var: 0.018279594301321325\n",
            "Total Loss: 0.38834869877901984\n",
            "----------------------------------------\n",
            "Epoch 310\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0255, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.36161615695893257\n",
            "SCOPE mean: 0.3361452720700068, SCOPE var: 0.018273617819391037\n",
            "Total Loss: 0.3871183838438417\n",
            "----------------------------------------\n",
            "Epoch 311\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0254, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.36047337509014954\n",
            "SCOPE mean: 0.3362624736168427, SCOPE var: 0.01826888398130592\n",
            "Total Loss: 0.385901049181569\n",
            "----------------------------------------\n",
            "Epoch 312\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0254, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.35932972017550624\n",
            "SCOPE mean: 0.3364230220505574, SCOPE var: 0.018266544302524595\n",
            "Total Loss: 0.38469000681557386\n",
            "----------------------------------------\n",
            "Epoch 313\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0253, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.35818598266545476\n",
            "SCOPE mean: 0.33661716295499133, SCOPE var: 0.01826642069669007\n",
            "Total Loss: 0.3834840780013299\n",
            "----------------------------------------\n",
            "Epoch 314\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0252, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.35704374947655954\n",
            "SCOPE mean: 0.33683256124232025, SCOPE var: 0.01826826969778933\n",
            "Total Loss: 0.3822871163571252\n",
            "----------------------------------------\n",
            "Epoch 315\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0252, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.35590630705939486\n",
            "SCOPE mean: 0.33705989947820647, SCOPE var: 0.018271766237769483\n",
            "Total Loss: 0.3811034717497026\n",
            "----------------------------------------\n",
            "Epoch 316\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0251, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.35481186016885097\n",
            "SCOPE mean: 0.33719518596525677, SCOPE var: 0.018266366327286794\n",
            "Total Loss: 0.3799274988172878\n",
            "----------------------------------------\n",
            "Epoch 317\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0250, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.35371579415069865\n",
            "SCOPE mean: 0.3373134520794415, SCOPE var: 0.018262079186867317\n",
            "Total Loss: 0.3787646743083289\n",
            "----------------------------------------\n",
            "Epoch 318\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0250, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.35262435478834125\n",
            "SCOPE mean: 0.33742112923413853, SCOPE var: 0.018258988715120553\n",
            "Total Loss: 0.377612247237597\n",
            "----------------------------------------\n",
            "Epoch 319\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0249, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3515303820473667\n",
            "SCOPE mean: 0.33753647944988197, SCOPE var: 0.01825706791061974\n",
            "Total Loss: 0.37647501078144135\n",
            "----------------------------------------\n",
            "Epoch 320\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0249, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3504865004926265\n",
            "SCOPE mean: 0.33761638916940917, SCOPE var: 0.01824786746449004\n",
            "Total Loss: 0.37533853887179863\n",
            "----------------------------------------\n",
            "Epoch 321\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0248, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.34944028358571155\n",
            "SCOPE mean: 0.33774392142286874, SCOPE var: 0.018241581218744175\n",
            "Total Loss: 0.37421468034083616\n",
            "----------------------------------------\n",
            "Epoch 322\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0247, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3483936100031661\n",
            "SCOPE mean: 0.33790810087882533, SCOPE var: 0.018237901822030347\n",
            "Total Loss: 0.37310794835619704\n",
            "----------------------------------------\n",
            "Epoch 323\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0247, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3473432998085856\n",
            "SCOPE mean: 0.33806927005846865, SCOPE var: 0.01823568223033732\n",
            "Total Loss: 0.37200423448623565\n",
            "----------------------------------------\n",
            "Epoch 324\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0246, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.34629517191247317\n",
            "SCOPE mean: 0.33824276488321536, SCOPE var: 0.01823541043736356\n",
            "Total Loss: 0.37090125486254705\n",
            "----------------------------------------\n",
            "Epoch 325\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0246, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.34524458862869395\n",
            "SCOPE mean: 0.33841362314935175, SCOPE var: 0.018236439100159228\n",
            "Total Loss: 0.3698102375886588\n",
            "----------------------------------------\n",
            "Epoch 326\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0245, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3442382684943885\n",
            "SCOPE mean: 0.3385047475120447, SCOPE var: 0.01822923718617695\n",
            "Total Loss: 0.3687331707992097\n",
            "----------------------------------------\n",
            "Epoch 327\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0244, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.34322715831064093\n",
            "SCOPE mean: 0.33858618899352244, SCOPE var: 0.01822455428405912\n",
            "Total Loss: 0.3676616553850953\n",
            "----------------------------------------\n",
            "Epoch 328\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0244, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.34220848603564574\n",
            "SCOPE mean: 0.3386818771088003, SCOPE var: 0.018222370571761688\n",
            "Total Loss: 0.3665884830803906\n",
            "----------------------------------------\n",
            "Epoch 329\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0243, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3411834975808697\n",
            "SCOPE mean: 0.3387879514013449, SCOPE var: 0.018222531055931183\n",
            "Total Loss: 0.3655217928118793\n",
            "----------------------------------------\n",
            "Epoch 330\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0243, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.34020372404392696\n",
            "SCOPE mean: 0.33881563918431457, SCOPE var: 0.01821539156522431\n",
            "Total Loss: 0.36446519669577015\n",
            "----------------------------------------\n",
            "Epoch 331\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0242, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3392192239028618\n",
            "SCOPE mean: 0.33887399645983, SCOPE var: 0.01821160747931683\n",
            "Total Loss: 0.3634132574159271\n",
            "----------------------------------------\n",
            "Epoch 332\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0241, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3382258792996812\n",
            "SCOPE mean: 0.33896159739278475, SCOPE var: 0.018210849520861928\n",
            "Total Loss: 0.36236326709428723\n",
            "----------------------------------------\n",
            "Epoch 333\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0241, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.33721867339637857\n",
            "SCOPE mean: 0.3390460046976908, SCOPE var: 0.01821237337882609\n",
            "Total Loss: 0.3613367998424942\n",
            "----------------------------------------\n",
            "Epoch 334\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0240, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.33625825932703124\n",
            "SCOPE mean: 0.33904614263366883, SCOPE var: 0.018206140028924206\n",
            "Total Loss: 0.36029439105843086\n",
            "----------------------------------------\n",
            "Epoch 335\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0239, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3353326874607559\n",
            "SCOPE mean: 0.33897982952763955, SCOPE var: 0.01819309507818393\n",
            "Total Loss: 0.3592796853206487\n",
            "----------------------------------------\n",
            "Epoch 336\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0239, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3343911368391292\n",
            "SCOPE mean: 0.3389333879090825, SCOPE var: 0.018183763289018034\n",
            "Total Loss: 0.358266016316986\n",
            "----------------------------------------\n",
            "Epoch 337\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0238, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.333438808433532\n",
            "SCOPE mean: 0.3389052244622495, SCOPE var: 0.01817760876387282\n",
            "Total Loss: 0.357254769934101\n",
            "----------------------------------------\n",
            "Epoch 338\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0238, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3324846018739239\n",
            "SCOPE mean: 0.33889762517105615, SCOPE var: 0.01817458367987993\n",
            "Total Loss: 0.3562585541884466\n",
            "----------------------------------------\n",
            "Epoch 339\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0237, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.33151728611641\n",
            "SCOPE mean: 0.33900269390808063, SCOPE var: 0.01817592295841536\n",
            "Total Loss: 0.3552520818457457\n",
            "----------------------------------------\n",
            "Epoch 340\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0237, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.33054491414518306\n",
            "SCOPE mean: 0.33920519246500536, SCOPE var: 0.01818137531915477\n",
            "Total Loss: 0.35424673052018835\n",
            "----------------------------------------\n",
            "Epoch 341\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0237, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3295676863985348\n",
            "SCOPE mean: 0.3394586394708223, SCOPE var: 0.018189599555651095\n",
            "Total Loss: 0.3532826835984705\n",
            "----------------------------------------\n",
            "Epoch 342\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0237, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3286444207329966\n",
            "SCOPE mean: 0.3396784115828319, SCOPE var: 0.01819012764380904\n",
            "Total Loss: 0.35230887024321395\n",
            "----------------------------------------\n",
            "Epoch 343\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0236, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3277674193243703\n",
            "SCOPE mean: 0.33986086175771363, SCOPE var: 0.01818388449816602\n",
            "Total Loss: 0.3513284062123852\n",
            "----------------------------------------\n",
            "Epoch 344\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0235, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3269189634089162\n",
            "SCOPE mean: 0.34002746264868544, SCOPE var: 0.018171595354478185\n",
            "Total Loss: 0.350377375128031\n",
            "----------------------------------------\n",
            "Epoch 345\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0234, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.32605085767139397\n",
            "SCOPE mean: 0.34025056949398286, SCOPE var: 0.018163673977942184\n",
            "Total Loss: 0.3494275940691426\n",
            "----------------------------------------\n",
            "Epoch 346\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0233, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3251664179315637\n",
            "SCOPE mean: 0.34052597101527254, SCOPE var: 0.018159914057585876\n",
            "Total Loss: 0.3484750697401426\n",
            "----------------------------------------\n",
            "Epoch 347\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0233, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3242680543543331\n",
            "SCOPE mean: 0.34084274760822875, SCOPE var: 0.018160014908841768\n",
            "Total Loss: 0.3475208794372307\n",
            "----------------------------------------\n",
            "Epoch 348\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0232, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3233627238075011\n",
            "SCOPE mean: 0.34118525137618333, SCOPE var: 0.018163609036342773\n",
            "Total Loss: 0.34657337620596723\n",
            "----------------------------------------\n",
            "Epoch 349\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0232, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.32245143973596624\n",
            "SCOPE mean: 0.3415404851634048, SCOPE var: 0.018169993606064208\n",
            "Total Loss: 0.34563176476119084\n",
            "----------------------------------------\n",
            "Epoch 350\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0232, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3215317854793863\n",
            "SCOPE mean: 0.3419084813851412, SCOPE var: 0.018178782380373185\n",
            "Total Loss: 0.3447205441218661\n",
            "----------------------------------------\n",
            "Epoch 351\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0232, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.32066287031775265\n",
            "SCOPE mean: 0.3422094430587738, SCOPE var: 0.018179270428248667\n",
            "Total Loss: 0.34381314908425\n",
            "----------------------------------------\n",
            "Epoch 352\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0230, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.31984273876176855\n",
            "SCOPE mean: 0.3424372889222797, SCOPE var: 0.01817197789498861\n",
            "Total Loss: 0.3428841453665942\n",
            "----------------------------------------\n",
            "Epoch 353\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0229, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.31906073186603584\n",
            "SCOPE mean: 0.3425964058214934, SCOPE var: 0.018157742644216258\n",
            "Total Loss: 0.3419788861090266\n",
            "----------------------------------------\n",
            "Epoch 354\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0228, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3182622484990905\n",
            "SCOPE mean: 0.34277926750885485, SCOPE var: 0.018147917422143046\n",
            "Total Loss: 0.34109416284499167\n",
            "----------------------------------------\n",
            "Epoch 355\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0228, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3174501217727769\n",
            "SCOPE mean: 0.3429770723469896, SCOPE var: 0.01814211705195769\n",
            "Total Loss: 0.3402096816815202\n",
            "----------------------------------------\n",
            "Epoch 356\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0227, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3166247846547675\n",
            "SCOPE mean: 0.3431880854070099, SCOPE var: 0.01814003960194233\n",
            "Total Loss: 0.3393254574049245\n",
            "----------------------------------------\n",
            "Epoch 357\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0227, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3157904785512637\n",
            "SCOPE mean: 0.34341265237014, SCOPE var: 0.018141386912313054\n",
            "Total Loss: 0.3384450251755111\n",
            "----------------------------------------\n",
            "Epoch 358\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0226, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.31495073912847116\n",
            "SCOPE mean: 0.3436680721751889, SCOPE var: 0.01814586555453015\n",
            "Total Loss: 0.33757127263766235\n",
            "----------------------------------------\n",
            "Epoch 359\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0226, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.31409520935447444\n",
            "SCOPE mean: 0.34394688530123296, SCOPE var: 0.01815306086429042\n",
            "Total Loss: 0.3367319626378328\n",
            "----------------------------------------\n",
            "Epoch 360\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0226, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.31328711957613004\n",
            "SCOPE mean: 0.3441608340637762, SCOPE var: 0.018151933133352425\n",
            "Total Loss: 0.335889835874461\n",
            "----------------------------------------\n",
            "Epoch 361\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0225, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3125242789483942\n",
            "SCOPE mean: 0.3443156162720284, SCOPE var: 0.018143416551597572\n",
            "Total Loss: 0.33502886783589314\n",
            "----------------------------------------\n",
            "Epoch 362\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0224, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3117890595279419\n",
            "SCOPE mean: 0.3444093367120036, SCOPE var: 0.018128501385353487\n",
            "Total Loss: 0.3341974127032665\n",
            "----------------------------------------\n",
            "Epoch 363\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0223, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.31102585429908663\n",
            "SCOPE mean: 0.34453587213890524, SCOPE var: 0.01811851030170093\n",
            "Total Loss: 0.3333745139619102\n",
            "----------------------------------------\n",
            "Epoch 364\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0223, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.31023979568578924\n",
            "SCOPE mean: 0.3446829301880036, SCOPE var: 0.01811309807067956\n",
            "Total Loss: 0.332544972755649\n",
            "----------------------------------------\n",
            "Epoch 365\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0223, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3094391969532539\n",
            "SCOPE mean: 0.34487498306151426, SCOPE var: 0.018112748321410743\n",
            "Total Loss: 0.33171492783908263\n",
            "----------------------------------------\n",
            "Epoch 366\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0223, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3086268218670963\n",
            "SCOPE mean: 0.34510706136926106, SCOPE var: 0.01811712926657237\n",
            "Total Loss: 0.33088627724185043\n",
            "----------------------------------------\n",
            "Epoch 367\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0223, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3078014395492643\n",
            "SCOPE mean: 0.34536726171958865, SCOPE var: 0.01812554057076211\n",
            "Total Loss: 0.33009708585790354\n",
            "----------------------------------------\n",
            "Epoch 368\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0223, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.307033659371123\n",
            "SCOPE mean: 0.3455714575867899, SCOPE var: 0.018126577446722834\n",
            "Total Loss: 0.32930159886834837\n",
            "----------------------------------------\n",
            "Epoch 369\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0222, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3063137101927737\n",
            "SCOPE mean: 0.34569217773782773, SCOPE var: 0.018119961119706558\n",
            "Total Loss: 0.3284893614533527\n",
            "----------------------------------------\n",
            "Epoch 370\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0220, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.30563429977794254\n",
            "SCOPE mean: 0.34573663033928514, SCOPE var: 0.01810655730150161\n",
            "Total Loss: 0.32767658960903373\n",
            "----------------------------------------\n",
            "Epoch 371\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0220, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3049238267533986\n",
            "SCOPE mean: 0.34580347801285677, SCOPE var: 0.018098503165519867\n",
            "Total Loss: 0.3268945831676586\n",
            "----------------------------------------\n",
            "Epoch 372\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0219, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.30419144118790803\n",
            "SCOPE mean: 0.34588840932388554, SCOPE var: 0.018095225896531578\n",
            "Total Loss: 0.3261043553013382\n",
            "----------------------------------------\n",
            "Epoch 373\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0219, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.30344159511361707\n",
            "SCOPE mean: 0.34599136054038165, SCOPE var: 0.01809642800730068\n",
            "Total Loss: 0.3253138175560538\n",
            "----------------------------------------\n",
            "Epoch 374\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0219, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.302673778043899\n",
            "SCOPE mean: 0.3461064051646704, SCOPE var: 0.018101487785157792\n",
            "Total Loss: 0.3245364735025375\n",
            "----------------------------------------\n",
            "Epoch 375\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0218, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.30195274384221826\n",
            "SCOPE mean: 0.3461568635599202, SCOPE var: 0.01809918206252326\n",
            "Total Loss: 0.32376669825935755\n",
            "----------------------------------------\n",
            "Epoch 376\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0217, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3012790569055891\n",
            "SCOPE mean: 0.3461590613232092, SCOPE var: 0.0180905761197758\n",
            "Total Loss: 0.3229901775892672\n",
            "----------------------------------------\n",
            "Epoch 377\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0217, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3005762319712946\n",
            "SCOPE mean: 0.3462090514017532, SCOPE var: 0.018087368223359775\n",
            "Total Loss: 0.3222265864670574\n",
            "----------------------------------------\n",
            "Epoch 378\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0216, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2998468286118784\n",
            "SCOPE mean: 0.34630753898135525, SCOPE var: 0.018089140664893002\n",
            "Total Loss: 0.32147614854880574\n",
            "----------------------------------------\n",
            "Epoch 379\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0216, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2991602605034345\n",
            "SCOPE mean: 0.34636701607511844, SCOPE var: 0.01808443737706231\n",
            "Total Loss: 0.3207154343026462\n",
            "----------------------------------------\n",
            "Epoch 380\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0214, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.29851462401847983\n",
            "SCOPE mean: 0.34638934540556604, SCOPE var: 0.018073933678152715\n",
            "Total Loss: 0.3199604808364824\n",
            "----------------------------------------\n",
            "Epoch 381\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0214, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2978397830299406\n",
            "SCOPE mean: 0.34645718554925836, SCOPE var: 0.018069267734467934\n",
            "Total Loss: 0.3192204775118605\n",
            "----------------------------------------\n",
            "Epoch 382\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0213, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2971402889596925\n",
            "SCOPE mean: 0.34657328332561027, SCOPE var: 0.018070087962658465\n",
            "Total Loss: 0.318476436787959\n",
            "----------------------------------------\n",
            "Epoch 383\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0213, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2964139310392456\n",
            "SCOPE mean: 0.3467297383859992, SCOPE var: 0.018075947674025726\n",
            "Total Loss: 0.3177459599306839\n",
            "----------------------------------------\n",
            "Epoch 384\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0213, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2957325609705252\n",
            "SCOPE mean: 0.34684397213489754, SCOPE var: 0.018075196853277613\n",
            "Total Loss: 0.3170137801087522\n",
            "----------------------------------------\n",
            "Epoch 385\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0212, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.29509094357394594\n",
            "SCOPE mean: 0.3469225548764848, SCOPE var: 0.018068600752572713\n",
            "Total Loss: 0.3162727812084498\n",
            "----------------------------------------\n",
            "Epoch 386\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0211, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.29447742760038736\n",
            "SCOPE mean: 0.34697504177448707, SCOPE var: 0.0180568139525072\n",
            "Total Loss: 0.3155655195732483\n",
            "----------------------------------------\n",
            "Epoch 387\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0210, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.29382880184591564\n",
            "SCOPE mean: 0.347080937738525, SCOPE var: 0.018051551265364493\n",
            "Total Loss: 0.3148494554087988\n",
            "----------------------------------------\n",
            "Epoch 388\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0210, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.29315466020400033\n",
            "SCOPE mean: 0.347228043112365, SCOPE var: 0.018051739152664333\n",
            "Total Loss: 0.314131773353279\n",
            "----------------------------------------\n",
            "Epoch 389\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0210, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.29246448151643967\n",
            "SCOPE mean: 0.3474115306963515, SCOPE var: 0.018056735731927263\n",
            "Total Loss: 0.31341758849163043\n",
            "----------------------------------------\n",
            "Epoch 390\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0210, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2917620182683747\n",
            "SCOPE mean: 0.3476455633492932, SCOPE var: 0.018066708850772824\n",
            "Total Loss: 0.3127188518554676\n",
            "----------------------------------------\n",
            "Epoch 391\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0209, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.29112055372064555\n",
            "SCOPE mean: 0.34785488021536604, SCOPE var: 0.018069766587628863\n",
            "Total Loss: 0.31203217412688317\n",
            "----------------------------------------\n",
            "Epoch 392\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0208, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.29052991845136494\n",
            "SCOPE mean: 0.34801216470851315, SCOPE var: 0.018065521327514534\n",
            "Total Loss: 0.3113331522872488\n",
            "----------------------------------------\n",
            "Epoch 393\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0207, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.289974861209946\n",
            "SCOPE mean: 0.34812665793156705, SCOPE var: 0.018054795405659217\n",
            "Total Loss: 0.31067060968599963\n",
            "----------------------------------------\n",
            "Epoch 394\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0206, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2893908435755899\n",
            "SCOPE mean: 0.3482728570872328, SCOPE var: 0.01804993492710941\n",
            "Total Loss: 0.3100038563013414\n",
            "----------------------------------------\n",
            "Epoch 395\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0205, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2887810245880698\n",
            "SCOPE mean: 0.34845590146936367, SCOPE var: 0.018050431270904704\n",
            "Total Loss: 0.3093283099165369\n",
            "----------------------------------------\n",
            "Epoch 396\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0205, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.288152793457227\n",
            "SCOPE mean: 0.34866343870402045, SCOPE var: 0.018055810877868145\n",
            "Total Loss: 0.30865130084081377\n",
            "----------------------------------------\n",
            "Epoch 397\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0205, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.28750841987029\n",
            "SCOPE mean: 0.34889372988037043, SCOPE var: 0.018065442869865146\n",
            "Total Loss: 0.30797363788991733\n",
            "----------------------------------------\n",
            "Epoch 398\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0205, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.28684261078912104\n",
            "SCOPE mean: 0.34913680834797445, SCOPE var: 0.018078598504945097\n",
            "Total Loss: 0.3073352064336852\n",
            "----------------------------------------\n",
            "Epoch 399\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0205, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.286228798872113\n",
            "SCOPE mean: 0.3493095563146693, SCOPE var: 0.018083301591948497\n",
            "Total Loss: 0.3066921220637088\n",
            "----------------------------------------\n",
            "Epoch 400\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0204, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.28566193646456206\n",
            "SCOPE mean: 0.3493276013978892, SCOPE var: 0.018080072472162024\n",
            "Total Loss: 0.3060331829995525\n",
            "----------------------------------------\n",
            "Epoch 401\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0202, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2851383308806231\n",
            "SCOPE mean: 0.3492970030702258, SCOPE var: 0.01806996461555082\n",
            "Total Loss: 0.3053646910939199\n",
            "----------------------------------------\n",
            "Epoch 402\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0201, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.28463940878391447\n",
            "SCOPE mean: 0.3492264383235918, SCOPE var: 0.018053998987030286\n",
            "Total Loss: 0.3047379294881921\n",
            "----------------------------------------\n",
            "Epoch 403\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0200, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.28410640810999355\n",
            "SCOPE mean: 0.3491944683933273, SCOPE var: 0.01804428387899401\n",
            "Total Loss: 0.3041122721106885\n",
            "----------------------------------------\n",
            "Epoch 404\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0199, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2835415777880276\n",
            "SCOPE mean: 0.34919736496999276, SCOPE var: 0.018040426279304494\n",
            "Total Loss: 0.3034808834158925\n",
            "----------------------------------------\n",
            "Epoch 405\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0199, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2829504953275273\n",
            "SCOPE mean: 0.3492114299498513, SCOPE var: 0.018042164289358533\n",
            "Total Loss: 0.3028422651205148\n",
            "----------------------------------------\n",
            "Epoch 406\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0199, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2823353170833659\n",
            "SCOPE mean: 0.34923416513152533, SCOPE var: 0.018048747631244724\n",
            "Total Loss: 0.3022010744858138\n",
            "----------------------------------------\n",
            "Epoch 407\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0199, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.28169985551279286\n",
            "SCOPE mean: 0.349272840162958, SCOPE var: 0.018059718628095675\n",
            "Total Loss: 0.3015655380591003\n",
            "----------------------------------------\n",
            "Epoch 408\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0198, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.28110620762484356\n",
            "SCOPE mean: 0.3492518193969498, SCOPE var: 0.018062739029854776\n",
            "Total Loss: 0.30095160954019456\n",
            "----------------------------------------\n",
            "Epoch 409\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0198, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.28055676236825067\n",
            "SCOPE mean: 0.34917609084431606, SCOPE var: 0.018058470769386718\n",
            "Total Loss: 0.3003206425838523\n",
            "----------------------------------------\n",
            "Epoch 410\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0197, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.28004169606162466\n",
            "SCOPE mean: 0.34903928850390814, SCOPE var: 0.018048216976551228\n",
            "Total Loss: 0.2997031368597435\n",
            "----------------------------------------\n",
            "Epoch 411\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0196, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.27950064394023866\n",
            "SCOPE mean: 0.34892899388231197, SCOPE var: 0.018044669596742995\n",
            "Total Loss: 0.2990950902829309\n",
            "----------------------------------------\n",
            "Epoch 412\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0195, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.27893162808237515\n",
            "SCOPE mean: 0.34886097433579455, SCOPE var: 0.018047094363684707\n",
            "Total Loss: 0.29847732327401766\n",
            "----------------------------------------\n",
            "Epoch 413\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0195, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.27833928810678615\n",
            "SCOPE mean: 0.34883053079800247, SCOPE var: 0.01805471373871332\n",
            "Total Loss: 0.2978510700037164\n",
            "----------------------------------------\n",
            "Epoch 414\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0195, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.27771977037043233\n",
            "SCOPE mean: 0.3488378528836815, SCOPE var: 0.01806693783061763\n",
            "Total Loss: 0.297268296423777\n",
            "----------------------------------------\n",
            "Epoch 415\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0195, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.27715134603835795\n",
            "SCOPE mean: 0.348802863578033, SCOPE var: 0.018070831694524805\n",
            "Total Loss: 0.29667433001668625\n",
            "----------------------------------------\n",
            "Epoch 416\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0194, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2766296863064918\n",
            "SCOPE mean: 0.3487336106313319, SCOPE var: 0.018066921427653686\n",
            "Total Loss: 0.2960641276757479\n",
            "----------------------------------------\n",
            "Epoch 417\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0193, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2761490366227931\n",
            "SCOPE mean: 0.34862818042383403, SCOPE var: 0.01805631019460846\n",
            "Total Loss: 0.2954480075112899\n",
            "----------------------------------------\n",
            "Epoch 418\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0192, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.27569304809611095\n",
            "SCOPE mean: 0.3484846912771861, SCOPE var: 0.01803976790015533\n",
            "Total Loss: 0.2948650360388079\n",
            "----------------------------------------\n",
            "Epoch 419\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0191, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.27520709892045847\n",
            "SCOPE mean: 0.3483783640077131, SCOPE var: 0.01802953068089145\n",
            "Total Loss: 0.2942811015572422\n",
            "----------------------------------------\n",
            "Epoch 420\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0190, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2746924624983665\n",
            "SCOPE mean: 0.3483189996740646, SCOPE var: 0.018025346414209064\n",
            "Total Loss: 0.29369871740675074\n",
            "----------------------------------------\n",
            "Epoch 421\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0190, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2741500297919781\n",
            "SCOPE mean: 0.34830877749825, SCOPE var: 0.01802656038091823\n",
            "Total Loss: 0.2931060829810772\n",
            "----------------------------------------\n",
            "Epoch 422\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0189, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.27358309967328887\n",
            "SCOPE mean: 0.34833668452227773, SCOPE var: 0.018032710444895184\n",
            "Total Loss: 0.29251199465341954\n",
            "----------------------------------------\n",
            "Epoch 423\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0189, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.272999491891111\n",
            "SCOPE mean: 0.3483975976248423, SCOPE var: 0.018042978085038814\n",
            "Total Loss: 0.29191573986033886\n",
            "----------------------------------------\n",
            "Epoch 424\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0190, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2723912942974038\n",
            "SCOPE mean: 0.34848611044749694, SCOPE var: 0.01805698849959416\n",
            "Total Loss: 0.29137099733740757\n",
            "----------------------------------------\n",
            "Epoch 425\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0190, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2718334328375989\n",
            "SCOPE mean: 0.3485256206406376, SCOPE var: 0.01806188557856329\n",
            "Total Loss: 0.2908201203526768\n",
            "----------------------------------------\n",
            "Epoch 426\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0189, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2713222063464712\n",
            "SCOPE mean: 0.34851272317026416, SCOPE var: 0.01805846515972172\n",
            "Total Loss: 0.2902491517922206\n",
            "----------------------------------------\n",
            "Epoch 427\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0188, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.270854007605853\n",
            "SCOPE mean: 0.3484556603742042, SCOPE var: 0.01804783150225619\n",
            "Total Loss: 0.28966848837971004\n",
            "----------------------------------------\n",
            "Epoch 428\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0187, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.27042407767093835\n",
            "SCOPE mean: 0.348357228721602, SCOPE var: 0.01803105014399953\n",
            "Total Loss: 0.2890788093657716\n",
            "----------------------------------------\n",
            "Epoch 429\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0185, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2700149956222352\n",
            "SCOPE mean: 0.3482229979150044, SCOPE var: 0.018009144259961765\n",
            "Total Loss: 0.28855048906153846\n",
            "----------------------------------------\n",
            "Epoch 430\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0184, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2695692095693396\n",
            "SCOPE mean: 0.3481350483739498, SCOPE var: 0.017995197152057194\n",
            "Total Loss: 0.28801508585607855\n",
            "----------------------------------------\n",
            "Epoch 431\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0184, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.26908795881567343\n",
            "SCOPE mean: 0.348089424249253, SCOPE var: 0.01798882567926745\n",
            "Total Loss: 0.28747142620513866\n",
            "----------------------------------------\n",
            "Epoch 432\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0183, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.26857277321476325\n",
            "SCOPE mean: 0.348074285944713, SCOPE var: 0.01798959678452193\n",
            "Total Loss: 0.28691916297641523\n",
            "----------------------------------------\n",
            "Epoch 433\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0183, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.26802404259937135\n",
            "SCOPE mean: 0.34810110052300514, SCOPE var: 0.017996831143436736\n",
            "Total Loss: 0.28635531920472157\n",
            "----------------------------------------\n",
            "Epoch 434\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0183, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.26744709657741655\n",
            "SCOPE mean: 0.3481687975708991, SCOPE var: 0.018009648087579336\n",
            "Total Loss: 0.28578333949256995\n",
            "----------------------------------------\n",
            "Epoch 435\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0184, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.26684121554165935\n",
            "SCOPE mean: 0.34826693717544976, SCOPE var: 0.01802724544169465\n",
            "Total Loss: 0.2852656445596414\n",
            "----------------------------------------\n",
            "Epoch 436\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0185, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2662867172807983\n",
            "SCOPE mean: 0.34831825168082486, SCOPE var: 0.01803660421374261\n",
            "Total Loss: 0.2847546071728916\n",
            "----------------------------------------\n",
            "Epoch 437\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0185, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.26578155413153476\n",
            "SCOPE mean: 0.3483261659320211, SCOPE var: 0.01803828298024139\n",
            "Total Loss: 0.2842351813332194\n",
            "----------------------------------------\n",
            "Epoch 438\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0184, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.26532097974133223\n",
            "SCOPE mean: 0.34828848006039725, SCOPE var: 0.018032919946015673\n",
            "Total Loss: 0.2836981085903818\n",
            "----------------------------------------\n",
            "Epoch 439\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0183, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.26489982103892873\n",
            "SCOPE mean: 0.34821095770368765, SCOPE var: 0.018021330685268157\n",
            "Total Loss: 0.28315707024471143\n",
            "----------------------------------------\n",
            "Epoch 440\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0181, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.26451275901470017\n",
            "SCOPE mean: 0.348102265221129, SCOPE var: 0.018004632518713762\n",
            "Total Loss: 0.2826113064797034\n",
            "----------------------------------------\n",
            "Epoch 441\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0180, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2641395756535406\n",
            "SCOPE mean: 0.3479584255711375, SCOPE var: 0.0179835196353034\n",
            "Total Loss: 0.2821138409519634\n",
            "----------------------------------------\n",
            "Epoch 442\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0179, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.26371715741285845\n",
            "SCOPE mean: 0.34786468861727005, SCOPE var: 0.017970968056542684\n",
            "Total Loss: 0.2816125732094386\n",
            "----------------------------------------\n",
            "Epoch 443\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0178, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.26325050860769966\n",
            "SCOPE mean: 0.3478188709218975, SCOPE var: 0.01796644398271802\n",
            "Total Loss: 0.2810925996287103\n",
            "----------------------------------------\n",
            "Epoch 444\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0178, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2627437790692898\n",
            "SCOPE mean: 0.34781448908229456, SCOPE var: 0.017969512609759312\n",
            "Total Loss: 0.280562458495288\n",
            "----------------------------------------\n",
            "Epoch 445\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0178, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2622053298480079\n",
            "SCOPE mean: 0.34784376738201106, SCOPE var: 0.017979204320809662\n",
            "Total Loss: 0.2800233791796793\n",
            "----------------------------------------\n",
            "Epoch 446\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0179, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2616295716813609\n",
            "SCOPE mean: 0.34789033678774495, SCOPE var: 0.01799452163096376\n",
            "Total Loss: 0.27952998930443945\n",
            "----------------------------------------\n",
            "Epoch 447\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0179, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2611013671139004\n",
            "SCOPE mean: 0.3478713686120341, SCOPE var: 0.018001964538025352\n",
            "Total Loss: 0.2790378827487858\n",
            "----------------------------------------\n",
            "Epoch 448\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0179, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2606193965584263\n",
            "SCOPE mean: 0.3477972678607456, SCOPE var: 0.018002183129742572\n",
            "Total Loss: 0.2785352113816096\n",
            "----------------------------------------\n",
            "Epoch 449\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0178, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.26017976583643365\n",
            "SCOPE mean: 0.34767569366510337, SCOPE var: 0.017995875691716446\n",
            "Total Loss: 0.2780248898379521\n",
            "----------------------------------------\n",
            "Epoch 450\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0177, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.25977568506811105\n",
            "SCOPE mean: 0.34750546901232426, SCOPE var: 0.01798373544218371\n",
            "Total Loss: 0.27750445799370144\n",
            "----------------------------------------\n",
            "Epoch 451\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0176, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2594047035065439\n",
            "SCOPE mean: 0.34729948405092803, SCOPE var: 0.017966679355235254\n",
            "Total Loss: 0.2769814033141501\n",
            "----------------------------------------\n",
            "Epoch 452\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0174, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2590553730827114\n",
            "SCOPE mean: 0.34707009183809057, SCOPE var: 0.017945679121628928\n",
            "Total Loss: 0.2764989916458086\n",
            "----------------------------------------\n",
            "Epoch 453\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0174, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2586579760847242\n",
            "SCOPE mean: 0.34690332365374543, SCOPE var: 0.01793405810105212\n",
            "Total Loss: 0.2760216872157899\n",
            "----------------------------------------\n",
            "Epoch 454\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0173, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.25821783356781913\n",
            "SCOPE mean: 0.3467979005720109, SCOPE var: 0.01793120736033585\n",
            "Total Loss: 0.27552839531070644\n",
            "----------------------------------------\n",
            "Epoch 455\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0173, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2577428049523699\n",
            "SCOPE mean: 0.346744694174275, SCOPE var: 0.017935374037838344\n",
            "Total Loss: 0.275020713163054\n",
            "----------------------------------------\n",
            "Epoch 456\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0173, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.25724067819289154\n",
            "SCOPE mean: 0.3467398734145445, SCOPE var: 0.017946212428603225\n",
            "Total Loss: 0.27450976917873376\n",
            "----------------------------------------\n",
            "Epoch 457\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0173, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.25672273912953775\n",
            "SCOPE mean: 0.3467988706873153, SCOPE var: 0.017962630264083665\n",
            "Total Loss: 0.2740407445544412\n",
            "----------------------------------------\n",
            "Epoch 458\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0173, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2562691016555478\n",
            "SCOPE mean: 0.3468369278676252, SCOPE var: 0.017970929684913713\n",
            "Total Loss: 0.27355807595758197\n",
            "----------------------------------------\n",
            "Epoch 459\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0172, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2558805522854709\n",
            "SCOPE mean: 0.3468489209515705, SCOPE var: 0.017972046134574957\n",
            "Total Loss: 0.27307228783630044\n",
            "----------------------------------------\n",
            "Epoch 460\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0171, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2555223304446308\n",
            "SCOPE mean: 0.3468226815469564, SCOPE var: 0.017966678214157344\n",
            "Total Loss: 0.2725835872770955\n",
            "----------------------------------------\n",
            "Epoch 461\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0169, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.255187732710994\n",
            "SCOPE mean: 0.34676321751387357, SCOPE var: 0.017955586211239907\n",
            "Total Loss: 0.2720836764388795\n",
            "----------------------------------------\n",
            "Epoch 462\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0168, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2548644055113243\n",
            "SCOPE mean: 0.3466810016897578, SCOPE var: 0.017939725719397684\n",
            "Total Loss: 0.27162376586086\n",
            "----------------------------------------\n",
            "Epoch 463\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0167, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2544841895459625\n",
            "SCOPE mean: 0.3466599018493722, SCOPE var: 0.01793247744217756\n",
            "Total Loss: 0.2711588372873065\n",
            "----------------------------------------\n",
            "Epoch 464\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0166, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.25405230294026193\n",
            "SCOPE mean: 0.346696538285371, SCOPE var: 0.017934061072472054\n",
            "Total Loss: 0.27067914150231115\n",
            "----------------------------------------\n",
            "Epoch 465\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0166, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.25357656313361915\n",
            "SCOPE mean: 0.3467759166826252, SCOPE var: 0.017942758063288537\n",
            "Total Loss: 0.2701905275385127\n",
            "----------------------------------------\n",
            "Epoch 466\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0167, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2530578450153998\n",
            "SCOPE mean: 0.3468846297648497, SCOPE var: 0.017957498116896696\n",
            "Total Loss: 0.26971602992892596\n",
            "----------------------------------------\n",
            "Epoch 467\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0167, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2525749373156712\n",
            "SCOPE mean: 0.3469442572522928, SCOPE var: 0.01796496143265911\n",
            "Total Loss: 0.2692604005557149\n",
            "----------------------------------------\n",
            "Epoch 468\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0167, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.25213164867008125\n",
            "SCOPE mean: 0.3469647114915691, SCOPE var: 0.017965439086423875\n",
            "Total Loss: 0.2687969917899796\n",
            "----------------------------------------\n",
            "Epoch 469\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0166, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.25172290796581753\n",
            "SCOPE mean: 0.34695070392443356, SCOPE var: 0.017959555785559547\n",
            "Total Loss: 0.26832535272375746\n",
            "----------------------------------------\n",
            "Epoch 470\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0165, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2513399769516115\n",
            "SCOPE mean: 0.3469061243641748, SCOPE var: 0.01794811121686362\n",
            "Total Loss: 0.2678433562820262\n",
            "----------------------------------------\n",
            "Epoch 471\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0164, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2509638804072766\n",
            "SCOPE mean: 0.34680505201965917, SCOPE var: 0.01793143104382814\n",
            "Total Loss: 0.2673953226020304\n",
            "----------------------------------------\n",
            "Epoch 472\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0164, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2505419527732557\n",
            "SCOPE mean: 0.3467310543861003, SCOPE var: 0.017923363459862625\n",
            "Total Loss: 0.2669355728561594\n",
            "----------------------------------------\n",
            "Epoch 473\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0164, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.25010071975180864\n",
            "SCOPE mean: 0.34670054574613063, SCOPE var: 0.017923154219057665\n",
            "Total Loss: 0.26646844047806406\n",
            "----------------------------------------\n",
            "Epoch 474\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0163, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.24963893569157758\n",
            "SCOPE mean: 0.3467068178652012, SCOPE var: 0.017930047855883275\n",
            "Total Loss: 0.2659863770133503\n",
            "----------------------------------------\n",
            "Epoch 475\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0163, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.24915988699056507\n",
            "SCOPE mean: 0.3467465486641051, SCOPE var: 0.017943276981914412\n",
            "Total Loss: 0.2654925601826713\n",
            "----------------------------------------\n",
            "Epoch 476\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0164, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.24865892029779352\n",
            "SCOPE mean: 0.3468232854958929, SCOPE var: 0.017961954522023177\n",
            "Total Loss: 0.26503273221516527\n",
            "----------------------------------------\n",
            "Epoch 477\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0164, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.24821781418888494\n",
            "SCOPE mean: 0.3468521004422819, SCOPE var: 0.017972308140214\n",
            "Total Loss: 0.26457223861196555\n",
            "----------------------------------------\n",
            "Epoch 478\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0163, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2478162085046229\n",
            "SCOPE mean: 0.3468176121856239, SCOPE var: 0.017975363031587248\n",
            "Total Loss: 0.2641077062655325\n",
            "----------------------------------------\n",
            "Epoch 479\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0162, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.24744618567456053\n",
            "SCOPE mean: 0.3467267487943182, SCOPE var: 0.017971728535282058\n",
            "Total Loss: 0.26363384582051336\n",
            "----------------------------------------\n",
            "Epoch 480\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0161, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.24710336137798508\n",
            "SCOPE mean: 0.34658031750130214, SCOPE var: 0.01796228422606159\n",
            "Total Loss: 0.26315464772057967\n",
            "----------------------------------------\n",
            "Epoch 481\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0159, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.24677633312041466\n",
            "SCOPE mean: 0.3463948371817103, SCOPE var: 0.01794831633692367\n",
            "Total Loss: 0.26272034212686624\n",
            "----------------------------------------\n",
            "Epoch 482\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0159, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.24639330022613004\n",
            "SCOPE mean: 0.34626926581015566, SCOPE var: 0.017943465009764095\n",
            "Total Loss: 0.2622855702262833\n",
            "----------------------------------------\n",
            "Epoch 483\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0159, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.24597112299343482\n",
            "SCOPE mean: 0.3461919220056945, SCOPE var: 0.017945106191730988\n",
            "Total Loss: 0.2618393051164079\n",
            "----------------------------------------\n",
            "Epoch 484\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0159, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.24551352298067075\n",
            "SCOPE mean: 0.3461594216172928, SCOPE var: 0.017952676964438485\n",
            "Total Loss: 0.2613823107291455\n",
            "----------------------------------------\n",
            "Epoch 485\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0159, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.24502706282470121\n",
            "SCOPE mean: 0.3461609066544313, SCOPE var: 0.017965599209482864\n",
            "Total Loss: 0.26093433548544853\n",
            "----------------------------------------\n",
            "Epoch 486\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0159, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.24458584020858687\n",
            "SCOPE mean: 0.3461094590741847, SCOPE var: 0.01796995745026418\n",
            "Total Loss: 0.2605030376408416\n",
            "----------------------------------------\n",
            "Epoch 487\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0159, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2441919783456836\n",
            "SCOPE mean: 0.34602178093107944, SCOPE var: 0.017966320710289998\n",
            "Total Loss: 0.2600584904460623\n",
            "----------------------------------------\n",
            "Epoch 488\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0158, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.243865126478008\n",
            "SCOPE mean: 0.34592177429590326, SCOPE var: 0.01795539150357199\n",
            "Total Loss: 0.2596265107997148\n",
            "----------------------------------------\n",
            "Epoch 489\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0157, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2434942449972707\n",
            "SCOPE mean: 0.3458796888110898, SCOPE var: 0.017951675874035712\n",
            "Total Loss: 0.2591997172236673\n",
            "----------------------------------------\n",
            "Epoch 490\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0157, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.24311251039936776\n",
            "SCOPE mean: 0.3459057929999892, SCOPE var: 0.017954289042837822\n",
            "Total Loss: 0.25877060278576913\n",
            "----------------------------------------\n",
            "Epoch 491\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0156, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2426983372013793\n",
            "SCOPE mean: 0.3459724722050858, SCOPE var: 0.01796318425633796\n",
            "Total Loss: 0.2583337043271529\n",
            "----------------------------------------\n",
            "Epoch 492\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0157, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2422513506887019\n",
            "SCOPE mean: 0.3460580878482877, SCOPE var: 0.017977483685453623\n",
            "Total Loss: 0.2579413820001197\n",
            "----------------------------------------\n",
            "Epoch 493\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0157, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.24187743069044287\n",
            "SCOPE mean: 0.34610653723616425, SCOPE var: 0.017982515004199878\n",
            "Total Loss: 0.2575278926447019\n",
            "----------------------------------------\n",
            "Epoch 494\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0155, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2415735401519055\n",
            "SCOPE mean: 0.3461169445912913, SCOPE var: 0.017979438284373823\n",
            "Total Loss: 0.2571001658967498\n",
            "----------------------------------------\n",
            "Epoch 495\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0154, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2413054634880725\n",
            "SCOPE mean: 0.3460704136651539, SCOPE var: 0.017969787529424096\n",
            "Total Loss: 0.2566687820808807\n",
            "----------------------------------------\n",
            "Epoch 496\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0152, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2410559232361872\n",
            "SCOPE mean: 0.3459768126184656, SCOPE var: 0.017954690746208875\n",
            "Total Loss: 0.2562889855785107\n",
            "----------------------------------------\n",
            "Epoch 497\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0152, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2407458006903752\n",
            "SCOPE mean: 0.3459381843968681, SCOPE var: 0.017950525314247002\n",
            "Total Loss: 0.25589947145558894\n",
            "----------------------------------------\n",
            "Epoch 498\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0151, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.24036911202909728\n",
            "SCOPE mean: 0.3459510386252716, SCOPE var: 0.01795648314970911\n",
            "Total Loss: 0.2554862792116145\n",
            "----------------------------------------\n",
            "Epoch 499\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0151, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2399300989491383\n",
            "SCOPE mean: 0.3460127945272136, SCOPE var: 0.017971551830723492\n",
            "Total Loss: 0.25505184517850854\n",
            "----------------------------------------\n",
            "Epoch 500\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0152, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2395151797146249\n",
            "SCOPE mean: 0.3460277946014945, SCOPE var: 0.017981631250484277\n",
            "Total Loss: 0.25467031359819614\n",
            "----------------------------------------\n",
            "Epoch 501\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0151, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.23913335735714603\n",
            "SCOPE mean: 0.34599096346122477, SCOPE var: 0.017986781401902324\n",
            "Total Loss: 0.2542814637270316\n",
            "----------------------------------------\n",
            "Epoch 502\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0151, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.23878414707683712\n",
            "SCOPE mean: 0.34590666161402356, SCOPE var: 0.01798757733335627\n",
            "Total Loss: 0.2538973322970798\n",
            "----------------------------------------\n",
            "Epoch 503\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0150, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.23848709911640426\n",
            "SCOPE mean: 0.3458094130853186, SCOPE var: 0.01798381758258662\n",
            "Total Loss: 0.2535092161473634\n",
            "----------------------------------------\n",
            "Epoch 504\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0149, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2382372288154281\n",
            "SCOPE mean: 0.3457060258531732, SCOPE var: 0.01797609990830172\n",
            "Total Loss: 0.25311703136963315\n",
            "----------------------------------------\n",
            "Epoch 505\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0148, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2380003303034427\n",
            "SCOPE mean: 0.3455820604689189, SCOPE var: 0.017966182639901938\n",
            "Total Loss: 0.2527563339434353\n",
            "----------------------------------------\n",
            "Epoch 506\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0147, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2376846597675664\n",
            "SCOPE mean: 0.34552986687242376, SCOPE var: 0.017967391131191536\n",
            "Total Loss: 0.25237838731827505\n",
            "----------------------------------------\n",
            "Epoch 507\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0147, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2372972509884227\n",
            "SCOPE mean: 0.3455423141154265, SCOPE var: 0.017978722055609513\n",
            "Total Loss: 0.25199440287978314\n",
            "----------------------------------------\n",
            "Epoch 508\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0147, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.23693411757254215\n",
            "SCOPE mean: 0.34552822454452314, SCOPE var: 0.01798568428328167\n",
            "Total Loss: 0.2516289016757717\n",
            "----------------------------------------\n",
            "Epoch 509\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0147, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.23659734691638257\n",
            "SCOPE mean: 0.34548510767664053, SCOPE var: 0.017988292483470954\n",
            "Total Loss: 0.2512647994206099\n",
            "----------------------------------------\n",
            "Epoch 510\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0146, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2362829504096811\n",
            "SCOPE mean: 0.34541825049614144, SCOPE var: 0.017987239581557048\n",
            "Total Loss: 0.2508992828040423\n",
            "----------------------------------------\n",
            "Epoch 511\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0145, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2359887332234439\n",
            "SCOPE mean: 0.3453392965502052, SCOPE var: 0.017982901350768056\n",
            "Total Loss: 0.2505345232828386\n",
            "----------------------------------------\n",
            "Epoch 512\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0144, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2357367855010036\n",
            "SCOPE mean: 0.34528785763482767, SCOPE var: 0.01797541104435458\n",
            "Total Loss: 0.2501714018980039\n",
            "----------------------------------------\n",
            "Epoch 513\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0143, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.23549616957509406\n",
            "SCOPE mean: 0.34522346259094483, SCOPE var: 0.017965852585181553\n",
            "Total Loss: 0.24981333625874608\n",
            "----------------------------------------\n",
            "Epoch 514\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0143, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.23517355027114067\n",
            "SCOPE mean: 0.345229739352912, SCOPE var: 0.017967955977426068\n",
            "Total Loss: 0.24945893108617467\n",
            "----------------------------------------\n",
            "Epoch 515\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0142, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.23486460099946055\n",
            "SCOPE mean: 0.3452242864577719, SCOPE var: 0.01796748556770328\n",
            "Total Loss: 0.2491074442716421\n",
            "----------------------------------------\n",
            "Epoch 516\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0142, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.23456924622486977\n",
            "SCOPE mean: 0.3452392462502719, SCOPE var: 0.017964831545604253\n",
            "Total Loss: 0.2487575226671594\n",
            "----------------------------------------\n",
            "Epoch 517\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0141, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2343163322167637\n",
            "SCOPE mean: 0.3452716127694879, SCOPE var: 0.017958326793945486\n",
            "Total Loss: 0.24842101513399087\n",
            "----------------------------------------\n",
            "Epoch 518\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0141, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2339980797205402\n",
            "SCOPE mean: 0.3453605067780671, SCOPE var: 0.01796220751682474\n",
            "Total Loss: 0.2480691583150596\n",
            "----------------------------------------\n",
            "Epoch 519\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0140, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.23369876339752185\n",
            "SCOPE mean: 0.34541890803518793, SCOPE var: 0.017962072746918998\n",
            "Total Loss: 0.24772832526536834\n",
            "----------------------------------------\n",
            "Epoch 520\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0140, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2334178421195038\n",
            "SCOPE mean: 0.34545682355755414, SCOPE var: 0.017958412828155197\n",
            "Total Loss: 0.24739817747151166\n",
            "----------------------------------------\n",
            "Epoch 521\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0140, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.23307143057942162\n",
            "SCOPE mean: 0.3455831166590881, SCOPE var: 0.017966621004424373\n",
            "Total Loss: 0.2470564201765914\n",
            "----------------------------------------\n",
            "Epoch 522\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0140, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.23276777696010384\n",
            "SCOPE mean: 0.34572051272835824, SCOPE var: 0.01797000583494677\n",
            "Total Loss: 0.2467215816455424\n",
            "----------------------------------------\n",
            "Epoch 523\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0139, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.23248375697252843\n",
            "SCOPE mean: 0.3458328897479849, SCOPE var: 0.01796954399913538\n",
            "Total Loss: 0.2463813042462476\n",
            "----------------------------------------\n",
            "Epoch 524\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0138, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.23221430151776326\n",
            "SCOPE mean: 0.345924631811581, SCOPE var: 0.01796559593007968\n",
            "Total Loss: 0.24604003441153405\n",
            "----------------------------------------\n",
            "Epoch 525\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0138, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.23195526667914584\n",
            "SCOPE mean: 0.34600498198456897, SCOPE var: 0.017958687646347424\n",
            "Total Loss: 0.24571300002339044\n",
            "----------------------------------------\n",
            "Epoch 526\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0138, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.23161243220890276\n",
            "SCOPE mean: 0.3461578377423149, SCOPE var: 0.017964609680758938\n",
            "Total Loss: 0.24536769915559561\n",
            "----------------------------------------\n",
            "Epoch 527\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0137, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.23128825425345642\n",
            "SCOPE mean: 0.3462894026283486, SCOPE var: 0.01796670554076832\n",
            "Total Loss: 0.24503579395594266\n",
            "----------------------------------------\n",
            "Epoch 528\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0137, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.23100764659601847\n",
            "SCOPE mean: 0.34642263234145204, SCOPE var: 0.017964713569861818\n",
            "Total Loss: 0.2447018286654655\n",
            "----------------------------------------\n",
            "Epoch 529\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0137, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2306575054354504\n",
            "SCOPE mean: 0.34660419670687354, SCOPE var: 0.017972892311994695\n",
            "Total Loss: 0.24437716682971788\n",
            "----------------------------------------\n",
            "Epoch 530\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0137, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2303555365147509\n",
            "SCOPE mean: 0.3467787037074598, SCOPE var: 0.017976243598680282\n",
            "Total Loss: 0.24405229643870377\n",
            "----------------------------------------\n",
            "Epoch 531\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0137, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.23007186972915933\n",
            "SCOPE mean: 0.34691853879229506, SCOPE var: 0.017975771498809082\n",
            "Total Loss: 0.2437261245403513\n",
            "----------------------------------------\n",
            "Epoch 532\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0136, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.22980445526428553\n",
            "SCOPE mean: 0.3470251231727228, SCOPE var: 0.017971924119064002\n",
            "Total Loss: 0.24339898703075893\n",
            "----------------------------------------\n",
            "Epoch 533\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0135, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.22954645684706346\n",
            "SCOPE mean: 0.34709467025946705, SCOPE var: 0.017965258543046463\n",
            "Total Loss: 0.24308703546449367\n",
            "----------------------------------------\n",
            "Epoch 534\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0135, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2292178024235134\n",
            "SCOPE mean: 0.3472035210436693, SCOPE var: 0.017969596666518355\n",
            "Total Loss: 0.24276121697546185\n",
            "----------------------------------------\n",
            "Epoch 535\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0136, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2288210530420814\n",
            "SCOPE mean: 0.3473365821535096, SCOPE var: 0.017984062715839595\n",
            "Total Loss: 0.24245213185009235\n",
            "----------------------------------------\n",
            "Epoch 536\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0137, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.22846095131433108\n",
            "SCOPE mean: 0.34745403406707226, SCOPE var: 0.017995088458726244\n",
            "Total Loss: 0.2421403288927842\n",
            "----------------------------------------\n",
            "Epoch 537\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0137, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2281374895690874\n",
            "SCOPE mean: 0.3475683115224957, SCOPE var: 0.0180026204096253\n",
            "Total Loss: 0.24182607048474147\n",
            "----------------------------------------\n",
            "Epoch 538\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0137, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.22785202157623827\n",
            "SCOPE mean: 0.347673899304328, SCOPE var: 0.018006338353332537\n",
            "Total Loss: 0.24150626448632403\n",
            "----------------------------------------\n",
            "Epoch 539\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0136, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.22760257623101462\n",
            "SCOPE mean: 0.3477688167943791, SCOPE var: 0.018006726094119158\n",
            "Total Loss: 0.2411864842826069\n",
            "----------------------------------------\n",
            "Epoch 540\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0135, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.22736374053222327\n",
            "SCOPE mean: 0.34782793464402756, SCOPE var: 0.01800489058966985\n",
            "Total Loss: 0.24087549816012652\n",
            "----------------------------------------\n",
            "Epoch 541\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0134, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2271273639444855\n",
            "SCOPE mean: 0.3478495286224876, SCOPE var: 0.018001128240703334\n",
            "Total Loss: 0.2405636703020717\n",
            "----------------------------------------\n",
            "Epoch 542\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0134, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2268915516840267\n",
            "SCOPE mean: 0.34784802977407725, SCOPE var: 0.017995830174422467\n",
            "Total Loss: 0.24025297777475046\n",
            "----------------------------------------\n",
            "Epoch 543\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0133, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.22665531406649458\n",
            "SCOPE mean: 0.34782947079484194, SCOPE var: 0.017989379060716078\n",
            "Total Loss: 0.2399431242313875\n",
            "----------------------------------------\n",
            "Epoch 544\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0132, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2264109834531988\n",
            "SCOPE mean: 0.3478012360320703, SCOPE var: 0.017982642931879973\n",
            "Total Loss: 0.239642658426802\n",
            "----------------------------------------\n",
            "Epoch 545\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0133, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2260719880972439\n",
            "SCOPE mean: 0.3478370927972389, SCOPE var: 0.017989292420510814\n",
            "Total Loss: 0.23932763117598926\n",
            "----------------------------------------\n",
            "Epoch 546\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0133, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.22574176293279377\n",
            "SCOPE mean: 0.3478561090910308, SCOPE var: 0.017994038646010544\n",
            "Total Loss: 0.23902417708270984\n",
            "----------------------------------------\n",
            "Epoch 547\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0133, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.22542091454133312\n",
            "SCOPE mean: 0.34786096444377756, SCOPE var: 0.017997007243163\n",
            "Total Loss: 0.23872476619974514\n",
            "----------------------------------------\n",
            "Epoch 548\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0133, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2251354641197029\n",
            "SCOPE mean: 0.3478705391611229, SCOPE var: 0.01799785685036444\n",
            "Total Loss: 0.23842744069726213\n",
            "----------------------------------------\n",
            "Epoch 549\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0133, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.22487719684184654\n",
            "SCOPE mean: 0.3478881068295908, SCOPE var: 0.01799666481688334\n",
            "Total Loss: 0.23812996999554498\n",
            "----------------------------------------\n",
            "Epoch 550\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0132, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.22464667594689278\n",
            "SCOPE mean: 0.3479238186524111, SCOPE var: 0.01799398425093937\n",
            "Total Loss: 0.23783495661059073\n",
            "----------------------------------------\n",
            "Epoch 551\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0131, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2244160290729303\n",
            "SCOPE mean: 0.34794816028449665, SCOPE var: 0.01799086572104518\n",
            "Total Loss: 0.23754542808684678\n",
            "----------------------------------------\n",
            "Epoch 552\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0131, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2241811436447279\n",
            "SCOPE mean: 0.34796395900957505, SCOPE var: 0.017987478237231312\n",
            "Total Loss: 0.23726516256243171\n",
            "----------------------------------------\n",
            "Epoch 553\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0131, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.22384673165405328\n",
            "SCOPE mean: 0.34805115670059156, SCOPE var: 0.01799830564625534\n",
            "Total Loss: 0.23697308057463695\n",
            "----------------------------------------\n",
            "Epoch 554\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0132, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.22351469164691226\n",
            "SCOPE mean: 0.34812930796901725, SCOPE var: 0.018008119292223065\n",
            "Total Loss: 0.23668976819589305\n",
            "----------------------------------------\n",
            "Epoch 555\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0132, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.223191395465486\n",
            "SCOPE mean: 0.3481925925163953, SCOPE var: 0.018016866071396527\n",
            "Total Loss: 0.2364133506761812\n",
            "----------------------------------------\n",
            "Epoch 556\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0132, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.222896474090603\n",
            "SCOPE mean: 0.34827010527803987, SCOPE var: 0.01802359573605709\n",
            "Total Loss: 0.23613331744445315\n",
            "----------------------------------------\n",
            "Epoch 557\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0132, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.222627931675926\n",
            "SCOPE mean: 0.34835825506178464, SCOPE var: 0.01802829864694467\n",
            "Total Loss: 0.23585580029016132\n",
            "----------------------------------------\n",
            "Epoch 558\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0132, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.22236329073958194\n",
            "SCOPE mean: 0.34841147570037595, SCOPE var: 0.018031837046843493\n",
            "Total Loss: 0.23557705319759514\n",
            "----------------------------------------\n",
            "Epoch 559\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0132, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.22209893585964427\n",
            "SCOPE mean: 0.3484347302483569, SCOPE var: 0.018034168188088038\n",
            "Total Loss: 0.23529327558253532\n",
            "----------------------------------------\n",
            "Epoch 560\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0132, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.22183599809924537\n",
            "SCOPE mean: 0.3484373390615431, SCOPE var: 0.018035373421394132\n",
            "Total Loss: 0.23501604791205918\n",
            "----------------------------------------\n",
            "Epoch 561\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0131, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2215981228926049\n",
            "SCOPE mean: 0.34844382273864066, SCOPE var: 0.018034676639477453\n",
            "Total Loss: 0.23473640803421492\n",
            "----------------------------------------\n",
            "Epoch 562\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0131, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.22136137778365025\n",
            "SCOPE mean: 0.34843171595986605, SCOPE var: 0.018033036605521927\n",
            "Total Loss: 0.23445877589694458\n",
            "----------------------------------------\n",
            "Epoch 563\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0131, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.22112693416858062\n",
            "SCOPE mean: 0.34840606743422997, SCOPE var: 0.01803063068435283\n",
            "Total Loss: 0.23418347519028068\n",
            "----------------------------------------\n",
            "Epoch 564\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0130, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.22092310661784537\n",
            "SCOPE mean: 0.348389771089228, SCOPE var: 0.018026817288640386\n",
            "Total Loss: 0.23391114152840856\n",
            "----------------------------------------\n",
            "Epoch 565\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0129, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.22071768643858655\n",
            "SCOPE mean: 0.3483621172883935, SCOPE var: 0.0180224675818704\n",
            "Total Loss: 0.2336406492001585\n",
            "----------------------------------------\n",
            "Epoch 566\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0129, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.22050791857310645\n",
            "SCOPE mean: 0.3483218143427772, SCOPE var: 0.018017830523485576\n",
            "Total Loss: 0.2333705344978483\n",
            "----------------------------------------\n",
            "Epoch 567\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0128, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.22029235770657699\n",
            "SCOPE mean: 0.34826425028325714, SCOPE var: 0.018013273721590877\n",
            "Total Loss: 0.2331010446774841\n",
            "----------------------------------------\n",
            "Epoch 568\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0127, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.22009425176634276\n",
            "SCOPE mean: 0.3482214527250108, SCOPE var: 0.018008451987962176\n",
            "Total Loss: 0.23283242155158596\n",
            "----------------------------------------\n",
            "Epoch 569\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0127, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.21991185039775477\n",
            "SCOPE mean: 0.3481937413644573, SCOPE var: 0.018003736558613877\n",
            "Total Loss: 0.23256642029380786\n",
            "----------------------------------------\n",
            "Epoch 570\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0126, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.21971695675097297\n",
            "SCOPE mean: 0.34815317901540643, SCOPE var: 0.017999944241980866\n",
            "Total Loss: 0.23230044367968047\n",
            "----------------------------------------\n",
            "Epoch 571\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0125, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.21950473716785587\n",
            "SCOPE mean: 0.3480827245840592, SCOPE var: 0.01799705790019316\n",
            "Total Loss: 0.23204216542696926\n",
            "----------------------------------------\n",
            "Epoch 572\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0126, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2191918065144209\n",
            "SCOPE mean: 0.3480621718111407, SCOPE var: 0.01800890076606007\n",
            "Total Loss: 0.23175985854723521\n",
            "----------------------------------------\n",
            "Epoch 573\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0126, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.21890379115615186\n",
            "SCOPE mean: 0.3480446736284644, SCOPE var: 0.018019641060053115\n",
            "Total Loss: 0.2314946753958063\n",
            "----------------------------------------\n",
            "Epoch 574\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0126, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.21863547895645913\n",
            "SCOPE mean: 0.3480802401395607, SCOPE var: 0.018029927342086288\n",
            "Total Loss: 0.2312292953129957\n",
            "----------------------------------------\n",
            "Epoch 575\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0126, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.21838548097950602\n",
            "SCOPE mean: 0.3481365141229414, SCOPE var: 0.018039104044737134\n",
            "Total Loss: 0.23096674023518116\n",
            "----------------------------------------\n",
            "Epoch 576\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0126, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2181223631918843\n",
            "SCOPE mean: 0.3482004491886021, SCOPE var: 0.018047657150257582\n",
            "Total Loss: 0.2307002472599267\n",
            "----------------------------------------\n",
            "Epoch 577\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0126, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.21785276249309055\n",
            "SCOPE mean: 0.3482838764774917, SCOPE var: 0.018055391869880148\n",
            "Total Loss: 0.23043281693533668\n",
            "----------------------------------------\n",
            "Epoch 578\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0126, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.21758270920095088\n",
            "SCOPE mean: 0.3483820031097207, SCOPE var: 0.018062295181550572\n",
            "Total Loss: 0.23016708664246907\n",
            "----------------------------------------\n",
            "Epoch 579\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0126, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.21731496430515726\n",
            "SCOPE mean: 0.34849037191228416, SCOPE var: 0.01806789985974733\n",
            "Total Loss: 0.22990161340448362\n",
            "----------------------------------------\n",
            "Epoch 580\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0126, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.21705114090222916\n",
            "SCOPE mean: 0.348615737871872, SCOPE var: 0.018072241464264113\n",
            "Total Loss: 0.22963818426029897\n",
            "----------------------------------------\n",
            "Epoch 581\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0126, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2168129433065751\n",
            "SCOPE mean: 0.34877966524259346, SCOPE var: 0.018074588690698265\n",
            "Total Loss: 0.2293732533178796\n",
            "----------------------------------------\n",
            "Epoch 582\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0125, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.21659797273880915\n",
            "SCOPE mean: 0.34898251997795887, SCOPE var: 0.018075216413181543\n",
            "Total Loss: 0.229109153458296\n",
            "----------------------------------------\n",
            "Epoch 583\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0125, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.21638027048222272\n",
            "SCOPE mean: 0.3492002064175269, SCOPE var: 0.018074985610228522\n",
            "Total Loss: 0.22884741768404032\n",
            "----------------------------------------\n",
            "Epoch 584\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0124, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2161553423931218\n",
            "SCOPE mean: 0.34941185491282334, SCOPE var: 0.018074348763300236\n",
            "Total Loss: 0.22858646501355784\n",
            "----------------------------------------\n",
            "Epoch 585\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0124, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.21592245884365396\n",
            "SCOPE mean: 0.3496129869456785, SCOPE var: 0.01807346491651483\n",
            "Total Loss: 0.2283253445893504\n",
            "----------------------------------------\n",
            "Epoch 586\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0124, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.21568114667164623\n",
            "SCOPE mean: 0.3498033639474699, SCOPE var: 0.0180725117390721\n",
            "Total Loss: 0.2280649063294769\n",
            "----------------------------------------\n",
            "Epoch 587\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0124, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.21543615885357895\n",
            "SCOPE mean: 0.3499670404908701, SCOPE var: 0.01807134661832723\n",
            "Total Loss: 0.22780155669062385\n",
            "----------------------------------------\n",
            "Epoch 588\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0124, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.21519116826721618\n",
            "SCOPE mean: 0.3501135964292835, SCOPE var: 0.018070112866392183\n",
            "Total Loss: 0.22754480702437327\n",
            "----------------------------------------\n",
            "Epoch 589\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0123, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.21496972840144432\n",
            "SCOPE mean: 0.3502677029267806, SCOPE var: 0.018068162745282473\n",
            "Total Loss: 0.22729006314524708\n",
            "----------------------------------------\n",
            "Epoch 590\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0123, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.21475981426572394\n",
            "SCOPE mean: 0.3504280725157614, SCOPE var: 0.01806606923380588\n",
            "Total Loss: 0.22703486827282843\n",
            "----------------------------------------\n",
            "Epoch 591\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0122, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.21456423339826297\n",
            "SCOPE mean: 0.3505799510868098, SCOPE var: 0.018064109443461825\n",
            "Total Loss: 0.22678251904728783\n",
            "----------------------------------------\n",
            "Epoch 592\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0122, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.21436069882048842\n",
            "SCOPE mean: 0.35069719459839854, SCOPE var: 0.01806274496962396\n",
            "Total Loss: 0.22653404831024004\n",
            "----------------------------------------\n",
            "Epoch 593\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0121, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.21414395041670703\n",
            "SCOPE mean: 0.35079205361527327, SCOPE var: 0.018062394650581702\n",
            "Total Loss: 0.22628568861842185\n",
            "----------------------------------------\n",
            "Epoch 594\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0121, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.21391715523611962\n",
            "SCOPE mean: 0.35086314598693774, SCOPE var: 0.01806283176698865\n",
            "Total Loss: 0.22603461612337097\n",
            "----------------------------------------\n",
            "Epoch 595\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0121, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.21368074605838203\n",
            "SCOPE mean: 0.3509132260200181, SCOPE var: 0.018064078111096202\n",
            "Total Loss: 0.22578266198673655\n",
            "----------------------------------------\n",
            "Epoch 596\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0121, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.21343745791219085\n",
            "SCOPE mean: 0.350942692891805, SCOPE var: 0.018066216234953348\n",
            "Total Loss: 0.22553386380615298\n",
            "----------------------------------------\n",
            "Epoch 597\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0121, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.2132105058743813\n",
            "SCOPE mean: 0.350977916723972, SCOPE var: 0.01806835198663598\n",
            "Total Loss: 0.22528625962404397\n",
            "----------------------------------------\n",
            "Epoch 598\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0120, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.21299592880029491\n",
            "SCOPE mean: 0.3510230115386653, SCOPE var: 0.018070391464874918\n",
            "Total Loss: 0.22503677678875222\n",
            "----------------------------------------\n",
            "Epoch 599\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0120, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.21279483242744218\n",
            "SCOPE mean: 0.3510781821342439, SCOPE var: 0.01807238322924565\n",
            "Total Loss: 0.22478926541672425\n",
            "----------------------------------------\n",
            "Epoch 600\n",
            "IS mean: 0.3143338730512621,IS variance: 0.02523737293606626\n",
            "SCOPE Var loss:  tensor(0.0120, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.21257713048809848\n",
            "SCOPE mean: 0.35112301272967844, SCOPE var: 0.018075442729197373\n",
            "Total Loss: 0.22454395005611427\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[-0.0186, -0.1972],\n",
            "        [-0.3706, -0.3068],\n",
            "        [ 0.1748, -0.0085],\n",
            "        [-0.5364, -0.5308],\n",
            "        [ 0.1937,  0.3166],\n",
            "        [ 0.4137, -0.7268],\n",
            "        [-0.3092, -0.5198],\n",
            "        [-0.7303,  0.4768],\n",
            "        [-0.3738, -0.4623],\n",
            "        [-0.3052, -0.0055],\n",
            "        [ 0.2510,  0.0611],\n",
            "        [-0.7413,  0.4571],\n",
            "        [ 0.1862,  0.1564],\n",
            "        [ 0.1463, -0.0615],\n",
            "        [-0.0362,  0.1971],\n",
            "        [-0.2221, -0.4742]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([-0.0533, -0.3120, -0.5159, -0.5761,  0.2326,  0.3029, -0.2647, -0.4596,\n",
            "        -0.5832, -0.2371, -0.3836, -0.5939, -0.7154,  0.5065,  0.3286, -0.4199],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[-0.1177,  0.0552, -0.1672, -0.1992,  0.1018,  0.1276, -0.1609, -0.0030,\n",
            "         -0.1216,  0.1443, -0.2615,  0.1019, -0.0299, -0.0458, -0.1883, -0.0437],\n",
            "        [ 0.1405,  0.0375, -0.1717, -0.0944, -0.1968, -0.1396,  0.0098, -0.0300,\n",
            "         -0.0414, -0.0584, -0.0884, -0.0543,  0.1135, -0.1216, -0.0309, -0.1156],\n",
            "        [-0.1156, -0.2106, -0.3689, -0.1215, -0.0653, -0.0888,  0.1165,  0.0686,\n",
            "          0.0276,  0.0368, -0.1880, -0.1053, -0.0642,  0.0636, -0.0068,  0.0711],\n",
            "        [ 0.0458,  0.2251,  0.1609, -0.0038,  0.0175,  0.1732, -0.0106,  0.0207,\n",
            "         -0.0628, -0.0223, -0.3637, -0.0836, -0.3271,  0.2186, -0.0571, -0.1720],\n",
            "        [-0.0031, -0.2483,  0.0962,  0.1643,  0.0628, -0.0398,  0.0911, -0.0761,\n",
            "          0.1842, -0.2327,  0.1730,  0.0539, -0.0820,  0.0806,  0.1265, -0.2459],\n",
            "        [-0.2132,  0.2441,  0.2022, -0.1061,  0.0706, -0.3034,  0.2160,  0.1323,\n",
            "          0.0179, -0.1739,  0.1372, -0.0817, -0.0527, -0.2854,  0.1469, -0.0475],\n",
            "        [ 0.2275, -0.1066, -0.1382,  0.1472,  0.1121, -0.1258, -0.1157,  0.0153,\n",
            "          0.0511,  0.2034, -0.2627,  0.0484, -0.2641, -0.1636,  0.1297,  0.2126],\n",
            "        [ 0.0831,  0.1702, -0.1354,  0.2022, -0.0507, -0.0041,  0.1440,  0.0303,\n",
            "         -0.0738,  0.0414,  0.0380, -0.0642, -0.2322,  0.0051, -0.1282, -0.2164],\n",
            "        [ 0.2111, -0.0143, -0.0276,  0.0009, -0.2137, -0.0249, -0.0071, -0.1676,\n",
            "         -0.1809,  0.2044,  0.0743, -0.1565,  0.0474,  0.1140, -0.3340, -0.0017],\n",
            "        [ 0.1093, -0.1100,  0.2690, -0.1925,  0.0589,  0.2392,  0.0990, -0.0957,\n",
            "          0.0691,  0.2447, -0.0074,  0.0968, -0.1270, -0.0343,  0.1376,  0.0439],\n",
            "        [-0.1150, -0.0344, -0.1975,  0.0541, -0.0655,  0.0171,  0.0160,  0.0294,\n",
            "         -0.0168,  0.2171, -0.3093,  0.0759, -0.2518,  0.0390,  0.0826,  0.1476],\n",
            "        [ 0.0539, -0.2007,  0.0456, -0.2019,  0.1571,  0.0785,  0.2311,  0.0448,\n",
            "          0.0942, -0.1031,  0.2040, -0.0416, -0.0043, -0.0945,  0.0296, -0.2097],\n",
            "        [ 0.0199,  0.1871,  0.0525,  0.2301, -0.0229,  0.1071,  0.0172, -0.1114,\n",
            "         -0.2080, -0.2113, -0.0565,  0.0293, -0.2827, -0.0222,  0.0454,  0.1663],\n",
            "        [ 0.0864,  0.1208,  0.0473, -0.1497, -0.0849, -0.2711,  0.1436, -0.0348,\n",
            "          0.1342,  0.1814,  0.0046, -0.1650, -0.2592, -0.0292,  0.0287,  0.0246],\n",
            "        [ 0.0765,  0.0677,  0.3223, -0.0259,  0.1124,  0.0772,  0.2338,  0.0156,\n",
            "          0.0088, -0.0649, -0.1420, -0.2096, -0.2015,  0.1168, -0.0365,  0.0133],\n",
            "        [-0.2097,  0.1283,  0.0073, -0.0258,  0.0202,  0.1300,  0.0710,  0.1192,\n",
            "         -0.1164, -0.1588, -0.0228, -0.1086,  0.2661, -0.0587, -0.2606, -0.0748]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([ 0.2178, -0.1365,  0.4032, -0.1828, -0.3732, -0.1247,  0.0875,  0.3972,\n",
            "        -0.1219,  0.1004,  0.1270,  0.1428,  0.2406, -0.0228,  0.0576,  0.1143],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[ 0.1399, -0.2177,  0.2024, -0.3494, -0.2599, -0.0202,  0.0840,  0.2883,\n",
            "         -0.1905,  0.0722,  0.1177, -0.0067,  0.2324, -0.1799,  0.1152, -0.1053]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([0.2837], dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NN_l1_l2_reg(\n",
              "  (hidden_layers): ModuleList(\n",
              "    (0): Linear(in_features=2, out_features=16, bias=True)\n",
              "    (1): Linear(in_features=16, out_features=16, bias=True)\n",
              "  )\n",
              "  (output_layer): Linear(in_features=16, out_features=1, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b_600_mse = action_probs_top_n_epsilon(q_table, 1, 0.4)\n",
        "pi_b_600_mse = experiment_actions(600, env_50, P_pi_b_600_mse)\n",
        "P_pi_e_600 = action_probs_top_n_epsilon(q_table, 1, 0.05)\n",
        "pi_e_600 = experiment_actions(1000, env_50, P_pi_e_600)\n",
        "# model_600_random_pi_b_600_mse = CustomizableFeatureNet(input_dim=2, hidden_dims=[8, 8], output_dim=1, dtype = torch.float64, l2_lambda=0.002)\n",
        "# model_600_random_pi_b_600_mse = NN_l1_reg(input_dim=2, hidden_dims=[16, 16], output_dim=1, dtype = torch.float64, l1_lambda=0.001)\n",
        "model_600_random_pi_b_600_mse = NN_l1_l2_reg(input_dim=2, hidden_dims=[16, 16], output_dim=1, dtype = torch.float64, l1_lambda=0.0001, l2_lambda = 0.0001)\n",
        "test_600_random_pi_b_600_mse = SCOPE_straight(model_600_random_pi_b_600_mse, 0.99, 10000, pi_b_600_mse, P_pi_b_600_mse, P_pi_e_600, 0.3, dtype = torch.float64)\n",
        "test_600_random_pi_b_600_mse.train_var_scope(200, 0.001, 1, 0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bea8645c-4250-4dc9-e2b2-f2db6e425119",
        "id": "Wae2fO3hGL29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(1.3600, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  16.85394573179525\n",
            "SCOPE mean: 1.233982608018241, SCOPE var: 0.1606939214573137\n",
            "Total Loss: 9.786936898906507\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(4.2376, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  16.160336248059092\n",
            "SCOPE mean: 1.2210136292921026, SCOPE var: 0.16082977309307356\n",
            "Total Loss: 12.317754979410687\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(4.2058, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  15.502035759824468\n",
            "SCOPE mean: 1.2070742898746634, SCOPE var: 0.16067468243348831\n",
            "Total Loss: 11.956863218297187\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(4.1569, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.877664108015582\n",
            "SCOPE mean: 1.1919518832949292, SCOPE var: 0.16023983518091042\n",
            "Total Loss: 11.595696072663614\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(4.0988, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.27723028604411\n",
            "SCOPE mean: 1.176742680072008, SCOPE var: 0.1596986214686087\n",
            "Total Loss: 11.237378404812446\n",
            "----------------------------------------\n",
            "Epoch 6\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(4.0373, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.701419813246293\n",
            "SCOPE mean: 1.1613171566958351, SCOPE var: 0.1590744784357451\n",
            "Total Loss: 10.88801691987226\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(3.9727, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.14852609062592\n",
            "SCOPE mean: 1.1456536600372045, SCOPE var: 0.15838546568225742\n",
            "Total Loss: 10.546953308516821\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(3.9060, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.615822906084976\n",
            "SCOPE mean: 1.1298103974697755, SCOPE var: 0.1576323628225401\n",
            "Total Loss: 10.213948774429088\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(3.8367, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.103027804033385\n",
            "SCOPE mean: 1.1137341243327232, SCOPE var: 0.15681694234386578\n",
            "Total Loss: 9.888167626095251\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(3.7670, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.609738124983146\n",
            "SCOPE mean: 1.0976031882232384, SCOPE var: 0.15596589360906213\n",
            "Total Loss: 9.571898411481897\n",
            "----------------------------------------\n",
            "Epoch 11\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(3.6959, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.134044727908423\n",
            "SCOPE mean: 1.0824730341559414, SCOPE var: 0.155094533429075\n",
            "Total Loss: 9.262957984121856\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(3.6245, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.6802155246526\n",
            "SCOPE mean: 1.068404607529904, SCOPE var: 0.15421253109333197\n",
            "Total Loss: 8.964586918701439\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(3.5546, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.249275854322077\n",
            "SCOPE mean: 1.0543151275012874, SCOPE var: 0.15332299823611126\n",
            "Total Loss: 8.679211981141211\n",
            "----------------------------------------\n",
            "Epoch 14\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(3.4861, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.84082582392018\n",
            "SCOPE mean: 1.0402901431310603, SCOPE var: 0.15241260985238841\n",
            "Total Loss: 8.406476370742217\n",
            "----------------------------------------\n",
            "Epoch 15\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(3.4177, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.453669347214522\n",
            "SCOPE mean: 1.026203080074541, SCOPE var: 0.15146338839506057\n",
            "Total Loss: 8.144518049356709\n",
            "----------------------------------------\n",
            "Epoch 16\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(3.3447, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.086029290488506\n",
            "SCOPE mean: 1.0120158603300162, SCOPE var: 0.15050856132362542\n",
            "Total Loss: 7.887669463891577\n",
            "----------------------------------------\n",
            "Epoch 17\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(3.2718, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.736968051856337\n",
            "SCOPE mean: 0.9977435789536767, SCOPE var: 0.14954688235152952\n",
            "Total Loss: 7.640310428449196\n",
            "----------------------------------------\n",
            "Epoch 18\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(3.1981, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.407115250655634\n",
            "SCOPE mean: 0.9828969843258965, SCOPE var: 0.14837966424810323\n",
            "Total Loss: 7.401689126073851\n",
            "----------------------------------------\n",
            "Epoch 19\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(3.1241, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.095728074334751\n",
            "SCOPE mean: 0.968143648945875, SCOPE var: 0.14721206879827425\n",
            "Total Loss: 7.171986743104318\n",
            "----------------------------------------\n",
            "Epoch 20\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(3.0506, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.802047162559123\n",
            "SCOPE mean: 0.9535422715768913, SCOPE var: 0.1460247176871215\n",
            "Total Loss: 6.951594870784249\n",
            "----------------------------------------\n",
            "Epoch 21\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(2.9781, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.525998493373461\n",
            "SCOPE mean: 0.9392247732708161, SCOPE var: 0.14481762354800778\n",
            "Total Loss: 6.741094244914297\n",
            "----------------------------------------\n",
            "Epoch 22\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(2.9072, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.267453062468793\n",
            "SCOPE mean: 0.9250559348794408, SCOPE var: 0.14361533900772827\n",
            "Total Loss: 6.54087887353448\n",
            "----------------------------------------\n",
            "Epoch 23\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(2.8374, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.023075872776455\n",
            "SCOPE mean: 0.9110490475875848, SCOPE var: 0.14242061485204724\n",
            "Total Loss: 6.348917251746595\n",
            "----------------------------------------\n",
            "Epoch 24\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(2.7684, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.794097522343706\n",
            "SCOPE mean: 0.8972788946654869, SCOPE var: 0.14124066571552016\n",
            "Total Loss: 6.165430371919015\n",
            "----------------------------------------\n",
            "Epoch 25\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(2.6996, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.580019082468718\n",
            "SCOPE mean: 0.8837985092026278, SCOPE var: 0.1400812913031526\n",
            "Total Loss: 5.989581201314717\n",
            "----------------------------------------\n",
            "Epoch 26\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(2.6311, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.380196373054374\n",
            "SCOPE mean: 0.8705279741561355, SCOPE var: 0.13893296610796801\n",
            "Total Loss: 5.8211665971538\n",
            "----------------------------------------\n",
            "Epoch 27\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(2.5621, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.193554308199383\n",
            "SCOPE mean: 0.857474264634059, SCOPE var: 0.13778025220385376\n",
            "Total Loss: 5.658851902158607\n",
            "----------------------------------------\n",
            "Epoch 28\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(2.4935, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.020735502472887\n",
            "SCOPE mean: 0.8446031617943852, SCOPE var: 0.13662694762473454\n",
            "Total Loss: 5.503845938197607\n",
            "----------------------------------------\n",
            "Epoch 29\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(2.4255, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.8595123537813025\n",
            "SCOPE mean: 0.8319883570325761, SCOPE var: 0.13547736535768157\n",
            "Total Loss: 5.355303313274911\n",
            "----------------------------------------\n",
            "Epoch 30\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(2.3578, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.710703525383153\n",
            "SCOPE mean: 0.8194573197829265, SCOPE var: 0.13433035299522242\n",
            "Total Loss: 5.213150955785662\n",
            "----------------------------------------\n",
            "Epoch 31\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(2.2872, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.5729250050975505\n",
            "SCOPE mean: 0.8044681188879192, SCOPE var: 0.1331945644083154\n",
            "Total Loss: 5.073640863082245\n",
            "----------------------------------------\n",
            "Epoch 32\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(2.2089, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.446974403613673\n",
            "SCOPE mean: 0.7894878700894779, SCOPE var: 0.13199803608072092\n",
            "Total Loss: 4.932401186712223\n",
            "----------------------------------------\n",
            "Epoch 33\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(2.1239, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.3341981440980435\n",
            "SCOPE mean: 0.7758965146665427, SCOPE var: 0.13085356204262275\n",
            "Total Loss: 4.790961708711828\n",
            "----------------------------------------\n",
            "Epoch 34\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(2.0406, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.231477492130763\n",
            "SCOPE mean: 0.7627459276301766, SCOPE var: 0.12971401109339709\n",
            "Total Loss: 4.65634629534272\n",
            "----------------------------------------\n",
            "Epoch 35\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(1.9570, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.1395596409850475\n",
            "SCOPE mean: 0.7498677871816173, SCOPE var: 0.12860961236621116\n",
            "Total Loss: 4.5267777726883\n",
            "----------------------------------------\n",
            "Epoch 36\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(1.8741, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.057644808686267\n",
            "SCOPE mean: 0.737220833223597, SCOPE var: 0.12751456714990458\n",
            "Total Loss: 4.402902402431734\n",
            "----------------------------------------\n",
            "Epoch 37\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(1.7971, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.984680108679904\n",
            "SCOPE mean: 0.724777852994982, SCOPE var: 0.1264181937096155\n",
            "Total Loss: 4.289403666108217\n",
            "----------------------------------------\n",
            "Epoch 38\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(1.7344, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.920387623294731\n",
            "SCOPE mean: 0.7127540078102301, SCOPE var: 0.12534750736992897\n",
            "Total Loss: 4.194547187677532\n",
            "----------------------------------------\n",
            "Epoch 39\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(1.6726, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.864593710510829\n",
            "SCOPE mean: 0.701185167269765, SCOPE var: 0.12430778146369295\n",
            "Total Loss: 4.104875813335865\n",
            "----------------------------------------\n",
            "Epoch 40\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(1.6107, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.815827617154858\n",
            "SCOPE mean: 0.6900902782522429, SCOPE var: 0.1232980620044777\n",
            "Total Loss: 4.018579047504679\n",
            "----------------------------------------\n",
            "Epoch 41\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(1.5491, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.775159830514775\n",
            "SCOPE mean: 0.6795310942122395, SCOPE var: 0.12232030115489002\n",
            "Total Loss: 3.9366316975695863\n",
            "----------------------------------------\n",
            "Epoch 42\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(1.4886, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.74209354279719\n",
            "SCOPE mean: 0.6652434635585772, SCOPE var: 0.12138131626466891\n",
            "Total Loss: 3.8596179214587742\n",
            "----------------------------------------\n",
            "Epoch 43\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(1.4303, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.7139415098684045\n",
            "SCOPE mean: 0.6508813452136455, SCOPE var: 0.12047477479624619\n",
            "Total Loss: 3.7872626813130537\n",
            "----------------------------------------\n",
            "Epoch 44\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(1.3743, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.690419955488901\n",
            "SCOPE mean: 0.6369904825787078, SCOPE var: 0.11958282623312998\n",
            "Total Loss: 3.7194657439244043\n",
            "----------------------------------------\n",
            "Epoch 45\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(1.3191, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.6700950019174545\n",
            "SCOPE mean: 0.6236760545770836, SCOPE var: 0.1186991916665528\n",
            "Total Loss: 3.654144971815502\n",
            "----------------------------------------\n",
            "Epoch 46\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(1.2616, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.65200591118741\n",
            "SCOPE mean: 0.6109925307551771, SCOPE var: 0.11782293087135685\n",
            "Total Loss: 3.587631850258143\n",
            "----------------------------------------\n",
            "Epoch 47\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(1.2047, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.635120011573649\n",
            "SCOPE mean: 0.5989775633664025, SCOPE var: 0.11696063155629073\n",
            "Total Loss: 3.522276729353793\n",
            "----------------------------------------\n",
            "Epoch 48\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(1.1498, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.619784802256536\n",
            "SCOPE mean: 0.5876500476275798, SCOPE var: 0.11611356855476086\n",
            "Total Loss: 3.459682801769433\n",
            "----------------------------------------\n",
            "Epoch 49\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(1.0966, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.605813354576967\n",
            "SCOPE mean: 0.5772304124774882, SCOPE var: 0.11522283870318428\n",
            "Total Loss: 3.399551933072054\n",
            "----------------------------------------\n",
            "Epoch 50\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(1.0458, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.593159978686156\n",
            "SCOPE mean: 0.567712223987565, SCOPE var: 0.11435200575852596\n",
            "Total Loss: 3.3423323286020947\n",
            "----------------------------------------\n",
            "Epoch 51\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.9979, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.580571488039271\n",
            "SCOPE mean: 0.5593085257061684, SCOPE var: 0.11350954230541725\n",
            "Total Loss: 3.288192601951819\n",
            "----------------------------------------\n",
            "Epoch 52\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.9512, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.567930364579668\n",
            "SCOPE mean: 0.551897822456411, SCOPE var: 0.11270227461341746\n",
            "Total Loss: 3.235180464187118\n",
            "----------------------------------------\n",
            "Epoch 53\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.9058, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.5545448874793095\n",
            "SCOPE mean: 0.5451704597242729, SCOPE var: 0.11178071594311528\n",
            "Total Loss: 3.1830283449451895\n",
            "----------------------------------------\n",
            "Epoch 54\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.8634, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.540233588449871\n",
            "SCOPE mean: 0.5393279163819152, SCOPE var: 0.1108505934164615\n",
            "Total Loss: 3.1335666186207063\n",
            "----------------------------------------\n",
            "Epoch 55\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.8225, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.525166484450138\n",
            "SCOPE mean: 0.5347640077234703, SCOPE var: 0.11005877496412253\n",
            "Total Loss: 3.0851133118688\n",
            "----------------------------------------\n",
            "Epoch 56\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.7823, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.509469564834307\n",
            "SCOPE mean: 0.5314905138746157, SCOPE var: 0.1093974929685836\n",
            "Total Loss: 3.0370440339841434\n",
            "----------------------------------------\n",
            "Epoch 57\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.7428, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.493482344963086\n",
            "SCOPE mean: 0.5293372690812693, SCOPE var: 0.10884322448953727\n",
            "Total Loss: 2.9895238389869863\n",
            "----------------------------------------\n",
            "Epoch 58\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.7048, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.477161876859736\n",
            "SCOPE mean: 0.5280118792286194, SCOPE var: 0.1083314821171101\n",
            "Total Loss: 2.9434058255557294\n",
            "----------------------------------------\n",
            "Epoch 59\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.6682, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.460646464441753\n",
            "SCOPE mean: 0.5275335453992122, SCOPE var: 0.10789634626304323\n",
            "Total Loss: 2.8985484448402907\n",
            "----------------------------------------\n",
            "Epoch 60\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.6327, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.443953084913597\n",
            "SCOPE mean: 0.528000952059569, SCOPE var: 0.10756833637438264\n",
            "Total Loss: 2.8547019063711363\n",
            "----------------------------------------\n",
            "Epoch 61\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.5991, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.427154257489177\n",
            "SCOPE mean: 0.5291961374337234, SCOPE var: 0.10731109636646764\n",
            "Total Loss: 2.8126474017035354\n",
            "----------------------------------------\n",
            "Epoch 62\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.5685, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.410156980988923\n",
            "SCOPE mean: 0.5306878822025576, SCOPE var: 0.10705893714748052\n",
            "Total Loss: 2.7735876824876526\n",
            "----------------------------------------\n",
            "Epoch 63\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.5396, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.392957368778487\n",
            "SCOPE mean: 0.5323963976667125, SCOPE var: 0.10680667408141901\n",
            "Total Loss: 2.736049456375132\n",
            "----------------------------------------\n",
            "Epoch 64\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.5123, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.375601564981568\n",
            "SCOPE mean: 0.5343644460163947, SCOPE var: 0.10656540101095112\n",
            "Total Loss: 2.7001488360382986\n",
            "----------------------------------------\n",
            "Epoch 65\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.4868, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.357611253761767\n",
            "SCOPE mean: 0.5365561910942516, SCOPE var: 0.10631619573509107\n",
            "Total Loss: 2.665598760817887\n",
            "----------------------------------------\n",
            "Epoch 66\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.4630, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.338886434974089\n",
            "SCOPE mean: 0.538978195590667, SCOPE var: 0.10610705137236075\n",
            "Total Loss: 2.6324282173683247\n",
            "----------------------------------------\n",
            "Epoch 67\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.4409, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.319476019586771\n",
            "SCOPE mean: 0.5415260412109528, SCOPE var: 0.10592671398012674\n",
            "Total Loss: 2.6006157005582557\n",
            "----------------------------------------\n",
            "Epoch 68\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.4203, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.299454078711362\n",
            "SCOPE mean: 0.5441071174489159, SCOPE var: 0.10576016071575142\n",
            "Total Loss: 2.570022006004996\n",
            "----------------------------------------\n",
            "Epoch 69\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.4009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.278147707083103\n",
            "SCOPE mean: 0.5466006899637614, SCOPE var: 0.10560146013337342\n",
            "Total Loss: 2.5399783704573924\n",
            "----------------------------------------\n",
            "Epoch 70\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.3829, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.255898129261843\n",
            "SCOPE mean: 0.5490170155248464, SCOPE var: 0.10545301121738011\n",
            "Total Loss: 2.510878137965152\n",
            "----------------------------------------\n",
            "Epoch 71\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.3664, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.232571829200604\n",
            "SCOPE mean: 0.5513884129734461, SCOPE var: 0.10530420000171956\n",
            "Total Loss: 2.4826529017134775\n",
            "----------------------------------------\n",
            "Epoch 72\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.3509, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.208162366235426\n",
            "SCOPE mean: 0.5537251037509491, SCOPE var: 0.10512288841320919\n",
            "Total Loss: 2.454950849752015\n",
            "----------------------------------------\n",
            "Epoch 73\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.3367, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.182544528111975\n",
            "SCOPE mean: 0.5576487708243999, SCOPE var: 0.10533032953507442\n",
            "Total Loss: 2.4279272204549818\n",
            "----------------------------------------\n",
            "Epoch 74\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.3236, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.155631504328613\n",
            "SCOPE mean: 0.5620707742647014, SCOPE var: 0.1056725333990722\n",
            "Total Loss: 2.401432276879262\n",
            "----------------------------------------\n",
            "Epoch 75\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.3124, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.127280917609962\n",
            "SCOPE mean: 0.5667221102978908, SCOPE var: 0.10608439660236689\n",
            "Total Loss: 2.3760618504158986\n",
            "----------------------------------------\n",
            "Epoch 76\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.3023, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.098051411444235\n",
            "SCOPE mean: 0.5712439362246522, SCOPE var: 0.1064682950866704\n",
            "Total Loss: 2.351278963780773\n",
            "----------------------------------------\n",
            "Epoch 77\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.2928, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.067907785599\n",
            "SCOPE mean: 0.5756788705593452, SCOPE var: 0.10682595716628857\n",
            "Total Loss: 2.3267179977586583\n",
            "----------------------------------------\n",
            "Epoch 78\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.2839, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.036817007232071\n",
            "SCOPE mean: 0.5800536547188765, SCOPE var: 0.10716305394551608\n",
            "Total Loss: 2.302338101409902\n",
            "----------------------------------------\n",
            "Epoch 79\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.2758, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.0045433489025895\n",
            "SCOPE mean: 0.5844081151830557, SCOPE var: 0.10747668418068881\n",
            "Total Loss: 2.2780684074161197\n",
            "----------------------------------------\n",
            "Epoch 80\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.2693, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.971314344233201\n",
            "SCOPE mean: 0.588846876571617, SCOPE var: 0.10779696657426943\n",
            "Total Loss: 2.2549928844071134\n",
            "----------------------------------------\n",
            "Epoch 81\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.2628, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.9381526338899366\n",
            "SCOPE mean: 0.593361930128067, SCOPE var: 0.10813225645298867\n",
            "Total Loss: 2.231869914473247\n",
            "----------------------------------------\n",
            "Epoch 82\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.2558, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.9053614499700897\n",
            "SCOPE mean: 0.5979051442341843, SCOPE var: 0.10846464885876095\n",
            "Total Loss: 2.208522838983057\n",
            "----------------------------------------\n",
            "Epoch 83\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.2488, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.8724907958617614\n",
            "SCOPE mean: 0.6025204588768432, SCOPE var: 0.10880641082055534\n",
            "Total Loss: 2.1850405948795584\n",
            "----------------------------------------\n",
            "Epoch 84\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.2427, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.839742031642701\n",
            "SCOPE mean: 0.6071743919494507, SCOPE var: 0.10915293090188641\n",
            "Total Loss: 2.162536984771682\n",
            "----------------------------------------\n",
            "Epoch 85\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.2376, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.806304822142616\n",
            "SCOPE mean: 0.61186862135552, SCOPE var: 0.10950666810791174\n",
            "Total Loss: 2.140782692924564\n",
            "----------------------------------------\n",
            "Epoch 86\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.2331, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.7720263432142924\n",
            "SCOPE mean: 0.6166270099661717, SCOPE var: 0.10986397806659086\n",
            "Total Loss: 2.1190927849348027\n",
            "----------------------------------------\n",
            "Epoch 87\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.2289, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.737389787424152\n",
            "SCOPE mean: 0.6214482019378127, SCOPE var: 0.11022820751310877\n",
            "Total Loss: 2.0976021294808227\n",
            "----------------------------------------\n",
            "Epoch 88\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.2250, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.703009053246448\n",
            "SCOPE mean: 0.626317611443573, SCOPE var: 0.11060228368738825\n",
            "Total Loss: 2.0765307322842412\n",
            "----------------------------------------\n",
            "Epoch 89\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.2214, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.668180086087759\n",
            "SCOPE mean: 0.6312801400440274, SCOPE var: 0.11098306549323775\n",
            "Total Loss: 2.055473360266868\n",
            "----------------------------------------\n",
            "Epoch 90\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.2180, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.6328529810639174\n",
            "SCOPE mean: 0.6363100653533221, SCOPE var: 0.11136572938799633\n",
            "Total Loss: 2.0344654956999175\n",
            "----------------------------------------\n",
            "Epoch 91\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.2148, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.5971985261904846\n",
            "SCOPE mean: 0.6414829013175686, SCOPE var: 0.11176908617863315\n",
            "Total Loss: 2.013432474570916\n",
            "----------------------------------------\n",
            "Epoch 92\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.2113, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.5608029245220227\n",
            "SCOPE mean: 0.6468055624988296, SCOPE var: 0.11219267238488387\n",
            "Total Loss: 1.9917284110771742\n",
            "----------------------------------------\n",
            "Epoch 93\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.2087, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.523799217468351\n",
            "SCOPE mean: 0.6520869824196546, SCOPE var: 0.11261682456037411\n",
            "Total Loss: 1.970598899787511\n",
            "----------------------------------------\n",
            "Epoch 94\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.2060, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.487789403618224\n",
            "SCOPE mean: 0.6573298656467277, SCOPE var: 0.11303639564588214\n",
            "Total Loss: 1.9498590744523223\n",
            "----------------------------------------\n",
            "Epoch 95\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.2024, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.45277627392078\n",
            "SCOPE mean: 0.6625660369690421, SCOPE var: 0.11345375897162654\n",
            "Total Loss: 1.9288178797033686\n",
            "----------------------------------------\n",
            "Epoch 96\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.1983, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.4185678303702245\n",
            "SCOPE mean: 0.6678013959147767, SCOPE var: 0.11386793163551474\n",
            "Total Loss: 1.907552183502898\n",
            "----------------------------------------\n",
            "Epoch 97\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.1949, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.385312180737186\n",
            "SCOPE mean: 0.6730203136574628, SCOPE var: 0.11427531060420577\n",
            "Total Loss: 1.8875085140145855\n",
            "----------------------------------------\n",
            "Epoch 98\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.1917, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.3520459323710363\n",
            "SCOPE mean: 0.6782213466459556, SCOPE var: 0.11467666056565667\n",
            "Total Loss: 1.8677175042523357\n",
            "----------------------------------------\n",
            "Epoch 99\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.1887, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.3189015665839467\n",
            "SCOPE mean: 0.6834152315677116, SCOPE var: 0.11507234799869102\n",
            "Total Loss: 1.8481626453289914\n",
            "----------------------------------------\n",
            "Epoch 100\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.1859, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.286235035433353\n",
            "SCOPE mean: 0.6885983311744382, SCOPE var: 0.11546100232470743\n",
            "Total Loss: 1.8290056401697687\n",
            "----------------------------------------\n",
            "Epoch 101\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.1831, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.2539973924213896\n",
            "SCOPE mean: 0.6938654073003265, SCOPE var: 0.11586642105966043\n",
            "Total Loss: 1.8100912845018324\n",
            "----------------------------------------\n",
            "Epoch 102\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.1802, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.2223140597768496\n",
            "SCOPE mean: 0.699110016772152, SCOPE var: 0.11626209194414905\n",
            "Total Loss: 1.7913773626126466\n",
            "----------------------------------------\n",
            "Epoch 103\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.1774, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.191470518163961\n",
            "SCOPE mean: 0.7042926226057952, SCOPE var: 0.11663924683884855\n",
            "Total Loss: 1.7731735090617675\n",
            "----------------------------------------\n",
            "Epoch 104\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.1750, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.16150939770769\n",
            "SCOPE mean: 0.7094153562562265, SCOPE var: 0.11699943512859579\n",
            "Total Loss: 1.7557990481186447\n",
            "----------------------------------------\n",
            "Epoch 105\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.1723, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.1332861453627276\n",
            "SCOPE mean: 0.7145399260955372, SCOPE var: 0.11735696326299404\n",
            "Total Loss: 1.7389872043665449\n",
            "----------------------------------------\n",
            "Epoch 106\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.1691, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.1065870774867\n",
            "SCOPE mean: 0.7196036941120274, SCOPE var: 0.11769918676568808\n",
            "Total Loss: 1.7223792618004192\n",
            "----------------------------------------\n",
            "Epoch 107\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.1666, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.080517131056877\n",
            "SCOPE mean: 0.7247707460285346, SCOPE var: 0.11806513695555049\n",
            "Total Loss: 1.7068446587149921\n",
            "----------------------------------------\n",
            "Epoch 108\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.1641, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.055217821020147\n",
            "SCOPE mean: 0.7299006803900902, SCOPE var: 0.1184257309976704\n",
            "Total Loss: 1.6917352516468698\n",
            "----------------------------------------\n",
            "Epoch 109\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.1617, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.0308146369193687\n",
            "SCOPE mean: 0.7349689928064879, SCOPE var: 0.1187787216080321\n",
            "Total Loss: 1.6771047347080232\n",
            "----------------------------------------\n",
            "Epoch 110\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.1593, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.0073137251298583\n",
            "SCOPE mean: 0.739969776795314, SCOPE var: 0.11912113238951243\n",
            "Total Loss: 1.6629522983195377\n",
            "----------------------------------------\n",
            "Epoch 111\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.1569, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.9846609920111047\n",
            "SCOPE mean: 0.7448842587008423, SCOPE var: 0.11945268931216048\n",
            "Total Loss: 1.6492260515015507\n",
            "----------------------------------------\n",
            "Epoch 112\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.1545, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.9629322459265617\n",
            "SCOPE mean: 0.7496998033372972, SCOPE var: 0.11977326732910051\n",
            "Total Loss: 1.6359844379110204\n",
            "----------------------------------------\n",
            "Epoch 113\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.1521, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.9419648791300594\n",
            "SCOPE mean: 0.7544102060517227, SCOPE var: 0.1200821507249603\n",
            "Total Loss: 1.6231226455065924\n",
            "----------------------------------------\n",
            "Epoch 114\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.1498, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.921705989854252\n",
            "SCOPE mean: 0.7591306115484117, SCOPE var: 0.12040028163421453\n",
            "Total Loss: 1.6106292631002272\n",
            "----------------------------------------\n",
            "Epoch 115\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.1474, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.902296113940302\n",
            "SCOPE mean: 0.763644816938937, SCOPE var: 0.12069992973288234\n",
            "Total Loss: 1.5985239637194617\n",
            "----------------------------------------\n",
            "Epoch 116\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.1450, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.883361070082654\n",
            "SCOPE mean: 0.7680192281168696, SCOPE var: 0.12098001300807776\n",
            "Total Loss: 1.5866322587675343\n",
            "----------------------------------------\n",
            "Epoch 117\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.1424, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.8641286889031794\n",
            "SCOPE mean: 0.7722567019127161, SCOPE var: 0.12122832995046955\n",
            "Total Loss: 1.574506688669328\n",
            "----------------------------------------\n",
            "Epoch 118\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.1399, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.8447075874046153\n",
            "SCOPE mean: 0.7764594500368799, SCOPE var: 0.12147919832848579\n",
            "Total Loss: 1.5622495878174236\n",
            "----------------------------------------\n",
            "Epoch 119\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.1373, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.8252561720656497\n",
            "SCOPE mean: 0.7805936006054953, SCOPE var: 0.12173132659287737\n",
            "Total Loss: 1.5499182168998558\n",
            "----------------------------------------\n",
            "Epoch 120\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.1347, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.8057982690470906\n",
            "SCOPE mean: 0.784653286078537, SCOPE var: 0.12198522882285961\n",
            "Total Loss: 1.5375843937360458\n",
            "----------------------------------------\n",
            "Epoch 121\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.1321, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.7864561137820094\n",
            "SCOPE mean: 0.7878147347403082, SCOPE var: 0.12223849543693163\n",
            "Total Loss: 1.5253349413387165\n",
            "----------------------------------------\n",
            "Epoch 122\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.1296, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.7676334309922885\n",
            "SCOPE mean: 0.7907970189159313, SCOPE var: 0.1224948797416996\n",
            "Total Loss: 1.513438239150302\n",
            "----------------------------------------\n",
            "Epoch 123\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.1272, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.7491891926327865\n",
            "SCOPE mean: 0.793484980041352, SCOPE var: 0.1227174637412705\n",
            "Total Loss: 1.5017574033081018\n",
            "----------------------------------------\n",
            "Epoch 124\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.1249, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.7309940400285875\n",
            "SCOPE mean: 0.7960071126357209, SCOPE var: 0.12292809762981971\n",
            "Total Loss: 1.4903647643015558\n",
            "----------------------------------------\n",
            "Epoch 125\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.1226, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.7129871955330747\n",
            "SCOPE mean: 0.7982855059878627, SCOPE var: 0.12310207581486958\n",
            "Total Loss: 1.47913368556602\n",
            "----------------------------------------\n",
            "Epoch 126\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.1206, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.6952604654854473\n",
            "SCOPE mean: 0.8003869666652815, SCOPE var: 0.12325151188770363\n",
            "Total Loss: 1.4682008119413743\n",
            "----------------------------------------\n",
            "Epoch 127\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.1183, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.67766482800106\n",
            "SCOPE mean: 0.8023808513230413, SCOPE var: 0.1233890965136077\n",
            "Total Loss: 1.4571680057326946\n",
            "----------------------------------------\n",
            "Epoch 128\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.1161, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.66019494607737\n",
            "SCOPE mean: 0.8042577569984125, SCOPE var: 0.12351706428512778\n",
            "Total Loss: 1.446188687598659\n",
            "----------------------------------------\n",
            "Epoch 129\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.1139, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.6426788066454003\n",
            "SCOPE mean: 0.806070889472187, SCOPE var: 0.12361423533999791\n",
            "Total Loss: 1.4352158902178556\n",
            "----------------------------------------\n",
            "Epoch 130\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.1120, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.6251488102491933\n",
            "SCOPE mean: 0.807792249480286, SCOPE var: 0.12369857608273442\n",
            "Total Loss: 1.424590730278742\n",
            "----------------------------------------\n",
            "Epoch 131\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.1104, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.6078311806249115\n",
            "SCOPE mean: 0.8094307578004919, SCOPE var: 0.12371918896698485\n",
            "Total Loss: 1.4143185627871566\n",
            "----------------------------------------\n",
            "Epoch 132\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.1091, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.590499482292592\n",
            "SCOPE mean: 0.8118016804464283, SCOPE var: 0.12392683755445973\n",
            "Total Loss: 1.4043643117986562\n",
            "----------------------------------------\n",
            "Epoch 133\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.1079, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.57195405428103\n",
            "SCOPE mean: 0.8145995212370148, SCOPE var: 0.1242042254005667\n",
            "Total Loss: 1.3938952436751306\n",
            "----------------------------------------\n",
            "Epoch 134\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.1067, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.5535466562483298\n",
            "SCOPE mean: 0.8175203896788209, SCOPE var: 0.12449745836424835\n",
            "Total Loss: 1.3834817354210307\n",
            "----------------------------------------\n",
            "Epoch 135\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.1054, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.534884801158622\n",
            "SCOPE mean: 0.8202616964921341, SCOPE var: 0.12475138920824651\n",
            "Total Loss: 1.3728283309616218\n",
            "----------------------------------------\n",
            "Epoch 136\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.1041, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.516150452908602\n",
            "SCOPE mean: 0.8229499777867015, SCOPE var: 0.12499362081562025\n",
            "Total Loss: 1.3621267387052278\n",
            "----------------------------------------\n",
            "Epoch 137\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.1027, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.497490661071936\n",
            "SCOPE mean: 0.825629930185033, SCOPE var: 0.12522387116402098\n",
            "Total Loss: 1.3514355717512856\n",
            "----------------------------------------\n",
            "Epoch 138\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.1012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.4789576108214897\n",
            "SCOPE mean: 0.8282052266666547, SCOPE var: 0.12531018154472498\n",
            "Total Loss: 1.340678683325871\n",
            "----------------------------------------\n",
            "Epoch 139\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0997, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.4605880475855595\n",
            "SCOPE mean: 0.8307768675966795, SCOPE var: 0.12538737636012476\n",
            "Total Loss: 1.3299734240023948\n",
            "----------------------------------------\n",
            "Epoch 140\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0982, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.4424185501049567\n",
            "SCOPE mean: 0.8333241052599449, SCOPE var: 0.12545325289145956\n",
            "Total Loss: 1.3193601238349548\n",
            "----------------------------------------\n",
            "Epoch 141\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0967, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.4230068651493\n",
            "SCOPE mean: 0.8360245094041918, SCOPE var: 0.12546730291176492\n",
            "Total Loss: 1.3082364523663563\n",
            "----------------------------------------\n",
            "Epoch 142\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0961, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.402644810279183\n",
            "SCOPE mean: 0.8388184219869821, SCOPE var: 0.12543326903293966\n",
            "Total Loss: 1.2974074970710743\n",
            "----------------------------------------\n",
            "Epoch 143\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0944, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.3821594013209286\n",
            "SCOPE mean: 0.8418284933295359, SCOPE var: 0.1253716448459039\n",
            "Total Loss: 1.2855292168938166\n",
            "----------------------------------------\n",
            "Epoch 144\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0924, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.360923593053313\n",
            "SCOPE mean: 0.8452678137954895, SCOPE var: 0.12528633813259366\n",
            "Total Loss: 1.2729018934860183\n",
            "----------------------------------------\n",
            "Epoch 145\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0908, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.3396472401410224\n",
            "SCOPE mean: 0.8487300458943781, SCOPE var: 0.12517762781998512\n",
            "Total Loss: 1.2605744304876103\n",
            "----------------------------------------\n",
            "Epoch 146\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0890, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.3184039958405247\n",
            "SCOPE mean: 0.8521441146270983, SCOPE var: 0.12502784667575173\n",
            "Total Loss: 1.2481608454840936\n",
            "----------------------------------------\n",
            "Epoch 147\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0871, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.2971498430087127\n",
            "SCOPE mean: 0.8555552527375759, SCOPE var: 0.12486269545481185\n",
            "Total Loss: 1.2356510511077057\n",
            "----------------------------------------\n",
            "Epoch 148\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0853, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.276137471263726\n",
            "SCOPE mean: 0.8588763015609909, SCOPE var: 0.12467309235674934\n",
            "Total Loss: 1.2233963550935956\n",
            "----------------------------------------\n",
            "Epoch 149\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0836, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.2544609073693533\n",
            "SCOPE mean: 0.8620934631903124, SCOPE var: 0.12444838316750487\n",
            "Total Loss: 1.2108489898273864\n",
            "----------------------------------------\n",
            "Epoch 150\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0817, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.2308800796697885\n",
            "SCOPE mean: 0.8653287460264475, SCOPE var: 0.1241828513364809\n",
            "Total Loss: 1.1971248593128416\n",
            "----------------------------------------\n",
            "Epoch 151\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0798, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.2073196826000285\n",
            "SCOPE mean: 0.868496539018351, SCOPE var: 0.12390463737361519\n",
            "Total Loss: 1.183465107874038\n",
            "----------------------------------------\n",
            "Epoch 152\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0780, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.183617740671302\n",
            "SCOPE mean: 0.8715369075419829, SCOPE var: 0.12359230947228372\n",
            "Total Loss: 1.169768047584528\n",
            "----------------------------------------\n",
            "Epoch 153\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0762, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.1600810263923944\n",
            "SCOPE mean: 0.8744600128402555, SCOPE var: 0.12325623254660767\n",
            "Total Loss: 1.156227452672203\n",
            "----------------------------------------\n",
            "Epoch 154\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0744, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.1360876104815176\n",
            "SCOPE mean: 0.8774433843059809, SCOPE var: 0.12291180751935833\n",
            "Total Loss: 1.1424599903431816\n",
            "----------------------------------------\n",
            "Epoch 155\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0723, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.1110539230170065\n",
            "SCOPE mean: 0.880525871311347, SCOPE var: 0.12256372730105915\n",
            "Total Loss: 1.127826211372411\n",
            "----------------------------------------\n",
            "Epoch 156\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0701, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.0861599281911447\n",
            "SCOPE mean: 0.8835783092083082, SCOPE var: 0.12219493609879137\n",
            "Total Loss: 1.11321844590227\n",
            "----------------------------------------\n",
            "Epoch 157\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0680, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.0614711884814083\n",
            "SCOPE mean: 0.8866446695920948, SCOPE var: 0.12181061482098257\n",
            "Total Loss: 1.0987362943211576\n",
            "----------------------------------------\n",
            "Epoch 158\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0661, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.0373893042809006\n",
            "SCOPE mean: 0.8898036816035646, SCOPE var: 0.1214267169033881\n",
            "Total Loss: 1.0847495207839712\n",
            "----------------------------------------\n",
            "Epoch 159\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0639, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.0138468026520053\n",
            "SCOPE mean: 0.8932217079969216, SCOPE var: 0.12107625186459879\n",
            "Total Loss: 1.0708223745672696\n",
            "----------------------------------------\n",
            "Epoch 160\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0615, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.9909158019382422\n",
            "SCOPE mean: 0.896858129161966, SCOPE var: 0.12074930502944478\n",
            "Total Loss: 1.0569634853433065\n",
            "----------------------------------------\n",
            "Epoch 161\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0591, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.9686339147217788\n",
            "SCOPE mean: 0.9006883972852034, SCOPE var: 0.12044690478438115\n",
            "Total Loss: 1.043436819913064\n",
            "----------------------------------------\n",
            "Epoch 162\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0570, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.9469145933915166\n",
            "SCOPE mean: 0.904572828428122, SCOPE var: 0.12015095081122636\n",
            "Total Loss: 1.0304516498720542\n",
            "----------------------------------------\n",
            "Epoch 163\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0548, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.9254303613462784\n",
            "SCOPE mean: 0.9084689152626731, SCOPE var: 0.11984361357006137\n",
            "Total Loss: 1.0175496932938812\n",
            "----------------------------------------\n",
            "Epoch 164\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0525, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.9033204564804853\n",
            "SCOPE mean: 0.9124541612375368, SCOPE var: 0.11949096380760289\n",
            "Total Loss: 1.0041764284082915\n",
            "----------------------------------------\n",
            "Epoch 165\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0503, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.881596369163906\n",
            "SCOPE mean: 0.9164672906593271, SCOPE var: 0.1191356839883692\n",
            "Total Loss: 0.9911236441442414\n",
            "----------------------------------------\n",
            "Epoch 166\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0484, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.8603883260304643\n",
            "SCOPE mean: 0.920499047296712, SCOPE var: 0.11877674066153694\n",
            "Total Loss: 0.9786280555216513\n",
            "----------------------------------------\n",
            "Epoch 167\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0467, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.8398896464790049\n",
            "SCOPE mean: 0.924505195310228, SCOPE var: 0.11841775909248443\n",
            "Total Loss: 0.9665985365041014\n",
            "----------------------------------------\n",
            "Epoch 168\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0449, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.819701616121776\n",
            "SCOPE mean: 0.9282900238976919, SCOPE var: 0.1180544438150046\n",
            "Total Loss: 0.9547795240849793\n",
            "----------------------------------------\n",
            "Epoch 169\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0431, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7999226606724787\n",
            "SCOPE mean: 0.9318910219477943, SCOPE var: 0.11768146901123462\n",
            "Total Loss: 0.9430812564331374\n",
            "----------------------------------------\n",
            "Epoch 170\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0414, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7809335712156988\n",
            "SCOPE mean: 0.9354265930891906, SCOPE var: 0.11730634892356301\n",
            "Total Loss: 0.9318219848764921\n",
            "----------------------------------------\n",
            "Epoch 171\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0397, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.762386360448118\n",
            "SCOPE mean: 0.938934963330787, SCOPE var: 0.11689951822017222\n",
            "Total Loss: 0.9209189314681913\n",
            "----------------------------------------\n",
            "Epoch 172\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0381, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7443582110859874\n",
            "SCOPE mean: 0.9424460412927219, SCOPE var: 0.11647579644729035\n",
            "Total Loss: 0.9102877427157517\n",
            "----------------------------------------\n",
            "Epoch 173\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0365, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.727114681084281\n",
            "SCOPE mean: 0.9458377744010399, SCOPE var: 0.11604296026091587\n",
            "Total Loss: 0.9000916716096441\n",
            "----------------------------------------\n",
            "Epoch 174\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0351, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7104484561303201\n",
            "SCOPE mean: 0.9491194694715616, SCOPE var: 0.1156031807545758\n",
            "Total Loss: 0.8902896998741877\n",
            "----------------------------------------\n",
            "Epoch 175\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0337, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.694336797572269\n",
            "SCOPE mean: 0.9521295557799218, SCOPE var: 0.1151575763814783\n",
            "Total Loss: 0.8808563612151384\n",
            "----------------------------------------\n",
            "Epoch 176\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0324, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6783647860540674\n",
            "SCOPE mean: 0.9548176108168757, SCOPE var: 0.11470913927122811\n",
            "Total Loss: 0.8715889505437033\n",
            "----------------------------------------\n",
            "Epoch 177\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0312, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6630469987687417\n",
            "SCOPE mean: 0.9570221944136629, SCOPE var: 0.11426124737559108\n",
            "Total Loss: 0.8627533881942862\n",
            "----------------------------------------\n",
            "Epoch 178\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0302, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6485543023428675\n",
            "SCOPE mean: 0.9582388446620574, SCOPE var: 0.11379383177268719\n",
            "Total Loss: 0.8544386371084489\n",
            "----------------------------------------\n",
            "Epoch 179\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0292, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.634705739836505\n",
            "SCOPE mean: 0.9594180452117839, SCOPE var: 0.11333168451787295\n",
            "Total Loss: 0.8465472406090104\n",
            "----------------------------------------\n",
            "Epoch 180\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0283, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6214260298683816\n",
            "SCOPE mean: 0.9604859965613421, SCOPE var: 0.11287694608505945\n",
            "Total Loss: 0.8390336690063173\n",
            "----------------------------------------\n",
            "Epoch 181\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0275, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.608802680560229\n",
            "SCOPE mean: 0.9614383039971041, SCOPE var: 0.11243220021910905\n",
            "Total Loss: 0.8319271090574624\n",
            "----------------------------------------\n",
            "Epoch 182\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0268, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5967236162024923\n",
            "SCOPE mean: 0.9623412725731412, SCOPE var: 0.11200013893340707\n",
            "Total Loss: 0.8251597390687861\n",
            "----------------------------------------\n",
            "Epoch 183\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0261, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5850649903937633\n",
            "SCOPE mean: 0.9632154856764346, SCOPE var: 0.1115821947178662\n",
            "Total Loss: 0.8186614303918182\n",
            "----------------------------------------\n",
            "Epoch 184\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0255, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5740615275212648\n",
            "SCOPE mean: 0.9640089241928596, SCOPE var: 0.11117582153055963\n",
            "Total Loss: 0.8125590466294539\n",
            "----------------------------------------\n",
            "Epoch 185\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0250, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5637268796485642\n",
            "SCOPE mean: 0.9647228359659457, SCOPE var: 0.11078513357041805\n",
            "Total Loss: 0.8068538363126775\n",
            "----------------------------------------\n",
            "Epoch 186\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0245, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5537903906218036\n",
            "SCOPE mean: 0.9654806251690489, SCOPE var: 0.11041968401732237\n",
            "Total Loss: 0.8014266371971245\n",
            "----------------------------------------\n",
            "Epoch 187\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0241, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5443035671299463\n",
            "SCOPE mean: 0.9662860341059841, SCOPE var: 0.1100808470727161\n",
            "Total Loss: 0.796260123066395\n",
            "----------------------------------------\n",
            "Epoch 188\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0238, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5352778286520645\n",
            "SCOPE mean: 0.9671531541961049, SCOPE var: 0.10977017438291799\n",
            "Total Loss: 0.7913890060643982\n",
            "----------------------------------------\n",
            "Epoch 189\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0235, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5266542515323238\n",
            "SCOPE mean: 0.968107114729053, SCOPE var: 0.1094895415836667\n",
            "Total Loss: 0.786804138474558\n",
            "----------------------------------------\n",
            "Epoch 190\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0233, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5183067868120876\n",
            "SCOPE mean: 0.9691955226016257, SCOPE var: 0.1092357105435621\n",
            "Total Loss: 0.7824336053561447\n",
            "----------------------------------------\n",
            "Epoch 191\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0231, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5102737276624532\n",
            "SCOPE mean: 0.9702746264123961, SCOPE var: 0.1090068393797449\n",
            "Total Loss: 0.7782268840771158\n",
            "----------------------------------------\n",
            "Epoch 192\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0229, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5025212487062538\n",
            "SCOPE mean: 0.9714186834861741, SCOPE var: 0.10881165886031076\n",
            "Total Loss: 0.7741943434883709\n",
            "----------------------------------------\n",
            "Epoch 193\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0228, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4949345783548078\n",
            "SCOPE mean: 0.972669743140131, SCOPE var: 0.10865456984393868\n",
            "Total Loss: 0.7702947391727478\n",
            "----------------------------------------\n",
            "Epoch 194\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0228, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4875329900029868\n",
            "SCOPE mean: 0.9740208034164108, SCOPE var: 0.10853463364449581\n",
            "Total Loss: 0.7665191754955811\n",
            "----------------------------------------\n",
            "Epoch 195\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0227, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4802904221047029\n",
            "SCOPE mean: 0.975434480921585, SCOPE var: 0.10844360901595562\n",
            "Total Loss: 0.7628500169853464\n",
            "----------------------------------------\n",
            "Epoch 196\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0227, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4731804729204412\n",
            "SCOPE mean: 0.9769057406617808, SCOPE var: 0.1083821636818221\n",
            "Total Loss: 0.7592737051640747\n",
            "----------------------------------------\n",
            "Epoch 197\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0226, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.466293439825263\n",
            "SCOPE mean: 0.9784022950470455, SCOPE var: 0.10834885388898056\n",
            "Total Loss: 0.7557490378813062\n",
            "----------------------------------------\n",
            "Epoch 198\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0225, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4596081425271956\n",
            "SCOPE mean: 0.9799173216845635, SCOPE var: 0.10834245217989055\n",
            "Total Loss: 0.7523277115279825\n",
            "----------------------------------------\n",
            "Epoch 199\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0225, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4529934237152702\n",
            "SCOPE mean: 0.9814744901165919, SCOPE var: 0.10836122962757164\n",
            "Total Loss: 0.7489587633177774\n",
            "----------------------------------------\n",
            "Epoch 200\n",
            "IS mean: 1.2158595644451584,IS variance: 0.3042718972439603\n",
            "SCOPE Var loss:  tensor(0.0224, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.446453834745164\n",
            "SCOPE mean: 0.9830969485418949, SCOPE var: 0.10840708906609792\n",
            "Total Loss: 0.7456401766210135\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[-0.0808, -0.0835],\n",
            "        [ 0.1481, -0.0426],\n",
            "        [ 0.4885,  0.5968],\n",
            "        [-0.4776,  0.2428],\n",
            "        [ 0.7361, -0.3812],\n",
            "        [ 0.2617, -0.2765],\n",
            "        [-0.6120,  0.0066],\n",
            "        [ 0.1929,  0.4693],\n",
            "        [ 0.5984,  0.4124],\n",
            "        [ 0.3461,  0.4344],\n",
            "        [-0.5825, -0.5235],\n",
            "        [-0.5225, -0.4385],\n",
            "        [-0.8346,  0.0165],\n",
            "        [ 0.3872, -0.4707],\n",
            "        [ 0.5157, -0.2013],\n",
            "        [ 0.4294, -0.2359]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([ 0.8916,  0.1670, -0.1882,  0.4880,  0.1673,  0.3218, -0.6856,  0.3367,\n",
            "        -0.0947, -0.2696, -0.1913, -0.3826,  0.4528,  0.1382,  0.5761, -0.4870],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[-3.1508e-02, -4.4350e-01, -1.0708e-01, -1.1544e-01, -2.2718e-01,\n",
            "         -5.5389e-02,  1.4583e-01,  1.4887e-01, -2.0767e-01, -7.3453e-02,\n",
            "          2.4297e-01, -1.3673e-01, -7.5410e-02, -3.2944e-02, -1.7400e-01,\n",
            "         -2.2504e-01],\n",
            "        [ 5.1544e-01, -3.1982e-01, -4.3893e-02, -5.1502e-02, -1.7340e-01,\n",
            "         -1.4702e-01, -1.4454e-01,  7.4338e-02, -1.8123e-01,  2.3381e-01,\n",
            "         -2.2206e-01, -2.4215e-01,  1.5463e-01,  2.4469e-01,  1.9538e-01,\n",
            "          2.2324e-01],\n",
            "        [ 3.4289e-01,  3.0770e-01,  1.0557e-01, -2.1609e-01,  1.6704e-01,\n",
            "          7.8937e-02,  2.2910e-01,  1.3918e-01, -3.6288e-02, -2.5807e-01,\n",
            "          7.8982e-02, -9.0411e-02,  9.7448e-02, -2.0167e-02, -7.6417e-02,\n",
            "         -1.4900e-01],\n",
            "        [-1.1004e-01,  1.6972e-01,  7.8621e-02, -1.3021e-01, -3.6098e-01,\n",
            "          2.2248e-01, -1.4361e-01, -1.8508e-01,  9.0025e-03, -3.2383e-01,\n",
            "         -7.3527e-02, -1.6425e-01, -2.9780e-01, -1.7336e-01,  2.4319e-01,\n",
            "         -9.2379e-02],\n",
            "        [ 3.1127e-01,  2.0426e-01, -1.9563e-02,  5.5031e-02,  3.6473e-02,\n",
            "          6.1446e-02, -1.6649e-01, -3.6020e-02,  4.6894e-02, -3.3398e-02,\n",
            "          1.2140e-01, -1.0947e-02,  3.7263e-01,  4.6224e-02,  7.6576e-02,\n",
            "         -1.8104e-01],\n",
            "        [ 1.3702e-01, -9.1475e-02, -1.4227e-01,  1.0449e-01,  2.1168e-01,\n",
            "         -5.2712e-02, -1.1532e-02,  1.8601e-01,  3.7855e-02,  1.4141e-01,\n",
            "          2.2387e-01,  1.0505e-01, -5.2616e-02, -2.0976e-01, -1.1532e-01,\n",
            "          6.3582e-02],\n",
            "        [ 1.7682e-01, -1.3768e-01, -4.1422e-04,  3.3053e-02, -6.9335e-02,\n",
            "          8.6507e-04, -2.3978e-01, -2.1345e-01,  1.5076e-01,  3.9007e-02,\n",
            "          2.0770e-01, -6.2762e-02,  2.4012e-01, -1.4346e-01, -4.2902e-02,\n",
            "          1.6721e-01],\n",
            "        [ 2.9240e-01, -3.0856e-02, -1.6431e-01,  1.0821e-01, -1.8018e-01,\n",
            "         -2.4922e-02,  1.0823e-01, -5.4668e-02, -1.9892e-01, -7.1920e-02,\n",
            "         -1.1448e-01, -2.7665e-02, -5.1639e-02, -1.1754e-01, -9.9080e-02,\n",
            "          3.0993e-02],\n",
            "        [ 1.0843e-01, -1.3669e-01, -2.2560e-01,  6.7764e-02, -2.2351e-01,\n",
            "         -1.3944e-01,  3.3424e-02,  7.6379e-02,  4.9653e-02, -2.3872e-01,\n",
            "         -2.0898e-01,  1.0012e-01,  1.4382e-01, -7.4411e-02, -3.9780e-02,\n",
            "         -1.9885e-01],\n",
            "        [ 3.1345e-01,  2.8550e-02,  7.3787e-02, -6.5938e-02,  8.4794e-03,\n",
            "          8.1180e-02,  1.5495e-01,  1.9043e-01, -2.5692e-01,  1.9271e-01,\n",
            "         -1.1588e-01,  2.0708e-01,  3.2348e-01, -8.1761e-02,  7.1920e-02,\n",
            "         -5.6576e-02],\n",
            "        [-2.8223e-01, -1.1030e-01,  1.8059e-01, -2.2086e-01, -1.6655e-01,\n",
            "         -1.3665e-01,  1.4947e-02, -1.2418e-01, -2.4436e-01,  4.4124e-02,\n",
            "         -1.8084e-01,  1.7568e-01, -2.5996e-01, -1.3068e-01, -1.0900e-01,\n",
            "         -1.1665e-01],\n",
            "        [ 5.4340e-01, -2.9243e-01,  6.7208e-02, -6.3691e-02, -1.6700e-01,\n",
            "          1.2363e-01, -1.9286e-01,  1.4193e-03,  1.6418e-01,  1.0007e-01,\n",
            "         -2.1854e-02,  6.2092e-03,  3.4679e-01, -1.3899e-01, -1.2380e-01,\n",
            "         -6.0104e-02],\n",
            "        [-4.1063e-01,  1.6957e-01, -2.5436e-02, -1.3004e-02, -5.3341e-02,\n",
            "         -1.8849e-01, -2.0478e-01,  1.4320e-01,  2.3014e-02, -6.5678e-02,\n",
            "         -8.5319e-02,  1.7251e-01, -6.6197e-02, -1.7335e-01,  5.3391e-02,\n",
            "          2.1040e-01],\n",
            "        [-6.0711e-02, -8.4152e-02,  9.3507e-02, -1.9656e-03, -8.9070e-02,\n",
            "         -2.9025e-01, -1.5954e-01,  7.0298e-02, -2.7538e-01, -4.9457e-02,\n",
            "         -1.9452e-01,  1.6456e-01, -1.9946e-01, -1.0340e-01, -1.1282e-01,\n",
            "         -3.8950e-02],\n",
            "        [ 2.8355e-01,  8.8117e-02, -2.5889e-02,  2.9456e-01,  4.8940e-02,\n",
            "         -1.5310e-01,  1.3956e-01,  1.7976e-01,  3.6808e-02, -1.4375e-01,\n",
            "         -2.4190e-01,  2.4075e-01,  1.1567e-01, -2.0393e-01,  2.0973e-01,\n",
            "         -4.5889e-02],\n",
            "        [-3.0540e-01, -1.1369e-01, -1.1146e-01,  1.4263e-01,  2.3686e-01,\n",
            "         -2.2893e-01, -6.0918e-02,  2.5694e-02, -8.1657e-02, -3.2699e-02,\n",
            "          1.7257e-03,  8.1709e-02,  8.0339e-02,  3.0510e-01, -8.1989e-02,\n",
            "          1.4261e-01]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([ 0.1355, -0.0157,  0.2162,  0.0387,  0.2509, -0.1720, -0.0616,  0.2079,\n",
            "        -0.2611,  0.2363, -0.2352,  0.2285,  0.1928,  0.1465,  0.2190,  0.1472],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[-0.1579,  0.2664,  0.2021, -0.2206,  0.2305,  0.0061,  0.2524,  0.0242,\n",
            "         -0.0312,  0.0613, -0.1494,  0.0649, -0.0317, -0.1015,  0.1234, -0.1448]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([-0.1242], dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NN_l1_l2_reg(\n",
              "  (hidden_layers): ModuleList(\n",
              "    (0): Linear(in_features=2, out_features=16, bias=True)\n",
              "    (1): Linear(in_features=16, out_features=16, bias=True)\n",
              "  )\n",
              "  (output_layer): Linear(in_features=16, out_features=1, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b_800_mse = action_probs_top_n_epsilon(q_table, 1, 0.4)\n",
        "pi_b_800_mse = experiment_actions(800, env_50, P_pi_b_800_mse)\n",
        "P_pi_e_800 = action_probs_top_n_epsilon(q_table, 1, 0.05)\n",
        "pi_e_800 = experiment_actions(1000, env_50, P_pi_e_800)\n",
        "model_800_random_pi_b_800_mse = CustomizableFeatureNet(input_dim=2, hidden_dims=[10, 10], output_dim=1, dtype = torch.float64, l2_lambda=0.002)\n",
        "# model_800_random_pi_b_800_mse = NN_l1_reg(input_dim=2, hidden_dims=[10, 10], output_dim=1, dtype = torch.float64, l1_lambda=0.0001)\n",
        "# model_800_random_pi_b_800_mse = NN_l1_l2_reg(input_dim=2, hidden_dims=[16, 16], output_dim=1, dtype = torch.float64, l1_lambda=0.0001, l2_lambda = 0.0001)\n",
        "test_800_random_pi_b_800_mse = SCOPE_straight(model_800_random_pi_b_800_mse, 0.99, 10000, pi_b_800_mse, P_pi_b_800_mse, P_pi_e_800, 0.3, dtype = torch.float64)\n",
        "test_800_random_pi_b_800_mse.train_var_scope(300, 0.001, 1, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a912c70-aba2-4653-a9ce-de9841f3adf9",
        "id": "jjfxP1R0GL2-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0088, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  20.77788605297548\n",
            "SCOPE mean: 0.5641474175565288, SCOPE var: 0.026994582664913284\n",
            "Total Loss: 20.78665849821228\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0214, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  20.40859379743519\n",
            "SCOPE mean: 0.5696977644839282, SCOPE var: 0.027384408647234945\n",
            "Total Loss: 20.430008994417012\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0219, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  20.070576188003972\n",
            "SCOPE mean: 0.5740741616282801, SCOPE var: 0.027672732431925605\n",
            "Total Loss: 20.09244975068282\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0223, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  19.737931407320403\n",
            "SCOPE mean: 0.5776975006036312, SCOPE var: 0.02789776265373525\n",
            "Total Loss: 19.760269799948556\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0228, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  19.411375768818726\n",
            "SCOPE mean: 0.5812667562039422, SCOPE var: 0.02813692384971797\n",
            "Total Loss: 19.434177641148125\n",
            "----------------------------------------\n",
            "Epoch 6\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0233, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  19.09016446690056\n",
            "SCOPE mean: 0.5848135348385282, SCOPE var: 0.02839465546246684\n",
            "Total Loss: 19.11343723040061\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0237, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  18.77422545248805\n",
            "SCOPE mean: 0.5882663418403519, SCOPE var: 0.028663886495238006\n",
            "Total Loss: 18.797971505838802\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0242, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  18.462111799741407\n",
            "SCOPE mean: 0.5916165451361721, SCOPE var: 0.028943205777494645\n",
            "Total Loss: 18.486334557955246\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0247, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  18.154681425914138\n",
            "SCOPE mean: 0.5948552859164689, SCOPE var: 0.02923070289578212\n",
            "Total Loss: 18.17938772920097\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0252, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  17.85046588391183\n",
            "SCOPE mean: 0.5980591029053361, SCOPE var: 0.02952335778302071\n",
            "Total Loss: 17.875663713938895\n",
            "----------------------------------------\n",
            "Epoch 11\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0257, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  17.549453960446723\n",
            "SCOPE mean: 0.6012147687582252, SCOPE var: 0.029826280280351954\n",
            "Total Loss: 17.57513112801962\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0262, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  17.25207793669518\n",
            "SCOPE mean: 0.6045840810696738, SCOPE var: 0.030134862738782353\n",
            "Total Loss: 17.2782384353551\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0267, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  16.960618228524158\n",
            "SCOPE mean: 0.608305105432809, SCOPE var: 0.030497071907854625\n",
            "Total Loss: 16.987273408921048\n",
            "----------------------------------------\n",
            "Epoch 14\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0272, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  16.674716212772523\n",
            "SCOPE mean: 0.6124485449483326, SCOPE var: 0.030943798420734324\n",
            "Total Loss: 16.701868118268187\n",
            "----------------------------------------\n",
            "Epoch 15\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0276, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  16.3929658620641\n",
            "SCOPE mean: 0.6161262865611868, SCOPE var: 0.03141131904553767\n",
            "Total Loss: 16.420531740352\n",
            "----------------------------------------\n",
            "Epoch 16\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0280, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  16.115344049336105\n",
            "SCOPE mean: 0.6196891073969218, SCOPE var: 0.03190356315395886\n",
            "Total Loss: 16.143301842669903\n",
            "----------------------------------------\n",
            "Epoch 17\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0282, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  15.842740426961395\n",
            "SCOPE mean: 0.6233933922472188, SCOPE var: 0.03240911979844419\n",
            "Total Loss: 15.87097461565692\n",
            "----------------------------------------\n",
            "Epoch 18\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0285, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  15.576791831993562\n",
            "SCOPE mean: 0.627194167681251, SCOPE var: 0.032952849774913785\n",
            "Total Loss: 15.605263823701728\n",
            "----------------------------------------\n",
            "Epoch 19\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0287, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  15.31597230568528\n",
            "SCOPE mean: 0.631015861560266, SCOPE var: 0.03352186493643457\n",
            "Total Loss: 15.344649996669455\n",
            "----------------------------------------\n",
            "Epoch 20\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0288, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  15.059018816325544\n",
            "SCOPE mean: 0.6347175558147855, SCOPE var: 0.03409901336924048\n",
            "Total Loss: 15.087828242072616\n",
            "----------------------------------------\n",
            "Epoch 21\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0289, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.806134793766239\n",
            "SCOPE mean: 0.6383226945836601, SCOPE var: 0.034680325177675525\n",
            "Total Loss: 14.835081224456493\n",
            "----------------------------------------\n",
            "Epoch 22\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0292, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.556299998848596\n",
            "SCOPE mean: 0.6419756002596699, SCOPE var: 0.035270361105811575\n",
            "Total Loss: 14.585496380073678\n",
            "----------------------------------------\n",
            "Epoch 23\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0295, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.309651232182064\n",
            "SCOPE mean: 0.6456076778457244, SCOPE var: 0.035868669623831895\n",
            "Total Loss: 14.33915391302609\n",
            "----------------------------------------\n",
            "Epoch 24\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0299, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  14.065896361674568\n",
            "SCOPE mean: 0.6497695334556544, SCOPE var: 0.03653408091823385\n",
            "Total Loss: 14.09575530487762\n",
            "----------------------------------------\n",
            "Epoch 25\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0302, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.825990037965418\n",
            "SCOPE mean: 0.6536304931480885, SCOPE var: 0.03717212019501664\n",
            "Total Loss: 13.856192063478128\n",
            "----------------------------------------\n",
            "Epoch 26\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0306, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.589902928404118\n",
            "SCOPE mean: 0.6574630211682425, SCOPE var: 0.03781668445998354\n",
            "Total Loss: 13.620460714546775\n",
            "----------------------------------------\n",
            "Epoch 27\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0309, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.358029344744086\n",
            "SCOPE mean: 0.6613047527795763, SCOPE var: 0.03847961964066956\n",
            "Total Loss: 13.38895244832291\n",
            "----------------------------------------\n",
            "Epoch 28\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0313, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  13.12989809223173\n",
            "SCOPE mean: 0.6651351228631547, SCOPE var: 0.039156844757561086\n",
            "Total Loss: 13.16118810777096\n",
            "----------------------------------------\n",
            "Epoch 29\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0317, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.904103297454737\n",
            "SCOPE mean: 0.6686265995074168, SCOPE var: 0.03983620142401124\n",
            "Total Loss: 12.935753399465918\n",
            "----------------------------------------\n",
            "Epoch 30\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0320, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.681732872316058\n",
            "SCOPE mean: 0.6717384873072271, SCOPE var: 0.04052233995734817\n",
            "Total Loss: 12.713750912558364\n",
            "----------------------------------------\n",
            "Epoch 31\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0324, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.46187550406626\n",
            "SCOPE mean: 0.6747695214216585, SCOPE var: 0.04121583904992581\n",
            "Total Loss: 12.494267748167912\n",
            "----------------------------------------\n",
            "Epoch 32\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0328, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.244581465980112\n",
            "SCOPE mean: 0.6777209108615236, SCOPE var: 0.041916840013067454\n",
            "Total Loss: 12.277365039396715\n",
            "----------------------------------------\n",
            "Epoch 33\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0332, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.029862899140074\n",
            "SCOPE mean: 0.6796039606814966, SCOPE var: 0.04250043765237563\n",
            "Total Loss: 12.06305244320532\n",
            "----------------------------------------\n",
            "Epoch 34\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0336, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.816954343358677\n",
            "SCOPE mean: 0.6814544648062825, SCOPE var: 0.04308633484459797\n",
            "Total Loss: 11.850540453305614\n",
            "----------------------------------------\n",
            "Epoch 35\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0340, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.605820445797853\n",
            "SCOPE mean: 0.6844546941768486, SCOPE var: 0.043677689247564815\n",
            "Total Loss: 11.639776796199246\n",
            "----------------------------------------\n",
            "Epoch 36\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0343, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.39692886653812\n",
            "SCOPE mean: 0.6874591578648743, SCOPE var: 0.044270898771378984\n",
            "Total Loss: 11.431232998997828\n",
            "----------------------------------------\n",
            "Epoch 37\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0346, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.190085261193842\n",
            "SCOPE mean: 0.6903368326215845, SCOPE var: 0.04486704381168075\n",
            "Total Loss: 11.22472825427561\n",
            "----------------------------------------\n",
            "Epoch 38\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0350, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.983597524955938\n",
            "SCOPE mean: 0.6925743981414384, SCOPE var: 0.04546283989556816\n",
            "Total Loss: 11.018560785035692\n",
            "----------------------------------------\n",
            "Epoch 39\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0353, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.776973680942353\n",
            "SCOPE mean: 0.693591562375887, SCOPE var: 0.04603827700894651\n",
            "Total Loss: 10.812246644883825\n",
            "----------------------------------------\n",
            "Epoch 40\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0356, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.571097371858224\n",
            "SCOPE mean: 0.6947031479288037, SCOPE var: 0.04659581327405682\n",
            "Total Loss: 10.606695263414824\n",
            "----------------------------------------\n",
            "Epoch 41\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0359, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.366129520844698\n",
            "SCOPE mean: 0.6958415812823198, SCOPE var: 0.04712897475038209\n",
            "Total Loss: 10.402071112532358\n",
            "----------------------------------------\n",
            "Epoch 42\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0363, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.163952268917361\n",
            "SCOPE mean: 0.6967804184431752, SCOPE var: 0.04765784003793424\n",
            "Total Loss: 10.200242059313858\n",
            "----------------------------------------\n",
            "Epoch 43\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0366, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.959347445559455\n",
            "SCOPE mean: 0.6978316813984722, SCOPE var: 0.048233433857632284\n",
            "Total Loss: 9.995946187889357\n",
            "----------------------------------------\n",
            "Epoch 44\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0369, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.752609783104564\n",
            "SCOPE mean: 0.6986066407569701, SCOPE var: 0.04879340195285054\n",
            "Total Loss: 9.789512704120478\n",
            "----------------------------------------\n",
            "Epoch 45\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0372, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.547400669607056\n",
            "SCOPE mean: 0.6989608948840917, SCOPE var: 0.04931763093963661\n",
            "Total Loss: 9.584592009126556\n",
            "----------------------------------------\n",
            "Epoch 46\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0374, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.344348255670297\n",
            "SCOPE mean: 0.6990787856033402, SCOPE var: 0.04981509060942699\n",
            "Total Loss: 9.381792607556813\n",
            "----------------------------------------\n",
            "Epoch 47\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0377, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.144522616627885\n",
            "SCOPE mean: 0.6990613024819156, SCOPE var: 0.050313885788764924\n",
            "Total Loss: 9.182218978881918\n",
            "----------------------------------------\n",
            "Epoch 48\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0379, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.947447935639378\n",
            "SCOPE mean: 0.6990503329785046, SCOPE var: 0.050823247107203005\n",
            "Total Loss: 8.98539500768474\n",
            "----------------------------------------\n",
            "Epoch 49\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0382, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.75406350054439\n",
            "SCOPE mean: 0.6987704289362872, SCOPE var: 0.051321299925573896\n",
            "Total Loss: 8.792257253976029\n",
            "----------------------------------------\n",
            "Epoch 50\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0384, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.564649141385887\n",
            "SCOPE mean: 0.698196120421497, SCOPE var: 0.051805225598290795\n",
            "Total Loss: 8.603085635377244\n",
            "----------------------------------------\n",
            "Epoch 51\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0387, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.378589354993917\n",
            "SCOPE mean: 0.6972549242686182, SCOPE var: 0.05226694732875903\n",
            "Total Loss: 8.417277282864726\n",
            "----------------------------------------\n",
            "Epoch 52\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0389, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.195849775786257\n",
            "SCOPE mean: 0.6957217499695428, SCOPE var: 0.05268473737344656\n",
            "Total Loss: 8.234798565515002\n",
            "----------------------------------------\n",
            "Epoch 53\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0392, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.016863725521619\n",
            "SCOPE mean: 0.693811669856557, SCOPE var: 0.05307916502361566\n",
            "Total Loss: 8.056067813614757\n",
            "----------------------------------------\n",
            "Epoch 54\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0394, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.840089663619086\n",
            "SCOPE mean: 0.6913746788060638, SCOPE var: 0.05343197691588806\n",
            "Total Loss: 7.879522604959498\n",
            "----------------------------------------\n",
            "Epoch 55\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0396, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.665168526337748\n",
            "SCOPE mean: 0.688385855957185, SCOPE var: 0.053743378904274386\n",
            "Total Loss: 7.704791079604914\n",
            "----------------------------------------\n",
            "Epoch 56\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0398, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.49324426518899\n",
            "SCOPE mean: 0.6848123892181733, SCOPE var: 0.05400241794652681\n",
            "Total Loss: 7.53306089060669\n",
            "----------------------------------------\n",
            "Epoch 57\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0400, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.322668257464467\n",
            "SCOPE mean: 0.6807969790436771, SCOPE var: 0.05418045384525972\n",
            "Total Loss: 7.362668431357772\n",
            "----------------------------------------\n",
            "Epoch 58\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0402, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.154379596863709\n",
            "SCOPE mean: 0.6766948974287574, SCOPE var: 0.05430276137501563\n",
            "Total Loss: 7.19454901948407\n",
            "----------------------------------------\n",
            "Epoch 59\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0403, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.991028478300469\n",
            "SCOPE mean: 0.6722059398140324, SCOPE var: 0.054399935986210825\n",
            "Total Loss: 7.031353271098694\n",
            "----------------------------------------\n",
            "Epoch 60\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0405, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.832943321443941\n",
            "SCOPE mean: 0.667312625666826, SCOPE var: 0.05446663412367091\n",
            "Total Loss: 6.873418553347034\n",
            "----------------------------------------\n",
            "Epoch 61\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0406, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.680070001785418\n",
            "SCOPE mean: 0.6620003138427039, SCOPE var: 0.05449671094486968\n",
            "Total Loss: 6.720687536471327\n",
            "----------------------------------------\n",
            "Epoch 62\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0408, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.53206097758687\n",
            "SCOPE mean: 0.6562909559563639, SCOPE var: 0.054488985455427484\n",
            "Total Loss: 6.572821155922961\n",
            "----------------------------------------\n",
            "Epoch 63\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0409, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.388629982857265\n",
            "SCOPE mean: 0.6502699497626522, SCOPE var: 0.05444279536345693\n",
            "Total Loss: 6.429528047717563\n",
            "----------------------------------------\n",
            "Epoch 64\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0411, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.25073142412286\n",
            "SCOPE mean: 0.6438225990368305, SCOPE var: 0.054355277255085245\n",
            "Total Loss: 6.291845464084217\n",
            "----------------------------------------\n",
            "Epoch 65\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0413, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.118033980107968\n",
            "SCOPE mean: 0.6369555834568795, SCOPE var: 0.0542263589364749\n",
            "Total Loss: 6.159376838613538\n",
            "----------------------------------------\n",
            "Epoch 66\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0416, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.990629124096805\n",
            "SCOPE mean: 0.6296639292053305, SCOPE var: 0.054049963666910276\n",
            "Total Loss: 6.032185396474517\n",
            "----------------------------------------\n",
            "Epoch 67\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0418, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.868052587387983\n",
            "SCOPE mean: 0.6216327954757065, SCOPE var: 0.05371678183110566\n",
            "Total Loss: 5.909870281028299\n",
            "----------------------------------------\n",
            "Epoch 68\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0421, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.7499087201480545\n",
            "SCOPE mean: 0.6131619971516784, SCOPE var: 0.05333850609561793\n",
            "Total Loss: 5.792037631841132\n",
            "----------------------------------------\n",
            "Epoch 69\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0424, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.636560606626756\n",
            "SCOPE mean: 0.6044344658107568, SCOPE var: 0.052931576495630586\n",
            "Total Loss: 5.678983082268908\n",
            "----------------------------------------\n",
            "Epoch 70\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0427, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.526913518830871\n",
            "SCOPE mean: 0.5954159597368194, SCOPE var: 0.05248440802158806\n",
            "Total Loss: 5.569598155261206\n",
            "----------------------------------------\n",
            "Epoch 71\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0428, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.419396855647163\n",
            "SCOPE mean: 0.586420611739129, SCOPE var: 0.051912613010679044\n",
            "Total Loss: 5.462216317484213\n",
            "----------------------------------------\n",
            "Epoch 72\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0428, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.3137206584580845\n",
            "SCOPE mean: 0.5774919355414129, SCOPE var: 0.05128704959707146\n",
            "Total Loss: 5.35656896189478\n",
            "----------------------------------------\n",
            "Epoch 73\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0429, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.212030536536852\n",
            "SCOPE mean: 0.5689096599606976, SCOPE var: 0.05071032550387841\n",
            "Total Loss: 5.254880745375242\n",
            "----------------------------------------\n",
            "Epoch 74\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0427, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.114664191714839\n",
            "SCOPE mean: 0.5606111086827442, SCOPE var: 0.05020165503676868\n",
            "Total Loss: 5.157314408104997\n",
            "----------------------------------------\n",
            "Epoch 75\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0423, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.021880750640525\n",
            "SCOPE mean: 0.5520966404376662, SCOPE var: 0.049662917493201786\n",
            "Total Loss: 5.0642288101760125\n",
            "----------------------------------------\n",
            "Epoch 76\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0422, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.933646110821722\n",
            "SCOPE mean: 0.5433544434572081, SCOPE var: 0.049096270333175186\n",
            "Total Loss: 4.975802016036251\n",
            "----------------------------------------\n",
            "Epoch 77\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0420, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.84958575907036\n",
            "SCOPE mean: 0.5342344508873579, SCOPE var: 0.04846813433547508\n",
            "Total Loss: 4.891553457076657\n",
            "----------------------------------------\n",
            "Epoch 78\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0418, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.769872707948376\n",
            "SCOPE mean: 0.5249624541114537, SCOPE var: 0.04782875873281057\n",
            "Total Loss: 4.811645614661882\n",
            "----------------------------------------\n",
            "Epoch 79\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0416, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.694560033643734\n",
            "SCOPE mean: 0.5155225876589086, SCOPE var: 0.04716982269291271\n",
            "Total Loss: 4.736131625973744\n",
            "----------------------------------------\n",
            "Epoch 80\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0414, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.622698879674159\n",
            "SCOPE mean: 0.5058694189397557, SCOPE var: 0.046489380336901136\n",
            "Total Loss: 4.66406454042292\n",
            "----------------------------------------\n",
            "Epoch 81\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0412, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.554655949272634\n",
            "SCOPE mean: 0.49613271537495923, SCOPE var: 0.0457627943478646\n",
            "Total Loss: 4.595819348306965\n",
            "----------------------------------------\n",
            "Epoch 82\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0410, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.488836653216221\n",
            "SCOPE mean: 0.48645099841867107, SCOPE var: 0.04499210065263223\n",
            "Total Loss: 4.529846166831359\n",
            "----------------------------------------\n",
            "Epoch 83\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0409, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.425269087402436\n",
            "SCOPE mean: 0.4768534320106787, SCOPE var: 0.0441971029719432\n",
            "Total Loss: 4.466131626886027\n",
            "----------------------------------------\n",
            "Epoch 84\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0407, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.365299152967858\n",
            "SCOPE mean: 0.4671515234012745, SCOPE var: 0.04339432676914145\n",
            "Total Loss: 4.406005578490113\n",
            "----------------------------------------\n",
            "Epoch 85\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0406, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.306203228710389\n",
            "SCOPE mean: 0.4574721405932687, SCOPE var: 0.04257387112888202\n",
            "Total Loss: 4.346780418954404\n",
            "----------------------------------------\n",
            "Epoch 86\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0405, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.246943674547514\n",
            "SCOPE mean: 0.44792361545084425, SCOPE var: 0.041732071980297804\n",
            "Total Loss: 4.287439863579316\n",
            "----------------------------------------\n",
            "Epoch 87\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0404, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.190277876376131\n",
            "SCOPE mean: 0.43835493496835687, SCOPE var: 0.04088846785186989\n",
            "Total Loss: 4.230710653632886\n",
            "----------------------------------------\n",
            "Epoch 88\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0404, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.135803233860843\n",
            "SCOPE mean: 0.42881907901428784, SCOPE var: 0.040048931519034665\n",
            "Total Loss: 4.176162230293397\n",
            "----------------------------------------\n",
            "Epoch 89\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0403, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.083435462809102\n",
            "SCOPE mean: 0.419354078159421, SCOPE var: 0.03921899329630642\n",
            "Total Loss: 4.123712524332712\n",
            "----------------------------------------\n",
            "Epoch 90\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0402, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.033149838463962\n",
            "SCOPE mean: 0.4099962339266163, SCOPE var: 0.03840254829403413\n",
            "Total Loss: 4.073328315686768\n",
            "----------------------------------------\n",
            "Epoch 91\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0401, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.9850167302844386\n",
            "SCOPE mean: 0.4008938697594905, SCOPE var: 0.03761419702538466\n",
            "Total Loss: 4.025083606229532\n",
            "----------------------------------------\n",
            "Epoch 92\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0399, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.938369225164407\n",
            "SCOPE mean: 0.39177562759756096, SCOPE var: 0.036851368801136965\n",
            "Total Loss: 3.978296479414545\n",
            "----------------------------------------\n",
            "Epoch 93\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0398, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.8897934968601846\n",
            "SCOPE mean: 0.38244786428213534, SCOPE var: 0.03610664855374838\n",
            "Total Loss: 3.9296054293788427\n",
            "----------------------------------------\n",
            "Epoch 94\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0397, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.8434576041727433\n",
            "SCOPE mean: 0.3732860607574474, SCOPE var: 0.03538753229626809\n",
            "Total Loss: 3.8831514225657573\n",
            "----------------------------------------\n",
            "Epoch 95\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0396, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.7985016420935924\n",
            "SCOPE mean: 0.3643933262763208, SCOPE var: 0.03468155061431021\n",
            "Total Loss: 3.838073972861423\n",
            "----------------------------------------\n",
            "Epoch 96\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0394, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.7556181165620965\n",
            "SCOPE mean: 0.35588581146260934, SCOPE var: 0.03399397985444888\n",
            "Total Loss: 3.795048801017377\n",
            "----------------------------------------\n",
            "Epoch 97\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0392, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.715112625884838\n",
            "SCOPE mean: 0.34781188024074605, SCOPE var: 0.03334735762723025\n",
            "Total Loss: 3.7543500347781897\n",
            "----------------------------------------\n",
            "Epoch 98\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0390, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.6733098573670917\n",
            "SCOPE mean: 0.3396521370683175, SCOPE var: 0.03271412788202306\n",
            "Total Loss: 3.7123260174047523\n",
            "----------------------------------------\n",
            "Epoch 99\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0388, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.63364948958146\n",
            "SCOPE mean: 0.3317392586136903, SCOPE var: 0.03210372320973498\n",
            "Total Loss: 3.6724550774397855\n",
            "----------------------------------------\n",
            "Epoch 100\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0386, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.5972774219962234\n",
            "SCOPE mean: 0.3242252667420304, SCOPE var: 0.03152323761077328\n",
            "Total Loss: 3.6358767250965935\n",
            "----------------------------------------\n",
            "Epoch 101\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0384, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.5639347643683834\n",
            "SCOPE mean: 0.3171471849985205, SCOPE var: 0.03097257975800906\n",
            "Total Loss: 3.602337197686489\n",
            "----------------------------------------\n",
            "Epoch 102\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0382, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.53036809222839\n",
            "SCOPE mean: 0.30989821367609066, SCOPE var: 0.030450038439380683\n",
            "Total Loss: 3.5685722970098332\n",
            "----------------------------------------\n",
            "Epoch 103\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0380, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.503291036380451\n",
            "SCOPE mean: 0.2976595587570107, SCOPE var: 0.029957310768051384\n",
            "Total Loss: 3.5413106997578088\n",
            "----------------------------------------\n",
            "Epoch 104\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0378, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.4778560755518555\n",
            "SCOPE mean: 0.2859904857852587, SCOPE var: 0.029496818798853092\n",
            "Total Loss: 3.5156902443318088\n",
            "----------------------------------------\n",
            "Epoch 105\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0377, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.453625709505874\n",
            "SCOPE mean: 0.27504399232096194, SCOPE var: 0.029062890976964642\n",
            "Total Loss: 3.4913061418056333\n",
            "----------------------------------------\n",
            "Epoch 106\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0376, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.430768040600407\n",
            "SCOPE mean: 0.2648853385015316, SCOPE var: 0.028656984472170317\n",
            "Total Loss: 3.4683217945265166\n",
            "----------------------------------------\n",
            "Epoch 107\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0374, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.4090087128731947\n",
            "SCOPE mean: 0.25549818303461996, SCOPE var: 0.02827974613560265\n",
            "Total Loss: 3.446431635170864\n",
            "----------------------------------------\n",
            "Epoch 108\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0373, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.388085797420154\n",
            "SCOPE mean: 0.24682100162932757, SCOPE var: 0.027929634514701502\n",
            "Total Loss: 3.4253653589187354\n",
            "----------------------------------------\n",
            "Epoch 109\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0371, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.3679515843427565\n",
            "SCOPE mean: 0.23879177849798056, SCOPE var: 0.027607587067597875\n",
            "Total Loss: 3.405081162035349\n",
            "----------------------------------------\n",
            "Epoch 110\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0370, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.348418808822643\n",
            "SCOPE mean: 0.2316099721921005, SCOPE var: 0.027312601631041662\n",
            "Total Loss: 3.3853937263348586\n",
            "----------------------------------------\n",
            "Epoch 111\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0368, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.3292014994199612\n",
            "SCOPE mean: 0.2252847249927293, SCOPE var: 0.02704330758930557\n",
            "Total Loss: 3.366003720679713\n",
            "----------------------------------------\n",
            "Epoch 112\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0366, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.31022492002775\n",
            "SCOPE mean: 0.2198077247306896, SCOPE var: 0.026798413306896213\n",
            "Total Loss: 3.346844352310241\n",
            "----------------------------------------\n",
            "Epoch 113\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0364, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.2914457978919853\n",
            "SCOPE mean: 0.21519208753015392, SCOPE var: 0.026575744853438565\n",
            "Total Loss: 3.327877480905915\n",
            "----------------------------------------\n",
            "Epoch 114\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0362, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.2727462895488797\n",
            "SCOPE mean: 0.2115823365396454, SCOPE var: 0.0263738434621941\n",
            "Total Loss: 3.308992145292596\n",
            "----------------------------------------\n",
            "Epoch 115\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0361, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.2540556689730478\n",
            "SCOPE mean: 0.20889795667593417, SCOPE var: 0.026191218704112552\n",
            "Total Loss: 3.29011149006138\n",
            "----------------------------------------\n",
            "Epoch 116\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0359, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.235353597972783\n",
            "SCOPE mean: 0.20694913619042246, SCOPE var: 0.026026391796005202\n",
            "Total Loss: 3.271209962197285\n",
            "----------------------------------------\n",
            "Epoch 117\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0357, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.2166429020514227\n",
            "SCOPE mean: 0.20569706348079808, SCOPE var: 0.025877839721772482\n",
            "Total Loss: 3.252296949321529\n",
            "----------------------------------------\n",
            "Epoch 118\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0355, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.197908860645371\n",
            "SCOPE mean: 0.20509665397479912, SCOPE var: 0.025744036321904997\n",
            "Total Loss: 3.233361044106742\n",
            "----------------------------------------\n",
            "Epoch 119\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0353, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.179142957674379\n",
            "SCOPE mean: 0.20510186835249838, SCOPE var: 0.025623698643502727\n",
            "Total Loss: 3.214394771951509\n",
            "----------------------------------------\n",
            "Epoch 120\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0351, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.1604461957913657\n",
            "SCOPE mean: 0.2056712229855842, SCOPE var: 0.02551563394044184\n",
            "Total Loss: 3.1954984381040075\n",
            "----------------------------------------\n",
            "Epoch 121\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0349, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.1418138257037707\n",
            "SCOPE mean: 0.20676322742583253, SCOPE var: 0.025418854623461544\n",
            "Total Loss: 3.176669159027136\n",
            "----------------------------------------\n",
            "Epoch 122\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0347, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.1232575718398587\n",
            "SCOPE mean: 0.2083234761726446, SCOPE var: 0.025332340869750353\n",
            "Total Loss: 3.157920306156085\n",
            "----------------------------------------\n",
            "Epoch 123\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0345, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.1048055852549563\n",
            "SCOPE mean: 0.21029735974430924, SCOPE var: 0.025255216791025478\n",
            "Total Loss: 3.1392811708480086\n",
            "----------------------------------------\n",
            "Epoch 124\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0343, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.0864715004676486\n",
            "SCOPE mean: 0.21262824382796597, SCOPE var: 0.025186680077671292\n",
            "Total Loss: 3.120766193249076\n",
            "----------------------------------------\n",
            "Epoch 125\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0341, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.06828275126667\n",
            "SCOPE mean: 0.21526016039786736, SCOPE var: 0.025125824912109823\n",
            "Total Loss: 3.1024031033246335\n",
            "----------------------------------------\n",
            "Epoch 126\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0340, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.0502130717837637\n",
            "SCOPE mean: 0.2181382173181955, SCOPE var: 0.025071907002511565\n",
            "Total Loss: 3.084166319035092\n",
            "----------------------------------------\n",
            "Epoch 127\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0338, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.0323005878725278\n",
            "SCOPE mean: 0.22121717933662344, SCOPE var: 0.025023845109676306\n",
            "Total Loss: 3.066093797534165\n",
            "----------------------------------------\n",
            "Epoch 128\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0336, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.014604265443708\n",
            "SCOPE mean: 0.22444182342165722, SCOPE var: 0.02498095928757453\n",
            "Total Loss: 3.048244874451044\n",
            "----------------------------------------\n",
            "Epoch 129\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0335, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.9971100240328608\n",
            "SCOPE mean: 0.22776625606100484, SCOPE var: 0.02494270898496539\n",
            "Total Loss: 3.0306058836168774\n",
            "----------------------------------------\n",
            "Epoch 130\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0334, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.979793046892951\n",
            "SCOPE mean: 0.2311491223197291, SCOPE var: 0.024908533353197627\n",
            "Total Loss: 3.0131525222031836\n",
            "----------------------------------------\n",
            "Epoch 131\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0332, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.962674711599652\n",
            "SCOPE mean: 0.23455641197067967, SCOPE var: 0.024877911255089476\n",
            "Total Loss: 2.995906226130546\n",
            "----------------------------------------\n",
            "Epoch 132\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0331, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.945694072261855\n",
            "SCOPE mean: 0.23799788222761098, SCOPE var: 0.024850272348755833\n",
            "Total Loss: 2.9788044142684846\n",
            "----------------------------------------\n",
            "Epoch 133\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0330, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.9288913388099465\n",
            "SCOPE mean: 0.2414221748876175, SCOPE var: 0.02482498456784332\n",
            "Total Loss: 2.96188718502234\n",
            "----------------------------------------\n",
            "Epoch 134\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0329, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.912257951959927\n",
            "SCOPE mean: 0.24477022782668856, SCOPE var: 0.0248014701111764\n",
            "Total Loss: 2.945145182261792\n",
            "----------------------------------------\n",
            "Epoch 135\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0328, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.8959102579370306\n",
            "SCOPE mean: 0.24801880210043223, SCOPE var: 0.02477921459536205\n",
            "Total Loss: 2.9286991714637765\n",
            "----------------------------------------\n",
            "Epoch 136\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0327, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.8796987428835683\n",
            "SCOPE mean: 0.25113630549616855, SCOPE var: 0.024757619400907344\n",
            "Total Loss: 2.9123945756111467\n",
            "----------------------------------------\n",
            "Epoch 137\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0326, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.8635982716952677\n",
            "SCOPE mean: 0.2541140425527893, SCOPE var: 0.0247357665909245\n",
            "Total Loss: 2.896204936356357\n",
            "----------------------------------------\n",
            "Epoch 138\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0325, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.847674350538695\n",
            "SCOPE mean: 0.25694150680814243, SCOPE var: 0.024713203448630795\n",
            "Total Loss: 2.8801953119120554\n",
            "----------------------------------------\n",
            "Epoch 139\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0324, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.83191969495676\n",
            "SCOPE mean: 0.2596202312410389, SCOPE var: 0.024676061417328716\n",
            "Total Loss: 2.8643584272244813\n",
            "----------------------------------------\n",
            "Epoch 140\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0324, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.816336304464252\n",
            "SCOPE mean: 0.2621429411042892, SCOPE var: 0.02462690478691425\n",
            "Total Loss: 2.848694110303269\n",
            "----------------------------------------\n",
            "Epoch 141\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0323, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.8009139486105967\n",
            "SCOPE mean: 0.2645184392813373, SCOPE var: 0.024577491645855824\n",
            "Total Loss: 2.8331923827064287\n",
            "----------------------------------------\n",
            "Epoch 142\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0322, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.785647282541676\n",
            "SCOPE mean: 0.2667489468875137, SCOPE var: 0.024527675547407066\n",
            "Total Loss: 2.8178482625332957\n",
            "----------------------------------------\n",
            "Epoch 143\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0322, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.770610675020612\n",
            "SCOPE mean: 0.26884076282279534, SCOPE var: 0.024477299691362826\n",
            "Total Loss: 2.8027657169398315\n",
            "----------------------------------------\n",
            "Epoch 144\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0321, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.7556962533050933\n",
            "SCOPE mean: 0.27077136760354437, SCOPE var: 0.02442843960795177\n",
            "Total Loss: 2.787810484221342\n",
            "----------------------------------------\n",
            "Epoch 145\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0321, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.7408789926403263\n",
            "SCOPE mean: 0.27255602444164195, SCOPE var: 0.02438089483825089\n",
            "Total Loss: 2.7729490624462687\n",
            "----------------------------------------\n",
            "Epoch 146\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0320, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.726145763210594\n",
            "SCOPE mean: 0.274204365924667, SCOPE var: 0.024334434237571728\n",
            "Total Loss: 2.7581680438765046\n",
            "----------------------------------------\n",
            "Epoch 147\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0320, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.7114863853763835\n",
            "SCOPE mean: 0.27572710082906177, SCOPE var: 0.024288692103660837\n",
            "Total Loss: 2.7434571065523854\n",
            "----------------------------------------\n",
            "Epoch 148\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0319, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.6969285529930436\n",
            "SCOPE mean: 0.27709849787639784, SCOPE var: 0.024239151628083835\n",
            "Total Loss: 2.728840939881502\n",
            "----------------------------------------\n",
            "Epoch 149\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0319, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.6824387726729406\n",
            "SCOPE mean: 0.27837160932574445, SCOPE var: 0.02419037672878137\n",
            "Total Loss: 2.7142893275756257\n",
            "----------------------------------------\n",
            "Epoch 150\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0318, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.6680149102904935\n",
            "SCOPE mean: 0.27955538111148215, SCOPE var: 0.024142152892322546\n",
            "Total Loss: 2.6998004264382947\n",
            "----------------------------------------\n",
            "Epoch 151\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0317, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.6536560063582137\n",
            "SCOPE mean: 0.2806614565040629, SCOPE var: 0.024094531121785733\n",
            "Total Loss: 2.685373041678749\n",
            "----------------------------------------\n",
            "Epoch 152\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0316, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.639350935965199\n",
            "SCOPE mean: 0.28170241483532565, SCOPE var: 0.024047592401901848\n",
            "Total Loss: 2.670995855552082\n",
            "----------------------------------------\n",
            "Epoch 153\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0316, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.6251132406737074\n",
            "SCOPE mean: 0.2826960425954407, SCOPE var: 0.024000841217382614\n",
            "Total Loss: 2.656680617976548\n",
            "----------------------------------------\n",
            "Epoch 154\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0315, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.610959197804938\n",
            "SCOPE mean: 0.28365252153907206, SCOPE var: 0.023954311742112107\n",
            "Total Loss: 2.6424459317425537\n",
            "----------------------------------------\n",
            "Epoch 155\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0314, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.5968760490376943\n",
            "SCOPE mean: 0.2845825473391589, SCOPE var: 0.023908122007009442\n",
            "Total Loss: 2.6282822176328415\n",
            "----------------------------------------\n",
            "Epoch 156\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0313, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.5828717325978254\n",
            "SCOPE mean: 0.28549399539145626, SCOPE var: 0.023862397351487936\n",
            "Total Loss: 2.614197959850105\n",
            "----------------------------------------\n",
            "Epoch 157\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0312, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.5689469400643024\n",
            "SCOPE mean: 0.2863952663959409, SCOPE var: 0.0238172154162171\n",
            "Total Loss: 2.600193564419938\n",
            "----------------------------------------\n",
            "Epoch 158\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0312, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.555102892175674\n",
            "SCOPE mean: 0.28729298784738455, SCOPE var: 0.023772611273206335\n",
            "Total Loss: 2.5862716462817215\n",
            "----------------------------------------\n",
            "Epoch 159\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0311, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.5413378391464487\n",
            "SCOPE mean: 0.2881975317604266, SCOPE var: 0.023728659793786584\n",
            "Total Loss: 2.572429837755903\n",
            "----------------------------------------\n",
            "Epoch 160\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0310, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.5276507057117703\n",
            "SCOPE mean: 0.2891140088981827, SCOPE var: 0.02368537205177041\n",
            "Total Loss: 2.5586672331657696\n",
            "----------------------------------------\n",
            "Epoch 161\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0309, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.5140407485885414\n",
            "SCOPE mean: 0.2900467699635864, SCOPE var: 0.023642744995925998\n",
            "Total Loss: 2.544983391670314\n",
            "----------------------------------------\n",
            "Epoch 162\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0309, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.5005222451710827\n",
            "SCOPE mean: 0.2910010942323785, SCOPE var: 0.023600629770736563\n",
            "Total Loss: 2.531399317832142\n",
            "----------------------------------------\n",
            "Epoch 163\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0308, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.4870844259706075\n",
            "SCOPE mean: 0.29200516588479597, SCOPE var: 0.02355690406228569\n",
            "Total Loss: 2.5179020775567906\n",
            "----------------------------------------\n",
            "Epoch 164\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0308, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.4737049887148026\n",
            "SCOPE mean: 0.29305534416600704, SCOPE var: 0.02351182836263837\n",
            "Total Loss: 2.504462319530919\n",
            "----------------------------------------\n",
            "Epoch 165\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0307, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.460384717998295\n",
            "SCOPE mean: 0.2941487408838254, SCOPE var: 0.02346568568082271\n",
            "Total Loss: 2.4910809760940884\n",
            "----------------------------------------\n",
            "Epoch 166\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0306, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.4471250169964245\n",
            "SCOPE mean: 0.29528987889341524, SCOPE var: 0.023418405554376232\n",
            "Total Loss: 2.477759528888371\n",
            "----------------------------------------\n",
            "Epoch 167\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0306, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.4339251658297676\n",
            "SCOPE mean: 0.2964782495813583, SCOPE var: 0.02337017678312514\n",
            "Total Loss: 2.464497430357644\n",
            "----------------------------------------\n",
            "Epoch 168\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0305, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.4209677891879506\n",
            "SCOPE mean: 0.29773182733925024, SCOPE var: 0.0233242273648776\n",
            "Total Loss: 2.4514650881592583\n",
            "----------------------------------------\n",
            "Epoch 169\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0304, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.408090027784544\n",
            "SCOPE mean: 0.29897947971519245, SCOPE var: 0.0232775153237786\n",
            "Total Loss: 2.4385134649109976\n",
            "----------------------------------------\n",
            "Epoch 170\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0304, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.3952893660587753\n",
            "SCOPE mean: 0.30022135264310457, SCOPE var: 0.02322987004742745\n",
            "Total Loss: 2.4256414995637403\n",
            "----------------------------------------\n",
            "Epoch 171\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0303, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.382603394575189\n",
            "SCOPE mean: 0.301464727109925, SCOPE var: 0.023181550362357608\n",
            "Total Loss: 2.412886504383205\n",
            "----------------------------------------\n",
            "Epoch 172\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0302, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.370019661048447\n",
            "SCOPE mean: 0.30269535938923975, SCOPE var: 0.023132458983447398\n",
            "Total Loss: 2.4002398517279278\n",
            "----------------------------------------\n",
            "Epoch 173\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0302, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.357515147231517\n",
            "SCOPE mean: 0.30389691984983086, SCOPE var: 0.023084804130739104\n",
            "Total Loss: 2.387678609201905\n",
            "----------------------------------------\n",
            "Epoch 174\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0301, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.345080780372847\n",
            "SCOPE mean: 0.3050750426046997, SCOPE var: 0.023038598031169383\n",
            "Total Loss: 2.375189696415521\n",
            "----------------------------------------\n",
            "Epoch 175\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0301, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.3327129555453845\n",
            "SCOPE mean: 0.30623761331964044, SCOPE var: 0.02299388212891453\n",
            "Total Loss: 2.362769215443553\n",
            "----------------------------------------\n",
            "Epoch 176\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0300, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.320466861023905\n",
            "SCOPE mean: 0.3073863018078854, SCOPE var: 0.02295062629884164\n",
            "Total Loss: 2.3504726675839756\n",
            "----------------------------------------\n",
            "Epoch 177\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0300, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.308297342758029\n",
            "SCOPE mean: 0.3085238863412781, SCOPE var: 0.022908812750503164\n",
            "Total Loss: 2.3382546467881165\n",
            "----------------------------------------\n",
            "Epoch 178\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0299, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.296195417309919\n",
            "SCOPE mean: 0.30965902517657135, SCOPE var: 0.022868479826680797\n",
            "Total Loss: 2.3261058809220265\n",
            "----------------------------------------\n",
            "Epoch 179\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0299, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.284164002555039\n",
            "SCOPE mean: 0.31079820199741764, SCOPE var: 0.02282952459609349\n",
            "Total Loss: 2.3140290171335605\n",
            "----------------------------------------\n",
            "Epoch 180\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0298, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.272214617345383\n",
            "SCOPE mean: 0.31194842617405544, SCOPE var: 0.022791987114513627\n",
            "Total Loss: 2.3020354262384526\n",
            "----------------------------------------\n",
            "Epoch 181\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0298, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.2603754200798014\n",
            "SCOPE mean: 0.3131041593088186, SCOPE var: 0.022756119725573756\n",
            "Total Loss: 2.2901536861737037\n",
            "----------------------------------------\n",
            "Epoch 182\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0297, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.2486212879829495\n",
            "SCOPE mean: 0.3142721130319732, SCOPE var: 0.02272192206505216\n",
            "Total Loss: 2.2783635068547468\n",
            "----------------------------------------\n",
            "Epoch 183\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0297, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.236946884551522\n",
            "SCOPE mean: 0.3154805018187895, SCOPE var: 0.022687341675948824\n",
            "Total Loss: 2.266653118218953\n",
            "----------------------------------------\n",
            "Epoch 184\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0297, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.225350643259451\n",
            "SCOPE mean: 0.3167314258298492, SCOPE var: 0.022652538267425467\n",
            "Total Loss: 2.25502054198011\n",
            "----------------------------------------\n",
            "Epoch 185\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0296, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.213866066697681\n",
            "SCOPE mean: 0.3180187528839738, SCOPE var: 0.022617569346461145\n",
            "Total Loss: 2.243499475115775\n",
            "----------------------------------------\n",
            "Epoch 186\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0296, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.2025806948490056\n",
            "SCOPE mean: 0.3193405479668588, SCOPE var: 0.022582575039615846\n",
            "Total Loss: 2.232186048011262\n",
            "----------------------------------------\n",
            "Epoch 187\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0296, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.19140054301378\n",
            "SCOPE mean: 0.3206253440259314, SCOPE var: 0.022546898560683173\n",
            "Total Loss: 2.2209804058021687\n",
            "----------------------------------------\n",
            "Epoch 188\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0296, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.1803070766386288\n",
            "SCOPE mean: 0.3218928093400967, SCOPE var: 0.02251084033179449\n",
            "Total Loss: 2.2098623592999407\n",
            "----------------------------------------\n",
            "Epoch 189\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0295, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.169312434798162\n",
            "SCOPE mean: 0.32314895319530784, SCOPE var: 0.022474586909648406\n",
            "Total Loss: 2.198844973659451\n",
            "----------------------------------------\n",
            "Epoch 190\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0295, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.1584149313130383\n",
            "SCOPE mean: 0.3243825468907096, SCOPE var: 0.022440480594052657\n",
            "Total Loss: 2.1879302620677956\n",
            "----------------------------------------\n",
            "Epoch 191\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0295, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.1476048241442784\n",
            "SCOPE mean: 0.3256073052466914, SCOPE var: 0.02240858446816437\n",
            "Total Loss: 2.177103578571582\n",
            "----------------------------------------\n",
            "Epoch 192\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0295, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.1368807744499225\n",
            "SCOPE mean: 0.3268381881934648, SCOPE var: 0.02237894658666225\n",
            "Total Loss: 2.166363114647653\n",
            "----------------------------------------\n",
            "Epoch 193\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0295, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.126273214329094\n",
            "SCOPE mean: 0.3280949216554645, SCOPE var: 0.022352072175723065\n",
            "Total Loss: 2.1557365804340884\n",
            "----------------------------------------\n",
            "Epoch 194\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0294, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.1157052382333594\n",
            "SCOPE mean: 0.3294549935973341, SCOPE var: 0.022326674095939126\n",
            "Total Loss: 2.145145365677163\n",
            "----------------------------------------\n",
            "Epoch 195\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0294, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.1051843588314623\n",
            "SCOPE mean: 0.3309100991609248, SCOPE var: 0.022303037446096602\n",
            "Total Loss: 2.1346009110803514\n",
            "----------------------------------------\n",
            "Epoch 196\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0294, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.094699472599823\n",
            "SCOPE mean: 0.3324895889369525, SCOPE var: 0.022278554222813662\n",
            "Total Loss: 2.12409088251663\n",
            "----------------------------------------\n",
            "Epoch 197\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0294, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.0844308699457716\n",
            "SCOPE mean: 0.33418955517989873, SCOPE var: 0.022253421769546932\n",
            "Total Loss: 2.1137963705729717\n",
            "----------------------------------------\n",
            "Epoch 198\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0293, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.074425453449515\n",
            "SCOPE mean: 0.33565230624463993, SCOPE var: 0.02222662253009636\n",
            "Total Loss: 2.1037739463859073\n",
            "----------------------------------------\n",
            "Epoch 199\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0293, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.0645138932446003\n",
            "SCOPE mean: 0.33690729276694065, SCOPE var: 0.02219929652178111\n",
            "Total Loss: 2.0938459204030293\n",
            "----------------------------------------\n",
            "Epoch 200\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0293, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.0546768876553183\n",
            "SCOPE mean: 0.3379056713393655, SCOPE var: 0.022171112389495557\n",
            "Total Loss: 2.0839961190938743\n",
            "----------------------------------------\n",
            "Epoch 201\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0293, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.0449177989105456\n",
            "SCOPE mean: 0.3386999404803228, SCOPE var: 0.022142502019169095\n",
            "Total Loss: 2.074227728798433\n",
            "----------------------------------------\n",
            "Epoch 202\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0293, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.035263927492345\n",
            "SCOPE mean: 0.33934584036761006, SCOPE var: 0.02211407924383456\n",
            "Total Loss: 2.0645667633661415\n",
            "----------------------------------------\n",
            "Epoch 203\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0293, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.0257290477633365\n",
            "SCOPE mean: 0.3399026893347648, SCOPE var: 0.02208651978379258\n",
            "Total Loss: 2.0550257137650165\n",
            "----------------------------------------\n",
            "Epoch 204\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0293, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.0163174127435566\n",
            "SCOPE mean: 0.34042509691151457, SCOPE var: 0.02206043226282435\n",
            "Total Loss: 2.0456075675329157\n",
            "----------------------------------------\n",
            "Epoch 205\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0293, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.007027890230629\n",
            "SCOPE mean: 0.34096340722712815, SCOPE var: 0.022036362463850045\n",
            "Total Loss: 2.036310176745449\n",
            "----------------------------------------\n",
            "Epoch 206\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0293, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.9978667051561274\n",
            "SCOPE mean: 0.34158957865742606, SCOPE var: 0.0220123856962909\n",
            "Total Loss: 2.0271443707077874\n",
            "----------------------------------------\n",
            "Epoch 207\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0293, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.9888091407562454\n",
            "SCOPE mean: 0.34233628695381896, SCOPE var: 0.021989053732720656\n",
            "Total Loss: 2.0180784730869443\n",
            "----------------------------------------\n",
            "Epoch 208\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0293, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.9798819391865157\n",
            "SCOPE mean: 0.343239678971289, SCOPE var: 0.021967364480876217\n",
            "Total Loss: 2.009135188793409\n",
            "----------------------------------------\n",
            "Epoch 209\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0292, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.9710188225629033\n",
            "SCOPE mean: 0.3443598074682248, SCOPE var: 0.021946502306843783\n",
            "Total Loss: 2.000250034502457\n",
            "----------------------------------------\n",
            "Epoch 210\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0292, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.9622094317217964\n",
            "SCOPE mean: 0.3456949512937284, SCOPE var: 0.021926627533570397\n",
            "Total Loss: 1.9914130433204222\n",
            "----------------------------------------\n",
            "Epoch 211\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0292, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.9534527633821357\n",
            "SCOPE mean: 0.34723675085107936, SCOPE var: 0.021907871051487213\n",
            "Total Loss: 1.9826237615655478\n",
            "----------------------------------------\n",
            "Epoch 212\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0291, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.9447554187100649\n",
            "SCOPE mean: 0.34896693701537723, SCOPE var: 0.02189022084369941\n",
            "Total Loss: 1.9738904124587784\n",
            "----------------------------------------\n",
            "Epoch 213\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0291, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.936140651815644\n",
            "SCOPE mean: 0.3508604300856786, SCOPE var: 0.02187382809236663\n",
            "Total Loss: 1.9652351876642669\n",
            "----------------------------------------\n",
            "Epoch 214\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0291, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.927618607301269\n",
            "SCOPE mean: 0.3528355720846018, SCOPE var: 0.021858948011310917\n",
            "Total Loss: 1.9566697902728907\n",
            "----------------------------------------\n",
            "Epoch 215\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0290, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.9191210076709433\n",
            "SCOPE mean: 0.35486060128675756, SCOPE var: 0.021844917562649453\n",
            "Total Loss: 1.9481284837354147\n",
            "----------------------------------------\n",
            "Epoch 216\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0290, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.9106798904731344\n",
            "SCOPE mean: 0.35699653367238404, SCOPE var: 0.021830550253483468\n",
            "Total Loss: 1.9396412269246035\n",
            "----------------------------------------\n",
            "Epoch 217\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0289, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.9023210492428893\n",
            "SCOPE mean: 0.35919517522845446, SCOPE var: 0.02181553464238241\n",
            "Total Loss: 1.931234974100956\n",
            "----------------------------------------\n",
            "Epoch 218\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0289, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.8940508819341089\n",
            "SCOPE mean: 0.36141403803388755, SCOPE var: 0.021799591094830425\n",
            "Total Loss: 1.922916504751721\n",
            "----------------------------------------\n",
            "Epoch 219\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0288, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.885872915325239\n",
            "SCOPE mean: 0.36361245197543923, SCOPE var: 0.02178244450746454\n",
            "Total Loss: 1.914690136604799\n",
            "----------------------------------------\n",
            "Epoch 220\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0288, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.8777845624152187\n",
            "SCOPE mean: 0.36575380884437214, SCOPE var: 0.021763861440880012\n",
            "Total Loss: 1.906553999752599\n",
            "----------------------------------------\n",
            "Epoch 221\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0287, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.8697813098534524\n",
            "SCOPE mean: 0.3678066422169765, SCOPE var: 0.021743653693488157\n",
            "Total Loss: 1.898504176518264\n",
            "----------------------------------------\n",
            "Epoch 222\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0287, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.861849006492401\n",
            "SCOPE mean: 0.36975816097303205, SCOPE var: 0.021721815820470735\n",
            "Total Loss: 1.8905268073761694\n",
            "----------------------------------------\n",
            "Epoch 223\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0286, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.8539827535559634\n",
            "SCOPE mean: 0.3715925475707552, SCOPE var: 0.02169804675813204\n",
            "Total Loss: 1.8826169670022892\n",
            "----------------------------------------\n",
            "Epoch 224\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0286, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.846198103514974\n",
            "SCOPE mean: 0.373301047590815, SCOPE var: 0.021672556069523417\n",
            "Total Loss: 1.8747896553932355\n",
            "----------------------------------------\n",
            "Epoch 225\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0286, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.838484956772508\n",
            "SCOPE mean: 0.37491788494344835, SCOPE var: 0.0216447469636607\n",
            "Total Loss: 1.8670403736694983\n",
            "----------------------------------------\n",
            "Epoch 226\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0285, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.8308381932541764\n",
            "SCOPE mean: 0.376423096250819, SCOPE var: 0.021617479776041938\n",
            "Total Loss: 1.8593631354477942\n",
            "----------------------------------------\n",
            "Epoch 227\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0285, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.8232656421513955\n",
            "SCOPE mean: 0.3777599104258672, SCOPE var: 0.021591053615865278\n",
            "Total Loss: 1.851763190251582\n",
            "----------------------------------------\n",
            "Epoch 228\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0285, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.81575287112155\n",
            "SCOPE mean: 0.3789496631550466, SCOPE var: 0.021565503817795796\n",
            "Total Loss: 1.844226175974657\n",
            "----------------------------------------\n",
            "Epoch 229\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0285, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.8083022063955632\n",
            "SCOPE mean: 0.38001906989370354, SCOPE var: 0.021541228538504625\n",
            "Total Loss: 1.8367538291703795\n",
            "----------------------------------------\n",
            "Epoch 230\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0284, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.8009165928677329\n",
            "SCOPE mean: 0.380998066820476, SCOPE var: 0.021518464192557023\n",
            "Total Loss: 1.8293485180590954\n",
            "----------------------------------------\n",
            "Epoch 231\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0284, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7936005341278516\n",
            "SCOPE mean: 0.3819157646040961, SCOPE var: 0.021497401606034517\n",
            "Total Loss: 1.8220141483680004\n",
            "----------------------------------------\n",
            "Epoch 232\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0284, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7863668684606866\n",
            "SCOPE mean: 0.3828017271093241, SCOPE var: 0.021478349140123594\n",
            "Total Loss: 1.814762177327776\n",
            "----------------------------------------\n",
            "Epoch 233\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0284, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7791997004799214\n",
            "SCOPE mean: 0.38373008434717715, SCOPE var: 0.021460843001465776\n",
            "Total Loss: 1.807575896891394\n",
            "----------------------------------------\n",
            "Epoch 234\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0284, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7722547414530336\n",
            "SCOPE mean: 0.38430810701470325, SCOPE var: 0.02144486217340423\n",
            "Total Loss: 1.8006117770998233\n",
            "----------------------------------------\n",
            "Epoch 235\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0283, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.76518482346468\n",
            "SCOPE mean: 0.38493792163303525, SCOPE var: 0.021424661519429428\n",
            "Total Loss: 1.7935311365446585\n",
            "----------------------------------------\n",
            "Epoch 236\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0283, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7583153241017302\n",
            "SCOPE mean: 0.3849472011710469, SCOPE var: 0.021400985878907788\n",
            "Total Loss: 1.7866605207624175\n",
            "----------------------------------------\n",
            "Epoch 237\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0283, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7515919038866434\n",
            "SCOPE mean: 0.3850776202510273, SCOPE var: 0.021381860876762738\n",
            "Total Loss: 1.779931807817379\n",
            "----------------------------------------\n",
            "Epoch 238\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0283, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7449163963648069\n",
            "SCOPE mean: 0.3855263251642783, SCOPE var: 0.021367723586978315\n",
            "Total Loss: 1.7732453787206413\n",
            "----------------------------------------\n",
            "Epoch 239\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0283, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7382585706567613\n",
            "SCOPE mean: 0.3863042266729939, SCOPE var: 0.021358553104518167\n",
            "Total Loss: 1.7665706018190843\n",
            "----------------------------------------\n",
            "Epoch 240\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0283, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7316102468519532\n",
            "SCOPE mean: 0.3874094461864902, SCOPE var: 0.021354193952336772\n",
            "Total Loss: 1.7599004502086688\n",
            "----------------------------------------\n",
            "Epoch 241\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0283, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7251990053204571\n",
            "SCOPE mean: 0.3882838318940003, SCOPE var: 0.021351227676001887\n",
            "Total Loss: 1.7534698999738896\n",
            "----------------------------------------\n",
            "Epoch 242\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0283, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.718909680540508\n",
            "SCOPE mean: 0.388882209822771, SCOPE var: 0.021343467125693353\n",
            "Total Loss: 1.747164377825986\n",
            "----------------------------------------\n",
            "Epoch 243\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0282, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7126113803127396\n",
            "SCOPE mean: 0.38959436827432337, SCOPE var: 0.021331554950549142\n",
            "Total Loss: 1.740851827543667\n",
            "----------------------------------------\n",
            "Epoch 244\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0282, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7063356629316198\n",
            "SCOPE mean: 0.39040967289937484, SCOPE var: 0.0213161807960954\n",
            "Total Loss: 1.7345634265294343\n",
            "----------------------------------------\n",
            "Epoch 245\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0282, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7001178140601498\n",
            "SCOPE mean: 0.39131032237570795, SCOPE var: 0.021298201676697003\n",
            "Total Loss: 1.7283338752767685\n",
            "----------------------------------------\n",
            "Epoch 246\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0282, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6941352359470025\n",
            "SCOPE mean: 0.39186974704181166, SCOPE var: 0.021278456331404533\n",
            "Total Loss: 1.7223410735103188\n",
            "----------------------------------------\n",
            "Epoch 247\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0282, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6881626301050165\n",
            "SCOPE mean: 0.39271248606507025, SCOPE var: 0.02126455778326982\n",
            "Total Loss: 1.7163494282119436\n",
            "----------------------------------------\n",
            "Epoch 248\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0282, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.682137656671092\n",
            "SCOPE mean: 0.39393304040090654, SCOPE var: 0.021256406665991847\n",
            "Total Loss: 1.7102961149757143\n",
            "----------------------------------------\n",
            "Epoch 249\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0281, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6763157389357621\n",
            "SCOPE mean: 0.3947793168852245, SCOPE var: 0.021246572309907535\n",
            "Total Loss: 1.7044470530275442\n",
            "----------------------------------------\n",
            "Epoch 250\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0281, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6705477444754668\n",
            "SCOPE mean: 0.3956787174638158, SCOPE var: 0.021235461374107416\n",
            "Total Loss: 1.6986518497278922\n",
            "----------------------------------------\n",
            "Epoch 251\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0281, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6648384444296636\n",
            "SCOPE mean: 0.39662081386541864, SCOPE var: 0.021223370578644915\n",
            "Total Loss: 1.692919253440746\n",
            "----------------------------------------\n",
            "Epoch 252\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0281, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6591866308726035\n",
            "SCOPE mean: 0.3975569819111715, SCOPE var: 0.021213173133136063\n",
            "Total Loss: 1.687245702877369\n",
            "----------------------------------------\n",
            "Epoch 253\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0280, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6535949229532216\n",
            "SCOPE mean: 0.39848200509690423, SCOPE var: 0.021204931838790266\n",
            "Total Loss: 1.6816322724444783\n",
            "----------------------------------------\n",
            "Epoch 254\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0280, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.648073106945876\n",
            "SCOPE mean: 0.39939402600787116, SCOPE var: 0.021198714971427855\n",
            "Total Loss: 1.6760875942737001\n",
            "----------------------------------------\n",
            "Epoch 255\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0280, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.64259708437467\n",
            "SCOPE mean: 0.4003314922622028, SCOPE var: 0.021193683135222095\n",
            "Total Loss: 1.6705881140412637\n",
            "----------------------------------------\n",
            "Epoch 256\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0280, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6371902643801166\n",
            "SCOPE mean: 0.40128960189299584, SCOPE var: 0.021190165971950867\n",
            "Total Loss: 1.6651551225304877\n",
            "----------------------------------------\n",
            "Epoch 257\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0279, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6318427297082654\n",
            "SCOPE mean: 0.40222199186844526, SCOPE var: 0.021188426135205267\n",
            "Total Loss: 1.659780803662679\n",
            "----------------------------------------\n",
            "Epoch 258\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0279, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.626552579092404\n",
            "SCOPE mean: 0.4031278821245748, SCOPE var: 0.02118837502870732\n",
            "Total Loss: 1.6544660491792622\n",
            "----------------------------------------\n",
            "Epoch 259\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0279, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6213204257768392\n",
            "SCOPE mean: 0.4040456394893046, SCOPE var: 0.021187349275509106\n",
            "Total Loss: 1.6492082702637658\n",
            "----------------------------------------\n",
            "Epoch 260\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0279, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.616141802325715\n",
            "SCOPE mean: 0.40497426584308394, SCOPE var: 0.021185452788143395\n",
            "Total Loss: 1.6440017236560287\n",
            "----------------------------------------\n",
            "Epoch 261\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0278, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6110154159471162\n",
            "SCOPE mean: 0.4059091270264813, SCOPE var: 0.021182799955479645\n",
            "Total Loss: 1.6388452170111227\n",
            "----------------------------------------\n",
            "Epoch 262\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0278, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.605927494860145\n",
            "SCOPE mean: 0.40684252731604714, SCOPE var: 0.021179400901685106\n",
            "Total Loss: 1.6337249591257117\n",
            "----------------------------------------\n",
            "Epoch 263\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0278, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.600813047277044\n",
            "SCOPE mean: 0.4077629497729416, SCOPE var: 0.021175039440766735\n",
            "Total Loss: 1.6285750006818986\n",
            "----------------------------------------\n",
            "Epoch 264\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0277, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5957480616589115\n",
            "SCOPE mean: 0.40868677875353404, SCOPE var: 0.02117007003278347\n",
            "Total Loss: 1.623474853328898\n",
            "----------------------------------------\n",
            "Epoch 265\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0277, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5907292098972974\n",
            "SCOPE mean: 0.4095732221242416, SCOPE var: 0.02116707712438771\n",
            "Total Loss: 1.6184226169515865\n",
            "----------------------------------------\n",
            "Epoch 266\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0277, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5857547066146391\n",
            "SCOPE mean: 0.41042341397299725, SCOPE var: 0.02116580163612211\n",
            "Total Loss: 1.6134149015110968\n",
            "----------------------------------------\n",
            "Epoch 267\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0276, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5808245876727256\n",
            "SCOPE mean: 0.4112396352710122, SCOPE var: 0.02116597683009949\n",
            "Total Loss: 1.6084518513209503\n",
            "----------------------------------------\n",
            "Epoch 268\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0276, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5759393364678975\n",
            "SCOPE mean: 0.4120251432323888, SCOPE var: 0.021167228071154964\n",
            "Total Loss: 1.603534165434635\n",
            "----------------------------------------\n",
            "Epoch 269\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0276, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5711001666018214\n",
            "SCOPE mean: 0.41278272878930394, SCOPE var: 0.021169457614360326\n",
            "Total Loss: 1.5986652668493615\n",
            "----------------------------------------\n",
            "Epoch 270\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0275, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5663062492999162\n",
            "SCOPE mean: 0.41355235027293874, SCOPE var: 0.021169897171637028\n",
            "Total Loss: 1.5938412748458775\n",
            "----------------------------------------\n",
            "Epoch 271\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0275, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5615643240534178\n",
            "SCOPE mean: 0.41433247905692394, SCOPE var: 0.021168615991250625\n",
            "Total Loss: 1.589068151662485\n",
            "----------------------------------------\n",
            "Epoch 272\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0275, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5568642211568722\n",
            "SCOPE mean: 0.4151320292835694, SCOPE var: 0.021165445021056658\n",
            "Total Loss: 1.5843354969187327\n",
            "----------------------------------------\n",
            "Epoch 273\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0274, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5522081943694361\n",
            "SCOPE mean: 0.41591042884585383, SCOPE var: 0.021163085880119253\n",
            "Total Loss: 1.5796499915328859\n",
            "----------------------------------------\n",
            "Epoch 274\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0274, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5475939264626153\n",
            "SCOPE mean: 0.41666642406967497, SCOPE var: 0.02116147507494008\n",
            "Total Loss: 1.5750072691932637\n",
            "----------------------------------------\n",
            "Epoch 275\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0274, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.543022143254885\n",
            "SCOPE mean: 0.41740196364446785, SCOPE var: 0.021160514247251808\n",
            "Total Loss: 1.5704079921036178\n",
            "----------------------------------------\n",
            "Epoch 276\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0274, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.538496666231257\n",
            "SCOPE mean: 0.4181245033916279, SCOPE var: 0.021159450900704074\n",
            "Total Loss: 1.5658556043153897\n",
            "----------------------------------------\n",
            "Epoch 277\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0273, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5340123034538165\n",
            "SCOPE mean: 0.41883227952010227, SCOPE var: 0.021158350311295853\n",
            "Total Loss: 1.5613447957826843\n",
            "----------------------------------------\n",
            "Epoch 278\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0273, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5295682837031082\n",
            "SCOPE mean: 0.41952350358825713, SCOPE var: 0.021157286113677974\n",
            "Total Loss: 1.5568746655536838\n",
            "----------------------------------------\n",
            "Epoch 279\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0273, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.525162145484804\n",
            "SCOPE mean: 0.4201976104178746, SCOPE var: 0.021156352718114727\n",
            "Total Loss: 1.5524426612964661\n",
            "----------------------------------------\n",
            "Epoch 280\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0273, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5207923809466735\n",
            "SCOPE mean: 0.42085689557055084, SCOPE var: 0.021155689126229168\n",
            "Total Loss: 1.5480472651672823\n",
            "----------------------------------------\n",
            "Epoch 281\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0272, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5164612469550596\n",
            "SCOPE mean: 0.42150098790528845, SCOPE var: 0.021155105513172102\n",
            "Total Loss: 1.5436905997004131\n",
            "----------------------------------------\n",
            "Epoch 282\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0272, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5121680306142948\n",
            "SCOPE mean: 0.4221281397339387, SCOPE var: 0.02115466676521303\n",
            "Total Loss: 1.539371848408014\n",
            "----------------------------------------\n",
            "Epoch 283\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0272, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5079120644994035\n",
            "SCOPE mean: 0.42273693733650664, SCOPE var: 0.021154421625470758\n",
            "Total Loss: 1.5350902657218402\n",
            "----------------------------------------\n",
            "Epoch 284\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0272, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.503692959511493\n",
            "SCOPE mean: 0.42332635896819565, SCOPE var: 0.02115440045038294\n",
            "Total Loss: 1.5308454128034832\n",
            "----------------------------------------\n",
            "Epoch 285\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0271, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4995135869017149\n",
            "SCOPE mean: 0.42390265227854795, SCOPE var: 0.02115468721467833\n",
            "Total Loss: 1.526640292516591\n",
            "----------------------------------------\n",
            "Epoch 286\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0271, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4953665627869228\n",
            "SCOPE mean: 0.4244653643484038, SCOPE var: 0.021155276558350027\n",
            "Total Loss: 1.5224675537761023\n",
            "----------------------------------------\n",
            "Epoch 287\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0271, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.491251410894874\n",
            "SCOPE mean: 0.42502668502281976, SCOPE var: 0.02115483865055283\n",
            "Total Loss: 1.518326401527787\n",
            "----------------------------------------\n",
            "Epoch 288\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0270, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.487169713648025\n",
            "SCOPE mean: 0.42558419629657374, SCOPE var: 0.0211534795518348\n",
            "Total Loss: 1.5142184449893836\n",
            "----------------------------------------\n",
            "Epoch 289\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0270, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.483123571745609\n",
            "SCOPE mean: 0.42613488719065773, SCOPE var: 0.021151302486060366\n",
            "Total Loss: 1.5101458420142366\n",
            "----------------------------------------\n",
            "Epoch 290\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0270, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4791120573338723\n",
            "SCOPE mean: 0.42667543386686885, SCOPE var: 0.021148415266144725\n",
            "Total Loss: 1.5061077017897637\n",
            "----------------------------------------\n",
            "Epoch 291\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0270, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4751346295328138\n",
            "SCOPE mean: 0.42720375998172166, SCOPE var: 0.021144932748043556\n",
            "Total Loss: 1.5021035688726567\n",
            "----------------------------------------\n",
            "Epoch 292\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0269, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.471188653156589\n",
            "SCOPE mean: 0.42771799471859506, SCOPE var: 0.021140791987350187\n",
            "Total Loss: 1.498130824963971\n",
            "----------------------------------------\n",
            "Epoch 293\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0269, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4672747562596484\n",
            "SCOPE mean: 0.42821564817528796, SCOPE var: 0.02113608907082935\n",
            "Total Loss: 1.4941901220918747\n",
            "----------------------------------------\n",
            "Epoch 294\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0269, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4633952236715255\n",
            "SCOPE mean: 0.428693899647398, SCOPE var: 0.021130916782124236\n",
            "Total Loss: 1.4902837355194003\n",
            "----------------------------------------\n",
            "Epoch 295\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0269, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4595494483944378\n",
            "SCOPE mean: 0.42916107518174984, SCOPE var: 0.021125140032092298\n",
            "Total Loss: 1.4864110619638002\n",
            "----------------------------------------\n",
            "Epoch 296\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0268, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4557550948442026\n",
            "SCOPE mean: 0.4296132085997592, SCOPE var: 0.021118875208181932\n",
            "Total Loss: 1.482589945245201\n",
            "----------------------------------------\n",
            "Epoch 297\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0268, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4519913121525496\n",
            "SCOPE mean: 0.43007144276869214, SCOPE var: 0.021111494065047857\n",
            "Total Loss: 1.4788002249751995\n",
            "----------------------------------------\n",
            "Epoch 298\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0268, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4482578201729015\n",
            "SCOPE mean: 0.4305299522303678, SCOPE var: 0.021103226268439725\n",
            "Total Loss: 1.4750414548629736\n",
            "----------------------------------------\n",
            "Epoch 299\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0268, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4445550800691618\n",
            "SCOPE mean: 0.43098261449957465, SCOPE var: 0.021094328437501673\n",
            "Total Loss: 1.4713138806188863\n",
            "----------------------------------------\n",
            "Epoch 300\n",
            "IS mean: 0.3930144894842784,IS variance: 0.01232476689934019\n",
            "SCOPE Var loss:  tensor(0.0267, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4408837111930262\n",
            "SCOPE mean: 0.431423302684022, SCOPE var: 0.02108506823492009\n",
            "Total Loss: 1.4676178781121065\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[ 0.2683, -0.0082],\n",
            "        [ 0.5658, -0.5158],\n",
            "        [ 0.2280, -0.3426],\n",
            "        [-0.6795, -0.5101],\n",
            "        [ 0.4237, -0.5255],\n",
            "        [ 0.2439, -0.3146],\n",
            "        [-0.1319,  0.1526],\n",
            "        [ 0.1255, -0.4886],\n",
            "        [-0.0673, -0.0474],\n",
            "        [ 0.1380,  0.0963]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([ 0.3939, -0.3511, -0.1922, -0.2926, -0.1087, -0.4182, -0.0928, -0.6843,\n",
            "         0.5291,  0.1348], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[ 1.7528e-02,  1.7396e-01, -9.2170e-02, -2.9890e-01, -5.4587e-02,\n",
            "         -1.4067e-01,  1.5013e-01, -7.8734e-02,  5.5488e-01, -7.5029e-02],\n",
            "        [ 1.5357e-01,  8.2677e-02, -3.3110e-01,  7.5220e-03, -2.5472e-01,\n",
            "         -1.1834e-01,  1.6128e-01, -6.8008e-02, -3.8038e-01, -2.5901e-01],\n",
            "        [ 1.3892e-01,  1.1859e-01,  2.4317e-02, -1.3855e-02,  2.8720e-02,\n",
            "          2.0126e-01, -1.5118e-01,  1.7491e-01, -2.9616e-01, -2.6000e-01],\n",
            "        [-1.8032e-01, -2.7714e-01, -3.6548e-01,  2.8875e-01,  2.4952e-01,\n",
            "         -2.5807e-01, -1.3266e-01, -2.7735e-01, -7.3262e-02, -3.2659e-02],\n",
            "        [ 3.1458e-02,  1.1915e-01, -1.5769e-01,  1.4222e-01,  1.6911e-01,\n",
            "         -3.1896e-01,  4.8320e-02,  2.7925e-01, -6.4890e-01, -3.3015e-01],\n",
            "        [ 3.4321e-02,  2.0803e-01, -2.2240e-01,  2.5195e-01,  1.3447e-01,\n",
            "         -2.1624e-01,  1.6331e-01,  1.3809e-01,  2.5341e-01,  9.2162e-03],\n",
            "        [-2.5572e-01,  1.5638e-01, -3.6290e-01, -2.4351e-01, -2.0262e-01,\n",
            "         -3.7468e-01, -9.9716e-02,  3.2281e-02, -5.9516e-01,  1.5447e-01],\n",
            "        [-3.0598e-01,  4.4537e-02, -3.0849e-01,  7.3063e-02,  6.4691e-02,\n",
            "          2.5388e-01,  1.0197e-01, -1.8247e-01,  1.6363e-02,  2.0747e-01],\n",
            "        [ 4.4732e-03, -1.8802e-02,  6.0544e-04, -1.1160e-01,  1.6055e-01,\n",
            "         -6.2247e-02,  2.1361e-01, -2.0471e-01,  6.4829e-01,  2.0612e-01],\n",
            "        [ 7.6621e-02, -2.1017e-01, -1.3490e-01, -1.1775e-01,  1.3611e-01,\n",
            "         -1.8010e-01, -4.0740e-02,  7.5174e-02,  5.7812e-01,  6.0749e-02]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([ 0.3155, -0.2183, -0.1472, -0.2229,  0.2145,  0.2684,  0.1874, -0.3612,\n",
            "         0.0110,  0.1451], dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[ 0.2586, -0.1521, -0.0467, -0.0990, -0.0779,  0.3562, -0.1194, -0.2332,\n",
            "          0.2363,  0.4965]], dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([-0.1397], dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomizableFeatureNet(\n",
              "  (hidden_layers): ModuleList(\n",
              "    (0): Linear(in_features=2, out_features=10, bias=True)\n",
              "    (1): Linear(in_features=10, out_features=10, bias=True)\n",
              "  )\n",
              "  (output_layer): Linear(in_features=10, out_features=1, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b_1000_mse = action_probs_top_n_epsilon(q_table, 1, 0.4)\n",
        "pi_b_1000_mse = experiment_actions(1000, env_50, P_pi_b_1000_mse)\n",
        "P_pi_e_1000 = action_probs_top_n_epsilon(q_table, 1, 0.05)\n",
        "pi_e_1000 = experiment_actions(1000, env_50, P_pi_e_1000)\n",
        "# model_1000_random_pi_b_1000_mse = CustomizableFeatureNet(input_dim=2, hidden_dims=[16, 16], output_dim=1, dtype = torch.float64, l2_lambda=0.002)\n",
        "model_1000_random_pi_b_1000_mse = NN_l1_l2_reg(input_dim=2, hidden_dims=[16, 16], output_dim=1, dtype = torch.float64, l1_lambda=0.0001, l2_lambda = 0.0001)\n",
        "test_1000_random_pi_b_1000_mse = SCOPE_straight(model_1000_random_pi_b_1000_mse, 0.99, 10000, pi_b_1000_mse, P_pi_b_1000_mse, P_pi_e_1000, 0.3, dtype = torch.float64)\n",
        "test_1000_random_pi_b_1000_mse.train_var_scope(300, 0.001, 1, 0.25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4ffb65e-714f-4794-85fa-535c8d289ad5",
        "id": "qxUc-4kYGL2-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0875, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.725384057721419\n",
            "SCOPE mean: 1.1199675594962764, SCOPE var: 0.23508798774489986\n",
            "Total Loss: 2.0188408086472145\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0873, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.469155030957495\n",
            "SCOPE mean: 1.1290194914259117, SCOPE var: 0.23862165890666512\n",
            "Total Loss: 1.9546099559807464\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0881, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.189022368268439\n",
            "SCOPE mean: 1.1373710890824933, SCOPE var: 0.24198196383120613\n",
            "Total Loss: 1.8853453551105308\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0886, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.919124181822893\n",
            "SCOPE mean: 1.1456551696073078, SCOPE var: 0.24535992265251244\n",
            "Total Loss: 1.8183748081213489\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0893, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.657430806372566\n",
            "SCOPE mean: 1.1539927663683012, SCOPE var: 0.24883317186171797\n",
            "Total Loss: 1.7536246890485272\n",
            "----------------------------------------\n",
            "Epoch 6\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0899, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.404394960233831\n",
            "SCOPE mean: 1.1620195518131815, SCOPE var: 0.2523503513503993\n",
            "Total Loss: 1.6910119872449363\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0905, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.159485826878838\n",
            "SCOPE mean: 1.1688001213652048, SCOPE var: 0.25586271355035617\n",
            "Total Loss: 1.6303543933142088\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0910, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.923203080370439\n",
            "SCOPE mean: 1.1753172244256984, SCOPE var: 0.25936007732938626\n",
            "Total Loss: 1.5718163629941266\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0915, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.695798582557353\n",
            "SCOPE mean: 1.181651454468854, SCOPE var: 0.26285062499998263\n",
            "Total Loss: 1.515470168909591\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0920, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.476360813103843\n",
            "SCOPE mean: 1.1877516803582913, SCOPE var: 0.26634547824682114\n",
            "Total Loss: 1.4611268826420973\n",
            "----------------------------------------\n",
            "Epoch 11\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0926, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.2653765048312335\n",
            "SCOPE mean: 1.1936346972335756, SCOPE var: 0.26986217143230695\n",
            "Total Loss: 1.408910437793852\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0931, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.063298960345697\n",
            "SCOPE mean: 1.1995242570642324, SCOPE var: 0.27342378192339023\n",
            "Total Loss: 1.3589095992551874\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0937, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.868969368912355\n",
            "SCOPE mean: 1.2054296013425023, SCOPE var: 0.2769211235110694\n",
            "Total Loss: 1.3109583303909764\n",
            "----------------------------------------\n",
            "Epoch 14\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0943, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.683285685118759\n",
            "SCOPE mean: 1.2113649410563065, SCOPE var: 0.2802929094737675\n",
            "Total Loss: 1.265167361996455\n",
            "----------------------------------------\n",
            "Epoch 15\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0950, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.506694130003006\n",
            "SCOPE mean: 1.2170844726582888, SCOPE var: 0.2836274047947979\n",
            "Total Loss: 1.2216339097665838\n",
            "----------------------------------------\n",
            "Epoch 16\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0956, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.3390671873212066\n",
            "SCOPE mean: 1.22257433390029, SCOPE var: 0.28691949809017314\n",
            "Total Loss: 1.1803276040327129\n",
            "----------------------------------------\n",
            "Epoch 17\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0962, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.1806637987225335\n",
            "SCOPE mean: 1.2278250498857244, SCOPE var: 0.2901601125743319\n",
            "Total Loss: 1.1413308058559408\n",
            "----------------------------------------\n",
            "Epoch 18\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0968, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.031354609041594\n",
            "SCOPE mean: 1.2328733554491698, SCOPE var: 0.2933595459760284\n",
            "Total Loss: 1.1046348565445074\n",
            "----------------------------------------\n",
            "Epoch 19\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0974, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.89137557619725\n",
            "SCOPE mean: 1.2376979407978683, SCOPE var: 0.29650951358058913\n",
            "Total Loss: 1.0702779657390489\n",
            "----------------------------------------\n",
            "Epoch 20\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0982, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.7605642660333616\n",
            "SCOPE mean: 1.242348773051016, SCOPE var: 0.2996153024562884\n",
            "Total Loss: 1.0383076663932858\n",
            "----------------------------------------\n",
            "Epoch 21\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0989, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.6386465610970844\n",
            "SCOPE mean: 1.2467095818371674, SCOPE var: 0.3026177867866657\n",
            "Total Loss: 1.0086003685475757\n",
            "----------------------------------------\n",
            "Epoch 22\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0997, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.5258651304198323\n",
            "SCOPE mean: 1.2507930658092252, SCOPE var: 0.3055205790551352\n",
            "Total Loss: 0.9811304836266983\n",
            "----------------------------------------\n",
            "Epoch 23\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.1003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.4220400015998296\n",
            "SCOPE mean: 1.2546141873873167, SCOPE var: 0.3083132997265356\n",
            "Total Loss: 0.9558369181784846\n",
            "----------------------------------------\n",
            "Epoch 24\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.1009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.3263509029177416\n",
            "SCOPE mean: 1.2581298423158722, SCOPE var: 0.3109513579251218\n",
            "Total Loss: 0.9325190601380645\n",
            "----------------------------------------\n",
            "Epoch 25\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.1015, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.2389009488352856\n",
            "SCOPE mean: 1.261380981492068, SCOPE var: 0.3134375313664136\n",
            "Total Loss: 0.9112712041297713\n",
            "----------------------------------------\n",
            "Epoch 26\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.1021, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.159808475553185\n",
            "SCOPE mean: 1.2643383858030708, SCOPE var: 0.315768359305807\n",
            "Total Loss: 0.8920686679261713\n",
            "----------------------------------------\n",
            "Epoch 27\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.1026, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.0889538337163525\n",
            "SCOPE mean: 1.266958902121008, SCOPE var: 0.3178976009509407\n",
            "Total Loss: 0.8748524162845275\n",
            "----------------------------------------\n",
            "Epoch 28\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.1030, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.025555830368551\n",
            "SCOPE mean: 1.2693644829297792, SCOPE var: 0.3198606280440222\n",
            "Total Loss: 0.8593543114770468\n",
            "----------------------------------------\n",
            "Epoch 29\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.1033, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.9689512102866873\n",
            "SCOPE mean: 1.2715422286381337, SCOPE var: 0.32166107269193567\n",
            "Total Loss: 0.845523998412838\n",
            "----------------------------------------\n",
            "Epoch 30\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.1035, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.918657149351657\n",
            "SCOPE mean: 1.273478011361511, SCOPE var: 0.32327716727011074\n",
            "Total Loss: 0.8332098049426413\n",
            "----------------------------------------\n",
            "Epoch 31\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.1037, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.874029995641897\n",
            "SCOPE mean: 1.2752037057848529, SCOPE var: 0.32466577926407986\n",
            "Total Loss: 0.8222361093092136\n",
            "----------------------------------------\n",
            "Epoch 32\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.1038, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.834456225564337\n",
            "SCOPE mean: 1.2767430869070064, SCOPE var: 0.3258554883233211\n",
            "Total Loss: 0.8124353444701382\n",
            "----------------------------------------\n",
            "Epoch 33\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.1039, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.7992897441911557\n",
            "SCOPE mean: 1.2780891466086945, SCOPE var: 0.32685072629019035\n",
            "Total Loss: 0.8036967015780131\n",
            "----------------------------------------\n",
            "Epoch 34\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.1038, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.767472298977572\n",
            "SCOPE mean: 1.2792425007250396, SCOPE var: 0.3276436268130259\n",
            "Total Loss: 0.7957136289740321\n",
            "----------------------------------------\n",
            "Epoch 35\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.1037, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.7384093373642844\n",
            "SCOPE mean: 1.28020078949913, SCOPE var: 0.32822751289031527\n",
            "Total Loss: 0.7883405833433458\n",
            "----------------------------------------\n",
            "Epoch 36\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.1035, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.7114862180369945\n",
            "SCOPE mean: 1.2809533882460378, SCOPE var: 0.32860445648176645\n",
            "Total Loss: 0.7814087943948004\n",
            "----------------------------------------\n",
            "Epoch 37\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.1033, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.6864270702954376\n",
            "SCOPE mean: 1.281489360925987, SCOPE var: 0.32879429602032534\n",
            "Total Loss: 0.7748604254548084\n",
            "----------------------------------------\n",
            "Epoch 38\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.1029, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.6627428948869745\n",
            "SCOPE mean: 1.2818448254760806, SCOPE var: 0.32879088987611693\n",
            "Total Loss: 0.7686265872331202\n",
            "----------------------------------------\n",
            "Epoch 39\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.1026, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.639886711414432\n",
            "SCOPE mean: 1.2820262122277577, SCOPE var: 0.32859274276500816\n",
            "Total Loss: 0.762526422672206\n",
            "----------------------------------------\n",
            "Epoch 40\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.1021, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.6174757078435085\n",
            "SCOPE mean: 1.2820253169694569, SCOPE var: 0.3281981931988181\n",
            "Total Loss: 0.75643446817356\n",
            "----------------------------------------\n",
            "Epoch 41\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.1015, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.595378536968423\n",
            "SCOPE mean: 1.281847420657225, SCOPE var: 0.3276204162654794\n",
            "Total Loss: 0.7503406493642014\n",
            "----------------------------------------\n",
            "Epoch 42\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.1008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.573333055474259\n",
            "SCOPE mean: 1.2814958908170877, SCOPE var: 0.32686857989472307\n",
            "Total Loss: 0.74417122150365\n",
            "----------------------------------------\n",
            "Epoch 43\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.1001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.551261867643062\n",
            "SCOPE mean: 1.2809232896997267, SCOPE var: 0.3259493930803325\n",
            "Total Loss: 0.7379027151790017\n",
            "----------------------------------------\n",
            "Epoch 44\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0993, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.529038717981804\n",
            "SCOPE mean: 1.280148894892205, SCOPE var: 0.3248705661218944\n",
            "Total Loss: 0.7315198723890778\n",
            "----------------------------------------\n",
            "Epoch 45\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0984, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.5062880103439498\n",
            "SCOPE mean: 1.2791795330521163, SCOPE var: 0.3236241436445701\n",
            "Total Loss: 0.7249482757501972\n",
            "----------------------------------------\n",
            "Epoch 46\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0974, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.4828936542481315\n",
            "SCOPE mean: 1.2780785083754431, SCOPE var: 0.3222182462507786\n",
            "Total Loss: 0.7181512512900458\n",
            "----------------------------------------\n",
            "Epoch 47\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0964, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.459365683071685\n",
            "SCOPE mean: 1.276558900742, SCOPE var: 0.32068915698356026\n",
            "Total Loss: 0.711259229325484\n",
            "----------------------------------------\n",
            "Epoch 48\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0953, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.435717520029354\n",
            "SCOPE mean: 1.2743319764998373, SCOPE var: 0.3190297256031619\n",
            "Total Loss: 0.7042225048579877\n",
            "----------------------------------------\n",
            "Epoch 49\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0941, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.411900247953144\n",
            "SCOPE mean: 1.2718186082276792, SCOPE var: 0.3172303397112143\n",
            "Total Loss: 0.6971040615255244\n",
            "----------------------------------------\n",
            "Epoch 50\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0930, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.3878850902007285\n",
            "SCOPE mean: 1.2692193469731134, SCOPE var: 0.3152999817986562\n",
            "Total Loss: 0.6899282606128944\n",
            "----------------------------------------\n",
            "Epoch 51\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0917, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.364266258814163\n",
            "SCOPE mean: 1.2665475414066298, SCOPE var: 0.3133025489545967\n",
            "Total Loss: 0.6828145401772585\n",
            "----------------------------------------\n",
            "Epoch 52\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0905, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.341029666909053\n",
            "SCOPE mean: 1.2637995124791679, SCOPE var: 0.3112475061322441\n",
            "Total Loss: 0.6757996045461806\n",
            "----------------------------------------\n",
            "Epoch 53\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0893, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.3179820274280085\n",
            "SCOPE mean: 1.2610005496736016, SCOPE var: 0.3091486624247509\n",
            "Total Loss: 0.6688050141441285\n",
            "----------------------------------------\n",
            "Epoch 54\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0881, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.2953412618002056\n",
            "SCOPE mean: 1.2581406526886487, SCOPE var: 0.30700864519893045\n",
            "Total Loss: 0.6619030239035963\n",
            "----------------------------------------\n",
            "Epoch 55\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0868, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.2727128857044\n",
            "SCOPE mean: 1.25536730730828, SCOPE var: 0.3048337210654495\n",
            "Total Loss: 0.6550181305100271\n",
            "----------------------------------------\n",
            "Epoch 56\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0856, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.2503310721912446\n",
            "SCOPE mean: 1.252645609040763, SCOPE var: 0.3026382359255063\n",
            "Total Loss: 0.6482243911037171\n",
            "----------------------------------------\n",
            "Epoch 57\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0845, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.2283651904114565\n",
            "SCOPE mean: 1.2498797699388666, SCOPE var: 0.30043329915976325\n",
            "Total Loss: 0.6415591884834517\n",
            "----------------------------------------\n",
            "Epoch 58\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0833, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.2068937552500643\n",
            "SCOPE mean: 1.247061341794734, SCOPE var: 0.2982239062383341\n",
            "Total Loss: 0.6350120342618736\n",
            "----------------------------------------\n",
            "Epoch 59\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0821, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.185960194652755\n",
            "SCOPE mean: 1.244087654599278, SCOPE var: 0.2959630758730396\n",
            "Total Loss: 0.628615298451089\n",
            "----------------------------------------\n",
            "Epoch 60\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0810, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.1657846891098482\n",
            "SCOPE mean: 1.2410366896916514, SCOPE var: 0.2937021610403078\n",
            "Total Loss: 0.6224423894101214\n",
            "----------------------------------------\n",
            "Epoch 61\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0799, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.146498321968887\n",
            "SCOPE mean: 1.2379768451879902, SCOPE var: 0.29144946600882476\n",
            "Total Loss: 0.6165132349237743\n",
            "----------------------------------------\n",
            "Epoch 62\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0788, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.1278727063928486\n",
            "SCOPE mean: 1.2349218543378184, SCOPE var: 0.28920565415942584\n",
            "Total Loss: 0.6107855340067058\n",
            "----------------------------------------\n",
            "Epoch 63\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0777, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.1093527676008255\n",
            "SCOPE mean: 1.2313832137706864, SCOPE var: 0.2869769948639587\n",
            "Total Loss: 0.605087804732211\n",
            "----------------------------------------\n",
            "Epoch 64\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0767, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.091532999426735\n",
            "SCOPE mean: 1.2271665266908411, SCOPE var: 0.2847501787602081\n",
            "Total Loss: 0.5996191202579351\n",
            "----------------------------------------\n",
            "Epoch 65\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0757, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.074127779043932\n",
            "SCOPE mean: 1.2229304934392493, SCOPE var: 0.28254065101729936\n",
            "Total Loss: 0.5942780792439016\n",
            "----------------------------------------\n",
            "Epoch 66\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0748, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.0570631276493843\n",
            "SCOPE mean: 1.2186705759234417, SCOPE var: 0.2803419644347841\n",
            "Total Loss: 0.5890465537548512\n",
            "----------------------------------------\n",
            "Epoch 67\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0738, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.0402000235892306\n",
            "SCOPE mean: 1.2144328350000257, SCOPE var: 0.2781646175959957\n",
            "Total Loss: 0.583886516964231\n",
            "----------------------------------------\n",
            "Epoch 68\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0730, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.0234941888370415\n",
            "SCOPE mean: 1.2104281876956733, SCOPE var: 0.2761256394089188\n",
            "Total Loss: 0.578825164467092\n",
            "----------------------------------------\n",
            "Epoch 69\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0721, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.007199943775898\n",
            "SCOPE mean: 1.2064333041380888, SCOPE var: 0.2741225153832313\n",
            "Total Loss: 0.573874061803831\n",
            "----------------------------------------\n",
            "Epoch 70\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0712, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.991197664645991\n",
            "SCOPE mean: 1.2023831294623424, SCOPE var: 0.272132407270809\n",
            "Total Loss: 0.569010032595155\n",
            "----------------------------------------\n",
            "Epoch 71\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0704, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.9753906104819656\n",
            "SCOPE mean: 1.1982406531029357, SCOPE var: 0.270154953128055\n",
            "Total Loss: 0.5642666816355943\n",
            "----------------------------------------\n",
            "Epoch 72\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0696, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.959856931123124\n",
            "SCOPE mean: 1.1939473216406105, SCOPE var: 0.2681673747011824\n",
            "Total Loss: 0.5596103658966877\n",
            "----------------------------------------\n",
            "Epoch 73\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0689, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.9446009996630664\n",
            "SCOPE mean: 1.1895519038055504, SCOPE var: 0.266172830196164\n",
            "Total Loss: 0.5550172009931054\n",
            "----------------------------------------\n",
            "Epoch 74\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0681, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.929508677239622\n",
            "SCOPE mean: 1.1850904824490935, SCOPE var: 0.26418154166506386\n",
            "Total Loss: 0.5504724659113384\n",
            "----------------------------------------\n",
            "Epoch 75\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0673, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.9145712896346851\n",
            "SCOPE mean: 1.180572951445243, SCOPE var: 0.26219665857877716\n",
            "Total Loss: 0.5459644205508054\n",
            "----------------------------------------\n",
            "Epoch 76\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0666, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.899834685980984\n",
            "SCOPE mean: 1.1759601496839682, SCOPE var: 0.26021186762841325\n",
            "Total Loss: 0.5415275919642449\n",
            "----------------------------------------\n",
            "Epoch 77\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0658, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.8853045921048397\n",
            "SCOPE mean: 1.1713826957429272, SCOPE var: 0.2582612194919084\n",
            "Total Loss: 0.5371669674963853\n",
            "----------------------------------------\n",
            "Epoch 78\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0651, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.8708458001561181\n",
            "SCOPE mean: 1.1668414780136755, SCOPE var: 0.25633468437727036\n",
            "Total Loss: 0.5328301055630685\n",
            "----------------------------------------\n",
            "Epoch 79\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0644, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.8565643609503495\n",
            "SCOPE mean: 1.162344603998951, SCOPE var: 0.25443987645404176\n",
            "Total Loss: 0.5285394918587363\n",
            "----------------------------------------\n",
            "Epoch 80\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0637, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.8425130110465848\n",
            "SCOPE mean: 1.1578383467708997, SCOPE var: 0.2525578563922364\n",
            "Total Loss: 0.5243048417300314\n",
            "----------------------------------------\n",
            "Epoch 81\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0630, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.8287493340999272\n",
            "SCOPE mean: 1.1530767567873819, SCOPE var: 0.25060715326918687\n",
            "Total Loss: 0.5201521728207879\n",
            "----------------------------------------\n",
            "Epoch 82\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0623, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.815201360480779\n",
            "SCOPE mean: 1.1483632374174737, SCOPE var: 0.24868879816482126\n",
            "Total Loss: 0.5160564788182793\n",
            "----------------------------------------\n",
            "Epoch 83\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0616, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.8018024042027831\n",
            "SCOPE mean: 1.1436952810407812, SCOPE var: 0.24681078022717476\n",
            "Total Loss: 0.5120361175304624\n",
            "----------------------------------------\n",
            "Epoch 84\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0609, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7885959810062255\n",
            "SCOPE mean: 1.1395622794003342, SCOPE var: 0.24491569311084438\n",
            "Total Loss: 0.5080756101697013\n",
            "----------------------------------------\n",
            "Epoch 85\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0602, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.775682399461213\n",
            "SCOPE mean: 1.1356019147926837, SCOPE var: 0.24304416406523877\n",
            "Total Loss: 0.5041467545175402\n",
            "----------------------------------------\n",
            "Epoch 86\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0595, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7629128115333557\n",
            "SCOPE mean: 1.1316921011929142, SCOPE var: 0.24120033788419093\n",
            "Total Loss: 0.5002325323806998\n",
            "----------------------------------------\n",
            "Epoch 87\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0588, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7502987646172778\n",
            "SCOPE mean: 1.1281507879821195, SCOPE var: 0.23951155860498013\n",
            "Total Loss: 0.49636412032037214\n",
            "----------------------------------------\n",
            "Epoch 88\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0581, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7379100160709382\n",
            "SCOPE mean: 1.1248023153005813, SCOPE var: 0.23791410961677725\n",
            "Total Loss: 0.4925621187184166\n",
            "----------------------------------------\n",
            "Epoch 89\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0574, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7257162396797745\n",
            "SCOPE mean: 1.1215404467279384, SCOPE var: 0.23634377810928678\n",
            "Total Loss: 0.48881016362044133\n",
            "----------------------------------------\n",
            "Epoch 90\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0567, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7137255772532425\n",
            "SCOPE mean: 1.1184506900811768, SCOPE var: 0.23483057204175464\n",
            "Total Loss: 0.48510639336045897\n",
            "----------------------------------------\n",
            "Epoch 91\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0560, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7019683433609434\n",
            "SCOPE mean: 1.116462710330841, SCOPE var: 0.2337586880663136\n",
            "Total Loss: 0.4814726079083531\n",
            "----------------------------------------\n",
            "Epoch 92\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0553, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6904079843148516\n",
            "SCOPE mean: 1.1143790705504517, SCOPE var: 0.2326613358245686\n",
            "Total Loss: 0.47787587553787503\n",
            "----------------------------------------\n",
            "Epoch 93\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0546, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6789155340775737\n",
            "SCOPE mean: 1.1122177348640505, SCOPE var: 0.23154137220854681\n",
            "Total Loss: 0.4742874793688991\n",
            "----------------------------------------\n",
            "Epoch 94\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0538, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6675434800435915\n",
            "SCOPE mean: 1.1100045074604232, SCOPE var: 0.2304088171966818\n",
            "Total Loss: 0.4707067779557203\n",
            "----------------------------------------\n",
            "Epoch 95\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0531, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6562921951612444\n",
            "SCOPE mean: 1.1077199617007474, SCOPE var: 0.22926037494580498\n",
            "Total Loss: 0.46715350876507794\n",
            "----------------------------------------\n",
            "Epoch 96\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0523, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.64515774639891\n",
            "SCOPE mean: 1.1053963164740388, SCOPE var: 0.2281012382062286\n",
            "Total Loss: 0.46363780546718275\n",
            "----------------------------------------\n",
            "Epoch 97\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0516, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6340216870615922\n",
            "SCOPE mean: 1.102975930822788, SCOPE var: 0.22691886001897593\n",
            "Total Loss: 0.460121337786582\n",
            "----------------------------------------\n",
            "Epoch 98\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0509, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6227314580849979\n",
            "SCOPE mean: 1.1004831659604024, SCOPE var: 0.22571796532091196\n",
            "Total Loss: 0.4565767810415616\n",
            "----------------------------------------\n",
            "Epoch 99\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0502, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6114919696169578\n",
            "SCOPE mean: 1.097947777647472, SCOPE var: 0.22450690194966125\n",
            "Total Loss: 0.45304264535733973\n",
            "----------------------------------------\n",
            "Epoch 100\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0494, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6003335740416524\n",
            "SCOPE mean: 1.095251691331606, SCOPE var: 0.22325516969746026\n",
            "Total Loss: 0.4495181872407683\n",
            "----------------------------------------\n",
            "Epoch 101\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0487, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5891315106718529\n",
            "SCOPE mean: 1.0923784079315932, SCOPE var: 0.22195551216406806\n",
            "Total Loss: 0.445969485406066\n",
            "----------------------------------------\n",
            "Epoch 102\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0479, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5780093526301888\n",
            "SCOPE mean: 1.0894198759366605, SCOPE var: 0.22063317405493973\n",
            "Total Loss: 0.44241294968398076\n",
            "----------------------------------------\n",
            "Epoch 103\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0471, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5669421956764464\n",
            "SCOPE mean: 1.08644508698275, SCOPE var: 0.21930850638212018\n",
            "Total Loss: 0.43886458916649673\n",
            "----------------------------------------\n",
            "Epoch 104\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0463, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.555782972311729\n",
            "SCOPE mean: 1.0834391607706442, SCOPE var: 0.21797375620054027\n",
            "Total Loss: 0.4352953116446499\n",
            "----------------------------------------\n",
            "Epoch 105\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0456, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5444176305077164\n",
            "SCOPE mean: 1.0804415092137927, SCOPE var: 0.21663824503090054\n",
            "Total Loss: 0.43168781825467933\n",
            "----------------------------------------\n",
            "Epoch 106\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0448, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5330583678684355\n",
            "SCOPE mean: 1.0772230877601023, SCOPE var: 0.21526724383564494\n",
            "Total Loss: 0.4281098766744513\n",
            "----------------------------------------\n",
            "Epoch 107\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0441, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.521551298571723\n",
            "SCOPE mean: 1.0739399431387635, SCOPE var: 0.21386791777057307\n",
            "Total Loss: 0.42451439553427195\n",
            "----------------------------------------\n",
            "Epoch 108\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0434, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5097581642731157\n",
            "SCOPE mean: 1.0707053706222571, SCOPE var: 0.2124632182223413\n",
            "Total Loss: 0.4208457259712969\n",
            "----------------------------------------\n",
            "Epoch 109\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0427, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.49799016960678\n",
            "SCOPE mean: 1.0675476058347735, SCOPE var: 0.21106672400268245\n",
            "Total Loss: 0.4171688968231597\n",
            "----------------------------------------\n",
            "Epoch 110\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0419, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.486194022700534\n",
            "SCOPE mean: 1.0644615696169002, SCOPE var: 0.20968346259598708\n",
            "Total Loss: 0.41348213298871467\n",
            "----------------------------------------\n",
            "Epoch 111\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0412, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4744081130779816\n",
            "SCOPE mean: 1.060952377394877, SCOPE var: 0.20830316170839658\n",
            "Total Loss: 0.4098023515878637\n",
            "----------------------------------------\n",
            "Epoch 112\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0405, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4630193079239977\n",
            "SCOPE mean: 1.057154076890279, SCOPE var: 0.20691939039001347\n",
            "Total Loss: 0.4062280526384516\n",
            "----------------------------------------\n",
            "Epoch 113\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0397, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4510946341048627\n",
            "SCOPE mean: 1.0534902898223042, SCOPE var: 0.20551708139433486\n",
            "Total Loss: 0.4025205844272196\n",
            "----------------------------------------\n",
            "Epoch 114\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0390, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4387287936204842\n",
            "SCOPE mean: 1.0498800558224624, SCOPE var: 0.20410171657402992\n",
            "Total Loss: 0.39870298457960135\n",
            "----------------------------------------\n",
            "Epoch 115\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0383, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4261950495375475\n",
            "SCOPE mean: 1.0461961969009956, SCOPE var: 0.20266461649514755\n",
            "Total Loss: 0.39484534856130254\n",
            "----------------------------------------\n",
            "Epoch 116\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0375, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4127916035642794\n",
            "SCOPE mean: 1.0425657447250432, SCOPE var: 0.2012201886644222\n",
            "Total Loss: 0.39071545079684183\n",
            "----------------------------------------\n",
            "Epoch 117\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0367, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.3986416184316997\n",
            "SCOPE mean: 1.0387682256820434, SCOPE var: 0.19970552798955854\n",
            "Total Loss: 0.38638259390768237\n",
            "----------------------------------------\n",
            "Epoch 118\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0359, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.3843817936095741\n",
            "SCOPE mean: 1.0343013489269197, SCOPE var: 0.197900847630144\n",
            "Total Loss: 0.3820122138038591\n",
            "----------------------------------------\n",
            "Epoch 119\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0351, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.3700624645572506\n",
            "SCOPE mean: 1.0299119127467495, SCOPE var: 0.19606022919721755\n",
            "Total Loss: 0.3776139388223005\n",
            "----------------------------------------\n",
            "Epoch 120\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0342, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.3555456640940713\n",
            "SCOPE mean: 1.0255509292657239, SCOPE var: 0.19421132165498997\n",
            "Total Loss: 0.37310027885336694\n",
            "----------------------------------------\n",
            "Epoch 121\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0334, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.3414612698905606\n",
            "SCOPE mean: 1.0216002627101186, SCOPE var: 0.19242946588229295\n",
            "Total Loss: 0.3688011842386726\n",
            "----------------------------------------\n",
            "Epoch 122\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0327, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.3273946759779878\n",
            "SCOPE mean: 1.0176852881142788, SCOPE var: 0.1905581492101065\n",
            "Total Loss: 0.36456636852420293\n",
            "----------------------------------------\n",
            "Epoch 123\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0320, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.3132553565526977\n",
            "SCOPE mean: 1.0160168757357932, SCOPE var: 0.18970723679739768\n",
            "Total Loss: 0.36033777856653426\n",
            "----------------------------------------\n",
            "Epoch 124\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0313, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.2982918733467408\n",
            "SCOPE mean: 1.016169548964655, SCOPE var: 0.1890656244616308\n",
            "Total Loss: 0.3558959051423055\n",
            "----------------------------------------\n",
            "Epoch 125\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0306, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.2823525251902306\n",
            "SCOPE mean: 1.0164740171031976, SCOPE var: 0.18827375118361267\n",
            "Total Loss: 0.3512074168131664\n",
            "----------------------------------------\n",
            "Epoch 126\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0299, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.2658975604846818\n",
            "SCOPE mean: 1.016493462276322, SCOPE var: 0.1873895203460681\n",
            "Total Loss: 0.346416496461562\n",
            "----------------------------------------\n",
            "Epoch 127\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0293, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.2494541423490781\n",
            "SCOPE mean: 1.0161914954383413, SCOPE var: 0.18640409425118404\n",
            "Total Loss: 0.34165758537046115\n",
            "----------------------------------------\n",
            "Epoch 128\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0287, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.2331487994908243\n",
            "SCOPE mean: 1.015401218882872, SCOPE var: 0.185290634222293\n",
            "Total Loss: 0.33695466573649646\n",
            "----------------------------------------\n",
            "Epoch 129\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0281, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.2169411178193235\n",
            "SCOPE mean: 1.0141119812090251, SCOPE var: 0.184053284819554\n",
            "Total Loss: 0.3323124545864504\n",
            "----------------------------------------\n",
            "Epoch 130\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0275, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.2008334277632695\n",
            "SCOPE mean: 1.0130977163110033, SCOPE var: 0.18296956638444806\n",
            "Total Loss: 0.32775031052883086\n",
            "----------------------------------------\n",
            "Epoch 131\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0270, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.1849547250593915\n",
            "SCOPE mean: 1.0112117073933642, SCOPE var: 0.18181119493886047\n",
            "Total Loss: 0.3232606954792965\n",
            "----------------------------------------\n",
            "Epoch 132\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0265, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.1693899529194667\n",
            "SCOPE mean: 1.0087235068111347, SCOPE var: 0.18059581182151624\n",
            "Total Loss: 0.3188658749764773\n",
            "----------------------------------------\n",
            "Epoch 133\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0260, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.1541179027189483\n",
            "SCOPE mean: 1.0060274763381796, SCOPE var: 0.17935269861392072\n",
            "Total Loss: 0.31454895032499997\n",
            "----------------------------------------\n",
            "Epoch 134\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0255, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.1383379623821483\n",
            "SCOPE mean: 1.0031672899639066, SCOPE var: 0.17802006426913836\n",
            "Total Loss: 0.3101108697468712\n",
            "----------------------------------------\n",
            "Epoch 135\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0250, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.1227945904131973\n",
            "SCOPE mean: 1.0001396700375598, SCOPE var: 0.1766735390024362\n",
            "Total Loss: 0.30573086411275413\n",
            "----------------------------------------\n",
            "Epoch 136\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0246, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.1074601625656884\n",
            "SCOPE mean: 0.9971378241597826, SCOPE var: 0.17530326052939676\n",
            "Total Loss: 0.30142795864904026\n",
            "----------------------------------------\n",
            "Epoch 137\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0241, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0923669555801743\n",
            "SCOPE mean: 0.9942780255209028, SCOPE var: 0.17396619571475072\n",
            "Total Loss: 0.297204069207084\n",
            "----------------------------------------\n",
            "Epoch 138\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0237, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0775603445837378\n",
            "SCOPE mean: 0.9914210389597465, SCOPE var: 0.17263084408199808\n",
            "Total Loss: 0.29306773839937883\n",
            "----------------------------------------\n",
            "Epoch 139\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0233, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0632917049245114\n",
            "SCOPE mean: 0.9886957197632169, SCOPE var: 0.1713451876582088\n",
            "Total Loss: 0.2890972870985675\n",
            "----------------------------------------\n",
            "Epoch 140\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0229, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.049108266227054\n",
            "SCOPE mean: 0.9858433041581509, SCOPE var: 0.17008574381522804\n",
            "Total Loss: 0.28516316052957064\n",
            "----------------------------------------\n",
            "Epoch 141\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0225, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0349191575950518\n",
            "SCOPE mean: 0.9827633741430143, SCOPE var: 0.16886529367219782\n",
            "Total Loss: 0.2812573211506955\n",
            "----------------------------------------\n",
            "Epoch 142\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0222, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0212368464991608\n",
            "SCOPE mean: 0.979716674596926, SCOPE var: 0.16769649140251897\n",
            "Total Loss: 0.2775075628489315\n",
            "----------------------------------------\n",
            "Epoch 143\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0219, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0081715600575365\n",
            "SCOPE mean: 0.9765314587690327, SCOPE var: 0.16652263747179996\n",
            "Total Loss: 0.2739378941470087\n",
            "----------------------------------------\n",
            "Epoch 144\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0216, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9956850906622094\n",
            "SCOPE mean: 0.9731560762634727, SCOPE var: 0.1653533809501276\n",
            "Total Loss: 0.2705319025963212\n",
            "----------------------------------------\n",
            "Epoch 145\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0213, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9838460146047823\n",
            "SCOPE mean: 0.9696474153652067, SCOPE var: 0.1641886162786869\n",
            "Total Loss: 0.26729811864148006\n",
            "----------------------------------------\n",
            "Epoch 146\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0211, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9719586974837569\n",
            "SCOPE mean: 0.9665138004087905, SCOPE var: 0.163091511033981\n",
            "Total Loss: 0.26411458619017586\n",
            "----------------------------------------\n",
            "Epoch 147\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0210, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9605320636117616\n",
            "SCOPE mean: 0.9638261414048976, SCOPE var: 0.16213537086430255\n",
            "Total Loss: 0.26110364510674705\n",
            "----------------------------------------\n",
            "Epoch 148\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0208, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9496301852394661\n",
            "SCOPE mean: 0.961407051138311, SCOPE var: 0.16128828145329102\n",
            "Total Loss: 0.2582537517614\n",
            "----------------------------------------\n",
            "Epoch 149\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0207, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9395455864963306\n",
            "SCOPE mean: 0.9586774589440101, SCOPE var: 0.16038076455575312\n",
            "Total Loss: 0.25561864861943984\n",
            "----------------------------------------\n",
            "Epoch 150\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0207, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9303210327776442\n",
            "SCOPE mean: 0.9557470203281991, SCOPE var: 0.15946493994124478\n",
            "Total Loss: 0.2532411232886288\n",
            "----------------------------------------\n",
            "Epoch 151\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0206, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9214839631690328\n",
            "SCOPE mean: 0.9537544810045889, SCOPE var: 0.15855073952209195\n",
            "Total Loss: 0.2509424375500573\n",
            "----------------------------------------\n",
            "Epoch 152\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0205, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9130031422517949\n",
            "SCOPE mean: 0.9520415826106596, SCOPE var: 0.15762820964787613\n",
            "Total Loss: 0.24872901821611743\n",
            "----------------------------------------\n",
            "Epoch 153\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0204, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9047831518084587\n",
            "SCOPE mean: 0.9533945556667017, SCOPE var: 0.15768423427278652\n",
            "Total Loss: 0.24662138785340748\n",
            "----------------------------------------\n",
            "Epoch 154\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0204, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8967799786064942\n",
            "SCOPE mean: 0.9554067151009811, SCOPE var: 0.157925369263859\n",
            "Total Loss: 0.2445851935368616\n",
            "----------------------------------------\n",
            "Epoch 155\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0204, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8890629742617544\n",
            "SCOPE mean: 0.958017061697646, SCOPE var: 0.15828364317760626\n",
            "Total Loss: 0.2426239949988153\n",
            "----------------------------------------\n",
            "Epoch 156\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0203, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.881446358487968\n",
            "SCOPE mean: 0.9611749184114681, SCOPE var: 0.15873277678290112\n",
            "Total Loss: 0.24069400634555593\n",
            "----------------------------------------\n",
            "Epoch 157\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0203, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8735412559960385\n",
            "SCOPE mean: 0.9650686446610034, SCOPE var: 0.15934990235870142\n",
            "Total Loss: 0.2386828424843848\n",
            "----------------------------------------\n",
            "Epoch 158\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0203, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.865468891782682\n",
            "SCOPE mean: 0.9696389914405565, SCOPE var: 0.16015662851433976\n",
            "Total Loss: 0.2366372260885658\n",
            "----------------------------------------\n",
            "Epoch 159\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0203, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8578075074251863\n",
            "SCOPE mean: 0.9744592042790249, SCOPE var: 0.16104914274077786\n",
            "Total Loss: 0.23474258436515\n",
            "----------------------------------------\n",
            "Epoch 160\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0203, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8505399543981824\n",
            "SCOPE mean: 0.9795777700209836, SCOPE var: 0.16196714161676304\n",
            "Total Loss: 0.2329472640537415\n",
            "----------------------------------------\n",
            "Epoch 161\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0203, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8434227688057481\n",
            "SCOPE mean: 0.9848996409591284, SCOPE var: 0.16288649945169628\n",
            "Total Loss: 0.2311812151797333\n",
            "----------------------------------------\n",
            "Epoch 162\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0203, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8363827050894712\n",
            "SCOPE mean: 0.9903353281683376, SCOPE var: 0.163790812194483\n",
            "Total Loss: 0.2294236075933586\n",
            "----------------------------------------\n",
            "Epoch 163\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0203, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8294190283105479\n",
            "SCOPE mean: 0.9957730457207373, SCOPE var: 0.16466180058631305\n",
            "Total Loss: 0.22767499264265328\n",
            "----------------------------------------\n",
            "Epoch 164\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0203, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8225462002567927\n",
            "SCOPE mean: 1.0011017760743892, SCOPE var: 0.16548457615515816\n",
            "Total Loss: 0.2259397854811343\n",
            "----------------------------------------\n",
            "Epoch 165\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0203, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8157994922188002\n",
            "SCOPE mean: 1.0061982142891586, SCOPE var: 0.1662403262437472\n",
            "Total Loss: 0.22423073433331148\n",
            "----------------------------------------\n",
            "Epoch 166\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0203, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8092296982317272\n",
            "SCOPE mean: 1.0109467979534055, SCOPE var: 0.16691204662594444\n",
            "Total Loss: 0.22256502053079819\n",
            "----------------------------------------\n",
            "Epoch 167\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0202, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8028713528464118\n",
            "SCOPE mean: 1.0152652643900142, SCOPE var: 0.16749341065455323\n",
            "Total Loss: 0.22094910522635852\n",
            "----------------------------------------\n",
            "Epoch 168\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0202, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7967438406182872\n",
            "SCOPE mean: 1.0190852606803318, SCOPE var: 0.16798728651367445\n",
            "Total Loss: 0.21938778362860537\n",
            "----------------------------------------\n",
            "Epoch 169\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0202, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7907996348857897\n",
            "SCOPE mean: 1.0223539426870516, SCOPE var: 0.16839311026601242\n",
            "Total Loss: 0.21786962212816358\n",
            "----------------------------------------\n",
            "Epoch 170\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0201, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7850033130243632\n",
            "SCOPE mean: 1.0250061452582047, SCOPE var: 0.16869795800050363\n",
            "Total Loss: 0.2163818669493393\n",
            "----------------------------------------\n",
            "Epoch 171\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0201, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7793124587865908\n",
            "SCOPE mean: 1.0266810429061328, SCOPE var: 0.16892734709170018\n",
            "Total Loss: 0.21492931779439928\n",
            "----------------------------------------\n",
            "Epoch 172\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0201, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7737105964970673\n",
            "SCOPE mean: 1.0276304848558309, SCOPE var: 0.16908979849700867\n",
            "Total Loss: 0.21349654178190886\n",
            "----------------------------------------\n",
            "Epoch 173\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0200, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.76822969427241\n",
            "SCOPE mean: 1.0281533032859518, SCOPE var: 0.1691930685929028\n",
            "Total Loss: 0.21208449527971532\n",
            "----------------------------------------\n",
            "Epoch 174\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0200, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.762960795119018\n",
            "SCOPE mean: 1.0284180643765677, SCOPE var: 0.16926370370769325\n",
            "Total Loss: 0.21071145586600332\n",
            "----------------------------------------\n",
            "Epoch 175\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0199, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7578123064537098\n",
            "SCOPE mean: 1.0284781667333984, SCOPE var: 0.1693032582518302\n",
            "Total Loss: 0.20936671823442848\n",
            "----------------------------------------\n",
            "Epoch 176\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0199, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7527693237425446\n",
            "SCOPE mean: 1.028368765280548, SCOPE var: 0.16931492257972094\n",
            "Total Loss: 0.20805003485418974\n",
            "----------------------------------------\n",
            "Epoch 177\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0198, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.74796067452399\n",
            "SCOPE mean: 1.028110828906598, SCOPE var: 0.16930300669701506\n",
            "Total Loss: 0.20679067463915504\n",
            "----------------------------------------\n",
            "Epoch 178\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0197, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7432430176247325\n",
            "SCOPE mean: 1.027787496149393, SCOPE var: 0.16926900239270676\n",
            "Total Loss: 0.2055567567766449\n",
            "----------------------------------------\n",
            "Epoch 179\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0197, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7385958034035978\n",
            "SCOPE mean: 1.0274687453017206, SCOPE var: 0.16922842379178413\n",
            "Total Loss: 0.20434329596453976\n",
            "----------------------------------------\n",
            "Epoch 180\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0196, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.734000219851263\n",
            "SCOPE mean: 1.0272076925729074, SCOPE var: 0.1691682983677161\n",
            "Total Loss: 0.20314582204698794\n",
            "----------------------------------------\n",
            "Epoch 181\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0196, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7294456275239883\n",
            "SCOPE mean: 1.0270157628032783, SCOPE var: 0.1690901678394462\n",
            "Total Loss: 0.2019640779843957\n",
            "----------------------------------------\n",
            "Epoch 182\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0196, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7249275276175575\n",
            "SCOPE mean: 1.0268701502742799, SCOPE var: 0.16900268133104418\n",
            "Total Loss: 0.20079354383221865\n",
            "----------------------------------------\n",
            "Epoch 183\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0195, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7205023459135695\n",
            "SCOPE mean: 1.0267921668883346, SCOPE var: 0.168912307501193\n",
            "Total Loss: 0.1996483864619474\n",
            "----------------------------------------\n",
            "Epoch 184\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0195, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7161442815379284\n",
            "SCOPE mean: 1.0268326081996582, SCOPE var: 0.1688471833949284\n",
            "Total Loss: 0.1985497152814572\n",
            "----------------------------------------\n",
            "Epoch 185\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0195, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.71184244302462\n",
            "SCOPE mean: 1.0272931957891964, SCOPE var: 0.16887202241469132\n",
            "Total Loss: 0.19747409082730813\n",
            "----------------------------------------\n",
            "Epoch 186\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0195, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7076134031970249\n",
            "SCOPE mean: 1.0280094780699742, SCOPE var: 0.16895976850959607\n",
            "Total Loss: 0.19641917822494087\n",
            "----------------------------------------\n",
            "Epoch 187\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0195, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7034506172507375\n",
            "SCOPE mean: 1.0289404947957996, SCOPE var: 0.16909908576990682\n",
            "Total Loss: 0.19538510247683366\n",
            "----------------------------------------\n",
            "Epoch 188\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0195, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.699341490942178\n",
            "SCOPE mean: 1.0300607157796946, SCOPE var: 0.1692906885522147\n",
            "Total Loss: 0.19437071864774375\n",
            "----------------------------------------\n",
            "Epoch 189\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0196, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6953202471503278\n",
            "SCOPE mean: 1.0314037081524852, SCOPE var: 0.1695595045580433\n",
            "Total Loss: 0.19338411122117125\n",
            "----------------------------------------\n",
            "Epoch 190\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0196, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6913779223085672\n",
            "SCOPE mean: 1.0328764112792888, SCOPE var: 0.16987922986015144\n",
            "Total Loss: 0.19241422650698378\n",
            "----------------------------------------\n",
            "Epoch 191\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0196, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6875309478135458\n",
            "SCOPE mean: 1.0341234075946086, SCOPE var: 0.17017610128460037\n",
            "Total Loss: 0.1914696066149498\n",
            "----------------------------------------\n",
            "Epoch 192\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0196, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6837635457550577\n",
            "SCOPE mean: 1.0351194956947605, SCOPE var: 0.1704436697656103\n",
            "Total Loss: 0.19053400488389197\n",
            "----------------------------------------\n",
            "Epoch 193\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0196, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6800818882430503\n",
            "SCOPE mean: 1.0358857274004603, SCOPE var: 0.17068360820137118\n",
            "Total Loss: 0.18960793244418214\n",
            "----------------------------------------\n",
            "Epoch 194\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0196, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6764824970074335\n",
            "SCOPE mean: 1.0364517116983494, SCOPE var: 0.17089922877770755\n",
            "Total Loss: 0.18869200063751354\n",
            "----------------------------------------\n",
            "Epoch 195\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0196, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6729656536505026\n",
            "SCOPE mean: 1.0368935970107656, SCOPE var: 0.17109092232001077\n",
            "Total Loss: 0.18779230570482403\n",
            "----------------------------------------\n",
            "Epoch 196\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0195, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.66951406560396\n",
            "SCOPE mean: 1.0378001427215922, SCOPE var: 0.1713078164797772\n",
            "Total Loss: 0.1869161913638963\n",
            "----------------------------------------\n",
            "Epoch 197\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0195, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6661092856673292\n",
            "SCOPE mean: 1.038905519098598, SCOPE var: 0.1715560061703935\n",
            "Total Loss: 0.18606111335372452\n",
            "----------------------------------------\n",
            "Epoch 198\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0195, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.662767716191571\n",
            "SCOPE mean: 1.0402277315967707, SCOPE var: 0.171823622661862\n",
            "Total Loss: 0.18520967561546048\n",
            "----------------------------------------\n",
            "Epoch 199\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0195, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6594785426913689\n",
            "SCOPE mean: 1.0416229777991124, SCOPE var: 0.17209184751537293\n",
            "Total Loss: 0.1843614105529249\n",
            "----------------------------------------\n",
            "Epoch 200\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0195, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6562497252434115\n",
            "SCOPE mean: 1.0431359237763358, SCOPE var: 0.17236611413741218\n",
            "Total Loss: 0.18352841381953058\n",
            "----------------------------------------\n",
            "Epoch 201\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0194, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6531083797060002\n",
            "SCOPE mean: 1.0452856298018853, SCOPE var: 0.17288128652424006\n",
            "Total Loss: 0.1827088902037628\n",
            "----------------------------------------\n",
            "Epoch 202\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0194, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.650066146846408\n",
            "SCOPE mean: 1.0475671568314826, SCOPE var: 0.17347287769914407\n",
            "Total Loss: 0.1819129356134405\n",
            "----------------------------------------\n",
            "Epoch 203\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0194, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6470803175122357\n",
            "SCOPE mean: 1.0495170547621282, SCOPE var: 0.1739916980132019\n",
            "Total Loss: 0.1811300882191165\n",
            "----------------------------------------\n",
            "Epoch 204\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0193, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6441426365120408\n",
            "SCOPE mean: 1.050946829898618, SCOPE var: 0.17436583966809976\n",
            "Total Loss: 0.18036299444249412\n",
            "----------------------------------------\n",
            "Epoch 205\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0193, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6412827176250521\n",
            "SCOPE mean: 1.0518914817040461, SCOPE var: 0.1746095606421285\n",
            "Total Loss: 0.17961464572381922\n",
            "----------------------------------------\n",
            "Epoch 206\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0193, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6384236449595267\n",
            "SCOPE mean: 1.0526604733434202, SCOPE var: 0.17480198695469087\n",
            "Total Loss: 0.17887351630231954\n",
            "----------------------------------------\n",
            "Epoch 207\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0192, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6355704523310232\n",
            "SCOPE mean: 1.0533238169458403, SCOPE var: 0.17495940355900214\n",
            "Total Loss: 0.1781375482446358\n",
            "----------------------------------------\n",
            "Epoch 208\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0192, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6327318231773497\n",
            "SCOPE mean: 1.0539204227580345, SCOPE var: 0.17509142655260357\n",
            "Total Loss: 0.1774087399090376\n",
            "----------------------------------------\n",
            "Epoch 209\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0192, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6299174798165152\n",
            "SCOPE mean: 1.0545007586894115, SCOPE var: 0.17519674744554461\n",
            "Total Loss: 0.1766824098403244\n",
            "----------------------------------------\n",
            "Epoch 210\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0192, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6271265399090985\n",
            "SCOPE mean: 1.055028813656131, SCOPE var: 0.17527199958144535\n",
            "Total Loss: 0.1759676340024007\n",
            "----------------------------------------\n",
            "Epoch 211\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0192, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.624399826963855\n",
            "SCOPE mean: 1.0551929697421834, SCOPE var: 0.17524783810057104\n",
            "Total Loss: 0.17526568538502119\n",
            "----------------------------------------\n",
            "Epoch 212\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0192, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6216955856215168\n",
            "SCOPE mean: 1.0550495989442366, SCOPE var: 0.1751434371669005\n",
            "Total Loss: 0.17457746386938214\n",
            "----------------------------------------\n",
            "Epoch 213\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0191, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6190109653146385\n",
            "SCOPE mean: 1.0552110995656636, SCOPE var: 0.17515458864501965\n",
            "Total Loss: 0.17388817356205133\n",
            "----------------------------------------\n",
            "Epoch 214\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0191, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6163626552004996\n",
            "SCOPE mean: 1.0556963532732184, SCOPE var: 0.175283899411197\n",
            "Total Loss: 0.1731993618819947\n",
            "----------------------------------------\n",
            "Epoch 215\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0191, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6137843721318159\n",
            "SCOPE mean: 1.056293575758129, SCOPE var: 0.17545821197803177\n",
            "Total Loss: 0.1725294816637508\n",
            "----------------------------------------\n",
            "Epoch 216\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0191, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6112423496230331\n",
            "SCOPE mean: 1.0572061766144198, SCOPE var: 0.17572375471132093\n",
            "Total Loss: 0.17188426940644758\n",
            "----------------------------------------\n",
            "Epoch 217\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0191, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6087384446526183\n",
            "SCOPE mean: 1.0582427983559783, SCOPE var: 0.17602850706394096\n",
            "Total Loss: 0.17125337070789629\n",
            "----------------------------------------\n",
            "Epoch 218\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0191, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6062525063209592\n",
            "SCOPE mean: 1.059028844750749, SCOPE var: 0.17624528095641653\n",
            "Total Loss: 0.17062184134348293\n",
            "----------------------------------------\n",
            "Epoch 219\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0190, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6038315938756428\n",
            "SCOPE mean: 1.0591275611826374, SCOPE var: 0.1762398421222104\n",
            "Total Loss: 0.16996873811035176\n",
            "----------------------------------------\n",
            "Epoch 220\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0189, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6014978955390423\n",
            "SCOPE mean: 1.0587246873872527, SCOPE var: 0.17609601802475391\n",
            "Total Loss: 0.16932334955686987\n",
            "----------------------------------------\n",
            "Epoch 221\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0189, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5992289420326716\n",
            "SCOPE mean: 1.0584414067661059, SCOPE var: 0.1759946724284897\n",
            "Total Loss: 0.16869081783934256\n",
            "----------------------------------------\n",
            "Epoch 222\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0188, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5970407789967316\n",
            "SCOPE mean: 1.05859100445317, SCOPE var: 0.17603490786663653\n",
            "Total Loss: 0.1680753137648095\n",
            "----------------------------------------\n",
            "Epoch 223\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0187, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.594865860589825\n",
            "SCOPE mean: 1.0595059729626386, SCOPE var: 0.17630535383321266\n",
            "Total Loss: 0.16745412326653936\n",
            "----------------------------------------\n",
            "Epoch 224\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0187, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5926651653962419\n",
            "SCOPE mean: 1.0610527209365685, SCOPE var: 0.1767774558106486\n",
            "Total Loss: 0.16683776462989575\n",
            "----------------------------------------\n",
            "Epoch 225\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0186, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5904982017300129\n",
            "SCOPE mean: 1.0627418836498153, SCOPE var: 0.17725976201951538\n",
            "Total Loss: 0.16623558324219936\n",
            "----------------------------------------\n",
            "Epoch 226\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0185, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.588376179611785\n",
            "SCOPE mean: 1.0639210882320218, SCOPE var: 0.17758330453442162\n",
            "Total Loss: 0.165634884494971\n",
            "----------------------------------------\n",
            "Epoch 227\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0185, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5862917034422331\n",
            "SCOPE mean: 1.0648188742619136, SCOPE var: 0.1778294410063356\n",
            "Total Loss: 0.16503366460589275\n",
            "----------------------------------------\n",
            "Epoch 228\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0184, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5842492750743196\n",
            "SCOPE mean: 1.0654434851922618, SCOPE var: 0.17799869913148364\n",
            "Total Loss: 0.16443392837019638\n",
            "----------------------------------------\n",
            "Epoch 229\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0183, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5822394151533559\n",
            "SCOPE mean: 1.065796637958928, SCOPE var: 0.17809191953077244\n",
            "Total Loss: 0.16384400926226467\n",
            "----------------------------------------\n",
            "Epoch 230\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0182, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5802758776871961\n",
            "SCOPE mean: 1.0661980351024645, SCOPE var: 0.1781722152217406\n",
            "Total Loss: 0.16327217059588883\n",
            "----------------------------------------\n",
            "Epoch 231\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0181, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5783402025990431\n",
            "SCOPE mean: 1.066608107638148, SCOPE var: 0.17822961452282576\n",
            "Total Loss: 0.1627225717581365\n",
            "----------------------------------------\n",
            "Epoch 232\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0181, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5764141881433232\n",
            "SCOPE mean: 1.0674241575559695, SCOPE var: 0.1784145993887218\n",
            "Total Loss: 0.16217609585057038\n",
            "----------------------------------------\n",
            "Epoch 233\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0180, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5745091046721444\n",
            "SCOPE mean: 1.0685374261476512, SCOPE var: 0.17869856656260646\n",
            "Total Loss: 0.16163089484423843\n",
            "----------------------------------------\n",
            "Epoch 234\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0179, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.572627625923467\n",
            "SCOPE mean: 1.0698206726394972, SCOPE var: 0.1790489588995784\n",
            "Total Loss: 0.16108695765684297\n",
            "----------------------------------------\n",
            "Epoch 235\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0179, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5707737291374128\n",
            "SCOPE mean: 1.071201703355687, SCOPE var: 0.17945099960401978\n",
            "Total Loss: 0.1605448164799833\n",
            "----------------------------------------\n",
            "Epoch 236\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0178, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.568959246312939\n",
            "SCOPE mean: 1.0725662736283925, SCOPE var: 0.1798727657570173\n",
            "Total Loss: 0.16002331868174155\n",
            "----------------------------------------\n",
            "Epoch 237\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0177, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5671804666148855\n",
            "SCOPE mean: 1.0730391894034295, SCOPE var: 0.1800568458999972\n",
            "Total Loss: 0.15950202443801662\n",
            "----------------------------------------\n",
            "Epoch 238\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0176, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5654336995241835\n",
            "SCOPE mean: 1.0724052658745475, SCOPE var: 0.17993549344156\n",
            "Total Loss: 0.15897346091565212\n",
            "----------------------------------------\n",
            "Epoch 239\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0175, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5637062933943311\n",
            "SCOPE mean: 1.0711999742182114, SCOPE var: 0.17963229026500047\n",
            "Total Loss: 0.15843966829132855\n",
            "----------------------------------------\n",
            "Epoch 240\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0174, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5620151850265712\n",
            "SCOPE mean: 1.0697634548858364, SCOPE var: 0.17925734877755384\n",
            "Total Loss: 0.15793287154735186\n",
            "----------------------------------------\n",
            "Epoch 241\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0173, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5603453312796893\n",
            "SCOPE mean: 1.0687226798176226, SCOPE var: 0.1790090923127761\n",
            "Total Loss: 0.1574306437747263\n",
            "----------------------------------------\n",
            "Epoch 242\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0173, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5586965369462843\n",
            "SCOPE mean: 1.0680544364571396, SCOPE var: 0.17887966604373023\n",
            "Total Loss: 0.1569311234552759\n",
            "----------------------------------------\n",
            "Epoch 243\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0172, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5570558775969494\n",
            "SCOPE mean: 1.0677784132406132, SCOPE var: 0.1788684272649599\n",
            "Total Loss: 0.15643408148810742\n",
            "----------------------------------------\n",
            "Epoch 244\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0171, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5554105306792477\n",
            "SCOPE mean: 1.0678451186914872, SCOPE var: 0.17895689828591063\n",
            "Total Loss: 0.15594084641950115\n",
            "----------------------------------------\n",
            "Epoch 245\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0170, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5537639187591298\n",
            "SCOPE mean: 1.0682165162459767, SCOPE var: 0.1791391955844062\n",
            "Total Loss: 0.1554450947146955\n",
            "----------------------------------------\n",
            "Epoch 246\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0170, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5521085365622413\n",
            "SCOPE mean: 1.0686191351244594, SCOPE var: 0.1793242757451977\n",
            "Total Loss: 0.15498242998762898\n",
            "----------------------------------------\n",
            "Epoch 247\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0169, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5504552261621395\n",
            "SCOPE mean: 1.0682577765132053, SCOPE var: 0.17924659865683085\n",
            "Total Loss: 0.15450046220834368\n",
            "----------------------------------------\n",
            "Epoch 248\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0168, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5488360094800536\n",
            "SCOPE mean: 1.0673093320057814, SCOPE var: 0.17895192791063524\n",
            "Total Loss: 0.1540019411966531\n",
            "----------------------------------------\n",
            "Epoch 249\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0167, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.547234500655036\n",
            "SCOPE mean: 1.0658876047439656, SCOPE var: 0.1784801984574638\n",
            "Total Loss: 0.15352903849265903\n",
            "----------------------------------------\n",
            "Epoch 250\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0167, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5456434592740347\n",
            "SCOPE mean: 1.064949298184987, SCOPE var: 0.17817139090582154\n",
            "Total Loss: 0.15306880499469488\n",
            "----------------------------------------\n",
            "Epoch 251\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0166, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5440508318522553\n",
            "SCOPE mean: 1.0644839379818405, SCOPE var: 0.17802110626048506\n",
            "Total Loss: 0.15260502495812023\n",
            "----------------------------------------\n",
            "Epoch 252\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0165, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5424502960997896\n",
            "SCOPE mean: 1.064540432635975, SCOPE var: 0.1780306208296152\n",
            "Total Loss: 0.15213927534083002\n",
            "----------------------------------------\n",
            "Epoch 253\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0165, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5408522169485498\n",
            "SCOPE mean: 1.065031698857584, SCOPE var: 0.17817800863836486\n",
            "Total Loss: 0.15167545967915858\n",
            "----------------------------------------\n",
            "Epoch 254\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0164, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5392800897860504\n",
            "SCOPE mean: 1.065530027805207, SCOPE var: 0.1783289807085533\n",
            "Total Loss: 0.15121984705636093\n",
            "----------------------------------------\n",
            "Epoch 255\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0163, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5377541023977307\n",
            "SCOPE mean: 1.0659680559228548, SCOPE var: 0.17845444151377424\n",
            "Total Loss: 0.1507868698726192\n",
            "----------------------------------------\n",
            "Epoch 256\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0163, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5362647415770111\n",
            "SCOPE mean: 1.0657789315370112, SCOPE var: 0.17837566205362615\n",
            "Total Loss: 0.15034988041783598\n",
            "----------------------------------------\n",
            "Epoch 257\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0162, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5348043676728927\n",
            "SCOPE mean: 1.0646810870194117, SCOPE var: 0.17800911608518522\n",
            "Total Loss: 0.1498918368591963\n",
            "----------------------------------------\n",
            "Epoch 258\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0161, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5333872710199226\n",
            "SCOPE mean: 1.0631754299473606, SCOPE var: 0.17750796680688066\n",
            "Total Loss: 0.14946383946503872\n",
            "----------------------------------------\n",
            "Epoch 259\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0160, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5319938192540603\n",
            "SCOPE mean: 1.0616751575546979, SCOPE var: 0.17706642133344214\n",
            "Total Loss: 0.14904133254249047\n",
            "----------------------------------------\n",
            "Epoch 260\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0160, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.530591733762903\n",
            "SCOPE mean: 1.0606313017134943, SCOPE var: 0.1767769370933426\n",
            "Total Loss: 0.14861705281201382\n",
            "----------------------------------------\n",
            "Epoch 261\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0159, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5291834455376555\n",
            "SCOPE mean: 1.059981349121946, SCOPE var: 0.17661447177933548\n",
            "Total Loss: 0.14819110051267986\n",
            "----------------------------------------\n",
            "Epoch 262\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0158, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5277826419201956\n",
            "SCOPE mean: 1.0597155199770218, SCOPE var: 0.17657234722812437\n",
            "Total Loss: 0.14776798584475284\n",
            "----------------------------------------\n",
            "Epoch 263\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0157, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5264034616297625\n",
            "SCOPE mean: 1.0597027265402474, SCOPE var: 0.17660750651550888\n",
            "Total Loss: 0.14734803748127917\n",
            "----------------------------------------\n",
            "Epoch 264\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0157, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5250273086208339\n",
            "SCOPE mean: 1.0599309331712161, SCOPE var: 0.17671172003955438\n",
            "Total Loss: 0.1469373147685132\n",
            "----------------------------------------\n",
            "Epoch 265\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0156, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5236674227539745\n",
            "SCOPE mean: 1.05986410570996, SCOPE var: 0.1767059817354336\n",
            "Total Loss: 0.14653728140620492\n",
            "----------------------------------------\n",
            "Epoch 266\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0156, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5223146842784839\n",
            "SCOPE mean: 1.0588906743777815, SCOPE var: 0.17639451026803027\n",
            "Total Loss: 0.14613048216623323\n",
            "----------------------------------------\n",
            "Epoch 267\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0155, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5209681642786869\n",
            "SCOPE mean: 1.0578031433807191, SCOPE var: 0.17603370819780695\n",
            "Total Loss: 0.14572646354677507\n",
            "----------------------------------------\n",
            "Epoch 268\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0154, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.519634045665857\n",
            "SCOPE mean: 1.057324218626645, SCOPE var: 0.17586899686378865\n",
            "Total Loss: 0.14534217270097594\n",
            "----------------------------------------\n",
            "Epoch 269\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0154, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5183107111472207\n",
            "SCOPE mean: 1.0573720929965034, SCOPE var: 0.17587118538893332\n",
            "Total Loss: 0.14495834695646223\n",
            "----------------------------------------\n",
            "Epoch 270\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0153, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5169926406814419\n",
            "SCOPE mean: 1.0574237359848975, SCOPE var: 0.17585748311214833\n",
            "Total Loss: 0.14457825263793272\n",
            "----------------------------------------\n",
            "Epoch 271\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0153, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5156913171770591\n",
            "SCOPE mean: 1.0574604608624991, SCOPE var: 0.17582585289727015\n",
            "Total Loss: 0.14420390568098035\n",
            "----------------------------------------\n",
            "Epoch 272\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0152, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5143945000039886\n",
            "SCOPE mean: 1.057363524554639, SCOPE var: 0.17575934140086605\n",
            "Total Loss: 0.14382967964276017\n",
            "----------------------------------------\n",
            "Epoch 273\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0152, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.513118355532686\n",
            "SCOPE mean: 1.0572191820595283, SCOPE var: 0.17567359597466065\n",
            "Total Loss: 0.1434614957681709\n",
            "----------------------------------------\n",
            "Epoch 274\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0151, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5118803254830802\n",
            "SCOPE mean: 1.0566271583276605, SCOPE var: 0.17549262230096577\n",
            "Total Loss: 0.14310030623473383\n",
            "----------------------------------------\n",
            "Epoch 275\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0151, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.510666583733471\n",
            "SCOPE mean: 1.0561093253375384, SCOPE var: 0.17534651123095463\n",
            "Total Loss: 0.142750851041415\n",
            "----------------------------------------\n",
            "Epoch 276\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0150, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5094724585394131\n",
            "SCOPE mean: 1.0556687010913062, SCOPE var: 0.17523524674416308\n",
            "Total Loss: 0.1424016978978381\n",
            "----------------------------------------\n",
            "Epoch 277\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0150, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5083021785674462\n",
            "SCOPE mean: 1.055306183877342, SCOPE var: 0.17515644204749276\n",
            "Total Loss: 0.14205460697528827\n",
            "----------------------------------------\n",
            "Epoch 278\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0149, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5071445198065472\n",
            "SCOPE mean: 1.0549821931412497, SCOPE var: 0.17509958467565281\n",
            "Total Loss: 0.14171818696054114\n",
            "----------------------------------------\n",
            "Epoch 279\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0149, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5059839011055813\n",
            "SCOPE mean: 1.054609104307711, SCOPE var: 0.1750258019850164\n",
            "Total Loss: 0.14138459153751362\n",
            "----------------------------------------\n",
            "Epoch 280\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0148, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5047894681243317\n",
            "SCOPE mean: 1.0543616205493058, SCOPE var: 0.17499409466863045\n",
            "Total Loss: 0.1410245703867419\n",
            "----------------------------------------\n",
            "Epoch 281\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0147, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5036200310229634\n",
            "SCOPE mean: 1.0542339465449633, SCOPE var: 0.17500529282205687\n",
            "Total Loss: 0.14064848562712756\n",
            "----------------------------------------\n",
            "Epoch 282\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0146, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5024678690130532\n",
            "SCOPE mean: 1.0542220011617, SCOPE var: 0.1750531305350061\n",
            "Total Loss: 0.14025952279635842\n",
            "----------------------------------------\n",
            "Epoch 283\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0145, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5013316420634328\n",
            "SCOPE mean: 1.05443025539576, SCOPE var: 0.1751677943814561\n",
            "Total Loss: 0.13986379643715705\n",
            "----------------------------------------\n",
            "Epoch 284\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0144, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5002165772947452\n",
            "SCOPE mean: 1.054965156936517, SCOPE var: 0.17537952436400983\n",
            "Total Loss: 0.13946542078420562\n",
            "----------------------------------------\n",
            "Epoch 285\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0143, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4991359417469379\n",
            "SCOPE mean: 1.0555879052873636, SCOPE var: 0.1756030301563922\n",
            "Total Loss: 0.13907129568347168\n",
            "----------------------------------------\n",
            "Epoch 286\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0142, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.49810444530325354\n",
            "SCOPE mean: 1.0562703626207717, SCOPE var: 0.17582865005033574\n",
            "Total Loss: 0.13868697783276154\n",
            "----------------------------------------\n",
            "Epoch 287\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0140, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4971007646781506\n",
            "SCOPE mean: 1.057086027041786, SCOPE var: 0.17608152261957566\n",
            "Total Loss: 0.13831230648824674\n",
            "----------------------------------------\n",
            "Epoch 288\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0139, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4961156593339527\n",
            "SCOPE mean: 1.057995036420432, SCOPE var: 0.17634863993869043\n",
            "Total Loss: 0.13794781940739168\n",
            "----------------------------------------\n",
            "Epoch 289\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0138, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4951419475197787\n",
            "SCOPE mean: 1.0588263800247653, SCOPE var: 0.17657440583801576\n",
            "Total Loss: 0.13759151311273332\n",
            "----------------------------------------\n",
            "Epoch 290\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0137, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4941605001484812\n",
            "SCOPE mean: 1.0595105720830604, SCOPE var: 0.17674911530768325\n",
            "Total Loss: 0.13723723750466452\n",
            "----------------------------------------\n",
            "Epoch 291\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0136, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4931678633901315\n",
            "SCOPE mean: 1.060084858446255, SCOPE var: 0.17689845653001104\n",
            "Total Loss: 0.1368860299623628\n",
            "----------------------------------------\n",
            "Epoch 292\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0135, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.492171417240651\n",
            "SCOPE mean: 1.060374139995948, SCOPE var: 0.17696972582002307\n",
            "Total Loss: 0.13653746964121527\n",
            "----------------------------------------\n",
            "Epoch 293\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0134, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.49117729597429655\n",
            "SCOPE mean: 1.060364335177673, SCOPE var: 0.17696221309347765\n",
            "Total Loss: 0.13619641290420922\n",
            "----------------------------------------\n",
            "Epoch 294\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0133, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4901897203630734\n",
            "SCOPE mean: 1.0601108857520274, SCOPE var: 0.17690891674254564\n",
            "Total Loss: 0.1358550469313823\n",
            "----------------------------------------\n",
            "Epoch 295\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0132, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4892135385621475\n",
            "SCOPE mean: 1.059550180188593, SCOPE var: 0.17678602588418274\n",
            "Total Loss: 0.135523535784869\n",
            "----------------------------------------\n",
            "Epoch 296\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0131, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4882564315728865\n",
            "SCOPE mean: 1.058704921029699, SCOPE var: 0.1766013942542929\n",
            "Total Loss: 0.1351996581457797\n",
            "----------------------------------------\n",
            "Epoch 297\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0131, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.48730578142740927\n",
            "SCOPE mean: 1.0576481966569051, SCOPE var: 0.17637226827335914\n",
            "Total Loss: 0.13488134569212504\n",
            "----------------------------------------\n",
            "Epoch 298\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0130, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4863621886247999\n",
            "SCOPE mean: 1.0564679224727527, SCOPE var: 0.17610750650209436\n",
            "Total Loss: 0.13456750255920177\n",
            "----------------------------------------\n",
            "Epoch 299\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0129, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4854185798172273\n",
            "SCOPE mean: 1.0552053152027605, SCOPE var: 0.1758182180786606\n",
            "Total Loss: 0.13425712810656323\n",
            "----------------------------------------\n",
            "Epoch 300\n",
            "IS mean: 1.106270715478129,IS variance: 0.12391107861689143\n",
            "SCOPE Var loss:  tensor(0.0128, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4844813970788626\n",
            "SCOPE mean: 1.0539014385352352, SCOPE var: 0.17551389700977124\n",
            "Total Loss: 0.1339481993461828\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[ 0.4454, -0.1346],\n",
            "        [ 0.5981, -0.4962],\n",
            "        [ 0.2534, -0.3049],\n",
            "        [-0.6795, -0.5101],\n",
            "        [ 0.4239, -0.5220],\n",
            "        [ 0.1265, -0.4236],\n",
            "        [-0.1538,  0.0449],\n",
            "        [ 0.2510, -0.5793],\n",
            "        [-0.0918, -0.1047],\n",
            "        [ 0.1016,  0.0057],\n",
            "        [ 0.3121, -0.2632],\n",
            "        [-0.2122, -0.2926],\n",
            "        [-0.1716, -0.4919],\n",
            "        [-0.2066, -0.5931],\n",
            "        [ 0.1594, -0.0884],\n",
            "        [-0.4021,  0.1645]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([-0.3656, -0.7607,  0.1976, -0.4146,  0.3182, -0.0911,  0.4173, -0.4445,\n",
            "         0.6673,  0.3378, -0.6724,  0.0168, -0.4960,  0.1372,  0.7372, -0.0784],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[ 0.0242, -0.2109,  0.1076,  0.1333,  0.1424,  0.1807,  0.0111,  0.0916,\n",
            "          0.2956,  0.1586,  0.0113, -0.1727, -0.1230, -0.2191, -0.2118,  0.1888],\n",
            "        [ 0.1369, -0.2325,  0.0011, -0.1953, -0.1548, -0.1465,  0.1195, -0.0092,\n",
            "          0.2651,  0.1887,  0.0292, -0.2232,  0.1200,  0.2395, -0.1268, -0.2095],\n",
            "        [-0.0459,  0.1563, -0.1951,  0.1992,  0.1471, -0.1500,  0.1853,  0.0122,\n",
            "          0.2329,  0.0281, -0.2085,  0.1685, -0.2120, -0.1925, -0.0482, -0.3104],\n",
            "        [-0.0468,  0.0101, -0.2492,  0.1861, -0.2240,  0.0246, -0.2491,  0.0124,\n",
            "         -0.0452,  0.2045,  0.0835, -0.1232, -0.0765,  0.2017, -0.1068, -0.0888],\n",
            "        [ 0.1161, -0.0645,  0.2869, -0.0274,  0.2575, -0.1249,  0.2013,  0.1510,\n",
            "          0.2159, -0.2493, -0.0897, -0.0931,  0.1759, -0.0908, -0.0402,  0.0955],\n",
            "        [ 0.0678, -0.0751,  0.2776, -0.1045, -0.0960, -0.1219,  0.2454,  0.0876,\n",
            "          0.4816, -0.1724, -0.2225, -0.0451,  0.0416, -0.1861, -0.0054, -0.1550],\n",
            "        [-0.1815,  0.1989, -0.2618, -0.2161,  0.0771,  0.1735, -0.2746,  0.1639,\n",
            "         -0.2167, -0.0888, -0.2992,  0.0260, -0.1448,  0.0232,  0.0581, -0.2750],\n",
            "        [ 0.2239, -0.3322, -0.1531,  0.1568,  0.0859, -0.0701,  0.1424,  0.3011,\n",
            "         -0.0143, -0.3524,  0.2353,  0.1421, -0.2307,  0.1671, -0.0595, -0.1976],\n",
            "        [-0.2524,  0.0815, -0.0286,  0.1350,  0.0350, -0.1381, -0.1076, -0.0713,\n",
            "          0.0668,  0.0736,  0.0085,  0.1062,  0.2066,  0.0431,  0.2072,  0.1092],\n",
            "        [-0.0130,  0.0386,  0.0183,  0.2159, -0.1204, -0.0580, -0.2435, -0.1562,\n",
            "          0.4081, -0.1483,  0.2981,  0.2483,  0.0854, -0.0089,  0.1526,  0.2071],\n",
            "        [-0.1869,  0.2143,  0.1087,  0.0883, -0.0692,  0.1983, -0.0467, -0.0535,\n",
            "          0.0139,  0.0766,  0.0871,  0.0946,  0.2147, -0.1459, -0.1495,  0.0122],\n",
            "        [ 0.0299, -0.1097, -0.0743, -0.1682,  0.0721, -0.0018,  0.0651, -0.1246,\n",
            "          0.2696, -0.0450, -0.1371,  0.2195, -0.2329,  0.1855,  0.0985,  0.1555],\n",
            "        [-0.0528, -0.2506, -0.2322, -0.0164, -0.1863,  0.0544, -0.1890,  0.1185,\n",
            "         -0.3569,  0.0389, -0.1806,  0.1579,  0.0199,  0.0141, -0.1970,  0.1270],\n",
            "        [ 0.1722, -0.2203, -0.0865, -0.1432, -0.1524, -0.0048, -0.1563, -0.0272,\n",
            "         -0.3122,  0.1387,  0.0985,  0.1203,  0.1856, -0.0276,  0.0990,  0.1275],\n",
            "        [ 0.0806, -0.1250,  0.2163,  0.0664, -0.0907,  0.0991,  0.0454,  0.0995,\n",
            "          0.2875,  0.1577, -0.0398,  0.1396,  0.0472, -0.2465,  0.2462,  0.1712],\n",
            "        [-0.0407,  0.1661, -0.1607,  0.0695,  0.0111,  0.0052,  0.0108, -0.2139,\n",
            "          0.1587, -0.1017,  0.0219,  0.2240, -0.1942,  0.0277,  0.0229,  0.0208]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([ 0.1403,  0.3143,  0.1076, -0.1037,  0.1771,  0.0956,  0.1237, -0.2422,\n",
            "         0.0436,  0.2242,  0.0349,  0.2330, -0.1872, -0.0603,  0.1827,  0.2835],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[ 0.2352,  0.1926,  0.2336, -0.1059,  0.0599,  0.3462, -0.1146, -0.3348,\n",
            "          0.2017,  0.1992, -0.0216,  0.1708, -0.1651, -0.0281,  0.0989,  0.2265]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([-0.0153], dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NN_l1_l2_reg(\n",
              "  (hidden_layers): ModuleList(\n",
              "    (0): Linear(in_features=2, out_features=16, bias=True)\n",
              "    (1): Linear(in_features=16, out_features=16, bias=True)\n",
              "  )\n",
              "  (output_layer): Linear(in_features=16, out_features=1, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_1000_random_pi_b_1000_mse.get_heatmap()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "6F_WX-VH6smT",
        "outputId": "8be72257-6aab-4121-8d16-781b25f33e9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"50f66f91-c8f6-4cd6-9707-fb58855bc899\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"50f66f91-c8f6-4cd6-9707-fb58855bc899\")) {                    Plotly.newPlot(                        \"50f66f91-c8f6-4cd6-9707-fb58855bc899\",                        [{\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"z\":[[0.7602143440809085,0.7219188394110355,0.6361248083264694,0.5162044169056704,0.43734908063580785,0.3653144258347806,0.337067527106659,0.3266448082453348,0.33796182375025785,0.3562135060310278],[0.7000603805454766,0.6449792205694039,0.5989578741150444,0.522330717637918,0.43343276040403006,0.35673588655971883,0.3163130663355696,0.3153805636373545,0.32934192809694274,0.3475936103777128],[0.6430753141130667,0.5775280412451608,0.5182920846502835,0.46825211892401075,0.39821511127798787,0.31756065525942384,0.3257226454187055,0.3306514517923347,0.33151019849625085,0.3414379939410658],[0.586090247680657,0.5212825553843744,0.45412320343183904,0.3869608168120358,0.3471725539934724,0.3306153747588197,0.3103203267861991,0.31291782562070775,0.33669429477341306,0.35438414752395636],[0.5291051812482469,0.4642974889519646,0.3953878767848824,0.3428144903399029,0.32684046241692144,0.3352628800504994,0.31445559550342966,0.30176669873500983,0.30407689528571635,0.330284101273375],[0.4721201148158371,0.4072933524438386,0.3617934595740955,0.3454232981371316,0.32793130393429337,0.32482013004213095,0.3245862973330148,0.30658702107198477,0.3068676851271073,0.30944943257572305],[0.4234247826954969,0.3791788288333858,0.3657011154129674,0.3479059110227389,0.3311526883185155,0.3227321105455563,0.3271534311783812,0.3226624580670224,0.31265002358277516,0.31523177103139083],[0.4134298217745746,0.38039294386898526,0.3671599529984417,0.35038852390834624,0.3343740727027377,0.32064409104898167,0.32182793503304397,0.33740729235276046,0.32310483349854263,0.3210141094870586],[0.423545937408005,0.3890012762374814,0.36837858358845876,0.35514107716349747,0.33759545708696004,0.3220361016701214,0.3186237586741912,0.331071318053404,0.34445260848830983,0.32705968737851965],[0.43603605765517833,0.39911739187091183,0.3695438918487912,0.3563642233079323,0.34081684147118213,0.32476963412430543,0.31898994317489876,0.3257458219080668,0.3422763904243863,0.34654694481310355]],\"type\":\"heatmap\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"Values\"},\"ticks\":\"outside\",\"tickvals\":[0.30176669873500983,0.7602143440809085],\"ticktext\":[0.30176669873500983,0.7602143440809085]}},\"xaxis\":{\"tickvals\":[0,1,2,3,4,5,6,7,8,9],\"ticktext\":[0,1,2,3,4,5,6,7,8,9],\"title\":{\"text\":\"X\"}},\"yaxis\":{\"tickvals\":[9,8,7,6,5,4,3,2,1,0],\"ticktext\":[9,8,7,6,5,4,3,2,1,0],\"title\":{\"text\":\"Y\"},\"autorange\":\"reversed\"},\"title\":{\"text\":\"Heatmap\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('50f66f91-c8f6-4cd6-9707-fb58855bc899');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IF6qj6JOF8jM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment 3 env_100"
      ],
      "metadata": {
        "id": "_0Qfio2f4vaw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VZKcZmV341Ek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_200_random_pi_b_200_env_100.evaluate_scope()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVK5dBacjvks",
        "outputId": "9d99e2c1-ca2d-4b16-ef4c-dee2a049b714"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.4748, dtype=torch.float64, grad_fn=<MeanBackward0>),\n",
              " tensor(0.0947, dtype=torch.float64, grad_fn=<VarBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b_200 = action_probs_top_n_epsilon(q_table, 1, 0.4)\n",
        "pi_b_200 = experiment_actions(200, env_100, P_pi_b_200)\n",
        "P_pi_e_200 = action_probs_top_n_epsilon(q_table, 1, 0.05)\n",
        "# pi_e_200 = experiment_actions(1000, env_100, P_pi_e_200)\n",
        "# model_200_random_pi_b_200_env_100 = CustomizableFeatureNet(input_dim=2, hidden_dims=[16, 16], output_dim=1, dtype = torch.float64, l2_lambda=0.002)\n",
        "model_200_random_pi_b_200_env_100 = NN_l1_l2_reg(input_dim=2, hidden_dims=[6], output_dim=1, dtype = torch.float64, l1_lambda=0.00001, l2_lambda = 0.00001)\n",
        "test_200_random_pi_b_200_env_100 = SCOPE_straight(model_200_random_pi_b_200_env_100, 0.99, 10000, pi_b_200, P_pi_b_200, P_pi_e_200, 0.3, dtype = torch.float64)\n",
        "test_200_random_pi_b_200_env_100.train_var_scope(300, 0.001, 1, 0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04d21b9f-f507-4682-f754-d579920379ed",
        "id": "eF2GH9wk41u4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0065, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.952126796991125\n",
            "SCOPE mean: -0.10654215033536209, SCOPE var: 0.016902695762594084\n",
            "Total Loss: 1.2017277958598398\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0289, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  12.041383567392199\n",
            "SCOPE mean: -0.10107118088490599, SCOPE var: 0.016076063682742302\n",
            "Total Loss: 1.233047946838456\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0277, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.797057650302548\n",
            "SCOPE mean: -0.0955841077017358, SCOPE var: 0.015279902652995808\n",
            "Total Loss: 1.2074291263107775\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0266, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.556248216906052\n",
            "SCOPE mean: -0.09008555276987734, SCOPE var: 0.014514864887931444\n",
            "Total Loss: 1.18218847159281\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0254, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.319069485971076\n",
            "SCOPE mean: -0.08457852163756474, SCOPE var: 0.013781270723017916\n",
            "Total Loss: 1.1573379914008317\n",
            "----------------------------------------\n",
            "Epoch 6\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0243, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  11.086278544506886\n",
            "SCOPE mean: -0.0791374479022111, SCOPE var: 0.013075303802390323\n",
            "Total Loss: 1.13294768372902\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0232, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.857551425450936\n",
            "SCOPE mean: -0.07372142293400756, SCOPE var: 0.012399809972091645\n",
            "Total Loss: 1.1089889015972836\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0222, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.632549809907228\n",
            "SCOPE mean: -0.06829987888106194, SCOPE var: 0.011756791511919745\n",
            "Total Loss: 1.085430920213544\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0211, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.410543152907673\n",
            "SCOPE mean: -0.0628859331201743, SCOPE var: 0.011146464258388895\n",
            "Total Loss: 1.0622009201697034\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0201, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  10.192546531032663\n",
            "SCOPE mean: -0.05745533809808885, SCOPE var: 0.010566493724131926\n",
            "Total Loss: 1.039400067337621\n",
            "----------------------------------------\n",
            "Epoch 11\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0192, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.978716631673125\n",
            "SCOPE mean: -0.052004010494651844, SCOPE var: 0.010016040857303496\n",
            "Total Loss: 1.017044084621929\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0182, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.768770775852522\n",
            "SCOPE mean: -0.046556989041538245, SCOPE var: 0.009497712711462443\n",
            "Total Loss: 0.995105110385066\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0173, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.56272506884156\n",
            "SCOPE mean: -0.04111570965187586, SCOPE var: 0.009011216942364873\n",
            "Total Loss: 0.9735846948978206\n",
            "----------------------------------------\n",
            "Epoch 14\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0164, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.360592559501525\n",
            "SCOPE mean: -0.03568164809827381, SCOPE var: 0.008556244203486095\n",
            "Total Loss: 0.9524840606878724\n",
            "----------------------------------------\n",
            "Epoch 15\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0156, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  9.162755310637\n",
            "SCOPE mean: -0.030240529869182405, SCOPE var: 0.0081326730088329\n",
            "Total Loss: 0.9318411550377382\n",
            "----------------------------------------\n",
            "Epoch 16\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0147, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.969130455803398\n",
            "SCOPE mean: -0.024800142435401896, SCOPE var: 0.007740063421575895\n",
            "Total Loss: 0.9116476830982176\n",
            "----------------------------------------\n",
            "Epoch 17\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0139, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.77959680964984\n",
            "SCOPE mean: -0.01937282570968237, SCOPE var: 0.007378000105893496\n",
            "Total Loss: 0.8918915224923903\n",
            "----------------------------------------\n",
            "Epoch 18\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0132, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.593998615095062\n",
            "SCOPE mean: -0.013958263025242161, SCOPE var: 0.007046041093658467\n",
            "Total Loss: 0.8725568856173783\n",
            "----------------------------------------\n",
            "Epoch 19\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0124, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.412324466948672\n",
            "SCOPE mean: -0.008558163992094567, SCOPE var: 0.0067437305984109795\n",
            "Total Loss: 0.8536424005236949\n",
            "----------------------------------------\n",
            "Epoch 20\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0117, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.234560620310907\n",
            "SCOPE mean: -0.0031742062088584693, SCOPE var: 0.00647059640710284\n",
            "Total Loss: 0.8351464409828847\n",
            "----------------------------------------\n",
            "Epoch 21\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0110, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  8.060690825081837\n",
            "SCOPE mean: 0.0021919625547154316, SCOPE var: 0.00622614924303001\n",
            "Total Loss: 0.8170671096348368\n",
            "----------------------------------------\n",
            "Epoch 22\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0103, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.89069622918275\n",
            "SCOPE mean: 0.0075387229515602484, SCOPE var: 0.006009882594827312\n",
            "Total Loss: 0.7994022283376557\n",
            "----------------------------------------\n",
            "Epoch 23\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0097, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.724555333660759\n",
            "SCOPE mean: 0.012864483057061477, SCOPE var: 0.005821272889011679\n",
            "Total Loss: 0.7821493339576177\n",
            "----------------------------------------\n",
            "Epoch 24\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0091, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.562243987591762\n",
            "SCOPE mean: 0.01816763142263287, SCOPE var: 0.005659780002882537\n",
            "Total Loss: 0.7653056782405221\n",
            "----------------------------------------\n",
            "Epoch 25\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0085, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.40373541300118\n",
            "SCOPE mean: 0.023446039349861753, SCOPE var: 0.005524848877028447\n",
            "Total Loss: 0.748868230010904\n",
            "----------------------------------------\n",
            "Epoch 26\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0079, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.248999448002483\n",
            "SCOPE mean: 0.028698844031269197, SCOPE var: 0.005415906926196124\n",
            "Total Loss: 0.7328336036740268\n",
            "----------------------------------------\n",
            "Epoch 27\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0074, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  7.09852390711137\n",
            "SCOPE mean: 0.033981550281322576, SCOPE var: 0.005332425117203995\n",
            "Total Loss: 0.7172503994554034\n",
            "----------------------------------------\n",
            "Epoch 28\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0069, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.9518455161825035\n",
            "SCOPE mean: 0.039245874647144685, SCOPE var: 0.005273770468531294\n",
            "Total Loss: 0.7020717360799559\n",
            "----------------------------------------\n",
            "Epoch 29\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0064, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.808848904530928\n",
            "SCOPE mean: 0.04448204887110017, SCOPE var: 0.005239309730298623\n",
            "Total Loss: 0.6872856143622026\n",
            "----------------------------------------\n",
            "Epoch 30\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0059, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.669489927866739\n",
            "SCOPE mean: 0.049688249576018806, SCOPE var: 0.005228409630560053\n",
            "Total Loss: 0.6728871743345971\n",
            "----------------------------------------\n",
            "Epoch 31\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0055, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.533736006383865\n",
            "SCOPE mean: 0.05486273344678426, SCOPE var: 0.005240428515534575\n",
            "Total Loss: 0.6588727006348198\n",
            "----------------------------------------\n",
            "Epoch 32\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0051, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.4015275050638\n",
            "SCOPE mean: 0.060003709158620765, SCOPE var: 0.0052747176931216165\n",
            "Total Loss: 0.6452357644863962\n",
            "----------------------------------------\n",
            "Epoch 33\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0047, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.272815530761042\n",
            "SCOPE mean: 0.06510959410540068, SCOPE var: 0.0053306196521010485\n",
            "Total Loss: 0.6319709957831127\n",
            "----------------------------------------\n",
            "Epoch 34\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0043, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.147550627474126\n",
            "SCOPE mean: 0.0701788656654423, SCOPE var: 0.005407471148276816\n",
            "Total Loss: 0.6190729586622082\n",
            "----------------------------------------\n",
            "Epoch 35\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0040, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.0256821756643975\n",
            "SCOPE mean: 0.07521005713591589, SCOPE var: 0.005504603953934613\n",
            "Total Loss: 0.6065360922424745\n",
            "----------------------------------------\n",
            "Epoch 36\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.907007286358742\n",
            "SCOPE mean: 0.08020173956193942, SCOPE var: 0.0056213457411924345\n",
            "Total Loss: 0.5943396029342177\n",
            "----------------------------------------\n",
            "Epoch 37\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0033, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.791556960955518\n",
            "SCOPE mean: 0.08515277586278024, SCOPE var: 0.005757032478169124\n",
            "Total Loss: 0.5824860757791098\n",
            "----------------------------------------\n",
            "Epoch 38\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0030, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.679338600636851\n",
            "SCOPE mean: 0.09006182534142737, SCOPE var: 0.005910985946191644\n",
            "Total Loss: 0.5709757310448149\n",
            "----------------------------------------\n",
            "Epoch 39\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0028, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.570300165176566\n",
            "SCOPE mean: 0.09492758702334618, SCOPE var: 0.006082525693611198\n",
            "Total Loss: 0.55980284006697\n",
            "----------------------------------------\n",
            "Epoch 40\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0025, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.464388496235187\n",
            "SCOPE mean: 0.09974880287845253, SCOPE var: 0.006270969720806514\n",
            "Total Loss: 0.5489615575780341\n",
            "----------------------------------------\n",
            "Epoch 41\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0023, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.361549425046363\n",
            "SCOPE mean: 0.1045242558189479, SCOPE var: 0.006475635197871838\n",
            "Total Loss: 0.538445933262892\n",
            "----------------------------------------\n",
            "Epoch 42\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0021, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.261721291806628\n",
            "SCOPE mean: 0.1092527723442495, SCOPE var: 0.0066958391482758685\n",
            "Total Loss: 0.5282492644678944\n",
            "----------------------------------------\n",
            "Epoch 43\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0019, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.1648380604247865\n",
            "SCOPE mean: 0.11393353861535434, SCOPE var: 0.006930910024533338\n",
            "Total Loss: 0.5183644008032389\n",
            "----------------------------------------\n",
            "Epoch 44\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0017, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.070942377163354\n",
            "SCOPE mean: 0.11857611776059232, SCOPE var: 0.007179719964280079\n",
            "Total Loss: 0.5087950428752692\n",
            "----------------------------------------\n",
            "Epoch 45\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0015, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.97993828330479\n",
            "SCOPE mean: 0.1231743924531489, SCOPE var: 0.007441888690901011\n",
            "Total Loss: 0.4995309966482169\n",
            "----------------------------------------\n",
            "Epoch 46\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0014, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.891727584104138\n",
            "SCOPE mean: 0.12772209508451557, SCOPE var: 0.007716957293159455\n",
            "Total Loss: 0.4905619026531415\n",
            "----------------------------------------\n",
            "Epoch 47\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.806251101415139\n",
            "SCOPE mean: 0.1322180944893095, SCOPE var: 0.008004247818676204\n",
            "Total Loss: 0.481881306826101\n",
            "----------------------------------------\n",
            "Epoch 48\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.723449424822188\n",
            "SCOPE mean: 0.1366613070615151, SCOPE var: 0.008303086237845687\n",
            "Total Loss: 0.47348273260729945\n",
            "----------------------------------------\n",
            "Epoch 49\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.643262973424281\n",
            "SCOPE mean: 0.141050694749004, SCOPE var: 0.008612803008596574\n",
            "Total Loss: 0.46535968775174924\n",
            "----------------------------------------\n",
            "Epoch 50\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.565632055991677\n",
            "SCOPE mean: 0.1453852633418509, SCOPE var: 0.008932733630363184\n",
            "Total Loss: 0.45750567095661315\n",
            "----------------------------------------\n",
            "Epoch 51\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.490505498453341\n",
            "SCOPE mean: 0.14966406293189333, SCOPE var: 0.009262219179298294\n",
            "Total Loss: 0.4499150352017462\n",
            "----------------------------------------\n",
            "Epoch 52\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.417819588897564\n",
            "SCOPE mean: 0.15388625942916975, SCOPE var: 0.009600605336657995\n",
            "Total Loss: 0.44258088350494107\n",
            "----------------------------------------\n",
            "Epoch 53\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.34751027632389\n",
            "SCOPE mean: 0.1580509731890019, SCOPE var: 0.009947245887938501\n",
            "Total Loss: 0.43549628771929816\n",
            "----------------------------------------\n",
            "Epoch 54\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.2795171767745535\n",
            "SCOPE mean: 0.16215736832178787, SCOPE var: 0.010301502031451203\n",
            "Total Loss: 0.4286546906770197\n",
            "----------------------------------------\n",
            "Epoch 55\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.213784134075281\n",
            "SCOPE mean: 0.16620463620689702, SCOPE var: 0.010662741671787676\n",
            "Total Loss: 0.4220499628256169\n",
            "----------------------------------------\n",
            "Epoch 56\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.150251998343579\n",
            "SCOPE mean: 0.17019200786262553, SCOPE var: 0.011030340871580158\n",
            "Total Loss: 0.41567568044959696\n",
            "----------------------------------------\n",
            "Epoch 57\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.088861863116649\n",
            "SCOPE mean: 0.17411875355899561, SCOPE var: 0.011403684357600925\n",
            "Total Loss: 0.4095254498790823\n",
            "----------------------------------------\n",
            "Epoch 58\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.029497350706299\n",
            "SCOPE mean: 0.17799296346412286, SCOPE var: 0.011783414267781463\n",
            "Total Loss: 0.4035869883481102\n",
            "----------------------------------------\n",
            "Epoch 59\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.9716463191443268\n",
            "SCOPE mean: 0.18187957883862102, SCOPE var: 0.012178569778060526\n",
            "Total Loss: 0.39780790699922286\n",
            "----------------------------------------\n",
            "Epoch 60\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.915734330727845\n",
            "SCOPE mean: 0.18570641532252796, SCOPE var: 0.012578699383172728\n",
            "Total Loss: 0.3922318099208259\n",
            "----------------------------------------\n",
            "Epoch 61\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.8616070576185724\n",
            "SCOPE mean: 0.18945765193815792, SCOPE var: 0.012983403344577954\n",
            "Total Loss: 0.38684279867343363\n",
            "----------------------------------------\n",
            "Epoch 62\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.809275940006264\n",
            "SCOPE mean: 0.19314549335036554, SCOPE var: 0.013392176027625918\n",
            "Total Loss: 0.3816415609309592\n",
            "----------------------------------------\n",
            "Epoch 63\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.7587302613812312\n",
            "SCOPE mean: 0.19677396631395866, SCOPE var: 0.013804327224735994\n",
            "Total Loss: 0.3766265676136061\n",
            "----------------------------------------\n",
            "Epoch 64\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.70992172718158\n",
            "SCOPE mean: 0.20034200716100753, SCOPE var: 0.014219260025561741\n",
            "Total Loss: 0.3717925346170933\n",
            "----------------------------------------\n",
            "Epoch 65\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.662801711836792\n",
            "SCOPE mean: 0.20384863110231352, SCOPE var: 0.014636386633630254\n",
            "Total Loss: 0.3671341477725814\n",
            "----------------------------------------\n",
            "Epoch 66\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.6173213873456493\n",
            "SCOPE mean: 0.20729292946912428, SCOPE var: 0.015055129254964456\n",
            "Total Loss: 0.3626460767056373\n",
            "----------------------------------------\n",
            "Epoch 67\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.573431841710403\n",
            "SCOPE mean: 0.21067406733069682, SCOPE var: 0.01547492094600247\n",
            "Total Loss: 0.35832298761314496\n",
            "----------------------------------------\n",
            "Epoch 68\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.5310841882826454\n",
            "SCOPE mean: 0.21399128143977733, SCOPE var: 0.015895206422977953\n",
            "Total Loss: 0.35415955506872143\n",
            "----------------------------------------\n",
            "Epoch 69\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.4902296669273025\n",
            "SCOPE mean: 0.21724387846257295, SCOPE var: 0.01631544283431735\n",
            "Total Loss: 0.3501504729515211\n",
            "----------------------------------------\n",
            "Epoch 70\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.4508113950486585\n",
            "SCOPE mean: 0.22043155436353237, SCOPE var: 0.01673510259967969\n",
            "Total Loss: 0.34628962588207945\n",
            "----------------------------------------\n",
            "Epoch 71\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.4131264082946875\n",
            "SCOPE mean: 0.22302704758386493, SCOPE var: 0.017089752351734083\n",
            "Total Loss: 0.342611464513954\n",
            "----------------------------------------\n",
            "Epoch 72\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0014, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.376836191681513\n",
            "SCOPE mean: 0.225508289040208, SCOPE var: 0.01743475547761196\n",
            "Total Loss: 0.3390776108629936\n",
            "----------------------------------------\n",
            "Epoch 73\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0015, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.341849533577334\n",
            "SCOPE mean: 0.2279350909491946, SCOPE var: 0.01777695507522209\n",
            "Total Loss: 0.33567792399466423\n",
            "----------------------------------------\n",
            "Epoch 74\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0016, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.308116648390402\n",
            "SCOPE mean: 0.2303068482169987, SCOPE var: 0.018115996625094995\n",
            "Total Loss: 0.3324069742227561\n",
            "----------------------------------------\n",
            "Epoch 75\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0017, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.2755886479363387\n",
            "SCOPE mean: 0.23262302546528357, SCOPE var: 0.018451537713379346\n",
            "Total Loss: 0.32925943861840656\n",
            "----------------------------------------\n",
            "Epoch 76\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0018, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.2442175924493055\n",
            "SCOPE mean: 0.2348831552057324, SCOPE var: 0.018783248506088177\n",
            "Total Loss: 0.3262301059287051\n",
            "----------------------------------------\n",
            "Epoch 77\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0019, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.2139565315139595\n",
            "SCOPE mean: 0.23708683635870997, SCOPE var: 0.019110812197317285\n",
            "Total Loss: 0.32331388051506554\n",
            "----------------------------------------\n",
            "Epoch 78\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0020, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.184759538541679\n",
            "SCOPE mean: 0.23923373298399578, SCOPE var: 0.01943392542869879\n",
            "Total Loss: 0.3205057856670088\n",
            "----------------------------------------\n",
            "Epoch 79\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0021, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.156741758734278\n",
            "SCOPE mean: 0.24172017275834196, SCOPE var: 0.019754844183909444\n",
            "Total Loss: 0.31781719257947866\n",
            "----------------------------------------\n",
            "Epoch 80\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0023, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.129728780041672\n",
            "SCOPE mean: 0.24419521821907023, SCOPE var: 0.02007101278455593\n",
            "Total Loss: 0.3152301142836742\n",
            "----------------------------------------\n",
            "Epoch 81\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0024, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.1035396901895664\n",
            "SCOPE mean: 0.24660261318472976, SCOPE var: 0.020381808983166133\n",
            "Total Loss: 0.31272608156314585\n",
            "----------------------------------------\n",
            "Epoch 82\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0025, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.078202184560597\n",
            "SCOPE mean: 0.24894580204606373, SCOPE var: 0.02068682488611993\n",
            "Total Loss: 0.31030759766486815\n",
            "----------------------------------------\n",
            "Epoch 83\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0026, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.0533364648743424\n",
            "SCOPE mean: 0.25128056511037655, SCOPE var: 0.020975311859628077\n",
            "Total Loss: 0.30793591120159325\n",
            "----------------------------------------\n",
            "Epoch 84\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0027, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.0292265896369117\n",
            "SCOPE mean: 0.2535574923096753, SCOPE var: 0.021256244004080427\n",
            "Total Loss: 0.3056394822441655\n",
            "----------------------------------------\n",
            "Epoch 85\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0028, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.0058318133256914\n",
            "SCOPE mean: 0.2557773626184576, SCOPE var: 0.02152930404322934\n",
            "Total Loss: 0.30341396547764427\n",
            "----------------------------------------\n",
            "Epoch 86\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0029, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.983116295321027\n",
            "SCOPE mean: 0.25794054031428043, SCOPE var: 0.021794276270733035\n",
            "Total Loss: 0.30125553009706757\n",
            "----------------------------------------\n",
            "Epoch 87\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0031, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.9610453141952062\n",
            "SCOPE mean: 0.2600474705747989, SCOPE var: 0.02205095737477162\n",
            "Total Loss: 0.2991604771525458\n",
            "----------------------------------------\n",
            "Epoch 88\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0032, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.939585166731169\n",
            "SCOPE mean: 0.2620986840193343, SCOPE var: 0.022299155537848177\n",
            "Total Loss: 0.2971252293688901\n",
            "----------------------------------------\n",
            "Epoch 89\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0033, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.9183414722216723\n",
            "SCOPE mean: 0.26403514689481034, SCOPE var: 0.022531825043688804\n",
            "Total Loss: 0.29510627667422645\n",
            "----------------------------------------\n",
            "Epoch 90\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0034, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.897195175726933\n",
            "SCOPE mean: 0.26583553990309444, SCOPE var: 0.022747057396885862\n",
            "Total Loss: 0.2930902878473795\n",
            "----------------------------------------\n",
            "Epoch 91\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0035, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.876499358983496\n",
            "SCOPE mean: 0.2675707983691438, SCOPE var: 0.0229517212234015\n",
            "Total Loss: 0.2911167548396002\n",
            "----------------------------------------\n",
            "Epoch 92\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.8562146318558295\n",
            "SCOPE mean: 0.2692411624520373, SCOPE var: 0.0231454325632529\n",
            "Total Loss: 0.2891815520979805\n",
            "----------------------------------------\n",
            "Epoch 93\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.836064294243006\n",
            "SCOPE mean: 0.27082100658087965, SCOPE var: 0.0233233003381346\n",
            "Total Loss: 0.28725495144130925\n",
            "----------------------------------------\n",
            "Epoch 94\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0037, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.815667453190264\n",
            "SCOPE mean: 0.2722715611993482, SCOPE var: 0.023478315256846412\n",
            "Total Loss: 0.2852956778319802\n",
            "----------------------------------------\n",
            "Epoch 95\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0038, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.7955458637408643\n",
            "SCOPE mean: 0.273652093828243, SCOPE var: 0.0236206550588918\n",
            "Total Loss: 0.28336000270600115\n",
            "----------------------------------------\n",
            "Epoch 96\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0039, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.775246208339731\n",
            "SCOPE mean: 0.2749608299866897, SCOPE var: 0.023744964293922925\n",
            "Total Loss: 0.2813999390551745\n",
            "----------------------------------------\n",
            "Epoch 97\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0039, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.7543145130763875\n",
            "SCOPE mean: 0.27619751551680266, SCOPE var: 0.023846054184740704\n",
            "Total Loss: 0.27936736091687125\n",
            "----------------------------------------\n",
            "Epoch 98\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0040, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.733431325824852\n",
            "SCOPE mean: 0.2773625600648206, SCOPE var: 0.023932793228252258\n",
            "Total Loss: 0.2773343325736311\n",
            "----------------------------------------\n",
            "Epoch 99\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0040, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.7117976778521355\n",
            "SCOPE mean: 0.27842503003743124, SCOPE var: 0.02400218826810614\n",
            "Total Loss: 0.2752153357419121\n",
            "----------------------------------------\n",
            "Epoch 100\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0041, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.689832205170737\n",
            "SCOPE mean: 0.2793665562256979, SCOPE var: 0.024052153495588622\n",
            "Total Loss: 0.27305634508351023\n",
            "----------------------------------------\n",
            "Epoch 101\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0041, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.6670826497285147\n",
            "SCOPE mean: 0.2801243625662085, SCOPE var: 0.024076619875744797\n",
            "Total Loss: 0.2708106663842937\n",
            "----------------------------------------\n",
            "Epoch 102\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0041, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.64428294813153\n",
            "SCOPE mean: 0.28080407994225154, SCOPE var: 0.024085845990791454\n",
            "Total Loss: 0.2685545825716411\n",
            "----------------------------------------\n",
            "Epoch 103\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0041, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.6214260917819017\n",
            "SCOPE mean: 0.28140674397928744, SCOPE var: 0.02408000111741965\n",
            "Total Loss: 0.2662875335423442\n",
            "----------------------------------------\n",
            "Epoch 104\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0042, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.5985126820004307\n",
            "SCOPE mean: 0.2819337745979945, SCOPE var: 0.02405938443158891\n",
            "Total Loss: 0.2640097825124053\n",
            "----------------------------------------\n",
            "Epoch 105\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0042, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.5755469578107606\n",
            "SCOPE mean: 0.2823867498194082, SCOPE var: 0.02402436102723883\n",
            "Total Loss: 0.2617219931604841\n",
            "----------------------------------------\n",
            "Epoch 106\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0042, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.552535258691424\n",
            "SCOPE mean: 0.2827673193718956, SCOPE var: 0.023975336357661744\n",
            "Total Loss: 0.25942506517482494\n",
            "----------------------------------------\n",
            "Epoch 107\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0042, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.529485383722317\n",
            "SCOPE mean: 0.28307717052937886, SCOPE var: 0.02391274488308487\n",
            "Total Loss: 0.2571200649541751\n",
            "----------------------------------------\n",
            "Epoch 108\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0042, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.506406304649295\n",
            "SCOPE mean: 0.2833180146806084, SCOPE var: 0.02383704440407674\n",
            "Total Loss: 0.25480819387987363\n",
            "----------------------------------------\n",
            "Epoch 109\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0042, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.4833080234182483\n",
            "SCOPE mean: 0.2834915822923661, SCOPE var: 0.023748712785259536\n",
            "Total Loss: 0.2524907719191559\n",
            "----------------------------------------\n",
            "Epoch 110\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0041, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.4602014883544725\n",
            "SCOPE mean: 0.2835996211913301, SCOPE var: 0.023648245708416244\n",
            "Total Loss: 0.2501692274453341\n",
            "----------------------------------------\n",
            "Epoch 111\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0041, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.4370985325770866\n",
            "SCOPE mean: 0.28364389603516776, SCOPE var: 0.023536154868314212\n",
            "Total Loss: 0.24784508940897712\n",
            "----------------------------------------\n",
            "Epoch 112\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0041, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.4140117622149053\n",
            "SCOPE mean: 0.2836261880915674, SCOPE var: 0.023412966352804414\n",
            "Total Loss: 0.24551997453016725\n",
            "----------------------------------------\n",
            "Epoch 113\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0041, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.3909544721130804\n",
            "SCOPE mean: 0.28354829622955097, SCOPE var: 0.02327921909579752\n",
            "Total Loss: 0.24319557786659568\n",
            "----------------------------------------\n",
            "Epoch 114\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0041, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.3679409544738546\n",
            "SCOPE mean: 0.2834120342632363, SCOPE var: 0.023135463370735423\n",
            "Total Loss: 0.24087370070798955\n",
            "----------------------------------------\n",
            "Epoch 115\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0041, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.344986023271249\n",
            "SCOPE mean: 0.2832192313896869, SCOPE var: 0.022982259243570988\n",
            "Total Loss: 0.23855620200696692\n",
            "----------------------------------------\n",
            "Epoch 116\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0040, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.322105086594215\n",
            "SCOPE mean: 0.28297173153975047, SCOPE var: 0.02282017505497901\n",
            "Total Loss: 0.23624500388787856\n",
            "----------------------------------------\n",
            "Epoch 117\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0040, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.2993140803413388\n",
            "SCOPE mean: 0.2826713926535485, SCOPE var: 0.022649785906041\n",
            "Total Loss: 0.23394208329759253\n",
            "----------------------------------------\n",
            "Epoch 118\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0040, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.2766413025251566\n",
            "SCOPE mean: 0.28232211765194615, SCOPE var: 0.022471671726375465\n",
            "Total Loss: 0.23165062590219956\n",
            "----------------------------------------\n",
            "Epoch 119\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0040, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.2541010739246103\n",
            "SCOPE mean: 0.28192485319306576, SCOPE var: 0.02228640188452182\n",
            "Total Loss: 0.22937245192324598\n",
            "----------------------------------------\n",
            "Epoch 120\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0039, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.23170187546575\n",
            "SCOPE mean: 0.2814801096818299, SCOPE var: 0.02209456694857158\n",
            "Total Loss: 0.22710880816912307\n",
            "----------------------------------------\n",
            "Epoch 121\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0039, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.2094608521383607\n",
            "SCOPE mean: 0.2809898254855446, SCOPE var: 0.021896756912995016\n",
            "Total Loss: 0.22486178367266932\n",
            "----------------------------------------\n",
            "Epoch 122\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0039, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.187395338933508\n",
            "SCOPE mean: 0.28045594663445306, SCOPE var: 0.02169356091462383\n",
            "Total Loss: 0.22263347978440517\n",
            "----------------------------------------\n",
            "Epoch 123\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0039, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.1655227820914047\n",
            "SCOPE mean: 0.2798804264642458, SCOPE var: 0.02148556582361118\n",
            "Total Loss: 0.2204260005490069\n",
            "----------------------------------------\n",
            "Epoch 124\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0039, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.143860659704957\n",
            "SCOPE mean: 0.27926522531112113, SCOPE var: 0.02127335485877627\n",
            "Total Loss: 0.21824144302335663\n",
            "----------------------------------------\n",
            "Epoch 125\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0038, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.1224264017905154\n",
            "SCOPE mean: 0.27861231026073635, SCOPE var: 0.021057506228136895\n",
            "Total Loss: 0.2160818875499003\n",
            "----------------------------------------\n",
            "Epoch 126\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0038, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.100623199110495\n",
            "SCOPE mean: 0.2780110115821934, SCOPE var: 0.020828728549789566\n",
            "Total Loss: 0.21388745212269739\n",
            "----------------------------------------\n",
            "Epoch 127\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0038, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.0780658960170446\n",
            "SCOPE mean: 0.27746085403975196, SCOPE var: 0.02058394213766987\n",
            "Total Loss: 0.21161988096298737\n",
            "----------------------------------------\n",
            "Epoch 128\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0038, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.055147127162677\n",
            "SCOPE mean: 0.276844635611799, SCOPE var: 0.020333817244545086\n",
            "Total Loss: 0.20931917605471043\n",
            "----------------------------------------\n",
            "Epoch 129\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0038, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.031426305975384\n",
            "SCOPE mean: 0.27604691844455526, SCOPE var: 0.02007940077414864\n",
            "Total Loss: 0.2069405564300563\n",
            "----------------------------------------\n",
            "Epoch 130\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0038, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.007707888844149\n",
            "SCOPE mean: 0.27518250892244084, SCOPE var: 0.019820772652251767\n",
            "Total Loss: 0.20456655961462084\n",
            "----------------------------------------\n",
            "Epoch 131\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0038, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.9839641324098536\n",
            "SCOPE mean: 0.2742319626473328, SCOPE var: 0.01955887142926283\n",
            "Total Loss: 0.20219512152663258\n",
            "----------------------------------------\n",
            "Epoch 132\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0038, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.9604776069785868\n",
            "SCOPE mean: 0.273243962008911, SCOPE var: 0.01929475597302978\n",
            "Total Loss: 0.19985501907553715\n",
            "----------------------------------------\n",
            "Epoch 133\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0038, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.9373079316670456\n",
            "SCOPE mean: 0.27222204146883294, SCOPE var: 0.01902944516707496\n",
            "Total Loss: 0.19755266111603573\n",
            "----------------------------------------\n",
            "Epoch 134\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0038, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.9145094544295427\n",
            "SCOPE mean: 0.27116961552682406, SCOPE var: 0.018763893993455908\n",
            "Total Loss: 0.19529387089967698\n",
            "----------------------------------------\n",
            "Epoch 135\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0039, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.891880435364104\n",
            "SCOPE mean: 0.2700426097755856, SCOPE var: 0.018481133001278564\n",
            "Total Loss: 0.19304336764252833\n",
            "----------------------------------------\n",
            "Epoch 136\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0038, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.8686007695420486\n",
            "SCOPE mean: 0.26869048966205183, SCOPE var: 0.01812651876143792\n",
            "Total Loss: 0.19067499161592943\n",
            "----------------------------------------\n",
            "Epoch 137\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0038, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.8457176961040915\n",
            "SCOPE mean: 0.2673028457539267, SCOPE var: 0.017771822786463626\n",
            "Total Loss: 0.18835607443026584\n",
            "----------------------------------------\n",
            "Epoch 138\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0038, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.8232923394130585\n",
            "SCOPE mean: 0.26588488931676424, SCOPE var: 0.017418549904099943\n",
            "Total Loss: 0.1860935988974285\n",
            "----------------------------------------\n",
            "Epoch 139\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0038, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.8010069263250303\n",
            "SCOPE mean: 0.26425821199879035, SCOPE var: 0.017043434162541973\n",
            "Total Loss: 0.18385706748405425\n",
            "----------------------------------------\n",
            "Epoch 140\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0038, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7782720663557863\n",
            "SCOPE mean: 0.26213565051908155, SCOPE var: 0.016610328085690657\n",
            "Total Loss: 0.18158933578906727\n",
            "----------------------------------------\n",
            "Epoch 141\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0038, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.756072445355106\n",
            "SCOPE mean: 0.2599762897824015, SCOPE var: 0.016183260976076648\n",
            "Total Loss: 0.1793884768335488\n",
            "----------------------------------------\n",
            "Epoch 142\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0038, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7344635252088991\n",
            "SCOPE mean: 0.25778781892004515, SCOPE var: 0.01576404806532261\n",
            "Total Loss: 0.17726054801666105\n",
            "----------------------------------------\n",
            "Epoch 143\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0039, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7134941952894807\n",
            "SCOPE mean: 0.2555778565241414, SCOPE var: 0.01535434287976189\n",
            "Total Loss: 0.17521077744247146\n",
            "----------------------------------------\n",
            "Epoch 144\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0039, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6932065940717531\n",
            "SCOPE mean: 0.2533538844504468, SCOPE var: 0.014955624604671876\n",
            "Total Loss: 0.17324353916894414\n",
            "----------------------------------------\n",
            "Epoch 145\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0040, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6735063420926788\n",
            "SCOPE mean: 0.2511262194890978, SCOPE var: 0.01456917940825689\n",
            "Total Loss: 0.17134937477804457\n",
            "----------------------------------------\n",
            "Epoch 146\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0041, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6544099959646963\n",
            "SCOPE mean: 0.24889874238668808, SCOPE var: 0.014195615047976616\n",
            "Total Loss: 0.16952979798152834\n",
            "----------------------------------------\n",
            "Epoch 147\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0042, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6360702158191651\n",
            "SCOPE mean: 0.24667590484344282, SCOPE var: 0.013836009452777225\n",
            "Total Loss: 0.16779975002157724\n",
            "----------------------------------------\n",
            "Epoch 148\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0043, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.618506836339524\n",
            "SCOPE mean: 0.2444649189639911, SCOPE var: 0.013491251599840163\n",
            "Total Loss: 0.16616070799253904\n",
            "----------------------------------------\n",
            "Epoch 149\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0044, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6017331961596393\n",
            "SCOPE mean: 0.24227288982790596, SCOPE var: 0.013162065289831019\n",
            "Total Loss: 0.1646133220477005\n",
            "----------------------------------------\n",
            "Epoch 150\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5850224089273572\n",
            "SCOPE mean: 0.23664674187837453, SCOPE var: 0.012832840539588922\n",
            "Total Loss: 0.1630837059135844\n",
            "----------------------------------------\n",
            "Epoch 151\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0047, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5690951683584686\n",
            "SCOPE mean: 0.2308537832223945, SCOPE var: 0.012518498496237162\n",
            "Total Loss: 0.16164387339976682\n",
            "----------------------------------------\n",
            "Epoch 152\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0049, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5540070683703011\n",
            "SCOPE mean: 0.22511281045474096, SCOPE var: 0.0122207137490231\n",
            "Total Loss: 0.1602983383581332\n",
            "----------------------------------------\n",
            "Epoch 153\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0051, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5396629498057401\n",
            "SCOPE mean: 0.21942532176017002, SCOPE var: 0.011939649490525537\n",
            "Total Loss: 0.15903676139948086\n",
            "----------------------------------------\n",
            "Epoch 154\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0053, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5260862720066617\n",
            "SCOPE mean: 0.21380882520797204, SCOPE var: 0.011677885712847282\n",
            "Total Loss: 0.15786132707976927\n",
            "----------------------------------------\n",
            "Epoch 155\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0054, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5133406749238034\n",
            "SCOPE mean: 0.2083043738520525, SCOPE var: 0.01143314631849089\n",
            "Total Loss: 0.156775416851036\n",
            "----------------------------------------\n",
            "Epoch 156\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0056, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.501403757318942\n",
            "SCOPE mean: 0.20293462442309015, SCOPE var: 0.01120539366015901\n",
            "Total Loss: 0.15577508385902497\n",
            "----------------------------------------\n",
            "Epoch 157\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0058, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.490260744250889\n",
            "SCOPE mean: 0.19772296028978575, SCOPE var: 0.010994544711983889\n",
            "Total Loss: 0.15485703357275324\n",
            "----------------------------------------\n",
            "Epoch 158\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0060, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4797948660404714\n",
            "SCOPE mean: 0.19269324128667373, SCOPE var: 0.010800347328432325\n",
            "Total Loss: 0.1540086828716156\n",
            "----------------------------------------\n",
            "Epoch 159\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0062, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4700412470546926\n",
            "SCOPE mean: 0.18785698125164985, SCOPE var: 0.010622184616335087\n",
            "Total Loss: 0.15323094859016614\n",
            "----------------------------------------\n",
            "Epoch 160\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0064, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4609728109335305\n",
            "SCOPE mean: 0.1832337764218204, SCOPE var: 0.0104595826897654\n",
            "Total Loss: 0.1525189787122946\n",
            "----------------------------------------\n",
            "Epoch 161\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0066, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4525430003023014\n",
            "SCOPE mean: 0.17884162913654222, SCOPE var: 0.0103119480958626\n",
            "Total Loss: 0.15186616402677083\n",
            "----------------------------------------\n",
            "Epoch 162\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0068, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4447019945864303\n",
            "SCOPE mean: 0.17469642508852218, SCOPE var: 0.010178590525011527\n",
            "Total Loss: 0.1512656318179614\n",
            "----------------------------------------\n",
            "Epoch 163\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0070, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.437397952303556\n",
            "SCOPE mean: 0.17081174361039575, SCOPE var: 0.010058745645690937\n",
            "Total Loss: 0.15071041130544807\n",
            "----------------------------------------\n",
            "Epoch 164\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0071, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4305782415235184\n",
            "SCOPE mean: 0.16719868838012822, SCOPE var: 0.009951597811755917\n",
            "Total Loss: 0.15019359570289362\n",
            "----------------------------------------\n",
            "Epoch 165\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0073, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4241728684942196\n",
            "SCOPE mean: 0.16386538573491177, SCOPE var: 0.009856302757783665\n",
            "Total Loss: 0.14970672028743032\n",
            "----------------------------------------\n",
            "Epoch 166\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0074, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4181458589168785\n",
            "SCOPE mean: 0.16081474551765343, SCOPE var: 0.009771933785109457\n",
            "Total Loss: 0.149245035097253\n",
            "----------------------------------------\n",
            "Epoch 167\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0076, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4124533157197279\n",
            "SCOPE mean: 0.15805027160464724, SCOPE var: 0.009697661146465027\n",
            "Total Loss: 0.14880311805219007\n",
            "----------------------------------------\n",
            "Epoch 168\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0077, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.407050357509808\n",
            "SCOPE mean: 0.1555726229374487, SCOPE var: 0.009632677597384797\n",
            "Total Loss: 0.14837569351945024\n",
            "----------------------------------------\n",
            "Epoch 169\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0078, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4018959097878059\n",
            "SCOPE mean: 0.15337980418383657, SCOPE var: 0.0095762096151749\n",
            "Total Loss: 0.14795812259849814\n",
            "----------------------------------------\n",
            "Epoch 170\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0079, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.396952912638656\n",
            "SCOPE mean: 0.15146715264193258, SCOPE var: 0.009527530877038316\n",
            "Total Loss: 0.1475464170769293\n",
            "----------------------------------------\n",
            "Epoch 171\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0079, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.3921887478875934\n",
            "SCOPE mean: 0.1498275996488549, SCOPE var: 0.009485965571366724\n",
            "Total Loss: 0.14713728024975326\n",
            "----------------------------------------\n",
            "Epoch 172\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0080, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.3875752928443497\n",
            "SCOPE mean: 0.14845187647285463, SCOPE var: 0.009450891446889891\n",
            "Total Loss: 0.14672809819584431\n",
            "----------------------------------------\n",
            "Epoch 173\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0080, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.383088779860969\n",
            "SCOPE mean: 0.14732874091249792, SCOPE var: 0.009421740518622285\n",
            "Total Loss: 0.14631690482239681\n",
            "----------------------------------------\n",
            "Epoch 174\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0080, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.3787095469293311\n",
            "SCOPE mean: 0.1464452457700639, SCOPE var: 0.009397996885404533\n",
            "Total Loss: 0.1459023323367425\n",
            "----------------------------------------\n",
            "Epoch 175\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0080, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.374421679051261\n",
            "SCOPE mean: 0.1457870235693432, SCOPE var: 0.009379192674747088\n",
            "Total Loss: 0.1454835475939776\n",
            "----------------------------------------\n",
            "Epoch 176\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0080, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.3702125730382595\n",
            "SCOPE mean: 0.1453385781189134, SCOPE var: 0.009364902680351648\n",
            "Total Loss: 0.14506017897096496\n",
            "----------------------------------------\n",
            "Epoch 177\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0080, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.3660724578186318\n",
            "SCOPE mean: 0.1450835742665738, SCOPE var: 0.009354738248336669\n",
            "Total Loss: 0.14463223827567745\n",
            "----------------------------------------\n",
            "Epoch 178\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0080, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.3619938997294405\n",
            "SCOPE mean: 0.145005118301064, SCOPE var: 0.009348340921922911\n",
            "Total Loss: 0.1442000417898573\n",
            "----------------------------------------\n",
            "Epoch 179\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0080, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.3579713181991153\n",
            "SCOPE mean: 0.14508602278652072, SCOPE var: 0.009345376280937564\n",
            "Total Loss: 0.1437641339406844\n",
            "----------------------------------------\n",
            "Epoch 180\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0079, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.354000532264006\n",
            "SCOPE mean: 0.14530905102995129, SCOPE var: 0.009345528322486222\n",
            "Total Loss: 0.1433252163840271\n",
            "----------------------------------------\n",
            "Epoch 181\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0079, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.350078353048544\n",
            "SCOPE mean: 0.14565713777319936, SCOPE var: 0.009348494632485774\n",
            "Total Loss: 0.1428840845313169\n",
            "----------------------------------------\n",
            "Epoch 182\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0078, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.3462022321260976\n",
            "SCOPE mean: 0.14611358398828297, SCOPE var: 0.009353982502881658\n",
            "Total Loss: 0.14244157282455763\n",
            "----------------------------------------\n",
            "Epoch 183\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0078, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.3423699709069459\n",
            "SCOPE mean: 0.14666222478712138, SCOPE var: 0.009361706062758518\n",
            "Total Loss: 0.14199850940408584\n",
            "----------------------------------------\n",
            "Epoch 184\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0077, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.3385794920962693\n",
            "SCOPE mean: 0.14728757040722693, SCOPE var: 0.009371384417514242\n",
            "Total Loss: 0.1415556802501438\n",
            "----------------------------------------\n",
            "Epoch 185\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0076, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.3348286709486363\n",
            "SCOPE mean: 0.1479749209974841, SCOPE var: 0.009382740731158959\n",
            "Total Loss: 0.14111380242653834\n",
            "----------------------------------------\n",
            "Epoch 186\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0076, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.3311152215483444\n",
            "SCOPE mean: 0.14871045651051745, SCOPE var: 0.009395502143300935\n",
            "Total Loss: 0.14067350571543918\n",
            "----------------------------------------\n",
            "Epoch 187\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0075, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.3274366316335298\n",
            "SCOPE mean: 0.1494813034272134, SCOPE var: 0.009409400383885717\n",
            "Total Loss: 0.14023532170091335\n",
            "----------------------------------------\n",
            "Epoch 188\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0074, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.3237901384772368\n",
            "SCOPE mean: 0.15027558031634836, SCOPE var: 0.009424172933752271\n",
            "Total Loss: 0.13979967922353953\n",
            "----------------------------------------\n",
            "Epoch 189\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0073, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.3201727379353452\n",
            "SCOPE mean: 0.15108242439116173, SCOPE var: 0.009439564575529748\n",
            "Total Loss: 0.1393669050746116\n",
            "----------------------------------------\n",
            "Epoch 190\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0073, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.3165812188526238\n",
            "SCOPE mean: 0.151892001287721, SCOPE var: 0.009455329185009348\n",
            "Total Loss: 0.13893722880995493\n",
            "----------------------------------------\n",
            "Epoch 191\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0072, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.3130122154673625\n",
            "SCOPE mean: 0.15269550027772816, SCOPE var: 0.009471231625594524\n",
            "Total Loss: 0.1385107906244008\n",
            "----------------------------------------\n",
            "Epoch 192\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0071, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.3094622711629287\n",
            "SCOPE mean: 0.15348511705922882, SCOPE var: 0.009487049625568334\n",
            "Total Loss: 0.13808765132381354\n",
            "----------------------------------------\n",
            "Epoch 193\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0071, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.305927907784736\n",
            "SCOPE mean: 0.15425402615793218, SCOPE var: 0.009502575537803955\n",
            "Total Loss: 0.13766780354936298\n",
            "----------------------------------------\n",
            "Epoch 194\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0070, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.3024056956921197\n",
            "SCOPE mean: 0.1549963448323899, SCOPE var: 0.009517617902545303\n",
            "Total Loss: 0.13725118353766064\n",
            "----------------------------------------\n",
            "Epoch 195\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0069, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.298892320681091\n",
            "SCOPE mean: 0.15570709021856943, SCOPE var: 0.009532002754704592\n",
            "Total Loss: 0.13683768283175676\n",
            "----------------------------------------\n",
            "Epoch 196\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0069, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.295384644845797\n",
            "SCOPE mean: 0.1563821312817784, SCOPE var: 0.009545574636758349\n",
            "Total Loss: 0.13642715948519157\n",
            "----------------------------------------\n",
            "Epoch 197\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0068, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.2918797593078821\n",
            "SCOPE mean: 0.15701813697309522, SCOPE var: 0.009558197296096714\n",
            "Total Loss: 0.1360194484195278\n",
            "----------------------------------------\n",
            "Epoch 198\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0068, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.2883750275102155\n",
            "SCOPE mean: 0.1576125218185695, SCOPE var: 0.009569754061132347\n",
            "Total Loss: 0.1356143707019182\n",
            "----------------------------------------\n",
            "Epoch 199\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0067, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.2848682353016552\n",
            "SCOPE mean: 0.15816337881392203, SCOPE var: 0.009580147910839321\n",
            "Total Loss: 0.1352117442631279\n",
            "----------------------------------------\n",
            "Epoch 200\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0067, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.281357916479134\n",
            "SCOPE mean: 0.15866938572525788, SCOPE var: 0.009589301009565886\n",
            "Total Loss: 0.1348113981592494\n",
            "----------------------------------------\n",
            "Epoch 201\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0066, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.2778417339921229\n",
            "SCOPE mean: 0.15912990421138692, SCOPE var: 0.009597154211098418\n",
            "Total Loss: 0.13441313881980205\n",
            "----------------------------------------\n",
            "Epoch 202\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0066, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.2743183612751543\n",
            "SCOPE mean: 0.15954475634143586, SCOPE var: 0.009603666608049616\n",
            "Total Loss: 0.13401679891057983\n",
            "----------------------------------------\n",
            "Epoch 203\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0065, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.2707868143528624\n",
            "SCOPE mean: 0.15991423314855657, SCOPE var: 0.009608814541947413\n",
            "Total Loss: 0.13362222492570863\n",
            "----------------------------------------\n",
            "Epoch 204\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0065, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.2672464405706492\n",
            "SCOPE mean: 0.1602390420750624, SCOPE var: 0.00961259048333163\n",
            "Total Loss: 0.13322927926198574\n",
            "----------------------------------------\n",
            "Epoch 205\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0065, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.2636969012696915\n",
            "SCOPE mean: 0.16052025647856738, SCOPE var: 0.009615001778021971\n",
            "Total Loss: 0.13283784137578739\n",
            "----------------------------------------\n",
            "Epoch 206\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0064, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.2601381495837638\n",
            "SCOPE mean: 0.1607592674406206, SCOPE var: 0.00961606929496312\n",
            "Total Loss: 0.13244780815702453\n",
            "----------------------------------------\n",
            "Epoch 207\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0064, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.2565704045137598\n",
            "SCOPE mean: 0.16095773805097252, SCOPE var: 0.009615826009143489\n",
            "Total Loss: 0.13205909365594762\n",
            "----------------------------------------\n",
            "Epoch 208\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0064, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.2529941223776682\n",
            "SCOPE mean: 0.1611175602831761, SCOPE var: 0.009614315550490062\n",
            "Total Loss: 0.1316716282947338\n",
            "----------------------------------------\n",
            "Epoch 209\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0063, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.2494099666488938\n",
            "SCOPE mean: 0.16124081452969816, SCOPE var: 0.009611590746585987\n",
            "Total Loss: 0.13128535768801683\n",
            "----------------------------------------\n",
            "Epoch 210\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0063, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.2458187770927698\n",
            "SCOPE mean: 0.16132973182603405, SCOPE var: 0.009607712183721803\n",
            "Total Loss: 0.13090024118596127\n",
            "----------------------------------------\n",
            "Epoch 211\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0063, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.2422215389971294\n",
            "SCOPE mean: 0.16138665876235048, SCOPE var: 0.009602746807339696\n",
            "Total Loss: 0.13051625024111832\n",
            "----------------------------------------\n",
            "Epoch 212\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0063, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.2386193531739507\n",
            "SCOPE mean: 0.16141402505686128, SCOPE var: 0.009596766579482144\n",
            "Total Loss: 0.13013336668692985\n",
            "----------------------------------------\n",
            "Epoch 213\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0063, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.2350134072901342\n",
            "SCOPE mean: 0.161414313746392, SCOPE var: 0.009589847207516454\n",
            "Total Loss: 0.12975158100204395\n",
            "----------------------------------------\n",
            "Epoch 214\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0062, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.2314049489702625\n",
            "SCOPE mean: 0.16139003393546153, SCOPE var: 0.009582066955243105\n",
            "Total Loss: 0.1293708906210829\n",
            "----------------------------------------\n",
            "Epoch 215\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0062, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.2277952610055263\n",
            "SCOPE mean: 0.1613436960347731, SCOPE var: 0.009573505544566206\n",
            "Total Loss: 0.12899129833958364\n",
            "----------------------------------------\n",
            "Epoch 216\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0062, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.2241856389029602\n",
            "SCOPE mean: 0.1612777894124781, SCOPE var: 0.009564243153240391\n",
            "Total Loss: 0.1286128108488017\n",
            "----------------------------------------\n",
            "Epoch 217\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0062, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.2205773709190244\n",
            "SCOPE mean: 0.1611947623762519, SCOPE var: 0.009554359511831884\n",
            "Total Loss: 0.12823543742513976\n",
            "----------------------------------------\n",
            "Epoch 218\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0062, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.2169717206422384\n",
            "SCOPE mean: 0.16109700440048982, SCOPE var: 0.009543933100948379\n",
            "Total Loss: 0.12785918878927488\n",
            "----------------------------------------\n",
            "Epoch 219\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0061, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.2133699121213073\n",
            "SCOPE mean: 0.16098683051032198, SCOPE var: 0.009533040448002171\n",
            "Total Loss: 0.1274840761416709\n",
            "----------------------------------------\n",
            "Epoch 220\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0061, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.2097731174779307\n",
            "SCOPE mean: 0.16086646773223648, SCOPE var: 0.009521755521265619\n",
            "Total Loss: 0.1271101103740974\n",
            "----------------------------------------\n",
            "Epoch 221\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0061, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.2061824468969464\n",
            "SCOPE mean: 0.16073804351961052, SCOPE var: 0.009510149217741118\n",
            "Total Loss: 0.12673730145101136\n",
            "----------------------------------------\n",
            "Epoch 222\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0061, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.2025989408500262\n",
            "SCOPE mean: 0.16060357606014114, SCOPE var: 0.00949828894038342\n",
            "Total Loss: 0.1263656579501283\n",
            "----------------------------------------\n",
            "Epoch 223\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0061, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.199023564382102\n",
            "SCOPE mean: 0.16046496637090757, SCOPE var: 0.009486238259455576\n",
            "Total Loss: 0.12599518674814006\n",
            "----------------------------------------\n",
            "Epoch 224\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0061, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.1954572032712008\n",
            "SCOPE mean: 0.16032399208550563, SCOPE var: 0.00947405665225735\n",
            "Total Loss: 0.1256258928352224\n",
            "----------------------------------------\n",
            "Epoch 225\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0061, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.1919006618614822\n",
            "SCOPE mean: 0.16018230283633042, SCOPE var: 0.00946179931509956\n",
            "Total Loss: 0.125257779240605\n",
            "----------------------------------------\n",
            "Epoch 226\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0061, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.1883546623650076\n",
            "SCOPE mean: 0.16004141713369113, SCOPE var: 0.00944951704120095\n",
            "Total Loss: 0.12489084705092689\n",
            "----------------------------------------\n",
            "Epoch 227\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0060, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.1848198454291947\n",
            "SCOPE mean: 0.15990272064203628, SCOPE var: 0.009437256158122744\n",
            "Total Loss: 0.12452509550325071\n",
            "----------------------------------------\n",
            "Epoch 228\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0060, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.1812969109622575\n",
            "SCOPE mean: 0.1597674713914932, SCOPE var: 0.009425058486696922\n",
            "Total Loss: 0.1241605360551242\n",
            "----------------------------------------\n",
            "Epoch 229\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0060, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.1777850431718397\n",
            "SCOPE mean: 0.15963635218572816, SCOPE var: 0.009412943254935299\n",
            "Total Loss: 0.12379703610441928\n",
            "----------------------------------------\n",
            "Epoch 230\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0060, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.1742830097909283\n",
            "SCOPE mean: 0.1595104296742369, SCOPE var: 0.00940094512209249\n",
            "Total Loss: 0.12343442842771044\n",
            "----------------------------------------\n",
            "Epoch 231\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0060, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.1707935851831006\n",
            "SCOPE mean: 0.1593905995778259, SCOPE var: 0.009389094648797473\n",
            "Total Loss: 0.1230729499227084\n",
            "----------------------------------------\n",
            "Epoch 232\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0060, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.1673170767001102\n",
            "SCOPE mean: 0.15927763203580517, SCOPE var: 0.009377418099770154\n",
            "Total Loss: 0.12271259661953063\n",
            "----------------------------------------\n",
            "Epoch 233\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0060, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.1638537265109428\n",
            "SCOPE mean: 0.15917217424444724, SCOPE var: 0.009365937643203355\n",
            "Total Loss: 0.1223533636446756\n",
            "----------------------------------------\n",
            "Epoch 234\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0060, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.1604037165578853\n",
            "SCOPE mean: 0.15907475598307058, SCOPE var: 0.009354671556856988\n",
            "Total Loss: 0.1219952454629124\n",
            "----------------------------------------\n",
            "Epoch 235\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0059, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.1569671735522575\n",
            "SCOPE mean: 0.15898579568502044, SCOPE var: 0.009343634449188062\n",
            "Total Loss: 0.12163823609660175\n",
            "----------------------------------------\n",
            "Epoch 236\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0059, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.1535441739345662\n",
            "SCOPE mean: 0.15890560695828457, SCOPE var: 0.009332837491729445\n",
            "Total Loss: 0.12128232931901044\n",
            "----------------------------------------\n",
            "Epoch 237\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0059, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.1501347487380111\n",
            "SCOPE mean: 0.1588344054631194, SCOPE var: 0.00932228865930024\n",
            "Total Loss: 0.12092751881968146\n",
            "----------------------------------------\n",
            "Epoch 238\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0059, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.14673888830715\n",
            "SCOPE mean: 0.1587723160573538, SCOPE var: 0.009311992974987313\n",
            "Total Loss: 0.1205737983412317\n",
            "----------------------------------------\n",
            "Epoch 239\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0059, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.1433565468350346\n",
            "SCOPE mean: 0.15871938012398465, SCOPE var: 0.009301952757171628\n",
            "Total Loss: 0.12022116178805706\n",
            "----------------------------------------\n",
            "Epoch 240\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0059, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.139987646692121\n",
            "SCOPE mean: 0.1586755630001584, SCOPE var: 0.00929216786618951\n",
            "Total Loss: 0.11986960330832354\n",
            "----------------------------------------\n",
            "Epoch 241\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0059, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.1366320825287988\n",
            "SCOPE mean: 0.15864076143167408, SCOPE var: 0.009282635948506904\n",
            "Total Loss: 0.11951911735131598\n",
            "----------------------------------------\n",
            "Epoch 242\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0058, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.133289725140485\n",
            "SCOPE mean: 0.15861481098258146, SCOPE var: 0.009273352676555434\n",
            "Total Loss: 0.11916969870271663\n",
            "----------------------------------------\n",
            "Epoch 243\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0058, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.1299604250899802\n",
            "SCOPE mean: 0.15859749333528034, SCOPE var: 0.009264311982622352\n",
            "Total Loss: 0.11882134250070486\n",
            "----------------------------------------\n",
            "Epoch 244\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0058, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.1266440160863096\n",
            "SCOPE mean: 0.15858854342260162, SCOPE var: 0.009255506285410853\n",
            "Total Loss: 0.11847404423593025\n",
            "----------------------------------------\n",
            "Epoch 245\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0058, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.1233403209202095\n",
            "SCOPE mean: 0.1585876563771513, SCOPE var: 0.009246926708104924\n",
            "Total Loss: 0.11812780001818356\n",
            "----------------------------------------\n",
            "Epoch 246\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0058, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.1200491729043247\n",
            "SCOPE mean: 0.15859443500486758, SCOPE var: 0.009238560838385833\n",
            "Total Loss: 0.11778260857457044\n",
            "----------------------------------------\n",
            "Epoch 247\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0058, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.116770346489273\n",
            "SCOPE mean: 0.15860851807922394, SCOPE var: 0.009230397990373288\n",
            "Total Loss: 0.11743846366185899\n",
            "----------------------------------------\n",
            "Epoch 248\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0057, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.1135036367684876\n",
            "SCOPE mean: 0.1586295236291141, SCOPE var: 0.009222426765996505\n",
            "Total Loss: 0.11709536191951829\n",
            "----------------------------------------\n",
            "Epoch 249\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0057, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.1102488354085296\n",
            "SCOPE mean: 0.15865705422492685, SCOPE var: 0.00921463523130985\n",
            "Total Loss: 0.11675330020149982\n",
            "----------------------------------------\n",
            "Epoch 250\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0057, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.1070057326813207\n",
            "SCOPE mean: 0.15869070224162668, SCOPE var: 0.009207011080940405\n",
            "Total Loss: 0.11641227553800645\n",
            "----------------------------------------\n",
            "Epoch 251\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0057, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.1037741193013837\n",
            "SCOPE mean: 0.15873005471853444, SCOPE var: 0.009199541790272851\n",
            "Total Loss: 0.11607228509828227\n",
            "----------------------------------------\n",
            "Epoch 252\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0057, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.100553788076357\n",
            "SCOPE mean: 0.1587746978060407, SCOPE var: 0.009192214755210027\n",
            "Total Loss: 0.11573332615566281\n",
            "----------------------------------------\n",
            "Epoch 253\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0057, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0973445353787261\n",
            "SCOPE mean: 0.1588242207944892, SCOPE var: 0.009185017419451645\n",
            "Total Loss: 0.11539539605580734\n",
            "----------------------------------------\n",
            "Epoch 254\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0056, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0941461624463922\n",
            "SCOPE mean: 0.1588782197250786, SCOPE var: 0.009177937389327439\n",
            "Total Loss: 0.11505849218874029\n",
            "----------------------------------------\n",
            "Epoch 255\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0056, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0909584765194025\n",
            "SCOPE mean: 0.15893630058684427, SCOPE var: 0.009170962536313224\n",
            "Total Loss: 0.11472261196506534\n",
            "----------------------------------------\n",
            "Epoch 256\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0056, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.087781291819933\n",
            "SCOPE mean: 0.15899808210755373, SCOPE var: 0.009164081087439727\n",
            "Total Loss: 0.1143877527964892\n",
            "----------------------------------------\n",
            "Epoch 257\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0056, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0846144303824727\n",
            "SCOPE mean: 0.15906319814970868, SCOPE var: 0.009157281703879071\n",
            "Total Loss: 0.1140539120805992\n",
            "----------------------------------------\n",
            "Epoch 258\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0056, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0814577227410915\n",
            "SCOPE mean: 0.15913129972575468, SCOPE var: 0.009150553548067212\n",
            "Total Loss: 0.11372108718968824\n",
            "----------------------------------------\n",
            "Epoch 259\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0056, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0783110084807024\n",
            "SCOPE mean: 0.1592020566490985, SCOPE var: 0.0091438863397806\n",
            "Total Loss: 0.11338927546330153\n",
            "----------------------------------------\n",
            "Epoch 260\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0055, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0751741366593395\n",
            "SCOPE mean: 0.1592751588396146, SCOPE var: 0.00913727040164383\n",
            "Total Loss: 0.11305847420409906\n",
            "----------------------------------------\n",
            "Epoch 261\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0055, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0720469661086296\n",
            "SCOPE mean: 0.15935031730399454, SCOPE var: 0.009130696694595547\n",
            "Total Loss: 0.11272868067657443\n",
            "----------------------------------------\n",
            "Epoch 262\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0055, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.068929365619852\n",
            "SCOPE mean: 0.15942726481261207, SCOPE var: 0.009124156843880175\n",
            "Total Loss: 0.1123998921081476\n",
            "----------------------------------------\n",
            "Epoch 263\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0055, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.06581072927203\n",
            "SCOPE mean: 0.15949954942243447, SCOPE var: 0.009117278933844005\n",
            "Total Loss: 0.11207113219682632\n",
            "----------------------------------------\n",
            "Epoch 264\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0055, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0626922514620032\n",
            "SCOPE mean: 0.15958099597317577, SCOPE var: 0.009110657826769682\n",
            "Total Loss: 0.11174248197768805\n",
            "----------------------------------------\n",
            "Epoch 265\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0055, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0595777471741183\n",
            "SCOPE mean: 0.15967228906158126, SCOPE var: 0.009104362351820963\n",
            "Total Loss: 0.11141430655786876\n",
            "----------------------------------------\n",
            "Epoch 266\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0054, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0564678132352163\n",
            "SCOPE mean: 0.15977234956811967, SCOPE var: 0.009098355197884715\n",
            "Total Loss: 0.11108667111417911\n",
            "----------------------------------------\n",
            "Epoch 267\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0054, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0533629901803991\n",
            "SCOPE mean: 0.15988019378336873, SCOPE var: 0.009092602154654234\n",
            "Total Loss: 0.11075963447294783\n",
            "----------------------------------------\n",
            "Epoch 268\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0054, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0502637672703594\n",
            "SCOPE mean: 0.15999492698107656, SCOPE var: 0.009087071909742452\n",
            "Total Loss: 0.11043324960667875\n",
            "----------------------------------------\n",
            "Epoch 269\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0054, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0471705871350427\n",
            "SCOPE mean: 0.1601157373461095, SCOPE var: 0.00908173586059104\n",
            "Total Loss: 0.110107564104814\n",
            "----------------------------------------\n",
            "Epoch 270\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0054, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0440838500512981\n",
            "SCOPE mean: 0.16024189022975177, SCOPE var: 0.00907656793905424\n",
            "Total Loss: 0.10978262061763712\n",
            "----------------------------------------\n",
            "Epoch 271\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0054, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0410039178666204\n",
            "SCOPE mean: 0.1603727227088541, SCOPE var: 0.009071544446920684\n",
            "Total Loss: 0.10945845727294433\n",
            "----------------------------------------\n",
            "Epoch 272\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0053, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0379311175843697\n",
            "SCOPE mean: 0.16050763842880297, SCOPE var: 0.009066643900961516\n",
            "Total Loss: 0.10913510806557977\n",
            "----------------------------------------\n",
            "Epoch 273\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0053, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0348657446281238\n",
            "SCOPE mean: 0.160646102713258, SCOPE var: 0.009061846886369865\n",
            "Total Loss: 0.10881260322028986\n",
            "----------------------------------------\n",
            "Epoch 274\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0053, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0318080658043152\n",
            "SCOPE mean: 0.1607876379261323, SCOPE var: 0.009057135917683444\n",
            "Total Loss: 0.1084909695286269\n",
            "----------------------------------------\n",
            "Epoch 275\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0053, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.028758321983167\n",
            "SCOPE mean: 0.16093181907340162, SCOPE var: 0.009052495306475403\n",
            "Total Loss: 0.10817023066083609\n",
            "----------------------------------------\n",
            "Epoch 276\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0053, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0257167305182981\n",
            "SCOPE mean: 0.16107826963409327, SCOPE var: 0.009047911035254205\n",
            "Total Loss: 0.10785040745380738\n",
            "----------------------------------------\n",
            "Epoch 277\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0053, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.022683487425317\n",
            "SCOPE mean: 0.16122665761123448, SCOPE var: 0.009043370637142145\n",
            "Total Loss: 0.10753151817627254\n",
            "----------------------------------------\n",
            "Epoch 278\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0052, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0196587693393688\n",
            "SCOPE mean: 0.16137669179470837, SCOPE var: 0.009038863081005112\n",
            "Total Loss: 0.10721357877249149\n",
            "----------------------------------------\n",
            "Epoch 279\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0052, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.016642735271\n",
            "SCOPE mean: 0.16152811822886778, SCOPE var: 0.009034378661788856\n",
            "Total Loss: 0.10689660308570366\n",
            "----------------------------------------\n",
            "Epoch 280\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0052, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.013635528178905\n",
            "SCOPE mean: 0.16168071687847455, SCOPE var: 0.009029908895879553\n",
            "Total Loss: 0.10658060306262665\n",
            "----------------------------------------\n",
            "Epoch 281\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0052, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0106372763772156\n",
            "SCOPE mean: 0.1618342984870419, SCOPE var: 0.009025446421355564\n",
            "Total Loss: 0.10626558894027317\n",
            "----------------------------------------\n",
            "Epoch 282\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0052, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0076480947939594\n",
            "SCOPE mean: 0.16198870162203632, SCOPE var: 0.009020984903032247\n",
            "Total Loss: 0.10595156941633019\n",
            "----------------------------------------\n",
            "Epoch 283\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0052, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0046680860962534\n",
            "SCOPE mean: 0.16214378990163705, SCOPE var: 0.009016518942224726\n",
            "Total Loss: 0.10563855180430431\n",
            "----------------------------------------\n",
            "Epoch 284\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0052, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0016973416966648\n",
            "SCOPE mean: 0.162299449397887, SCOPE var: 0.009012043991170438\n",
            "Total Loss: 0.1053265421745898\n",
            "----------------------------------------\n",
            "Epoch 285\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0051, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9987359426540792\n",
            "SCOPE mean: 0.1624555862111269, SCOPE var: 0.009007556272060194\n",
            "Total Loss: 0.10501554548256324\n",
            "----------------------------------------\n",
            "Epoch 286\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0051, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9957839604812745\n",
            "SCOPE mean: 0.1626121242105881, SCOPE var: 0.009003052700627758\n",
            "Total Loss: 0.10470556568474845\n",
            "----------------------------------------\n",
            "Epoch 287\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0051, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9928414578703303\n",
            "SCOPE mean: 0.16276900293596086, SCOPE var: 0.008998530814245793\n",
            "Total Loss: 0.10439660584403611\n",
            "----------------------------------------\n",
            "Epoch 288\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0051, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9899084893459345\n",
            "SCOPE mean: 0.16292617565465373, SCOPE var: 0.008993988704471071\n",
            "Total Loss: 0.10408866822488072\n",
            "----------------------------------------\n",
            "Epoch 289\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0051, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.986985101855647\n",
            "SCOPE mean: 0.16308360756933438, SCOPE var: 0.008989424953969954\n",
            "Total Loss: 0.1037817543793357\n",
            "----------------------------------------\n",
            "Epoch 290\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0051, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9840713353052147\n",
            "SCOPE mean: 0.16324127417021567, SCOPE var: 0.00898483857774773\n",
            "Total Loss: 0.10347586522472667\n",
            "----------------------------------------\n",
            "Epoch 291\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0051, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9811672230461348\n",
            "SCOPE mean: 0.163399159726399, SCOPE var: 0.008980228968591847\n",
            "Total Loss: 0.10317100111370439\n",
            "----------------------------------------\n",
            "Epoch 292\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0050, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9782727923218208\n",
            "SCOPE mean: 0.16355725591046086, SCOPE var: 0.008975595846627854\n",
            "Total Loss: 0.10286716189736327\n",
            "----------------------------------------\n",
            "Epoch 293\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0050, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9753880646779393\n",
            "SCOPE mean: 0.1637155605503376, SCOPE var: 0.008970939212874085\n",
            "Total Loss: 0.10256434698205436\n",
            "----------------------------------------\n",
            "Epoch 294\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0050, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9725130563417707\n",
            "SCOPE mean: 0.163874076502457, SCOPE var: 0.008966259306670523\n",
            "Total Loss: 0.10226255538047442\n",
            "----------------------------------------\n",
            "Epoch 295\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0050, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9696477785747947\n",
            "SCOPE mean: 0.16403281063997374, SCOPE var: 0.008961556566845124\n",
            "Total Loss: 0.10196178575756226\n",
            "----------------------------------------\n",
            "Epoch 296\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0050, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9667922380020944\n",
            "SCOPE mean: 0.16419177294989687, SCOPE var: 0.008956831596472002\n",
            "Total Loss: 0.1016620364716886\n",
            "----------------------------------------\n",
            "Epoch 297\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0050, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9639464369216466\n",
            "SCOPE mean: 0.16435097573286475, SCOPE var: 0.008952085131065908\n",
            "Total Loss: 0.1013633056115861\n",
            "----------------------------------------\n",
            "Epoch 298\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0050, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9611103735960783\n",
            "SCOPE mean: 0.16451043289929515, SCOPE var: 0.008947318010051544\n",
            "Total Loss: 0.10106559102942449\n",
            "----------------------------------------\n",
            "Epoch 299\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0049, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9582840425290462\n",
            "SCOPE mean: 0.16467015935566748, SCOPE var: 0.008942531151337755\n",
            "Total Loss: 0.10076889037040308\n",
            "----------------------------------------\n",
            "Epoch 300\n",
            "IS mean: 0.14880267027988744,IS variance: 0.0061515626555271935\n",
            "SCOPE Var loss:  tensor(0.0049, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9554674347280155\n",
            "SCOPE mean: 0.1648301704747279, SCOPE var: 0.008937725528825012\n",
            "Total Loss: 0.1004732010991976\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[-0.3762,  0.0549],\n",
            "        [ 0.4447, -0.3575],\n",
            "        [-0.4130, -0.4055],\n",
            "        [ 0.5455, -0.1814],\n",
            "        [ 0.3116, -0.3587],\n",
            "        [ 0.6804, -0.4494]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([ 0.4944, -0.0437, -0.6384,  0.0645, -0.4119,  0.6913],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[ 0.1955, -0.1242,  0.1029, -0.0542,  0.0734,  0.1266]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([0.2864], dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NN_l1_l2_reg(\n",
              "  (hidden_layers): ModuleList(\n",
              "    (0): Linear(in_features=2, out_features=6, bias=True)\n",
              "  )\n",
              "  (output_layer): Linear(in_features=6, out_features=1, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b_400 = action_probs_top_n_epsilon(q_table, 1, 0.4)\n",
        "pi_b_400 = experiment_actions(400, env_100, P_pi_b_400)\n",
        "P_pi_e_400 = action_probs_top_n_epsilon(q_table, 1, 0.05)\n",
        "pi_e_400 = experiment_actions(1000, env_100, P_pi_e_400)\n",
        "# model_400_random_pi_b_400_env_100 = CustomizableFeatureNet(input_dim=2, hidden_dims=[16, 16], output_dim=1, dtype = torch.float64, l2_lambda=0.002)\n",
        "model_400_random_pi_b_400_env_100 = NN_l1_l2_reg(input_dim=2, hidden_dims=[10, 10], output_dim=1, dtype = torch.float64, l1_lambda=0.0002, l2_lambda = 0.0001)\n",
        "test_400_random_pi_b_400_env_100 = SCOPE_straight(model_400_random_pi_b_400_env_100, 0.99, 10000, pi_b_400, P_pi_b_400, P_pi_e_400, 0.3, dtype = torch.float64)\n",
        "test_400_random_pi_b_400_env_100.train_var_scope(400, 0.001, 1, 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29315954-391a-43ba-a385-c750c5af0e90",
        "id": "2tRoseSL41u6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0889, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  20.362240639987892\n",
            "SCOPE mean: 1.100768566131586, SCOPE var: 0.6797449399930097\n",
            "Total Loss: 0.08887433149744364\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.7305, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  20.542493045851415\n",
            "SCOPE mean: 1.0917943729755988, SCOPE var: 0.6700620990008974\n",
            "Total Loss: 0.730538071979331\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.6992, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  20.562039665563347\n",
            "SCOPE mean: 1.0809234196303648, SCOPE var: 0.6619065042285946\n",
            "Total Loss: 0.6992122502132285\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.6654, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  20.57784748896114\n",
            "SCOPE mean: 1.0694560518145, SCOPE var: 0.6536285889808953\n",
            "Total Loss: 0.6653708474091665\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.6317, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  20.593466710084726\n",
            "SCOPE mean: 1.0577394889054186, SCOPE var: 0.6453351551827743\n",
            "Total Loss: 0.631704520228117\n",
            "----------------------------------------\n",
            "Epoch 6\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.5984, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  20.60992363756017\n",
            "SCOPE mean: 1.0465748547470803, SCOPE var: 0.6370865557936958\n",
            "Total Loss: 0.5983795127903889\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.5656, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  20.6275024173402\n",
            "SCOPE mean: 1.0356889364055544, SCOPE var: 0.6288911713770143\n",
            "Total Loss: 0.5656053134819556\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.5336, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  20.646762858644855\n",
            "SCOPE mean: 1.0248711231329437, SCOPE var: 0.6207376152897195\n",
            "Total Loss: 0.5335776877498271\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.5024, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  20.666880167206394\n",
            "SCOPE mean: 1.0140955925415418, SCOPE var: 0.612632315432273\n",
            "Total Loss: 0.502413524074456\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.4722, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  20.688079720448137\n",
            "SCOPE mean: 1.003322037428187, SCOPE var: 0.6045845922282244\n",
            "Total Loss: 0.47217224008953684\n",
            "----------------------------------------\n",
            "Epoch 11\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.4430, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  20.711894264809004\n",
            "SCOPE mean: 0.9925686326074065, SCOPE var: 0.5965986567454569\n",
            "Total Loss: 0.4429824740175569\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.4148, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  20.737818570226253\n",
            "SCOPE mean: 0.9818434564706331, SCOPE var: 0.5886806685297054\n",
            "Total Loss: 0.4148337548677865\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.3878, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  20.76592340742499\n",
            "SCOPE mean: 0.9711456869158348, SCOPE var: 0.5808383808056431\n",
            "Total Loss: 0.3878124816145953\n",
            "----------------------------------------\n",
            "Epoch 14\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.3618, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  20.79560921784677\n",
            "SCOPE mean: 0.960478697021946, SCOPE var: 0.573059504263492\n",
            "Total Loss: 0.3618250554544755\n",
            "----------------------------------------\n",
            "Epoch 15\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.3369, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  20.8261607836228\n",
            "SCOPE mean: 0.9498183558943416, SCOPE var: 0.5652895544682217\n",
            "Total Loss: 0.3369138014705479\n",
            "----------------------------------------\n",
            "Epoch 16\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.3131, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  20.858806783941148\n",
            "SCOPE mean: 0.9391913385547843, SCOPE var: 0.557577448386923\n",
            "Total Loss: 0.31314323544088135\n",
            "----------------------------------------\n",
            "Epoch 17\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.2905, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  20.894503784221094\n",
            "SCOPE mean: 0.9286357289793785, SCOPE var: 0.5499669863872702\n",
            "Total Loss: 0.29046303676802543\n",
            "----------------------------------------\n",
            "Epoch 18\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.2689, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  20.931937382241244\n",
            "SCOPE mean: 0.9181497802026348, SCOPE var: 0.5424606745633175\n",
            "Total Loss: 0.2689242685997703\n",
            "----------------------------------------\n",
            "Epoch 19\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.2485, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  20.97047345503046\n",
            "SCOPE mean: 0.9077238547322184, SCOPE var: 0.5350431183179523\n",
            "Total Loss: 0.24850814577463304\n",
            "----------------------------------------\n",
            "Epoch 20\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.2292, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.01005002424154\n",
            "SCOPE mean: 0.8975721627155266, SCOPE var: 0.5279556536240586\n",
            "Total Loss: 0.22919406497150321\n",
            "----------------------------------------\n",
            "Epoch 21\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.2121, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.049485650519205\n",
            "SCOPE mean: 0.8878038591119594, SCOPE var: 0.5212136914493173\n",
            "Total Loss: 0.212109548376929\n",
            "----------------------------------------\n",
            "Epoch 22\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.1960, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.088188811798815\n",
            "SCOPE mean: 0.8782383612242287, SCOPE var: 0.5145987180765579\n",
            "Total Loss: 0.19597573296068632\n",
            "----------------------------------------\n",
            "Epoch 23\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.1808, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.126901565513737\n",
            "SCOPE mean: 0.8688559099455084, SCOPE var: 0.5081154732437964\n",
            "Total Loss: 0.18083880435387242\n",
            "----------------------------------------\n",
            "Epoch 24\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.1666, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.166429899042505\n",
            "SCOPE mean: 0.8595002154394149, SCOPE var: 0.5016217749260032\n",
            "Total Loss: 0.16658816290914752\n",
            "----------------------------------------\n",
            "Epoch 25\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.1532, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.206519208377678\n",
            "SCOPE mean: 0.8502480597108454, SCOPE var: 0.4951993442115733\n",
            "Total Loss: 0.15318630692787444\n",
            "----------------------------------------\n",
            "Epoch 26\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.1406, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.247077016327072\n",
            "SCOPE mean: 0.8411255324151505, SCOPE var: 0.488866832966984\n",
            "Total Loss: 0.14061112488446922\n",
            "----------------------------------------\n",
            "Epoch 27\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.1288, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.28821758642952\n",
            "SCOPE mean: 0.8321456107707483, SCOPE var: 0.48263510132930143\n",
            "Total Loss: 0.1288440190898944\n",
            "----------------------------------------\n",
            "Epoch 28\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.1179, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.32936754160938\n",
            "SCOPE mean: 0.8233122300252828, SCOPE var: 0.47651305923139264\n",
            "Total Loss: 0.11787453075139477\n",
            "----------------------------------------\n",
            "Epoch 29\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.1077, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.370747391383265\n",
            "SCOPE mean: 0.8143779336111981, SCOPE var: 0.4705009699016841\n",
            "Total Loss: 0.10765906135924612\n",
            "----------------------------------------\n",
            "Epoch 30\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0983, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.411825264569462\n",
            "SCOPE mean: 0.8055773923346882, SCOPE var: 0.46465704277173314\n",
            "Total Loss: 0.09829611971015503\n",
            "----------------------------------------\n",
            "Epoch 31\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0897, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.453014300103426\n",
            "SCOPE mean: 0.797018662047465, SCOPE var: 0.45897454550674344\n",
            "Total Loss: 0.08973222786082982\n",
            "----------------------------------------\n",
            "Epoch 32\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0818, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.49428762729828\n",
            "SCOPE mean: 0.7886900203939423, SCOPE var: 0.45344006568331363\n",
            "Total Loss: 0.08180972572852319\n",
            "----------------------------------------\n",
            "Epoch 33\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0745, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.535559260579856\n",
            "SCOPE mean: 0.7806009872529608, SCOPE var: 0.4480643313076981\n",
            "Total Loss: 0.07449736910958808\n",
            "----------------------------------------\n",
            "Epoch 34\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0678, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.576818050901903\n",
            "SCOPE mean: 0.7727599534226269, SCOPE var: 0.4428464636434076\n",
            "Total Loss: 0.0678194537277957\n",
            "----------------------------------------\n",
            "Epoch 35\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0617, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.618375851496797\n",
            "SCOPE mean: 0.7651888487463204, SCOPE var: 0.4377865583136714\n",
            "Total Loss: 0.06173691651028009\n",
            "----------------------------------------\n",
            "Epoch 36\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0562, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.65981924888084\n",
            "SCOPE mean: 0.7578806988493764, SCOPE var: 0.43288384556041676\n",
            "Total Loss: 0.05616860957120752\n",
            "----------------------------------------\n",
            "Epoch 37\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0511, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.70146788259198\n",
            "SCOPE mean: 0.7508341101836189, SCOPE var: 0.42813758853265976\n",
            "Total Loss: 0.05108952576325827\n",
            "----------------------------------------\n",
            "Epoch 38\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0465, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.7432762393849\n",
            "SCOPE mean: 0.7440716246078332, SCOPE var: 0.4235618910877116\n",
            "Total Loss: 0.046465130537813565\n",
            "----------------------------------------\n",
            "Epoch 39\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0422, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.786075321653534\n",
            "SCOPE mean: 0.7376170920905343, SCOPE var: 0.419200788270289\n",
            "Total Loss: 0.04223619810682536\n",
            "----------------------------------------\n",
            "Epoch 40\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0384, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.828647031116294\n",
            "SCOPE mean: 0.7314191860177638, SCOPE var: 0.4149935574193694\n",
            "Total Loss: 0.03841645780871664\n",
            "----------------------------------------\n",
            "Epoch 41\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0350, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.871050247204078\n",
            "SCOPE mean: 0.7254806799374046, SCOPE var: 0.4109396681768701\n",
            "Total Loss: 0.03499326414080465\n",
            "----------------------------------------\n",
            "Epoch 42\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0321, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.913371388391095\n",
            "SCOPE mean: 0.7198003778911339, SCOPE var: 0.407038647086147\n",
            "Total Loss: 0.032076066756651526\n",
            "----------------------------------------\n",
            "Epoch 43\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0295, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.955661203607338\n",
            "SCOPE mean: 0.714400891004024, SCOPE var: 0.4032824148151152\n",
            "Total Loss: 0.029459757233742098\n",
            "----------------------------------------\n",
            "Epoch 44\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0271, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.997459109902415\n",
            "SCOPE mean: 0.7092757438554446, SCOPE var: 0.39968381723496\n",
            "Total Loss: 0.02713480433226866\n",
            "----------------------------------------\n",
            "Epoch 45\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0251, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.038596248629815\n",
            "SCOPE mean: 0.704411441799575, SCOPE var: 0.39624390009978816\n",
            "Total Loss: 0.025107961756802175\n",
            "----------------------------------------\n",
            "Epoch 46\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0233, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.080124915327538\n",
            "SCOPE mean: 0.6997694085468227, SCOPE var: 0.3929320920864536\n",
            "Total Loss: 0.02332348425510145\n",
            "----------------------------------------\n",
            "Epoch 47\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0218, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.12100684850289\n",
            "SCOPE mean: 0.6953462541734284, SCOPE var: 0.389753570595829\n",
            "Total Loss: 0.02178450639028568\n",
            "----------------------------------------\n",
            "Epoch 48\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0204, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.16128482849881\n",
            "SCOPE mean: 0.6910821075439004, SCOPE var: 0.3867097309604045\n",
            "Total Loss: 0.020435436717091294\n",
            "----------------------------------------\n",
            "Epoch 49\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0193, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.200969135024714\n",
            "SCOPE mean: 0.6870201468454431, SCOPE var: 0.38380166950456707\n",
            "Total Loss: 0.01926039548516636\n",
            "----------------------------------------\n",
            "Epoch 50\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0182, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.240045067823093\n",
            "SCOPE mean: 0.6831922860435274, SCOPE var: 0.38103034182475404\n",
            "Total Loss: 0.018244170228873886\n",
            "----------------------------------------\n",
            "Epoch 51\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0174, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.278490458280594\n",
            "SCOPE mean: 0.6795995414063587, SCOPE var: 0.37839642855793887\n",
            "Total Loss: 0.017371527013638123\n",
            "----------------------------------------\n",
            "Epoch 52\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0166, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.316221453251167\n",
            "SCOPE mean: 0.6762421671746841, SCOPE var: 0.37590023090190494\n",
            "Total Loss: 0.016626687086322287\n",
            "----------------------------------------\n",
            "Epoch 53\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0160, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.353175333438266\n",
            "SCOPE mean: 0.67311980928279, SCOPE var: 0.3735417052112503\n",
            "Total Loss: 0.01599528333520137\n",
            "----------------------------------------\n",
            "Epoch 54\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0155, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.389298040826485\n",
            "SCOPE mean: 0.6702314750954067, SCOPE var: 0.3713204464490811\n",
            "Total Loss: 0.015463654056640566\n",
            "----------------------------------------\n",
            "Epoch 55\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0150, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.424552944314247\n",
            "SCOPE mean: 0.6675751972561227, SCOPE var: 0.3692356606287755\n",
            "Total Loss: 0.01501875115882782\n",
            "----------------------------------------\n",
            "Epoch 56\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0146, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.45890119527337\n",
            "SCOPE mean: 0.6651482698648082, SCOPE var: 0.367286146380272\n",
            "Total Loss: 0.014648567468036494\n",
            "----------------------------------------\n",
            "Epoch 57\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0143, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.49228401632475\n",
            "SCOPE mean: 0.6629466069456097, SCOPE var: 0.36547029944318493\n",
            "Total Loss: 0.014340348800946257\n",
            "----------------------------------------\n",
            "Epoch 58\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0141, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.52480431735747\n",
            "SCOPE mean: 0.6609563569389572, SCOPE var: 0.3637799186462242\n",
            "Total Loss: 0.014080533007021473\n",
            "----------------------------------------\n",
            "Epoch 59\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0139, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.556788650161668\n",
            "SCOPE mean: 0.6591379586373617, SCOPE var: 0.3621840954317208\n",
            "Total Loss: 0.013864850963363757\n",
            "----------------------------------------\n",
            "Epoch 60\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0137, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.587713607013036\n",
            "SCOPE mean: 0.6575253587474339, SCOPE var: 0.36071257186546646\n",
            "Total Loss: 0.013686684226591611\n",
            "----------------------------------------\n",
            "Epoch 61\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0135, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.617509066801645\n",
            "SCOPE mean: 0.6561112117897574, SCOPE var: 0.35936256034952546\n",
            "Total Loss: 0.013538841569347714\n",
            "----------------------------------------\n",
            "Epoch 62\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0134, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.646391725544\n",
            "SCOPE mean: 0.6548764695479674, SCOPE var: 0.3581088464102069\n",
            "Total Loss: 0.013414453896538135\n",
            "----------------------------------------\n",
            "Epoch 63\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0133, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.674269629587403\n",
            "SCOPE mean: 0.6538275184367335, SCOPE var: 0.35695118201086357\n",
            "Total Loss: 0.01330807399757811\n",
            "----------------------------------------\n",
            "Epoch 64\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0132, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.701462923070384\n",
            "SCOPE mean: 0.6529462275135426, SCOPE var: 0.35589424053116936\n",
            "Total Loss: 0.01321210943040022\n",
            "----------------------------------------\n",
            "Epoch 65\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0131, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.727361601117742\n",
            "SCOPE mean: 0.6522236105452469, SCOPE var: 0.3549379068922396\n",
            "Total Loss: 0.013133574867246372\n",
            "----------------------------------------\n",
            "Epoch 66\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0131, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.751619190967865\n",
            "SCOPE mean: 0.6516622276591694, SCOPE var: 0.35408917561350745\n",
            "Total Loss: 0.013058297616668709\n",
            "----------------------------------------\n",
            "Epoch 67\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0130, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.774467079013007\n",
            "SCOPE mean: 0.6512460454580485, SCOPE var: 0.35333672125163385\n",
            "Total Loss: 0.012982920146708777\n",
            "----------------------------------------\n",
            "Epoch 68\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0129, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.795964461909097\n",
            "SCOPE mean: 0.650968031609449, SCOPE var: 0.35267770813591276\n",
            "Total Loss: 0.012904766964356353\n",
            "----------------------------------------\n",
            "Epoch 69\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0128, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.81604932765726\n",
            "SCOPE mean: 0.6508215779181216, SCOPE var: 0.35210854572448913\n",
            "Total Loss: 0.012822591027723443\n",
            "----------------------------------------\n",
            "Epoch 70\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0127, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.83470440567215\n",
            "SCOPE mean: 0.6507993628807522, SCOPE var: 0.35162506194402393\n",
            "Total Loss: 0.012734154483392428\n",
            "----------------------------------------\n",
            "Epoch 71\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0126, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.851828489266087\n",
            "SCOPE mean: 0.650889787705977, SCOPE var: 0.351222359107854\n",
            "Total Loss: 0.012642353215294777\n",
            "----------------------------------------\n",
            "Epoch 72\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0125, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.867559668735087\n",
            "SCOPE mean: 0.6510846716888647, SCOPE var: 0.3508953817561423\n",
            "Total Loss: 0.012544681280254388\n",
            "----------------------------------------\n",
            "Epoch 73\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0124, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.881983951576398\n",
            "SCOPE mean: 0.6513735894733196, SCOPE var: 0.3506387556660149\n",
            "Total Loss: 0.012445972880912665\n",
            "----------------------------------------\n",
            "Epoch 74\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0123, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.895173464424147\n",
            "SCOPE mean: 0.6517490322407317, SCOPE var: 0.3504450418955631\n",
            "Total Loss: 0.012341140705588973\n",
            "----------------------------------------\n",
            "Epoch 75\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0122, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.906933606159214\n",
            "SCOPE mean: 0.6522215286344337, SCOPE var: 0.3503069629769748\n",
            "Total Loss: 0.012225418335413674\n",
            "----------------------------------------\n",
            "Epoch 76\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0121, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.91771039696382\n",
            "SCOPE mean: 0.6527665763664566, SCOPE var: 0.3502224872327766\n",
            "Total Loss: 0.012105474985300022\n",
            "----------------------------------------\n",
            "Epoch 77\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0120, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.92755338299203\n",
            "SCOPE mean: 0.6533745064052644, SCOPE var: 0.3501854670655785\n",
            "Total Loss: 0.011983371363879293\n",
            "----------------------------------------\n",
            "Epoch 78\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0119, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.936411403154672\n",
            "SCOPE mean: 0.6540365831839167, SCOPE var: 0.35018977332036577\n",
            "Total Loss: 0.011861850504712819\n",
            "----------------------------------------\n",
            "Epoch 79\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0117, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.944406296509197\n",
            "SCOPE mean: 0.6547428935242776, SCOPE var: 0.3502293958397658\n",
            "Total Loss: 0.011738241082976919\n",
            "----------------------------------------\n",
            "Epoch 80\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0116, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.95156375661505\n",
            "SCOPE mean: 0.655499136128633, SCOPE var: 0.3503118506209589\n",
            "Total Loss: 0.011614178812914272\n",
            "----------------------------------------\n",
            "Epoch 81\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0115, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.958021163430878\n",
            "SCOPE mean: 0.6562912464423863, SCOPE var: 0.3504269572098358\n",
            "Total Loss: 0.011491829474915928\n",
            "----------------------------------------\n",
            "Epoch 82\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0114, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.963874813270824\n",
            "SCOPE mean: 0.6571078705386649, SCOPE var: 0.35056507926492764\n",
            "Total Loss: 0.011372257630661483\n",
            "----------------------------------------\n",
            "Epoch 83\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0113, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.96917094758579\n",
            "SCOPE mean: 0.6579355270946013, SCOPE var: 0.35071717663804436\n",
            "Total Loss: 0.01125600319644947\n",
            "----------------------------------------\n",
            "Epoch 84\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0111, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.973887931848427\n",
            "SCOPE mean: 0.6587601694983343, SCOPE var: 0.3508752419283285\n",
            "Total Loss: 0.011143621053264234\n",
            "----------------------------------------\n",
            "Epoch 85\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0110, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.978013110109654\n",
            "SCOPE mean: 0.6595800750050931, SCOPE var: 0.351037060750345\n",
            "Total Loss: 0.011035760308695875\n",
            "----------------------------------------\n",
            "Epoch 86\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0109, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.98185242433565\n",
            "SCOPE mean: 0.6603823556475829, SCOPE var: 0.35119476731476984\n",
            "Total Loss: 0.010935195544242602\n",
            "----------------------------------------\n",
            "Epoch 87\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0108, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.985560631072083\n",
            "SCOPE mean: 0.6611544671714904, SCOPE var: 0.3513414786507289\n",
            "Total Loss: 0.010840422759720029\n",
            "----------------------------------------\n",
            "Epoch 88\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0107, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.989166673918305\n",
            "SCOPE mean: 0.6618846635220716, SCOPE var: 0.35147212746291767\n",
            "Total Loss: 0.0107498516591353\n",
            "----------------------------------------\n",
            "Epoch 89\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0107, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.992689357825142\n",
            "SCOPE mean: 0.6625774273270175, SCOPE var: 0.35158224756776896\n",
            "Total Loss: 0.010662438887404051\n",
            "----------------------------------------\n",
            "Epoch 90\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0106, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.996202689697792\n",
            "SCOPE mean: 0.6632278419958331, SCOPE var: 0.3516683146210887\n",
            "Total Loss: 0.010577896819878389\n",
            "----------------------------------------\n",
            "Epoch 91\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0105, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.999783892262318\n",
            "SCOPE mean: 0.6638234301313972, SCOPE var: 0.3517276484841756\n",
            "Total Loss: 0.010495836418917688\n",
            "----------------------------------------\n",
            "Epoch 92\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0104, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  23.00344048843402\n",
            "SCOPE mean: 0.6642537064312817, SCOPE var: 0.35175786003570214\n",
            "Total Loss: 0.010416082578765173\n",
            "----------------------------------------\n",
            "Epoch 93\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0103, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  23.007168445724144\n",
            "SCOPE mean: 0.664635279443624, SCOPE var: 0.351757381333798\n",
            "Total Loss: 0.010340353076221411\n",
            "----------------------------------------\n",
            "Epoch 94\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0103, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  23.010659121035715\n",
            "SCOPE mean: 0.6649641272122461, SCOPE var: 0.351725232070276\n",
            "Total Loss: 0.0102688235748499\n",
            "----------------------------------------\n",
            "Epoch 95\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0102, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  23.01390614118024\n",
            "SCOPE mean: 0.6652404140317715, SCOPE var: 0.3516616136312322\n",
            "Total Loss: 0.010193994489825775\n",
            "----------------------------------------\n",
            "Epoch 96\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0101, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  23.017100863188166\n",
            "SCOPE mean: 0.6654662290694136, SCOPE var: 0.3515668154304967\n",
            "Total Loss: 0.010119313664015557\n",
            "----------------------------------------\n",
            "Epoch 97\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0100, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  23.020263143549865\n",
            "SCOPE mean: 0.6656425399922283, SCOPE var: 0.3514415261813475\n",
            "Total Loss: 0.01004473162879598\n",
            "----------------------------------------\n",
            "Epoch 98\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0100, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  23.023386217640482\n",
            "SCOPE mean: 0.6657710564494685, SCOPE var: 0.35128691786157745\n",
            "Total Loss: 0.00997019141083644\n",
            "----------------------------------------\n",
            "Epoch 99\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0099, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  23.026560916306416\n",
            "SCOPE mean: 0.66585410873892, SCOPE var: 0.3511045904320224\n",
            "Total Loss: 0.009896229920743103\n",
            "----------------------------------------\n",
            "Epoch 100\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0098, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  23.02974226200333\n",
            "SCOPE mean: 0.6658936899542706, SCOPE var: 0.3508963308488903\n",
            "Total Loss: 0.00982273971390574\n",
            "----------------------------------------\n",
            "Epoch 101\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0098, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  23.032863812583386\n",
            "SCOPE mean: 0.6658944266402704, SCOPE var: 0.35066433400863406\n",
            "Total Loss: 0.009750580911011834\n",
            "----------------------------------------\n",
            "Epoch 102\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0097, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  23.036053900677892\n",
            "SCOPE mean: 0.6658610141936462, SCOPE var: 0.35041090415260234\n",
            "Total Loss: 0.009679923249166974\n",
            "----------------------------------------\n",
            "Epoch 103\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0096, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  23.03927628059788\n",
            "SCOPE mean: 0.6657958220581639, SCOPE var: 0.35013831131895934\n",
            "Total Loss: 0.009609580389155593\n",
            "----------------------------------------\n",
            "Epoch 104\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0095, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  23.04252413637846\n",
            "SCOPE mean: 0.6657026629431934, SCOPE var: 0.34984924348166063\n",
            "Total Loss: 0.00953953784244189\n",
            "----------------------------------------\n",
            "Epoch 105\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0095, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  23.04576735716273\n",
            "SCOPE mean: 0.6655875072781915, SCOPE var: 0.34954644708591925\n",
            "Total Loss: 0.009469965007597296\n",
            "----------------------------------------\n",
            "Epoch 106\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0094, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  23.048933797579704\n",
            "SCOPE mean: 0.6654540928039172, SCOPE var: 0.3492327278550004\n",
            "Total Loss: 0.00940103484644484\n",
            "----------------------------------------\n",
            "Epoch 107\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0093, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  23.051811926295606\n",
            "SCOPE mean: 0.6653052100882316, SCOPE var: 0.348910881925051\n",
            "Total Loss: 0.009336911749206412\n",
            "----------------------------------------\n",
            "Epoch 108\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0093, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  23.054149812982732\n",
            "SCOPE mean: 0.6651588376516222, SCOPE var: 0.34859688784426174\n",
            "Total Loss: 0.00928020800789454\n",
            "----------------------------------------\n",
            "Epoch 109\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0092, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  23.055943602462985\n",
            "SCOPE mean: 0.6650155643009956, SCOPE var: 0.34829175048794053\n",
            "Total Loss: 0.009228126528354006\n",
            "----------------------------------------\n",
            "Epoch 110\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0092, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  23.057181663462394\n",
            "SCOPE mean: 0.6648760126609649, SCOPE var: 0.3479953260643943\n",
            "Total Loss: 0.009176607865697316\n",
            "----------------------------------------\n",
            "Epoch 111\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0091, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  23.058059260867484\n",
            "SCOPE mean: 0.6647406084093782, SCOPE var: 0.3477074841544312\n",
            "Total Loss: 0.009125736137584505\n",
            "----------------------------------------\n",
            "Epoch 112\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0091, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  23.05882351678819\n",
            "SCOPE mean: 0.6646096491456978, SCOPE var: 0.34742811366060994\n",
            "Total Loss: 0.00907562249561495\n",
            "----------------------------------------\n",
            "Epoch 113\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0090, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  23.05917954011968\n",
            "SCOPE mean: 0.6644821906372146, SCOPE var: 0.3471572290939986\n",
            "Total Loss: 0.009027158202293927\n",
            "----------------------------------------\n",
            "Epoch 114\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0090, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  23.059423853049573\n",
            "SCOPE mean: 0.664360486494474, SCOPE var: 0.34689481849814335\n",
            "Total Loss: 0.008980235312959283\n",
            "----------------------------------------\n",
            "Epoch 115\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0089, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  23.059514595057006\n",
            "SCOPE mean: 0.6642446871736184, SCOPE var: 0.3466407104513059\n",
            "Total Loss: 0.008933899661248098\n",
            "----------------------------------------\n",
            "Epoch 116\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0089, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  23.059139595402904\n",
            "SCOPE mean: 0.664160211909779, SCOPE var: 0.34639101182387005\n",
            "Total Loss: 0.00888695434250458\n",
            "----------------------------------------\n",
            "Epoch 117\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0088, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  23.058596937896247\n",
            "SCOPE mean: 0.664089099468087, SCOPE var: 0.3461489510778624\n",
            "Total Loss: 0.008840204552364898\n",
            "----------------------------------------\n",
            "Epoch 118\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0088, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  23.05793314403282\n",
            "SCOPE mean: 0.6641609457031307, SCOPE var: 0.3460415916069595\n",
            "Total Loss: 0.00879384464772034\n",
            "----------------------------------------\n",
            "Epoch 119\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0087, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  23.057109499273427\n",
            "SCOPE mean: 0.6642763311661672, SCOPE var: 0.3459749657197164\n",
            "Total Loss: 0.00874912851252786\n",
            "----------------------------------------\n",
            "Epoch 120\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0087, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  23.055994177884806\n",
            "SCOPE mean: 0.6643881752109149, SCOPE var: 0.345906331921806\n",
            "Total Loss: 0.008705347828046835\n",
            "----------------------------------------\n",
            "Epoch 121\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0087, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  23.05463438542369\n",
            "SCOPE mean: 0.6644944806493308, SCOPE var: 0.34583349837939503\n",
            "Total Loss: 0.008663532110001329\n",
            "----------------------------------------\n",
            "Epoch 122\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0086, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  23.052997835913498\n",
            "SCOPE mean: 0.6645969714798408, SCOPE var: 0.34575857465832366\n",
            "Total Loss: 0.00862208142481135\n",
            "----------------------------------------\n",
            "Epoch 123\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0086, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  23.05111104649088\n",
            "SCOPE mean: 0.6646959383587155, SCOPE var: 0.345681812238287\n",
            "Total Loss: 0.008581055768055281\n",
            "----------------------------------------\n",
            "Epoch 124\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0085, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  23.048910569373763\n",
            "SCOPE mean: 0.6647898202891998, SCOPE var: 0.3456033874602327\n",
            "Total Loss: 0.00854079099899202\n",
            "----------------------------------------\n",
            "Epoch 125\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0085, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  23.046429720364507\n",
            "SCOPE mean: 0.6648788630664, SCOPE var: 0.34552340341287535\n",
            "Total Loss: 0.008502167319601095\n",
            "----------------------------------------\n",
            "Epoch 126\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0085, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  23.043870016659834\n",
            "SCOPE mean: 0.6649654546190543, SCOPE var: 0.34544174618771384\n",
            "Total Loss: 0.0084639174133394\n",
            "----------------------------------------\n",
            "Epoch 127\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0084, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  23.04132180847016\n",
            "SCOPE mean: 0.6650545993447448, SCOPE var: 0.3453655879094053\n",
            "Total Loss: 0.008424158314856591\n",
            "----------------------------------------\n",
            "Epoch 128\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0084, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  23.038811379962908\n",
            "SCOPE mean: 0.665145445559128, SCOPE var: 0.34529438185158595\n",
            "Total Loss: 0.00838455128573426\n",
            "----------------------------------------\n",
            "Epoch 129\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0083, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  23.03633730750386\n",
            "SCOPE mean: 0.6652384014993783, SCOPE var: 0.345227665678806\n",
            "Total Loss: 0.008344993061772258\n",
            "----------------------------------------\n",
            "Epoch 130\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0083, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  23.034054826130284\n",
            "SCOPE mean: 0.6653348750250155, SCOPE var: 0.34516514215370314\n",
            "Total Loss: 0.008304951333374376\n",
            "----------------------------------------\n",
            "Epoch 131\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0083, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  23.031787353767786\n",
            "SCOPE mean: 0.6654332955544388, SCOPE var: 0.3451065467358303\n",
            "Total Loss: 0.008266415121220814\n",
            "----------------------------------------\n",
            "Epoch 132\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0082, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  23.029417432565477\n",
            "SCOPE mean: 0.665532144225954, SCOPE var: 0.3450518192853349\n",
            "Total Loss: 0.008228047711259127\n",
            "----------------------------------------\n",
            "Epoch 133\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0082, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  23.026916324821308\n",
            "SCOPE mean: 0.6656325044546402, SCOPE var: 0.34500066411573893\n",
            "Total Loss: 0.008189849998661966\n",
            "----------------------------------------\n",
            "Epoch 134\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0082, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  23.024276318865592\n",
            "SCOPE mean: 0.6657343209095407, SCOPE var: 0.34495281797579985\n",
            "Total Loss: 0.008151922824553296\n",
            "----------------------------------------\n",
            "Epoch 135\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0081, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  23.02151210863398\n",
            "SCOPE mean: 0.6658375635404804, SCOPE var: 0.34490804989750173\n",
            "Total Loss: 0.008114305825227546\n",
            "----------------------------------------\n",
            "Epoch 136\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0081, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  23.018645634360055\n",
            "SCOPE mean: 0.6659422219975089, SCOPE var: 0.34486615578298274\n",
            "Total Loss: 0.008077030057982257\n",
            "----------------------------------------\n",
            "Epoch 137\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0080, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  23.015656126956493\n",
            "SCOPE mean: 0.6660483094570456, SCOPE var: 0.3448269510256327\n",
            "Total Loss: 0.00804013009363733\n",
            "----------------------------------------\n",
            "Epoch 138\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0080, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  23.012486891346175\n",
            "SCOPE mean: 0.6661558112921677, SCOPE var: 0.3447902675718655\n",
            "Total Loss: 0.008004143867025127\n",
            "----------------------------------------\n",
            "Epoch 139\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0080, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  23.009350729179737\n",
            "SCOPE mean: 0.6662673386401284, SCOPE var: 0.34475574189010544\n",
            "Total Loss: 0.00796860856443127\n",
            "----------------------------------------\n",
            "Epoch 140\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0079, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  23.006184507450193\n",
            "SCOPE mean: 0.6663821046359104, SCOPE var: 0.34472324118733244\n",
            "Total Loss: 0.007933273089035625\n",
            "----------------------------------------\n",
            "Epoch 141\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0079, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  23.00301330150991\n",
            "SCOPE mean: 0.666498119501543, SCOPE var: 0.34469272122078365\n",
            "Total Loss: 0.007898107761113996\n",
            "----------------------------------------\n",
            "Epoch 142\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0079, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.99973722034422\n",
            "SCOPE mean: 0.6666160973533781, SCOPE var: 0.3446656196704552\n",
            "Total Loss: 0.007862639668362748\n",
            "----------------------------------------\n",
            "Epoch 143\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0078, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.99646252566691\n",
            "SCOPE mean: 0.6667373149778552, SCOPE var: 0.34464131913533386\n",
            "Total Loss: 0.007827636514388362\n",
            "----------------------------------------\n",
            "Epoch 144\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0078, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.99300742892758\n",
            "SCOPE mean: 0.6668596077862601, SCOPE var: 0.34461962417243164\n",
            "Total Loss: 0.007793783480552569\n",
            "----------------------------------------\n",
            "Epoch 145\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0078, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.989502019050324\n",
            "SCOPE mean: 0.6669834256652587, SCOPE var: 0.34460031147689546\n",
            "Total Loss: 0.007760341754871603\n",
            "----------------------------------------\n",
            "Epoch 146\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0077, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.985935982313386\n",
            "SCOPE mean: 0.6671080150243225, SCOPE var: 0.3445829657970571\n",
            "Total Loss: 0.007727249971855522\n",
            "----------------------------------------\n",
            "Epoch 147\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0077, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.98233794076062\n",
            "SCOPE mean: 0.6672329353369058, SCOPE var: 0.3445672048000242\n",
            "Total Loss: 0.007694525582344058\n",
            "----------------------------------------\n",
            "Epoch 148\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0077, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.978701748676112\n",
            "SCOPE mean: 0.6673576683444722, SCOPE var: 0.344552682186057\n",
            "Total Loss: 0.007662185216300015\n",
            "----------------------------------------\n",
            "Epoch 149\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0076, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.975027458758618\n",
            "SCOPE mean: 0.6674817517950256, SCOPE var: 0.344539085722436\n",
            "Total Loss: 0.007630278723983577\n",
            "----------------------------------------\n",
            "Epoch 150\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0076, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.971445282477536\n",
            "SCOPE mean: 0.6676083305782308, SCOPE var: 0.34452591661574045\n",
            "Total Loss: 0.007598994628616092\n",
            "----------------------------------------\n",
            "Epoch 151\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0076, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.96791607546053\n",
            "SCOPE mean: 0.667735380468227, SCOPE var: 0.34451293923453985\n",
            "Total Loss: 0.007568075669700964\n",
            "----------------------------------------\n",
            "Epoch 152\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0075, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.96427318746798\n",
            "SCOPE mean: 0.6678565673640332, SCOPE var: 0.3445001898251452\n",
            "Total Loss: 0.007537317705267795\n",
            "----------------------------------------\n",
            "Epoch 153\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0075, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.960636682069627\n",
            "SCOPE mean: 0.6679757394871685, SCOPE var: 0.3444874962726198\n",
            "Total Loss: 0.007506782171518261\n",
            "----------------------------------------\n",
            "Epoch 154\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0075, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.956942633195602\n",
            "SCOPE mean: 0.6680987488760683, SCOPE var: 0.3444746316597647\n",
            "Total Loss: 0.007476505073240364\n",
            "----------------------------------------\n",
            "Epoch 155\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0074, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.95329107457481\n",
            "SCOPE mean: 0.6682206942090633, SCOPE var: 0.3444615304929922\n",
            "Total Loss: 0.0074476085045035246\n",
            "----------------------------------------\n",
            "Epoch 156\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0074, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.949724319399387\n",
            "SCOPE mean: 0.6683413822574076, SCOPE var: 0.34444785298767033\n",
            "Total Loss: 0.007419475242617399\n",
            "----------------------------------------\n",
            "Epoch 157\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0074, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.946152925554927\n",
            "SCOPE mean: 0.6684298407319776, SCOPE var: 0.34438732707227404\n",
            "Total Loss: 0.007391627775902309\n",
            "----------------------------------------\n",
            "Epoch 158\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0074, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.942485835402355\n",
            "SCOPE mean: 0.6685125119604439, SCOPE var: 0.3443243741040252\n",
            "Total Loss: 0.007364472172656676\n",
            "----------------------------------------\n",
            "Epoch 159\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0073, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.93863382620625\n",
            "SCOPE mean: 0.6685909270035373, SCOPE var: 0.344261209372501\n",
            "Total Loss: 0.007338415723712388\n",
            "----------------------------------------\n",
            "Epoch 160\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0073, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.93455824626689\n",
            "SCOPE mean: 0.6686627122965615, SCOPE var: 0.3441937452940764\n",
            "Total Loss: 0.007313397013749566\n",
            "----------------------------------------\n",
            "Epoch 161\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0073, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.93031487025781\n",
            "SCOPE mean: 0.6687276382337717, SCOPE var: 0.34412197461050187\n",
            "Total Loss: 0.007288574827070621\n",
            "----------------------------------------\n",
            "Epoch 162\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0073, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.925891692047287\n",
            "SCOPE mean: 0.6687855255172569, SCOPE var: 0.3440459154172897\n",
            "Total Loss: 0.007264142092772172\n",
            "----------------------------------------\n",
            "Epoch 163\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0072, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.921433289679328\n",
            "SCOPE mean: 0.6688365804247287, SCOPE var: 0.3439654651299513\n",
            "Total Loss: 0.0072397646879335574\n",
            "----------------------------------------\n",
            "Epoch 164\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0072, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.91692890548756\n",
            "SCOPE mean: 0.6688816736434438, SCOPE var: 0.34388080599270326\n",
            "Total Loss: 0.007215814874720705\n",
            "----------------------------------------\n",
            "Epoch 165\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0072, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.912184928012483\n",
            "SCOPE mean: 0.6689188838062311, SCOPE var: 0.34379341995762663\n",
            "Total Loss: 0.00719422559174329\n",
            "----------------------------------------\n",
            "Epoch 166\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0072, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.90732429714815\n",
            "SCOPE mean: 0.6689463348171198, SCOPE var: 0.34370122238822026\n",
            "Total Loss: 0.0071728120911722995\n",
            "----------------------------------------\n",
            "Epoch 167\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0072, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.902364828573322\n",
            "SCOPE mean: 0.6689636354850617, SCOPE var: 0.34360391773051085\n",
            "Total Loss: 0.0071515431296137735\n",
            "----------------------------------------\n",
            "Epoch 168\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0071, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.897318872736665\n",
            "SCOPE mean: 0.6689706150473026, SCOPE var: 0.34350135233911094\n",
            "Total Loss: 0.007130393642292362\n",
            "----------------------------------------\n",
            "Epoch 169\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0071, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.892131196217232\n",
            "SCOPE mean: 0.6689673015535034, SCOPE var: 0.3433935013463362\n",
            "Total Loss: 0.007109242823883154\n",
            "----------------------------------------\n",
            "Epoch 170\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0071, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.88676349170565\n",
            "SCOPE mean: 0.6690844571247687, SCOPE var: 0.34328059886922474\n",
            "Total Loss: 0.007088441366001165\n",
            "----------------------------------------\n",
            "Epoch 171\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0071, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.881570525708543\n",
            "SCOPE mean: 0.6691958362089492, SCOPE var: 0.34316572740552137\n",
            "Total Loss: 0.007068012372639956\n",
            "----------------------------------------\n",
            "Epoch 172\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0070, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.876563009341265\n",
            "SCOPE mean: 0.6693019490408254, SCOPE var: 0.3430486967084205\n",
            "Total Loss: 0.00704766010909673\n",
            "----------------------------------------\n",
            "Epoch 173\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0070, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.871552593485735\n",
            "SCOPE mean: 0.6694011198974827, SCOPE var: 0.3429297408822303\n",
            "Total Loss: 0.00702742604532542\n",
            "----------------------------------------\n",
            "Epoch 174\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0070, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.866626673449105\n",
            "SCOPE mean: 0.6694958198965908, SCOPE var: 0.3428088581717126\n",
            "Total Loss: 0.00700746466931638\n",
            "----------------------------------------\n",
            "Epoch 175\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0070, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.86159061893392\n",
            "SCOPE mean: 0.6695793450275405, SCOPE var: 0.3426860833322749\n",
            "Total Loss: 0.006987547727722012\n",
            "----------------------------------------\n",
            "Epoch 176\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0070, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.856452777712708\n",
            "SCOPE mean: 0.6696527795590705, SCOPE var: 0.34256171161249893\n",
            "Total Loss: 0.006967658110811986\n",
            "----------------------------------------\n",
            "Epoch 177\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0069, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.851218284319824\n",
            "SCOPE mean: 0.6697172386407647, SCOPE var: 0.342436089749124\n",
            "Total Loss: 0.006947818532476148\n",
            "----------------------------------------\n",
            "Epoch 178\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0069, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.84588360430083\n",
            "SCOPE mean: 0.6697738489906737, SCOPE var: 0.3423096014465118\n",
            "Total Loss: 0.006928004007938755\n",
            "----------------------------------------\n",
            "Epoch 179\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0069, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.840483574692577\n",
            "SCOPE mean: 0.6698274097309204, SCOPE var: 0.34218293193811167\n",
            "Total Loss: 0.006909034178147996\n",
            "----------------------------------------\n",
            "Epoch 180\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0069, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.83513192228609\n",
            "SCOPE mean: 0.6698800640079525, SCOPE var: 0.34205615112781046\n",
            "Total Loss: 0.006889995588340963\n",
            "----------------------------------------\n",
            "Epoch 181\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0069, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.82982603675891\n",
            "SCOPE mean: 0.6699488279160735, SCOPE var: 0.3419295009151951\n",
            "Total Loss: 0.0068710711890953005\n",
            "----------------------------------------\n",
            "Epoch 182\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0069, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.824450909390162\n",
            "SCOPE mean: 0.6700763962621662, SCOPE var: 0.3418033818994711\n",
            "Total Loss: 0.006852430326785013\n",
            "----------------------------------------\n",
            "Epoch 183\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0068, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.819010728168006\n",
            "SCOPE mean: 0.6701314572171195, SCOPE var: 0.3416778805385269\n",
            "Total Loss: 0.006833929837879953\n",
            "----------------------------------------\n",
            "Epoch 184\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0068, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.813505037017602\n",
            "SCOPE mean: 0.6701862829062442, SCOPE var: 0.34155326659263874\n",
            "Total Loss: 0.006815572294389565\n",
            "----------------------------------------\n",
            "Epoch 185\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0068, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.80790627381403\n",
            "SCOPE mean: 0.6702414748019322, SCOPE var: 0.34142973462170606\n",
            "Total Loss: 0.006797486192674593\n",
            "----------------------------------------\n",
            "Epoch 186\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0068, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.802182979101406\n",
            "SCOPE mean: 0.670295387869712, SCOPE var: 0.3413073475464196\n",
            "Total Loss: 0.006779663753115558\n",
            "----------------------------------------\n",
            "Epoch 187\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0068, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.796362540192398\n",
            "SCOPE mean: 0.6703487017038156, SCOPE var: 0.34118628847093907\n",
            "Total Loss: 0.006761988327409041\n",
            "----------------------------------------\n",
            "Epoch 188\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0067, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.79044337783538\n",
            "SCOPE mean: 0.6704021609010888, SCOPE var: 0.3410667229875249\n",
            "Total Loss: 0.006744520977667178\n",
            "----------------------------------------\n",
            "Epoch 189\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0067, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.784341208984923\n",
            "SCOPE mean: 0.6704539340612587, SCOPE var: 0.3409484651744723\n",
            "Total Loss: 0.006727163006191163\n",
            "----------------------------------------\n",
            "Epoch 190\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0067, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.778068650013985\n",
            "SCOPE mean: 0.6705046904303228, SCOPE var: 0.3408316790826656\n",
            "Total Loss: 0.0067099102097915265\n",
            "----------------------------------------\n",
            "Epoch 191\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0067, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.771538314709378\n",
            "SCOPE mean: 0.670545406396843, SCOPE var: 0.3407165459707983\n",
            "Total Loss: 0.006692748636265624\n",
            "----------------------------------------\n",
            "Epoch 192\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0067, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.76504154635914\n",
            "SCOPE mean: 0.6705893940702256, SCOPE var: 0.3406033932509289\n",
            "Total Loss: 0.006675685701878227\n",
            "----------------------------------------\n",
            "Epoch 193\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0067, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.7584891830326\n",
            "SCOPE mean: 0.6706371943787103, SCOPE var: 0.34049240907938183\n",
            "Total Loss: 0.006659071847435392\n",
            "----------------------------------------\n",
            "Epoch 194\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0066, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.751952945129606\n",
            "SCOPE mean: 0.670685275907566, SCOPE var: 0.34038204886331275\n",
            "Total Loss: 0.00664261828339731\n",
            "----------------------------------------\n",
            "Epoch 195\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0066, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.745430521867398\n",
            "SCOPE mean: 0.6707338897059567, SCOPE var: 0.3402724726962499\n",
            "Total Loss: 0.006626256026630801\n",
            "----------------------------------------\n",
            "Epoch 196\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0066, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.738993296138098\n",
            "SCOPE mean: 0.6707845865368711, SCOPE var: 0.34016367309161527\n",
            "Total Loss: 0.006610087845830655\n",
            "----------------------------------------\n",
            "Epoch 197\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0066, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.73249865411683\n",
            "SCOPE mean: 0.6708345898034213, SCOPE var: 0.3400557512587041\n",
            "Total Loss: 0.0065941463421168795\n",
            "----------------------------------------\n",
            "Epoch 198\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0066, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.725939148086756\n",
            "SCOPE mean: 0.670883779203349, SCOPE var: 0.33994856722236655\n",
            "Total Loss: 0.006578241509632824\n",
            "----------------------------------------\n",
            "Epoch 199\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0066, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.71930728335465\n",
            "SCOPE mean: 0.6709316920865928, SCOPE var: 0.33984199723507\n",
            "Total Loss: 0.006562380529689798\n",
            "----------------------------------------\n",
            "Epoch 200\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0065, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.712601363251647\n",
            "SCOPE mean: 0.6709784750508943, SCOPE var: 0.3397362424454043\n",
            "Total Loss: 0.006546702623083038\n",
            "----------------------------------------\n",
            "Epoch 201\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0065, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.705908770187705\n",
            "SCOPE mean: 0.671025508651179, SCOPE var: 0.33963201075272625\n",
            "Total Loss: 0.0065313801304127325\n",
            "----------------------------------------\n",
            "Epoch 202\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0065, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.699293390914125\n",
            "SCOPE mean: 0.671074653251188, SCOPE var: 0.3395289546603261\n",
            "Total Loss: 0.006515910828254625\n",
            "----------------------------------------\n",
            "Epoch 203\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0065, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.692843907756092\n",
            "SCOPE mean: 0.6711318401287979, SCOPE var: 0.33942717675297157\n",
            "Total Loss: 0.006499733637485872\n",
            "----------------------------------------\n",
            "Epoch 204\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0065, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.686076897714884\n",
            "SCOPE mean: 0.6709394568433621, SCOPE var: 0.3393262642744623\n",
            "Total Loss: 0.0064835572329783936\n",
            "----------------------------------------\n",
            "Epoch 205\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0065, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.67938304575209\n",
            "SCOPE mean: 0.6707418307186704, SCOPE var: 0.3392263291966737\n",
            "Total Loss: 0.006467351050005145\n",
            "----------------------------------------\n",
            "Epoch 206\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0065, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.672631705137974\n",
            "SCOPE mean: 0.6705455352645433, SCOPE var: 0.33912725479150474\n",
            "Total Loss: 0.00645133845058618\n",
            "----------------------------------------\n",
            "Epoch 207\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0064, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.665846196971362\n",
            "SCOPE mean: 0.6703489227841695, SCOPE var: 0.33902573459548185\n",
            "Total Loss: 0.006435272678803954\n",
            "----------------------------------------\n",
            "Epoch 208\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0064, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.659074665867745\n",
            "SCOPE mean: 0.6701529657372084, SCOPE var: 0.3389229590142222\n",
            "Total Loss: 0.006419393955328127\n",
            "----------------------------------------\n",
            "Epoch 209\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0064, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.652386500128333\n",
            "SCOPE mean: 0.6699545827758524, SCOPE var: 0.33881709210825356\n",
            "Total Loss: 0.006403478055820946\n",
            "----------------------------------------\n",
            "Epoch 210\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0064, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.645945493420786\n",
            "SCOPE mean: 0.6697554242300792, SCOPE var: 0.3387107586004127\n",
            "Total Loss: 0.006387420059945313\n",
            "----------------------------------------\n",
            "Epoch 211\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0064, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.639451365910237\n",
            "SCOPE mean: 0.6695517943879749, SCOPE var: 0.33860365464048003\n",
            "Total Loss: 0.006371431119417647\n",
            "----------------------------------------\n",
            "Epoch 212\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0064, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.63293549684704\n",
            "SCOPE mean: 0.6693443432891767, SCOPE var: 0.33849639846953644\n",
            "Total Loss: 0.006355447252762634\n",
            "----------------------------------------\n",
            "Epoch 213\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0063, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.626407574029773\n",
            "SCOPE mean: 0.6691330169944415, SCOPE var: 0.3383887513183996\n",
            "Total Loss: 0.006339456516570584\n",
            "----------------------------------------\n",
            "Epoch 214\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0063, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.619803518778\n",
            "SCOPE mean: 0.668912816961205, SCOPE var: 0.3382801128437481\n",
            "Total Loss: 0.00632339776327879\n",
            "----------------------------------------\n",
            "Epoch 215\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0063, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.61295548305539\n",
            "SCOPE mean: 0.6686696418145648, SCOPE var: 0.3381692520410345\n",
            "Total Loss: 0.00630704316970222\n",
            "----------------------------------------\n",
            "Epoch 216\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0063, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.60611130499383\n",
            "SCOPE mean: 0.6684228089515937, SCOPE var: 0.33805776141848703\n",
            "Total Loss: 0.006290791625837143\n",
            "----------------------------------------\n",
            "Epoch 217\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0063, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.59939897953736\n",
            "SCOPE mean: 0.6681753546695202, SCOPE var: 0.33794646558760444\n",
            "Total Loss: 0.006274873565745606\n",
            "----------------------------------------\n",
            "Epoch 218\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0063, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.59273433652301\n",
            "SCOPE mean: 0.6679318658259612, SCOPE var: 0.337837133760947\n",
            "Total Loss: 0.006258970229254964\n",
            "----------------------------------------\n",
            "Epoch 219\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0062, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.586107982457705\n",
            "SCOPE mean: 0.6676919157892276, SCOPE var: 0.33772949193089824\n",
            "Total Loss: 0.006243039251125014\n",
            "----------------------------------------\n",
            "Epoch 220\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0062, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.579502245248328\n",
            "SCOPE mean: 0.6674548523121273, SCOPE var: 0.3376234154035293\n",
            "Total Loss: 0.0062270956507546465\n",
            "----------------------------------------\n",
            "Epoch 221\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0062, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.572792516792962\n",
            "SCOPE mean: 0.6672167666643468, SCOPE var: 0.33751882352047385\n",
            "Total Loss: 0.006211123313454663\n",
            "----------------------------------------\n",
            "Epoch 222\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0062, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.566107568208686\n",
            "SCOPE mean: 0.666981454527352, SCOPE var: 0.33741560858008113\n",
            "Total Loss: 0.006195168607700102\n",
            "----------------------------------------\n",
            "Epoch 223\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0062, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.55944879383181\n",
            "SCOPE mean: 0.6667489177759299, SCOPE var: 0.3373139322262672\n",
            "Total Loss: 0.006179326784829461\n",
            "----------------------------------------\n",
            "Epoch 224\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0062, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.552804008615503\n",
            "SCOPE mean: 0.666517821785449, SCOPE var: 0.33721317691713903\n",
            "Total Loss: 0.006163635051390759\n",
            "----------------------------------------\n",
            "Epoch 225\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0061, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.546150784019314\n",
            "SCOPE mean: 0.6662878939637216, SCOPE var: 0.3371129899665908\n",
            "Total Loss: 0.006147985080337653\n",
            "----------------------------------------\n",
            "Epoch 226\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0061, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.539478999025008\n",
            "SCOPE mean: 0.6660590294781407, SCOPE var: 0.3370133174941683\n",
            "Total Loss: 0.006132501509932669\n",
            "----------------------------------------\n",
            "Epoch 227\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0061, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.532706593403088\n",
            "SCOPE mean: 0.6658288211848991, SCOPE var: 0.33691386831441983\n",
            "Total Loss: 0.006117055252160607\n",
            "----------------------------------------\n",
            "Epoch 228\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0061, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.525819346094217\n",
            "SCOPE mean: 0.6655976356171779, SCOPE var: 0.3368148842627936\n",
            "Total Loss: 0.0061017016012297285\n",
            "----------------------------------------\n",
            "Epoch 229\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0061, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.518753527957973\n",
            "SCOPE mean: 0.6653677368712332, SCOPE var: 0.3367142098285999\n",
            "Total Loss: 0.006086511700802552\n",
            "----------------------------------------\n",
            "Epoch 230\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0061, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.511779273752335\n",
            "SCOPE mean: 0.6651382941675403, SCOPE var: 0.33661346241670825\n",
            "Total Loss: 0.006071482093118594\n",
            "----------------------------------------\n",
            "Epoch 231\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0061, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.504893300577884\n",
            "SCOPE mean: 0.6649083984560697, SCOPE var: 0.33651263955123173\n",
            "Total Loss: 0.006056483090203442\n",
            "----------------------------------------\n",
            "Epoch 232\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0060, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.498085573871624\n",
            "SCOPE mean: 0.6646770057950454, SCOPE var: 0.33641161605998904\n",
            "Total Loss: 0.006041534158092797\n",
            "----------------------------------------\n",
            "Epoch 233\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0060, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.4912352433924\n",
            "SCOPE mean: 0.6644429647568872, SCOPE var: 0.33631057370815554\n",
            "Total Loss: 0.006026764450386403\n",
            "----------------------------------------\n",
            "Epoch 234\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0060, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.484305852753057\n",
            "SCOPE mean: 0.6642045819781384, SCOPE var: 0.3362078321860791\n",
            "Total Loss: 0.006012066771092817\n",
            "----------------------------------------\n",
            "Epoch 235\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0060, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.477444422672935\n",
            "SCOPE mean: 0.6639651523008415, SCOPE var: 0.3361044250739623\n",
            "Total Loss: 0.005997383103679525\n",
            "----------------------------------------\n",
            "Epoch 236\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0060, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.4706492619045\n",
            "SCOPE mean: 0.6637248941111399, SCOPE var: 0.33600057674586664\n",
            "Total Loss: 0.005982777200194449\n",
            "----------------------------------------\n",
            "Epoch 237\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0060, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.463925771906695\n",
            "SCOPE mean: 0.6634852241432141, SCOPE var: 0.33589710212589435\n",
            "Total Loss: 0.005968369122456287\n",
            "----------------------------------------\n",
            "Epoch 238\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0060, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.45707788169572\n",
            "SCOPE mean: 0.6632466350687183, SCOPE var: 0.3357948262515706\n",
            "Total Loss: 0.005954033487455726\n",
            "----------------------------------------\n",
            "Epoch 239\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0059, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.450118890807456\n",
            "SCOPE mean: 0.663008972342955, SCOPE var: 0.33569360402865794\n",
            "Total Loss: 0.005939747987177133\n",
            "----------------------------------------\n",
            "Epoch 240\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0059, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.443182769087283\n",
            "SCOPE mean: 0.6627745810388578, SCOPE var: 0.33559361190926046\n",
            "Total Loss: 0.0059255561434883594\n",
            "----------------------------------------\n",
            "Epoch 241\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0059, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.4362511283067\n",
            "SCOPE mean: 0.6625423756644863, SCOPE var: 0.33549413775228804\n",
            "Total Loss: 0.005911477403650548\n",
            "----------------------------------------\n",
            "Epoch 242\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0059, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.429207594545947\n",
            "SCOPE mean: 0.662317982272884, SCOPE var: 0.33539576704556334\n",
            "Total Loss: 0.005897478862786131\n",
            "----------------------------------------\n",
            "Epoch 243\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0059, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.422173322729364\n",
            "SCOPE mean: 0.6620940322664607, SCOPE var: 0.33529738520902674\n",
            "Total Loss: 0.005883498473440414\n",
            "----------------------------------------\n",
            "Epoch 244\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0059, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.4150407385049\n",
            "SCOPE mean: 0.6618694342357025, SCOPE var: 0.3351995384239855\n",
            "Total Loss: 0.0058696129792226\n",
            "----------------------------------------\n",
            "Epoch 245\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0059, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.407818159594772\n",
            "SCOPE mean: 0.6616442023708712, SCOPE var: 0.3351021461892997\n",
            "Total Loss: 0.005855839918944559\n",
            "----------------------------------------\n",
            "Epoch 246\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0058, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.400626078093964\n",
            "SCOPE mean: 0.661419498259784, SCOPE var: 0.3350046004096859\n",
            "Total Loss: 0.005842132531225882\n",
            "----------------------------------------\n",
            "Epoch 247\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0058, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.39351545478401\n",
            "SCOPE mean: 0.6611949219472304, SCOPE var: 0.33490624818410675\n",
            "Total Loss: 0.005828519494691763\n",
            "----------------------------------------\n",
            "Epoch 248\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0058, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.3861080381322\n",
            "SCOPE mean: 0.660991340995917, SCOPE var: 0.33480467175530493\n",
            "Total Loss: 0.005815982277628983\n",
            "----------------------------------------\n",
            "Epoch 249\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0058, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.378636019755085\n",
            "SCOPE mean: 0.6607825257325785, SCOPE var: 0.3347011409046945\n",
            "Total Loss: 0.005803525499673525\n",
            "----------------------------------------\n",
            "Epoch 250\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0058, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.371071464955186\n",
            "SCOPE mean: 0.6605733885490773, SCOPE var: 0.33459790572006853\n",
            "Total Loss: 0.005791604796768099\n",
            "----------------------------------------\n",
            "Epoch 251\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0058, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.363549023851878\n",
            "SCOPE mean: 0.6603646080446444, SCOPE var: 0.3344949355743224\n",
            "Total Loss: 0.005779861045011163\n",
            "----------------------------------------\n",
            "Epoch 252\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0058, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.356191871128214\n",
            "SCOPE mean: 0.6601589618307377, SCOPE var: 0.33439271421985634\n",
            "Total Loss: 0.00576831227938261\n",
            "----------------------------------------\n",
            "Epoch 253\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0058, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.348996630112666\n",
            "SCOPE mean: 0.659955195648023, SCOPE var: 0.3342908775165017\n",
            "Total Loss: 0.0057570292824079055\n",
            "----------------------------------------\n",
            "Epoch 254\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0057, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.341987039173898\n",
            "SCOPE mean: 0.6597546944467185, SCOPE var: 0.3341903607446342\n",
            "Total Loss: 0.005745828723303856\n",
            "----------------------------------------\n",
            "Epoch 255\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0057, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.335139119278665\n",
            "SCOPE mean: 0.6595572527286078, SCOPE var: 0.33409107220820516\n",
            "Total Loss: 0.0057347826495314615\n",
            "----------------------------------------\n",
            "Epoch 256\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0057, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.328353482410527\n",
            "SCOPE mean: 0.6593557292677381, SCOPE var: 0.3339904694490949\n",
            "Total Loss: 0.005723746275667385\n",
            "----------------------------------------\n",
            "Epoch 257\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0057, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.321642367454192\n",
            "SCOPE mean: 0.6591519561162351, SCOPE var: 0.3338895986442069\n",
            "Total Loss: 0.005712766852306221\n",
            "----------------------------------------\n",
            "Epoch 258\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0057, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.31492889200779\n",
            "SCOPE mean: 0.658949244731866, SCOPE var: 0.3337897230415053\n",
            "Total Loss: 0.005701682723374117\n",
            "----------------------------------------\n",
            "Epoch 259\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0057, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.3081843813275\n",
            "SCOPE mean: 0.6587457762796485, SCOPE var: 0.3336907033222321\n",
            "Total Loss: 0.005690642040331514\n",
            "----------------------------------------\n",
            "Epoch 260\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0057, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.30161043847193\n",
            "SCOPE mean: 0.6585417324432282, SCOPE var: 0.3335918136198998\n",
            "Total Loss: 0.005679679677838582\n",
            "----------------------------------------\n",
            "Epoch 261\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0057, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.295173073828437\n",
            "SCOPE mean: 0.6583360020614506, SCOPE var: 0.3334919257402455\n",
            "Total Loss: 0.005668679590933873\n",
            "----------------------------------------\n",
            "Epoch 262\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0057, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.288573935917658\n",
            "SCOPE mean: 0.6581305638411032, SCOPE var: 0.3333928411377016\n",
            "Total Loss: 0.005658004953287105\n",
            "----------------------------------------\n",
            "Epoch 263\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0056, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.282010732827484\n",
            "SCOPE mean: 0.6579277251358606, SCOPE var: 0.3332949900816781\n",
            "Total Loss: 0.005647399475222611\n",
            "----------------------------------------\n",
            "Epoch 264\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0056, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.27536945607666\n",
            "SCOPE mean: 0.6577248700756376, SCOPE var: 0.33319798302686315\n",
            "Total Loss: 0.005636863568999057\n",
            "----------------------------------------\n",
            "Epoch 265\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0056, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.26866326933118\n",
            "SCOPE mean: 0.6575221134600271, SCOPE var: 0.33310177778639205\n",
            "Total Loss: 0.005626338245894313\n",
            "----------------------------------------\n",
            "Epoch 266\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0056, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.26189231697628\n",
            "SCOPE mean: 0.6573195705642466, SCOPE var: 0.33300634405499885\n",
            "Total Loss: 0.005615843129399114\n",
            "----------------------------------------\n",
            "Epoch 267\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0056, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.2551934377546\n",
            "SCOPE mean: 0.6571192912837036, SCOPE var: 0.3329119631373673\n",
            "Total Loss: 0.005605380666102105\n",
            "----------------------------------------\n",
            "Epoch 268\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0056, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.248610872401446\n",
            "SCOPE mean: 0.6569184235924488, SCOPE var: 0.3328173537435495\n",
            "Total Loss: 0.005594949763121254\n",
            "----------------------------------------\n",
            "Epoch 269\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0056, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.242076649941435\n",
            "SCOPE mean: 0.6567170946319275, SCOPE var: 0.33272256455638344\n",
            "Total Loss: 0.005584915167299873\n",
            "----------------------------------------\n",
            "Epoch 270\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0056, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.235426200509853\n",
            "SCOPE mean: 0.6565154306486949, SCOPE var: 0.33262863588908204\n",
            "Total Loss: 0.0055750274165056\n",
            "----------------------------------------\n",
            "Epoch 271\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0056, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.228679754797096\n",
            "SCOPE mean: 0.6563135225987345, SCOPE var: 0.33253549003653365\n",
            "Total Loss: 0.005565207221830932\n",
            "----------------------------------------\n",
            "Epoch 272\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0056, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.222019243763352\n",
            "SCOPE mean: 0.6561119074589651, SCOPE var: 0.3324427061014654\n",
            "Total Loss: 0.005555511281486186\n",
            "----------------------------------------\n",
            "Epoch 273\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0055, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.21526268574098\n",
            "SCOPE mean: 0.6559097091853903, SCOPE var: 0.332349790164749\n",
            "Total Loss: 0.00554545482033538\n",
            "----------------------------------------\n",
            "Epoch 274\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0055, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.208292933120507\n",
            "SCOPE mean: 0.6557048229261336, SCOPE var: 0.3322567513385686\n",
            "Total Loss: 0.005535111766569453\n",
            "----------------------------------------\n",
            "Epoch 275\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0055, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.201200089415618\n",
            "SCOPE mean: 0.6554998105296964, SCOPE var: 0.3321650280881397\n",
            "Total Loss: 0.005525150031238642\n",
            "----------------------------------------\n",
            "Epoch 276\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0055, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.194101627676297\n",
            "SCOPE mean: 0.6552949833461708, SCOPE var: 0.33207302122656684\n",
            "Total Loss: 0.005515498512575565\n",
            "----------------------------------------\n",
            "Epoch 277\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0055, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.18704531268203\n",
            "SCOPE mean: 0.6550876562842971, SCOPE var: 0.33198040232355513\n",
            "Total Loss: 0.005505799374942628\n",
            "----------------------------------------\n",
            "Epoch 278\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0055, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.179963703784654\n",
            "SCOPE mean: 0.6548807015015033, SCOPE var: 0.331888355170343\n",
            "Total Loss: 0.005496052159279976\n",
            "----------------------------------------\n",
            "Epoch 279\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0055, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.1729864356933\n",
            "SCOPE mean: 0.654676820086521, SCOPE var: 0.3317971321337295\n",
            "Total Loss: 0.005486307653016994\n",
            "----------------------------------------\n",
            "Epoch 280\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0055, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.166159540301425\n",
            "SCOPE mean: 0.6544745591915844, SCOPE var: 0.33170662248133453\n",
            "Total Loss: 0.005476599154458962\n",
            "----------------------------------------\n",
            "Epoch 281\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0055, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.159354587495542\n",
            "SCOPE mean: 0.6542699968032842, SCOPE var: 0.3316164880939308\n",
            "Total Loss: 0.005466973535550173\n",
            "----------------------------------------\n",
            "Epoch 282\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0055, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.15264162277019\n",
            "SCOPE mean: 0.6540673400089259, SCOPE var: 0.33152699291675525\n",
            "Total Loss: 0.005457369606040721\n",
            "----------------------------------------\n",
            "Epoch 283\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0054, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.145913343211195\n",
            "SCOPE mean: 0.6538611091020488, SCOPE var: 0.3314365766599931\n",
            "Total Loss: 0.005447696487898672\n",
            "----------------------------------------\n",
            "Epoch 284\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0054, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.13905218841372\n",
            "SCOPE mean: 0.6536552966809998, SCOPE var: 0.3313439869753895\n",
            "Total Loss: 0.0054376367022466975\n",
            "----------------------------------------\n",
            "Epoch 285\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0054, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.132069977905317\n",
            "SCOPE mean: 0.6534485849044162, SCOPE var: 0.33125093096767744\n",
            "Total Loss: 0.005427537390402145\n",
            "----------------------------------------\n",
            "Epoch 286\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0054, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.12497508468542\n",
            "SCOPE mean: 0.6532411424439901, SCOPE var: 0.33115746492808096\n",
            "Total Loss: 0.005417390842797778\n",
            "----------------------------------------\n",
            "Epoch 287\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0054, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.117773152966723\n",
            "SCOPE mean: 0.6530331122949623, SCOPE var: 0.3310636333179066\n",
            "Total Loss: 0.0054072602507375\n",
            "----------------------------------------\n",
            "Epoch 288\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0054, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.110614270908943\n",
            "SCOPE mean: 0.6528273982451824, SCOPE var: 0.3309697986691745\n",
            "Total Loss: 0.005397094479265082\n",
            "----------------------------------------\n",
            "Epoch 289\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0054, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.10347891539788\n",
            "SCOPE mean: 0.6526239497895991, SCOPE var: 0.33087612945862976\n",
            "Total Loss: 0.005386926949198964\n",
            "----------------------------------------\n",
            "Epoch 290\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0054, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.096212006193284\n",
            "SCOPE mean: 0.652418142622087, SCOPE var: 0.3307811570768515\n",
            "Total Loss: 0.0053767278951599275\n",
            "----------------------------------------\n",
            "Epoch 291\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0054, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.08886651153737\n",
            "SCOPE mean: 0.6522116431045643, SCOPE var: 0.33068598407848676\n",
            "Total Loss: 0.005366569079722498\n",
            "----------------------------------------\n",
            "Epoch 292\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0054, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.08157785865222\n",
            "SCOPE mean: 0.6520071984526467, SCOPE var: 0.3305907116528326\n",
            "Total Loss: 0.005356433688274537\n",
            "----------------------------------------\n",
            "Epoch 293\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0053, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.074211153379295\n",
            "SCOPE mean: 0.6518011781064108, SCOPE var: 0.3304949240464519\n",
            "Total Loss: 0.005346309016562857\n",
            "----------------------------------------\n",
            "Epoch 294\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0053, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.066776763897533\n",
            "SCOPE mean: 0.6515940146477449, SCOPE var: 0.33039858423173457\n",
            "Total Loss: 0.0053362007263526145\n",
            "----------------------------------------\n",
            "Epoch 295\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0053, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.059406218182364\n",
            "SCOPE mean: 0.6513886882271058, SCOPE var: 0.3303020062794756\n",
            "Total Loss: 0.005326131590645109\n",
            "----------------------------------------\n",
            "Epoch 296\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0053, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.05189475234985\n",
            "SCOPE mean: 0.6511821146730721, SCOPE var: 0.33020477420496175\n",
            "Total Loss: 0.005315407912062947\n",
            "----------------------------------------\n",
            "Epoch 297\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0053, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.044189441967525\n",
            "SCOPE mean: 0.6509666355844769, SCOPE var: 0.33010669117359726\n",
            "Total Loss: 0.005304508657305583\n",
            "----------------------------------------\n",
            "Epoch 298\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0053, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.03645149686998\n",
            "SCOPE mean: 0.6507459767437554, SCOPE var: 0.33000812239094773\n",
            "Total Loss: 0.005293459067709131\n",
            "----------------------------------------\n",
            "Epoch 299\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0053, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.02865874071278\n",
            "SCOPE mean: 0.6505206558870994, SCOPE var: 0.3299087830128249\n",
            "Total Loss: 0.005282263794958042\n",
            "----------------------------------------\n",
            "Epoch 300\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0053, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.02069679815447\n",
            "SCOPE mean: 0.650288373371342, SCOPE var: 0.32980837351205816\n",
            "Total Loss: 0.005270996324064235\n",
            "----------------------------------------\n",
            "Epoch 301\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0053, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.012556562022088\n",
            "SCOPE mean: 0.6500429389163096, SCOPE var: 0.3297066953221447\n",
            "Total Loss: 0.005259649734548443\n",
            "----------------------------------------\n",
            "Epoch 302\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0052, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  22.004246574202693\n",
            "SCOPE mean: 0.6497883610730507, SCOPE var: 0.3296040606948291\n",
            "Total Loss: 0.005248447176648268\n",
            "----------------------------------------\n",
            "Epoch 303\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0052, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.99596122699986\n",
            "SCOPE mean: 0.6495355142229939, SCOPE var: 0.32950089749414185\n",
            "Total Loss: 0.005237688678045472\n",
            "----------------------------------------\n",
            "Epoch 304\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0052, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.98776755508286\n",
            "SCOPE mean: 0.6492845012621303, SCOPE var: 0.329397170782744\n",
            "Total Loss: 0.005226940465949858\n",
            "----------------------------------------\n",
            "Epoch 305\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0052, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.979647273514136\n",
            "SCOPE mean: 0.6490347123345035, SCOPE var: 0.3292931746948277\n",
            "Total Loss: 0.005216307444889619\n",
            "----------------------------------------\n",
            "Epoch 306\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0052, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.971468938454304\n",
            "SCOPE mean: 0.6487833657063111, SCOPE var: 0.3291885145442196\n",
            "Total Loss: 0.005205712881961638\n",
            "----------------------------------------\n",
            "Epoch 307\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0052, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.963242313852167\n",
            "SCOPE mean: 0.6485304971335145, SCOPE var: 0.32908326048558006\n",
            "Total Loss: 0.005195920741630189\n",
            "----------------------------------------\n",
            "Epoch 308\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0052, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.954933274819997\n",
            "SCOPE mean: 0.6482745945102606, SCOPE var: 0.3289768824835022\n",
            "Total Loss: 0.005186445377386514\n",
            "----------------------------------------\n",
            "Epoch 309\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0052, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.946554159312765\n",
            "SCOPE mean: 0.6480171015403873, SCOPE var: 0.3288692078786038\n",
            "Total Loss: 0.005177006575757047\n",
            "----------------------------------------\n",
            "Epoch 310\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0052, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.938083748303026\n",
            "SCOPE mean: 0.6477575370442444, SCOPE var: 0.3287605802398288\n",
            "Total Loss: 0.005167663812858912\n",
            "----------------------------------------\n",
            "Epoch 311\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0052, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.929549217738206\n",
            "SCOPE mean: 0.6474964008422529, SCOPE var: 0.3286514069086537\n",
            "Total Loss: 0.005158396521405529\n",
            "----------------------------------------\n",
            "Epoch 312\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0051, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.92100993404042\n",
            "SCOPE mean: 0.6472325527112831, SCOPE var: 0.32854123843887745\n",
            "Total Loss: 0.005149255318434787\n",
            "----------------------------------------\n",
            "Epoch 313\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0051, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.912683972131095\n",
            "SCOPE mean: 0.6469700697791825, SCOPE var: 0.3284310020987272\n",
            "Total Loss: 0.005140167778020827\n",
            "----------------------------------------\n",
            "Epoch 314\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0051, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.90445240239876\n",
            "SCOPE mean: 0.6467120139592651, SCOPE var: 0.32832214564940165\n",
            "Total Loss: 0.005131206179832022\n",
            "----------------------------------------\n",
            "Epoch 315\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0051, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.89629639711269\n",
            "SCOPE mean: 0.6464596095511829, SCOPE var: 0.3282149663197436\n",
            "Total Loss: 0.005122410811159412\n",
            "----------------------------------------\n",
            "Epoch 316\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0051, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.888066239115364\n",
            "SCOPE mean: 0.646210178792047, SCOPE var: 0.32810932809443427\n",
            "Total Loss: 0.0051137069032953075\n",
            "----------------------------------------\n",
            "Epoch 317\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0051, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.879774001973423\n",
            "SCOPE mean: 0.6459641282207065, SCOPE var: 0.3280054246501751\n",
            "Total Loss: 0.005105075730535069\n",
            "----------------------------------------\n",
            "Epoch 318\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0051, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.87141376906755\n",
            "SCOPE mean: 0.6457229857659816, SCOPE var: 0.3279031880184225\n",
            "Total Loss: 0.005096517342186554\n",
            "----------------------------------------\n",
            "Epoch 319\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0051, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.862986013047667\n",
            "SCOPE mean: 0.6454863890323779, SCOPE var: 0.32780282657680365\n",
            "Total Loss: 0.005087903149380547\n",
            "----------------------------------------\n",
            "Epoch 320\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0051, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.85427663351232\n",
            "SCOPE mean: 0.6452474176371564, SCOPE var: 0.3277042881955718\n",
            "Total Loss: 0.005078369193672724\n",
            "----------------------------------------\n",
            "Epoch 321\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0051, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.845375041387943\n",
            "SCOPE mean: 0.6450065368103991, SCOPE var: 0.3276073726019121\n",
            "Total Loss: 0.005069049045962822\n",
            "----------------------------------------\n",
            "Epoch 322\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0051, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.836381823712813\n",
            "SCOPE mean: 0.6447768915416731, SCOPE var: 0.3275117309632943\n",
            "Total Loss: 0.005060849453836542\n",
            "----------------------------------------\n",
            "Epoch 323\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0051, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.82757192315558\n",
            "SCOPE mean: 0.6445631040839658, SCOPE var: 0.32741842066326127\n",
            "Total Loss: 0.00505429537628749\n",
            "----------------------------------------\n",
            "Epoch 324\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0050, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.819042994885574\n",
            "SCOPE mean: 0.6443614167426785, SCOPE var: 0.3273261623262362\n",
            "Total Loss: 0.005047790160314769\n",
            "----------------------------------------\n",
            "Epoch 325\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0050, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.810812774905994\n",
            "SCOPE mean: 0.6441720599122166, SCOPE var: 0.3272348169389368\n",
            "Total Loss: 0.005041177782937739\n",
            "----------------------------------------\n",
            "Epoch 326\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0050, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.80294487670129\n",
            "SCOPE mean: 0.6439988821160482, SCOPE var: 0.3271455528732004\n",
            "Total Loss: 0.0050344344864327265\n",
            "----------------------------------------\n",
            "Epoch 327\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0050, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.795268354111546\n",
            "SCOPE mean: 0.6438373001209758, SCOPE var: 0.32705758775231447\n",
            "Total Loss: 0.005027858214314662\n",
            "----------------------------------------\n",
            "Epoch 328\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0050, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.787749137234997\n",
            "SCOPE mean: 0.6436854285006325, SCOPE var: 0.3269705312899104\n",
            "Total Loss: 0.005021432554445055\n",
            "----------------------------------------\n",
            "Epoch 329\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0050, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.780386847547394\n",
            "SCOPE mean: 0.6435419121072972, SCOPE var: 0.3268839664058655\n",
            "Total Loss: 0.005014922119126657\n",
            "----------------------------------------\n",
            "Epoch 330\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0050, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.773174932305057\n",
            "SCOPE mean: 0.6434054730172571, SCOPE var: 0.32679748627659916\n",
            "Total Loss: 0.005008339073312589\n",
            "----------------------------------------\n",
            "Epoch 331\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0050, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.766106285777138\n",
            "SCOPE mean: 0.6432749174126128, SCOPE var: 0.3267107020804898\n",
            "Total Loss: 0.005001694168006002\n",
            "----------------------------------------\n",
            "Epoch 332\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0050, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.759175873416687\n",
            "SCOPE mean: 0.6431491409493514, SCOPE var: 0.3266232495763098\n",
            "Total Loss: 0.00499499674431182\n",
            "----------------------------------------\n",
            "Epoch 333\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0050, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.75237890677371\n",
            "SCOPE mean: 0.6430271327864673, SCOPE var: 0.3265347945165963\n",
            "Total Loss: 0.004988254797691087\n",
            "----------------------------------------\n",
            "Epoch 334\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0050, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.74570711196633\n",
            "SCOPE mean: 0.6429079780900993, SCOPE var: 0.3264450369168839\n",
            "Total Loss: 0.004981475049726254\n",
            "----------------------------------------\n",
            "Epoch 335\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0050, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.739159729551492\n",
            "SCOPE mean: 0.6427893814000711, SCOPE var: 0.3263513574040828\n",
            "Total Loss: 0.004974666772028901\n",
            "----------------------------------------\n",
            "Epoch 336\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0050, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.732839984987994\n",
            "SCOPE mean: 0.6426644421494047, SCOPE var: 0.3262397307866975\n",
            "Total Loss: 0.004968676198705431\n",
            "----------------------------------------\n",
            "Epoch 337\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0050, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.726323201892622\n",
            "SCOPE mean: 0.6425281881838402, SCOPE var: 0.3261257667348662\n",
            "Total Loss: 0.004962945376001356\n",
            "----------------------------------------\n",
            "Epoch 338\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0050, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.719648493974894\n",
            "SCOPE mean: 0.642381337707578, SCOPE var: 0.32600940819951457\n",
            "Total Loss: 0.00495714175474478\n",
            "----------------------------------------\n",
            "Epoch 339\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0050, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.71281838699635\n",
            "SCOPE mean: 0.6422246573464492, SCOPE var: 0.3258906738170013\n",
            "Total Loss: 0.0049512811009878145\n",
            "----------------------------------------\n",
            "Epoch 340\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0049, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.70606850415486\n",
            "SCOPE mean: 0.6420591845313868, SCOPE var: 0.3257687364715745\n",
            "Total Loss: 0.004945324051200721\n",
            "----------------------------------------\n",
            "Epoch 341\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0049, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.69938844745516\n",
            "SCOPE mean: 0.6418856947942237, SCOPE var: 0.32564380227743944\n",
            "Total Loss: 0.004939360957067004\n",
            "----------------------------------------\n",
            "Epoch 342\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0049, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.692583681150563\n",
            "SCOPE mean: 0.6417046391565792, SCOPE var: 0.32551695034276706\n",
            "Total Loss: 0.004933357483069395\n",
            "----------------------------------------\n",
            "Epoch 343\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0049, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.685669872655485\n",
            "SCOPE mean: 0.6415168210539648, SCOPE var: 0.3253883492049559\n",
            "Total Loss: 0.00492731124005278\n",
            "----------------------------------------\n",
            "Epoch 344\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0049, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.678660016852383\n",
            "SCOPE mean: 0.6413230543960275, SCOPE var: 0.3252582037138028\n",
            "Total Loss: 0.004921230113608511\n",
            "----------------------------------------\n",
            "Epoch 345\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0049, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.671552216817258\n",
            "SCOPE mean: 0.6411241523894264, SCOPE var: 0.3251267451844465\n",
            "Total Loss: 0.004915154818369665\n",
            "----------------------------------------\n",
            "Epoch 346\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0049, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.664390841089887\n",
            "SCOPE mean: 0.6409196933120936, SCOPE var: 0.3249930192269161\n",
            "Total Loss: 0.004909159066183946\n",
            "----------------------------------------\n",
            "Epoch 347\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0049, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.65721801206683\n",
            "SCOPE mean: 0.640712776344201, SCOPE var: 0.3248570711276342\n",
            "Total Loss: 0.004903150911853497\n",
            "----------------------------------------\n",
            "Epoch 348\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0049, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.650036147094262\n",
            "SCOPE mean: 0.6405016208355031, SCOPE var: 0.32471968441203586\n",
            "Total Loss: 0.004897153263947427\n",
            "----------------------------------------\n",
            "Epoch 349\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0049, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.64279305608638\n",
            "SCOPE mean: 0.6402905644970328, SCOPE var: 0.32458240369979585\n",
            "Total Loss: 0.0048911531759202945\n",
            "----------------------------------------\n",
            "Epoch 350\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0049, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.63546360209666\n",
            "SCOPE mean: 0.6400791962145463, SCOPE var: 0.3244454277837547\n",
            "Total Loss: 0.004885853519332756\n",
            "----------------------------------------\n",
            "Epoch 351\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0049, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.628521323675272\n",
            "SCOPE mean: 0.6398809273364657, SCOPE var: 0.3243098534457543\n",
            "Total Loss: 0.004880467760761422\n",
            "----------------------------------------\n",
            "Epoch 352\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0049, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.621933364802356\n",
            "SCOPE mean: 0.6396947560720936, SCOPE var: 0.3241756870743443\n",
            "Total Loss: 0.004874869719834649\n",
            "----------------------------------------\n",
            "Epoch 353\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0049, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.615651864932254\n",
            "SCOPE mean: 0.6395197088831496, SCOPE var: 0.3240428759416389\n",
            "Total Loss: 0.00486921031837431\n",
            "----------------------------------------\n",
            "Epoch 354\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0049, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.609516350890537\n",
            "SCOPE mean: 0.6393519641965976, SCOPE var: 0.3239109688770624\n",
            "Total Loss: 0.00486342978941984\n",
            "----------------------------------------\n",
            "Epoch 355\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0049, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.603514954501307\n",
            "SCOPE mean: 0.6391908223531986, SCOPE var: 0.3237798507592097\n",
            "Total Loss: 0.004857537537238259\n",
            "----------------------------------------\n",
            "Epoch 356\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0049, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.597631224685525\n",
            "SCOPE mean: 0.6390355974083776, SCOPE var: 0.3236493873887497\n",
            "Total Loss: 0.004851684193486704\n",
            "----------------------------------------\n",
            "Epoch 357\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0048, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.591553493445538\n",
            "SCOPE mean: 0.6388754026468647, SCOPE var: 0.32351884225107314\n",
            "Total Loss: 0.004846258150343311\n",
            "----------------------------------------\n",
            "Epoch 358\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0048, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.58532044973065\n",
            "SCOPE mean: 0.6387106921065765, SCOPE var: 0.32338816485437616\n",
            "Total Loss: 0.004840796332497653\n",
            "----------------------------------------\n",
            "Epoch 359\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0048, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.57900590832748\n",
            "SCOPE mean: 0.638539253162039, SCOPE var: 0.3232561119846858\n",
            "Total Loss: 0.004835290719646916\n",
            "----------------------------------------\n",
            "Epoch 360\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0048, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.572617095408997\n",
            "SCOPE mean: 0.6383617916360941, SCOPE var: 0.3231228053903258\n",
            "Total Loss: 0.0048297408107908476\n",
            "----------------------------------------\n",
            "Epoch 361\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0048, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.566164616194175\n",
            "SCOPE mean: 0.6381789790616056, SCOPE var: 0.322988374322119\n",
            "Total Loss: 0.0048241527521760905\n",
            "----------------------------------------\n",
            "Epoch 362\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0048, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.559658058358412\n",
            "SCOPE mean: 0.637991451185613, SCOPE var: 0.3228529518663041\n",
            "Total Loss: 0.0048185352832193305\n",
            "----------------------------------------\n",
            "Epoch 363\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0048, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.553049343685757\n",
            "SCOPE mean: 0.637802487643559, SCOPE var: 0.32271790014742757\n",
            "Total Loss: 0.004812907733505524\n",
            "----------------------------------------\n",
            "Epoch 364\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0048, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.546344976289433\n",
            "SCOPE mean: 0.6376123855948641, SCOPE var: 0.32258322980715093\n",
            "Total Loss: 0.004807375411263529\n",
            "----------------------------------------\n",
            "Epoch 365\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0048, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.53984097641734\n",
            "SCOPE mean: 0.6374316482855727, SCOPE var: 0.3224495481453917\n",
            "Total Loss: 0.004801982824097487\n",
            "----------------------------------------\n",
            "Epoch 366\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0048, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.53353815744287\n",
            "SCOPE mean: 0.6372588397934332, SCOPE var: 0.322316471662468\n",
            "Total Loss: 0.00479647741140748\n",
            "----------------------------------------\n",
            "Epoch 367\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0048, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.527469097068902\n",
            "SCOPE mean: 0.637090499867429, SCOPE var: 0.32218267623401825\n",
            "Total Loss: 0.004790929435209095\n",
            "----------------------------------------\n",
            "Epoch 368\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0048, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.521264240649614\n",
            "SCOPE mean: 0.6369186196440535, SCOPE var: 0.3220488129172979\n",
            "Total Loss: 0.004785512151262702\n",
            "----------------------------------------\n",
            "Epoch 369\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0048, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.5149465344292\n",
            "SCOPE mean: 0.636740907367659, SCOPE var: 0.3219120837435231\n",
            "Total Loss: 0.004780047773331335\n",
            "----------------------------------------\n",
            "Epoch 370\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0048, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.50858574432549\n",
            "SCOPE mean: 0.6365575260513174, SCOPE var: 0.3217738929173853\n",
            "Total Loss: 0.004774565128641201\n",
            "----------------------------------------\n",
            "Epoch 371\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0048, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.502181151134216\n",
            "SCOPE mean: 0.6363697768484388, SCOPE var: 0.32163476117169604\n",
            "Total Loss: 0.004769074957366714\n",
            "----------------------------------------\n",
            "Epoch 372\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0048, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.495672312253767\n",
            "SCOPE mean: 0.6361808898269287, SCOPE var: 0.3214960410775615\n",
            "Total Loss: 0.0047638019648350806\n",
            "----------------------------------------\n",
            "Epoch 373\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0048, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.489372537500767\n",
            "SCOPE mean: 0.6360012720848105, SCOPE var: 0.32135827780703574\n",
            "Total Loss: 0.004758397198233835\n",
            "----------------------------------------\n",
            "Epoch 374\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0048, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.483260689419932\n",
            "SCOPE mean: 0.6358300177016853, SCOPE var: 0.3212213405427074\n",
            "Total Loss: 0.004752844156839356\n",
            "----------------------------------------\n",
            "Epoch 375\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0047, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.477299051546144\n",
            "SCOPE mean: 0.6356662602327761, SCOPE var: 0.32108510501324\n",
            "Total Loss: 0.004747473113074674\n",
            "----------------------------------------\n",
            "Epoch 376\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0047, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.471263779088126\n",
            "SCOPE mean: 0.6354961812203365, SCOPE var: 0.32094754588044805\n",
            "Total Loss: 0.004742146412502509\n",
            "----------------------------------------\n",
            "Epoch 377\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0047, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.46511091361691\n",
            "SCOPE mean: 0.6353230686283848, SCOPE var: 0.32080997176236487\n",
            "Total Loss: 0.004736785713078644\n",
            "----------------------------------------\n",
            "Epoch 378\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0047, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.459048112064867\n",
            "SCOPE mean: 0.6351472174244802, SCOPE var: 0.3206713557415468\n",
            "Total Loss: 0.004731384706574997\n",
            "----------------------------------------\n",
            "Epoch 379\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0047, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.452875723088173\n",
            "SCOPE mean: 0.6349687866355401, SCOPE var: 0.32053268365225185\n",
            "Total Loss: 0.00472595651790833\n",
            "----------------------------------------\n",
            "Epoch 380\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0047, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.446585635059595\n",
            "SCOPE mean: 0.634787999672885, SCOPE var: 0.3203939033253104\n",
            "Total Loss: 0.0047204107917387175\n",
            "----------------------------------------\n",
            "Epoch 381\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0047, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.440198121993166\n",
            "SCOPE mean: 0.6346003569976963, SCOPE var: 0.32025085188394087\n",
            "Total Loss: 0.004714678701826496\n",
            "----------------------------------------\n",
            "Epoch 382\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0047, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.433744108776462\n",
            "SCOPE mean: 0.6344062240666137, SCOPE var: 0.3201037344109023\n",
            "Total Loss: 0.00470916423296255\n",
            "----------------------------------------\n",
            "Epoch 383\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0047, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.42747042825993\n",
            "SCOPE mean: 0.6342188882667267, SCOPE var: 0.3199545792495425\n",
            "Total Loss: 0.004703519184837304\n",
            "----------------------------------------\n",
            "Epoch 384\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0047, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.42132426590716\n",
            "SCOPE mean: 0.6340344933535116, SCOPE var: 0.3198028543322122\n",
            "Total Loss: 0.004697730173775282\n",
            "----------------------------------------\n",
            "Epoch 385\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0047, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.41530325701421\n",
            "SCOPE mean: 0.6338522677372076, SCOPE var: 0.31964850587686616\n",
            "Total Loss: 0.004691836789763888\n",
            "----------------------------------------\n",
            "Epoch 386\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0047, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.409376215272687\n",
            "SCOPE mean: 0.6336709362595901, SCOPE var: 0.3194914366894513\n",
            "Total Loss: 0.004686136365165784\n",
            "----------------------------------------\n",
            "Epoch 387\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0047, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.40324256950928\n",
            "SCOPE mean: 0.6334802912670832, SCOPE var: 0.319331305752249\n",
            "Total Loss: 0.004680387364960508\n",
            "----------------------------------------\n",
            "Epoch 388\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0047, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.39693397461056\n",
            "SCOPE mean: 0.6332807825359426, SCOPE var: 0.31916811549730423\n",
            "Total Loss: 0.004674514272180417\n",
            "----------------------------------------\n",
            "Epoch 389\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0047, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.39053104655745\n",
            "SCOPE mean: 0.6330701103334447, SCOPE var: 0.31900062794090395\n",
            "Total Loss: 0.004668544636187684\n",
            "----------------------------------------\n",
            "Epoch 390\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0047, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.384340700817802\n",
            "SCOPE mean: 0.6328592633002058, SCOPE var: 0.31882963313733287\n",
            "Total Loss: 0.004662734368088294\n",
            "----------------------------------------\n",
            "Epoch 391\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0047, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.37835516208684\n",
            "SCOPE mean: 0.6326479365998443, SCOPE var: 0.318655257045808\n",
            "Total Loss: 0.0046568453166217615\n",
            "----------------------------------------\n",
            "Epoch 392\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0047, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.372501119543283\n",
            "SCOPE mean: 0.6324386533556091, SCOPE var: 0.3184789036252407\n",
            "Total Loss: 0.004650998417383049\n",
            "----------------------------------------\n",
            "Epoch 393\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.36646925030949\n",
            "SCOPE mean: 0.6322207056893593, SCOPE var: 0.31829997511736957\n",
            "Total Loss: 0.004645115314272514\n",
            "----------------------------------------\n",
            "Epoch 394\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.360425270467008\n",
            "SCOPE mean: 0.6319946569952166, SCOPE var: 0.3181170093385027\n",
            "Total Loss: 0.004639225349457006\n",
            "----------------------------------------\n",
            "Epoch 395\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.35453244861747\n",
            "SCOPE mean: 0.6317709003685662, SCOPE var: 0.31793209195249045\n",
            "Total Loss: 0.004633341112557759\n",
            "----------------------------------------\n",
            "Epoch 396\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.348783882849503\n",
            "SCOPE mean: 0.6315492448024289, SCOPE var: 0.3177454140637339\n",
            "Total Loss: 0.004627386842124611\n",
            "----------------------------------------\n",
            "Epoch 397\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.34317175550722\n",
            "SCOPE mean: 0.6313286771132944, SCOPE var: 0.31755670785335777\n",
            "Total Loss: 0.004621477132617906\n",
            "----------------------------------------\n",
            "Epoch 398\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.33743543843902\n",
            "SCOPE mean: 0.6310965843700693, SCOPE var: 0.31736450132880417\n",
            "Total Loss: 0.004615554430371182\n",
            "----------------------------------------\n",
            "Epoch 399\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.33159878226928\n",
            "SCOPE mean: 0.6308537145763132, SCOPE var: 0.3171687561940642\n",
            "Total Loss: 0.0046095748828208286\n",
            "----------------------------------------\n",
            "Epoch 400\n",
            "IS mean: 0.9031099370141558,IS variance: 0.3119340165290428\n",
            "SCOPE Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  21.32590586250705\n",
            "SCOPE mean: 0.6306148158271786, SCOPE var: 0.3169720264472136\n",
            "Total Loss: 0.004603640222688189\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[ 0.4044, -0.1406],\n",
            "        [ 0.6843, -0.4732],\n",
            "        [ 0.1716, -0.5760],\n",
            "        [-0.6795, -0.5101],\n",
            "        [ 0.3902, -0.6433],\n",
            "        [ 0.0975, -0.4655],\n",
            "        [-0.1953,  0.0411],\n",
            "        [ 0.2749, -0.4131],\n",
            "        [-0.0517, -0.1990],\n",
            "        [ 0.1154,  0.1311]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([ 0.2676, -0.2684, -0.1865, -0.2926, -0.2015, -0.5063, -0.3068, -0.5262,\n",
            "         0.2177,  0.0498], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[-0.1411,  0.1181, -0.5188, -0.2989, -0.0051, -0.2171,  0.1404,  0.0649,\n",
            "          0.1433, -0.1265],\n",
            "        [ 0.2554,  0.1563, -0.2213,  0.0075, -0.1853,  0.0673,  0.2423,  0.0040,\n",
            "         -0.1577, -0.1969],\n",
            "        [ 0.1621,  0.1377,  0.1878, -0.0139,  0.1179,  0.3213, -0.0040,  0.2525,\n",
            "         -0.1996, -0.2490],\n",
            "        [-0.1556, -0.2771, -0.2832,  0.2888,  0.2728, -0.2357, -0.1273, -0.2418,\n",
            "         -0.1808, -0.0133],\n",
            "        [ 0.1641,  0.2198, -0.0233,  0.1422,  0.2506, -0.2751,  0.1453,  0.3564,\n",
            "         -0.3154, -0.2294],\n",
            "        [-0.0390,  0.1875, -0.1826,  0.2520,  0.1828, -0.0862,  0.1541,  0.0972,\n",
            "          0.0030, -0.0712],\n",
            "        [-0.1335,  0.2905, -0.1214, -0.2435, -0.0995, -0.2270, -0.0573,  0.1635,\n",
            "         -0.2587,  0.2614],\n",
            "        [-0.3080,  0.0484, -0.0295,  0.0731,  0.0780,  0.3058,  0.0985, -0.2337,\n",
            "         -0.0967,  0.2152],\n",
            "        [-0.0670, -0.1141, -0.1777, -0.1116,  0.2266, -0.0367,  0.1967, -0.2928,\n",
            "          0.2731,  0.1744],\n",
            "        [-0.0107, -0.3209, -0.4862, -0.1177,  0.2425, -0.0834, -0.2668, -0.0981,\n",
            "          0.2267,  0.0343]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([ 0.1653, -0.1265, -0.1192, -0.2364,  0.3220,  0.1330,  0.1647, -0.3468,\n",
            "        -0.0921, -0.0201], dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[ 0.0941, -0.2700, -0.1490, -0.1362, -0.2082,  0.2736, -0.1609, -0.2483,\n",
            "          0.2172,  0.2921]], dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([-0.1965], dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NN_l1_l2_reg(\n",
              "  (hidden_layers): ModuleList(\n",
              "    (0): Linear(in_features=2, out_features=10, bias=True)\n",
              "    (1): Linear(in_features=10, out_features=10, bias=True)\n",
              "  )\n",
              "  (output_layer): Linear(in_features=10, out_features=1, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# P_pi_b_600 = action_probs_top_n_epsilon(q_table, 1, 0.4)\n",
        "# pi_b_600 = experiment_actions(600, env_100, P_pi_b_600)\n",
        "# P_pi_e_600 = action_probs_top_n_epsilon(q_table, 1, 0.05)\n",
        "# pi_e_600 = experiment_actions(1000, env_100, P_pi_e_600)\n",
        "# # model_600_random_pi_b_600_env_100 = CustomizableFeatureNet(input_dim=2, hidden_dims=[8, 8], output_dim=1, dtype = torch.float64, l2_lambda=0.002)\n",
        "# # model_600_random_pi_b_600_env_100 = NN_l1_reg(input_dim=2, hidden_dims=[16, 16], output_dim=1, dtype = torch.float64, l1_lambda=0.001)\n",
        "# model_600_random_pi_b_600_env_100 = NN_l1_l2_reg(input_dim=2, hidden_dims=[16, 16], output_dim=1, dtype = torch.float64, l1_lambda=0.0001, l2_lambda = 0.0001)\n",
        "# test_600_random_pi_b_600_env_100 = SCOPE_straight(model_600_random_pi_b_600_env_100, 0.99, 10000, pi_b_600, P_pi_b_600, P_pi_e_600, 0.3, dtype = torch.float64)\n",
        "test_600_random_pi_b_600_env_100.train_var_scope(50, 0.001, 1, 0.15)"
      ],
      "metadata": {
        "id": "d1rJ3YLH41u7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# P_pi_b_800 = action_probs_top_n_epsilon(q_table, 1, 0.4)\n",
        "# pi_b_800 = experiment_actions(800, env_100, P_pi_b_800)\n",
        "# P_pi_e_800 = action_probs_top_n_epsilon(q_table, 1, 0.05)\n",
        "# pi_e_800 = experiment_actions(1000, env_100, P_pi_e_800)\n",
        "# # model_800_random_pi_b_800_env_100 = CustomizableFeatureNet(input_dim=2, hidden_dims=[10, 10], output_dim=1, dtype = torch.float64, l2_lambda=0.002)\n",
        "# # model_800_random_pi_b_800_env_100 = NN_l1_reg(input_dim=2, hidden_dims=[10, 10], output_dim=1, dtype = torch.float64, l1_lambda=0.0001)\n",
        "# model_800_random_pi_b_800_env_100 = NN_l1_l2_reg(input_dim=2, hidden_dims=[16, 16], output_dim=1, dtype = torch.float64, l1_lambda=0.0001, l2_lambda = 0.0001)\n",
        "# test_800_random_pi_b_800_env_100 = SCOPE_straight(model_800_random_pi_b_800_env_100, 0.99, 10000, pi_b_800, P_pi_b_800, P_pi_e_800, 0.3, dtype = torch.float64)\n",
        "test_800_random_pi_b_800_env_100.train_var_scope(100, 0.001, 1, 0.3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f80f8cff-7410-4d7c-cc29-e89727b59a59",
        "id": "YJSuYyd-41u8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.3102, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7104331187633571\n",
            "SCOPE mean: 0.25145097682447576, SCOPE var: 0.005720949296649719\n",
            "Total Loss: 0.523304287323519\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0144, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.693729122102974\n",
            "SCOPE mean: 0.23986316648905373, SCOPE var: 0.005580951116453046\n",
            "Total Loss: 0.22250727909176887\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0145, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6932282166881837\n",
            "SCOPE mean: 0.23705876587684002, SCOPE var: 0.00552501777462655\n",
            "Total Loss: 0.22251044319185878\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0145, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6887074958954114\n",
            "SCOPE mean: 0.23796857799129706, SCOPE var: 0.005507052994177353\n",
            "Total Loss: 0.2211328385025181\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0144, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6842108043016356\n",
            "SCOPE mean: 0.24065408652697415, SCOPE var: 0.005508719792473398\n",
            "Total Loss: 0.21968857822369828\n",
            "----------------------------------------\n",
            "Epoch 6\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0143, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6811166953324801\n",
            "SCOPE mean: 0.24422038908022758, SCOPE var: 0.005523551725135856\n",
            "Total Loss: 0.21861829364539484\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0141, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6789876446531197\n",
            "SCOPE mean: 0.2476178276384649, SCOPE var: 0.0055428255571256845\n",
            "Total Loss: 0.21776774326177817\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0139, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6765102412566608\n",
            "SCOPE mean: 0.2501578923732427, SCOPE var: 0.005559367334951603\n",
            "Total Loss: 0.2168187319551308\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0137, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6730238522985511\n",
            "SCOPE mean: 0.2515793838593339, SCOPE var: 0.005570657987813805\n",
            "Total Loss: 0.2155761066931891\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0135, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6688703336349804\n",
            "SCOPE mean: 0.25198416597827844, SCOPE var: 0.005576151816387805\n",
            "Total Loss: 0.21415322866771325\n",
            "----------------------------------------\n",
            "Epoch 11\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0134, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6647598205775904\n",
            "SCOPE mean: 0.25165124365524794, SCOPE var: 0.0055764776116611495\n",
            "Total Loss: 0.21279585358339914\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0133, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6610917856325393\n",
            "SCOPE mean: 0.2508505492318361, SCOPE var: 0.005574175877254066\n",
            "Total Loss: 0.21159934006904396\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0132, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6577160344896407\n",
            "SCOPE mean: 0.24984790236607224, SCOPE var: 0.00557049588249194\n",
            "Total Loss: 0.21048795628572983\n",
            "----------------------------------------\n",
            "Epoch 14\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0131, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6542030551963282\n",
            "SCOPE mean: 0.24885592468086415, SCOPE var: 0.00556653236485866\n",
            "Total Loss: 0.20932699952617315\n",
            "----------------------------------------\n",
            "Epoch 15\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0129, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.650271646875039\n",
            "SCOPE mean: 0.24803554948893197, SCOPE var: 0.0055636498935776124\n",
            "Total Loss: 0.2080305887168211\n",
            "----------------------------------------\n",
            "Epoch 16\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0128, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6459850973694259\n",
            "SCOPE mean: 0.24748111546610388, SCOPE var: 0.005563097654367079\n",
            "Total Loss: 0.20661785665469212\n",
            "----------------------------------------\n",
            "Epoch 17\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0127, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6415955885161355\n",
            "SCOPE mean: 0.24706339057976426, SCOPE var: 0.005563375408741923\n",
            "Total Loss: 0.20519406082941416\n",
            "----------------------------------------\n",
            "Epoch 18\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0126, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6373571681410314\n",
            "SCOPE mean: 0.24676448728781739, SCOPE var: 0.005562897185509958\n",
            "Total Loss: 0.203838530501992\n",
            "----------------------------------------\n",
            "Epoch 19\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0126, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.633272359548113\n",
            "SCOPE mean: 0.24644983528129874, SCOPE var: 0.005560751943267244\n",
            "Total Loss: 0.2025471198154924\n",
            "----------------------------------------\n",
            "Epoch 20\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0125, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.629175953234225\n",
            "SCOPE mean: 0.24601738876554674, SCOPE var: 0.005556360339468168\n",
            "Total Loss: 0.20126472394797593\n",
            "----------------------------------------\n",
            "Epoch 21\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0125, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6249451385363144\n",
            "SCOPE mean: 0.24541795197059132, SCOPE var: 0.005549888045962026\n",
            "Total Loss: 0.1999536996758299\n",
            "----------------------------------------\n",
            "Epoch 22\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0125, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6205561278677382\n",
            "SCOPE mean: 0.2446626498283077, SCOPE var: 0.005541974824188512\n",
            "Total Loss: 0.19861978644074121\n",
            "----------------------------------------\n",
            "Epoch 23\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0124, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6161138670400322\n",
            "SCOPE mean: 0.24383980175662218, SCOPE var: 0.005532917826443797\n",
            "Total Loss: 0.1972574269073765\n",
            "----------------------------------------\n",
            "Epoch 24\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0124, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6117425158897173\n",
            "SCOPE mean: 0.24304455397684868, SCOPE var: 0.005524136267694176\n",
            "Total Loss: 0.19591119178456565\n",
            "----------------------------------------\n",
            "Epoch 25\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0124, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6075405704033342\n",
            "SCOPE mean: 0.24252576590054287, SCOPE var: 0.00552025658417746\n",
            "Total Loss: 0.1946143928380741\n",
            "----------------------------------------\n",
            "Epoch 26\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0123, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6034064992260717\n",
            "SCOPE mean: 0.24232157098620463, SCOPE var: 0.005518850664015888\n",
            "Total Loss: 0.19332817715710107\n",
            "----------------------------------------\n",
            "Epoch 27\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0122, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5992457988127662\n",
            "SCOPE mean: 0.24247440305809823, SCOPE var: 0.005519969447100757\n",
            "Total Loss: 0.1920207294359887\n",
            "----------------------------------------\n",
            "Epoch 28\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0122, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5950426638646614\n",
            "SCOPE mean: 0.24295008357201223, SCOPE var: 0.005523424811211879\n",
            "Total Loss: 0.19068949650277064\n",
            "----------------------------------------\n",
            "Epoch 29\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0121, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5908418349054052\n",
            "SCOPE mean: 0.24365303776370315, SCOPE var: 0.00552853333932132\n",
            "Total Loss: 0.189352911012736\n",
            "----------------------------------------\n",
            "Epoch 30\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0120, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5867451194549876\n",
            "SCOPE mean: 0.24443160478157402, SCOPE var: 0.00553414756552094\n",
            "Total Loss: 0.18804397758571414\n",
            "----------------------------------------\n",
            "Epoch 31\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0119, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5828576212927509\n",
            "SCOPE mean: 0.24508073371567374, SCOPE var: 0.005539028689168256\n",
            "Total Loss: 0.1867956824501709\n",
            "----------------------------------------\n",
            "Epoch 32\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0119, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5790464467646995\n",
            "SCOPE mean: 0.245405675123357, SCOPE var: 0.005542112494092447\n",
            "Total Loss: 0.18556784428015222\n",
            "----------------------------------------\n",
            "Epoch 33\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0118, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5752025337926099\n",
            "SCOPE mean: 0.24534628598451627, SCOPE var: 0.005543356468824604\n",
            "Total Loss: 0.18433117861227072\n",
            "----------------------------------------\n",
            "Epoch 34\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0117, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5713277232276116\n",
            "SCOPE mean: 0.24493491788620658, SCOPE var: 0.005542939013248117\n",
            "Total Loss: 0.1830892194602026\n",
            "----------------------------------------\n",
            "Epoch 35\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0116, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5673102841240208\n",
            "SCOPE mean: 0.24414741610107113, SCOPE var: 0.0055408698772494045\n",
            "Total Loss: 0.1818073199925818\n",
            "----------------------------------------\n",
            "Epoch 36\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0115, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5633396081039777\n",
            "SCOPE mean: 0.24320219242587318, SCOPE var: 0.005538590743148241\n",
            "Total Loss: 0.18054436993403147\n",
            "----------------------------------------\n",
            "Epoch 37\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0115, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5594143233807659\n",
            "SCOPE mean: 0.24214030163573924, SCOPE var: 0.005536013013391272\n",
            "Total Loss: 0.17930005406781846\n",
            "----------------------------------------\n",
            "Epoch 38\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0114, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5555076865892701\n",
            "SCOPE mean: 0.24110595726705888, SCOPE var: 0.005534549944873148\n",
            "Total Loss: 0.1780650975042761\n",
            "----------------------------------------\n",
            "Epoch 39\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0114, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5516177980601562\n",
            "SCOPE mean: 0.24018739278814946, SCOPE var: 0.005534600228333932\n",
            "Total Loss: 0.17683749382552383\n",
            "----------------------------------------\n",
            "Epoch 40\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0113, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5477882327480299\n",
            "SCOPE mean: 0.23953284219616294, SCOPE var: 0.005537038254692305\n",
            "Total Loss: 0.17563292940223532\n",
            "----------------------------------------\n",
            "Epoch 41\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0112, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5440201500992857\n",
            "SCOPE mean: 0.23920343273966826, SCOPE var: 0.005542265098768074\n",
            "Total Loss: 0.17445037814492814\n",
            "----------------------------------------\n",
            "Epoch 42\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0112, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5403284866764555\n",
            "SCOPE mean: 0.23914827938783456, SCOPE var: 0.005549549145940133\n",
            "Total Loss: 0.17329469531283767\n",
            "----------------------------------------\n",
            "Epoch 43\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0112, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5366923242111893\n",
            "SCOPE mean: 0.2393039889709443, SCOPE var: 0.005557838003896935\n",
            "Total Loss: 0.17216359977927856\n",
            "----------------------------------------\n",
            "Epoch 44\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0111, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5331040068667394\n",
            "SCOPE mean: 0.23962130685439675, SCOPE var: 0.0055666859027523954\n",
            "Total Loss: 0.17104947631616507\n",
            "----------------------------------------\n",
            "Epoch 45\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0111, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5295625552344132\n",
            "SCOPE mean: 0.2400520047171164, SCOPE var: 0.005575625998656292\n",
            "Total Loss: 0.1699573643044612\n",
            "----------------------------------------\n",
            "Epoch 46\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0111, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.526089953319162\n",
            "SCOPE mean: 0.2405438382465697, SCOPE var: 0.005583946687176762\n",
            "Total Loss: 0.16888800638138424\n",
            "----------------------------------------\n",
            "Epoch 47\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0110, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5226896665398375\n",
            "SCOPE mean: 0.24107976456380115, SCOPE var: 0.0055913448808099404\n",
            "Total Loss: 0.16783786493509384\n",
            "----------------------------------------\n",
            "Epoch 48\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0110, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.519363284536216\n",
            "SCOPE mean: 0.24165806893964764, SCOPE var: 0.005597708157095057\n",
            "Total Loss: 0.1668084000931182\n",
            "----------------------------------------\n",
            "Epoch 49\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0110, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5161071456979733\n",
            "SCOPE mean: 0.24213840153235663, SCOPE var: 0.005601830333025662\n",
            "Total Loss: 0.1658022604465944\n",
            "----------------------------------------\n",
            "Epoch 50\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0109, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5128923106264632\n",
            "SCOPE mean: 0.24251332151106023, SCOPE var: 0.0056040813020543576\n",
            "Total Loss: 0.1648068145822701\n",
            "----------------------------------------\n",
            "Epoch 51\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0109, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5097209698519782\n",
            "SCOPE mean: 0.24277496914555005, SCOPE var: 0.005604661021605446\n",
            "Total Loss: 0.16382846383176206\n",
            "----------------------------------------\n",
            "Epoch 52\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0109, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5066053550975436\n",
            "SCOPE mean: 0.24305432329770638, SCOPE var: 0.005604369504289528\n",
            "Total Loss: 0.1628641176694225\n",
            "----------------------------------------\n",
            "Epoch 53\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0108, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5035449073598243\n",
            "SCOPE mean: 0.24331868633215917, SCOPE var: 0.005603221225816673\n",
            "Total Loss: 0.16191291815015638\n",
            "----------------------------------------\n",
            "Epoch 54\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0108, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5005407212411568\n",
            "SCOPE mean: 0.24354717861442987, SCOPE var: 0.005601358962913643\n",
            "Total Loss: 0.16097758801144782\n",
            "----------------------------------------\n",
            "Epoch 55\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0108, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.49758531111373805\n",
            "SCOPE mean: 0.2437400790198265, SCOPE var: 0.005598989023695822\n",
            "Total Loss: 0.16006049816630058\n",
            "----------------------------------------\n",
            "Epoch 56\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0108, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4946730811852663\n",
            "SCOPE mean: 0.2439538980912197, SCOPE var: 0.00559737617168784\n",
            "Total Loss: 0.15915780313884553\n",
            "----------------------------------------\n",
            "Epoch 57\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0107, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.49180555430010664\n",
            "SCOPE mean: 0.24420662543151953, SCOPE var: 0.0055966361063012155\n",
            "Total Loss: 0.1582669325827969\n",
            "----------------------------------------\n",
            "Epoch 58\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0107, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4889841423146699\n",
            "SCOPE mean: 0.24452078216508008, SCOPE var: 0.005596819765379819\n",
            "Total Loss: 0.15739024671879118\n",
            "----------------------------------------\n",
            "Epoch 59\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0107, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4861986946147827\n",
            "SCOPE mean: 0.2448949557611336, SCOPE var: 0.005598443355237653\n",
            "Total Loss: 0.1565234008603172\n",
            "----------------------------------------\n",
            "Epoch 60\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0106, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4834388963234516\n",
            "SCOPE mean: 0.24522466637920148, SCOPE var: 0.005600170852062741\n",
            "Total Loss: 0.15566669330591004\n",
            "----------------------------------------\n",
            "Epoch 61\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0106, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4807066493262273\n",
            "SCOPE mean: 0.24551375680147283, SCOPE var: 0.005602230311231036\n",
            "Total Loss: 0.1548193769310204\n",
            "----------------------------------------\n",
            "Epoch 62\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0106, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4780038885269917\n",
            "SCOPE mean: 0.24576833200372347, SCOPE var: 0.005604276763147289\n",
            "Total Loss: 0.15398539637546707\n",
            "----------------------------------------\n",
            "Epoch 63\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0106, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4753364592862418\n",
            "SCOPE mean: 0.24607005759948541, SCOPE var: 0.005606819074983562\n",
            "Total Loss: 0.15315870495191722\n",
            "----------------------------------------\n",
            "Epoch 64\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0105, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4727042848345955\n",
            "SCOPE mean: 0.24641819676815113, SCOPE var: 0.005609894085090539\n",
            "Total Loss: 0.15233752857717905\n",
            "----------------------------------------\n",
            "Epoch 65\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0105, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4701187468699119\n",
            "SCOPE mean: 0.24679107809806192, SCOPE var: 0.005613428082574717\n",
            "Total Loss: 0.15152583051922752\n",
            "----------------------------------------\n",
            "Epoch 66\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0105, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4675665819574585\n",
            "SCOPE mean: 0.2470959001064033, SCOPE var: 0.005616844538022439\n",
            "Total Loss: 0.1507227672470604\n",
            "----------------------------------------\n",
            "Epoch 67\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0104, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.46503843334011324\n",
            "SCOPE mean: 0.24733739755763054, SCOPE var: 0.005620069830690463\n",
            "Total Loss: 0.14992413848136274\n",
            "----------------------------------------\n",
            "Epoch 68\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0104, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4625318990158671\n",
            "SCOPE mean: 0.24751435803032842, SCOPE var: 0.005622922043614537\n",
            "Total Loss: 0.14913030664621188\n",
            "----------------------------------------\n",
            "Epoch 69\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0103, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4600441964911018\n",
            "SCOPE mean: 0.24763023227285766, SCOPE var: 0.005625253034881221\n",
            "Total Loss: 0.14834072609616752\n",
            "----------------------------------------\n",
            "Epoch 70\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0103, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4575549479406534\n",
            "SCOPE mean: 0.24764923376370826, SCOPE var: 0.005626930633269468\n",
            "Total Loss: 0.14754933596468056\n",
            "----------------------------------------\n",
            "Epoch 71\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0102, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4550927984131281\n",
            "SCOPE mean: 0.2477179447782414, SCOPE var: 0.005629298570141414\n",
            "Total Loss: 0.14676596567979253\n",
            "----------------------------------------\n",
            "Epoch 72\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0102, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.45264555424313324\n",
            "SCOPE mean: 0.24780354842514093, SCOPE var: 0.0056324734087050705\n",
            "Total Loss: 0.14598739163685673\n",
            "----------------------------------------\n",
            "Epoch 73\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0102, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4502227860437301\n",
            "SCOPE mean: 0.2479432080617593, SCOPE var: 0.005636308200106774\n",
            "Total Loss: 0.145220039698075\n",
            "----------------------------------------\n",
            "Epoch 74\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0101, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4478183691659561\n",
            "SCOPE mean: 0.24799808918622526, SCOPE var: 0.005639678177463293\n",
            "Total Loss: 0.1444581968013109\n",
            "----------------------------------------\n",
            "Epoch 75\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0101, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.44540778726563396\n",
            "SCOPE mean: 0.2479729019518787, SCOPE var: 0.0056423655145186845\n",
            "Total Loss: 0.14369507863621922\n",
            "----------------------------------------\n",
            "Epoch 76\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0100, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.442848525181445\n",
            "SCOPE mean: 0.24777797139242985, SCOPE var: 0.0056436868595521475\n",
            "Total Loss: 0.14288246385600817\n",
            "----------------------------------------\n",
            "Epoch 77\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0100, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.44027122037619065\n",
            "SCOPE mean: 0.2474234992846545, SCOPE var: 0.00564445680994976\n",
            "Total Loss: 0.14206431480712403\n",
            "----------------------------------------\n",
            "Epoch 78\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0099, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.437690602871324\n",
            "SCOPE mean: 0.24701998522789023, SCOPE var: 0.005645520255690854\n",
            "Total Loss: 0.141242809304511\n",
            "----------------------------------------\n",
            "Epoch 79\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0099, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4351196056041953\n",
            "SCOPE mean: 0.24659706638819257, SCOPE var: 0.005646927792332879\n",
            "Total Loss: 0.1404223986625306\n",
            "----------------------------------------\n",
            "Epoch 80\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0098, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.43256767500843574\n",
            "SCOPE mean: 0.24617953489240393, SCOPE var: 0.0056486850683452935\n",
            "Total Loss: 0.13960724364593946\n",
            "----------------------------------------\n",
            "Epoch 81\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0098, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.43003447695250363\n",
            "SCOPE mean: 0.24577137062886867, SCOPE var: 0.005651058735531666\n",
            "Total Loss: 0.13879947356933808\n",
            "----------------------------------------\n",
            "Epoch 82\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0097, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.42752041305331384\n",
            "SCOPE mean: 0.24545453627456362, SCOPE var: 0.005654263344758964\n",
            "Total Loss: 0.1379974883040983\n",
            "----------------------------------------\n",
            "Epoch 83\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0097, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4250298841190894\n",
            "SCOPE mean: 0.24523498056870313, SCOPE var: 0.005657943011945363\n",
            "Total Loss: 0.1372044432941276\n",
            "----------------------------------------\n",
            "Epoch 84\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0097, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.42257705728544614\n",
            "SCOPE mean: 0.24515066739657831, SCOPE var: 0.005662016719577998\n",
            "Total Loss: 0.1364357873790156\n",
            "----------------------------------------\n",
            "Epoch 85\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0096, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4201500105554756\n",
            "SCOPE mean: 0.2451518754027464, SCOPE var: 0.0056662706555339745\n",
            "Total Loss: 0.1356810242424698\n",
            "----------------------------------------\n",
            "Epoch 86\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0096, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4177411083417585\n",
            "SCOPE mean: 0.24523758310225058, SCOPE var: 0.005670081836756823\n",
            "Total Loss: 0.1349330358941898\n",
            "----------------------------------------\n",
            "Epoch 87\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0096, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4153561716126159\n",
            "SCOPE mean: 0.24541207041473517, SCOPE var: 0.005672984230553635\n",
            "Total Loss: 0.13419531293844159\n",
            "----------------------------------------\n",
            "Epoch 88\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0096, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4129764368754228\n",
            "SCOPE mean: 0.2456884637205983, SCOPE var: 0.005675253713955496\n",
            "Total Loss: 0.13346545554984693\n",
            "----------------------------------------\n",
            "Epoch 89\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0095, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.41061157335225246\n",
            "SCOPE mean: 0.2460088027804164, SCOPE var: 0.005676779407819003\n",
            "Total Loss: 0.13273082933756702\n",
            "----------------------------------------\n",
            "Epoch 90\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0095, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4082554732149708\n",
            "SCOPE mean: 0.2463715989944467, SCOPE var: 0.0056772951673066865\n",
            "Total Loss: 0.13200331255870865\n",
            "----------------------------------------\n",
            "Epoch 91\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0095, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4059306906342956\n",
            "SCOPE mean: 0.24676474322664443, SCOPE var: 0.005676895788324282\n",
            "Total Loss: 0.13128896228349757\n",
            "----------------------------------------\n",
            "Epoch 92\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0095, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.40363861949613783\n",
            "SCOPE mean: 0.24710274138788177, SCOPE var: 0.005675836270729678\n",
            "Total Loss: 0.1305827109536051\n",
            "----------------------------------------\n",
            "Epoch 93\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0095, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4013845201777283\n",
            "SCOPE mean: 0.2473669848313125, SCOPE var: 0.0056739570891414645\n",
            "Total Loss: 0.12988566132812754\n",
            "----------------------------------------\n",
            "Epoch 94\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0094, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.39916991754539216\n",
            "SCOPE mean: 0.24745776179271498, SCOPE var: 0.005671091220629545\n",
            "Total Loss: 0.1291966257355308\n",
            "----------------------------------------\n",
            "Epoch 95\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0094, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3969809003058009\n",
            "SCOPE mean: 0.24742313966394064, SCOPE var: 0.005667676171321473\n",
            "Total Loss: 0.12851291843213275\n",
            "----------------------------------------\n",
            "Epoch 96\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0094, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3948143915106954\n",
            "SCOPE mean: 0.24731621772109852, SCOPE var: 0.005664433104430067\n",
            "Total Loss: 0.12783425468878118\n",
            "----------------------------------------\n",
            "Epoch 97\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0094, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.39267315972399275\n",
            "SCOPE mean: 0.24728569872352776, SCOPE var: 0.00566249308877658\n",
            "Total Loss: 0.1271647838404877\n",
            "----------------------------------------\n",
            "Epoch 98\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0093, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3905579749307988\n",
            "SCOPE mean: 0.24742439887716963, SCOPE var: 0.005661655129750883\n",
            "Total Loss: 0.12649761925153308\n",
            "----------------------------------------\n",
            "Epoch 99\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0093, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.3884506253162954\n",
            "SCOPE mean: 0.24782548915570496, SCOPE var: 0.005662239150927392\n",
            "Total Loss: 0.12582712265357282\n",
            "----------------------------------------\n",
            "Epoch 100\n",
            "IS mean: 0.39155172544201666,IS variance: 0.03464493922526116\n",
            "SCOPE Var loss:  tensor(0.0093, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.38635402260506513\n",
            "SCOPE mean: 0.24843876209792085, SCOPE var: 0.005663959264206618\n",
            "Total Loss: 0.12516042304955008\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[-0.1428, -0.1443],\n",
            "        [ 0.0526, -0.1858],\n",
            "        [ 0.5322,  0.4858],\n",
            "        [-0.5487,  0.0785],\n",
            "        [ 0.6554, -0.4069],\n",
            "        [ 0.3017, -0.6639],\n",
            "        [-0.6120,  0.0066],\n",
            "        [ 0.0951,  0.3729],\n",
            "        [ 0.6201,  0.2789],\n",
            "        [ 0.2357,  0.3357],\n",
            "        [-0.5825, -0.5235],\n",
            "        [-0.5225, -0.4385],\n",
            "        [-0.8306,  0.0049],\n",
            "        [ 0.4171, -0.2878],\n",
            "        [ 0.4101, -0.2418],\n",
            "        [ 0.3660, -0.1997]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([ 0.8931, -0.0036, -0.3343,  0.5153,  0.1995,  0.2016, -0.6856,  0.3559,\n",
            "        -0.1030, -0.3448, -0.1913, -0.3826,  0.3357,  0.1351,  0.6495, -0.4070],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[ 0.0134, -0.2735, -0.0669, -0.1734, -0.2846, -0.0734,  0.1458,  0.1400,\n",
            "         -0.2736, -0.1011,  0.2430, -0.1367, -0.0494, -0.1391, -0.2592, -0.2477],\n",
            "        [ 0.5764, -0.2891,  0.0359,  0.0011, -0.2019, -0.2211, -0.1445,  0.0076,\n",
            "         -0.1398,  0.1515, -0.2221, -0.2422,  0.0992,  0.3332,  0.0390, -0.0064],\n",
            "        [ 0.3445,  0.0686, -0.0062, -0.1660,  0.0754, -0.0725,  0.2291,  0.1240,\n",
            "         -0.0197, -0.1490,  0.0790, -0.0904,  0.0951,  0.1197, -0.0892, -0.0033],\n",
            "        [-0.0967,  0.2054, -0.1151, -0.2605, -0.2427,  0.0943, -0.1436, -0.3404,\n",
            "         -0.1429, -0.0995, -0.0735, -0.1642, -0.0996,  0.0191,  0.2267, -0.1135],\n",
            "        [ 0.1761, -0.1528, -0.0247,  0.0138, -0.0037, -0.0168, -0.1665, -0.0210,\n",
            "         -0.0139, -0.0182,  0.1214, -0.0109,  0.2033,  0.0073,  0.0346, -0.0555],\n",
            "        [ 0.6178, -0.2464, -0.0864,  0.2263,  0.0771, -0.2308, -0.0115,  0.1718,\n",
            "          0.0673,  0.1617,  0.2239,  0.1051,  0.0459, -0.1156, -0.0480, -0.0917],\n",
            "        [ 0.5643, -0.2770, -0.0197, -0.0067, -0.0500, -0.0264, -0.2398, -0.1444,\n",
            "          0.0897, -0.0180,  0.2077, -0.0628,  0.0662, -0.0384, -0.0136,  0.2317],\n",
            "        [ 0.4374, -0.0502,  0.0416,  0.0920,  0.0777, -0.0303,  0.1082, -0.0964,\n",
            "         -0.2964, -0.0979, -0.1145, -0.0277, -0.2517,  0.1725, -0.1638, -0.0144],\n",
            "        [-0.3154, -0.3427, -0.3436, -0.0815, -0.0363, -0.3449,  0.0334,  0.0144,\n",
            "          0.2534, -0.0355, -0.2090,  0.1001, -0.1192, -0.1243,  0.0367,  0.1831],\n",
            "        [ 0.3284, -0.4727,  0.0482,  0.0127, -0.0237,  0.1312,  0.1550,  0.0421,\n",
            "         -0.1933,  0.0783, -0.1159,  0.2071,  0.1699,  0.2301,  0.1081, -0.3883],\n",
            "        [-0.3882,  0.0725,  0.1459, -0.3248, -0.0598, -0.1283,  0.0149, -0.0213,\n",
            "         -0.2427,  0.0007, -0.1808,  0.1757, -0.4436,  0.0910,  0.0373,  0.0635],\n",
            "        [ 0.5836, -0.0927, -0.0248, -0.0097,  0.0601,  0.3651, -0.1929, -0.1012,\n",
            "          0.0906,  0.0404, -0.0219,  0.0062,  0.1733, -0.1241, -0.1045,  0.0285],\n",
            "        [-0.3560,  0.2552,  0.0139,  0.0688,  0.0330, -0.0741, -0.2048,  0.1493,\n",
            "          0.0177, -0.0392, -0.0853,  0.1725, -0.0140, -0.0985,  0.0493,  0.1453],\n",
            "        [-0.0520,  0.0702,  0.0440, -0.0813, -0.1544, -0.2825, -0.1595,  0.1027,\n",
            "         -0.2928, -0.0747, -0.1945,  0.1646, -0.2865, -0.2142, -0.0702, -0.0863],\n",
            "        [ 0.3046, -0.1338, -0.0581,  0.2472,  0.0411, -0.2787,  0.1396,  0.1020,\n",
            "          0.0285, -0.1297, -0.2419,  0.2408, -0.0112, -0.2069,  0.1646, -0.0307],\n",
            "        [-0.0376,  0.0346, -0.2051,  0.1410,  0.2606, -0.0278, -0.0609,  0.0341,\n",
            "         -0.0687, -0.0696,  0.0017,  0.0817,  0.0941, -0.0083, -0.2157, -0.0958]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([ 0.0531,  0.1295,  0.3414,  0.0351,  0.3949,  0.0567,  0.2033,  0.3316,\n",
            "        -0.6321,  0.5010, -0.3472,  0.3736,  0.2720,  0.0653,  0.3138,  0.1016],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[-0.1488,  0.1102,  0.1255, -0.1911,  0.2843,  0.0504,  0.2359,  0.1182,\n",
            "         -0.2724,  0.0858, -0.1749,  0.1091,  0.0684, -0.0683,  0.1305, -0.1170]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([0.0447], dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NN_l1_l2_reg(\n",
              "  (hidden_layers): ModuleList(\n",
              "    (0): Linear(in_features=2, out_features=16, bias=True)\n",
              "    (1): Linear(in_features=16, out_features=16, bias=True)\n",
              "  )\n",
              "  (output_layer): Linear(in_features=16, out_features=1, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b_1000 = action_probs_top_n_epsilon(q_table, 1, 0.4)\n",
        "pi_b_1000 = experiment_actions(1000, env_100, P_pi_b_1000)\n",
        "P_pi_e_1000 = action_probs_top_n_epsilon(q_table, 1, 0.05)\n",
        "pi_e_1000 = experiment_actions(1000, env_100, P_pi_e_1000)\n",
        "# model_1000_random_pi_b_1000_env_100 = CustomizableFeatureNet(input_dim=2, hidden_dims=[16, 16], output_dim=1, dtype = torch.float64, l2_lambda=0.002)\n",
        "model_1000_random_pi_b_1000_env_100 = NN_l1_l2_reg(input_dim=2, hidden_dims=[16, 16], output_dim=1, dtype = torch.float64, l1_lambda=0.0002, l2_lambda = 0.0001)\n",
        "test_1000_random_pi_b_1000_env_100 = SCOPE_straight(model_1000_random_pi_b_1000_env_100, 0.99, 10000, pi_b_1000, P_pi_b_1000, P_pi_e_1000, 0.3, dtype = torch.float64)\n",
        "test_1000_random_pi_b_1000_env_100.train_var_scope(300, 0.001, 1, 0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "840bbd74-af94-4037-cf26-43e8f43a1603",
        "id": "bmp2h8ft41u9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0427, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.337769062885827\n",
            "SCOPE mean: 0.41989625769625855, SCOPE var: 0.03388364029488501\n",
            "Total Loss: 0.6764456763066073\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0402, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  6.120085835006211\n",
            "SCOPE mean: 0.4182087240737377, SCOPE var: 0.03439496238293219\n",
            "Total Loss: 0.6522064849802002\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0393, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.931176821983479\n",
            "SCOPE mean: 0.4164676401268267, SCOPE var: 0.034900649650177674\n",
            "Total Loss: 0.6324637253841687\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0384, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.759639445494777\n",
            "SCOPE mean: 0.41344703242434555, SCOPE var: 0.035420519246800994\n",
            "Total Loss: 0.6143772640599109\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0374, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.604117495988793\n",
            "SCOPE mean: 0.41250564358998254, SCOPE var: 0.035932935395315196\n",
            "Total Loss: 0.597769690172349\n",
            "----------------------------------------\n",
            "Epoch 6\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0362, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.462573387605645\n",
            "SCOPE mean: 0.4137106264704086, SCOPE var: 0.0364473796065249\n",
            "Total Loss: 0.5824882581648694\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0350, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.332783635751879\n",
            "SCOPE mean: 0.4171905368429909, SCOPE var: 0.036923909073726904\n",
            "Total Loss: 0.5682609517234409\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0337, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.213391020006787\n",
            "SCOPE mean: 0.422139750607473, SCOPE var: 0.03741271132608199\n",
            "Total Loss: 0.5550229407881135\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0323, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  5.1028323376168325\n",
            "SCOPE mean: 0.42840049728979573, SCOPE var: 0.037906982141200855\n",
            "Total Loss: 0.5426260556088752\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0310, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.999604623836896\n",
            "SCOPE mean: 0.4357562609491386, SCOPE var: 0.03839493047595267\n",
            "Total Loss: 0.5309606772702741\n",
            "----------------------------------------\n",
            "Epoch 11\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0297, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.903112152835229\n",
            "SCOPE mean: 0.44407691573212515, SCOPE var: 0.03886414910863839\n",
            "Total Loss: 0.5200020938843747\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0284, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.812737470222913\n",
            "SCOPE mean: 0.4525833602865883, SCOPE var: 0.039287336144886054\n",
            "Total Loss: 0.5096728145746852\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0272, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.727656501863168\n",
            "SCOPE mean: 0.46165851189927526, SCOPE var: 0.03970476567893469\n",
            "Total Loss: 0.4999680532231633\n",
            "----------------------------------------\n",
            "Epoch 14\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0260, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.647621397093708\n",
            "SCOPE mean: 0.4699779224275291, SCOPE var: 0.04010701835384713\n",
            "Total Loss: 0.49080784837350233\n",
            "----------------------------------------\n",
            "Epoch 15\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0249, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.572115747166604\n",
            "SCOPE mean: 0.4779993325775298, SCOPE var: 0.040490997956856296\n",
            "Total Loss: 0.4821445475298265\n",
            "----------------------------------------\n",
            "Epoch 16\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0239, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.5003089342503\n",
            "SCOPE mean: 0.48603160344326496, SCOPE var: 0.040854299541154826\n",
            "Total Loss: 0.4738866291498332\n",
            "----------------------------------------\n",
            "Epoch 17\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0228, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.4317808784456885\n",
            "SCOPE mean: 0.4939853971058326, SCOPE var: 0.04119106306421001\n",
            "Total Loss: 0.4660074705059544\n",
            "----------------------------------------\n",
            "Epoch 18\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0219, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.366294030798755\n",
            "SCOPE mean: 0.5017921302645412, SCOPE var: 0.04149602458667143\n",
            "Total Loss: 0.4585032513939639\n",
            "----------------------------------------\n",
            "Epoch 19\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0210, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.303821209196925\n",
            "SCOPE mean: 0.5093117794024651, SCOPE var: 0.041768264941357935\n",
            "Total Loss: 0.4513589062804001\n",
            "----------------------------------------\n",
            "Epoch 20\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0201, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.243859041720236\n",
            "SCOPE mean: 0.5164529511887941, SCOPE var: 0.042006239165808354\n",
            "Total Loss: 0.44451554582334124\n",
            "----------------------------------------\n",
            "Epoch 21\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0193, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.18615033227444\n",
            "SCOPE mean: 0.5231321682786273, SCOPE var: 0.04220611025312937\n",
            "Total Loss: 0.43795577008102327\n",
            "----------------------------------------\n",
            "Epoch 22\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0186, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.1304455885201525\n",
            "SCOPE mean: 0.5292435998019429, SCOPE var: 0.04235863765331874\n",
            "Total Loss: 0.43165551672619135\n",
            "----------------------------------------\n",
            "Epoch 23\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0179, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.076302574341792\n",
            "SCOPE mean: 0.5348368110552094, SCOPE var: 0.042476951629577465\n",
            "Total Loss: 0.42557194712717095\n",
            "----------------------------------------\n",
            "Epoch 24\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0173, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  4.023657955629442\n",
            "SCOPE mean: 0.5398637142890647, SCOPE var: 0.0425590822217892\n",
            "Total Loss: 0.4196746552834755\n",
            "----------------------------------------\n",
            "Epoch 25\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0167, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.972466335018568\n",
            "SCOPE mean: 0.5441883766600271, SCOPE var: 0.04259220050271747\n",
            "Total Loss: 0.4139641126911515\n",
            "----------------------------------------\n",
            "Epoch 26\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0162, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.9224752105514047\n",
            "SCOPE mean: 0.5478135250757061, SCOPE var: 0.042579427413348116\n",
            "Total Loss: 0.40841798927862394\n",
            "----------------------------------------\n",
            "Epoch 27\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0157, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.8734261483753802\n",
            "SCOPE mean: 0.5507844950854028, SCOPE var: 0.04251613932739403\n",
            "Total Loss: 0.40301336324932124\n",
            "----------------------------------------\n",
            "Epoch 28\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0152, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.8252233980689105\n",
            "SCOPE mean: 0.5531673704055584, SCOPE var: 0.04242132262754213\n",
            "Total Loss: 0.39773308361137\n",
            "----------------------------------------\n",
            "Epoch 29\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0148, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.777904768072946\n",
            "SCOPE mean: 0.5549716491394345, SCOPE var: 0.042300974862373414\n",
            "Total Loss: 0.39259026340906455\n",
            "----------------------------------------\n",
            "Epoch 30\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0144, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.7313106287321625\n",
            "SCOPE mean: 0.5563031247179311, SCOPE var: 0.04215856781988134\n",
            "Total Loss: 0.3875716355471198\n",
            "----------------------------------------\n",
            "Epoch 31\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0141, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.6851512659597074\n",
            "SCOPE mean: 0.5571281245556782, SCOPE var: 0.04199621519283208\n",
            "Total Loss: 0.3826191698665098\n",
            "----------------------------------------\n",
            "Epoch 32\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0138, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.639632653090521\n",
            "SCOPE mean: 0.5574745070219425, SCOPE var: 0.04181648916190384\n",
            "Total Loss: 0.377773062043857\n",
            "----------------------------------------\n",
            "Epoch 33\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0136, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.5949161832126153\n",
            "SCOPE mean: 0.557409536153169, SCOPE var: 0.04162175447586829\n",
            "Total Loss: 0.3730434916611166\n",
            "----------------------------------------\n",
            "Epoch 34\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0133, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.5509817224700235\n",
            "SCOPE mean: 0.5569822774175041, SCOPE var: 0.04141390659350637\n",
            "Total Loss: 0.36842750091187926\n",
            "----------------------------------------\n",
            "Epoch 35\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0131, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.5077536544033454\n",
            "SCOPE mean: 0.5562663404095248, SCOPE var: 0.04119616770221215\n",
            "Total Loss: 0.3638796506647394\n",
            "----------------------------------------\n",
            "Epoch 36\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0129, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.4652214326599022\n",
            "SCOPE mean: 0.5550918751065094, SCOPE var: 0.040970469068528456\n",
            "Total Loss: 0.35940959019765406\n",
            "----------------------------------------\n",
            "Epoch 37\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0127, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.4230919221991805\n",
            "SCOPE mean: 0.5521524795194377, SCOPE var: 0.04073781654303582\n",
            "Total Loss: 0.35499631204367105\n",
            "----------------------------------------\n",
            "Epoch 38\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0125, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.381481861914596\n",
            "SCOPE mean: 0.5488982522939213, SCOPE var: 0.0404984778411029\n",
            "Total Loss: 0.3506607767337086\n",
            "----------------------------------------\n",
            "Epoch 39\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0124, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.3403960994766106\n",
            "SCOPE mean: 0.5457593882074112, SCOPE var: 0.04025459644024792\n",
            "Total Loss: 0.3464046703928456\n",
            "----------------------------------------\n",
            "Epoch 40\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0122, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.299776029678069\n",
            "SCOPE mean: 0.5425393532166315, SCOPE var: 0.04001104225571833\n",
            "Total Loss: 0.3422254088939559\n",
            "----------------------------------------\n",
            "Epoch 41\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0122, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.259720098688149\n",
            "SCOPE mean: 0.5393507764081069, SCOPE var: 0.03976979904661961\n",
            "Total Loss: 0.33812693540049304\n",
            "----------------------------------------\n",
            "Epoch 42\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0121, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.2202528463881634\n",
            "SCOPE mean: 0.5365473861533885, SCOPE var: 0.039527868583613054\n",
            "Total Loss: 0.3340873114063531\n",
            "----------------------------------------\n",
            "Epoch 43\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0120, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.1814154813112454\n",
            "SCOPE mean: 0.5340115727240925, SCOPE var: 0.039289316415865784\n",
            "Total Loss: 0.33009795992837404\n",
            "----------------------------------------\n",
            "Epoch 44\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0118, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.143090799078095\n",
            "SCOPE mean: 0.5317586109538608, SCOPE var: 0.03905434695661933\n",
            "Total Loss: 0.32615293906670734\n",
            "----------------------------------------\n",
            "Epoch 45\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0117, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.1066167712182806\n",
            "SCOPE mean: 0.5291175994714078, SCOPE var: 0.03882361756788785\n",
            "Total Loss: 0.32237186440653687\n",
            "----------------------------------------\n",
            "Epoch 46\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0116, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.07073616596755\n",
            "SCOPE mean: 0.5268033024585268, SCOPE var: 0.03859751189803726\n",
            "Total Loss: 0.3186679680305027\n",
            "----------------------------------------\n",
            "Epoch 47\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0115, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  3.0349594272963967\n",
            "SCOPE mean: 0.5249343180219638, SCOPE var: 0.038375913846200566\n",
            "Total Loss: 0.31499638881173\n",
            "----------------------------------------\n",
            "Epoch 48\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0114, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.999558668655255\n",
            "SCOPE mean: 0.5235724532622, SCOPE var: 0.03812286397216447\n",
            "Total Loss: 0.31136370207732694\n",
            "----------------------------------------\n",
            "Epoch 49\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0113, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.9642300674758553\n",
            "SCOPE mean: 0.5233120189042364, SCOPE var: 0.0378472196185458\n",
            "Total Loss: 0.30776208387854476\n",
            "----------------------------------------\n",
            "Epoch 50\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0113, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.9286987523856753\n",
            "SCOPE mean: 0.5234883563586623, SCOPE var: 0.03757723790047611\n",
            "Total Loss: 0.3041396749465601\n",
            "----------------------------------------\n",
            "Epoch 51\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0112, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.892634071407721\n",
            "SCOPE mean: 0.5246298023600539, SCOPE var: 0.037292437691713365\n",
            "Total Loss: 0.30045360139438765\n",
            "----------------------------------------\n",
            "Epoch 52\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0111, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.856824137389953\n",
            "SCOPE mean: 0.5262178210112123, SCOPE var: 0.03696967045311851\n",
            "Total Loss: 0.2967886356928545\n",
            "----------------------------------------\n",
            "Epoch 53\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0110, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.8214093480268363\n",
            "SCOPE mean: 0.5274251144665557, SCOPE var: 0.03663645693725107\n",
            "Total Loss: 0.2931658480200905\n",
            "----------------------------------------\n",
            "Epoch 54\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0110, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.7859288797748136\n",
            "SCOPE mean: 0.5284696453589772, SCOPE var: 0.03627947913252413\n",
            "Total Loss: 0.2895456405564636\n",
            "----------------------------------------\n",
            "Epoch 55\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0109, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.750444735685941\n",
            "SCOPE mean: 0.5296012468095835, SCOPE var: 0.03591460118436837\n",
            "Total Loss: 0.28591102115768935\n",
            "----------------------------------------\n",
            "Epoch 56\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0107, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.715657363434873\n",
            "SCOPE mean: 0.530992624531581, SCOPE var: 0.03554369241429148\n",
            "Total Loss: 0.2823056391463351\n",
            "----------------------------------------\n",
            "Epoch 57\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0106, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.681471091566196\n",
            "SCOPE mean: 0.5327603368497593, SCOPE var: 0.03513656788142874\n",
            "Total Loss: 0.2787221811822619\n",
            "----------------------------------------\n",
            "Epoch 58\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0104, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.64785967065159\n",
            "SCOPE mean: 0.5346740887779978, SCOPE var: 0.0347060847097148\n",
            "Total Loss: 0.2751843141171087\n",
            "----------------------------------------\n",
            "Epoch 59\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0102, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.6148007281296013\n",
            "SCOPE mean: 0.5363119598520325, SCOPE var: 0.03428247816023322\n",
            "Total Loss: 0.2716630117894259\n",
            "----------------------------------------\n",
            "Epoch 60\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0100, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.5823499723496837\n",
            "SCOPE mean: 0.5380986332459007, SCOPE var: 0.033862368527136706\n",
            "Total Loss: 0.26820202853148256\n",
            "----------------------------------------\n",
            "Epoch 61\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0098, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.550977227857718\n",
            "SCOPE mean: 0.5396145495013734, SCOPE var: 0.03345333807181218\n",
            "Total Loss: 0.2648583906428333\n",
            "----------------------------------------\n",
            "Epoch 62\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0096, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.520451607282063\n",
            "SCOPE mean: 0.5415551858818908, SCOPE var: 0.033053632262638556\n",
            "Total Loss: 0.26160213871567134\n",
            "----------------------------------------\n",
            "Epoch 63\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0094, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.4908810486495283\n",
            "SCOPE mean: 0.5440563099120266, SCOPE var: 0.03266152961811108\n",
            "Total Loss: 0.2584486079883372\n",
            "----------------------------------------\n",
            "Epoch 64\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0092, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.462541757734359\n",
            "SCOPE mean: 0.5466172617925232, SCOPE var: 0.03226675058021209\n",
            "Total Loss: 0.2554216516123977\n",
            "----------------------------------------\n",
            "Epoch 65\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0090, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.4353108727642385\n",
            "SCOPE mean: 0.5496975780398108, SCOPE var: 0.03187170191645047\n",
            "Total Loss: 0.2525443101390096\n",
            "----------------------------------------\n",
            "Epoch 66\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0089, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.409370082315123\n",
            "SCOPE mean: 0.5457243630883752, SCOPE var: 0.031496448246567686\n",
            "Total Loss: 0.24982019059870303\n",
            "----------------------------------------\n",
            "Epoch 67\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0087, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.385002153862616\n",
            "SCOPE mean: 0.5424700992341878, SCOPE var: 0.031147195755559815\n",
            "Total Loss: 0.24723940041684947\n",
            "----------------------------------------\n",
            "Epoch 68\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0086, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.3617111801971578\n",
            "SCOPE mean: 0.5401548012412081, SCOPE var: 0.03083899434988637\n",
            "Total Loss: 0.2447413109290081\n",
            "----------------------------------------\n",
            "Epoch 69\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0084, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.3392987892650208\n",
            "SCOPE mean: 0.538679354212208, SCOPE var: 0.030564636929381276\n",
            "Total Loss: 0.24231959662436686\n",
            "----------------------------------------\n",
            "Epoch 70\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0082, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.317741315271149\n",
            "SCOPE mean: 0.5378199085307366, SCOPE var: 0.03032569865547816\n",
            "Total Loss: 0.2399780545630032\n",
            "----------------------------------------\n",
            "Epoch 71\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0080, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.296935135412459\n",
            "SCOPE mean: 0.5373835187959503, SCOPE var: 0.030116581565458742\n",
            "Total Loss: 0.237710285048709\n",
            "----------------------------------------\n",
            "Epoch 72\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0078, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.276647286022716\n",
            "SCOPE mean: 0.5371332598168835, SCOPE var: 0.029928972907230986\n",
            "Total Loss: 0.2355030693450895\n",
            "----------------------------------------\n",
            "Epoch 73\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0077, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.256621237604071\n",
            "SCOPE mean: 0.5368070962246531, SCOPE var: 0.029764048511869246\n",
            "Total Loss: 0.23333293695918322\n",
            "----------------------------------------\n",
            "Epoch 74\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0075, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.23674212357979\n",
            "SCOPE mean: 0.5363294176464053, SCOPE var: 0.029619099056938665\n",
            "Total Loss: 0.23120220367651978\n",
            "----------------------------------------\n",
            "Epoch 75\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0074, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.217038589254051\n",
            "SCOPE mean: 0.5356330043566285, SCOPE var: 0.029496444644081365\n",
            "Total Loss: 0.22910244004602193\n",
            "----------------------------------------\n",
            "Epoch 76\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0073, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.1974051932597587\n",
            "SCOPE mean: 0.534722477777175, SCOPE var: 0.02939891592501533\n",
            "Total Loss: 0.2270185272531924\n",
            "----------------------------------------\n",
            "Epoch 77\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0072, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.1778786972907564\n",
            "SCOPE mean: 0.5336952847226515, SCOPE var: 0.02932277417600613\n",
            "Total Loss: 0.2249588645928567\n",
            "----------------------------------------\n",
            "Epoch 78\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0071, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.158594912035617\n",
            "SCOPE mean: 0.5326925688802482, SCOPE var: 0.02926453087147033\n",
            "Total Loss: 0.2229325450865289\n",
            "----------------------------------------\n",
            "Epoch 79\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0070, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.1394987728259234\n",
            "SCOPE mean: 0.5319167291092634, SCOPE var: 0.029216240909238012\n",
            "Total Loss: 0.22092474989748562\n",
            "----------------------------------------\n",
            "Epoch 80\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0069, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.120671861600404\n",
            "SCOPE mean: 0.5315253655798108, SCOPE var: 0.029186579555567724\n",
            "Total Loss: 0.2189407245591008\n",
            "----------------------------------------\n",
            "Epoch 81\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0068, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.102229021273874\n",
            "SCOPE mean: 0.531628793633039, SCOPE var: 0.029175193987777515\n",
            "Total Loss: 0.21699932614442866\n",
            "----------------------------------------\n",
            "Epoch 82\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0067, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.0841930078057382\n",
            "SCOPE mean: 0.5323668120023388, SCOPE var: 0.029182023363054182\n",
            "Total Loss: 0.21510966794152872\n",
            "----------------------------------------\n",
            "Epoch 83\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0066, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.066583923461522\n",
            "SCOPE mean: 0.5337916110169015, SCOPE var: 0.029204018273876194\n",
            "Total Loss: 0.21326268070385607\n",
            "----------------------------------------\n",
            "Epoch 84\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0065, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.0493092568437756\n",
            "SCOPE mean: 0.5360079065003259, SCOPE var: 0.029239545777732225\n",
            "Total Loss: 0.21144287105995882\n",
            "----------------------------------------\n",
            "Epoch 85\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0064, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.032248297692557\n",
            "SCOPE mean: 0.5389593497915982, SCOPE var: 0.02928409472979833\n",
            "Total Loss: 0.20963711126699888\n",
            "----------------------------------------\n",
            "Epoch 86\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0063, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  2.0155377060702953\n",
            "SCOPE mean: 0.5428144263268501, SCOPE var: 0.02932525470038064\n",
            "Total Loss: 0.20786088675811604\n",
            "----------------------------------------\n",
            "Epoch 87\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0062, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.9989326251798571\n",
            "SCOPE mean: 0.5471474282499241, SCOPE var: 0.02937322690484054\n",
            "Total Loss: 0.20609295910576889\n",
            "----------------------------------------\n",
            "Epoch 88\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0061, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.9824213572086986\n",
            "SCOPE mean: 0.551876208616558, SCOPE var: 0.029425815402384106\n",
            "Total Loss: 0.20434326070415865\n",
            "----------------------------------------\n",
            "Epoch 89\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0060, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.9660204420403322\n",
            "SCOPE mean: 0.5568051918356128, SCOPE var: 0.029481780727199182\n",
            "Total Loss: 0.20260904132574764\n",
            "----------------------------------------\n",
            "Epoch 90\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0059, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.949665257452961\n",
            "SCOPE mean: 0.5618390067850423, SCOPE var: 0.02952039677768849\n",
            "Total Loss: 0.20088368336480708\n",
            "----------------------------------------\n",
            "Epoch 91\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0058, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.9333864289568563\n",
            "SCOPE mean: 0.5667251373118741, SCOPE var: 0.02955418079871351\n",
            "Total Loss: 0.19917276066362377\n",
            "----------------------------------------\n",
            "Epoch 92\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0058, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.9172077050110439\n",
            "SCOPE mean: 0.5713638932717061, SCOPE var: 0.029581192344437818\n",
            "Total Loss: 0.1974801721460472\n",
            "----------------------------------------\n",
            "Epoch 93\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0057, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.9011913850441993\n",
            "SCOPE mean: 0.5756479850045549, SCOPE var: 0.029599813212758737\n",
            "Total Loss: 0.1958124108974179\n",
            "----------------------------------------\n",
            "Epoch 94\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0056, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.885292993446168\n",
            "SCOPE mean: 0.5795729681037396, SCOPE var: 0.029607024249548433\n",
            "Total Loss: 0.19416201890858525\n",
            "----------------------------------------\n",
            "Epoch 95\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0056, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.8695393288844033\n",
            "SCOPE mean: 0.5831222137088338, SCOPE var: 0.029602008152109317\n",
            "Total Loss: 0.19253343903890113\n",
            "----------------------------------------\n",
            "Epoch 96\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0055, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.853913880489599\n",
            "SCOPE mean: 0.5864099908464786, SCOPE var: 0.029586304653339057\n",
            "Total Loss: 0.19091981915858458\n",
            "----------------------------------------\n",
            "Epoch 97\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0055, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.838337311290362\n",
            "SCOPE mean: 0.5891874044869002, SCOPE var: 0.029565699141318777\n",
            "Total Loss: 0.18930694141604917\n",
            "----------------------------------------\n",
            "Epoch 98\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0054, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.8230082749992516\n",
            "SCOPE mean: 0.5905048678985501, SCOPE var: 0.029538203175398327\n",
            "Total Loss: 0.18773068956000824\n",
            "----------------------------------------\n",
            "Epoch 99\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0054, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.807786850189649\n",
            "SCOPE mean: 0.5917138024309648, SCOPE var: 0.029501393188932697\n",
            "Total Loss: 0.18616623523648212\n",
            "----------------------------------------\n",
            "Epoch 100\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0053, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7926659510776608\n",
            "SCOPE mean: 0.5927664794568849, SCOPE var: 0.029453438269534112\n",
            "Total Loss: 0.18461097076198185\n",
            "----------------------------------------\n",
            "Epoch 101\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0053, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7776143101673623\n",
            "SCOPE mean: 0.5936804226154767, SCOPE var: 0.029387694851635844\n",
            "Total Loss: 0.1830638675421837\n",
            "----------------------------------------\n",
            "Epoch 102\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0053, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7625860132705427\n",
            "SCOPE mean: 0.5945740290245564, SCOPE var: 0.029312480106657095\n",
            "Total Loss: 0.18151817463829809\n",
            "----------------------------------------\n",
            "Epoch 103\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0052, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7475879723649768\n",
            "SCOPE mean: 0.5954489049951187, SCOPE var: 0.029231130415517306\n",
            "Total Loss: 0.1799697030031783\n",
            "----------------------------------------\n",
            "Epoch 104\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0052, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.732508206256024\n",
            "SCOPE mean: 0.5962450603498544, SCOPE var: 0.02914430261168991\n",
            "Total Loss: 0.17841810255328902\n",
            "----------------------------------------\n",
            "Epoch 105\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0051, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.7173947765260895\n",
            "SCOPE mean: 0.5968908249718197, SCOPE var: 0.029053243589573126\n",
            "Total Loss: 0.1768659754376651\n",
            "----------------------------------------\n",
            "Epoch 106\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0051, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.702330703142511\n",
            "SCOPE mean: 0.5974270804826676, SCOPE var: 0.02896103966566795\n",
            "Total Loss: 0.17532550399021027\n",
            "----------------------------------------\n",
            "Epoch 107\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0051, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6873886936074023\n",
            "SCOPE mean: 0.5977555823667139, SCOPE var: 0.02886843930136254\n",
            "Total Loss: 0.1738042695199724\n",
            "----------------------------------------\n",
            "Epoch 108\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0050, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6724863519214188\n",
            "SCOPE mean: 0.5980133843289384, SCOPE var: 0.02877831703576492\n",
            "Total Loss: 0.17228780876817218\n",
            "----------------------------------------\n",
            "Epoch 109\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0050, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6576597726411701\n",
            "SCOPE mean: 0.5982011884876891, SCOPE var: 0.028693517565631835\n",
            "Total Loss: 0.1707846123922563\n",
            "----------------------------------------\n",
            "Epoch 110\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0050, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6429087736059922\n",
            "SCOPE mean: 0.5984154093866105, SCOPE var: 0.0286137145720316\n",
            "Total Loss: 0.16930081287086235\n",
            "----------------------------------------\n",
            "Epoch 111\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0050, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.6282781279795848\n",
            "SCOPE mean: 0.5990007309816434, SCOPE var: 0.02853737044143954\n",
            "Total Loss: 0.1678468742051671\n",
            "----------------------------------------\n",
            "Epoch 112\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0050, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.613894821997227\n",
            "SCOPE mean: 0.5997488727949861, SCOPE var: 0.028465686597015295\n",
            "Total Loss: 0.16641830153110365\n",
            "----------------------------------------\n",
            "Epoch 113\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0050, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5994166093369786\n",
            "SCOPE mean: 0.6006965891453587, SCOPE var: 0.028400036389121485\n",
            "Total Loss: 0.1649759952710066\n",
            "----------------------------------------\n",
            "Epoch 114\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0050, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.584733288225574\n",
            "SCOPE mean: 0.6018844758542009, SCOPE var: 0.028341097576592963\n",
            "Total Loss: 0.16352146485457644\n",
            "----------------------------------------\n",
            "Epoch 115\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0051, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5700315055699565\n",
            "SCOPE mean: 0.6033329226849473, SCOPE var: 0.02828859059720754\n",
            "Total Loss: 0.16207281778840657\n",
            "----------------------------------------\n",
            "Epoch 116\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0051, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5552007540919308\n",
            "SCOPE mean: 0.6049744336971419, SCOPE var: 0.028242338270990864\n",
            "Total Loss: 0.16061325027433507\n",
            "----------------------------------------\n",
            "Epoch 117\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0051, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.54017524800431\n",
            "SCOPE mean: 0.6067989188619501, SCOPE var: 0.028202024358506723\n",
            "Total Loss: 0.15913408174596141\n",
            "----------------------------------------\n",
            "Epoch 118\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0051, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5250472378043083\n",
            "SCOPE mean: 0.6087330375818713, SCOPE var: 0.028167858021378896\n",
            "Total Loss: 0.15764839629719057\n",
            "----------------------------------------\n",
            "Epoch 119\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0052, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.5096768439558645\n",
            "SCOPE mean: 0.6107548997873044, SCOPE var: 0.028142293645806556\n",
            "Total Loss: 0.15614195565558314\n",
            "----------------------------------------\n",
            "Epoch 120\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0052, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4944844195125835\n",
            "SCOPE mean: 0.6127847626920605, SCOPE var: 0.02812396772653388\n",
            "Total Loss: 0.15465107616182688\n",
            "----------------------------------------\n",
            "Epoch 121\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0052, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.47917000948382\n",
            "SCOPE mean: 0.6147777303405779, SCOPE var: 0.028111374835290512\n",
            "Total Loss: 0.15315451914574882\n",
            "----------------------------------------\n",
            "Epoch 122\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0053, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4638695627760152\n",
            "SCOPE mean: 0.6167095806380581, SCOPE var: 0.02810195497371887\n",
            "Total Loss: 0.15165590383965769\n",
            "----------------------------------------\n",
            "Epoch 123\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0053, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4486907684337198\n",
            "SCOPE mean: 0.6185042072714617, SCOPE var: 0.028095093074640313\n",
            "Total Loss: 0.15017613173519107\n",
            "----------------------------------------\n",
            "Epoch 124\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0053, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4335689999292738\n",
            "SCOPE mean: 0.6199590887405814, SCOPE var: 0.028067700388632127\n",
            "Total Loss: 0.14870393916935715\n",
            "----------------------------------------\n",
            "Epoch 125\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0054, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4183128565149548\n",
            "SCOPE mean: 0.6209404213622308, SCOPE var: 0.02800702746750793\n",
            "Total Loss: 0.14723973904024196\n",
            "----------------------------------------\n",
            "Epoch 126\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0055, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.4030326213296336\n",
            "SCOPE mean: 0.6218119372359299, SCOPE var: 0.027945208099373064\n",
            "Total Loss: 0.14582114833930596\n",
            "----------------------------------------\n",
            "Epoch 127\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0056, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.3879567215677502\n",
            "SCOPE mean: 0.6224949245068898, SCOPE var: 0.027880375503339865\n",
            "Total Loss: 0.14442208085354313\n",
            "----------------------------------------\n",
            "Epoch 128\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0058, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.3730078096842966\n",
            "SCOPE mean: 0.623135470046835, SCOPE var: 0.027818473169027396\n",
            "Total Loss: 0.14306320395013375\n",
            "----------------------------------------\n",
            "Epoch 129\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0059, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.3582953326566611\n",
            "SCOPE mean: 0.623724548935422, SCOPE var: 0.027760331913791313\n",
            "Total Loss: 0.14172354456930591\n",
            "----------------------------------------\n",
            "Epoch 130\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0060, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.3436048584377964\n",
            "SCOPE mean: 0.6242083802634365, SCOPE var: 0.027707138603490774\n",
            "Total Loss: 0.1404003143231252\n",
            "----------------------------------------\n",
            "Epoch 131\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0062, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.3291341858563628\n",
            "SCOPE mean: 0.6246009366601989, SCOPE var: 0.027658024074541786\n",
            "Total Loss: 0.1390937009432502\n",
            "----------------------------------------\n",
            "Epoch 132\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0063, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.3147814788881669\n",
            "SCOPE mean: 0.625115303278574, SCOPE var: 0.027631587524275854\n",
            "Total Loss: 0.13778821557699342\n",
            "----------------------------------------\n",
            "Epoch 133\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0064, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.300629688623359\n",
            "SCOPE mean: 0.6256493725831013, SCOPE var: 0.027616083460223113\n",
            "Total Loss: 0.13648127286827735\n",
            "----------------------------------------\n",
            "Epoch 134\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0065, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.2868233866452612\n",
            "SCOPE mean: 0.6262445112529553, SCOPE var: 0.02760371870705689\n",
            "Total Loss: 0.1351757133164077\n",
            "----------------------------------------\n",
            "Epoch 135\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0065, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.273305532177273\n",
            "SCOPE mean: 0.6269385732237717, SCOPE var: 0.027595420228679984\n",
            "Total Loss: 0.1338606130356439\n",
            "----------------------------------------\n",
            "Epoch 136\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0066, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.260055799060285\n",
            "SCOPE mean: 0.627490788068961, SCOPE var: 0.02759200483351314\n",
            "Total Loss: 0.13255716378674012\n",
            "----------------------------------------\n",
            "Epoch 137\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0065, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.2472656745894615\n",
            "SCOPE mean: 0.6270238933704556, SCOPE var: 0.027589534174573577\n",
            "Total Loss: 0.1312614577836531\n",
            "----------------------------------------\n",
            "Epoch 138\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0065, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.2344549406832102\n",
            "SCOPE mean: 0.626865132335833, SCOPE var: 0.027590608509456216\n",
            "Total Loss: 0.12996592743284108\n",
            "----------------------------------------\n",
            "Epoch 139\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0065, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.2214071178100598\n",
            "SCOPE mean: 0.6270586393165059, SCOPE var: 0.027595875016354562\n",
            "Total Loss: 0.1286596359126239\n",
            "----------------------------------------\n",
            "Epoch 140\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0065, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.2081564058894265\n",
            "SCOPE mean: 0.6276553112162144, SCOPE var: 0.02760642369585414\n",
            "Total Loss: 0.12730846044192673\n",
            "----------------------------------------\n",
            "Epoch 141\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0065, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.194223727077707\n",
            "SCOPE mean: 0.6287728601453894, SCOPE var: 0.027622709862776366\n",
            "Total Loss: 0.12588411322755189\n",
            "----------------------------------------\n",
            "Epoch 142\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0064, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.1800273768874106\n",
            "SCOPE mean: 0.6303514043004614, SCOPE var: 0.027645167675076278\n",
            "Total Loss: 0.12444500928197137\n",
            "----------------------------------------\n",
            "Epoch 143\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0065, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.1657711464311695\n",
            "SCOPE mean: 0.633427577182845, SCOPE var: 0.027663395899518245\n",
            "Total Loss: 0.12305485354972334\n",
            "----------------------------------------\n",
            "Epoch 144\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0066, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.1516886474605625\n",
            "SCOPE mean: 0.6372337733437536, SCOPE var: 0.027686689562255704\n",
            "Total Loss: 0.12172708053387843\n",
            "----------------------------------------\n",
            "Epoch 145\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0066, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.137688519858142\n",
            "SCOPE mean: 0.6405969661451173, SCOPE var: 0.027709542983931554\n",
            "Total Loss: 0.12035693108541087\n",
            "----------------------------------------\n",
            "Epoch 146\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0066, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.1238910192797023\n",
            "SCOPE mean: 0.6447650961167057, SCOPE var: 0.027709641907339835\n",
            "Total Loss: 0.11896330559905456\n",
            "----------------------------------------\n",
            "Epoch 147\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0066, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.1103407888723824\n",
            "SCOPE mean: 0.6489284309693034, SCOPE var: 0.027688766447331488\n",
            "Total Loss: 0.11763092887215754\n",
            "----------------------------------------\n",
            "Epoch 148\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0066, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0971851096399912\n",
            "SCOPE mean: 0.6533732279217942, SCOPE var: 0.027681931403935184\n",
            "Total Loss: 0.11632139227736812\n",
            "----------------------------------------\n",
            "Epoch 149\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0066, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0838615156732283\n",
            "SCOPE mean: 0.657507337318911, SCOPE var: 0.0276858214303548\n",
            "Total Loss: 0.1149501149639166\n",
            "----------------------------------------\n",
            "Epoch 150\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0065, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.070708382905046\n",
            "SCOPE mean: 0.6609272924624882, SCOPE var: 0.02769051425796011\n",
            "Total Loss: 0.11359015983466192\n",
            "----------------------------------------\n",
            "Epoch 151\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0064, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.057634094917103\n",
            "SCOPE mean: 0.6635008368496229, SCOPE var: 0.02769011074915196\n",
            "Total Loss: 0.11221098693381265\n",
            "----------------------------------------\n",
            "Epoch 152\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0064, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0447318740964415\n",
            "SCOPE mean: 0.6653328705065822, SCOPE var: 0.027660355312894756\n",
            "Total Loss: 0.11086640873166695\n",
            "----------------------------------------\n",
            "Epoch 153\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0063, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0322476657937671\n",
            "SCOPE mean: 0.6664624751310917, SCOPE var: 0.027635558165647837\n",
            "Total Loss: 0.10956296376780225\n",
            "----------------------------------------\n",
            "Epoch 154\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0063, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0201664418195848\n",
            "SCOPE mean: 0.6671891021040743, SCOPE var: 0.027620332615131263\n",
            "Total Loss: 0.1082754144475383\n",
            "----------------------------------------\n",
            "Epoch 155\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0062, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  1.0083888361320172\n",
            "SCOPE mean: 0.6680005847994437, SCOPE var: 0.02761672537362883\n",
            "Total Loss: 0.10700509637153252\n",
            "----------------------------------------\n",
            "Epoch 156\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0061, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9969009480354858\n",
            "SCOPE mean: 0.669010429495376, SCOPE var: 0.027623748478939857\n",
            "Total Loss: 0.10575141190285905\n",
            "----------------------------------------\n",
            "Epoch 157\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0060, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9857248403035199\n",
            "SCOPE mean: 0.670194055712516, SCOPE var: 0.027626605070708955\n",
            "Total Loss: 0.10452955116559476\n",
            "----------------------------------------\n",
            "Epoch 158\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0059, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.974772978734872\n",
            "SCOPE mean: 0.6714899269501391, SCOPE var: 0.02761538382737935\n",
            "Total Loss: 0.1033389743775608\n",
            "----------------------------------------\n",
            "Epoch 159\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0058, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9641181092447529\n",
            "SCOPE mean: 0.673052830614172, SCOPE var: 0.02761017664294058\n",
            "Total Loss: 0.10219299153795405\n",
            "----------------------------------------\n",
            "Epoch 160\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0057, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9538145686255006\n",
            "SCOPE mean: 0.6745762008136903, SCOPE var: 0.027610986402685715\n",
            "Total Loss: 0.1011069974344623\n",
            "----------------------------------------\n",
            "Epoch 161\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0057, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.943493923979161\n",
            "SCOPE mean: 0.6759074708213728, SCOPE var: 0.027617215258450137\n",
            "Total Loss: 0.10008064993674738\n",
            "----------------------------------------\n",
            "Epoch 162\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0057, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9333932658109988\n",
            "SCOPE mean: 0.676943902311006, SCOPE var: 0.027628006777789257\n",
            "Total Loss: 0.09908117506460244\n",
            "----------------------------------------\n",
            "Epoch 163\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0058, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9236462511771416\n",
            "SCOPE mean: 0.6778349820905225, SCOPE var: 0.027644615763677893\n",
            "Total Loss: 0.09813066438347896\n",
            "----------------------------------------\n",
            "Epoch 164\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0058, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9144015476810561\n",
            "SCOPE mean: 0.67456808012624, SCOPE var: 0.0276671634620729\n",
            "Total Loss: 0.09722392261722142\n",
            "----------------------------------------\n",
            "Epoch 165\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0058, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.9055478534323381\n",
            "SCOPE mean: 0.6708345767438354, SCOPE var: 0.027695353161796634\n",
            "Total Loss: 0.0963454797615979\n",
            "----------------------------------------\n",
            "Epoch 166\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0058, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8969468710150934\n",
            "SCOPE mean: 0.6678189406758804, SCOPE var: 0.027728775555100744\n",
            "Total Loss: 0.09545916081129181\n",
            "----------------------------------------\n",
            "Epoch 167\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0057, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.888373287235936\n",
            "SCOPE mean: 0.664256842466594, SCOPE var: 0.027759056641411498\n",
            "Total Loss: 0.09453013277342026\n",
            "----------------------------------------\n",
            "Epoch 168\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0056, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8799012529652411\n",
            "SCOPE mean: 0.6602752343302412, SCOPE var: 0.02778567552736885\n",
            "Total Loss: 0.09361097976173023\n",
            "----------------------------------------\n",
            "Epoch 169\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0055, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8716546422435071\n",
            "SCOPE mean: 0.6561002794117657, SCOPE var: 0.027810691697566378\n",
            "Total Loss: 0.09270260820236316\n",
            "----------------------------------------\n",
            "Epoch 170\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0054, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8638162018713332\n",
            "SCOPE mean: 0.6521898460545648, SCOPE var: 0.027836862476951104\n",
            "Total Loss: 0.09183020662049618\n",
            "----------------------------------------\n",
            "Epoch 171\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0054, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8564063376807192\n",
            "SCOPE mean: 0.6497252745822832, SCOPE var: 0.027872327513464266\n",
            "Total Loss: 0.09100432877690441\n",
            "----------------------------------------\n",
            "Epoch 172\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0053, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8491984703915582\n",
            "SCOPE mean: 0.649723496970281, SCOPE var: 0.027922028006583943\n",
            "Total Loss: 0.0902131454094586\n",
            "----------------------------------------\n",
            "Epoch 173\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0052, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8423168803275041\n",
            "SCOPE mean: 0.6517718141473068, SCOPE var: 0.02798088294891718\n",
            "Total Loss: 0.08945192398073278\n",
            "----------------------------------------\n",
            "Epoch 174\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0052, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8357372545992025\n",
            "SCOPE mean: 0.6544610843705787, SCOPE var: 0.028036462184086904\n",
            "Total Loss: 0.08873142228819834\n",
            "----------------------------------------\n",
            "Epoch 175\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0051, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8291439832287564\n",
            "SCOPE mean: 0.6564321053076893, SCOPE var: 0.02807538804172168\n",
            "Total Loss: 0.08802404657629007\n",
            "----------------------------------------\n",
            "Epoch 176\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0051, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8223486447053999\n",
            "SCOPE mean: 0.657183205410661, SCOPE var: 0.028092479419631736\n",
            "Total Loss: 0.08731364946154298\n",
            "----------------------------------------\n",
            "Epoch 177\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0051, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8155387129497336\n",
            "SCOPE mean: 0.6570390069572376, SCOPE var: 0.028091856521985665\n",
            "Total Loss: 0.08661039303376893\n",
            "----------------------------------------\n",
            "Epoch 178\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0050, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8089759056849263\n",
            "SCOPE mean: 0.6571474944898428, SCOPE var: 0.028084106397095358\n",
            "Total Loss: 0.08593288785573394\n",
            "----------------------------------------\n",
            "Epoch 179\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0050, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.8026466337651756\n",
            "SCOPE mean: 0.6585849261100657, SCOPE var: 0.028079977584850747\n",
            "Total Loss: 0.08526667596390561\n",
            "----------------------------------------\n",
            "Epoch 180\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0050, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7965290522446751\n",
            "SCOPE mean: 0.6612755147918052, SCOPE var: 0.028080810086529767\n",
            "Total Loss: 0.08461340646575878\n",
            "----------------------------------------\n",
            "Epoch 181\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0049, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7907431214041756\n",
            "SCOPE mean: 0.6640810320479027, SCOPE var: 0.028079361565445934\n",
            "Total Loss: 0.08399376842887865\n",
            "----------------------------------------\n",
            "Epoch 182\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0049, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7851715046640412\n",
            "SCOPE mean: 0.6659584180014158, SCOPE var: 0.028068325281708786\n",
            "Total Loss: 0.08339783924744763\n",
            "----------------------------------------\n",
            "Epoch 183\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0049, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7796247825057644\n",
            "SCOPE mean: 0.6661697438162496, SCOPE var: 0.02804392498660505\n",
            "Total Loss: 0.08281471575460476\n",
            "----------------------------------------\n",
            "Epoch 184\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0048, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7741164602725742\n",
            "SCOPE mean: 0.6650994811481583, SCOPE var: 0.028010864145710093\n",
            "Total Loss: 0.08224216437255549\n",
            "----------------------------------------\n",
            "Epoch 185\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0048, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7687392503823551\n",
            "SCOPE mean: 0.6630929205418733, SCOPE var: 0.027971652053918723\n",
            "Total Loss: 0.08168111896751877\n",
            "----------------------------------------\n",
            "Epoch 186\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0048, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7635723541832455\n",
            "SCOPE mean: 0.6614470278688155, SCOPE var: 0.0279375104443067\n",
            "Total Loss: 0.08113911743420144\n",
            "----------------------------------------\n",
            "Epoch 187\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0048, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7585413806666534\n",
            "SCOPE mean: 0.6607858732187349, SCOPE var: 0.027912751806882536\n",
            "Total Loss: 0.08060559225007694\n",
            "----------------------------------------\n",
            "Epoch 188\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0047, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7536825726014839\n",
            "SCOPE mean: 0.6610255767935612, SCOPE var: 0.02789619389870556\n",
            "Total Loss: 0.08008672196773957\n",
            "----------------------------------------\n",
            "Epoch 189\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0047, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7490017133148839\n",
            "SCOPE mean: 0.660953884539815, SCOPE var: 0.027878455362520385\n",
            "Total Loss: 0.07959181226307951\n",
            "----------------------------------------\n",
            "Epoch 190\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0047, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7443496540439228\n",
            "SCOPE mean: 0.659592222650497, SCOPE var: 0.02785099241845898\n",
            "Total Loss: 0.07910728079762369\n",
            "----------------------------------------\n",
            "Epoch 191\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0047, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7397061232678783\n",
            "SCOPE mean: 0.6570138617852878, SCOPE var: 0.027813977799263177\n",
            "Total Loss: 0.07863304672102571\n",
            "----------------------------------------\n",
            "Epoch 192\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0047, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.735216915023465\n",
            "SCOPE mean: 0.6543696148753035, SCOPE var: 0.027776855813681448\n",
            "Total Loss: 0.0781786709435981\n",
            "----------------------------------------\n",
            "Epoch 193\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7308568438088673\n",
            "SCOPE mean: 0.6527374952418655, SCOPE var: 0.02774822031304295\n",
            "Total Loss: 0.07773435696368945\n",
            "----------------------------------------\n",
            "Epoch 194\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7265806133377265\n",
            "SCOPE mean: 0.6524786634192743, SCOPE var: 0.027731180587109605\n",
            "Total Loss: 0.07729371614543797\n",
            "----------------------------------------\n",
            "Epoch 195\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7224346563506313\n",
            "SCOPE mean: 0.6526481541457956, SCOPE var: 0.02771860520119057\n",
            "Total Loss: 0.07686656314329894\n",
            "----------------------------------------\n",
            "Epoch 196\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7183246684198803\n",
            "SCOPE mean: 0.651909544344339, SCOPE var: 0.027700219666340384\n",
            "Total Loss: 0.07644988851529333\n",
            "----------------------------------------\n",
            "Epoch 197\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7141580478092755\n",
            "SCOPE mean: 0.6501266409931726, SCOPE var: 0.027674306319394937\n",
            "Total Loss: 0.0760363927235959\n",
            "----------------------------------------\n",
            "Epoch 198\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7100390610074211\n",
            "SCOPE mean: 0.6484008188080114, SCOPE var: 0.02765095700694974\n",
            "Total Loss: 0.07562952739403662\n",
            "----------------------------------------\n",
            "Epoch 199\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7060601750333533\n",
            "SCOPE mean: 0.6474907895255139, SCOPE var: 0.027637607237699046\n",
            "Total Loss: 0.07523035195501715\n",
            "----------------------------------------\n",
            "Epoch 200\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.7022731051251417\n",
            "SCOPE mean: 0.6476668257235688, SCOPE var: 0.027636327201411584\n",
            "Total Loss: 0.0748441438535394\n",
            "----------------------------------------\n",
            "Epoch 201\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6986065748688188\n",
            "SCOPE mean: 0.648035730126992, SCOPE var: 0.027639849902807566\n",
            "Total Loss: 0.07446940347746046\n",
            "----------------------------------------\n",
            "Epoch 202\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6949930634041487\n",
            "SCOPE mean: 0.6478873536112371, SCOPE var: 0.027641846625446477\n",
            "Total Loss: 0.07410237831470555\n",
            "----------------------------------------\n",
            "Epoch 203\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6914014694298747\n",
            "SCOPE mean: 0.6470503918519239, SCOPE var: 0.027640964029300677\n",
            "Total Loss: 0.07374115659764391\n",
            "----------------------------------------\n",
            "Epoch 204\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6878627270016479\n",
            "SCOPE mean: 0.6459757251230314, SCOPE var: 0.027639537088247193\n",
            "Total Loss: 0.07338691086448217\n",
            "----------------------------------------\n",
            "Epoch 205\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6844081659509399\n",
            "SCOPE mean: 0.6454265057187006, SCOPE var: 0.027643306828908965\n",
            "Total Loss: 0.07303906148915548\n",
            "----------------------------------------\n",
            "Epoch 206\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6810192334511641\n",
            "SCOPE mean: 0.6456734604546727, SCOPE var: 0.027653871033645125\n",
            "Total Loss: 0.07269501600685513\n",
            "----------------------------------------\n",
            "Epoch 207\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6777022381566414\n",
            "SCOPE mean: 0.646264825909226, SCOPE var: 0.027667201765288838\n",
            "Total Loss: 0.07235766316889577\n",
            "----------------------------------------\n",
            "Epoch 208\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6744229400874966\n",
            "SCOPE mean: 0.646469072938247, SCOPE var: 0.027677016428953496\n",
            "Total Loss: 0.07202795679430023\n",
            "----------------------------------------\n",
            "Epoch 209\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.671141966011624\n",
            "SCOPE mean: 0.6461507345400511, SCOPE var: 0.027681651489954346\n",
            "Total Loss: 0.07170196852036441\n",
            "----------------------------------------\n",
            "Epoch 210\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6679019759792671\n",
            "SCOPE mean: 0.6457332086760178, SCOPE var: 0.027677529203227108\n",
            "Total Loss: 0.0713814204542586\n",
            "----------------------------------------\n",
            "Epoch 211\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6647430871410627\n",
            "SCOPE mean: 0.6459048778835523, SCOPE var: 0.02767309045324919\n",
            "Total Loss: 0.07106775221910269\n",
            "----------------------------------------\n",
            "Epoch 212\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6616555915313476\n",
            "SCOPE mean: 0.6467663479333469, SCOPE var: 0.027673375990684652\n",
            "Total Loss: 0.07075663588877182\n",
            "----------------------------------------\n",
            "Epoch 213\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6586469569533073\n",
            "SCOPE mean: 0.6477941938571316, SCOPE var: 0.027674522787853966\n",
            "Total Loss: 0.07045316904665865\n",
            "----------------------------------------\n",
            "Epoch 214\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6556698103006192\n",
            "SCOPE mean: 0.648225288736739, SCOPE var: 0.027668999523812004\n",
            "Total Loss: 0.07015454061299725\n",
            "----------------------------------------\n",
            "Epoch 215\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6527231144840494\n",
            "SCOPE mean: 0.6479192575052101, SCOPE var: 0.02765550644892403\n",
            "Total Loss: 0.06986049421169388\n",
            "----------------------------------------\n",
            "Epoch 216\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6498486468596365\n",
            "SCOPE mean: 0.6477094545397291, SCOPE var: 0.027642291536242848\n",
            "Total Loss: 0.06957195956335194\n",
            "----------------------------------------\n",
            "Epoch 217\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6470346365851037\n",
            "SCOPE mean: 0.6478750289335382, SCOPE var: 0.027630441520138018\n",
            "Total Loss: 0.0692868521105438\n",
            "----------------------------------------\n",
            "Epoch 218\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6442779291149299\n",
            "SCOPE mean: 0.6482508753083164, SCOPE var: 0.027619098001345502\n",
            "Total Loss: 0.06900543589966027\n",
            "----------------------------------------\n",
            "Epoch 219\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6415705383050238\n",
            "SCOPE mean: 0.6484009422489395, SCOPE var: 0.027605197828624615\n",
            "Total Loss: 0.0687287099295699\n",
            "----------------------------------------\n",
            "Epoch 220\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6389105243322382\n",
            "SCOPE mean: 0.6481379565215055, SCOPE var: 0.027587987111148016\n",
            "Total Loss: 0.06845641370845955\n",
            "----------------------------------------\n",
            "Epoch 221\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6363142604081419\n",
            "SCOPE mean: 0.6476812705078591, SCOPE var: 0.027570261914285972\n",
            "Total Loss: 0.06818939027036391\n",
            "----------------------------------------\n",
            "Epoch 222\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0045, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6337762771442559\n",
            "SCOPE mean: 0.6474032336432007, SCOPE var: 0.02755547173166201\n",
            "Total Loss: 0.06792659429585961\n",
            "----------------------------------------\n",
            "Epoch 223\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0045, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6312985400935684\n",
            "SCOPE mean: 0.6474048011217346, SCOPE var: 0.027547344755969542\n",
            "Total Loss: 0.0676689692471085\n",
            "----------------------------------------\n",
            "Epoch 224\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0045, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6288564387404504\n",
            "SCOPE mean: 0.6471773240058951, SCOPE var: 0.027539047086934876\n",
            "Total Loss: 0.06741621799476716\n",
            "----------------------------------------\n",
            "Epoch 225\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0045, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6264269007914015\n",
            "SCOPE mean: 0.64680701512077, SCOPE var: 0.027529846807445867\n",
            "Total Loss: 0.06716568971198046\n",
            "----------------------------------------\n",
            "Epoch 226\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0045, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6240419112509246\n",
            "SCOPE mean: 0.646844573884582, SCOPE var: 0.02752452960181823\n",
            "Total Loss: 0.06691880447094516\n",
            "----------------------------------------\n",
            "Epoch 227\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0045, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6216803220980504\n",
            "SCOPE mean: 0.6470510640677312, SCOPE var: 0.027520485652978578\n",
            "Total Loss: 0.0666744653488805\n",
            "----------------------------------------\n",
            "Epoch 228\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0045, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6193310610450612\n",
            "SCOPE mean: 0.6470776509553511, SCOPE var: 0.02751376545566031\n",
            "Total Loss: 0.06643318090711903\n",
            "----------------------------------------\n",
            "Epoch 229\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0045, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6169912523765407\n",
            "SCOPE mean: 0.6468973935873694, SCOPE var: 0.0275045362197303\n",
            "Total Loss: 0.06619444658384811\n",
            "----------------------------------------\n",
            "Epoch 230\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0045, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.61466348291133\n",
            "SCOPE mean: 0.6467398438786347, SCOPE var: 0.02749507327403071\n",
            "Total Loss: 0.06595697899779664\n",
            "----------------------------------------\n",
            "Epoch 231\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0045, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6123454374274917\n",
            "SCOPE mean: 0.6468538237267905, SCOPE var: 0.027486693941799253\n",
            "Total Loss: 0.06572037155528983\n",
            "----------------------------------------\n",
            "Epoch 232\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0045, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6099303085724489\n",
            "SCOPE mean: 0.6471542887090789, SCOPE var: 0.02748342919566334\n",
            "Total Loss: 0.06546667969573496\n",
            "----------------------------------------\n",
            "Epoch 233\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0045, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6075087319892888\n",
            "SCOPE mean: 0.6474059537422097, SCOPE var: 0.02748319629916205\n",
            "Total Loss: 0.06520798271473509\n",
            "----------------------------------------\n",
            "Epoch 234\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0044, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6049890120088839\n",
            "SCOPE mean: 0.6472803823800368, SCOPE var: 0.027480217514740925\n",
            "Total Loss: 0.0649399479581648\n",
            "----------------------------------------\n",
            "Epoch 235\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0044, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.6024501343370781\n",
            "SCOPE mean: 0.6468190392541859, SCOPE var: 0.027474645591080597\n",
            "Total Loss: 0.06467039205631431\n",
            "----------------------------------------\n",
            "Epoch 236\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0044, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5999233225805195\n",
            "SCOPE mean: 0.6464132897578478, SCOPE var: 0.027470542494637786\n",
            "Total Loss: 0.06440149991550215\n",
            "----------------------------------------\n",
            "Epoch 237\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0044, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5974317298989437\n",
            "SCOPE mean: 0.6463381884848914, SCOPE var: 0.027470666069097243\n",
            "Total Loss: 0.06413513858856393\n",
            "----------------------------------------\n",
            "Epoch 238\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0044, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5949773931698195\n",
            "SCOPE mean: 0.6464237363659009, SCOPE var: 0.027472035763554545\n",
            "Total Loss: 0.06387208362433869\n",
            "----------------------------------------\n",
            "Epoch 239\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0044, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5925642423970355\n",
            "SCOPE mean: 0.6463108931085959, SCOPE var: 0.02747157131876474\n",
            "Total Loss: 0.06361476117046781\n",
            "----------------------------------------\n",
            "Epoch 240\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0043, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5901858696071287\n",
            "SCOPE mean: 0.6459181191843045, SCOPE var: 0.027468399891247833\n",
            "Total Loss: 0.06336312749258902\n",
            "----------------------------------------\n",
            "Epoch 241\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0043, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.587847020209195\n",
            "SCOPE mean: 0.6454747904500742, SCOPE var: 0.027462200160852816\n",
            "Total Loss: 0.06311735563835526\n",
            "----------------------------------------\n",
            "Epoch 242\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0043, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5855548859867057\n",
            "SCOPE mean: 0.6452690797856792, SCOPE var: 0.02745551717159248\n",
            "Total Loss: 0.06287635020910012\n",
            "----------------------------------------\n",
            "Epoch 243\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0043, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5833322472461931\n",
            "SCOPE mean: 0.6451340976302354, SCOPE var: 0.027444364271403943\n",
            "Total Loss: 0.06264016985017674\n",
            "----------------------------------------\n",
            "Epoch 244\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0043, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5811477880537897\n",
            "SCOPE mean: 0.6449303893011588, SCOPE var: 0.02742891070815278\n",
            "Total Loss: 0.062408866965718464\n",
            "----------------------------------------\n",
            "Epoch 245\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0043, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5790405399160276\n",
            "SCOPE mean: 0.6445874555745181, SCOPE var: 0.027408345035466995\n",
            "Total Loss: 0.06218228812621909\n",
            "----------------------------------------\n",
            "Epoch 246\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0043, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5770081599455061\n",
            "SCOPE mean: 0.6443284064048012, SCOPE var: 0.027389390600282868\n",
            "Total Loss: 0.06195921791123398\n",
            "----------------------------------------\n",
            "Epoch 247\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0042, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5750056358283263\n",
            "SCOPE mean: 0.6442583906715977, SCOPE var: 0.027374253151010802\n",
            "Total Loss: 0.061737960472849254\n",
            "----------------------------------------\n",
            "Epoch 248\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0042, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5727124484137169\n",
            "SCOPE mean: 0.6464161064541046, SCOPE var: 0.027366675595652007\n",
            "Total Loss: 0.06148473816769874\n",
            "----------------------------------------\n",
            "Epoch 249\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0042, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5703856888849586\n",
            "SCOPE mean: 0.6486044653965906, SCOPE var: 0.027358411329774724\n",
            "Total Loss: 0.06122765559835766\n",
            "----------------------------------------\n",
            "Epoch 250\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0042, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5680709028831469\n",
            "SCOPE mean: 0.6505911069781454, SCOPE var: 0.027348343615002737\n",
            "Total Loss: 0.060972246909555966\n",
            "----------------------------------------\n",
            "Epoch 251\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0041, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5657962734047768\n",
            "SCOPE mean: 0.6527847837592499, SCOPE var: 0.027335263088067576\n",
            "Total Loss: 0.060721113197468854\n",
            "----------------------------------------\n",
            "Epoch 252\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0041, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5635676127928367\n",
            "SCOPE mean: 0.6554960166514555, SCOPE var: 0.02732498659436168\n",
            "Total Loss: 0.060474256570932756\n",
            "----------------------------------------\n",
            "Epoch 253\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0041, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5613853010898001\n",
            "SCOPE mean: 0.6584505752840805, SCOPE var: 0.027316421347213724\n",
            "Total Loss: 0.06023273966374342\n",
            "----------------------------------------\n",
            "Epoch 254\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0041, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5592510722138608\n",
            "SCOPE mean: 0.6612056560469814, SCOPE var: 0.02730612369783679\n",
            "Total Loss: 0.05999879325116366\n",
            "----------------------------------------\n",
            "Epoch 255\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0041, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5571645698404907\n",
            "SCOPE mean: 0.6636139959215965, SCOPE var: 0.02729284905389696\n",
            "Total Loss: 0.05977259885775496\n",
            "----------------------------------------\n",
            "Epoch 256\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0040, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5551206778684483\n",
            "SCOPE mean: 0.6657948526682983, SCOPE var: 0.027278790164455596\n",
            "Total Loss: 0.05955306324679176\n",
            "----------------------------------------\n",
            "Epoch 257\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0040, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5531222311277828\n",
            "SCOPE mean: 0.6683186524485513, SCOPE var: 0.027269345705731647\n",
            "Total Loss: 0.059333814760733045\n",
            "----------------------------------------\n",
            "Epoch 258\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0040, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5510948243833229\n",
            "SCOPE mean: 0.671180744030933, SCOPE var: 0.0272606148308801\n",
            "Total Loss: 0.05911216069690656\n",
            "----------------------------------------\n",
            "Epoch 259\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0040, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5490223511009372\n",
            "SCOPE mean: 0.6738647240385967, SCOPE var: 0.027250568770592693\n",
            "Total Loss: 0.058887097245167164\n",
            "----------------------------------------\n",
            "Epoch 260\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0040, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5469781231283332\n",
            "SCOPE mean: 0.6760041349389768, SCOPE var: 0.027236802616896316\n",
            "Total Loss: 0.05866540500791844\n",
            "----------------------------------------\n",
            "Epoch 261\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0039, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5449606568650763\n",
            "SCOPE mean: 0.6776130432400758, SCOPE var: 0.0272228502994186\n",
            "Total Loss: 0.058444208470438685\n",
            "----------------------------------------\n",
            "Epoch 262\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0039, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.543026981479905\n",
            "SCOPE mean: 0.67937022768306, SCOPE var: 0.027218172919395857\n",
            "Total Loss: 0.058225452384600494\n",
            "----------------------------------------\n",
            "Epoch 263\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0039, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5411733377703438\n",
            "SCOPE mean: 0.6813961992474035, SCOPE var: 0.0272243571985462\n",
            "Total Loss: 0.05800995944945223\n",
            "----------------------------------------\n",
            "Epoch 264\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0039, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5393860566555908\n",
            "SCOPE mean: 0.683432184788014, SCOPE var: 0.02723790511136049\n",
            "Total Loss: 0.05779851389695049\n",
            "----------------------------------------\n",
            "Epoch 265\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0038, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5376504863278266\n",
            "SCOPE mean: 0.6846716160915571, SCOPE var: 0.027248189813295062\n",
            "Total Loss: 0.05759320890068789\n",
            "----------------------------------------\n",
            "Epoch 266\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0038, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.535956691341082\n",
            "SCOPE mean: 0.6853122914830656, SCOPE var: 0.027254757694570808\n",
            "Total Loss: 0.05739469786337014\n",
            "----------------------------------------\n",
            "Epoch 267\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0038, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.534292155378957\n",
            "SCOPE mean: 0.6857713070295451, SCOPE var: 0.02726191547977605\n",
            "Total Loss: 0.05720126673715942\n",
            "----------------------------------------\n",
            "Epoch 268\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0037, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5326419196592815\n",
            "SCOPE mean: 0.6867561814197793, SCOPE var: 0.02727088168374214\n",
            "Total Loss: 0.05701235600400604\n",
            "----------------------------------------\n",
            "Epoch 269\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0037, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.530996901734234\n",
            "SCOPE mean: 0.6878758881649074, SCOPE var: 0.027277774155224206\n",
            "Total Loss: 0.056828010765075584\n",
            "----------------------------------------\n",
            "Epoch 270\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0037, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.529330619457615\n",
            "SCOPE mean: 0.6886155930132994, SCOPE var: 0.0272803518530511\n",
            "Total Loss: 0.05664821859049727\n",
            "----------------------------------------\n",
            "Epoch 271\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0037, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5276688436717063\n",
            "SCOPE mean: 0.688488951647454, SCOPE var: 0.027274853564476002\n",
            "Total Loss: 0.056472553185921766\n",
            "----------------------------------------\n",
            "Epoch 272\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0037, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5260575261627835\n",
            "SCOPE mean: 0.6883064546012475, SCOPE var: 0.027270860989168654\n",
            "Total Loss: 0.05630289444918157\n",
            "----------------------------------------\n",
            "Epoch 273\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0037, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5244783334685478\n",
            "SCOPE mean: 0.6890830237520834, SCOPE var: 0.027305525374606728\n",
            "Total Loss: 0.05613500990880267\n",
            "----------------------------------------\n",
            "Epoch 274\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0037, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.522930681774162\n",
            "SCOPE mean: 0.6907381645290295, SCOPE var: 0.027393819587438518\n",
            "Total Loss: 0.05597006735709658\n",
            "----------------------------------------\n",
            "Epoch 275\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0037, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5213996495873313\n",
            "SCOPE mean: 0.6917101092540534, SCOPE var: 0.027469176410837293\n",
            "Total Loss: 0.05580591622470805\n",
            "----------------------------------------\n",
            "Epoch 276\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0037, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5198562494365789\n",
            "SCOPE mean: 0.6918255007829257, SCOPE var: 0.02753067749180443\n",
            "Total Loss: 0.05564139660200129\n",
            "----------------------------------------\n",
            "Epoch 277\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.518321790129346\n",
            "SCOPE mean: 0.6917729109484954, SCOPE var: 0.027582577637966708\n",
            "Total Loss: 0.05547825681528416\n",
            "----------------------------------------\n",
            "Epoch 278\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.516798607214964\n",
            "SCOPE mean: 0.6922660503538238, SCOPE var: 0.027633528969046445\n",
            "Total Loss: 0.05531670690827278\n",
            "----------------------------------------\n",
            "Epoch 279\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5152867469463479\n",
            "SCOPE mean: 0.6932470413480922, SCOPE var: 0.02768579570416255\n",
            "Total Loss: 0.05515764553848641\n",
            "----------------------------------------\n",
            "Epoch 280\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5137629336965421\n",
            "SCOPE mean: 0.694093570878085, SCOPE var: 0.027741660993770054\n",
            "Total Loss: 0.05500028493419003\n",
            "----------------------------------------\n",
            "Epoch 281\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5122123952498028\n",
            "SCOPE mean: 0.6946219560429614, SCOPE var: 0.027798949213307063\n",
            "Total Loss: 0.054843291598937985\n",
            "----------------------------------------\n",
            "Epoch 282\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5106542311716571\n",
            "SCOPE mean: 0.6952179243913239, SCOPE var: 0.02785754697570309\n",
            "Total Loss: 0.05468791214907687\n",
            "----------------------------------------\n",
            "Epoch 283\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5090863240982373\n",
            "SCOPE mean: 0.6963163903331469, SCOPE var: 0.027922432851524716\n",
            "Total Loss: 0.054532735299538615\n",
            "----------------------------------------\n",
            "Epoch 284\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5075087889654968\n",
            "SCOPE mean: 0.6975213121729139, SCOPE var: 0.02799213737412134\n",
            "Total Loss: 0.05437673624421169\n",
            "----------------------------------------\n",
            "Epoch 285\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5059300704387151\n",
            "SCOPE mean: 0.6986180810544368, SCOPE var: 0.02805300221845543\n",
            "Total Loss: 0.05422117147419625\n",
            "----------------------------------------\n",
            "Epoch 286\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5043582752609272\n",
            "SCOPE mean: 0.6996880611357087, SCOPE var: 0.028093867620949703\n",
            "Total Loss: 0.05406539329662213\n",
            "----------------------------------------\n",
            "Epoch 287\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5028059150306948\n",
            "SCOPE mean: 0.7006147361551592, SCOPE var: 0.02813225165777653\n",
            "Total Loss: 0.05391036177948777\n",
            "----------------------------------------\n",
            "Epoch 288\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.5012913339432062\n",
            "SCOPE mean: 0.7014228030030853, SCOPE var: 0.028168406574048125\n",
            "Total Loss: 0.053758834464673395\n",
            "----------------------------------------\n",
            "Epoch 289\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.49981676039144946\n",
            "SCOPE mean: 0.7024148475139301, SCOPE var: 0.028201984594469695\n",
            "Total Loss: 0.05360977748374436\n",
            "----------------------------------------\n",
            "Epoch 290\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.49837399265474175\n",
            "SCOPE mean: 0.7033645501632165, SCOPE var: 0.028234214701008557\n",
            "Total Loss: 0.05346292579323039\n",
            "----------------------------------------\n",
            "Epoch 291\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.49693335749342427\n",
            "SCOPE mean: 0.7041001482134484, SCOPE var: 0.028267309762472412\n",
            "Total Loss: 0.05331623490359319\n",
            "----------------------------------------\n",
            "Epoch 292\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.49549975821641196\n",
            "SCOPE mean: 0.7047129122322531, SCOPE var: 0.02830177177293727\n",
            "Total Loss: 0.053170885214527834\n",
            "----------------------------------------\n",
            "Epoch 293\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4940826188088416\n",
            "SCOPE mean: 0.7056536510775573, SCOPE var: 0.02834201719236886\n",
            "Total Loss: 0.053026620265961076\n",
            "----------------------------------------\n",
            "Epoch 294\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4926772777065211\n",
            "SCOPE mean: 0.7068534805347211, SCOPE var: 0.028388245349317554\n",
            "Total Loss: 0.052884144147358654\n",
            "----------------------------------------\n",
            "Epoch 295\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4912546895209983\n",
            "SCOPE mean: 0.7080174345648238, SCOPE var: 0.028437783516327607\n",
            "Total Loss: 0.052741545827543944\n",
            "----------------------------------------\n",
            "Epoch 296\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.48985583820316964\n",
            "SCOPE mean: 0.7089492725035828, SCOPE var: 0.028488800883220165\n",
            "Total Loss: 0.05260035119082777\n",
            "----------------------------------------\n",
            "Epoch 297\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4885079818005521\n",
            "SCOPE mean: 0.7098158542611969, SCOPE var: 0.028540990616344467\n",
            "Total Loss: 0.05246181861992421\n",
            "----------------------------------------\n",
            "Epoch 298\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4871973489938649\n",
            "SCOPE mean: 0.7107256182169522, SCOPE var: 0.028592575513861986\n",
            "Total Loss: 0.0523246118117961\n",
            "----------------------------------------\n",
            "Epoch 299\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4859414655892976\n",
            "SCOPE mean: 0.7114841681903942, SCOPE var: 0.02864129329016765\n",
            "Total Loss: 0.05218891980152928\n",
            "----------------------------------------\n",
            "Epoch 300\n",
            "IS mean: 0.46514684963012803,IS variance: 0.014499969252461947\n",
            "SCOPE Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "MSE loss:  0.4847195706139535\n",
            "SCOPE mean: 0.7117085400589089, SCOPE var: 0.028683537876875737\n",
            "Total Loss: 0.05205377786200582\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[-0.7880,  0.3435],\n",
            "        [ 0.1187,  0.1739],\n",
            "        [-0.0424, -0.1672],\n",
            "        [ 0.1793,  0.0643],\n",
            "        [ 0.5344, -0.0807],\n",
            "        [ 0.5409,  0.1366],\n",
            "        [-0.6652,  0.5258],\n",
            "        [ 0.3348, -0.2981],\n",
            "        [-0.3773,  0.2395],\n",
            "        [-0.7207,  0.5355],\n",
            "        [ 0.4268, -0.5615],\n",
            "        [-0.0741, -0.0935],\n",
            "        [ 0.2690,  0.2021],\n",
            "        [ 0.1627,  0.2267],\n",
            "        [-0.1964,  0.6497],\n",
            "        [ 0.3448, -0.0348]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([ 0.0658, -0.5955,  0.1749, -0.4597,  0.6124, -0.6678,  0.7964, -0.5967,\n",
            "         0.0429, -0.4588, -0.8171,  0.4948,  0.3202,  0.3630, -0.6885,  0.2558],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[ 1.0107e-02,  2.9216e-02, -2.4658e-01, -6.9363e-02, -3.5020e-04,\n",
            "         -4.9744e-02, -1.0764e-02, -1.1028e-01,  3.3062e-03, -3.4723e-02,\n",
            "         -1.1289e-01,  4.2536e-01, -1.5100e-02, -1.9254e-02,  4.5610e-03,\n",
            "         -3.6121e-02],\n",
            "        [ 1.5759e-01, -2.2577e-01,  4.0604e-03,  2.4353e-01, -8.9067e-03,\n",
            "         -2.6997e-01, -5.9960e-02, -1.0999e-01, -8.7861e-02,  6.0024e-02,\n",
            "          2.5220e-02,  6.1100e-02, -5.6151e-02, -3.4824e-02, -1.0326e-01,\n",
            "          2.3141e-01],\n",
            "        [-3.5619e-03, -1.7923e-01,  1.8316e-01, -2.2978e-01,  1.5354e-01,\n",
            "         -1.1930e-01,  1.6618e-01, -1.2155e-01, -1.4175e-01, -1.0209e-01,\n",
            "         -3.0485e-02,  6.9489e-02,  4.9398e-02,  1.4706e-01, -1.1449e-02,\n",
            "         -2.4839e-01],\n",
            "        [-1.8041e-01, -1.4973e-01, -2.3171e-01, -3.3318e-01,  1.5402e-01,\n",
            "         -1.7744e-01,  5.1750e-02, -8.8996e-02,  1.4503e-01,  9.8540e-02,\n",
            "          4.2859e-04,  3.1816e-01,  8.6840e-02,  3.6138e-02, -1.0362e-01,\n",
            "         -2.4013e-02],\n",
            "        [ 1.6697e-01, -7.1624e-02, -2.5319e-02, -1.6985e-01,  2.2393e-01,\n",
            "         -4.9303e-02, -5.6547e-02,  2.2020e-03,  2.4156e-02,  6.6889e-02,\n",
            "          1.0774e-01,  3.4781e-01, -9.0474e-02, -2.1007e-02,  1.5616e-02,\n",
            "         -7.7205e-02],\n",
            "        [-8.4582e-03,  1.9970e-02, -1.3848e-01, -1.0524e-01, -5.5104e-02,\n",
            "         -4.7467e-03, -2.2421e-02, -4.0905e-02, -1.1711e-02, -1.4054e-02,\n",
            "          3.0488e-03,  5.2642e-01, -8.3768e-03, -2.6183e-02,  3.6260e-03,\n",
            "         -3.8099e-02],\n",
            "        [-6.6860e-02, -9.5177e-02,  2.1223e-01, -3.3705e-01, -7.8337e-02,\n",
            "         -2.0617e-01,  1.8959e-02,  2.1395e-01, -1.1321e-01,  1.7504e-01,\n",
            "         -7.1767e-02, -1.9056e-01, -1.0950e-01, -1.5615e-01, -2.0663e-01,\n",
            "         -2.8024e-01],\n",
            "        [ 2.1931e-01, -1.1292e-01,  4.5585e-02,  6.7010e-02,  2.1118e-01,\n",
            "          3.6726e-02,  2.2487e-02,  2.1590e-01,  1.6133e-01,  1.0082e-01,\n",
            "          1.9866e-01,  2.3746e-01,  2.0562e-01,  1.1701e-01, -1.0708e-02,\n",
            "          1.5462e-01],\n",
            "        [-6.1817e-02,  1.0818e-01, -6.8508e-02, -1.0054e-01,  7.8977e-02,\n",
            "         -3.8640e-01,  3.6560e-03, -6.0168e-02, -1.5225e-02,  3.3748e-02,\n",
            "         -1.3633e-02, -3.6049e-01, -4.4524e-03,  1.6669e-01, -4.0729e-02,\n",
            "          1.0758e-01],\n",
            "        [-2.9191e-02, -2.2586e-01,  1.9243e-01, -5.2162e-02, -7.1011e-02,\n",
            "          2.2107e-01, -1.2999e-01,  1.4311e-01, -2.5462e-01, -9.1382e-02,\n",
            "         -1.8414e-01, -4.6750e-02,  4.7870e-02,  2.2868e-01, -2.4132e-01,\n",
            "          5.9997e-02],\n",
            "        [ 1.9396e-01,  4.5957e-02,  3.9154e-02, -5.8615e-02, -5.5205e-02,\n",
            "          2.1040e-01, -5.2854e-02,  2.5673e-01, -3.1925e-02,  5.2543e-02,\n",
            "          4.9598e-02,  2.3672e-01,  8.6564e-02, -1.1875e-01,  1.0425e-01,\n",
            "          4.3291e-02],\n",
            "        [-1.7096e-01,  1.0717e-01,  2.1243e-01,  2.4581e-02,  7.5273e-02,\n",
            "         -3.6609e-02, -2.1448e-01, -2.6846e-01,  1.9569e-02, -2.1176e-01,\n",
            "          1.6083e-01, -2.1194e-01, -2.6126e-01,  1.6456e-01,  1.3050e-01,\n",
            "         -1.9146e-01],\n",
            "        [-1.7825e-01,  3.5434e-02,  1.5692e-01,  1.1088e-01, -6.9951e-02,\n",
            "         -1.0870e-01, -9.6137e-02,  1.3611e-01, -2.3937e-01,  1.6721e-01,\n",
            "          1.8801e-01, -1.9323e-01,  2.0324e-01, -6.2429e-02,  1.5880e-01,\n",
            "         -5.8121e-02],\n",
            "        [-1.0596e-01, -1.6611e-01, -1.4898e-01,  5.2305e-02, -7.3840e-02,\n",
            "         -3.1080e-02, -5.2352e-02, -4.6398e-02, -3.7808e-02,  1.3646e-01,\n",
            "          9.8831e-02,  1.3883e-01, -5.0128e-02, -2.8572e-02,  4.6607e-03,\n",
            "          2.3017e-01],\n",
            "        [-1.1020e-01, -2.9993e-02, -3.9704e-02,  1.2827e-01, -3.1930e-01,\n",
            "         -1.1203e-01,  2.0531e-01,  6.1132e-02, -5.4656e-02, -3.2608e-03,\n",
            "          5.3649e-02,  3.5319e-01,  1.0129e-02,  6.3751e-02,  5.9926e-02,\n",
            "          1.5956e-01],\n",
            "        [-1.3170e-01,  1.9782e-01, -2.1456e-01,  6.0950e-02,  1.1064e-01,\n",
            "         -7.6895e-02,  4.7102e-02, -1.6304e-01, -9.9676e-02, -1.3243e-01,\n",
            "          2.1680e-02, -2.6495e-01, -1.4609e-01,  1.2606e-01, -9.0594e-02,\n",
            "         -2.3758e-01]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([ 0.3833, -0.0940,  0.3124,  0.2625,  0.2562,  0.4099, -0.0545,  0.1008,\n",
            "        -0.2769, -0.1244,  0.2642,  0.1762, -0.2542,  0.2976, -0.0159,  0.1640],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[ 0.3728,  0.1237,  0.1001,  0.1700,  0.1559,  0.4498,  0.1856,  0.0348,\n",
            "         -0.1522,  0.1291,  0.0546, -0.0125, -0.0075,  0.1864,  0.0647, -0.0037]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([-0.0724], dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NN_l1_l2_reg(\n",
              "  (hidden_layers): ModuleList(\n",
              "    (0): Linear(in_features=2, out_features=16, bias=True)\n",
              "    (1): Linear(in_features=16, out_features=16, bias=True)\n",
              "  )\n",
              "  (output_layer): Linear(in_features=16, out_features=1, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# train var scope"
      ],
      "metadata": {
        "id": "UWo2rOO_SLUR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_var_scope(model, num_epochs, learning_rate, test1):\n",
        "\n",
        "    padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors, padded_states_next_tensors, padded_states_current_tensors = test1.prepare()\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    # Enable anomaly detection\n",
        "    torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "\n",
        "        # Forward pass\n",
        "        # states_output, states_first_output, states_last_output = test1.pass_states(model, padded_state_tensors, states_first_tensor, states_last_tensor)\n",
        "        # sums_states_weight_diff = test1.states_weight_diff_sums(states_output, padded_weight_diff_tensors)\n",
        "        # gamma_weights_states_last_sub_states_first = test1.last_first_terms_operations(gamma_weights_last_tensor, states_last_output, states_first_output, weight_first_tensor)\n",
        "        # # sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, samples_all_shaping, samples_IS_SCOPE = test1.bootstrap_shaping_terms(sums_states_weight_diff, gamma_weights_states_last_sub_states_first, IS_tensor)\n",
        "\n",
        "        # samples_IS, sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, samples_all_shaping, samples_IS_SCOPE = test1.bootstrap_all_terms(sums_states_weight_diff, gamma_weights_states_last_sub_states_first, IS_tensor, padded_psi_tensors)\n",
        "\n",
        "\n",
        "        # Calculate MSE loss between states_output and padded_state_tensors\n",
        "        # mse_loss = F.mse_loss(states_output, padded_state_tensors)\n",
        "\n",
        "        # E_IS_sq, E_IS_all_sq, E_s_wdiff_sq, E_s_wdiff_all_sq, E_IS_SCOPE, E_IS_E_SCOPE, _, variance_loss, E_IS, E_SCOPE = calculate_shaped_variance_play(samples_IS, sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, samples_all_shaping, samples_IS_SCOPE)\n",
        "\n",
        "        timestep_bootstraps, rewards_bootstraps, weights_bootstraps, phi_states_next_bootstraps, phi_states_current_bootstraps = test1.pass_then_boostraps(model, padded_states_next_tensors, padded_states_current_tensors, padded_timestep_tensors, padded_reward_tensors, padded_weight_tensors)\n",
        "        IS_variance, variance_loss = test1.calc_variance_straight(timestep_bootstraps, weights_bootstraps, rewards_bootstraps, phi_states_next_bootstraps, phi_states_current_bootstraps)\n",
        "        print(f\"Epoch {epoch+1}\")\n",
        "        print(\"IS variance: \", IS_variance)\n",
        "        print(\"SCOPE Var loss: \", variance_loss)\n",
        "        # print(\"MSE loss: \", mse_loss.item())\n",
        "\n",
        "\n",
        "        tot = variance_loss\n",
        "        # tot = variance_loss + mse_loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Retain the graph to avoid clearing it before backward pass\n",
        "        tot.backward(retain_graph=True)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += tot.item()\n",
        "\n",
        "        print(f\"Total Loss: {total_loss}\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "    # Disable anomaly detection after running the code\n",
        "    torch.autograd.set_detect_anomaly(False)\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            print(f\"Parameter name: {name}\")\n",
        "            print(f\"Weights: {param.data}\")\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "c0xC288M7vT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UOqxfdgBmS81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fNLH1JIcmTJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test"
      ],
      "metadata": {
        "id": "40GxgnTBmj9x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b = action_probs_top_n_epsilon(q_table, 1, 0.4)\n",
        "pi_b = experiment_actions(200, env, P_pi_b)\n",
        "P_pi_e = action_probs_top_n_epsilon(q_table, 2, 0.05)\n",
        "pi_e = experiment_actions(200, env, P_pi_e)"
      ],
      "metadata": {
        "id": "FmgfU0K6mk6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_200 = CustomizableFeatureNet(input_dim=2, hidden_dims=[16, 32], output_dim=1, dtype = torch.float64)"
      ],
      "metadata": {
        "id": "911brDimm4wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_200 = SCOPE_straight(model_200, 0.9, 10000, pi_b, P_pi_b, P_pi_e, dtype = torch.float64)"
      ],
      "metadata": {
        "id": "U79ry5NxmnCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_200 = train_var_scope(model_200, 1000, 0.0005, test_200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pIcVizym9n_",
        "outputId": "e69cdfd5-0595-4226-80fb-a82cd7b0d07c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0008492256656322879\n",
            "----------------------------------------\n",
            "Epoch 22\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.000832036997470311\n",
            "----------------------------------------\n",
            "Epoch 23\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0008178091443168292\n",
            "----------------------------------------\n",
            "Epoch 24\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0008067588044517235\n",
            "----------------------------------------\n",
            "Epoch 25\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0007938512145564716\n",
            "----------------------------------------\n",
            "Epoch 26\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0007788995781305973\n",
            "----------------------------------------\n",
            "Epoch 27\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0007657443959582411\n",
            "----------------------------------------\n",
            "Epoch 28\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0007538666733296384\n",
            "----------------------------------------\n",
            "Epoch 29\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0007421691758702111\n",
            "----------------------------------------\n",
            "Epoch 30\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0007303255456230735\n",
            "----------------------------------------\n",
            "Epoch 31\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0007187112391046453\n",
            "----------------------------------------\n",
            "Epoch 32\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.000707883908565864\n",
            "----------------------------------------\n",
            "Epoch 33\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0006971014030871082\n",
            "----------------------------------------\n",
            "Epoch 34\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0006862588634799347\n",
            "----------------------------------------\n",
            "Epoch 35\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0006757597277906554\n",
            "----------------------------------------\n",
            "Epoch 36\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0006657211420834642\n",
            "----------------------------------------\n",
            "Epoch 37\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00065551527512402\n",
            "----------------------------------------\n",
            "Epoch 38\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0006457058049450084\n",
            "----------------------------------------\n",
            "Epoch 39\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0006359561093684281\n",
            "----------------------------------------\n",
            "Epoch 40\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0006268297890434793\n",
            "----------------------------------------\n",
            "Epoch 41\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0006176695790374126\n",
            "----------------------------------------\n",
            "Epoch 42\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0006088172295279874\n",
            "----------------------------------------\n",
            "Epoch 43\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0006001613262505393\n",
            "----------------------------------------\n",
            "Epoch 44\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0005917351211344535\n",
            "----------------------------------------\n",
            "Epoch 45\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0005834743861129547\n",
            "----------------------------------------\n",
            "Epoch 46\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0005753437649026478\n",
            "----------------------------------------\n",
            "Epoch 47\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0005674102836727932\n",
            "----------------------------------------\n",
            "Epoch 48\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0005595685919933554\n",
            "----------------------------------------\n",
            "Epoch 49\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.000551992504895417\n",
            "----------------------------------------\n",
            "Epoch 50\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0005444868933553543\n",
            "----------------------------------------\n",
            "Epoch 51\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0005371548163724429\n",
            "----------------------------------------\n",
            "Epoch 52\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0005299083217440924\n",
            "----------------------------------------\n",
            "Epoch 53\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0005228363198028344\n",
            "----------------------------------------\n",
            "Epoch 54\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0005158219587202258\n",
            "----------------------------------------\n",
            "Epoch 55\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0005088778763243133\n",
            "----------------------------------------\n",
            "Epoch 56\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0005020616816041798\n",
            "----------------------------------------\n",
            "Epoch 57\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0004952986833330397\n",
            "----------------------------------------\n",
            "Epoch 58\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0004886668705097123\n",
            "----------------------------------------\n",
            "Epoch 59\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00048214910421574147\n",
            "----------------------------------------\n",
            "Epoch 60\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0004757488869078596\n",
            "----------------------------------------\n",
            "Epoch 61\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00046944728948148724\n",
            "----------------------------------------\n",
            "Epoch 62\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0004632417046995436\n",
            "----------------------------------------\n",
            "Epoch 63\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00045707461168116657\n",
            "----------------------------------------\n",
            "Epoch 64\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00045102825216827223\n",
            "----------------------------------------\n",
            "Epoch 65\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00044507496219341197\n",
            "----------------------------------------\n",
            "Epoch 66\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0004391699970035594\n",
            "----------------------------------------\n",
            "Epoch 67\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0004333230599644562\n",
            "----------------------------------------\n",
            "Epoch 68\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00042761250144480274\n",
            "----------------------------------------\n",
            "Epoch 69\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0004219644492074685\n",
            "----------------------------------------\n",
            "Epoch 70\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0004164604380851949\n",
            "----------------------------------------\n",
            "Epoch 71\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0004110514097699362\n",
            "----------------------------------------\n",
            "Epoch 72\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0004057153133658589\n",
            "----------------------------------------\n",
            "Epoch 73\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0004004735708122344\n",
            "----------------------------------------\n",
            "Epoch 74\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00039543175676454563\n",
            "----------------------------------------\n",
            "Epoch 75\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0003904754894518335\n",
            "----------------------------------------\n",
            "Epoch 76\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0003855896335018986\n",
            "----------------------------------------\n",
            "Epoch 77\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00038081944363259194\n",
            "----------------------------------------\n",
            "Epoch 78\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0003761076287718471\n",
            "----------------------------------------\n",
            "Epoch 79\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00037148031388432314\n",
            "----------------------------------------\n",
            "Epoch 80\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00036694533068793947\n",
            "----------------------------------------\n",
            "Epoch 81\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0003624837490230216\n",
            "----------------------------------------\n",
            "Epoch 82\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0003581522064171912\n",
            "----------------------------------------\n",
            "Epoch 83\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00035390981479894247\n",
            "----------------------------------------\n",
            "Epoch 84\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0003497487072180543\n",
            "----------------------------------------\n",
            "Epoch 85\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0003456423814906023\n",
            "----------------------------------------\n",
            "Epoch 86\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0003415342148518471\n",
            "----------------------------------------\n",
            "Epoch 87\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00033748409519833525\n",
            "----------------------------------------\n",
            "Epoch 88\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00033357758121261124\n",
            "----------------------------------------\n",
            "Epoch 89\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00032966937145839447\n",
            "----------------------------------------\n",
            "Epoch 90\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0003257789056837663\n",
            "----------------------------------------\n",
            "Epoch 91\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00032201754209288264\n",
            "----------------------------------------\n",
            "Epoch 92\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0003183200983898995\n",
            "----------------------------------------\n",
            "Epoch 93\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0003146851804160395\n",
            "----------------------------------------\n",
            "Epoch 94\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00031110142682717515\n",
            "----------------------------------------\n",
            "Epoch 95\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0003075700186692655\n",
            "----------------------------------------\n",
            "Epoch 96\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0003040839840760883\n",
            "----------------------------------------\n",
            "Epoch 97\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0003006453888635111\n",
            "----------------------------------------\n",
            "Epoch 98\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0002972676159097015\n",
            "----------------------------------------\n",
            "Epoch 99\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00029397181536515573\n",
            "----------------------------------------\n",
            "Epoch 100\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.000290714618616006\n",
            "----------------------------------------\n",
            "Epoch 101\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00028754093491767526\n",
            "----------------------------------------\n",
            "Epoch 102\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00028436621835897314\n",
            "----------------------------------------\n",
            "Epoch 103\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0002812702834925871\n",
            "----------------------------------------\n",
            "Epoch 104\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0002782205293417825\n",
            "----------------------------------------\n",
            "Epoch 105\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00027517542848118186\n",
            "----------------------------------------\n",
            "Epoch 106\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0002721673910811486\n",
            "----------------------------------------\n",
            "Epoch 107\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0002691772934722593\n",
            "----------------------------------------\n",
            "Epoch 108\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0002662458741311763\n",
            "----------------------------------------\n",
            "Epoch 109\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00026334525372414023\n",
            "----------------------------------------\n",
            "Epoch 110\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00026048058207414274\n",
            "----------------------------------------\n",
            "Epoch 111\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.000257679029752464\n",
            "----------------------------------------\n",
            "Epoch 112\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00025491702413513233\n",
            "----------------------------------------\n",
            "Epoch 113\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00025218869607327197\n",
            "----------------------------------------\n",
            "Epoch 114\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0002495659451975771\n",
            "----------------------------------------\n",
            "Epoch 115\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0002470028098219896\n",
            "----------------------------------------\n",
            "Epoch 116\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00024446738640779373\n",
            "----------------------------------------\n",
            "Epoch 117\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00024197302723749767\n",
            "----------------------------------------\n",
            "Epoch 118\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00023949914758569896\n",
            "----------------------------------------\n",
            "Epoch 119\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00023706675344837175\n",
            "----------------------------------------\n",
            "Epoch 120\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00023467001993446638\n",
            "----------------------------------------\n",
            "Epoch 121\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00023230188876613452\n",
            "----------------------------------------\n",
            "Epoch 122\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00022996372596278763\n",
            "----------------------------------------\n",
            "Epoch 123\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0002276657162691316\n",
            "----------------------------------------\n",
            "Epoch 124\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00022540613135710726\n",
            "----------------------------------------\n",
            "Epoch 125\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00022318047154214616\n",
            "----------------------------------------\n",
            "Epoch 126\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00022097652743278528\n",
            "----------------------------------------\n",
            "Epoch 127\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00021880198498063093\n",
            "----------------------------------------\n",
            "Epoch 128\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0002166567722388153\n",
            "----------------------------------------\n",
            "Epoch 129\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0002145398967420797\n",
            "----------------------------------------\n",
            "Epoch 130\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00021244651154387546\n",
            "----------------------------------------\n",
            "Epoch 131\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0002103786889959395\n",
            "----------------------------------------\n",
            "Epoch 132\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00020834284407611194\n",
            "----------------------------------------\n",
            "Epoch 133\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00020633337019717728\n",
            "----------------------------------------\n",
            "Epoch 134\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0002043474151014792\n",
            "----------------------------------------\n",
            "Epoch 135\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00020238983145584003\n",
            "----------------------------------------\n",
            "Epoch 136\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00020046381092816209\n",
            "----------------------------------------\n",
            "Epoch 137\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001985589834736423\n",
            "----------------------------------------\n",
            "Epoch 138\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001966728843224388\n",
            "----------------------------------------\n",
            "Epoch 139\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001948101544284598\n",
            "----------------------------------------\n",
            "Epoch 140\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00019297127622431426\n",
            "----------------------------------------\n",
            "Epoch 141\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.000191153527420611\n",
            "----------------------------------------\n",
            "Epoch 142\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00018935645490605007\n",
            "----------------------------------------\n",
            "Epoch 143\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00018758075254708326\n",
            "----------------------------------------\n",
            "Epoch 144\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001858269587543017\n",
            "----------------------------------------\n",
            "Epoch 145\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00018409581733747497\n",
            "----------------------------------------\n",
            "Epoch 146\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001823877852810283\n",
            "----------------------------------------\n",
            "Epoch 147\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001806990919695813\n",
            "----------------------------------------\n",
            "Epoch 148\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00017902986656422035\n",
            "----------------------------------------\n",
            "Epoch 149\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00017738397061152375\n",
            "----------------------------------------\n",
            "Epoch 150\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00017575113374770711\n",
            "----------------------------------------\n",
            "Epoch 151\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00017412878630337895\n",
            "----------------------------------------\n",
            "Epoch 152\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00017252730053461684\n",
            "----------------------------------------\n",
            "Epoch 153\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001709447546339227\n",
            "----------------------------------------\n",
            "Epoch 154\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00016937549791380736\n",
            "----------------------------------------\n",
            "Epoch 155\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00016780965197323638\n",
            "----------------------------------------\n",
            "Epoch 156\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00016626873679654024\n",
            "----------------------------------------\n",
            "Epoch 157\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00016476819395158548\n",
            "----------------------------------------\n",
            "Epoch 158\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001632822592991993\n",
            "----------------------------------------\n",
            "Epoch 159\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00016181057413798233\n",
            "----------------------------------------\n",
            "Epoch 160\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00016035359810366101\n",
            "----------------------------------------\n",
            "Epoch 161\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001589068409013391\n",
            "----------------------------------------\n",
            "Epoch 162\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00015746872186145762\n",
            "----------------------------------------\n",
            "Epoch 163\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001560398248287147\n",
            "----------------------------------------\n",
            "Epoch 164\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00015461560722389406\n",
            "----------------------------------------\n",
            "Epoch 165\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00015319526770349903\n",
            "----------------------------------------\n",
            "Epoch 166\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00015178367998271887\n",
            "----------------------------------------\n",
            "Epoch 167\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00015038312943554743\n",
            "----------------------------------------\n",
            "Epoch 168\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00014899510745470528\n",
            "----------------------------------------\n",
            "Epoch 169\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001476054614344439\n",
            "----------------------------------------\n",
            "Epoch 170\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00014621893399159946\n",
            "----------------------------------------\n",
            "Epoch 171\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00014485502160647672\n",
            "----------------------------------------\n",
            "Epoch 172\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00014350339452472911\n",
            "----------------------------------------\n",
            "Epoch 173\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00014216087793788164\n",
            "----------------------------------------\n",
            "Epoch 174\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.000140830490821699\n",
            "----------------------------------------\n",
            "Epoch 175\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00013950732187264974\n",
            "----------------------------------------\n",
            "Epoch 176\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00013820179762622683\n",
            "----------------------------------------\n",
            "Epoch 177\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001368967432458594\n",
            "----------------------------------------\n",
            "Epoch 178\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00013559422535950943\n",
            "----------------------------------------\n",
            "Epoch 179\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001343162810900871\n",
            "----------------------------------------\n",
            "Epoch 180\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00013303815065772028\n",
            "----------------------------------------\n",
            "Epoch 181\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00013177523769975145\n",
            "----------------------------------------\n",
            "Epoch 182\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00013052931057876144\n",
            "----------------------------------------\n",
            "Epoch 183\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00012930307436596485\n",
            "----------------------------------------\n",
            "Epoch 184\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00012809870006286737\n",
            "----------------------------------------\n",
            "Epoch 185\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00012692767144281705\n",
            "----------------------------------------\n",
            "Epoch 186\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001257186136946716\n",
            "----------------------------------------\n",
            "Epoch 187\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00012440407716868436\n",
            "----------------------------------------\n",
            "Epoch 188\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00012311919427811604\n",
            "----------------------------------------\n",
            "Epoch 189\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00012197322557004407\n",
            "----------------------------------------\n",
            "Epoch 190\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00012087626076809482\n",
            "----------------------------------------\n",
            "Epoch 191\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00011971664442531696\n",
            "----------------------------------------\n",
            "Epoch 192\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001185639369531777\n",
            "----------------------------------------\n",
            "Epoch 193\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00011752053728073698\n",
            "----------------------------------------\n",
            "Epoch 194\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001164592934238245\n",
            "----------------------------------------\n",
            "Epoch 195\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00011533870288203292\n",
            "----------------------------------------\n",
            "Epoch 196\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00011426861724768149\n",
            "----------------------------------------\n",
            "Epoch 197\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00011326264215393649\n",
            "----------------------------------------\n",
            "Epoch 198\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00011222679364241443\n",
            "----------------------------------------\n",
            "Epoch 199\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00011119125356414037\n",
            "----------------------------------------\n",
            "Epoch 200\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00011020430921033742\n",
            "----------------------------------------\n",
            "Epoch 201\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00010922351280646204\n",
            "----------------------------------------\n",
            "Epoch 202\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00010822126360227963\n",
            "----------------------------------------\n",
            "Epoch 203\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00010723283976101278\n",
            "----------------------------------------\n",
            "Epoch 204\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00010627933906459941\n",
            "----------------------------------------\n",
            "Epoch 205\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00010532171637350396\n",
            "----------------------------------------\n",
            "Epoch 206\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00010435902241609148\n",
            "----------------------------------------\n",
            "Epoch 207\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00010341922065436709\n",
            "----------------------------------------\n",
            "Epoch 208\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00010248465969284747\n",
            "----------------------------------------\n",
            "Epoch 209\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001015440703268652\n",
            "----------------------------------------\n",
            "Epoch 210\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00010061149169569957\n",
            "----------------------------------------\n",
            "Epoch 211\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.9697e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.969677409070994e-05\n",
            "----------------------------------------\n",
            "Epoch 212\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.8783e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.878335989654519e-05\n",
            "----------------------------------------\n",
            "Epoch 213\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.7873e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.787279168785962e-05\n",
            "----------------------------------------\n",
            "Epoch 214\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.6976e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.69758197476198e-05\n",
            "----------------------------------------\n",
            "Epoch 215\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.6105e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.610492493381914e-05\n",
            "----------------------------------------\n",
            "Epoch 216\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.5233e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.523263355361816e-05\n",
            "----------------------------------------\n",
            "Epoch 217\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.4360e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.435985163446957e-05\n",
            "----------------------------------------\n",
            "Epoch 218\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.3505e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.35053755766774e-05\n",
            "----------------------------------------\n",
            "Epoch 219\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.2670e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.266979831918592e-05\n",
            "----------------------------------------\n",
            "Epoch 220\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.1839e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.183938236310378e-05\n",
            "----------------------------------------\n",
            "Epoch 221\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.0988e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.098814326320734e-05\n",
            "----------------------------------------\n",
            "Epoch 222\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.0143e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.014278646659148e-05\n",
            "----------------------------------------\n",
            "Epoch 223\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.9306e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.930625427545809e-05\n",
            "----------------------------------------\n",
            "Epoch 224\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.8480e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.847991591928882e-05\n",
            "----------------------------------------\n",
            "Epoch 225\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.7656e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.765628041198527e-05\n",
            "----------------------------------------\n",
            "Epoch 226\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.6843e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.68429811717542e-05\n",
            "----------------------------------------\n",
            "Epoch 227\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.6045e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.604519059921131e-05\n",
            "----------------------------------------\n",
            "Epoch 228\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.5246e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.524567753589901e-05\n",
            "----------------------------------------\n",
            "Epoch 229\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.4455e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.445540310284939e-05\n",
            "----------------------------------------\n",
            "Epoch 230\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.3675e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.367503866475242e-05\n",
            "----------------------------------------\n",
            "Epoch 231\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.2888e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.28877858052401e-05\n",
            "----------------------------------------\n",
            "Epoch 232\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.2091e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.209147611315046e-05\n",
            "----------------------------------------\n",
            "Epoch 233\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.1303e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.130269964015309e-05\n",
            "----------------------------------------\n",
            "Epoch 234\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.0524e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.052404453516736e-05\n",
            "----------------------------------------\n",
            "Epoch 235\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.9769e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.976872594309536e-05\n",
            "----------------------------------------\n",
            "Epoch 236\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.9008e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.900798278279476e-05\n",
            "----------------------------------------\n",
            "Epoch 237\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.8226e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.82262197504637e-05\n",
            "----------------------------------------\n",
            "Epoch 238\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.7463e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.746266993315425e-05\n",
            "----------------------------------------\n",
            "Epoch 239\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.6717e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.67171917254087e-05\n",
            "----------------------------------------\n",
            "Epoch 240\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.5976e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.597618400565901e-05\n",
            "----------------------------------------\n",
            "Epoch 241\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.5234e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.523359023477829e-05\n",
            "----------------------------------------\n",
            "Epoch 242\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.4502e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.45021281678714e-05\n",
            "----------------------------------------\n",
            "Epoch 243\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3773e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.377297094007641e-05\n",
            "----------------------------------------\n",
            "Epoch 244\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3053e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.305314289660489e-05\n",
            "----------------------------------------\n",
            "Epoch 245\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2360e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.236024390150411e-05\n",
            "----------------------------------------\n",
            "Epoch 246\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1663e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.16630498391982e-05\n",
            "----------------------------------------\n",
            "Epoch 247\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0977e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.097702283039156e-05\n",
            "----------------------------------------\n",
            "Epoch 248\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0308e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.030772379447493e-05\n",
            "----------------------------------------\n",
            "Epoch 249\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9643e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.964279675343819e-05\n",
            "----------------------------------------\n",
            "Epoch 250\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8975e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.897455842562479e-05\n",
            "----------------------------------------\n",
            "Epoch 251\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8315e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.8315215636455e-05\n",
            "----------------------------------------\n",
            "Epoch 252\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7702e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.770222175028961e-05\n",
            "----------------------------------------\n",
            "Epoch 253\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7116e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.711640575376605e-05\n",
            "----------------------------------------\n",
            "Epoch 254\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6542e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.654200496153875e-05\n",
            "----------------------------------------\n",
            "Epoch 255\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5981e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.598050820401602e-05\n",
            "----------------------------------------\n",
            "Epoch 256\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5400e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.539972867814303e-05\n",
            "----------------------------------------\n",
            "Epoch 257\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4821e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.482105817145616e-05\n",
            "----------------------------------------\n",
            "Epoch 258\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4261e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.426106372951936e-05\n",
            "----------------------------------------\n",
            "Epoch 259\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3702e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.370162752683761e-05\n",
            "----------------------------------------\n",
            "Epoch 260\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3136e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.313604238992362e-05\n",
            "----------------------------------------\n",
            "Epoch 261\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.2593e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.259344745237913e-05\n",
            "----------------------------------------\n",
            "Epoch 262\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.2057e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.205717658728037e-05\n",
            "----------------------------------------\n",
            "Epoch 263\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.1516e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.151618398033388e-05\n",
            "----------------------------------------\n",
            "Epoch 264\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.0991e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.099073526508293e-05\n",
            "----------------------------------------\n",
            "Epoch 265\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.0472e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.0471672927703575e-05\n",
            "----------------------------------------\n",
            "Epoch 266\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.9963e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.996324473357272e-05\n",
            "----------------------------------------\n",
            "Epoch 267\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.9476e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.947636380901482e-05\n",
            "----------------------------------------\n",
            "Epoch 268\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.8994e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.899372743628718e-05\n",
            "----------------------------------------\n",
            "Epoch 269\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.8505e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.8504877289483376e-05\n",
            "----------------------------------------\n",
            "Epoch 270\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.8037e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.803672900925304e-05\n",
            "----------------------------------------\n",
            "Epoch 271\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.7575e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.757533646635286e-05\n",
            "----------------------------------------\n",
            "Epoch 272\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.7113e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.7113019288540736e-05\n",
            "----------------------------------------\n",
            "Epoch 273\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.6658e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.665847843405303e-05\n",
            "----------------------------------------\n",
            "Epoch 274\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.6213e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.6212753710204996e-05\n",
            "----------------------------------------\n",
            "Epoch 275\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.5769e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.576871097714104e-05\n",
            "----------------------------------------\n",
            "Epoch 276\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.5335e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.53349274830648e-05\n",
            "----------------------------------------\n",
            "Epoch 277\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.4908e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.490777826260673e-05\n",
            "----------------------------------------\n",
            "Epoch 278\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.4483e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.448341001642345e-05\n",
            "----------------------------------------\n",
            "Epoch 279\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.4064e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.4064165372956725e-05\n",
            "----------------------------------------\n",
            "Epoch 280\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.3653e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.365268471371259e-05\n",
            "----------------------------------------\n",
            "Epoch 281\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.3246e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.3245848267945756e-05\n",
            "----------------------------------------\n",
            "Epoch 282\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.2842e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.284200317169358e-05\n",
            "----------------------------------------\n",
            "Epoch 283\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.2449e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.244853348082652e-05\n",
            "----------------------------------------\n",
            "Epoch 284\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.2058e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.205816813909749e-05\n",
            "----------------------------------------\n",
            "Epoch 285\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.1672e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.167185029830273e-05\n",
            "----------------------------------------\n",
            "Epoch 286\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.1288e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.1287687115397415e-05\n",
            "----------------------------------------\n",
            "Epoch 287\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.0911e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.091104628457276e-05\n",
            "----------------------------------------\n",
            "Epoch 288\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.0538e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.053780690285663e-05\n",
            "----------------------------------------\n",
            "Epoch 289\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.0169e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.016907290713931e-05\n",
            "----------------------------------------\n",
            "Epoch 290\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.9800e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.980032913959201e-05\n",
            "----------------------------------------\n",
            "Epoch 291\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.9447e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.944722636349524e-05\n",
            "----------------------------------------\n",
            "Epoch 292\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.9087e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.908725615747006e-05\n",
            "----------------------------------------\n",
            "Epoch 293\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.8734e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.873403874893399e-05\n",
            "----------------------------------------\n",
            "Epoch 294\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.8391e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.839098239765689e-05\n",
            "----------------------------------------\n",
            "Epoch 295\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.8042e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.804195425956049e-05\n",
            "----------------------------------------\n",
            "Epoch 296\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.7699e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.7699016412675674e-05\n",
            "----------------------------------------\n",
            "Epoch 297\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.7364e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.736420606014769e-05\n",
            "----------------------------------------\n",
            "Epoch 298\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.7034e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.703361545076622e-05\n",
            "----------------------------------------\n",
            "Epoch 299\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.6701e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.670104210312564e-05\n",
            "----------------------------------------\n",
            "Epoch 300\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.6374e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.637362142046941e-05\n",
            "----------------------------------------\n",
            "Epoch 301\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.6054e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.6054495865686785e-05\n",
            "----------------------------------------\n",
            "Epoch 302\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.5737e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.5736593336108175e-05\n",
            "----------------------------------------\n",
            "Epoch 303\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.5420e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.54204996567932e-05\n",
            "----------------------------------------\n",
            "Epoch 304\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.5108e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.510752497015295e-05\n",
            "----------------------------------------\n",
            "Epoch 305\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.4799e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.4799312244357624e-05\n",
            "----------------------------------------\n",
            "Epoch 306\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.4493e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.449283518855385e-05\n",
            "----------------------------------------\n",
            "Epoch 307\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.4189e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.418855865310275e-05\n",
            "----------------------------------------\n",
            "Epoch 308\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.3887e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.3886564498877126e-05\n",
            "----------------------------------------\n",
            "Epoch 309\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.3589e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.358852927114633e-05\n",
            "----------------------------------------\n",
            "Epoch 310\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.3292e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.329234679500792e-05\n",
            "----------------------------------------\n",
            "Epoch 311\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.3001e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.300096193925238e-05\n",
            "----------------------------------------\n",
            "Epoch 312\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.2713e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.27131341388663e-05\n",
            "----------------------------------------\n",
            "Epoch 313\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.2426e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.24258690960057e-05\n",
            "----------------------------------------\n",
            "Epoch 314\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.2142e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.214246737842867e-05\n",
            "----------------------------------------\n",
            "Epoch 315\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.1860e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.186002219363668e-05\n",
            "----------------------------------------\n",
            "Epoch 316\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.1580e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.1580304956656985e-05\n",
            "----------------------------------------\n",
            "Epoch 317\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.1300e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.1300166107670276e-05\n",
            "----------------------------------------\n",
            "Epoch 318\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.1021e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.1021377296911025e-05\n",
            "----------------------------------------\n",
            "Epoch 319\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.0741e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.074067824852833e-05\n",
            "----------------------------------------\n",
            "Epoch 320\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.0460e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.046027264010877e-05\n",
            "----------------------------------------\n",
            "Epoch 321\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.0181e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.018076411126676e-05\n",
            "----------------------------------------\n",
            "Epoch 322\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.9903e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.990324351557248e-05\n",
            "----------------------------------------\n",
            "Epoch 323\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.9627e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.9627310512778886e-05\n",
            "----------------------------------------\n",
            "Epoch 324\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.9357e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.9356599173565026e-05\n",
            "----------------------------------------\n",
            "Epoch 325\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.9084e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.908405524791476e-05\n",
            "----------------------------------------\n",
            "Epoch 326\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.8813e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.8812922690681225e-05\n",
            "----------------------------------------\n",
            "Epoch 327\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.8543e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.8543174461272455e-05\n",
            "----------------------------------------\n",
            "Epoch 328\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.8273e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.8273267673638243e-05\n",
            "----------------------------------------\n",
            "Epoch 329\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.8011e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.801086596798809e-05\n",
            "----------------------------------------\n",
            "Epoch 330\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.7747e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.774661066157103e-05\n",
            "----------------------------------------\n",
            "Epoch 331\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.7481e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.74807408492115e-05\n",
            "----------------------------------------\n",
            "Epoch 332\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.7220e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.722009498015186e-05\n",
            "----------------------------------------\n",
            "Epoch 333\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.6964e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.696391533399378e-05\n",
            "----------------------------------------\n",
            "Epoch 334\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.6705e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.670514778304468e-05\n",
            "----------------------------------------\n",
            "Epoch 335\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.6456e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.645607882622268e-05\n",
            "----------------------------------------\n",
            "Epoch 336\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.6209e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.620887551657613e-05\n",
            "----------------------------------------\n",
            "Epoch 337\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.5962e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.5962129599482044e-05\n",
            "----------------------------------------\n",
            "Epoch 338\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.5717e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.571652022907381e-05\n",
            "----------------------------------------\n",
            "Epoch 339\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.5473e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.54727578233288e-05\n",
            "----------------------------------------\n",
            "Epoch 340\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.5232e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.5232076211667935e-05\n",
            "----------------------------------------\n",
            "Epoch 341\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.4996e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.499647598281811e-05\n",
            "----------------------------------------\n",
            "Epoch 342\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.4765e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.476507410630298e-05\n",
            "----------------------------------------\n",
            "Epoch 343\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.4527e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.4527102922746365e-05\n",
            "----------------------------------------\n",
            "Epoch 344\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.4295e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.429497861910557e-05\n",
            "----------------------------------------\n",
            "Epoch 345\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.4066e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.4065595822805726e-05\n",
            "----------------------------------------\n",
            "Epoch 346\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.3839e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.3838730341864375e-05\n",
            "----------------------------------------\n",
            "Epoch 347\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.3617e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.361732272030674e-05\n",
            "----------------------------------------\n",
            "Epoch 348\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.3398e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.339790885123833e-05\n",
            "----------------------------------------\n",
            "Epoch 349\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.3183e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.3183031258184304e-05\n",
            "----------------------------------------\n",
            "Epoch 350\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.2965e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.296462021882803e-05\n",
            "----------------------------------------\n",
            "Epoch 351\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.2754e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.2753967063140575e-05\n",
            "----------------------------------------\n",
            "Epoch 352\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.2547e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.254742624683552e-05\n",
            "----------------------------------------\n",
            "Epoch 353\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.2341e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.234098979016392e-05\n",
            "----------------------------------------\n",
            "Epoch 354\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.2136e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.213612970216434e-05\n",
            "----------------------------------------\n",
            "Epoch 355\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.1933e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.1933096691888275e-05\n",
            "----------------------------------------\n",
            "Epoch 356\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.1731e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.1731352755415303e-05\n",
            "----------------------------------------\n",
            "Epoch 357\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.1529e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.1528698844340294e-05\n",
            "----------------------------------------\n",
            "Epoch 358\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.1324e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.132389925184917e-05\n",
            "----------------------------------------\n",
            "Epoch 359\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.1124e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.1123505979830835e-05\n",
            "----------------------------------------\n",
            "Epoch 360\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.0924e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.092428357645794e-05\n",
            "----------------------------------------\n",
            "Epoch 361\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.0726e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.0726477289141325e-05\n",
            "----------------------------------------\n",
            "Epoch 362\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.0533e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.0533185541762077e-05\n",
            "----------------------------------------\n",
            "Epoch 363\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.0342e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.0341954897718023e-05\n",
            "----------------------------------------\n",
            "Epoch 364\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.0153e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.015280160167472e-05\n",
            "----------------------------------------\n",
            "Epoch 365\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.9968e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.99678468118364e-05\n",
            "----------------------------------------\n",
            "Epoch 366\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.9786e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.9786352860800152e-05\n",
            "----------------------------------------\n",
            "Epoch 367\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.9602e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.9601761435657524e-05\n",
            "----------------------------------------\n",
            "Epoch 368\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.9421e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.9420716377132473e-05\n",
            "----------------------------------------\n",
            "Epoch 369\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.9239e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.923944645598509e-05\n",
            "----------------------------------------\n",
            "Epoch 370\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.9061e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.906081881145796e-05\n",
            "----------------------------------------\n",
            "Epoch 371\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.8885e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.8884577157553185e-05\n",
            "----------------------------------------\n",
            "Epoch 372\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.8708e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.870755882730994e-05\n",
            "----------------------------------------\n",
            "Epoch 373\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.8532e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.8531896822173865e-05\n",
            "----------------------------------------\n",
            "Epoch 374\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.8359e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.8358575559953866e-05\n",
            "----------------------------------------\n",
            "Epoch 375\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.8187e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.818710442596032e-05\n",
            "----------------------------------------\n",
            "Epoch 376\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.8017e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.801693561541207e-05\n",
            "----------------------------------------\n",
            "Epoch 377\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.7848e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.7848416772059425e-05\n",
            "----------------------------------------\n",
            "Epoch 378\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.7681e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.7680500128531057e-05\n",
            "----------------------------------------\n",
            "Epoch 379\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.7514e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.751419461686585e-05\n",
            "----------------------------------------\n",
            "Epoch 380\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.7348e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.734784383544903e-05\n",
            "----------------------------------------\n",
            "Epoch 381\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.7186e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.7185931422522828e-05\n",
            "----------------------------------------\n",
            "Epoch 382\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.7023e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.7023125039210853e-05\n",
            "----------------------------------------\n",
            "Epoch 383\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.6863e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.6863493479831305e-05\n",
            "----------------------------------------\n",
            "Epoch 384\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.6703e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.670337194452883e-05\n",
            "----------------------------------------\n",
            "Epoch 385\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.6544e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.654419782910289e-05\n",
            "----------------------------------------\n",
            "Epoch 386\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.6389e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.6388700967940504e-05\n",
            "----------------------------------------\n",
            "Epoch 387\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.6237e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.6236880869231954e-05\n",
            "----------------------------------------\n",
            "Epoch 388\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.6086e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.6085819491730384e-05\n",
            "----------------------------------------\n",
            "Epoch 389\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.5939e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.593896646818686e-05\n",
            "----------------------------------------\n",
            "Epoch 390\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.5789e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.5789407186383366e-05\n",
            "----------------------------------------\n",
            "Epoch 391\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.5644e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.5643708177398852e-05\n",
            "----------------------------------------\n",
            "Epoch 392\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.5500e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.5499624871587048e-05\n",
            "----------------------------------------\n",
            "Epoch 393\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.5355e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.535532471342399e-05\n",
            "----------------------------------------\n",
            "Epoch 394\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.5213e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.5212757055899176e-05\n",
            "----------------------------------------\n",
            "Epoch 395\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.5072e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.5071699817538887e-05\n",
            "----------------------------------------\n",
            "Epoch 396\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.4933e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.493262536643489e-05\n",
            "----------------------------------------\n",
            "Epoch 397\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.4794e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.4794294381524616e-05\n",
            "----------------------------------------\n",
            "Epoch 398\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.4656e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.4656222111300847e-05\n",
            "----------------------------------------\n",
            "Epoch 399\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.4520e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.452047769151297e-05\n",
            "----------------------------------------\n",
            "Epoch 400\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.4386e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.438598920121162e-05\n",
            "----------------------------------------\n",
            "Epoch 401\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.4252e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.4252336504901778e-05\n",
            "----------------------------------------\n",
            "Epoch 402\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.4121e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.4120600911082388e-05\n",
            "----------------------------------------\n",
            "Epoch 403\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.3989e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.3989189377619764e-05\n",
            "----------------------------------------\n",
            "Epoch 404\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.3861e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.3861140146277532e-05\n",
            "----------------------------------------\n",
            "Epoch 405\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.3732e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.3732133377032427e-05\n",
            "----------------------------------------\n",
            "Epoch 406\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.3607e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.3606626665311617e-05\n",
            "----------------------------------------\n",
            "Epoch 407\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.3482e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.348188999480035e-05\n",
            "----------------------------------------\n",
            "Epoch 408\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.3355e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.3355472861304606e-05\n",
            "----------------------------------------\n",
            "Epoch 409\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.3230e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.3229766814136952e-05\n",
            "----------------------------------------\n",
            "Epoch 410\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.3104e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.310436656111011e-05\n",
            "----------------------------------------\n",
            "Epoch 411\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.2980e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.297972945239816e-05\n",
            "----------------------------------------\n",
            "Epoch 412\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.2856e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.2856254769874023e-05\n",
            "----------------------------------------\n",
            "Epoch 413\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.2731e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.2730639048937134e-05\n",
            "----------------------------------------\n",
            "Epoch 414\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.2608e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.260753688836752e-05\n",
            "----------------------------------------\n",
            "Epoch 415\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.2485e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.2484807601067045e-05\n",
            "----------------------------------------\n",
            "Epoch 416\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.2367e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.236660147184186e-05\n",
            "----------------------------------------\n",
            "Epoch 417\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.2249e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.224896625176123e-05\n",
            "----------------------------------------\n",
            "Epoch 418\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.2130e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.2130331333236658e-05\n",
            "----------------------------------------\n",
            "Epoch 419\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.2013e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.201331193753736e-05\n",
            "----------------------------------------\n",
            "Epoch 420\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.1899e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.189871441964559e-05\n",
            "----------------------------------------\n",
            "Epoch 421\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.1786e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.178604235923495e-05\n",
            "----------------------------------------\n",
            "Epoch 422\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.1672e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.1672329830814667e-05\n",
            "----------------------------------------\n",
            "Epoch 423\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.1561e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.156052820502702e-05\n",
            "----------------------------------------\n",
            "Epoch 424\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.1448e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.1447777429019927e-05\n",
            "----------------------------------------\n",
            "Epoch 425\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.1340e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.1340203138769182e-05\n",
            "----------------------------------------\n",
            "Epoch 426\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.1228e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.122849526024304e-05\n",
            "----------------------------------------\n",
            "Epoch 427\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.1121e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.1121202014858878e-05\n",
            "----------------------------------------\n",
            "Epoch 428\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.1015e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.101464024934643e-05\n",
            "----------------------------------------\n",
            "Epoch 429\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0908e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.090780466993527e-05\n",
            "----------------------------------------\n",
            "Epoch 430\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0803e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.0802669561112895e-05\n",
            "----------------------------------------\n",
            "Epoch 431\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0699e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.0699277092889588e-05\n",
            "----------------------------------------\n",
            "Epoch 432\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0596e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.0596134505556497e-05\n",
            "----------------------------------------\n",
            "Epoch 433\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0495e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.0494959421655e-05\n",
            "----------------------------------------\n",
            "Epoch 434\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0394e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.0393504773549608e-05\n",
            "----------------------------------------\n",
            "Epoch 435\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0293e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.0292973013855927e-05\n",
            "----------------------------------------\n",
            "Epoch 436\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0192e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.0192416726704118e-05\n",
            "----------------------------------------\n",
            "Epoch 437\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0092e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.009183223398696e-05\n",
            "----------------------------------------\n",
            "Epoch 438\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9992e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.999158992109217e-05\n",
            "----------------------------------------\n",
            "Epoch 439\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9891e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.9891422384120074e-05\n",
            "----------------------------------------\n",
            "Epoch 440\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9792e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.979216785937777e-05\n",
            "----------------------------------------\n",
            "Epoch 441\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9692e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.9692416269238992e-05\n",
            "----------------------------------------\n",
            "Epoch 442\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9593e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.9592931401757175e-05\n",
            "----------------------------------------\n",
            "Epoch 443\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9495e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.9494554860774023e-05\n",
            "----------------------------------------\n",
            "Epoch 444\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9398e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.9397953354304037e-05\n",
            "----------------------------------------\n",
            "Epoch 445\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9302e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.930209545470215e-05\n",
            "----------------------------------------\n",
            "Epoch 446\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9207e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.9206778996021408e-05\n",
            "----------------------------------------\n",
            "Epoch 447\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9113e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.9113254234977327e-05\n",
            "----------------------------------------\n",
            "Epoch 448\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9020e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.9019701785588482e-05\n",
            "----------------------------------------\n",
            "Epoch 449\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8927e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8926752179458734e-05\n",
            "----------------------------------------\n",
            "Epoch 450\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8836e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8835796686918132e-05\n",
            "----------------------------------------\n",
            "Epoch 451\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8745e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.87450241339437e-05\n",
            "----------------------------------------\n",
            "Epoch 452\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8655e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8654538954842562e-05\n",
            "----------------------------------------\n",
            "Epoch 453\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8565e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8565150988417155e-05\n",
            "----------------------------------------\n",
            "Epoch 454\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8477e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.847709347057959e-05\n",
            "----------------------------------------\n",
            "Epoch 455\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8390e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8389731639103224e-05\n",
            "----------------------------------------\n",
            "Epoch 456\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8303e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8302783463865627e-05\n",
            "----------------------------------------\n",
            "Epoch 457\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8215e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8214857097142336e-05\n",
            "----------------------------------------\n",
            "Epoch 458\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8129e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8128720934006212e-05\n",
            "----------------------------------------\n",
            "Epoch 459\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8043e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.804266788917738e-05\n",
            "----------------------------------------\n",
            "Epoch 460\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7957e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.7957274338526418e-05\n",
            "----------------------------------------\n",
            "Epoch 461\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7873e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.7873255212023606e-05\n",
            "----------------------------------------\n",
            "Epoch 462\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7791e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.779063946834054e-05\n",
            "----------------------------------------\n",
            "Epoch 463\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7708e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.770802216897308e-05\n",
            "----------------------------------------\n",
            "Epoch 464\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7627e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.762659969324139e-05\n",
            "----------------------------------------\n",
            "Epoch 465\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7546e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.7546331469657008e-05\n",
            "----------------------------------------\n",
            "Epoch 466\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7469e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.746864035205386e-05\n",
            "----------------------------------------\n",
            "Epoch 467\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7392e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.739151021747901e-05\n",
            "----------------------------------------\n",
            "Epoch 468\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7314e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.73139029512958e-05\n",
            "----------------------------------------\n",
            "Epoch 469\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7237e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.7236710599925994e-05\n",
            "----------------------------------------\n",
            "Epoch 470\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7159e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.715911809498747e-05\n",
            "----------------------------------------\n",
            "Epoch 471\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7082e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.708191352659031e-05\n",
            "----------------------------------------\n",
            "Epoch 472\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7005e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.7005262697572185e-05\n",
            "----------------------------------------\n",
            "Epoch 473\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.6928e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.6927973083020383e-05\n",
            "----------------------------------------\n",
            "Epoch 474\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.6853e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.6852547893865636e-05\n",
            "----------------------------------------\n",
            "Epoch 475\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.6778e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.6778307054558186e-05\n",
            "----------------------------------------\n",
            "Epoch 476\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.6705e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.670502756884706e-05\n",
            "----------------------------------------\n",
            "Epoch 477\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.6633e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.663301490671409e-05\n",
            "----------------------------------------\n",
            "Epoch 478\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.6562e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.6561971869183986e-05\n",
            "----------------------------------------\n",
            "Epoch 479\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.6492e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.6491785031238073e-05\n",
            "----------------------------------------\n",
            "Epoch 480\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.6423e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.642274963991396e-05\n",
            "----------------------------------------\n",
            "Epoch 481\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.6354e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.6353731192078812e-05\n",
            "----------------------------------------\n",
            "Epoch 482\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.6285e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.6285349431132467e-05\n",
            "----------------------------------------\n",
            "Epoch 483\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.6217e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.6217367325363588e-05\n",
            "----------------------------------------\n",
            "Epoch 484\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.6150e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.6150050515679848e-05\n",
            "----------------------------------------\n",
            "Epoch 485\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.6083e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.6082915428412144e-05\n",
            "----------------------------------------\n",
            "Epoch 486\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.6016e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.6015979152122895e-05\n",
            "----------------------------------------\n",
            "Epoch 487\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.5950e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.594963551359844e-05\n",
            "----------------------------------------\n",
            "Epoch 488\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.5884e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.5883806895374583e-05\n",
            "----------------------------------------\n",
            "Epoch 489\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.5818e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.5818153318074477e-05\n",
            "----------------------------------------\n",
            "Epoch 490\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.5753e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.575308359263744e-05\n",
            "----------------------------------------\n",
            "Epoch 491\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.5689e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.5688642018873506e-05\n",
            "----------------------------------------\n",
            "Epoch 492\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.5624e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.562365422278097e-05\n",
            "----------------------------------------\n",
            "Epoch 493\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.5560e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.555953189594072e-05\n",
            "----------------------------------------\n",
            "Epoch 494\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.5496e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.54958877636794e-05\n",
            "----------------------------------------\n",
            "Epoch 495\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.5432e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.5432485288769504e-05\n",
            "----------------------------------------\n",
            "Epoch 496\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.5369e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.5369176800630954e-05\n",
            "----------------------------------------\n",
            "Epoch 497\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.5306e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.530629581785336e-05\n",
            "----------------------------------------\n",
            "Epoch 498\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.5244e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.5244048797021676e-05\n",
            "----------------------------------------\n",
            "Epoch 499\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.5182e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.5182087726207302e-05\n",
            "----------------------------------------\n",
            "Epoch 500\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.5120e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.5120433276237812e-05\n",
            "----------------------------------------\n",
            "Epoch 501\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.5059e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.5058893194364405e-05\n",
            "----------------------------------------\n",
            "Epoch 502\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4998e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.4997875960890615e-05\n",
            "----------------------------------------\n",
            "Epoch 503\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4938e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.4937688852518146e-05\n",
            "----------------------------------------\n",
            "Epoch 504\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4878e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.4878287872223396e-05\n",
            "----------------------------------------\n",
            "Epoch 505\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4819e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.481914846659287e-05\n",
            "----------------------------------------\n",
            "Epoch 506\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4760e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.4760053905106438e-05\n",
            "----------------------------------------\n",
            "Epoch 507\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4701e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.470114402608226e-05\n",
            "----------------------------------------\n",
            "Epoch 508\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4643e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.4642555226838194e-05\n",
            "----------------------------------------\n",
            "Epoch 509\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4585e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.4585212200931878e-05\n",
            "----------------------------------------\n",
            "Epoch 510\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4527e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.4527255570958493e-05\n",
            "----------------------------------------\n",
            "Epoch 511\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4470e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.4469658713834085e-05\n",
            "----------------------------------------\n",
            "Epoch 512\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4413e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.4413036097390941e-05\n",
            "----------------------------------------\n",
            "Epoch 513\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4357e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.4356986633671797e-05\n",
            "----------------------------------------\n",
            "Epoch 514\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4301e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.4300961843194654e-05\n",
            "----------------------------------------\n",
            "Epoch 515\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4246e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.4245965779599444e-05\n",
            "----------------------------------------\n",
            "Epoch 516\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4191e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.4191465180584123e-05\n",
            "----------------------------------------\n",
            "Epoch 517\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4137e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.4137418715206713e-05\n",
            "----------------------------------------\n",
            "Epoch 518\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4084e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.4083840394217231e-05\n",
            "----------------------------------------\n",
            "Epoch 519\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4031e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.4031369381442996e-05\n",
            "----------------------------------------\n",
            "Epoch 520\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3980e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3979767288086743e-05\n",
            "----------------------------------------\n",
            "Epoch 521\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3929e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3929029429790715e-05\n",
            "----------------------------------------\n",
            "Epoch 522\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3880e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3879787641502867e-05\n",
            "----------------------------------------\n",
            "Epoch 523\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3833e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3833282945940465e-05\n",
            "----------------------------------------\n",
            "Epoch 524\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3789e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3789311085996936e-05\n",
            "----------------------------------------\n",
            "Epoch 525\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3749e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3748512057519106e-05\n",
            "----------------------------------------\n",
            "Epoch 526\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3712e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3711506120304935e-05\n",
            "----------------------------------------\n",
            "Epoch 527\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3677e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3677399224067588e-05\n",
            "----------------------------------------\n",
            "Epoch 528\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3640e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3640232934691128e-05\n",
            "----------------------------------------\n",
            "Epoch 529\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3595e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3595288371342423e-05\n",
            "----------------------------------------\n",
            "Epoch 530\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3536e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3535786642943022e-05\n",
            "----------------------------------------\n",
            "Epoch 531\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3462e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3461942184752149e-05\n",
            "----------------------------------------\n",
            "Epoch 532\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3383e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3382525330336567e-05\n",
            "----------------------------------------\n",
            "Epoch 533\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3313e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.331273786771144e-05\n",
            "----------------------------------------\n",
            "Epoch 534\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3259e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3259455289393232e-05\n",
            "----------------------------------------\n",
            "Epoch 535\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3219e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.321907805264832e-05\n",
            "----------------------------------------\n",
            "Epoch 536\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3182e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3182016322868137e-05\n",
            "----------------------------------------\n",
            "Epoch 537\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3138e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3137942094978146e-05\n",
            "----------------------------------------\n",
            "Epoch 538\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3083e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.30827082220143e-05\n",
            "----------------------------------------\n",
            "Epoch 539\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3020e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3019555271513447e-05\n",
            "----------------------------------------\n",
            "Epoch 540\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2958e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2957513681047242e-05\n",
            "----------------------------------------\n",
            "Epoch 541\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2904e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2903573660642584e-05\n",
            "----------------------------------------\n",
            "Epoch 542\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2858e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2857931159112953e-05\n",
            "----------------------------------------\n",
            "Epoch 543\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2815e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2814590467297593e-05\n",
            "----------------------------------------\n",
            "Epoch 544\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2767e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2767143180473518e-05\n",
            "----------------------------------------\n",
            "Epoch 545\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2714e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2713672943365728e-05\n",
            "----------------------------------------\n",
            "Epoch 546\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2657e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.265748857122879e-05\n",
            "----------------------------------------\n",
            "Epoch 547\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2603e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2603020204993312e-05\n",
            "----------------------------------------\n",
            "Epoch 548\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2554e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.25537145001066e-05\n",
            "----------------------------------------\n",
            "Epoch 549\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2509e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2508510697431409e-05\n",
            "----------------------------------------\n",
            "Epoch 550\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2464e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2463536351825626e-05\n",
            "----------------------------------------\n",
            "Epoch 551\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2417e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2416606631806624e-05\n",
            "----------------------------------------\n",
            "Epoch 552\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2366e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2366392164307541e-05\n",
            "----------------------------------------\n",
            "Epoch 553\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2315e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2315357659531196e-05\n",
            "----------------------------------------\n",
            "Epoch 554\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2266e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2266280248494186e-05\n",
            "----------------------------------------\n",
            "Epoch 555\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2220e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2220086530058517e-05\n",
            "----------------------------------------\n",
            "Epoch 556\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2176e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2175940709417794e-05\n",
            "----------------------------------------\n",
            "Epoch 557\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2132e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2131848979581588e-05\n",
            "----------------------------------------\n",
            "Epoch 558\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2086e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.20855292439563e-05\n",
            "----------------------------------------\n",
            "Epoch 559\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2037e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2037222013742187e-05\n",
            "----------------------------------------\n",
            "Epoch 560\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1989e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1988777494849121e-05\n",
            "----------------------------------------\n",
            "Epoch 561\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1942e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1941542208167131e-05\n",
            "----------------------------------------\n",
            "Epoch 562\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1896e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.189563170775708e-05\n",
            "----------------------------------------\n",
            "Epoch 563\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1850e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1850412578222707e-05\n",
            "----------------------------------------\n",
            "Epoch 564\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1806e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.180627193819347e-05\n",
            "----------------------------------------\n",
            "Epoch 565\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1763e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1763210772942293e-05\n",
            "----------------------------------------\n",
            "Epoch 566\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1720e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1719552989049111e-05\n",
            "----------------------------------------\n",
            "Epoch 567\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1676e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1676227263652522e-05\n",
            "----------------------------------------\n",
            "Epoch 568\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1634e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1633581025971187e-05\n",
            "----------------------------------------\n",
            "Epoch 569\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1592e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.159172264729097e-05\n",
            "----------------------------------------\n",
            "Epoch 570\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1550e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1550036513231593e-05\n",
            "----------------------------------------\n",
            "Epoch 571\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1508e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1508163951290118e-05\n",
            "----------------------------------------\n",
            "Epoch 572\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1466e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1466228662072152e-05\n",
            "----------------------------------------\n",
            "Epoch 573\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1424e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1424334363443679e-05\n",
            "----------------------------------------\n",
            "Epoch 574\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1383e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.138264559405212e-05\n",
            "----------------------------------------\n",
            "Epoch 575\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1341e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1341226534236857e-05\n",
            "----------------------------------------\n",
            "Epoch 576\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1300e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.130041380680045e-05\n",
            "----------------------------------------\n",
            "Epoch 577\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1260e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.126008620819722e-05\n",
            "----------------------------------------\n",
            "Epoch 578\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1220e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1220092209194774e-05\n",
            "----------------------------------------\n",
            "Epoch 579\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1180e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1180171453493145e-05\n",
            "----------------------------------------\n",
            "Epoch 580\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1140e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1140379866225069e-05\n",
            "----------------------------------------\n",
            "Epoch 581\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1101e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1100899660488096e-05\n",
            "----------------------------------------\n",
            "Epoch 582\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1062e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1061638923151898e-05\n",
            "----------------------------------------\n",
            "Epoch 583\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1023e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1023103736370482e-05\n",
            "----------------------------------------\n",
            "Epoch 584\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0985e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0984890401719405e-05\n",
            "----------------------------------------\n",
            "Epoch 585\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0947e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0946870864490308e-05\n",
            "----------------------------------------\n",
            "Epoch 586\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0909e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0909314778314988e-05\n",
            "----------------------------------------\n",
            "Epoch 587\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0872e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0871802540498322e-05\n",
            "----------------------------------------\n",
            "Epoch 588\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0834e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0834353312926589e-05\n",
            "----------------------------------------\n",
            "Epoch 589\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0797e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0797101491303865e-05\n",
            "----------------------------------------\n",
            "Epoch 590\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0760e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0760289699887326e-05\n",
            "----------------------------------------\n",
            "Epoch 591\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0724e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0724417154202008e-05\n",
            "----------------------------------------\n",
            "Epoch 592\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0689e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0688570969159785e-05\n",
            "----------------------------------------\n",
            "Epoch 593\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0653e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0652522610515287e-05\n",
            "----------------------------------------\n",
            "Epoch 594\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0616e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0615996888453128e-05\n",
            "----------------------------------------\n",
            "Epoch 595\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0580e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0579707040886388e-05\n",
            "----------------------------------------\n",
            "Epoch 596\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0544e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0544111172965866e-05\n",
            "----------------------------------------\n",
            "Epoch 597\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0509e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0508621555403671e-05\n",
            "----------------------------------------\n",
            "Epoch 598\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0473e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0473302119117834e-05\n",
            "----------------------------------------\n",
            "Epoch 599\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0438e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0438119444852171e-05\n",
            "----------------------------------------\n",
            "Epoch 600\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0403e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0403257132164128e-05\n",
            "----------------------------------------\n",
            "Epoch 601\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0369e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0368533288679419e-05\n",
            "----------------------------------------\n",
            "Epoch 602\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0334e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0334106903667875e-05\n",
            "----------------------------------------\n",
            "Epoch 603\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0300e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.029996942972543e-05\n",
            "----------------------------------------\n",
            "Epoch 604\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0266e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0265960908875135e-05\n",
            "----------------------------------------\n",
            "Epoch 605\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0232e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0232084873461173e-05\n",
            "----------------------------------------\n",
            "Epoch 606\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0198e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0198205279745892e-05\n",
            "----------------------------------------\n",
            "Epoch 607\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0165e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0164531088021264e-05\n",
            "----------------------------------------\n",
            "Epoch 608\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0131e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.013142253059981e-05\n",
            "----------------------------------------\n",
            "Epoch 609\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0098e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0098139454524867e-05\n",
            "----------------------------------------\n",
            "Epoch 610\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0065e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.00647081914433e-05\n",
            "----------------------------------------\n",
            "Epoch 611\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0031e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.003143903870121e-05\n",
            "----------------------------------------\n",
            "Epoch 612\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.9998e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.999838436869885e-06\n",
            "----------------------------------------\n",
            "Epoch 613\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.9687e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.968666052112891e-06\n",
            "----------------------------------------\n",
            "Epoch 614\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.9378e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.937831374207047e-06\n",
            "----------------------------------------\n",
            "Epoch 615\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.9071e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.907147060115282e-06\n",
            "----------------------------------------\n",
            "Epoch 616\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.8767e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.87674094776269e-06\n",
            "----------------------------------------\n",
            "Epoch 617\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.8466e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.846583033751407e-06\n",
            "----------------------------------------\n",
            "Epoch 618\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.8165e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.816473742809703e-06\n",
            "----------------------------------------\n",
            "Epoch 619\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.7866e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.786617656248949e-06\n",
            "----------------------------------------\n",
            "Epoch 620\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.7569e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.756938815910973e-06\n",
            "----------------------------------------\n",
            "Epoch 621\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.7274e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.727424303635867e-06\n",
            "----------------------------------------\n",
            "Epoch 622\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.6982e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.698172373983967e-06\n",
            "----------------------------------------\n",
            "Epoch 623\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.6691e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.66908274436466e-06\n",
            "----------------------------------------\n",
            "Epoch 624\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.6400e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.639998531985638e-06\n",
            "----------------------------------------\n",
            "Epoch 625\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.6112e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.611246451765864e-06\n",
            "----------------------------------------\n",
            "Epoch 626\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.5825e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.582513522807958e-06\n",
            "----------------------------------------\n",
            "Epoch 627\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.5539e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.55389304348151e-06\n",
            "----------------------------------------\n",
            "Epoch 628\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.5255e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.525491614583638e-06\n",
            "----------------------------------------\n",
            "Epoch 629\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.4971e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.497144979917675e-06\n",
            "----------------------------------------\n",
            "Epoch 630\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.4690e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.468958087616972e-06\n",
            "----------------------------------------\n",
            "Epoch 631\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.4409e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.440863781604734e-06\n",
            "----------------------------------------\n",
            "Epoch 632\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.4127e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.412672557181043e-06\n",
            "----------------------------------------\n",
            "Epoch 633\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.3845e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.384519028883956e-06\n",
            "----------------------------------------\n",
            "Epoch 634\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.3565e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.356526185389734e-06\n",
            "----------------------------------------\n",
            "Epoch 635\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.3288e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.32876652182987e-06\n",
            "----------------------------------------\n",
            "Epoch 636\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.3013e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.301317104443821e-06\n",
            "----------------------------------------\n",
            "Epoch 637\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.2742e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.274194194131709e-06\n",
            "----------------------------------------\n",
            "Epoch 638\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.2470e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.24695524175791e-06\n",
            "----------------------------------------\n",
            "Epoch 639\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.2201e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.220055651422837e-06\n",
            "----------------------------------------\n",
            "Epoch 640\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.1933e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.193288169708878e-06\n",
            "----------------------------------------\n",
            "Epoch 641\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.1666e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.166582800732414e-06\n",
            "----------------------------------------\n",
            "Epoch 642\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.1400e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.140031188250686e-06\n",
            "----------------------------------------\n",
            "Epoch 643\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.1137e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.113718415575919e-06\n",
            "----------------------------------------\n",
            "Epoch 644\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.0876e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.087572255137824e-06\n",
            "----------------------------------------\n",
            "Epoch 645\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.0617e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.061680786827047e-06\n",
            "----------------------------------------\n",
            "Epoch 646\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.0359e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.035936826516608e-06\n",
            "----------------------------------------\n",
            "Epoch 647\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.0103e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.01031868737301e-06\n",
            "----------------------------------------\n",
            "Epoch 648\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.9845e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.984519395677459e-06\n",
            "----------------------------------------\n",
            "Epoch 649\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.9588e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.958789341063496e-06\n",
            "----------------------------------------\n",
            "Epoch 650\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.9331e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.93305912837144e-06\n",
            "----------------------------------------\n",
            "Epoch 651\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.9075e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.907523770881543e-06\n",
            "----------------------------------------\n",
            "Epoch 652\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.8821e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.88208840945759e-06\n",
            "----------------------------------------\n",
            "Epoch 653\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.8569e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.856907933899592e-06\n",
            "----------------------------------------\n",
            "Epoch 654\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.8316e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.831641721042123e-06\n",
            "----------------------------------------\n",
            "Epoch 655\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.8065e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.80651531990067e-06\n",
            "----------------------------------------\n",
            "Epoch 656\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.7816e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.781562201349515e-06\n",
            "----------------------------------------\n",
            "Epoch 657\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.7571e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.757052820987406e-06\n",
            "----------------------------------------\n",
            "Epoch 658\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.7326e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.732621727888613e-06\n",
            "----------------------------------------\n",
            "Epoch 659\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.7082e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.708218839392676e-06\n",
            "----------------------------------------\n",
            "Epoch 660\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.6836e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.683634746674374e-06\n",
            "----------------------------------------\n",
            "Epoch 661\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.6591e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.659147994333974e-06\n",
            "----------------------------------------\n",
            "Epoch 662\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.6347e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.634701623340153e-06\n",
            "----------------------------------------\n",
            "Epoch 663\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.6103e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.610322283631594e-06\n",
            "----------------------------------------\n",
            "Epoch 664\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.5860e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.586021961310189e-06\n",
            "----------------------------------------\n",
            "Epoch 665\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.5618e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.561826339949466e-06\n",
            "----------------------------------------\n",
            "Epoch 666\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.5377e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.537703614020985e-06\n",
            "----------------------------------------\n",
            "Epoch 667\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.5138e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.513778561470222e-06\n",
            "----------------------------------------\n",
            "Epoch 668\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.4902e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.490245877767958e-06\n",
            "----------------------------------------\n",
            "Epoch 669\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.4662e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.466220177384649e-06\n",
            "----------------------------------------\n",
            "Epoch 670\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.4429e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.442868717934825e-06\n",
            "----------------------------------------\n",
            "Epoch 671\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.4192e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.419158074182264e-06\n",
            "----------------------------------------\n",
            "Epoch 672\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.3952e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.395199273154264e-06\n",
            "----------------------------------------\n",
            "Epoch 673\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.3718e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.371771104755943e-06\n",
            "----------------------------------------\n",
            "Epoch 674\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.3482e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.34815357058824e-06\n",
            "----------------------------------------\n",
            "Epoch 675\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.3246e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.3246232449536e-06\n",
            "----------------------------------------\n",
            "Epoch 676\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.3013e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.301295469311155e-06\n",
            "----------------------------------------\n",
            "Epoch 677\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.2779e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.277887737956466e-06\n",
            "----------------------------------------\n",
            "Epoch 678\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.2550e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.255021414070895e-06\n",
            "----------------------------------------\n",
            "Epoch 679\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.2327e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.23265362469655e-06\n",
            "----------------------------------------\n",
            "Epoch 680\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.2103e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.210254343107245e-06\n",
            "----------------------------------------\n",
            "Epoch 681\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.1880e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.188036870540324e-06\n",
            "----------------------------------------\n",
            "Epoch 682\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.1660e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.16604475997928e-06\n",
            "----------------------------------------\n",
            "Epoch 683\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.1441e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.144077488635671e-06\n",
            "----------------------------------------\n",
            "Epoch 684\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.1223e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.122265090159514e-06\n",
            "----------------------------------------\n",
            "Epoch 685\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.1006e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.10058347179006e-06\n",
            "----------------------------------------\n",
            "Epoch 686\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.0790e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.079020880662618e-06\n",
            "----------------------------------------\n",
            "Epoch 687\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.0578e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.057766052877307e-06\n",
            "----------------------------------------\n",
            "Epoch 688\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.0363e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.036280377318548e-06\n",
            "----------------------------------------\n",
            "Epoch 689\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.0151e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.015065637825286e-06\n",
            "----------------------------------------\n",
            "Epoch 690\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.9940e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.994002564768659e-06\n",
            "----------------------------------------\n",
            "Epoch 691\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.9730e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.973035385261864e-06\n",
            "----------------------------------------\n",
            "Epoch 692\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.9522e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.952192644660669e-06\n",
            "----------------------------------------\n",
            "Epoch 693\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.9314e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.93140048381596e-06\n",
            "----------------------------------------\n",
            "Epoch 694\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.9107e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.910724071018069e-06\n",
            "----------------------------------------\n",
            "Epoch 695\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.8902e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.89016715285379e-06\n",
            "----------------------------------------\n",
            "Epoch 696\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.8697e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.869659562954376e-06\n",
            "----------------------------------------\n",
            "Epoch 697\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.8492e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.849235328898694e-06\n",
            "----------------------------------------\n",
            "Epoch 698\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.8289e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.828937689531348e-06\n",
            "----------------------------------------\n",
            "Epoch 699\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.8087e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.808684675910992e-06\n",
            "----------------------------------------\n",
            "Epoch 700\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.7885e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.788530282395569e-06\n",
            "----------------------------------------\n",
            "Epoch 701\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.7685e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.768465746182588e-06\n",
            "----------------------------------------\n",
            "Epoch 702\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.7485e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.7484588213387e-06\n",
            "----------------------------------------\n",
            "Epoch 703\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.7286e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.728554176904503e-06\n",
            "----------------------------------------\n",
            "Epoch 704\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.7088e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.708776137790376e-06\n",
            "----------------------------------------\n",
            "Epoch 705\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.6891e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.689133910635681e-06\n",
            "----------------------------------------\n",
            "Epoch 706\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.6696e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.669557248638832e-06\n",
            "----------------------------------------\n",
            "Epoch 707\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.6500e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.650008925786037e-06\n",
            "----------------------------------------\n",
            "Epoch 708\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.6305e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.630532593999313e-06\n",
            "----------------------------------------\n",
            "Epoch 709\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.6112e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.611218365355172e-06\n",
            "----------------------------------------\n",
            "Epoch 710\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.5918e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.5918418710316424e-06\n",
            "----------------------------------------\n",
            "Epoch 711\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.5726e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.572628322041073e-06\n",
            "----------------------------------------\n",
            "Epoch 712\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.5535e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.553477746666121e-06\n",
            "----------------------------------------\n",
            "Epoch 713\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.5344e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.534419900088396e-06\n",
            "----------------------------------------\n",
            "Epoch 714\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.5154e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.515434514529349e-06\n",
            "----------------------------------------\n",
            "Epoch 715\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.4966e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.496596332069689e-06\n",
            "----------------------------------------\n",
            "Epoch 716\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.4779e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.477856884793299e-06\n",
            "----------------------------------------\n",
            "Epoch 717\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.4592e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.459168653946338e-06\n",
            "----------------------------------------\n",
            "Epoch 718\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.4405e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.440486642149688e-06\n",
            "----------------------------------------\n",
            "Epoch 719\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.4220e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.4219528544730574e-06\n",
            "----------------------------------------\n",
            "Epoch 720\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.4034e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.403362910834853e-06\n",
            "----------------------------------------\n",
            "Epoch 721\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3849e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.384889696145958e-06\n",
            "----------------------------------------\n",
            "Epoch 722\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3665e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.36648746031029e-06\n",
            "----------------------------------------\n",
            "Epoch 723\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3481e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.348145234779892e-06\n",
            "----------------------------------------\n",
            "Epoch 724\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3299e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.329863347652183e-06\n",
            "----------------------------------------\n",
            "Epoch 725\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3117e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.311652236359258e-06\n",
            "----------------------------------------\n",
            "Epoch 726\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2935e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.2935198664173674e-06\n",
            "----------------------------------------\n",
            "Epoch 727\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2755e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.275487632998186e-06\n",
            "----------------------------------------\n",
            "Epoch 728\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2575e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.257526515993993e-06\n",
            "----------------------------------------\n",
            "Epoch 729\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2396e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.239634009678592e-06\n",
            "----------------------------------------\n",
            "Epoch 730\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2218e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.221835917382804e-06\n",
            "----------------------------------------\n",
            "Epoch 731\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2041e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.20408456614118e-06\n",
            "----------------------------------------\n",
            "Epoch 732\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1864e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.18640496646378e-06\n",
            "----------------------------------------\n",
            "Epoch 733\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1688e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.1687991913397746e-06\n",
            "----------------------------------------\n",
            "Epoch 734\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1513e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.151250847977357e-06\n",
            "----------------------------------------\n",
            "Epoch 735\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1338e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.133762459958404e-06\n",
            "----------------------------------------\n",
            "Epoch 736\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1164e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.1163926856956925e-06\n",
            "----------------------------------------\n",
            "Epoch 737\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0990e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.0990107375325055e-06\n",
            "----------------------------------------\n",
            "Epoch 738\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0818e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.081753703571002e-06\n",
            "----------------------------------------\n",
            "Epoch 739\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0645e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.064534968864768e-06\n",
            "----------------------------------------\n",
            "Epoch 740\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0474e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.047395876215032e-06\n",
            "----------------------------------------\n",
            "Epoch 741\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0303e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.030344032509025e-06\n",
            "----------------------------------------\n",
            "Epoch 742\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0133e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.013344800074168e-06\n",
            "----------------------------------------\n",
            "Epoch 743\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9964e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.996435181977323e-06\n",
            "----------------------------------------\n",
            "Epoch 744\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9796e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.979591902911158e-06\n",
            "----------------------------------------\n",
            "Epoch 745\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9628e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.962772387680999e-06\n",
            "----------------------------------------\n",
            "Epoch 746\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9460e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.945954116777822e-06\n",
            "----------------------------------------\n",
            "Epoch 747\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9292e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.929200718724065e-06\n",
            "----------------------------------------\n",
            "Epoch 748\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9124e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.912411147351215e-06\n",
            "----------------------------------------\n",
            "Epoch 749\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8956e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.895597880154173e-06\n",
            "----------------------------------------\n",
            "Epoch 750\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8788e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.878817339184308e-06\n",
            "----------------------------------------\n",
            "Epoch 751\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8620e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.862031104265756e-06\n",
            "----------------------------------------\n",
            "Epoch 752\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8453e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.845251969490648e-06\n",
            "----------------------------------------\n",
            "Epoch 753\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8285e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.828538497285855e-06\n",
            "----------------------------------------\n",
            "Epoch 754\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8118e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.811849649776431e-06\n",
            "----------------------------------------\n",
            "Epoch 755\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7955e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.795455037503317e-06\n",
            "----------------------------------------\n",
            "Epoch 756\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7791e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.779103456600541e-06\n",
            "----------------------------------------\n",
            "Epoch 757\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7628e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.7628466955375215e-06\n",
            "----------------------------------------\n",
            "Epoch 758\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7467e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.746739735400868e-06\n",
            "----------------------------------------\n",
            "Epoch 759\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7307e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.730741851678048e-06\n",
            "----------------------------------------\n",
            "Epoch 760\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7149e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.714892501900936e-06\n",
            "----------------------------------------\n",
            "Epoch 761\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6992e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.699195131003278e-06\n",
            "----------------------------------------\n",
            "Epoch 762\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6837e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.68368906645652e-06\n",
            "----------------------------------------\n",
            "Epoch 763\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6685e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.668450419808167e-06\n",
            "----------------------------------------\n",
            "Epoch 764\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6536e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.653582638385843e-06\n",
            "----------------------------------------\n",
            "Epoch 765\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6392e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.6392174317431225e-06\n",
            "----------------------------------------\n",
            "Epoch 766\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6255e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.625474652504363e-06\n",
            "----------------------------------------\n",
            "Epoch 767\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6126e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.61255237816874e-06\n",
            "----------------------------------------\n",
            "Epoch 768\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6006e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.600555761343627e-06\n",
            "----------------------------------------\n",
            "Epoch 769\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5896e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.589622677653054e-06\n",
            "----------------------------------------\n",
            "Epoch 770\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5796e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.579551759164323e-06\n",
            "----------------------------------------\n",
            "Epoch 771\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5701e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.5701050876781375e-06\n",
            "----------------------------------------\n",
            "Epoch 772\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5604e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.560404292768259e-06\n",
            "----------------------------------------\n",
            "Epoch 773\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5491e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.549056206772362e-06\n",
            "----------------------------------------\n",
            "Epoch 774\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5347e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.53467573158713e-06\n",
            "----------------------------------------\n",
            "Epoch 775\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5160e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.5159924642491045e-06\n",
            "----------------------------------------\n",
            "Epoch 776\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4928e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.492759010520037e-06\n",
            "----------------------------------------\n",
            "Epoch 777\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4645e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.464486044523303e-06\n",
            "----------------------------------------\n",
            "Epoch 778\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6160e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.6159711745993e-06\n",
            "----------------------------------------\n",
            "Epoch 779\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3493e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.349339091096235e-06\n",
            "----------------------------------------\n",
            "Epoch 780\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.5970e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.597001741826103e-06\n",
            "----------------------------------------\n",
            "Epoch 781\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5323e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.5322558845222235e-06\n",
            "----------------------------------------\n",
            "Epoch 782\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7347e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.734664198914599e-06\n",
            "----------------------------------------\n",
            "Epoch 783\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1505e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.1505067244313395e-06\n",
            "----------------------------------------\n",
            "Epoch 784\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3819e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.381854300748931e-06\n",
            "----------------------------------------\n",
            "Epoch 785\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7326e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.732638662315612e-06\n",
            "----------------------------------------\n",
            "Epoch 786\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7506e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.750590011138753e-06\n",
            "----------------------------------------\n",
            "Epoch 787\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3037e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.303683752874833e-06\n",
            "----------------------------------------\n",
            "Epoch 788\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7223e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.722321137708598e-06\n",
            "----------------------------------------\n",
            "Epoch 789\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3917e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.391651437897074e-06\n",
            "----------------------------------------\n",
            "Epoch 790\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3856e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.385599653483475e-06\n",
            "----------------------------------------\n",
            "Epoch 791\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5396e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.539573153944552e-06\n",
            "----------------------------------------\n",
            "Epoch 792\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.2217e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.221744449630972e-06\n",
            "----------------------------------------\n",
            "Epoch 793\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4467e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.446671425943872e-06\n",
            "----------------------------------------\n",
            "Epoch 794\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.2824e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.28237274480974e-06\n",
            "----------------------------------------\n",
            "Epoch 795\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.2483e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.248331746412401e-06\n",
            "----------------------------------------\n",
            "Epoch 796\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3423e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.342271104255554e-06\n",
            "----------------------------------------\n",
            "Epoch 797\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.1497e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.14965648874693e-06\n",
            "----------------------------------------\n",
            "Epoch 798\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.2785e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.278458539976854e-06\n",
            "----------------------------------------\n",
            "Epoch 799\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.1667e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.166698402074632e-06\n",
            "----------------------------------------\n",
            "Epoch 800\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.1542e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.154249412641356e-06\n",
            "----------------------------------------\n",
            "Epoch 801\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.1907e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.190700510876305e-06\n",
            "----------------------------------------\n",
            "Epoch 802\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.0763e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.076339519591238e-06\n",
            "----------------------------------------\n",
            "Epoch 803\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.1493e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.149259105283037e-06\n",
            "----------------------------------------\n",
            "Epoch 804\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.0688e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.068758248930306e-06\n",
            "----------------------------------------\n",
            "Epoch 805\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.0671e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.0671356897930855e-06\n",
            "----------------------------------------\n",
            "Epoch 806\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.0739e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.07392324556847e-06\n",
            "----------------------------------------\n",
            "Epoch 807\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.0055e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.005498723006554e-06\n",
            "----------------------------------------\n",
            "Epoch 808\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.0435e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.043512302261288e-06\n",
            "----------------------------------------\n",
            "Epoch 809\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.9858e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.985775077132882e-06\n",
            "----------------------------------------\n",
            "Epoch 810\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.9848e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.98478150017932e-06\n",
            "----------------------------------------\n",
            "Epoch 811\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.9782e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.9781873529238695e-06\n",
            "----------------------------------------\n",
            "Epoch 812\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.9349e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.934863310040185e-06\n",
            "----------------------------------------\n",
            "Epoch 813\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.9515e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.951504487124688e-06\n",
            "----------------------------------------\n",
            "Epoch 814\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.9098e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.909803378560522e-06\n",
            "----------------------------------------\n",
            "Epoch 815\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.9068e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.906827554194401e-06\n",
            "----------------------------------------\n",
            "Epoch 816\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.8945e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.894468212921086e-06\n",
            "----------------------------------------\n",
            "Epoch 817\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.8652e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.865191462813886e-06\n",
            "----------------------------------------\n",
            "Epoch 818\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.8692e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.869179198792307e-06\n",
            "----------------------------------------\n",
            "Epoch 819\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.8381e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.838147352209301e-06\n",
            "----------------------------------------\n",
            "Epoch 820\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.8325e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.832452398396235e-06\n",
            "----------------------------------------\n",
            "Epoch 821\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.8181e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.818100011606705e-06\n",
            "----------------------------------------\n",
            "Epoch 822\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.7964e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.796381683228385e-06\n",
            "----------------------------------------\n",
            "Epoch 823\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.7928e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.792779359558954e-06\n",
            "----------------------------------------\n",
            "Epoch 824\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.7687e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.768697480019575e-06\n",
            "----------------------------------------\n",
            "Epoch 825\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.7603e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.760280849667393e-06\n",
            "----------------------------------------\n",
            "Epoch 826\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.7458e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.7458282528529195e-06\n",
            "----------------------------------------\n",
            "Epoch 827\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.7280e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.728027895908281e-06\n",
            "----------------------------------------\n",
            "Epoch 828\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.7206e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.7205883564861304e-06\n",
            "----------------------------------------\n",
            "Epoch 829\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.7008e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.700783911632315e-06\n",
            "----------------------------------------\n",
            "Epoch 830\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.6911e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.691086035410192e-06\n",
            "----------------------------------------\n",
            "Epoch 831\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.6769e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.676898239823332e-06\n",
            "----------------------------------------\n",
            "Epoch 832\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.6614e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.66135172285795e-06\n",
            "----------------------------------------\n",
            "Epoch 833\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.6516e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.651636642250814e-06\n",
            "----------------------------------------\n",
            "Epoch 834\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.6348e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.634772019611635e-06\n",
            "----------------------------------------\n",
            "Epoch 835\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.6239e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.62385819704428e-06\n",
            "----------------------------------------\n",
            "Epoch 836\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.6103e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.610310135528389e-06\n",
            "----------------------------------------\n",
            "Epoch 837\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.5961e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.596129889991644e-06\n",
            "----------------------------------------\n",
            "Epoch 838\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.5853e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.585349290528626e-06\n",
            "----------------------------------------\n",
            "Epoch 839\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.5703e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.570305097053238e-06\n",
            "----------------------------------------\n",
            "Epoch 840\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.5590e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.559012039114551e-06\n",
            "----------------------------------------\n",
            "Epoch 841\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.5462e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.546236889684056e-06\n",
            "----------------------------------------\n",
            "Epoch 842\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.5330e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.53303355013229e-06\n",
            "----------------------------------------\n",
            "Epoch 843\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.5221e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.522146231936849e-06\n",
            "----------------------------------------\n",
            "Epoch 844\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.5087e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.508701476645154e-06\n",
            "----------------------------------------\n",
            "Epoch 845\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.4973e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.497330719966634e-06\n",
            "----------------------------------------\n",
            "Epoch 846\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.4851e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.485099001966675e-06\n",
            "----------------------------------------\n",
            "Epoch 847\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.4725e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.472533504436025e-06\n",
            "----------------------------------------\n",
            "Epoch 848\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.4614e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.461375486021435e-06\n",
            "----------------------------------------\n",
            "Epoch 849\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.4487e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.448714082019441e-06\n",
            "----------------------------------------\n",
            "Epoch 850\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.4372e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.437238528576331e-06\n",
            "----------------------------------------\n",
            "Epoch 851\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.4254e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.425352672076715e-06\n",
            "----------------------------------------\n",
            "Epoch 852\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.4133e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.4132852699277435e-06\n",
            "----------------------------------------\n",
            "Epoch 853\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.4021e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.402053641687304e-06\n",
            "----------------------------------------\n",
            "Epoch 854\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.3899e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.389855603477778e-06\n",
            "----------------------------------------\n",
            "Epoch 855\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.3784e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.3784393455637436e-06\n",
            "----------------------------------------\n",
            "Epoch 856\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.3669e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.366877628887148e-06\n",
            "----------------------------------------\n",
            "Epoch 857\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.3551e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.355131054173876e-06\n",
            "----------------------------------------\n",
            "Epoch 858\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.3440e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.343965143251497e-06\n",
            "----------------------------------------\n",
            "Epoch 859\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.3321e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.332149092016089e-06\n",
            "----------------------------------------\n",
            "Epoch 860\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.3209e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.320890575137618e-06\n",
            "----------------------------------------\n",
            "Epoch 861\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.3095e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.3095205231500804e-06\n",
            "----------------------------------------\n",
            "Epoch 862\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.2979e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.297908946892838e-06\n",
            "----------------------------------------\n",
            "Epoch 863\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.2867e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.286653656274361e-06\n",
            "----------------------------------------\n",
            "Epoch 864\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.2751e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.275106637347438e-06\n",
            "----------------------------------------\n",
            "Epoch 865\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.2637e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.263737809006187e-06\n",
            "----------------------------------------\n",
            "Epoch 866\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.2525e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.252515736782866e-06\n",
            "----------------------------------------\n",
            "Epoch 867\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.2412e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.241180270279359e-06\n",
            "----------------------------------------\n",
            "Epoch 868\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.2299e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.22994663835292e-06\n",
            "----------------------------------------\n",
            "Epoch 869\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.2187e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.218703514673314e-06\n",
            "----------------------------------------\n",
            "Epoch 870\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.2076e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.207587632752226e-06\n",
            "----------------------------------------\n",
            "Epoch 871\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.1965e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.196516661550964e-06\n",
            "----------------------------------------\n",
            "Epoch 872\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.1853e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.1852984025598685e-06\n",
            "----------------------------------------\n",
            "Epoch 873\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.1743e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.174250659546256e-06\n",
            "----------------------------------------\n",
            "Epoch 874\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.1632e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.163163180810256e-06\n",
            "----------------------------------------\n",
            "Epoch 875\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.1521e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.152121827766469e-06\n",
            "----------------------------------------\n",
            "Epoch 876\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.1412e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.141164166020394e-06\n",
            "----------------------------------------\n",
            "Epoch 877\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.1302e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.130220575599021e-06\n",
            "----------------------------------------\n",
            "Epoch 878\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.1194e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.119373186024773e-06\n",
            "----------------------------------------\n",
            "Epoch 879\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.1086e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.108597314541698e-06\n",
            "----------------------------------------\n",
            "Epoch 880\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.0979e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.09790063602426e-06\n",
            "----------------------------------------\n",
            "Epoch 881\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.0873e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.087251541828544e-06\n",
            "----------------------------------------\n",
            "Epoch 882\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.0766e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.076555318539462e-06\n",
            "----------------------------------------\n",
            "Epoch 883\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.0660e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.066002312950064e-06\n",
            "----------------------------------------\n",
            "Epoch 884\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.0555e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.055524649919032e-06\n",
            "----------------------------------------\n",
            "Epoch 885\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.0449e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.044882275100243e-06\n",
            "----------------------------------------\n",
            "Epoch 886\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.0343e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.034258117403481e-06\n",
            "----------------------------------------\n",
            "Epoch 887\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.0238e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.023816203431153e-06\n",
            "----------------------------------------\n",
            "Epoch 888\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.0134e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.013399852650723e-06\n",
            "----------------------------------------\n",
            "Epoch 889\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.0029e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.002923051920174e-06\n",
            "----------------------------------------\n",
            "Epoch 890\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.9925e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.992482435251689e-06\n",
            "----------------------------------------\n",
            "Epoch 891\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.9821e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.9821346300589355e-06\n",
            "----------------------------------------\n",
            "Epoch 892\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.9718e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.97180439716603e-06\n",
            "----------------------------------------\n",
            "Epoch 893\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.9615e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.96151021619495e-06\n",
            "----------------------------------------\n",
            "Epoch 894\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.9512e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.951152700059951e-06\n",
            "----------------------------------------\n",
            "Epoch 895\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.9409e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.940938900394557e-06\n",
            "----------------------------------------\n",
            "Epoch 896\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.9307e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.9307071378884275e-06\n",
            "----------------------------------------\n",
            "Epoch 897\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.9205e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.920486168857144e-06\n",
            "----------------------------------------\n",
            "Epoch 898\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.9103e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.9102940291907676e-06\n",
            "----------------------------------------\n",
            "Epoch 899\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.9001e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.9001117349174336e-06\n",
            "----------------------------------------\n",
            "Epoch 900\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.8899e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.8899168716507156e-06\n",
            "----------------------------------------\n",
            "Epoch 901\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.8797e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.879722911972981e-06\n",
            "----------------------------------------\n",
            "Epoch 902\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.8695e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.869546529152836e-06\n",
            "----------------------------------------\n",
            "Epoch 903\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.8594e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.8593994169870915e-06\n",
            "----------------------------------------\n",
            "Epoch 904\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.8493e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.849283125814158e-06\n",
            "----------------------------------------\n",
            "Epoch 905\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.8392e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.839166701820462e-06\n",
            "----------------------------------------\n",
            "Epoch 906\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.8291e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.829071932964402e-06\n",
            "----------------------------------------\n",
            "Epoch 907\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.8190e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.8190269004042555e-06\n",
            "----------------------------------------\n",
            "Epoch 908\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.8092e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.809175938133802e-06\n",
            "----------------------------------------\n",
            "Epoch 909\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.7993e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.7993275674220465e-06\n",
            "----------------------------------------\n",
            "Epoch 910\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.7895e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.789473477068608e-06\n",
            "----------------------------------------\n",
            "Epoch 911\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.7796e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.779610564338512e-06\n",
            "----------------------------------------\n",
            "Epoch 912\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.7698e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.7697641865245785e-06\n",
            "----------------------------------------\n",
            "Epoch 913\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.7599e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.759901287749582e-06\n",
            "----------------------------------------\n",
            "Epoch 914\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.7500e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.749977931509845e-06\n",
            "----------------------------------------\n",
            "Epoch 915\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.7401e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.74005711536166e-06\n",
            "----------------------------------------\n",
            "Epoch 916\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.7302e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.730181272237483e-06\n",
            "----------------------------------------\n",
            "Epoch 917\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.7203e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.720314048829986e-06\n",
            "----------------------------------------\n",
            "Epoch 918\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.7104e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.710434841245707e-06\n",
            "----------------------------------------\n",
            "Epoch 919\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.7006e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.700605443710088e-06\n",
            "----------------------------------------\n",
            "Epoch 920\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.6908e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.690822098434268e-06\n",
            "----------------------------------------\n",
            "Epoch 921\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.6811e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.681076685665487e-06\n",
            "----------------------------------------\n",
            "Epoch 922\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.6714e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.671354238553826e-06\n",
            "----------------------------------------\n",
            "Epoch 923\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.6616e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.661644617101923e-06\n",
            "----------------------------------------\n",
            "Epoch 924\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.6520e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.651969175425576e-06\n",
            "----------------------------------------\n",
            "Epoch 925\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.6423e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.642336961972815e-06\n",
            "----------------------------------------\n",
            "Epoch 926\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.6327e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.632713792896418e-06\n",
            "----------------------------------------\n",
            "Epoch 927\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.6231e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.623122168402589e-06\n",
            "----------------------------------------\n",
            "Epoch 928\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.6136e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.613588195885479e-06\n",
            "----------------------------------------\n",
            "Epoch 929\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.6041e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.604082886974572e-06\n",
            "----------------------------------------\n",
            "Epoch 930\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.5946e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.594605343767997e-06\n",
            "----------------------------------------\n",
            "Epoch 931\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.5852e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.585214720786681e-06\n",
            "----------------------------------------\n",
            "Epoch 932\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.5759e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.575876582608836e-06\n",
            "----------------------------------------\n",
            "Epoch 933\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.5666e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.566565402371411e-06\n",
            "----------------------------------------\n",
            "Epoch 934\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.5573e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.5572927468761126e-06\n",
            "----------------------------------------\n",
            "Epoch 935\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.5480e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.548037740526441e-06\n",
            "----------------------------------------\n",
            "Epoch 936\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.5388e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.538814458172767e-06\n",
            "----------------------------------------\n",
            "Epoch 937\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.5296e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.529617422222607e-06\n",
            "----------------------------------------\n",
            "Epoch 938\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.5205e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.520465589268317e-06\n",
            "----------------------------------------\n",
            "Epoch 939\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.5113e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.511329747184247e-06\n",
            "----------------------------------------\n",
            "Epoch 940\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.5022e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.502203075066162e-06\n",
            "----------------------------------------\n",
            "Epoch 941\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.4931e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.493116872740971e-06\n",
            "----------------------------------------\n",
            "Epoch 942\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.4840e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.484040054513565e-06\n",
            "----------------------------------------\n",
            "Epoch 943\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.4750e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.4749985676383265e-06\n",
            "----------------------------------------\n",
            "Epoch 944\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.4660e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.465997593583453e-06\n",
            "----------------------------------------\n",
            "Epoch 945\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.4570e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.457006201090774e-06\n",
            "----------------------------------------\n",
            "Epoch 946\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.4480e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.448045306877989e-06\n",
            "----------------------------------------\n",
            "Epoch 947\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.4391e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.439108439532241e-06\n",
            "----------------------------------------\n",
            "Epoch 948\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.4302e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.430171713457378e-06\n",
            "----------------------------------------\n",
            "Epoch 949\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.4213e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.4212711533638305e-06\n",
            "----------------------------------------\n",
            "Epoch 950\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.4124e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.4124345145791485e-06\n",
            "----------------------------------------\n",
            "Epoch 951\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.4036e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.403607418654391e-06\n",
            "----------------------------------------\n",
            "Epoch 952\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.3948e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.394815631471154e-06\n",
            "----------------------------------------\n",
            "Epoch 953\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.3860e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.386026739928362e-06\n",
            "----------------------------------------\n",
            "Epoch 954\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.3772e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.377233455496574e-06\n",
            "----------------------------------------\n",
            "Epoch 955\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.3684e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.368446346895171e-06\n",
            "----------------------------------------\n",
            "Epoch 956\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.3597e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.359722221080673e-06\n",
            "----------------------------------------\n",
            "Epoch 957\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.3510e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.351017474159306e-06\n",
            "----------------------------------------\n",
            "Epoch 958\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.3423e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.342336084592606e-06\n",
            "----------------------------------------\n",
            "Epoch 959\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.3337e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.333688648587514e-06\n",
            "----------------------------------------\n",
            "Epoch 960\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.3251e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.325057787878992e-06\n",
            "----------------------------------------\n",
            "Epoch 961\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.3164e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.3164381596847845e-06\n",
            "----------------------------------------\n",
            "Epoch 962\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.3078e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.307827435558673e-06\n",
            "----------------------------------------\n",
            "Epoch 963\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.2992e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.2992476350854304e-06\n",
            "----------------------------------------\n",
            "Epoch 964\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.2907e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.29071877412872e-06\n",
            "----------------------------------------\n",
            "Epoch 965\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.2822e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.2821963090279245e-06\n",
            "----------------------------------------\n",
            "Epoch 966\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.2737e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.273668232812994e-06\n",
            "----------------------------------------\n",
            "Epoch 967\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.2652e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.265167145533412e-06\n",
            "----------------------------------------\n",
            "Epoch 968\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.2567e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.256689727540196e-06\n",
            "----------------------------------------\n",
            "Epoch 969\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.2483e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.248296632267837e-06\n",
            "----------------------------------------\n",
            "Epoch 970\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.2398e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.239814806018294e-06\n",
            "----------------------------------------\n",
            "Epoch 971\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.2314e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.231404450146819e-06\n",
            "----------------------------------------\n",
            "Epoch 972\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.2230e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.223002413154543e-06\n",
            "----------------------------------------\n",
            "Epoch 973\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.2146e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.214621937106034e-06\n",
            "----------------------------------------\n",
            "Epoch 974\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.2063e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.206264709457703e-06\n",
            "----------------------------------------\n",
            "Epoch 975\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.1980e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.197956119099178e-06\n",
            "----------------------------------------\n",
            "Epoch 976\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.1896e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.189641136705306e-06\n",
            "----------------------------------------\n",
            "Epoch 977\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.1814e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.181395767840048e-06\n",
            "----------------------------------------\n",
            "Epoch 978\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.1732e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.173233441268033e-06\n",
            "----------------------------------------\n",
            "Epoch 979\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.1650e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.165035590883192e-06\n",
            "----------------------------------------\n",
            "Epoch 980\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.1569e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.156930354061651e-06\n",
            "----------------------------------------\n",
            "Epoch 981\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.1489e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.148853966873219e-06\n",
            "----------------------------------------\n",
            "Epoch 982\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.1408e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.140782895061452e-06\n",
            "----------------------------------------\n",
            "Epoch 983\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.1326e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.132614890319409e-06\n",
            "----------------------------------------\n",
            "Epoch 984\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.1245e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.124466018701765e-06\n",
            "----------------------------------------\n",
            "Epoch 985\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.1164e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.11641935301327e-06\n",
            "----------------------------------------\n",
            "Epoch 986\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.1084e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.108387582364282e-06\n",
            "----------------------------------------\n",
            "Epoch 987\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.1005e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.100472480701735e-06\n",
            "----------------------------------------\n",
            "Epoch 988\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.0924e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.092407132352681e-06\n",
            "----------------------------------------\n",
            "Epoch 989\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.0845e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.0844629952304134e-06\n",
            "----------------------------------------\n",
            "Epoch 990\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.0766e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.076563157941235e-06\n",
            "----------------------------------------\n",
            "Epoch 991\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.0687e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.068657002009449e-06\n",
            "----------------------------------------\n",
            "Epoch 992\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.0608e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.060771900774584e-06\n",
            "----------------------------------------\n",
            "Epoch 993\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.0529e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.052896907629822e-06\n",
            "----------------------------------------\n",
            "Epoch 994\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.0450e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.045022629156914e-06\n",
            "----------------------------------------\n",
            "Epoch 995\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.0372e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.037157314750649e-06\n",
            "----------------------------------------\n",
            "Epoch 996\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.0293e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.029300901823153e-06\n",
            "----------------------------------------\n",
            "Epoch 997\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.0214e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.021449635842377e-06\n",
            "----------------------------------------\n",
            "Epoch 998\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.0136e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.013638560524795e-06\n",
            "----------------------------------------\n",
            "Epoch 999\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.0058e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.005830628139071e-06\n",
            "----------------------------------------\n",
            "Epoch 1000\n",
            "IS variance:  tensor(4.4229e-05, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.9982e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.9981560197614436e-06\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[-5.5204e-04, -1.1648e-01],\n",
            "        [-4.5293e-01, -3.8106e-01],\n",
            "        [-2.5930e-01, -8.7127e-02],\n",
            "        [ 4.4813e-01, -1.6232e-01],\n",
            "        [-8.1455e-03,  7.8029e-02],\n",
            "        [ 1.1004e-01,  3.4091e-03],\n",
            "        [ 2.9693e-01,  4.3980e-01],\n",
            "        [ 6.2576e-01, -5.5355e-01],\n",
            "        [-1.0444e-01,  5.5520e-01],\n",
            "        [-3.0028e-01, -1.3046e-01],\n",
            "        [-5.3901e-01, -2.4041e-01],\n",
            "        [ 1.0723e-01,  1.4509e-01],\n",
            "        [-4.1380e-01,  2.4634e-01],\n",
            "        [ 1.7922e-01,  3.3803e-01],\n",
            "        [-3.7337e-01, -1.3246e-01],\n",
            "        [-6.9054e-01, -6.8765e-01]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([ 0.5092,  0.4352,  0.7202,  0.4023,  0.4572, -0.6651, -0.0837,  0.3502,\n",
            "        -0.6959,  0.6241, -0.0528, -0.1184, -0.6749,  0.5630, -0.3820,  0.4062],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[-0.1059,  0.0348, -0.1211, -0.1186, -0.2161,  0.2042, -0.0126,  0.1244,\n",
            "          0.2356,  0.0704,  0.2263, -0.0731,  0.1759, -0.1584, -0.1582, -0.0644],\n",
            "        [ 0.0482,  0.1365,  0.2008, -0.1384,  0.1320,  0.0593, -0.0738,  0.0601,\n",
            "         -0.0785, -0.0454,  0.1469, -0.2405, -0.0496,  0.0664,  0.0934,  0.0403],\n",
            "        [ 0.0710,  0.0682, -0.0611,  0.0600,  0.1012, -0.2105, -0.2516,  0.1933,\n",
            "         -0.1968, -0.0189,  0.1533, -0.1566, -0.1075,  0.1345, -0.1637,  0.0113],\n",
            "        [-0.1001,  0.0853, -0.1011,  0.1986,  0.1516, -0.1680, -0.0438, -0.0598,\n",
            "          0.1153, -0.1011, -0.1849,  0.0017, -0.0356,  0.0592,  0.1066, -0.2067],\n",
            "        [ 0.0485,  0.2396, -0.0166,  0.2245,  0.0383,  0.1002,  0.1858,  0.0793,\n",
            "          0.0560, -0.1151,  0.1724, -0.0213,  0.0387,  0.1261,  0.0363, -0.0657],\n",
            "        [ 0.1195,  0.1694, -0.1735, -0.2022, -0.1880, -0.1023, -0.0673,  0.1393,\n",
            "         -0.0087, -0.0683, -0.0222,  0.1336, -0.1221,  0.2136, -0.2079,  0.1589],\n",
            "        [-0.0781, -0.1996,  0.1168,  0.1149,  0.0527,  0.1633, -0.1541,  0.2709,\n",
            "          0.0268,  0.0679,  0.1485,  0.0339,  0.0422,  0.0662, -0.0014,  0.0425],\n",
            "        [-0.0461, -0.1450, -0.1952,  0.1243,  0.1511,  0.0309,  0.1699,  0.1166,\n",
            "         -0.2554, -0.2381,  0.0199,  0.1038, -0.1051, -0.0508, -0.2054, -0.1726],\n",
            "        [-0.1728,  0.1716,  0.3580, -0.1372, -0.0661,  0.1081,  0.1373,  0.1145,\n",
            "          0.0249,  0.1201, -0.0654,  0.0284,  0.0638, -0.1162,  0.0172,  0.1396],\n",
            "        [ 0.1042,  0.1746,  0.3908,  0.0058,  0.1786, -0.1368, -0.0759, -0.0043,\n",
            "          0.0850,  0.0507, -0.0090, -0.1311,  0.1271,  0.0124,  0.1397,  0.2339],\n",
            "        [ 0.2133,  0.0509,  0.2322, -0.1479, -0.2051, -0.0269, -0.1886, -0.1002,\n",
            "         -0.1174, -0.0421,  0.2283, -0.1851,  0.1653,  0.1272, -0.2184, -0.2322],\n",
            "        [ 0.2097,  0.2253,  0.3185,  0.1029,  0.0387,  0.0292,  0.0161,  0.0778,\n",
            "         -0.0773, -0.1021,  0.1186, -0.0954, -0.0134, -0.0401, -0.1185,  0.2487],\n",
            "        [ 0.0689, -0.0969, -0.0106,  0.0204,  0.0230,  0.2184, -0.2816, -0.0923,\n",
            "          0.2334,  0.1604,  0.0403, -0.1636,  0.1268, -0.0127,  0.1386,  0.1866],\n",
            "        [ 0.2480,  0.1819,  0.0612, -0.1424,  0.0304, -0.0997, -0.2740,  0.3344,\n",
            "          0.0511, -0.1114,  0.0226, -0.0524,  0.0449,  0.1124, -0.2474,  0.1864],\n",
            "        [ 0.1872,  0.2367, -0.2487,  0.0882,  0.0338,  0.1907,  0.1273, -0.1082,\n",
            "         -0.0604,  0.0663,  0.0350, -0.1319,  0.1821, -0.0847, -0.2468, -0.2229],\n",
            "        [ 0.2759,  0.0425, -0.4191, -0.1359, -0.0629,  0.0942, -0.0608, -0.3922,\n",
            "          0.2084, -0.1408, -0.2414, -0.0204,  0.0059, -0.0352,  0.0191,  0.0218],\n",
            "        [-0.1869, -0.0160,  0.1168,  0.0116, -0.0226, -0.1437,  0.0360,  0.0223,\n",
            "          0.1339,  0.1268,  0.1077, -0.1652,  0.2013, -0.1835, -0.0167,  0.2096],\n",
            "        [ 0.0782, -0.1589, -0.2673, -0.0680, -0.0904,  0.1165, -0.0635, -0.1919,\n",
            "         -0.1050,  0.2005, -0.1449, -0.0545,  0.0925,  0.0203,  0.1139,  0.1484],\n",
            "        [ 0.1595,  0.0643, -0.3432,  0.1120,  0.0515, -0.1801, -0.0238,  0.2495,\n",
            "          0.0111, -0.0368,  0.1770, -0.0914, -0.0333,  0.0507, -0.2133, -0.0470],\n",
            "        [-0.1760, -0.0565, -0.0034, -0.0679,  0.2087, -0.0109, -0.3103, -0.1276,\n",
            "         -0.0425,  0.2443,  0.0807, -0.1902,  0.1366, -0.1344,  0.2271,  0.0099],\n",
            "        [ 0.0740, -0.2291,  0.3031, -0.0556,  0.2903, -0.1666, -0.2427,  0.0299,\n",
            "         -0.1052,  0.2062,  0.1986,  0.2072, -0.1006, -0.2910, -0.1149,  0.2293],\n",
            "        [-0.2314,  0.0108,  0.1455,  0.0379,  0.0895,  0.1859,  0.1108,  0.0656,\n",
            "         -0.1844, -0.0440,  0.1627,  0.1713, -0.1886,  0.1660,  0.2276, -0.0430],\n",
            "        [-0.1424, -0.2437, -0.2496,  0.1048,  0.1263, -0.0228, -0.1983, -0.1492,\n",
            "          0.0542, -0.0686, -0.0583,  0.2295,  0.1212, -0.0762, -0.2098, -0.1740],\n",
            "        [-0.0499, -0.0182, -0.0033, -0.2612,  0.1046,  0.1527, -0.2250,  0.1123,\n",
            "          0.3199,  0.0036, -0.0979,  0.0189,  0.4894,  0.1434,  0.0015,  0.1857],\n",
            "        [-0.0472, -0.2177, -0.3356, -0.2372, -0.1786, -0.0646,  0.1518,  0.1087,\n",
            "          0.1342,  0.0026, -0.0035, -0.0459,  0.0608,  0.1693, -0.1012, -0.1482],\n",
            "        [ 0.2154,  0.1541, -0.2505,  0.0957, -0.0772, -0.0424, -0.0055,  0.0201,\n",
            "          0.1128, -0.0870,  0.1013, -0.2620,  0.1731,  0.1945, -0.1662, -0.1743],\n",
            "        [ 0.0804,  0.2025,  0.1082,  0.1488,  0.0771, -0.1524, -0.0055,  0.1546,\n",
            "          0.0714,  0.0475,  0.0299, -0.0967, -0.2741, -0.1917, -0.2107,  0.1779],\n",
            "        [ 0.0226,  0.2049, -0.0964, -0.1163, -0.3449,  0.1606, -0.2469, -0.1766,\n",
            "          0.0112,  0.1923,  0.1600,  0.0973,  0.0950,  0.1102,  0.2348,  0.0826],\n",
            "        [-0.1786, -0.0534, -0.1874, -0.2366, -0.2194, -0.2432, -0.1082, -0.0627,\n",
            "         -0.2210, -0.1653,  0.0558, -0.0767,  0.0716, -0.0069,  0.0766,  0.1254],\n",
            "        [ 0.0998, -0.0821, -0.0266,  0.3557, -0.1546,  0.1037, -0.1897, -0.1107,\n",
            "          0.2187, -0.1475,  0.0765, -0.0652, -0.1617, -0.2278, -0.1803, -0.0159],\n",
            "        [ 0.0723, -0.0547,  0.1122, -0.1597, -0.2257,  0.0456,  0.0558, -0.1876,\n",
            "         -0.1533,  0.0010, -0.0860,  0.1341, -0.0255, -0.1400, -0.2324, -0.0714],\n",
            "        [-0.1025,  0.2154, -0.1576, -0.0725, -0.3789, -0.1893,  0.0019, -0.0331,\n",
            "         -0.0127, -0.2737, -0.1962, -0.3930,  0.1908, -0.0846,  0.0596,  0.0310]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([ 0.0779,  0.0979, -0.1855, -0.0197, -0.2061, -0.0197, -0.0312, -0.1266,\n",
            "         0.1745,  0.1747,  0.1095,  0.0302, -0.2134,  0.1202,  0.1321, -0.0621,\n",
            "        -0.0627,  0.1290, -0.1620,  0.2175, -0.1138, -0.1350,  0.0453, -0.1198,\n",
            "         0.1928,  0.0903, -0.2025, -0.2451, -0.0756, -0.0444,  0.1104,  0.2030],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[-0.0050,  0.1012, -0.1624,  0.0061,  0.0033, -0.0260,  0.0611, -0.0235,\n",
            "          0.0087,  0.0359, -0.1329,  0.0868, -0.0292,  0.0288, -0.0205, -0.0243,\n",
            "          0.0543,  0.1526,  0.1952, -0.0964,  0.0931,  0.0370, -0.0143, -0.0043,\n",
            "          0.0086, -0.0133, -0.3197,  0.1091, -0.1526,  0.0273,  0.1383, -0.1366]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([0.0110], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test 200 0.99"
      ],
      "metadata": {
        "id": "TRlCPzkUEvi4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b = action_probs_top_n_epsilon(q_table, 1, 0.4)\n",
        "pi_b = experiment_actions(200, env, P_pi_b)\n",
        "P_pi_e = action_probs_top_n_epsilon(q_table, 2, 0.05)\n",
        "# pi_e = experiment_actions(200, env, P_pi_e)"
      ],
      "metadata": {
        "id": "Hn4yWSa6Ey1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b = action_probs_top_n_epsilon(q_table, 1, 0.4)\n",
        "pi_b = experiment_actions(200, env_30, P_pi_b)\n",
        "P_pi_e = action_probs_top_n_epsilon(q_table, 2, 0.05)\n",
        "# pi_e = experiment_actions(200, env, P_pi_e)\n",
        "model_200_0p99 = CustomizableFeatureNet(input_dim=2, hidden_dims=[6, 6], output_dim=1, dtype = torch.float64)\n",
        "test_200_0p99 = SCOPE_straight(model_200_0p99, 0.99, 10000, pi_b, P_pi_b, P_pi_e, dtype = torch.float64)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFPqTUz9EzVg",
        "outputId": "c24dbb18-401e-4404-e503-19176586c47b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.8547, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.8546716723749704\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.8345, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.8344950296004069\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.8157, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.815702575610253\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.7972, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.7971985257757953\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.7790, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.7790125020004666\n",
            "----------------------------------------\n",
            "Epoch 11\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.7612, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.761163863570924\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.7437, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.7436643420651126\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.7265, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.7265202843486895\n",
            "----------------------------------------\n",
            "Epoch 14\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.7097, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.7097352689463908\n",
            "----------------------------------------\n",
            "Epoch 15\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.6937, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.6936950996361412\n",
            "----------------------------------------\n",
            "Epoch 16\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.6787, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.6787496091902381\n",
            "----------------------------------------\n",
            "Epoch 17\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.6641, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.6641326426056419\n",
            "----------------------------------------\n",
            "Epoch 18\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.6491, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.6491106577802083\n",
            "----------------------------------------\n",
            "Epoch 19\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.6334, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.6333667722630629\n",
            "----------------------------------------\n",
            "Epoch 20\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.6176, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.6176165169242289\n",
            "----------------------------------------\n",
            "Epoch 21\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.6020, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.6019587691009125\n",
            "----------------------------------------\n",
            "Epoch 22\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.5865, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.5864614333403655\n",
            "----------------------------------------\n",
            "Epoch 23\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.5712, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.5711710016875733\n",
            "----------------------------------------\n",
            "Epoch 24\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.5561, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.5561201093237699\n",
            "----------------------------------------\n",
            "Epoch 25\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.5413, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.5413312509285723\n",
            "----------------------------------------\n",
            "Epoch 26\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.5268, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.5268211222619228\n",
            "----------------------------------------\n",
            "Epoch 27\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.5128, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.5127662288046468\n",
            "----------------------------------------\n",
            "Epoch 28\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.4991, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.4990903180712609\n",
            "----------------------------------------\n",
            "Epoch 29\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.4857, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.48571725956488965\n",
            "----------------------------------------\n",
            "Epoch 30\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.4727, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.4726511735617668\n",
            "----------------------------------------\n",
            "Epoch 31\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.4599, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.45988918164358644\n",
            "----------------------------------------\n",
            "Epoch 32\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.4474, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.44742813206934556\n",
            "----------------------------------------\n",
            "Epoch 33\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.4353, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.4352655622205185\n",
            "----------------------------------------\n",
            "Epoch 34\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.4234, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.4233983242252763\n",
            "----------------------------------------\n",
            "Epoch 35\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.4118, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.4118227108286335\n",
            "----------------------------------------\n",
            "Epoch 36\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.4021, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.4021134038855513\n",
            "----------------------------------------\n",
            "Epoch 37\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.3926, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.39257963185991446\n",
            "----------------------------------------\n",
            "Epoch 38\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.3831, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.38308203997671986\n",
            "----------------------------------------\n",
            "Epoch 39\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.3737, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.3736948442815689\n",
            "----------------------------------------\n",
            "Epoch 40\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.3645, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.36445031056541616\n",
            "----------------------------------------\n",
            "Epoch 41\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.3554, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.35536750421714974\n",
            "----------------------------------------\n",
            "Epoch 42\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.3465, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.34645815470296126\n",
            "----------------------------------------\n",
            "Epoch 43\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.3377, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.3377294703442143\n",
            "----------------------------------------\n",
            "Epoch 44\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.3287, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.32871648276595317\n",
            "----------------------------------------\n",
            "Epoch 45\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.3179, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.31790126888277037\n",
            "----------------------------------------\n",
            "Epoch 46\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.3071, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.3070625734259544\n",
            "----------------------------------------\n",
            "Epoch 47\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.2963, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.29627239376597064\n",
            "----------------------------------------\n",
            "Epoch 48\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.2856, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.28558616595403796\n",
            "----------------------------------------\n",
            "Epoch 49\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.2750, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.27504909881481915\n",
            "----------------------------------------\n",
            "Epoch 50\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.2647, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.26469327157199624\n",
            "----------------------------------------\n",
            "Epoch 51\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.2545, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.25454693646675536\n",
            "----------------------------------------\n",
            "Epoch 52\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.2446, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.24462840025074462\n",
            "----------------------------------------\n",
            "Epoch 53\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.2350, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.234953140051005\n",
            "----------------------------------------\n",
            "Epoch 54\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.2255, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.22553328412755216\n",
            "----------------------------------------\n",
            "Epoch 55\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.2164, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.21637794682926711\n",
            "----------------------------------------\n",
            "Epoch 56\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.2077, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.20765838692198108\n",
            "----------------------------------------\n",
            "Epoch 57\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.1994, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.19944057999559758\n",
            "----------------------------------------\n",
            "Epoch 58\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.1914, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.19136714645965625\n",
            "----------------------------------------\n",
            "Epoch 59\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.1835, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.18345732333640694\n",
            "----------------------------------------\n",
            "Epoch 60\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.1757, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.17572677515007384\n",
            "----------------------------------------\n",
            "Epoch 61\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.1682, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.16818803679903824\n",
            "----------------------------------------\n",
            "Epoch 62\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.1609, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.16090624467500525\n",
            "----------------------------------------\n",
            "Epoch 63\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.1541, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.1541089350798193\n",
            "----------------------------------------\n",
            "Epoch 64\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.1475, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.14753160424431366\n",
            "----------------------------------------\n",
            "Epoch 65\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.1412, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.14117376185585162\n",
            "----------------------------------------\n",
            "Epoch 66\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.1350, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.1350122598852806\n",
            "----------------------------------------\n",
            "Epoch 67\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.1291, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.12905755269560512\n",
            "----------------------------------------\n",
            "Epoch 68\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.1233, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.12331488088602341\n",
            "----------------------------------------\n",
            "Epoch 69\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.1178, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.11778112624286458\n",
            "----------------------------------------\n",
            "Epoch 70\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.1125, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.11245276892457491\n",
            "----------------------------------------\n",
            "Epoch 71\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.1074, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.10736790659156419\n",
            "----------------------------------------\n",
            "Epoch 72\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.1025, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.1025438984825482\n",
            "----------------------------------------\n",
            "Epoch 73\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0979, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.09787412170464208\n",
            "----------------------------------------\n",
            "Epoch 74\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0933, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.09334454892496756\n",
            "----------------------------------------\n",
            "Epoch 75\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0890, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.088957830242839\n",
            "----------------------------------------\n",
            "Epoch 76\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0847, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.08471570257624039\n",
            "----------------------------------------\n",
            "Epoch 77\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0806, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.08061900739904902\n",
            "----------------------------------------\n",
            "Epoch 78\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0767, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0766678274095598\n",
            "----------------------------------------\n",
            "Epoch 79\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0729, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.07286188557593551\n",
            "----------------------------------------\n",
            "Epoch 80\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0692, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.06919982278324037\n",
            "----------------------------------------\n",
            "Epoch 81\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0657, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.06567997995547233\n",
            "----------------------------------------\n",
            "Epoch 82\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0623, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.06230029651117082\n",
            "----------------------------------------\n",
            "Epoch 83\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0591, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.059058377477843316\n",
            "----------------------------------------\n",
            "Epoch 84\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0559, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.05594751305442548\n",
            "----------------------------------------\n",
            "Epoch 85\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0530, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.052966288055453295\n",
            "----------------------------------------\n",
            "Epoch 86\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0501, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.050113888317941106\n",
            "----------------------------------------\n",
            "Epoch 87\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0474, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.04738722108288303\n",
            "----------------------------------------\n",
            "Epoch 88\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0448, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.04478295871729696\n",
            "----------------------------------------\n",
            "Epoch 89\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0423, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.04229763834861956\n",
            "----------------------------------------\n",
            "Epoch 90\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0399, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.03992773570038501\n",
            "----------------------------------------\n",
            "Epoch 91\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0377, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.037669457929341316\n",
            "----------------------------------------\n",
            "Epoch 92\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0355, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0355193769124232\n",
            "----------------------------------------\n",
            "Epoch 93\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0335, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.03347395745564995\n",
            "----------------------------------------\n",
            "Epoch 94\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0315, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.031529609108374254\n",
            "----------------------------------------\n",
            "Epoch 95\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0297, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.02968271250845121\n",
            "----------------------------------------\n",
            "Epoch 96\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0279, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.027932768635906338\n",
            "----------------------------------------\n",
            "Epoch 97\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0263, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.026305800771803944\n",
            "----------------------------------------\n",
            "Epoch 98\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0248, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.024764322857021973\n",
            "----------------------------------------\n",
            "Epoch 99\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0233, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.02330437486812094\n",
            "----------------------------------------\n",
            "Epoch 100\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0219, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.02192264482312758\n",
            "----------------------------------------\n",
            "Epoch 101\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0206, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.020615676357044713\n",
            "----------------------------------------\n",
            "Epoch 102\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0194, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.01938006119066497\n",
            "----------------------------------------\n",
            "Epoch 103\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0182, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.018212120834255302\n",
            "----------------------------------------\n",
            "Epoch 104\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0171, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.017108966523152948\n",
            "----------------------------------------\n",
            "Epoch 105\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0161, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.016066395022520556\n",
            "----------------------------------------\n",
            "Epoch 106\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0151, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.015082014883762413\n",
            "----------------------------------------\n",
            "Epoch 107\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0142, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.014153956836780278\n",
            "----------------------------------------\n",
            "Epoch 108\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0133, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.013279728808191522\n",
            "----------------------------------------\n",
            "Epoch 109\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0125, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.012457231985769056\n",
            "----------------------------------------\n",
            "Epoch 110\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0117, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.011683105457310276\n",
            "----------------------------------------\n",
            "Epoch 111\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0113, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.011342913577924043\n",
            "----------------------------------------\n",
            "Epoch 112\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0112, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.011180702497889685\n",
            "----------------------------------------\n",
            "Epoch 113\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0110, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.011022237359410294\n",
            "----------------------------------------\n",
            "Epoch 114\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0109, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.010869776597278611\n",
            "----------------------------------------\n",
            "Epoch 115\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0107, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.010719522645914525\n",
            "----------------------------------------\n",
            "Epoch 116\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0106, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.010574777320221747\n",
            "----------------------------------------\n",
            "Epoch 117\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0104, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.010437090352892598\n",
            "----------------------------------------\n",
            "Epoch 118\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0103, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.010304455074789026\n",
            "----------------------------------------\n",
            "Epoch 119\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0102, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.010176327263684923\n",
            "----------------------------------------\n",
            "Epoch 120\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0101, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.010054057177073139\n",
            "----------------------------------------\n",
            "Epoch 121\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0099, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.009935777820803718\n",
            "----------------------------------------\n",
            "Epoch 122\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0098, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.009820751026385733\n",
            "----------------------------------------\n",
            "Epoch 123\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0097, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00970874948631789\n",
            "----------------------------------------\n",
            "Epoch 124\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0096, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.009599568012298087\n",
            "----------------------------------------\n",
            "Epoch 125\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0095, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00949302114531486\n",
            "----------------------------------------\n",
            "Epoch 126\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0094, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.009388941046875874\n",
            "----------------------------------------\n",
            "Epoch 127\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0093, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00928717563506485\n",
            "----------------------------------------\n",
            "Epoch 128\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0092, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.009187586934257173\n",
            "----------------------------------------\n",
            "Epoch 129\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0091, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.009090049611678653\n",
            "----------------------------------------\n",
            "Epoch 130\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0090, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.008994449677683479\n",
            "----------------------------------------\n",
            "Epoch 131\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0089, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.008900683329802086\n",
            "----------------------------------------\n",
            "Epoch 132\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0088, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.008808655923198792\n",
            "----------------------------------------\n",
            "Epoch 133\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0087, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.008718281052589538\n",
            "----------------------------------------\n",
            "Epoch 134\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0086, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00862947973253226\n",
            "----------------------------------------\n",
            "Epoch 135\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0085, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.008542179664715939\n",
            "----------------------------------------\n",
            "Epoch 136\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0085, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.008456314584310247\n",
            "----------------------------------------\n",
            "Epoch 137\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0084, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.008371823668269196\n",
            "----------------------------------------\n",
            "Epoch 138\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0083, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.008288661209704297\n",
            "----------------------------------------\n",
            "Epoch 139\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0082, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.008206768155038686\n",
            "----------------------------------------\n",
            "Epoch 140\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0081, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.008127881769166252\n",
            "----------------------------------------\n",
            "Epoch 141\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0081, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.008053068775143953\n",
            "----------------------------------------\n",
            "Epoch 142\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0080, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.007975731942808041\n",
            "----------------------------------------\n",
            "Epoch 143\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0079, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.007896228550827554\n",
            "----------------------------------------\n",
            "Epoch 144\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0078, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.007821717120735011\n",
            "----------------------------------------\n",
            "Epoch 145\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0077, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00774887220816159\n",
            "----------------------------------------\n",
            "Epoch 146\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0077, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.007676765820170244\n",
            "----------------------------------------\n",
            "Epoch 147\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0076, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.007605394924886864\n",
            "----------------------------------------\n",
            "Epoch 148\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0075, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.007534756645308239\n",
            "----------------------------------------\n",
            "Epoch 149\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0075, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.007464847531560026\n",
            "----------------------------------------\n",
            "Epoch 150\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0074, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.007395663626410915\n",
            "----------------------------------------\n",
            "Epoch 151\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0073, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.007327200524725006\n",
            "----------------------------------------\n",
            "Epoch 152\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0073, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.007259453427351505\n",
            "----------------------------------------\n",
            "Epoch 153\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0072, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.007192417678624616\n",
            "----------------------------------------\n",
            "Epoch 154\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0071, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.007126087383820872\n",
            "----------------------------------------\n",
            "Epoch 155\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0071, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.007060456797068244\n",
            "----------------------------------------\n",
            "Epoch 156\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0070, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.006995519991076635\n",
            "----------------------------------------\n",
            "Epoch 157\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0069, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.006931270845352345\n",
            "----------------------------------------\n",
            "Epoch 158\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0069, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.006867703074766262\n",
            "----------------------------------------\n",
            "Epoch 159\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0068, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.006804810257151416\n",
            "----------------------------------------\n",
            "Epoch 160\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0067, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.006744395701342055\n",
            "----------------------------------------\n",
            "Epoch 161\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0067, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.006683942467567038\n",
            "----------------------------------------\n",
            "Epoch 162\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0066, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.006622084782085688\n",
            "----------------------------------------\n",
            "Epoch 163\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0066, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.006562973766531543\n",
            "----------------------------------------\n",
            "Epoch 164\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0065, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.006504374055503997\n",
            "----------------------------------------\n",
            "Epoch 165\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0064, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0064462946883922885\n",
            "----------------------------------------\n",
            "Epoch 166\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0064, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.006388741330523116\n",
            "----------------------------------------\n",
            "Epoch 167\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0063, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00633171551006158\n",
            "----------------------------------------\n",
            "Epoch 168\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0063, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.006275219631772799\n",
            "----------------------------------------\n",
            "Epoch 169\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0062, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.006219282434222159\n",
            "----------------------------------------\n",
            "Epoch 170\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0062, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.006164465507695038\n",
            "----------------------------------------\n",
            "Epoch 171\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0061, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0061101379558747585\n",
            "----------------------------------------\n",
            "Epoch 172\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0061, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.006056278845595384\n",
            "----------------------------------------\n",
            "Epoch 173\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0060, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.006002893239057439\n",
            "----------------------------------------\n",
            "Epoch 174\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0059, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.005949985106260439\n",
            "----------------------------------------\n",
            "Epoch 175\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0059, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.005898682865317154\n",
            "----------------------------------------\n",
            "Epoch 176\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0058, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.005846501613345426\n",
            "----------------------------------------\n",
            "Epoch 177\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0058, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.005795741430318968\n",
            "----------------------------------------\n",
            "Epoch 178\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0057, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.005745371177043594\n",
            "----------------------------------------\n",
            "Epoch 179\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0057, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.005695388445082429\n",
            "----------------------------------------\n",
            "Epoch 180\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0056, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.005645809115981477\n",
            "----------------------------------------\n",
            "Epoch 181\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0056, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.005597565871908052\n",
            "----------------------------------------\n",
            "Epoch 182\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0055, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.005548486469223402\n",
            "----------------------------------------\n",
            "Epoch 183\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0055, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.005500687588614943\n",
            "----------------------------------------\n",
            "Epoch 184\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0055, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.005453322596869906\n",
            "----------------------------------------\n",
            "Epoch 185\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0054, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.005406428182001911\n",
            "----------------------------------------\n",
            "Epoch 186\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0054, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00535991919315069\n",
            "----------------------------------------\n",
            "Epoch 187\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0053, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.005313930317373878\n",
            "----------------------------------------\n",
            "Epoch 188\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0053, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.005268645073306434\n",
            "----------------------------------------\n",
            "Epoch 189\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0052, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.005223825966489567\n",
            "----------------------------------------\n",
            "Epoch 190\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0052, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0051793524821357765\n",
            "----------------------------------------\n",
            "Epoch 191\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0051, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.005135232092539864\n",
            "----------------------------------------\n",
            "Epoch 192\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0051, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.005091471085501814\n",
            "----------------------------------------\n",
            "Epoch 193\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0050, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.005048074801492975\n",
            "----------------------------------------\n",
            "Epoch 194\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0050, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.005005651857176431\n",
            "----------------------------------------\n",
            "Epoch 195\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0050, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00496293353017183\n",
            "----------------------------------------\n",
            "Epoch 196\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0049, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.004921147681785879\n",
            "----------------------------------------\n",
            "Epoch 197\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0049, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.004879736006744593\n",
            "----------------------------------------\n",
            "Epoch 198\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0048, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.004838633802147718\n",
            "----------------------------------------\n",
            "Epoch 199\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0048, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.004797849085388216\n",
            "----------------------------------------\n",
            "Epoch 200\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0048, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.004758342649854319\n",
            "----------------------------------------\n",
            "Epoch 201\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0047, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.004717834883760589\n",
            "----------------------------------------\n",
            "Epoch 202\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0047, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.004678563087059537\n",
            "----------------------------------------\n",
            "Epoch 203\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.004639583265879986\n",
            "----------------------------------------\n",
            "Epoch 204\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.004600902497375698\n",
            "----------------------------------------\n",
            "Epoch 205\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.004562558611391957\n",
            "----------------------------------------\n",
            "Epoch 206\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0045, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.004524752132582197\n",
            "----------------------------------------\n",
            "Epoch 207\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0045, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.004487267497615992\n",
            "----------------------------------------\n",
            "Epoch 208\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0045, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.004450305403283982\n",
            "----------------------------------------\n",
            "Epoch 209\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0044, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.004413621927511726\n",
            "----------------------------------------\n",
            "Epoch 210\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0044, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.004380276312199833\n",
            "----------------------------------------\n",
            "Epoch 211\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0043, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.004347794941432448\n",
            "----------------------------------------\n",
            "Epoch 212\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0043, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.004312246269516688\n",
            "----------------------------------------\n",
            "Epoch 213\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0043, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.004277212033990483\n",
            "----------------------------------------\n",
            "Epoch 214\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0042, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.004240766660121044\n",
            "----------------------------------------\n",
            "Epoch 215\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0042, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.004203105753520934\n",
            "----------------------------------------\n",
            "Epoch 216\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0042, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.004167187609976871\n",
            "----------------------------------------\n",
            "Epoch 217\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0041, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0041274968982973614\n",
            "----------------------------------------\n",
            "Epoch 218\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0041, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.004088275959400935\n",
            "----------------------------------------\n",
            "Epoch 219\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0040, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.004049404203066784\n",
            "----------------------------------------\n",
            "Epoch 220\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0040, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.004009802907216467\n",
            "----------------------------------------\n",
            "Epoch 221\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0040, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.003969598803202217\n",
            "----------------------------------------\n",
            "Epoch 222\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0039, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.003931009339283031\n",
            "----------------------------------------\n",
            "Epoch 223\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0039, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0038909835262761774\n",
            "----------------------------------------\n",
            "Epoch 224\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0039, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.003852249326284995\n",
            "----------------------------------------\n",
            "Epoch 225\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0038, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0038154266741377988\n",
            "----------------------------------------\n",
            "Epoch 226\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0038, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0037782966894316958\n",
            "----------------------------------------\n",
            "Epoch 227\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0037, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0037406923524199525\n",
            "----------------------------------------\n",
            "Epoch 228\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0037, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0037027104211728615\n",
            "----------------------------------------\n",
            "Epoch 229\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0037, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0036644387059539844\n",
            "----------------------------------------\n",
            "Epoch 230\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0036259561758741343\n",
            "----------------------------------------\n",
            "Epoch 231\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0035873340671417693\n",
            "----------------------------------------\n",
            "Epoch 232\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0035, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0035498575816885532\n",
            "----------------------------------------\n",
            "Epoch 233\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0035, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0035137252880671163\n",
            "----------------------------------------\n",
            "Epoch 234\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0035, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0034771764375151324\n",
            "----------------------------------------\n",
            "Epoch 235\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0034, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0034406799530181617\n",
            "----------------------------------------\n",
            "Epoch 236\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0034, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0034050940073021858\n",
            "----------------------------------------\n",
            "Epoch 237\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0034, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.003369205994145485\n",
            "----------------------------------------\n",
            "Epoch 238\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0033, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0033330940652911457\n",
            "----------------------------------------\n",
            "Epoch 239\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0033, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0032975089801288247\n",
            "----------------------------------------\n",
            "Epoch 240\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0033, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.003263995372325778\n",
            "----------------------------------------\n",
            "Epoch 241\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0032, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.003229933705532338\n",
            "----------------------------------------\n",
            "Epoch 242\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0032, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.003194965188322567\n",
            "----------------------------------------\n",
            "Epoch 243\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0032, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0031614555083920876\n",
            "----------------------------------------\n",
            "Epoch 244\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0031, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.003128298186928097\n",
            "----------------------------------------\n",
            "Epoch 245\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0031, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.003095087022228678\n",
            "----------------------------------------\n",
            "Epoch 246\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0031, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0030624423837157322\n",
            "----------------------------------------\n",
            "Epoch 247\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0030, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0030296016042369524\n",
            "----------------------------------------\n",
            "Epoch 248\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0030, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0029968038042988312\n",
            "----------------------------------------\n",
            "Epoch 249\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0030, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0029648621633291913\n",
            "----------------------------------------\n",
            "Epoch 250\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0029, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0029336828362678978\n",
            "----------------------------------------\n",
            "Epoch 251\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0029, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.002902063357916683\n",
            "----------------------------------------\n",
            "Epoch 252\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0029, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.002871873313538257\n",
            "----------------------------------------\n",
            "Epoch 253\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0028, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.002841618716728247\n",
            "----------------------------------------\n",
            "Epoch 254\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0028, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0028118252567851626\n",
            "----------------------------------------\n",
            "Epoch 255\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0028, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0027819871259834672\n",
            "----------------------------------------\n",
            "Epoch 256\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0028, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0027521081311857945\n",
            "----------------------------------------\n",
            "Epoch 257\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0027, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0027222301530419775\n",
            "----------------------------------------\n",
            "Epoch 258\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0027, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.002694197551154959\n",
            "----------------------------------------\n",
            "Epoch 259\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0027, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0026660688744658124\n",
            "----------------------------------------\n",
            "Epoch 260\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0026, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.002637505433064731\n",
            "----------------------------------------\n",
            "Epoch 261\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0026, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0026084026861855005\n",
            "----------------------------------------\n",
            "Epoch 262\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0026, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.002580850796633104\n",
            "----------------------------------------\n",
            "Epoch 263\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0026, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00255380875616087\n",
            "----------------------------------------\n",
            "Epoch 264\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0025, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0025267630039775843\n",
            "----------------------------------------\n",
            "Epoch 265\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0025, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00250001731427122\n",
            "----------------------------------------\n",
            "Epoch 266\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0025, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0024733673118707213\n",
            "----------------------------------------\n",
            "Epoch 267\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0024, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.002447453594632654\n",
            "----------------------------------------\n",
            "Epoch 268\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0024, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0024215791143245126\n",
            "----------------------------------------\n",
            "Epoch 269\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0024, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.002396174798345287\n",
            "----------------------------------------\n",
            "Epoch 270\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0024, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0023707946409597946\n",
            "----------------------------------------\n",
            "Epoch 271\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0023, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0023454885158656815\n",
            "----------------------------------------\n",
            "Epoch 272\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0023, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0023205889623067757\n",
            "----------------------------------------\n",
            "Epoch 273\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0023, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0022961210399871264\n",
            "----------------------------------------\n",
            "Epoch 274\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0023, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.002272196914480386\n",
            "----------------------------------------\n",
            "Epoch 275\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0022, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0022482202971244496\n",
            "----------------------------------------\n",
            "Epoch 276\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0022, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0022242332146298702\n",
            "----------------------------------------\n",
            "Epoch 277\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0022, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0022015418178001874\n",
            "----------------------------------------\n",
            "Epoch 278\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0022, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0021786352210143543\n",
            "----------------------------------------\n",
            "Epoch 279\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0022, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0021552920226886076\n",
            "----------------------------------------\n",
            "Epoch 280\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0021, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0021327727917707317\n",
            "----------------------------------------\n",
            "Epoch 281\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0021, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.002110641087452761\n",
            "----------------------------------------\n",
            "Epoch 282\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0021, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0020887613356420746\n",
            "----------------------------------------\n",
            "Epoch 283\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0021, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0020668416786557365\n",
            "----------------------------------------\n",
            "Epoch 284\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0020, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.002044915099760511\n",
            "----------------------------------------\n",
            "Epoch 285\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0020, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.002023322519608584\n",
            "----------------------------------------\n",
            "Epoch 286\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0020, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.002002763615305977\n",
            "----------------------------------------\n",
            "Epoch 287\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0020, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.001982121914126294\n",
            "----------------------------------------\n",
            "Epoch 288\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0020, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0019612276218746844\n",
            "----------------------------------------\n",
            "Epoch 289\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0019, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.001940268246372342\n",
            "----------------------------------------\n",
            "Epoch 290\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0019, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.001920379034445509\n",
            "----------------------------------------\n",
            "Epoch 291\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0019, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0019004476057686171\n",
            "----------------------------------------\n",
            "Epoch 292\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0019, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0018805071867076574\n",
            "----------------------------------------\n",
            "Epoch 293\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0019, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0018611948164111507\n",
            "----------------------------------------\n",
            "Epoch 294\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0018, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0018419817386779612\n",
            "----------------------------------------\n",
            "Epoch 295\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0018, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0018230014607385399\n",
            "----------------------------------------\n",
            "Epoch 296\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0018, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0018041461237785325\n",
            "----------------------------------------\n",
            "Epoch 297\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0018, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0017855587760095897\n",
            "----------------------------------------\n",
            "Epoch 298\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0018, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0017669611615841435\n",
            "----------------------------------------\n",
            "Epoch 299\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0017, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.001749272264864262\n",
            "----------------------------------------\n",
            "Epoch 300\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0017, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0017315572465489608\n",
            "----------------------------------------\n",
            "Epoch 301\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0017, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0017134210936991957\n",
            "----------------------------------------\n",
            "Epoch 302\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0017, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0016959944185007871\n",
            "----------------------------------------\n",
            "Epoch 303\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0017, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.001678989113777594\n",
            "----------------------------------------\n",
            "Epoch 304\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0017, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0016620447517144107\n",
            "----------------------------------------\n",
            "Epoch 305\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0016, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0016450720030536927\n",
            "----------------------------------------\n",
            "Epoch 306\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0016, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.001628099743668732\n",
            "----------------------------------------\n",
            "Epoch 307\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0016, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0016111489750585289\n",
            "----------------------------------------\n",
            "Epoch 308\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0016, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0015954247655366439\n",
            "----------------------------------------\n",
            "Epoch 309\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0016, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.001579632828789209\n",
            "----------------------------------------\n",
            "Epoch 310\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0016, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0015634376479176488\n",
            "----------------------------------------\n",
            "Epoch 311\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0015, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0015471617564655573\n",
            "----------------------------------------\n",
            "Epoch 312\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0015, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0015319451038816152\n",
            "----------------------------------------\n",
            "Epoch 313\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0015, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.001516574396806452\n",
            "----------------------------------------\n",
            "Epoch 314\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0015, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0015010398515153598\n",
            "----------------------------------------\n",
            "Epoch 315\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0015, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0014853835457157199\n",
            "----------------------------------------\n",
            "Epoch 316\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0015, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0014697745268949162\n",
            "----------------------------------------\n",
            "Epoch 317\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0015, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.001454085361399833\n",
            "----------------------------------------\n",
            "Epoch 318\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0014, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0014382371258495094\n",
            "----------------------------------------\n",
            "Epoch 319\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0014, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0014231376927888912\n",
            "----------------------------------------\n",
            "Epoch 320\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0014, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0014082641480695005\n",
            "----------------------------------------\n",
            "Epoch 321\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0014, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0013940163722198813\n",
            "----------------------------------------\n",
            "Epoch 322\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0014, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0013775471158843954\n",
            "----------------------------------------\n",
            "Epoch 323\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0014, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.001362554621608391\n",
            "----------------------------------------\n",
            "Epoch 324\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0013456469770667032\n",
            "----------------------------------------\n",
            "Epoch 325\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0013282705151685204\n",
            "----------------------------------------\n",
            "Epoch 326\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0013104633615438981\n",
            "----------------------------------------\n",
            "Epoch 327\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0012922268404032041\n",
            "----------------------------------------\n",
            "Epoch 328\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.001273853847479378\n",
            "----------------------------------------\n",
            "Epoch 329\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0013, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0012557244089278668\n",
            "----------------------------------------\n",
            "Epoch 330\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0012373629313586227\n",
            "----------------------------------------\n",
            "Epoch 331\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0012177641314448534\n",
            "----------------------------------------\n",
            "Epoch 332\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0011977798007275515\n",
            "----------------------------------------\n",
            "Epoch 333\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0011782542286178535\n",
            "----------------------------------------\n",
            "Epoch 334\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0012, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0011585501652845904\n",
            "----------------------------------------\n",
            "Epoch 335\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0011346905256367043\n",
            "----------------------------------------\n",
            "Epoch 336\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0011041609069554013\n",
            "----------------------------------------\n",
            "Epoch 337\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0011, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0010744883525759382\n",
            "----------------------------------------\n",
            "Epoch 338\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0010441761847287943\n",
            "----------------------------------------\n",
            "Epoch 339\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0010143799094075097\n",
            "----------------------------------------\n",
            "Epoch 340\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0009848751401308508\n",
            "----------------------------------------\n",
            "Epoch 341\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0010, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.000955346152842433\n",
            "----------------------------------------\n",
            "Epoch 342\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.000923429748031222\n",
            "----------------------------------------\n",
            "Epoch 343\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.000891988612060904\n",
            "----------------------------------------\n",
            "Epoch 344\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0009, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0008620014901299793\n",
            "----------------------------------------\n",
            "Epoch 345\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0008330483619741713\n",
            "----------------------------------------\n",
            "Epoch 346\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.000804933611751626\n",
            "----------------------------------------\n",
            "Epoch 347\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0007774862353237556\n",
            "----------------------------------------\n",
            "Epoch 348\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0008, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0007508325484410617\n",
            "----------------------------------------\n",
            "Epoch 349\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0007255744901805848\n",
            "----------------------------------------\n",
            "Epoch 350\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0007013321125494831\n",
            "----------------------------------------\n",
            "Epoch 351\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0006782316782719347\n",
            "----------------------------------------\n",
            "Epoch 352\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0007, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0006564792524678985\n",
            "----------------------------------------\n",
            "Epoch 353\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0006357222359547283\n",
            "----------------------------------------\n",
            "Epoch 354\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0006060479559767884\n",
            "----------------------------------------\n",
            "Epoch 355\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0005757659998306523\n",
            "----------------------------------------\n",
            "Epoch 356\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0006, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0005527655179251005\n",
            "----------------------------------------\n",
            "Epoch 357\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0005354388693546488\n",
            "----------------------------------------\n",
            "Epoch 358\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0005215574141305902\n",
            "----------------------------------------\n",
            "Epoch 359\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0005106774329698534\n",
            "----------------------------------------\n",
            "Epoch 360\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.000501490453558698\n",
            "----------------------------------------\n",
            "Epoch 361\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0004928403230214485\n",
            "----------------------------------------\n",
            "Epoch 362\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00048424476755108556\n",
            "----------------------------------------\n",
            "Epoch 363\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0004746704877561292\n",
            "----------------------------------------\n",
            "Epoch 364\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0004641593668757794\n",
            "----------------------------------------\n",
            "Epoch 365\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0005, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00045332896497080353\n",
            "----------------------------------------\n",
            "Epoch 366\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0004425779553906703\n",
            "----------------------------------------\n",
            "Epoch 367\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0004314530582880676\n",
            "----------------------------------------\n",
            "Epoch 368\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0004202141836297342\n",
            "----------------------------------------\n",
            "Epoch 369\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00040927741231566267\n",
            "----------------------------------------\n",
            "Epoch 370\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0003990015951528856\n",
            "----------------------------------------\n",
            "Epoch 371\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00038955485631928796\n",
            "----------------------------------------\n",
            "Epoch 372\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00038100944125670107\n",
            "----------------------------------------\n",
            "Epoch 373\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0003733366079823045\n",
            "----------------------------------------\n",
            "Epoch 374\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0003665685855314465\n",
            "----------------------------------------\n",
            "Epoch 375\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00036033234734610727\n",
            "----------------------------------------\n",
            "Epoch 376\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0004, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00035458788503525316\n",
            "----------------------------------------\n",
            "Epoch 377\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.000348058630473583\n",
            "----------------------------------------\n",
            "Epoch 378\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00033947873307019547\n",
            "----------------------------------------\n",
            "Epoch 379\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00033025998788080327\n",
            "----------------------------------------\n",
            "Epoch 380\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0003205026866896507\n",
            "----------------------------------------\n",
            "Epoch 381\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00031046374798354893\n",
            "----------------------------------------\n",
            "Epoch 382\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0003001810798512492\n",
            "----------------------------------------\n",
            "Epoch 383\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00028982515711268263\n",
            "----------------------------------------\n",
            "Epoch 384\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00027966795437917686\n",
            "----------------------------------------\n",
            "Epoch 385\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00027030744434853053\n",
            "----------------------------------------\n",
            "Epoch 386\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0002627508230190878\n",
            "----------------------------------------\n",
            "Epoch 387\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0003, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0002555573467011567\n",
            "----------------------------------------\n",
            "Epoch 388\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0002486300651710869\n",
            "----------------------------------------\n",
            "Epoch 389\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0002421377087176469\n",
            "----------------------------------------\n",
            "Epoch 390\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00023608910347038263\n",
            "----------------------------------------\n",
            "Epoch 391\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0002304596087958113\n",
            "----------------------------------------\n",
            "Epoch 392\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00022509120144213618\n",
            "----------------------------------------\n",
            "Epoch 393\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00021993870692853243\n",
            "----------------------------------------\n",
            "Epoch 394\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0002149928057170318\n",
            "----------------------------------------\n",
            "Epoch 395\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00021025006153355157\n",
            "----------------------------------------\n",
            "Epoch 396\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0002057025268646185\n",
            "----------------------------------------\n",
            "Epoch 397\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00020131042512004977\n",
            "----------------------------------------\n",
            "Epoch 398\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001970658355520743\n",
            "----------------------------------------\n",
            "Epoch 399\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00019297794080183142\n",
            "----------------------------------------\n",
            "Epoch 400\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00018914210640103555\n",
            "----------------------------------------\n",
            "Epoch 401\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00018551038882905365\n",
            "----------------------------------------\n",
            "Epoch 402\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001820520038178839\n",
            "----------------------------------------\n",
            "Epoch 403\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00017876948726092996\n",
            "----------------------------------------\n",
            "Epoch 404\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001756626742500793\n",
            "----------------------------------------\n",
            "Epoch 405\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00017273369147808137\n",
            "----------------------------------------\n",
            "Epoch 406\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00016997469611855585\n",
            "----------------------------------------\n",
            "Epoch 407\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00016734929977990464\n",
            "----------------------------------------\n",
            "Epoch 408\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00016485231447057835\n",
            "----------------------------------------\n",
            "Epoch 409\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00016249194240447365\n",
            "----------------------------------------\n",
            "Epoch 410\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001602472935378069\n",
            "----------------------------------------\n",
            "Epoch 411\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00015810488819045652\n",
            "----------------------------------------\n",
            "Epoch 412\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00015605248952082668\n",
            "----------------------------------------\n",
            "Epoch 413\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00015406964834989092\n",
            "----------------------------------------\n",
            "Epoch 414\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00015220250459948174\n",
            "----------------------------------------\n",
            "Epoch 415\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001504320532635276\n",
            "----------------------------------------\n",
            "Epoch 416\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001487337350639054\n",
            "----------------------------------------\n",
            "Epoch 417\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001470971649972191\n",
            "----------------------------------------\n",
            "Epoch 418\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001455207784503063\n",
            "----------------------------------------\n",
            "Epoch 419\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00014400657688069777\n",
            "----------------------------------------\n",
            "Epoch 420\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00014254782019648297\n",
            "----------------------------------------\n",
            "Epoch 421\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001411392067566479\n",
            "----------------------------------------\n",
            "Epoch 422\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00013977735136350703\n",
            "----------------------------------------\n",
            "Epoch 423\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00013845931181420874\n",
            "----------------------------------------\n",
            "Epoch 424\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00013718221015337258\n",
            "----------------------------------------\n",
            "Epoch 425\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001359333556896158\n",
            "----------------------------------------\n",
            "Epoch 426\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001347192116079215\n",
            "----------------------------------------\n",
            "Epoch 427\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00013353819263737756\n",
            "----------------------------------------\n",
            "Epoch 428\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00013238820356297005\n",
            "----------------------------------------\n",
            "Epoch 429\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00013126718144396013\n",
            "----------------------------------------\n",
            "Epoch 430\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00013017346693689578\n",
            "----------------------------------------\n",
            "Epoch 431\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00012910573585163182\n",
            "----------------------------------------\n",
            "Epoch 432\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00012806230548860037\n",
            "----------------------------------------\n",
            "Epoch 433\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00012704166120768427\n",
            "----------------------------------------\n",
            "Epoch 434\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00012604250441508081\n",
            "----------------------------------------\n",
            "Epoch 435\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001250636492978868\n",
            "----------------------------------------\n",
            "Epoch 436\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001241040224849837\n",
            "----------------------------------------\n",
            "Epoch 437\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00012316266113518632\n",
            "----------------------------------------\n",
            "Epoch 438\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00012223870754101974\n",
            "----------------------------------------\n",
            "Epoch 439\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001213314099062881\n",
            "----------------------------------------\n",
            "Epoch 440\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00012043013120516517\n",
            "----------------------------------------\n",
            "Epoch 441\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00011951294546292964\n",
            "----------------------------------------\n",
            "Epoch 442\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00011860824418407979\n",
            "----------------------------------------\n",
            "Epoch 443\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00011771542270500585\n",
            "----------------------------------------\n",
            "Epoch 444\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00011683455388081289\n",
            "----------------------------------------\n",
            "Epoch 445\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00011596566650270851\n",
            "----------------------------------------\n",
            "Epoch 446\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00011510881796107951\n",
            "----------------------------------------\n",
            "Epoch 447\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001142640798546647\n",
            "----------------------------------------\n",
            "Epoch 448\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00011343154017157597\n",
            "----------------------------------------\n",
            "Epoch 449\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00011261141396677496\n",
            "----------------------------------------\n",
            "Epoch 450\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00011180367323267924\n",
            "----------------------------------------\n",
            "Epoch 451\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00011100854528419645\n",
            "----------------------------------------\n",
            "Epoch 452\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00011022970784588333\n",
            "----------------------------------------\n",
            "Epoch 453\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001094688779074053\n",
            "----------------------------------------\n",
            "Epoch 454\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00010872155927584015\n",
            "----------------------------------------\n",
            "Epoch 455\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00010798761796236049\n",
            "----------------------------------------\n",
            "Epoch 456\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00010726910582915247\n",
            "----------------------------------------\n",
            "Epoch 457\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00010656538911198648\n",
            "----------------------------------------\n",
            "Epoch 458\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00010587508340766908\n",
            "----------------------------------------\n",
            "Epoch 459\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00010519822356570929\n",
            "----------------------------------------\n",
            "Epoch 460\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001045348510920827\n",
            "----------------------------------------\n",
            "Epoch 461\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00010388501014020814\n",
            "----------------------------------------\n",
            "Epoch 462\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00010324874420823071\n",
            "----------------------------------------\n",
            "Epoch 463\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00010262609330777083\n",
            "----------------------------------------\n",
            "Epoch 464\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00010201709167558936\n",
            "----------------------------------------\n",
            "Epoch 465\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00010142176598871864\n",
            "----------------------------------------\n",
            "Epoch 466\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0001008401340523783\n",
            "----------------------------------------\n",
            "Epoch 467\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0001, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.00010027222489698721\n",
            "----------------------------------------\n",
            "Epoch 468\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.9718e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.971796432054721e-05\n",
            "----------------------------------------\n",
            "Epoch 469\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.9177e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.917734263558461e-05\n",
            "----------------------------------------\n",
            "Epoch 470\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.8650e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.865044255195552e-05\n",
            "----------------------------------------\n",
            "Epoch 471\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.8137e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.813712776023634e-05\n",
            "----------------------------------------\n",
            "Epoch 472\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.7637e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.763735251167343e-05\n",
            "----------------------------------------\n",
            "Epoch 473\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.7151e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.715105542997485e-05\n",
            "----------------------------------------\n",
            "Epoch 474\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.6678e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.667815116795096e-05\n",
            "----------------------------------------\n",
            "Epoch 475\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.6218e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.62183189122225e-05\n",
            "----------------------------------------\n",
            "Epoch 476\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.5771e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.577145001745294e-05\n",
            "----------------------------------------\n",
            "Epoch 477\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.5338e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.53376261741958e-05\n",
            "----------------------------------------\n",
            "Epoch 478\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.4917e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.491671238201975e-05\n",
            "----------------------------------------\n",
            "Epoch 479\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.4508e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.450775290575526e-05\n",
            "----------------------------------------\n",
            "Epoch 480\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.4059e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.405935422179418e-05\n",
            "----------------------------------------\n",
            "Epoch 481\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.3597e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.359653799068847e-05\n",
            "----------------------------------------\n",
            "Epoch 482\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.3126e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.312629750715886e-05\n",
            "----------------------------------------\n",
            "Epoch 483\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.2658e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.265782626688734e-05\n",
            "----------------------------------------\n",
            "Epoch 484\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.2200e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.219950800967883e-05\n",
            "----------------------------------------\n",
            "Epoch 485\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.1758e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.175833767677823e-05\n",
            "----------------------------------------\n",
            "Epoch 486\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.1340e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.133958048126332e-05\n",
            "----------------------------------------\n",
            "Epoch 487\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.0949e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.094910363344034e-05\n",
            "----------------------------------------\n",
            "Epoch 488\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.0593e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.059317598010678e-05\n",
            "----------------------------------------\n",
            "Epoch 489\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.0265e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.026539483706539e-05\n",
            "----------------------------------------\n",
            "Epoch 490\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.9965e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.99645076167691e-05\n",
            "----------------------------------------\n",
            "Epoch 491\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.9688e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.968811981540364e-05\n",
            "----------------------------------------\n",
            "Epoch 492\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.9432e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.943193887280256e-05\n",
            "----------------------------------------\n",
            "Epoch 493\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.9194e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.919390185573453e-05\n",
            "----------------------------------------\n",
            "Epoch 494\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.8971e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.897073091099512e-05\n",
            "----------------------------------------\n",
            "Epoch 495\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.8759e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.875940048325994e-05\n",
            "----------------------------------------\n",
            "Epoch 496\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.8557e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.855731514465743e-05\n",
            "----------------------------------------\n",
            "Epoch 497\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.8363e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.836257676649113e-05\n",
            "----------------------------------------\n",
            "Epoch 498\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.8175e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.817460024874166e-05\n",
            "----------------------------------------\n",
            "Epoch 499\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.7992e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.799184564323814e-05\n",
            "----------------------------------------\n",
            "Epoch 500\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.7813e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.781347917973461e-05\n",
            "----------------------------------------\n",
            "Epoch 501\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.7639e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.763938405703171e-05\n",
            "----------------------------------------\n",
            "Epoch 502\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.7470e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.746971101505755e-05\n",
            "----------------------------------------\n",
            "Epoch 503\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.7305e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.730476729562923e-05\n",
            "----------------------------------------\n",
            "Epoch 504\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.7145e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.714491574094922e-05\n",
            "----------------------------------------\n",
            "Epoch 505\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.6990e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.69899424100473e-05\n",
            "----------------------------------------\n",
            "Epoch 506\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.6840e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.684038753342556e-05\n",
            "----------------------------------------\n",
            "Epoch 507\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.6697e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.669677563473562e-05\n",
            "----------------------------------------\n",
            "Epoch 508\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.6559e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.65590087099747e-05\n",
            "----------------------------------------\n",
            "Epoch 509\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.6431e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.64311804421734e-05\n",
            "----------------------------------------\n",
            "Epoch 510\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.6310e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.630993948637582e-05\n",
            "----------------------------------------\n",
            "Epoch 511\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.6193e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.61928003915945e-05\n",
            "----------------------------------------\n",
            "Epoch 512\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.6079e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.607930191262107e-05\n",
            "----------------------------------------\n",
            "Epoch 513\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.5969e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.596908086196596e-05\n",
            "----------------------------------------\n",
            "Epoch 514\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.5862e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.586194157876907e-05\n",
            "----------------------------------------\n",
            "Epoch 515\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.5758e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.575758313234516e-05\n",
            "----------------------------------------\n",
            "Epoch 516\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.5656e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.565554644026795e-05\n",
            "----------------------------------------\n",
            "Epoch 517\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.5556e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.555563211143476e-05\n",
            "----------------------------------------\n",
            "Epoch 518\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.5458e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.545768507962494e-05\n",
            "----------------------------------------\n",
            "Epoch 519\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.5362e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.53615860155631e-05\n",
            "----------------------------------------\n",
            "Epoch 520\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.5267e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.526724609894265e-05\n",
            "----------------------------------------\n",
            "Epoch 521\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.5175e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.517459033074577e-05\n",
            "----------------------------------------\n",
            "Epoch 522\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.5084e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.508358727779532e-05\n",
            "----------------------------------------\n",
            "Epoch 523\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.4994e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.499420292741217e-05\n",
            "----------------------------------------\n",
            "Epoch 524\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.4906e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.490631406836577e-05\n",
            "----------------------------------------\n",
            "Epoch 525\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.4820e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.48198521573866e-05\n",
            "----------------------------------------\n",
            "Epoch 526\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.4735e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.473474125613863e-05\n",
            "----------------------------------------\n",
            "Epoch 527\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.4651e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.465089753141982e-05\n",
            "----------------------------------------\n",
            "Epoch 528\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.4568e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.456823000753702e-05\n",
            "----------------------------------------\n",
            "Epoch 529\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.4487e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.448664227857084e-05\n",
            "----------------------------------------\n",
            "Epoch 530\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.4406e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.440646452620853e-05\n",
            "----------------------------------------\n",
            "Epoch 531\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.4327e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.432741854775503e-05\n",
            "----------------------------------------\n",
            "Epoch 532\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.4249e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.424895572316617e-05\n",
            "----------------------------------------\n",
            "Epoch 533\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.4171e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.417103313033832e-05\n",
            "----------------------------------------\n",
            "Epoch 534\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.4094e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.409357514206891e-05\n",
            "----------------------------------------\n",
            "Epoch 535\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.4017e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.401651964757775e-05\n",
            "----------------------------------------\n",
            "Epoch 536\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.3940e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.39398826000485e-05\n",
            "----------------------------------------\n",
            "Epoch 537\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.3864e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.386352707294488e-05\n",
            "----------------------------------------\n",
            "Epoch 538\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.3787e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.378747020662781e-05\n",
            "----------------------------------------\n",
            "Epoch 539\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.3712e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.371166187470494e-05\n",
            "----------------------------------------\n",
            "Epoch 540\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.3636e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.363593039234458e-05\n",
            "----------------------------------------\n",
            "Epoch 541\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.3561e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.356096997799295e-05\n",
            "----------------------------------------\n",
            "Epoch 542\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.3486e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.348626756731773e-05\n",
            "----------------------------------------\n",
            "Epoch 543\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.3412e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.34115507702473e-05\n",
            "----------------------------------------\n",
            "Epoch 544\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.3338e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.333765923415715e-05\n",
            "----------------------------------------\n",
            "Epoch 545\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.3264e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.326407319956006e-05\n",
            "----------------------------------------\n",
            "Epoch 546\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.3191e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.319064510354874e-05\n",
            "----------------------------------------\n",
            "Epoch 547\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.3117e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.31173842354559e-05\n",
            "----------------------------------------\n",
            "Epoch 548\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.3044e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.3044288367534e-05\n",
            "----------------------------------------\n",
            "Epoch 549\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.2971e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.297136597554558e-05\n",
            "----------------------------------------\n",
            "Epoch 550\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.2899e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.289854047052946e-05\n",
            "----------------------------------------\n",
            "Epoch 551\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.2826e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.282615017540665e-05\n",
            "----------------------------------------\n",
            "Epoch 552\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.2754e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.275382279707811e-05\n",
            "----------------------------------------\n",
            "Epoch 553\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.2682e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.268159947965978e-05\n",
            "----------------------------------------\n",
            "Epoch 554\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.2610e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.2609715342976e-05\n",
            "----------------------------------------\n",
            "Epoch 555\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.2538e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.253812088678584e-05\n",
            "----------------------------------------\n",
            "Epoch 556\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.2467e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.246666018143786e-05\n",
            "----------------------------------------\n",
            "Epoch 557\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.2395e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.239520193852635e-05\n",
            "----------------------------------------\n",
            "Epoch 558\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.2324e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.232394522966604e-05\n",
            "----------------------------------------\n",
            "Epoch 559\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.2253e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.225303437098097e-05\n",
            "----------------------------------------\n",
            "Epoch 560\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.2182e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.218213516197201e-05\n",
            "----------------------------------------\n",
            "Epoch 561\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.2111e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.211136303639088e-05\n",
            "----------------------------------------\n",
            "Epoch 562\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.2041e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.20408098629851e-05\n",
            "----------------------------------------\n",
            "Epoch 563\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.1970e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.197028144371378e-05\n",
            "----------------------------------------\n",
            "Epoch 564\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.1900e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.18999610969623e-05\n",
            "----------------------------------------\n",
            "Epoch 565\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.1830e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.182980165694709e-05\n",
            "----------------------------------------\n",
            "Epoch 566\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.1760e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.175965442802085e-05\n",
            "----------------------------------------\n",
            "Epoch 567\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.1690e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.168959240002508e-05\n",
            "----------------------------------------\n",
            "Epoch 568\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.1620e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.161989120029467e-05\n",
            "----------------------------------------\n",
            "Epoch 569\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.1550e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.155021883859295e-05\n",
            "----------------------------------------\n",
            "Epoch 570\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.1481e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.148057507956001e-05\n",
            "----------------------------------------\n",
            "Epoch 571\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.1411e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.14109700299364e-05\n",
            "----------------------------------------\n",
            "Epoch 572\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.1342e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.13416664639278e-05\n",
            "----------------------------------------\n",
            "Epoch 573\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.1273e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.127252182735469e-05\n",
            "----------------------------------------\n",
            "Epoch 574\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.1203e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.120346165988403e-05\n",
            "----------------------------------------\n",
            "Epoch 575\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.1134e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.113443062908621e-05\n",
            "----------------------------------------\n",
            "Epoch 576\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.1066e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.106550543101298e-05\n",
            "----------------------------------------\n",
            "Epoch 577\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.0997e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.099682260577192e-05\n",
            "----------------------------------------\n",
            "Epoch 578\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.0928e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.092826554598626e-05\n",
            "----------------------------------------\n",
            "Epoch 579\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.0860e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.085976961380725e-05\n",
            "----------------------------------------\n",
            "Epoch 580\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.0792e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.079150126311066e-05\n",
            "----------------------------------------\n",
            "Epoch 581\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.0723e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.072333723707361e-05\n",
            "----------------------------------------\n",
            "Epoch 582\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.0655e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.065519037997213e-05\n",
            "----------------------------------------\n",
            "Epoch 583\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.0587e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.058712436869413e-05\n",
            "----------------------------------------\n",
            "Epoch 584\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.0519e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.051934615795742e-05\n",
            "----------------------------------------\n",
            "Epoch 585\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.0452e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.045160626786896e-05\n",
            "----------------------------------------\n",
            "Epoch 586\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.0384e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.038401577358519e-05\n",
            "----------------------------------------\n",
            "Epoch 587\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.0316e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.031647978007902e-05\n",
            "----------------------------------------\n",
            "Epoch 588\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.0249e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.02491419478247e-05\n",
            "----------------------------------------\n",
            "Epoch 589\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.0182e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.018191075322592e-05\n",
            "----------------------------------------\n",
            "Epoch 590\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.0115e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.011493082633144e-05\n",
            "----------------------------------------\n",
            "Epoch 591\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.0048e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.004806183112009e-05\n",
            "----------------------------------------\n",
            "Epoch 592\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.9981e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.998122930650098e-05\n",
            "----------------------------------------\n",
            "Epoch 593\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.9915e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.99148289766466e-05\n",
            "----------------------------------------\n",
            "Epoch 594\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.9849e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.984852973227115e-05\n",
            "----------------------------------------\n",
            "Epoch 595\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.9782e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.978218028028097e-05\n",
            "----------------------------------------\n",
            "Epoch 596\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.9716e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.971614917644634e-05\n",
            "----------------------------------------\n",
            "Epoch 597\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.9650e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.965019920845874e-05\n",
            "----------------------------------------\n",
            "Epoch 598\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.9584e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.958443164274485e-05\n",
            "----------------------------------------\n",
            "Epoch 599\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.9519e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.951878356755504e-05\n",
            "----------------------------------------\n",
            "Epoch 600\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.9453e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.94531375994869e-05\n",
            "----------------------------------------\n",
            "Epoch 601\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.9388e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.93877841178286e-05\n",
            "----------------------------------------\n",
            "Epoch 602\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.9322e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.9322464705968e-05\n",
            "----------------------------------------\n",
            "Epoch 603\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.9257e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.925724218326754e-05\n",
            "----------------------------------------\n",
            "Epoch 604\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.9192e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.919221080575382e-05\n",
            "----------------------------------------\n",
            "Epoch 605\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.9127e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.912728412545479e-05\n",
            "----------------------------------------\n",
            "Epoch 606\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.9063e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.906252054365199e-05\n",
            "----------------------------------------\n",
            "Epoch 607\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.8998e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.89978091748467e-05\n",
            "----------------------------------------\n",
            "Epoch 608\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.8933e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.893315825922105e-05\n",
            "----------------------------------------\n",
            "Epoch 609\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.8869e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.8868732797984e-05\n",
            "----------------------------------------\n",
            "Epoch 610\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.8804e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.880435738684894e-05\n",
            "----------------------------------------\n",
            "Epoch 611\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.8740e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.874014359531318e-05\n",
            "----------------------------------------\n",
            "Epoch 612\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.8676e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.867603733819493e-05\n",
            "----------------------------------------\n",
            "Epoch 613\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.8612e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.861196749723857e-05\n",
            "----------------------------------------\n",
            "Epoch 614\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.8548e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.854825663507851e-05\n",
            "----------------------------------------\n",
            "Epoch 615\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.8484e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.848447603705441e-05\n",
            "----------------------------------------\n",
            "Epoch 616\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.8421e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.842072258408149e-05\n",
            "----------------------------------------\n",
            "Epoch 617\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.8357e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.835723162157456e-05\n",
            "----------------------------------------\n",
            "Epoch 618\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.8294e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.829383167876025e-05\n",
            "----------------------------------------\n",
            "Epoch 619\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.8230e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.823046770215592e-05\n",
            "----------------------------------------\n",
            "Epoch 620\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.8167e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.816716925972018e-05\n",
            "----------------------------------------\n",
            "Epoch 621\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.8104e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.810427547969237e-05\n",
            "----------------------------------------\n",
            "Epoch 622\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.8041e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.804127199941432e-05\n",
            "----------------------------------------\n",
            "Epoch 623\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.7978e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.797831514664392e-05\n",
            "----------------------------------------\n",
            "Epoch 624\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.7916e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.791557922057309e-05\n",
            "----------------------------------------\n",
            "Epoch 625\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.7853e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.785297924061715e-05\n",
            "----------------------------------------\n",
            "Epoch 626\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.7790e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.779044294233166e-05\n",
            "----------------------------------------\n",
            "Epoch 627\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.7728e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.772802723658548e-05\n",
            "----------------------------------------\n",
            "Epoch 628\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.7666e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.766567362418125e-05\n",
            "----------------------------------------\n",
            "Epoch 629\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.7603e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.760338771666893e-05\n",
            "----------------------------------------\n",
            "Epoch 630\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.7541e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.754135776581682e-05\n",
            "----------------------------------------\n",
            "Epoch 631\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.7479e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.747941058721277e-05\n",
            "----------------------------------------\n",
            "Epoch 632\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.7418e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.741750380699572e-05\n",
            "----------------------------------------\n",
            "Epoch 633\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.7356e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.735574758320975e-05\n",
            "----------------------------------------\n",
            "Epoch 634\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.7294e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.729403497873552e-05\n",
            "----------------------------------------\n",
            "Epoch 635\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.7233e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.72326171852106e-05\n",
            "----------------------------------------\n",
            "Epoch 636\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.7171e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.717135198065069e-05\n",
            "----------------------------------------\n",
            "Epoch 637\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.7110e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.711004071606e-05\n",
            "----------------------------------------\n",
            "Epoch 638\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.7049e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.704897613239586e-05\n",
            "----------------------------------------\n",
            "Epoch 639\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.6988e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.698797958170155e-05\n",
            "----------------------------------------\n",
            "Epoch 640\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.6928e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.692766199002758e-05\n",
            "----------------------------------------\n",
            "Epoch 641\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.6868e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.686785619342311e-05\n",
            "----------------------------------------\n",
            "Epoch 642\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.6808e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.680840129182385e-05\n",
            "----------------------------------------\n",
            "Epoch 643\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.6749e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.674919505809426e-05\n",
            "----------------------------------------\n",
            "Epoch 644\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.6690e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.669041295195246e-05\n",
            "----------------------------------------\n",
            "Epoch 645\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.6632e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.663191924715133e-05\n",
            "----------------------------------------\n",
            "Epoch 646\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.6574e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.657374397508109e-05\n",
            "----------------------------------------\n",
            "Epoch 647\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.6516e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.651586728813478e-05\n",
            "----------------------------------------\n",
            "Epoch 648\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.6458e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.645847455847045e-05\n",
            "----------------------------------------\n",
            "Epoch 649\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.6401e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.640117897393993e-05\n",
            "----------------------------------------\n",
            "Epoch 650\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.6344e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.634449543611681e-05\n",
            "----------------------------------------\n",
            "Epoch 651\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.6288e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.628807469075689e-05\n",
            "----------------------------------------\n",
            "Epoch 652\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.6232e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.623190961624487e-05\n",
            "----------------------------------------\n",
            "Epoch 653\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.6176e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.617600340950899e-05\n",
            "----------------------------------------\n",
            "Epoch 654\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.6120e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.612035809976075e-05\n",
            "----------------------------------------\n",
            "Epoch 655\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.6065e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.60650006824153e-05\n",
            "----------------------------------------\n",
            "Epoch 656\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.6010e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.601006382067951e-05\n",
            "----------------------------------------\n",
            "Epoch 657\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.5955e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.595537700272362e-05\n",
            "----------------------------------------\n",
            "Epoch 658\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.5901e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.590102536981254e-05\n",
            "----------------------------------------\n",
            "Epoch 659\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.5847e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.584700085705074e-05\n",
            "----------------------------------------\n",
            "Epoch 660\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.5793e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.579319175714673e-05\n",
            "----------------------------------------\n",
            "Epoch 661\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.5740e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.573993315995991e-05\n",
            "----------------------------------------\n",
            "Epoch 662\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.5687e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.568725034162923e-05\n",
            "----------------------------------------\n",
            "Epoch 663\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.5635e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.563495296705626e-05\n",
            "----------------------------------------\n",
            "Epoch 664\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.5583e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.558278964112198e-05\n",
            "----------------------------------------\n",
            "Epoch 665\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.5531e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.553104616145819e-05\n",
            "----------------------------------------\n",
            "Epoch 666\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.5480e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.547959048376596e-05\n",
            "----------------------------------------\n",
            "Epoch 667\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.5428e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.542833196344196e-05\n",
            "----------------------------------------\n",
            "Epoch 668\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.5377e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.537726762170067e-05\n",
            "----------------------------------------\n",
            "Epoch 669\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.5326e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.53263944058334e-05\n",
            "----------------------------------------\n",
            "Epoch 670\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.5276e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.527577161651583e-05\n",
            "----------------------------------------\n",
            "Epoch 671\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.5225e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.522546797149643e-05\n",
            "----------------------------------------\n",
            "Epoch 672\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.5175e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.517525925411886e-05\n",
            "----------------------------------------\n",
            "Epoch 673\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.5125e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.512533856614406e-05\n",
            "----------------------------------------\n",
            "Epoch 674\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.5076e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.507566883216213e-05\n",
            "----------------------------------------\n",
            "Epoch 675\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.5026e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.502614926838012e-05\n",
            "----------------------------------------\n",
            "Epoch 676\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.4977e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.497683594369246e-05\n",
            "----------------------------------------\n",
            "Epoch 677\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.4928e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.492766848678513e-05\n",
            "----------------------------------------\n",
            "Epoch 678\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.4879e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.487877567595169e-05\n",
            "----------------------------------------\n",
            "Epoch 679\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.4830e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.48300841867039e-05\n",
            "----------------------------------------\n",
            "Epoch 680\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.4781e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.47814356545497e-05\n",
            "----------------------------------------\n",
            "Epoch 681\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.4733e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.473297406011866e-05\n",
            "----------------------------------------\n",
            "Epoch 682\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.4685e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.468470036065293e-05\n",
            "----------------------------------------\n",
            "Epoch 683\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.4637e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.463669524411134e-05\n",
            "----------------------------------------\n",
            "Epoch 684\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.4589e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.458870437657646e-05\n",
            "----------------------------------------\n",
            "Epoch 685\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.4541e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.454090491363197e-05\n",
            "----------------------------------------\n",
            "Epoch 686\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.4493e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.449324728676247e-05\n",
            "----------------------------------------\n",
            "Epoch 687\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.4446e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.444569608043214e-05\n",
            "----------------------------------------\n",
            "Epoch 688\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.4398e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.439827805483982e-05\n",
            "----------------------------------------\n",
            "Epoch 689\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.4351e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.435106165701532e-05\n",
            "----------------------------------------\n",
            "Epoch 690\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.4304e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.430394889765936e-05\n",
            "----------------------------------------\n",
            "Epoch 691\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.4257e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.425694413848716e-05\n",
            "----------------------------------------\n",
            "Epoch 692\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.4210e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.421001025948914e-05\n",
            "----------------------------------------\n",
            "Epoch 693\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.4163e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.416326922399905e-05\n",
            "----------------------------------------\n",
            "Epoch 694\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.4117e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.41166226281267e-05\n",
            "----------------------------------------\n",
            "Epoch 695\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.4070e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.40702698167927e-05\n",
            "----------------------------------------\n",
            "Epoch 696\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.4024e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.402444513899813e-05\n",
            "----------------------------------------\n",
            "Epoch 697\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3979e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.397853663994796e-05\n",
            "----------------------------------------\n",
            "Epoch 698\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3933e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.393262510319124e-05\n",
            "----------------------------------------\n",
            "Epoch 699\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3887e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.38867956721549e-05\n",
            "----------------------------------------\n",
            "Epoch 700\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3841e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.384092967432305e-05\n",
            "----------------------------------------\n",
            "Epoch 701\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3795e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.379503743927028e-05\n",
            "----------------------------------------\n",
            "Epoch 702\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3749e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.374936994324875e-05\n",
            "----------------------------------------\n",
            "Epoch 703\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3704e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.370416236765796e-05\n",
            "----------------------------------------\n",
            "Epoch 704\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3659e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.365897554814992e-05\n",
            "----------------------------------------\n",
            "Epoch 705\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3614e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.361382937793085e-05\n",
            "----------------------------------------\n",
            "Epoch 706\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3569e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.356872829362663e-05\n",
            "----------------------------------------\n",
            "Epoch 707\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3524e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.352369604188031e-05\n",
            "----------------------------------------\n",
            "Epoch 708\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3479e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.347872210452653e-05\n",
            "----------------------------------------\n",
            "Epoch 709\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3434e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.343381190395092e-05\n",
            "----------------------------------------\n",
            "Epoch 710\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3389e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.338921794002941e-05\n",
            "----------------------------------------\n",
            "Epoch 711\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3345e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.334475026805207e-05\n",
            "----------------------------------------\n",
            "Epoch 712\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3300e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.330031474525746e-05\n",
            "----------------------------------------\n",
            "Epoch 713\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3256e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.325579643007365e-05\n",
            "----------------------------------------\n",
            "Epoch 714\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3211e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.321147441559433e-05\n",
            "----------------------------------------\n",
            "Epoch 715\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3167e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.31673901865099e-05\n",
            "----------------------------------------\n",
            "Epoch 716\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3123e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.312331743455844e-05\n",
            "----------------------------------------\n",
            "Epoch 717\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3079e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.307935533437162e-05\n",
            "----------------------------------------\n",
            "Epoch 718\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.3035e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.303526459552834e-05\n",
            "----------------------------------------\n",
            "Epoch 719\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2991e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.299139353457374e-05\n",
            "----------------------------------------\n",
            "Epoch 720\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2948e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.294772471202691e-05\n",
            "----------------------------------------\n",
            "Epoch 721\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2904e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.290398462527016e-05\n",
            "----------------------------------------\n",
            "Epoch 722\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2861e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.286051818357266e-05\n",
            "----------------------------------------\n",
            "Epoch 723\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2817e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.28170715621852e-05\n",
            "----------------------------------------\n",
            "Epoch 724\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2774e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.277366065767547e-05\n",
            "----------------------------------------\n",
            "Epoch 725\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2730e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.273023586741673e-05\n",
            "----------------------------------------\n",
            "Epoch 726\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2687e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.268687888914892e-05\n",
            "----------------------------------------\n",
            "Epoch 727\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2644e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.264367862974162e-05\n",
            "----------------------------------------\n",
            "Epoch 728\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2600e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.260049506115391e-05\n",
            "----------------------------------------\n",
            "Epoch 729\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2558e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.255755655945307e-05\n",
            "----------------------------------------\n",
            "Epoch 730\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2515e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.251456782847813e-05\n",
            "----------------------------------------\n",
            "Epoch 731\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2472e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.247169457300482e-05\n",
            "----------------------------------------\n",
            "Epoch 732\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2429e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.242900938247754e-05\n",
            "----------------------------------------\n",
            "Epoch 733\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2386e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.238636460542914e-05\n",
            "----------------------------------------\n",
            "Epoch 734\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2344e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.234366811998881e-05\n",
            "----------------------------------------\n",
            "Epoch 735\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2301e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.230097893721285e-05\n",
            "----------------------------------------\n",
            "Epoch 736\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2258e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.22584062940956e-05\n",
            "----------------------------------------\n",
            "Epoch 737\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2216e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.221595982763161e-05\n",
            "----------------------------------------\n",
            "Epoch 738\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2174e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.217353508631529e-05\n",
            "----------------------------------------\n",
            "Epoch 739\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2131e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.213115733253307e-05\n",
            "----------------------------------------\n",
            "Epoch 740\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2089e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.208897539836721e-05\n",
            "----------------------------------------\n",
            "Epoch 741\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2047e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.204681938003631e-05\n",
            "----------------------------------------\n",
            "Epoch 742\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.2004e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.200449733333167e-05\n",
            "----------------------------------------\n",
            "Epoch 743\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1963e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.196262037955988e-05\n",
            "----------------------------------------\n",
            "Epoch 744\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1921e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.192073434863781e-05\n",
            "----------------------------------------\n",
            "Epoch 745\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1879e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.187877877945702e-05\n",
            "----------------------------------------\n",
            "Epoch 746\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1837e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.183682124364233e-05\n",
            "----------------------------------------\n",
            "Epoch 747\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1795e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.179481177623264e-05\n",
            "----------------------------------------\n",
            "Epoch 748\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1753e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.175310520061581e-05\n",
            "----------------------------------------\n",
            "Epoch 749\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1711e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.171135208038667e-05\n",
            "----------------------------------------\n",
            "Epoch 750\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1670e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.166974000224407e-05\n",
            "----------------------------------------\n",
            "Epoch 751\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1628e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.16282361466964e-05\n",
            "----------------------------------------\n",
            "Epoch 752\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1587e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.158668163504469e-05\n",
            "----------------------------------------\n",
            "Epoch 753\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1545e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.154515974602277e-05\n",
            "----------------------------------------\n",
            "Epoch 754\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1504e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.150367589475269e-05\n",
            "----------------------------------------\n",
            "Epoch 755\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1462e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.146231263796181e-05\n",
            "----------------------------------------\n",
            "Epoch 756\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1421e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.142082155075568e-05\n",
            "----------------------------------------\n",
            "Epoch 757\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1380e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.137963229987375e-05\n",
            "----------------------------------------\n",
            "Epoch 758\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1338e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.13384081020667e-05\n",
            "----------------------------------------\n",
            "Epoch 759\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1297e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.129708171149402e-05\n",
            "----------------------------------------\n",
            "Epoch 760\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1256e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.125573500221475e-05\n",
            "----------------------------------------\n",
            "Epoch 761\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1215e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.121485843271929e-05\n",
            "----------------------------------------\n",
            "Epoch 762\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1174e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.117389043379512e-05\n",
            "----------------------------------------\n",
            "Epoch 763\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1133e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.113279923851174e-05\n",
            "----------------------------------------\n",
            "Epoch 764\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1092e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.109157661547698e-05\n",
            "----------------------------------------\n",
            "Epoch 765\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1051e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.105073100339374e-05\n",
            "----------------------------------------\n",
            "Epoch 766\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1010e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.101001933086154e-05\n",
            "----------------------------------------\n",
            "Epoch 767\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0969e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.096932921913845e-05\n",
            "----------------------------------------\n",
            "Epoch 768\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0928e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.092833140996792e-05\n",
            "----------------------------------------\n",
            "Epoch 769\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0887e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.088744398199539e-05\n",
            "----------------------------------------\n",
            "Epoch 770\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0847e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.084687646017949e-05\n",
            "----------------------------------------\n",
            "Epoch 771\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0806e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.080640963826513e-05\n",
            "----------------------------------------\n",
            "Epoch 772\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0766e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.076578818928316e-05\n",
            "----------------------------------------\n",
            "Epoch 773\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0725e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.072503237948853e-05\n",
            "----------------------------------------\n",
            "Epoch 774\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0685e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.068456421559013e-05\n",
            "----------------------------------------\n",
            "Epoch 775\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0644e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.064428617174603e-05\n",
            "----------------------------------------\n",
            "Epoch 776\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0604e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.060396011712034e-05\n",
            "----------------------------------------\n",
            "Epoch 777\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0563e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.056344883070356e-05\n",
            "----------------------------------------\n",
            "Epoch 778\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0523e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.05229575459881e-05\n",
            "----------------------------------------\n",
            "Epoch 779\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0483e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.048282489795915e-05\n",
            "----------------------------------------\n",
            "Epoch 780\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0442e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.044194587160469e-05\n",
            "----------------------------------------\n",
            "Epoch 781\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0400e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.040044298914236e-05\n",
            "----------------------------------------\n",
            "Epoch 782\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0359e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.035888653185844e-05\n",
            "----------------------------------------\n",
            "Epoch 783\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0317e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.031714620957267e-05\n",
            "----------------------------------------\n",
            "Epoch 784\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0276e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.027555083311591e-05\n",
            "----------------------------------------\n",
            "Epoch 785\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0234e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.023393576855524e-05\n",
            "----------------------------------------\n",
            "Epoch 786\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0192e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.019195336515679e-05\n",
            "----------------------------------------\n",
            "Epoch 787\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0150e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.015012689966169e-05\n",
            "----------------------------------------\n",
            "Epoch 788\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0108e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.010831522111086e-05\n",
            "----------------------------------------\n",
            "Epoch 789\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0066e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.006646607402812e-05\n",
            "----------------------------------------\n",
            "Epoch 790\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.0025e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.002475000513466e-05\n",
            "----------------------------------------\n",
            "Epoch 791\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9983e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.998284953674483e-05\n",
            "----------------------------------------\n",
            "Epoch 792\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9941e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.99412013432495e-05\n",
            "----------------------------------------\n",
            "Epoch 793\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9899e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.989949691870092e-05\n",
            "----------------------------------------\n",
            "Epoch 794\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9858e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.985772516945986e-05\n",
            "----------------------------------------\n",
            "Epoch 795\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9816e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.981585795748717e-05\n",
            "----------------------------------------\n",
            "Epoch 796\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9774e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.977422904280194e-05\n",
            "----------------------------------------\n",
            "Epoch 797\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9733e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.973252650350853e-05\n",
            "----------------------------------------\n",
            "Epoch 798\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9691e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.969086189223287e-05\n",
            "----------------------------------------\n",
            "Epoch 799\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9649e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.964947443171891e-05\n",
            "----------------------------------------\n",
            "Epoch 800\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9608e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.960792717960807e-05\n",
            "----------------------------------------\n",
            "Epoch 801\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9566e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.95662744421895e-05\n",
            "----------------------------------------\n",
            "Epoch 802\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9525e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.95247819575715e-05\n",
            "----------------------------------------\n",
            "Epoch 803\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9483e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.948342652339858e-05\n",
            "----------------------------------------\n",
            "Epoch 804\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9442e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.944199818752428e-05\n",
            "----------------------------------------\n",
            "Epoch 805\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9401e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.940080004375677e-05\n",
            "----------------------------------------\n",
            "Epoch 806\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9359e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.935938987605281e-05\n",
            "----------------------------------------\n",
            "Epoch 807\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9318e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.931795999867337e-05\n",
            "----------------------------------------\n",
            "Epoch 808\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9277e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.927685546350298e-05\n",
            "----------------------------------------\n",
            "Epoch 809\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9236e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.923569743238552e-05\n",
            "----------------------------------------\n",
            "Epoch 810\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9194e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.919435741421716e-05\n",
            "----------------------------------------\n",
            "Epoch 811\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9153e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.915322921044821e-05\n",
            "----------------------------------------\n",
            "Epoch 812\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9112e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.911223639449644e-05\n",
            "----------------------------------------\n",
            "Epoch 813\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9071e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.907111736062383e-05\n",
            "----------------------------------------\n",
            "Epoch 814\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.9030e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.903020941565885e-05\n",
            "----------------------------------------\n",
            "Epoch 815\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8989e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.898902656062401e-05\n",
            "----------------------------------------\n",
            "Epoch 816\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8948e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.894825659258152e-05\n",
            "----------------------------------------\n",
            "Epoch 817\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8907e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.89073684897917e-05\n",
            "----------------------------------------\n",
            "Epoch 818\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8866e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.886646639393106e-05\n",
            "----------------------------------------\n",
            "Epoch 819\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8826e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.882570615993206e-05\n",
            "----------------------------------------\n",
            "Epoch 820\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8785e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.878511052529032e-05\n",
            "----------------------------------------\n",
            "Epoch 821\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8744e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.87443744520686e-05\n",
            "----------------------------------------\n",
            "Epoch 822\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8704e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.870385021399202e-05\n",
            "----------------------------------------\n",
            "Epoch 823\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8663e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.866333771684233e-05\n",
            "----------------------------------------\n",
            "Epoch 824\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8623e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.862269535514759e-05\n",
            "----------------------------------------\n",
            "Epoch 825\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8582e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.85822115549493e-05\n",
            "----------------------------------------\n",
            "Epoch 826\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8542e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.854185539938882e-05\n",
            "----------------------------------------\n",
            "Epoch 827\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8501e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.850134441875238e-05\n",
            "----------------------------------------\n",
            "Epoch 828\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8461e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.846109214844832e-05\n",
            "----------------------------------------\n",
            "Epoch 829\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8421e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.842086307994197e-05\n",
            "----------------------------------------\n",
            "Epoch 830\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8381e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.838055537026003e-05\n",
            "----------------------------------------\n",
            "Epoch 831\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8340e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.834008429315148e-05\n",
            "----------------------------------------\n",
            "Epoch 832\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8300e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.829993387423964e-05\n",
            "----------------------------------------\n",
            "Epoch 833\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8260e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.825990117838436e-05\n",
            "----------------------------------------\n",
            "Epoch 834\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8220e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.821981150192269e-05\n",
            "----------------------------------------\n",
            "Epoch 835\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8180e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.81797591385016e-05\n",
            "----------------------------------------\n",
            "Epoch 836\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8140e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.813976753061587e-05\n",
            "----------------------------------------\n",
            "Epoch 837\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8100e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.809985320032082e-05\n",
            "----------------------------------------\n",
            "Epoch 838\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8060e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.805997832282596e-05\n",
            "----------------------------------------\n",
            "Epoch 839\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.8020e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.802005518375531e-05\n",
            "----------------------------------------\n",
            "Epoch 840\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7980e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.798020485112395e-05\n",
            "----------------------------------------\n",
            "Epoch 841\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7941e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.794068231846866e-05\n",
            "----------------------------------------\n",
            "Epoch 842\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7901e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.790099538589011e-05\n",
            "----------------------------------------\n",
            "Epoch 843\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7861e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.78611669673766e-05\n",
            "----------------------------------------\n",
            "Epoch 844\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7822e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.782166560645713e-05\n",
            "----------------------------------------\n",
            "Epoch 845\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7782e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.778223863089558e-05\n",
            "----------------------------------------\n",
            "Epoch 846\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7743e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.774256601037013e-05\n",
            "----------------------------------------\n",
            "Epoch 847\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7703e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.770300833185501e-05\n",
            "----------------------------------------\n",
            "Epoch 848\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7664e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.766367350624933e-05\n",
            "----------------------------------------\n",
            "Epoch 849\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7624e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.762419945269224e-05\n",
            "----------------------------------------\n",
            "Epoch 850\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7585e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.758497198482006e-05\n",
            "----------------------------------------\n",
            "Epoch 851\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7546e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.754574391137882e-05\n",
            "----------------------------------------\n",
            "Epoch 852\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7506e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.750636262256495e-05\n",
            "----------------------------------------\n",
            "Epoch 853\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7467e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.746729937916169e-05\n",
            "----------------------------------------\n",
            "Epoch 854\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7428e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.742822992405257e-05\n",
            "----------------------------------------\n",
            "Epoch 855\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7389e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.738911163743782e-05\n",
            "----------------------------------------\n",
            "Epoch 856\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7350e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.734984963249413e-05\n",
            "----------------------------------------\n",
            "Epoch 857\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7311e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.731110867152707e-05\n",
            "----------------------------------------\n",
            "Epoch 858\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7272e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.727227518297046e-05\n",
            "----------------------------------------\n",
            "Epoch 859\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7233e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.723333355156245e-05\n",
            "----------------------------------------\n",
            "Epoch 860\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7194e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.719424898851742e-05\n",
            "----------------------------------------\n",
            "Epoch 861\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7155e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.715530174201452e-05\n",
            "----------------------------------------\n",
            "Epoch 862\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7117e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.711666135414095e-05\n",
            "----------------------------------------\n",
            "Epoch 863\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7078e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.707789471002316e-05\n",
            "----------------------------------------\n",
            "Epoch 864\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7039e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.7039035552051e-05\n",
            "----------------------------------------\n",
            "Epoch 865\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.7001e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.700058118220002e-05\n",
            "----------------------------------------\n",
            "Epoch 866\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6962e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.696208024428752e-05\n",
            "----------------------------------------\n",
            "Epoch 867\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6923e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.692347863332894e-05\n",
            "----------------------------------------\n",
            "Epoch 868\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6885e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.688476200216631e-05\n",
            "----------------------------------------\n",
            "Epoch 869\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6847e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.684687467738607e-05\n",
            "----------------------------------------\n",
            "Epoch 870\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6809e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.680891160757381e-05\n",
            "----------------------------------------\n",
            "Epoch 871\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6771e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.6770828808024e-05\n",
            "----------------------------------------\n",
            "Epoch 872\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6733e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.673271440938649e-05\n",
            "----------------------------------------\n",
            "Epoch 873\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6694e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.669449742087043e-05\n",
            "----------------------------------------\n",
            "Epoch 874\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6657e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.665686114893137e-05\n",
            "----------------------------------------\n",
            "Epoch 875\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6619e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.661921922402521e-05\n",
            "----------------------------------------\n",
            "Epoch 876\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6581e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.658148754150641e-05\n",
            "----------------------------------------\n",
            "Epoch 877\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6544e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.654362013388895e-05\n",
            "----------------------------------------\n",
            "Epoch 878\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6506e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.650563585559169e-05\n",
            "----------------------------------------\n",
            "Epoch 879\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6468e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.646817479547013e-05\n",
            "----------------------------------------\n",
            "Epoch 880\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6431e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.643086098749567e-05\n",
            "----------------------------------------\n",
            "Epoch 881\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6393e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.63934056004345e-05\n",
            "----------------------------------------\n",
            "Epoch 882\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6356e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.635581800848889e-05\n",
            "----------------------------------------\n",
            "Epoch 883\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6318e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.631816350856613e-05\n",
            "----------------------------------------\n",
            "Epoch 884\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6281e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.628072534957856e-05\n",
            "----------------------------------------\n",
            "Epoch 885\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6244e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.62435946638251e-05\n",
            "----------------------------------------\n",
            "Epoch 886\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6206e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.620632569490642e-05\n",
            "----------------------------------------\n",
            "Epoch 887\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6169e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.61689286859026e-05\n",
            "----------------------------------------\n",
            "Epoch 888\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6132e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.613175814804443e-05\n",
            "----------------------------------------\n",
            "Epoch 889\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6095e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.609474918101735e-05\n",
            "----------------------------------------\n",
            "Epoch 890\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6058e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.60576312456152e-05\n",
            "----------------------------------------\n",
            "Epoch 891\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6020e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.602042781242605e-05\n",
            "----------------------------------------\n",
            "Epoch 892\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5984e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.598364643184979e-05\n",
            "----------------------------------------\n",
            "Epoch 893\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5947e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.594687070891443e-05\n",
            "----------------------------------------\n",
            "Epoch 894\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5910e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.590991284813077e-05\n",
            "----------------------------------------\n",
            "Epoch 895\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5873e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.587285543576676e-05\n",
            "----------------------------------------\n",
            "Epoch 896\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5836e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.583609680503256e-05\n",
            "----------------------------------------\n",
            "Epoch 897\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5800e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.580030724201949e-05\n",
            "----------------------------------------\n",
            "Epoch 898\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5764e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.576446841211593e-05\n",
            "----------------------------------------\n",
            "Epoch 899\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5729e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.572853013109186e-05\n",
            "----------------------------------------\n",
            "Epoch 900\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5693e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.569280611101695e-05\n",
            "----------------------------------------\n",
            "Epoch 901\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5657e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.565729036783484e-05\n",
            "----------------------------------------\n",
            "Epoch 902\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5622e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.562165867010835e-05\n",
            "----------------------------------------\n",
            "Epoch 903\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5586e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.558593185319648e-05\n",
            "----------------------------------------\n",
            "Epoch 904\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5551e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.555080362916665e-05\n",
            "----------------------------------------\n",
            "Epoch 905\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5516e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.551557346028762e-05\n",
            "----------------------------------------\n",
            "Epoch 906\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5480e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.548020045314145e-05\n",
            "----------------------------------------\n",
            "Epoch 907\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5445e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.544480302715971e-05\n",
            "----------------------------------------\n",
            "Epoch 908\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5409e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.540947445347577e-05\n",
            "----------------------------------------\n",
            "Epoch 909\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5374e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.53744990720556e-05\n",
            "----------------------------------------\n",
            "Epoch 910\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5339e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.533940155876152e-05\n",
            "----------------------------------------\n",
            "Epoch 911\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5304e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.530425233983515e-05\n",
            "----------------------------------------\n",
            "Epoch 912\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5269e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.526930560256859e-05\n",
            "----------------------------------------\n",
            "Epoch 913\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5234e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.523443227173981e-05\n",
            "----------------------------------------\n",
            "Epoch 914\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5200e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.519954124792607e-05\n",
            "----------------------------------------\n",
            "Epoch 915\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5165e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.516481694590605e-05\n",
            "----------------------------------------\n",
            "Epoch 916\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5130e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.51300498295321e-05\n",
            "----------------------------------------\n",
            "Epoch 917\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5095e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.509522727352372e-05\n",
            "----------------------------------------\n",
            "Epoch 918\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5061e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.506060290116982e-05\n",
            "----------------------------------------\n",
            "Epoch 919\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.5026e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.502606874122263e-05\n",
            "----------------------------------------\n",
            "Epoch 920\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4991e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.499145377947555e-05\n",
            "----------------------------------------\n",
            "Epoch 921\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4957e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.495699044441372e-05\n",
            "----------------------------------------\n",
            "Epoch 922\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4923e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.49225162463289e-05\n",
            "----------------------------------------\n",
            "Epoch 923\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4888e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.488793437359755e-05\n",
            "----------------------------------------\n",
            "Epoch 924\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4854e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.485377565372958e-05\n",
            "----------------------------------------\n",
            "Epoch 925\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4820e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.481952046111364e-05\n",
            "----------------------------------------\n",
            "Epoch 926\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4785e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.478514833724923e-05\n",
            "----------------------------------------\n",
            "Epoch 927\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4751e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.475067002185372e-05\n",
            "----------------------------------------\n",
            "Epoch 928\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4717e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.471672365422545e-05\n",
            "----------------------------------------\n",
            "Epoch 929\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4683e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.468274492986852e-05\n",
            "----------------------------------------\n",
            "Epoch 930\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4649e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.464861330768735e-05\n",
            "----------------------------------------\n",
            "Epoch 931\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4614e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.461436480983595e-05\n",
            "----------------------------------------\n",
            "Epoch 932\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4580e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.458005300784663e-05\n",
            "----------------------------------------\n",
            "Epoch 933\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4546e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.454631637651863e-05\n",
            "----------------------------------------\n",
            "Epoch 934\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4513e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.451254209531439e-05\n",
            "----------------------------------------\n",
            "Epoch 935\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4479e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.44786260391356e-05\n",
            "----------------------------------------\n",
            "Epoch 936\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4445e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.444460904647601e-05\n",
            "----------------------------------------\n",
            "Epoch 937\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4410e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.4410482830042e-05\n",
            "----------------------------------------\n",
            "Epoch 938\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4377e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.437671234459959e-05\n",
            "----------------------------------------\n",
            "Epoch 939\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4343e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.434325304540378e-05\n",
            "----------------------------------------\n",
            "Epoch 940\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4310e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.430969739458132e-05\n",
            "----------------------------------------\n",
            "Epoch 941\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4276e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.427605505972907e-05\n",
            "----------------------------------------\n",
            "Epoch 942\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4242e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.424231495354138e-05\n",
            "----------------------------------------\n",
            "Epoch 943\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4209e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.42090608627282e-05\n",
            "----------------------------------------\n",
            "Epoch 944\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4176e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.417581531506657e-05\n",
            "----------------------------------------\n",
            "Epoch 945\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4142e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.414246625805484e-05\n",
            "----------------------------------------\n",
            "Epoch 946\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4109e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.410897623089364e-05\n",
            "----------------------------------------\n",
            "Epoch 947\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4076e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.407554713324534e-05\n",
            "----------------------------------------\n",
            "Epoch 948\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4043e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.404284724234842e-05\n",
            "----------------------------------------\n",
            "Epoch 949\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.4010e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.401010000111365e-05\n",
            "----------------------------------------\n",
            "Epoch 950\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3977e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.397724566338711e-05\n",
            "----------------------------------------\n",
            "Epoch 951\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3944e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.394429921539483e-05\n",
            "----------------------------------------\n",
            "Epoch 952\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3911e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.391127441358725e-05\n",
            "----------------------------------------\n",
            "Epoch 953\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3878e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.387825697206434e-05\n",
            "----------------------------------------\n",
            "Epoch 954\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3846e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.384571352277782e-05\n",
            "----------------------------------------\n",
            "Epoch 955\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3813e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.3813021719726e-05\n",
            "----------------------------------------\n",
            "Epoch 956\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3780e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.378026261122327e-05\n",
            "----------------------------------------\n",
            "Epoch 957\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3748e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.374791493868998e-05\n",
            "----------------------------------------\n",
            "Epoch 958\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3715e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.371548793600908e-05\n",
            "----------------------------------------\n",
            "Epoch 959\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3683e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.368297611047616e-05\n",
            "----------------------------------------\n",
            "Epoch 960\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3650e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.36503739928302e-05\n",
            "----------------------------------------\n",
            "Epoch 961\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3618e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.361790158879536e-05\n",
            "----------------------------------------\n",
            "Epoch 962\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3586e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.35856512491698e-05\n",
            "----------------------------------------\n",
            "Epoch 963\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3553e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.355326459861853e-05\n",
            "----------------------------------------\n",
            "Epoch 964\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3521e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.35208018510986e-05\n",
            "----------------------------------------\n",
            "Epoch 965\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3489e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.348858431387677e-05\n",
            "----------------------------------------\n",
            "Epoch 966\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3456e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.345641255059946e-05\n",
            "----------------------------------------\n",
            "Epoch 967\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3424e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.342418436515275e-05\n",
            "----------------------------------------\n",
            "Epoch 968\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3392e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.339214610752716e-05\n",
            "----------------------------------------\n",
            "Epoch 969\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3360e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.336005173854665e-05\n",
            "----------------------------------------\n",
            "Epoch 970\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3328e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.332791494602804e-05\n",
            "----------------------------------------\n",
            "Epoch 971\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3296e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.329586610943645e-05\n",
            "----------------------------------------\n",
            "Epoch 972\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3264e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.326378799914014e-05\n",
            "----------------------------------------\n",
            "Epoch 973\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3232e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.323163705128207e-05\n",
            "----------------------------------------\n",
            "Epoch 974\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3199e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.319920692997565e-05\n",
            "----------------------------------------\n",
            "Epoch 975\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3167e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.316664450574696e-05\n",
            "----------------------------------------\n",
            "Epoch 976\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3134e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.313394682684595e-05\n",
            "----------------------------------------\n",
            "Epoch 977\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3101e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.310131156741689e-05\n",
            "----------------------------------------\n",
            "Epoch 978\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3069e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.306868202019133e-05\n",
            "----------------------------------------\n",
            "Epoch 979\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3036e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.30359033929156e-05\n",
            "----------------------------------------\n",
            "Epoch 980\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.3003e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.300332755139826e-05\n",
            "----------------------------------------\n",
            "Epoch 981\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.2971e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.297070660687398e-05\n",
            "----------------------------------------\n",
            "Epoch 982\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.2938e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.293795938141911e-05\n",
            "----------------------------------------\n",
            "Epoch 983\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.2905e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.290510293071546e-05\n",
            "----------------------------------------\n",
            "Epoch 984\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.2873e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.287269141890785e-05\n",
            "----------------------------------------\n",
            "Epoch 985\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.2840e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.284016167924761e-05\n",
            "----------------------------------------\n",
            "Epoch 986\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.2807e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.280749246085571e-05\n",
            "----------------------------------------\n",
            "Epoch 987\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.2775e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.277472342909968e-05\n",
            "----------------------------------------\n",
            "Epoch 988\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.2742e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.274196287951634e-05\n",
            "----------------------------------------\n",
            "Epoch 989\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.2709e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.270948634130596e-05\n",
            "----------------------------------------\n",
            "Epoch 990\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.2677e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.267691117380659e-05\n",
            "----------------------------------------\n",
            "Epoch 991\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.2644e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.264430784199565e-05\n",
            "----------------------------------------\n",
            "Epoch 992\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.2612e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.261202512170919e-05\n",
            "----------------------------------------\n",
            "Epoch 993\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.2580e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.257962337063057e-05\n",
            "----------------------------------------\n",
            "Epoch 994\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.2547e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.254714607148184e-05\n",
            "----------------------------------------\n",
            "Epoch 995\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.2515e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.251456215273072e-05\n",
            "----------------------------------------\n",
            "Epoch 996\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.2482e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.248226805508457e-05\n",
            "----------------------------------------\n",
            "Epoch 997\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.2450e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.245003856723117e-05\n",
            "----------------------------------------\n",
            "Epoch 998\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.2418e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.241771750427889e-05\n",
            "----------------------------------------\n",
            "Epoch 999\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.2385e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.238530851327873e-05\n",
            "----------------------------------------\n",
            "Epoch 1000\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.2353e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.235286385014605e-05\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[-0.1982, -0.5572],\n",
            "        [-0.1288,  0.6843],\n",
            "        [-0.1759,  0.5148],\n",
            "        [ 0.1354,  0.2921],\n",
            "        [ 0.0147,  0.1771],\n",
            "        [-0.6556,  0.0107]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([ 0.4311,  0.6651, -0.2020,  0.5516, -0.4184,  1.0147],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[ 0.2854, -0.1002, -0.0428, -0.3139,  0.2698, -0.3971],\n",
            "        [ 0.2810, -0.1355, -0.1690, -0.0417,  0.1544, -0.1611],\n",
            "        [ 0.1248, -0.3361,  0.2905, -0.2386, -0.5225, -0.8673],\n",
            "        [ 0.0696, -0.1192, -0.2622, -0.3630, -0.4198,  0.3015],\n",
            "        [-0.0504,  0.0689, -0.1116,  0.1144, -0.6136, -0.3159],\n",
            "        [-0.2525, -0.3236, -0.1373, -0.1378, -0.2818, -0.2362]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([-0.4125,  0.1437, -0.1493,  0.1047, -0.0062,  0.3237],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[ 0.3169,  0.3006, -0.3145, -0.4081,  0.0387,  0.2194]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([0.0140], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_200_0p99 = train_var_scope(model_200_0p99, 200, 0.001, test_200_0p99)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5TXDNed9lBv",
        "outputId": "a3e112b9-3cde-44fb-c52a-ccd925e732c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.2321e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.232071548283213e-05\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.8212e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.821238477719147e-05\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.4394e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.439401945160914e-05\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.0930e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.093024913095342e-05\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.7785e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.778548904449979e-05\n",
            "----------------------------------------\n",
            "Epoch 6\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.4622e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.4622360365619785e-05\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.1637e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.163712912528531e-05\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.8728e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.872768128666346e-05\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.9401e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.940123982244951e-05\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.4341e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.434085554924648e-05\n",
            "----------------------------------------\n",
            "Epoch 11\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.4416e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.441581653301738e-05\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.2003e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.2002592960711154e-05\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.9325e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.9324880394725342e-05\n",
            "----------------------------------------\n",
            "Epoch 14\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.8260e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.826008145046087e-05\n",
            "----------------------------------------\n",
            "Epoch 15\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.6655e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.6654770480795158e-05\n",
            "----------------------------------------\n",
            "Epoch 16\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.4882e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.4882377958571897e-05\n",
            "----------------------------------------\n",
            "Epoch 17\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.3413e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.3412574584680357e-05\n",
            "----------------------------------------\n",
            "Epoch 18\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.2282e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.228214661454187e-05\n",
            "----------------------------------------\n",
            "Epoch 19\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.1096e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.1095740576177908e-05\n",
            "----------------------------------------\n",
            "Epoch 20\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9732e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.9731898146340064e-05\n",
            "----------------------------------------\n",
            "Epoch 21\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8462e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.846166132217096e-05\n",
            "----------------------------------------\n",
            "Epoch 22\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7457e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.745727241245481e-05\n",
            "----------------------------------------\n",
            "Epoch 23\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.6586e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.658622499752148e-05\n",
            "----------------------------------------\n",
            "Epoch 24\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.5694e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.569448938710995e-05\n",
            "----------------------------------------\n",
            "Epoch 25\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4832e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.4831801610583826e-05\n",
            "----------------------------------------\n",
            "Epoch 26\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.4172e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.4171757183129453e-05\n",
            "----------------------------------------\n",
            "Epoch 27\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.3447e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.3446537497075548e-05\n",
            "----------------------------------------\n",
            "Epoch 28\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.2688e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.2688020337093774e-05\n",
            "----------------------------------------\n",
            "Epoch 29\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1887e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.188671872960388e-05\n",
            "----------------------------------------\n",
            "Epoch 30\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.1173e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.1173157717969415e-05\n",
            "----------------------------------------\n",
            "Epoch 31\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0627e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0627027705963712e-05\n",
            "----------------------------------------\n",
            "Epoch 32\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.0176e-05, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.0176497106586096e-05\n",
            "----------------------------------------\n",
            "Epoch 33\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.7312e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.731234013682844e-06\n",
            "----------------------------------------\n",
            "Epoch 34\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(9.3134e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 9.313408623644975e-06\n",
            "----------------------------------------\n",
            "Epoch 35\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.9891e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.989130458391421e-06\n",
            "----------------------------------------\n",
            "Epoch 36\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.7417e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.74169899224684e-06\n",
            "----------------------------------------\n",
            "Epoch 37\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.4942e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.49423565511665e-06\n",
            "----------------------------------------\n",
            "Epoch 38\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(8.2226e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 8.22256456031814e-06\n",
            "----------------------------------------\n",
            "Epoch 39\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.7415e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.74154972183705e-06\n",
            "----------------------------------------\n",
            "Epoch 40\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(7.1792e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 7.179246606933622e-06\n",
            "----------------------------------------\n",
            "Epoch 41\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.6720e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.671963247185429e-06\n",
            "----------------------------------------\n",
            "Epoch 42\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(6.1794e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 6.1793651527326965e-06\n",
            "----------------------------------------\n",
            "Epoch 43\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.7239e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.723899093810125e-06\n",
            "----------------------------------------\n",
            "Epoch 44\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.3452e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.345220389815732e-06\n",
            "----------------------------------------\n",
            "Epoch 45\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(5.0412e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 5.04117343967594e-06\n",
            "----------------------------------------\n",
            "Epoch 46\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.7811e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.781139465130999e-06\n",
            "----------------------------------------\n",
            "Epoch 47\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.5570e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.55701526538185e-06\n",
            "----------------------------------------\n",
            "Epoch 48\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.3869e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.386887215283719e-06\n",
            "----------------------------------------\n",
            "Epoch 49\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.2724e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.272380360992422e-06\n",
            "----------------------------------------\n",
            "Epoch 50\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.1881e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.188135022804692e-06\n",
            "----------------------------------------\n",
            "Epoch 51\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.1156e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.115572063188474e-06\n",
            "----------------------------------------\n",
            "Epoch 52\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.0591e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.059125669463513e-06\n",
            "----------------------------------------\n",
            "Epoch 53\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(4.0228e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 4.022809203595509e-06\n",
            "----------------------------------------\n",
            "Epoch 54\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.9924e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.992423520053543e-06\n",
            "----------------------------------------\n",
            "Epoch 55\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.9525e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.952535016769134e-06\n",
            "----------------------------------------\n",
            "Epoch 56\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.9046e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.904606334132071e-06\n",
            "----------------------------------------\n",
            "Epoch 57\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.8552e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.8551802709118265e-06\n",
            "----------------------------------------\n",
            "Epoch 58\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.8025e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.8025362456450284e-06\n",
            "----------------------------------------\n",
            "Epoch 59\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.7381e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.7381477724112374e-06\n",
            "----------------------------------------\n",
            "Epoch 60\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.6642e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.6641787715576744e-06\n",
            "----------------------------------------\n",
            "Epoch 61\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.5884e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.588425868337358e-06\n",
            "----------------------------------------\n",
            "Epoch 62\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.5131e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.5130708766717514e-06\n",
            "----------------------------------------\n",
            "Epoch 63\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.4344e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.4343960164209754e-06\n",
            "----------------------------------------\n",
            "Epoch 64\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.3534e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.3534373587515606e-06\n",
            "----------------------------------------\n",
            "Epoch 65\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.2765e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.2764955832449052e-06\n",
            "----------------------------------------\n",
            "Epoch 66\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.2060e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.206018049482695e-06\n",
            "----------------------------------------\n",
            "Epoch 67\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.1392e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.139198962697873e-06\n",
            "----------------------------------------\n",
            "Epoch 68\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.0755e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.0754769723086325e-06\n",
            "----------------------------------------\n",
            "Epoch 69\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(3.0183e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 3.018287735407156e-06\n",
            "----------------------------------------\n",
            "Epoch 70\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.9689e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.9689023498630194e-06\n",
            "----------------------------------------\n",
            "Epoch 71\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.9244e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.9244430417502362e-06\n",
            "----------------------------------------\n",
            "Epoch 72\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.8832e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.8832480728302296e-06\n",
            "----------------------------------------\n",
            "Epoch 73\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.8471e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.847067127363581e-06\n",
            "----------------------------------------\n",
            "Epoch 74\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.8161e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.8161061856503806e-06\n",
            "----------------------------------------\n",
            "Epoch 75\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.7880e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.787970151392337e-06\n",
            "----------------------------------------\n",
            "Epoch 76\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.7612e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.761247115220838e-06\n",
            "----------------------------------------\n",
            "Epoch 77\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.7367e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.7367417045850254e-06\n",
            "----------------------------------------\n",
            "Epoch 78\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.7145e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.7144980849099483e-06\n",
            "----------------------------------------\n",
            "Epoch 79\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.6928e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.6928448014164476e-06\n",
            "----------------------------------------\n",
            "Epoch 80\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.6710e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.6710407284137763e-06\n",
            "----------------------------------------\n",
            "Epoch 81\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.6499e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.6498825943202615e-06\n",
            "----------------------------------------\n",
            "Epoch 82\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.6295e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.629492171779276e-06\n",
            "----------------------------------------\n",
            "Epoch 83\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.6089e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.608948923006397e-06\n",
            "----------------------------------------\n",
            "Epoch 84\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.5881e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.5881206262751213e-06\n",
            "----------------------------------------\n",
            "Epoch 85\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.5678e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.5678181528272734e-06\n",
            "----------------------------------------\n",
            "Epoch 86\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.5482e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.5482001563681935e-06\n",
            "----------------------------------------\n",
            "Epoch 87\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.5287e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.5287279986501263e-06\n",
            "----------------------------------------\n",
            "Epoch 88\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.5096e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.5095712984026917e-06\n",
            "----------------------------------------\n",
            "Epoch 89\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.4913e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.491331441947872e-06\n",
            "----------------------------------------\n",
            "Epoch 90\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.4740e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.4739896222317836e-06\n",
            "----------------------------------------\n",
            "Epoch 91\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.4572e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.457217900286923e-06\n",
            "----------------------------------------\n",
            "Epoch 92\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.4413e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.441342888793847e-06\n",
            "----------------------------------------\n",
            "Epoch 93\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.4266e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.4266289316713183e-06\n",
            "----------------------------------------\n",
            "Epoch 94\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.4126e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.4126474266256146e-06\n",
            "----------------------------------------\n",
            "Epoch 95\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.3992e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.399240460662034e-06\n",
            "----------------------------------------\n",
            "Epoch 96\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.3867e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.386696964481814e-06\n",
            "----------------------------------------\n",
            "Epoch 97\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.3750e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.3750263241011085e-06\n",
            "----------------------------------------\n",
            "Epoch 98\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.3638e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.3638338599968297e-06\n",
            "----------------------------------------\n",
            "Epoch 99\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.3530e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.3530333904979355e-06\n",
            "----------------------------------------\n",
            "Epoch 100\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.3428e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.3427912684184003e-06\n",
            "----------------------------------------\n",
            "Epoch 101\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.3329e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.332925437130794e-06\n",
            "----------------------------------------\n",
            "Epoch 102\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.3230e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.323005556056758e-06\n",
            "----------------------------------------\n",
            "Epoch 103\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.3132e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.3132345676878474e-06\n",
            "----------------------------------------\n",
            "Epoch 104\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.3037e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.303730947046211e-06\n",
            "----------------------------------------\n",
            "Epoch 105\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.2943e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.294327325274627e-06\n",
            "----------------------------------------\n",
            "Epoch 106\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.2850e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.2849878033793764e-06\n",
            "----------------------------------------\n",
            "Epoch 107\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.2758e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.275845989347572e-06\n",
            "----------------------------------------\n",
            "Epoch 108\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.2669e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.2668898882774385e-06\n",
            "----------------------------------------\n",
            "Epoch 109\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.2580e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.258024029193613e-06\n",
            "----------------------------------------\n",
            "Epoch 110\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.2493e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.2493056076170312e-06\n",
            "----------------------------------------\n",
            "Epoch 111\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.2408e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.2408059588411795e-06\n",
            "----------------------------------------\n",
            "Epoch 112\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.2325e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.2324621972205252e-06\n",
            "----------------------------------------\n",
            "Epoch 113\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.2242e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.2242467217121105e-06\n",
            "----------------------------------------\n",
            "Epoch 114\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.2162e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.2162296678170867e-06\n",
            "----------------------------------------\n",
            "Epoch 115\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.2084e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.208432399093976e-06\n",
            "----------------------------------------\n",
            "Epoch 116\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.2008e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.2007662587121027e-06\n",
            "----------------------------------------\n",
            "Epoch 117\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.1932e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.1932456163666733e-06\n",
            "----------------------------------------\n",
            "Epoch 118\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.1859e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.1858942998587142e-06\n",
            "----------------------------------------\n",
            "Epoch 119\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.1787e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.17866634190406e-06\n",
            "----------------------------------------\n",
            "Epoch 120\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.1715e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.1715366384167817e-06\n",
            "----------------------------------------\n",
            "Epoch 121\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.1645e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.1645245303434507e-06\n",
            "----------------------------------------\n",
            "Epoch 122\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.1576e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.1576197295609702e-06\n",
            "----------------------------------------\n",
            "Epoch 123\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.1508e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.15078833358545e-06\n",
            "----------------------------------------\n",
            "Epoch 124\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.1440e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.144038688734293e-06\n",
            "----------------------------------------\n",
            "Epoch 125\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.1374e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.137378277180507e-06\n",
            "----------------------------------------\n",
            "Epoch 126\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.1308e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.1307823284916546e-06\n",
            "----------------------------------------\n",
            "Epoch 127\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.1242e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.1242462436466606e-06\n",
            "----------------------------------------\n",
            "Epoch 128\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.1178e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.1177854794923314e-06\n",
            "----------------------------------------\n",
            "Epoch 129\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.1114e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.111391574104614e-06\n",
            "----------------------------------------\n",
            "Epoch 130\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.1051e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.1050539609173344e-06\n",
            "----------------------------------------\n",
            "Epoch 131\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0988e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.098783865981421e-06\n",
            "----------------------------------------\n",
            "Epoch 132\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0926e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.0925783522228365e-06\n",
            "----------------------------------------\n",
            "Epoch 133\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0864e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.08643391770894e-06\n",
            "----------------------------------------\n",
            "Epoch 134\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0804e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.0803504347891387e-06\n",
            "----------------------------------------\n",
            "Epoch 135\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0743e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.0743335448577e-06\n",
            "----------------------------------------\n",
            "Epoch 136\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0684e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.0683753499056466e-06\n",
            "----------------------------------------\n",
            "Epoch 137\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0625e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.0624733502552397e-06\n",
            "----------------------------------------\n",
            "Epoch 138\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0566e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.0566320355733708e-06\n",
            "----------------------------------------\n",
            "Epoch 139\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0508e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.050846219446491e-06\n",
            "----------------------------------------\n",
            "Epoch 140\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0451e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.045110378020883e-06\n",
            "----------------------------------------\n",
            "Epoch 141\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0394e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.0394270573886586e-06\n",
            "----------------------------------------\n",
            "Epoch 142\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0338e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.0337944284764476e-06\n",
            "----------------------------------------\n",
            "Epoch 143\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0282e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.028206947796103e-06\n",
            "----------------------------------------\n",
            "Epoch 144\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0227e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.0226652794487827e-06\n",
            "----------------------------------------\n",
            "Epoch 145\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0172e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.0171694556371917e-06\n",
            "----------------------------------------\n",
            "Epoch 146\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0117e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.0117152581233164e-06\n",
            "----------------------------------------\n",
            "Epoch 147\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0063e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.006302387649375e-06\n",
            "----------------------------------------\n",
            "Epoch 148\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(2.0009e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 2.000932092002731e-06\n",
            "----------------------------------------\n",
            "Epoch 149\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9956e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.9956018978720763e-06\n",
            "----------------------------------------\n",
            "Epoch 150\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9903e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.9903109398601224e-06\n",
            "----------------------------------------\n",
            "Epoch 151\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9851e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.9850604943223607e-06\n",
            "----------------------------------------\n",
            "Epoch 152\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9798e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.9798491225865887e-06\n",
            "----------------------------------------\n",
            "Epoch 153\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9747e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.9746756428191184e-06\n",
            "----------------------------------------\n",
            "Epoch 154\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9695e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.9695409995541253e-06\n",
            "----------------------------------------\n",
            "Epoch 155\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9644e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.964444419430508e-06\n",
            "----------------------------------------\n",
            "Epoch 156\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9594e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.9593845626157954e-06\n",
            "----------------------------------------\n",
            "Epoch 157\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9544e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.9543617785214914e-06\n",
            "----------------------------------------\n",
            "Epoch 158\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9494e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.9493754821316875e-06\n",
            "----------------------------------------\n",
            "Epoch 159\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9444e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.9444243041901704e-06\n",
            "----------------------------------------\n",
            "Epoch 160\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9395e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.9395082148359967e-06\n",
            "----------------------------------------\n",
            "Epoch 161\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9346e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.9346268358555923e-06\n",
            "----------------------------------------\n",
            "Epoch 162\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9298e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.9297789961677606e-06\n",
            "----------------------------------------\n",
            "Epoch 163\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9250e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.924964460907087e-06\n",
            "----------------------------------------\n",
            "Epoch 164\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9201e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.920134717357947e-06\n",
            "----------------------------------------\n",
            "Epoch 165\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9153e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.9153403017164248e-06\n",
            "----------------------------------------\n",
            "Epoch 166\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9106e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.910565030908935e-06\n",
            "----------------------------------------\n",
            "Epoch 167\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9058e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.90580979004132e-06\n",
            "----------------------------------------\n",
            "Epoch 168\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.9011e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.9010773847426175e-06\n",
            "----------------------------------------\n",
            "Epoch 169\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8964e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8963655378845105e-06\n",
            "----------------------------------------\n",
            "Epoch 170\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8917e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8916745921999245e-06\n",
            "----------------------------------------\n",
            "Epoch 171\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8870e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8870063951529825e-06\n",
            "----------------------------------------\n",
            "Epoch 172\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8824e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8823607310205955e-06\n",
            "----------------------------------------\n",
            "Epoch 173\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8777e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8777372385904874e-06\n",
            "----------------------------------------\n",
            "Epoch 174\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8731e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8731361227469885e-06\n",
            "----------------------------------------\n",
            "Epoch 175\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8686e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.868562676277342e-06\n",
            "----------------------------------------\n",
            "Epoch 176\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8640e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.86401293933565e-06\n",
            "----------------------------------------\n",
            "Epoch 177\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8595e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8594864823457134e-06\n",
            "----------------------------------------\n",
            "Epoch 178\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8550e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8549834311021532e-06\n",
            "----------------------------------------\n",
            "Epoch 179\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8505e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8505037548690575e-06\n",
            "----------------------------------------\n",
            "Epoch 180\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8460e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8460474310255552e-06\n",
            "----------------------------------------\n",
            "Epoch 181\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8416e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.841614492540779e-06\n",
            "----------------------------------------\n",
            "Epoch 182\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8372e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8372048612368845e-06\n",
            "----------------------------------------\n",
            "Epoch 183\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8328e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8328184747169835e-06\n",
            "----------------------------------------\n",
            "Epoch 184\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8285e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8284553193490085e-06\n",
            "----------------------------------------\n",
            "Epoch 185\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8241e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8241153015093954e-06\n",
            "----------------------------------------\n",
            "Epoch 186\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8198e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8197872260624523e-06\n",
            "----------------------------------------\n",
            "Epoch 187\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8155e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8154502718086458e-06\n",
            "----------------------------------------\n",
            "Epoch 188\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8111e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.811132235138781e-06\n",
            "----------------------------------------\n",
            "Epoch 189\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8068e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.8068334997762367e-06\n",
            "----------------------------------------\n",
            "Epoch 190\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.8026e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.802554426585657e-06\n",
            "----------------------------------------\n",
            "Epoch 191\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7983e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.7982952841613823e-06\n",
            "----------------------------------------\n",
            "Epoch 192\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7941e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.7940563131123993e-06\n",
            "----------------------------------------\n",
            "Epoch 193\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7898e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.7898377309640536e-06\n",
            "----------------------------------------\n",
            "Epoch 194\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7856e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.7856396864458774e-06\n",
            "----------------------------------------\n",
            "Epoch 195\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7815e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.781462313106846e-06\n",
            "----------------------------------------\n",
            "Epoch 196\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7773e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.7773057250698368e-06\n",
            "----------------------------------------\n",
            "Epoch 197\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7732e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.7731699862984152e-06\n",
            "----------------------------------------\n",
            "Epoch 198\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7691e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.769055151931568e-06\n",
            "----------------------------------------\n",
            "Epoch 199\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7650e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.7649612586442072e-06\n",
            "----------------------------------------\n",
            "Epoch 200\n",
            "IS variance:  tensor(6.4534e-06, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(1.7609e-06, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 1.7608883084495522e-06\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[-0.1982, -0.5572],\n",
            "        [-0.1224,  0.6697],\n",
            "        [-0.1859,  0.4811],\n",
            "        [ 0.1263,  0.2894],\n",
            "        [ 0.0221,  0.1914],\n",
            "        [-0.5981,  0.0634]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([ 0.4311,  0.6609, -0.2139,  0.5443, -0.4112,  1.0631],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[ 0.2854, -0.1002, -0.0428, -0.3139,  0.2459, -0.3971],\n",
            "        [ 0.2810, -0.1530, -0.1758, -0.0745,  0.1052, -0.1795],\n",
            "        [ 0.1248, -0.3361,  0.2486, -0.2877, -0.5554, -0.9408],\n",
            "        [ 0.0696, -0.1333, -0.2595, -0.3630, -0.3887,  0.1157],\n",
            "        [-0.0504,  0.0526, -0.1121,  0.1065, -0.6129, -0.3498],\n",
            "        [-0.2525, -0.3633, -0.1271, -0.1265, -0.2754, -0.2697]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([-0.4361,  0.1258, -0.1636,  0.0014, -0.0254,  0.3282],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[ 0.3004,  0.2740, -0.2649, -0.2538, -0.0028,  0.1882]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([0.0124], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test 400 0.99"
      ],
      "metadata": {
        "id": "-Y6XSrxLTUPw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b_400 = action_probs_top_n_epsilon(q_table, 1, 0.4)\n",
        "pi_b_400 = experiment_actions(400, env, P_pi_b_400)\n",
        "P_pi_e_400 = action_probs_top_n_epsilon(q_table, 2, 0.05)\n",
        "# pi_e_400 = experiment_actions(400, env, P_pi_e_400)\n",
        "model_400_0p99 = CustomizableFeatureNet(input_dim=2, hidden_dims=[6, 6], output_dim=1, dtype = torch.float64)\n",
        "test_400_0p99 = SCOPE_straight(model_400_0p99, 0.99, 1000, pi_b_400, P_pi_b_400, P_pi_e_400, dtype = torch.float64)\n",
        "model_400_0p99 = train_var_scope(model_400_0p99, 5, 0.001, test_400_0p99)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-GtA_2_H3jW",
        "outputId": "255985ec-858b-495f-a37b-6c1d83b80245"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "IS variance:  tensor(0.0002, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.0864, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.08636927251674584\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "IS variance:  tensor(0.0002, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.2360, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.23601228060459742\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "IS variance:  tensor(0.0002, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.2284, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.22842130839536168\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "IS variance:  tensor(0.0002, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.2203, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.22034274292801542\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "IS variance:  tensor(0.0002, dtype=torch.float64)\n",
            "SCOPE Var loss:  tensor(0.2122, dtype=torch.float64, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.21219201524204384\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[-0.2227, -0.2377],\n",
            "        [-0.1161, -0.0580],\n",
            "        [-0.1448,  0.0938],\n",
            "        [-0.1531,  0.6014],\n",
            "        [ 0.6863, -0.3983],\n",
            "        [-0.6208,  0.5967]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([-0.1459,  0.6348,  0.5511, -0.0894, -0.6099, -0.4201],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[ 0.0188,  0.1783,  0.1906, -0.1831, -0.2326,  0.3907],\n",
            "        [ 0.1501,  0.2778,  0.3853,  0.2220,  0.2562,  0.2344],\n",
            "        [-0.2534,  0.3682,  0.3991,  0.0664, -0.1327,  0.1305],\n",
            "        [ 0.3641,  0.1544,  0.0996,  0.0388,  0.3387,  0.2223],\n",
            "        [-0.1971,  0.1551, -0.1208, -0.2238,  0.3284,  0.2085],\n",
            "        [-0.2006,  0.0626,  0.0105, -0.3599, -0.2018,  0.0474]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([-0.0877, -0.3765,  0.2807, -0.3098,  0.2580, -0.0114],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[-0.3840,  0.2713,  0.0393, -0.2318,  0.2767,  0.1556]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([-0.2633], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test 600 0.99"
      ],
      "metadata": {
        "id": "pGLbkJw_OMtl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b_600 = action_probs_top_n_epsilon(q_table, 1, 0.4)\n",
        "pi_b_600 = experiment_actions(600, env_30, P_pi_b_600)\n",
        "P_pi_e_600 = action_probs_top_n_epsilon(q_table, 2, 0.05)\n",
        "# pi_e_600 = experiment_actions(600, env, P_pi_e_600)\n",
        "model_600_0p99 = CustomizableFeatureNet(input_dim=2, hidden_dims=[6, 6], output_dim=1, dtype = torch.float32)\n",
        "test_600_0p99 = SCOPE_straight(model_600_0p99, 0.99, 10000, pi_b_600, P_pi_b_600, P_pi_e_600, dtype = torch.float32)\n",
        "model_600_0p99 = train_var_scope(model_600_0p99, 5, 0.001, test_600_0p99)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DJzov1IOPEV",
        "outputId": "2289774b-c244-4899-98bb-4aa0a28de6b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "IS variance:  tensor(0.0007)\n",
            "SCOPE Var loss:  tensor(0.0505, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.05046245828270912\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "IS variance:  tensor(0.0007)\n",
            "SCOPE Var loss:  tensor(0.0493, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0493154413998127\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "IS variance:  tensor(0.0007)\n",
            "SCOPE Var loss:  tensor(0.0481, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.04812745749950409\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "IS variance:  tensor(0.0007)\n",
            "SCOPE Var loss:  tensor(0.0469, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.046937569975852966\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "IS variance:  tensor(0.0007)\n",
            "SCOPE Var loss:  tensor(0.0458, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.04576045647263527\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[ 0.1204,  0.1797],\n",
            "        [ 0.1732,  0.2432],\n",
            "        [ 0.6242,  0.4461],\n",
            "        [ 0.4436,  0.0618],\n",
            "        [ 0.2962, -0.5830],\n",
            "        [-0.3988, -0.6057]])\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([-0.5419,  0.4819,  0.6672, -0.3882, -0.3168, -0.5845])\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[ 0.3440, -0.1163, -0.2793,  0.0047, -0.1040, -0.2861],\n",
            "        [-0.2082, -0.2452, -0.2654, -0.3990, -0.1743, -0.2673],\n",
            "        [-0.1590, -0.3511, -0.3919,  0.1778, -0.1089, -0.2762],\n",
            "        [ 0.3015,  0.0899, -0.3342,  0.2264, -0.1954, -0.0921],\n",
            "        [ 0.3359,  0.2783,  0.3255, -0.1074, -0.0552,  0.3129],\n",
            "        [ 0.0065,  0.2449,  0.0709,  0.2463, -0.0068,  0.1182]])\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([ 0.3040, -0.2149, -0.0412, -0.2949, -0.2522,  0.2680])\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[-0.1696, -0.0297, -0.3140, -0.0297, -0.3058,  0.3434]])\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([-0.0148])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test 800 0.99"
      ],
      "metadata": {
        "id": "ariP9U-abrzP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b_800 = action_probs_top_n_epsilon(q_table, 1, 0.4)\n",
        "pi_b_800 = experiment_actions(800, env_30, P_pi_b_800)\n",
        "P_pi_e_800 = action_probs_top_n_epsilon(q_table, 2, 0.05)\n",
        "# pi_e_800 = experiment_actions(800, env_30, P_pi_e_800)\n",
        "model_800_0p99 = CustomizableFeatureNet(input_dim=2, hidden_dims=[6, 6], output_dim=1, dtype = torch.float32)\n",
        "test_800_0p99 = SCOPE_straight(model_800_0p99, 0.99, 10000, pi_b_800, P_pi_b_800, P_pi_e_800, dtype = torch.float32)\n",
        "model_800_0p99 = train_var_scope(model_800_0p99, 5, 0.001, test_800_0p99)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fY3ZZMqFbucT",
        "outputId": "d170bc23-4df3-467c-92a6-82dbe78457c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "IS variance:  tensor(6.2439e-07)\n",
            "SCOPE Var loss:  tensor(0.1004, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.10040785372257233\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "IS variance:  tensor(6.2439e-07)\n",
            "SCOPE Var loss:  tensor(0.1327, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.13271035254001617\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "IS variance:  tensor(6.2439e-07)\n",
            "SCOPE Var loss:  tensor(0.1297, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.12969112396240234\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "IS variance:  tensor(6.2439e-07)\n",
            "SCOPE Var loss:  tensor(0.1267, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.12670785188674927\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "IS variance:  tensor(6.2439e-07)\n",
            "SCOPE Var loss:  tensor(0.1238, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.12376594543457031\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[ 0.1256,  0.1763],\n",
            "        [ 0.1731,  0.2431],\n",
            "        [ 0.6243,  0.4461],\n",
            "        [ 0.4445,  0.0656],\n",
            "        [ 0.2962, -0.5871],\n",
            "        [-0.3988, -0.6057]])\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([-0.5420,  0.4819,  0.6672, -0.3851, -0.3175, -0.5845])\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[ 3.4210e-01, -1.1714e-01, -2.7928e-01,  1.6665e-04, -1.0937e-01,\n",
            "         -2.8613e-01],\n",
            "        [-2.0815e-01, -2.4523e-01, -2.6536e-01, -3.9900e-01, -1.7434e-01,\n",
            "         -2.6726e-01],\n",
            "        [-1.5169e-01, -3.5114e-01, -3.9192e-01,  1.8578e-01, -1.1592e-01,\n",
            "         -2.7624e-01],\n",
            "        [ 2.9939e-01,  9.2404e-02, -3.3420e-01,  2.2824e-01, -1.9231e-01,\n",
            "         -9.2125e-02],\n",
            "        [ 3.3559e-01,  2.7832e-01,  3.2552e-01, -1.0750e-01, -5.3136e-02,\n",
            "          3.1286e-01],\n",
            "        [ 1.6141e-02,  2.4356e-01,  7.9191e-02,  2.5596e-01, -3.4911e-03,\n",
            "          1.1824e-01]])\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([ 0.2993, -0.2149, -0.0318, -0.2958, -0.2523,  0.2699])\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[-0.1668, -0.0297, -0.3204, -0.0275, -0.3058,  0.3439]])\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([-0.0079])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test 1000 0.99"
      ],
      "metadata": {
        "id": "AZrEQ4ieTxeg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b_1000 = action_probs_top_n_epsilon(q_table, 1, 0.4)\n",
        "pi_b_1000 = experiment_actions(1000, env_30, P_pi_b_1000)\n",
        "P_pi_e_1000 = action_probs_top_n_epsilon(q_table, 2, 0.05)\n",
        "# pi_e_1000 = experiment_actions(1000, env, P_pi_e_1000)\n",
        "model_1000_0p99 = CustomizableFeatureNet(input_dim=2, hidden_dims=[6, 6], output_dim=1, dtype = torch.float32)\n",
        "test_1000_0p99 = SCOPE_straight(model_1000_0p99, 0.90, 10000, pi_b_1000, P_pi_b_1000, P_pi_e_1000, dtype = torch.float32)\n",
        "model_1000_0p99 = train_var_scope(model_1000_0p99, 5, 0.001, test_1000_0p99)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e06BDW8QSg_g",
        "outputId": "775bd8ae-65b2-4ede-9674-30b8610a6f67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "IS variance:  tensor(1.3628e-08)\n",
            "SCOPE Var loss:  tensor(0.0071, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.0071372101083397865\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "IS variance:  tensor(1.3628e-08)\n",
            "SCOPE Var loss:  tensor(0.0059, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.005885153077542782\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "IS variance:  tensor(1.3628e-08)\n",
            "SCOPE Var loss:  tensor(0.0057, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.005744975060224533\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "IS variance:  tensor(1.3628e-08)\n",
            "SCOPE Var loss:  tensor(0.0056, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.005605767946690321\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "IS variance:  tensor(1.3628e-08)\n",
            "SCOPE Var loss:  tensor(0.0055, grad_fn=<VarBackward0>)\n",
            "Total Loss: 0.005469260271638632\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[-0.3398,  0.4284],\n",
            "        [ 0.6470, -0.5601],\n",
            "        [-0.0836, -0.5419],\n",
            "        [ 0.2371, -0.0722],\n",
            "        [-0.2191, -0.1823],\n",
            "        [-0.6192, -0.4586]])\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([ 0.4420,  0.4668,  0.2511,  0.5432, -0.0262, -0.6044])\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[-0.1204, -0.0890, -0.2383,  0.3484,  0.3641, -0.3094],\n",
            "        [-0.3600, -0.0599,  0.1120,  0.2181,  0.0257,  0.3971],\n",
            "        [-0.0396, -0.1132, -0.0198, -0.3503,  0.3299,  0.3989],\n",
            "        [-0.3419, -0.0945, -0.0509,  0.2863, -0.0306,  0.4073],\n",
            "        [ 0.2843,  0.4049,  0.2897, -0.2459,  0.1344,  0.0443],\n",
            "        [-0.0682,  0.2438, -0.2887,  0.2774,  0.4038, -0.2734]])\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([-0.1609,  0.3603,  0.3371, -0.4036,  0.0650,  0.0022])\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[-0.3125, -0.0285,  0.1303,  0.3379,  0.3765, -0.1660]])\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([-0.1458])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tM7NaSOMSktR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}