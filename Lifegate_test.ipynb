{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMOvDcZShr8mxaGD5gzeotD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ai4ai-lab/Reward-Shaping/blob/main/Lifegate_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "zZ2S2CI8K_jT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jsHzrhmfpiTr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from google.colab import drive\n",
        "import pickle\n",
        "np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)\n",
        "from scipy.optimize import minimize\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.lines import Line2D\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# deadend dependencies"
      ],
      "metadata": {
        "id": "UMj8NNrGfwu8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/microsoft/med-deadend.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KStXBTWK3f64",
        "outputId": "c0252e4f-1c11-4ca5-86a6-e3bf7bb13929"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'med-deadend'...\n",
            "remote: Enumerating objects: 130, done.\u001b[K\n",
            "remote: Counting objects: 100% (130/130), done.\u001b[K\n",
            "remote: Compressing objects: 100% (105/105), done.\u001b[K\n",
            "remote: Total 130 (delta 52), reused 77 (delta 22), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (130/130), 395.48 KiB | 10.69 MiB/s, done.\n",
            "Resolving deltas: 100% (52/52), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# shaping dependencies"
      ],
      "metadata": {
        "id": "AsZMw4C0f2K-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ajagota7/Shaping.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wu7X59dK3hqk",
        "outputId": "2fd35d18-44f6-4e05-9ff5-e6578c3ffc52"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Shaping'...\n",
            "remote: Enumerating objects: 63, done.\u001b[K\n",
            "remote: Counting objects: 100% (63/63), done.\u001b[K\n",
            "remote: Compressing objects: 100% (44/44), done.\u001b[K\n",
            "remote: Total 63 (delta 24), reused 55 (delta 18), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (63/63), 11.54 MiB | 17.05 MiB/s, done.\n",
            "Resolving deltas: 100% (24/24), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cd /content/"
      ],
      "metadata": {
        "id": "hZ8dnFnidxL_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/Shaping\n",
        "\n",
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile('/content/Shaping/lifegate_1.zip', 'r') as zip_ref:\n",
        "    # zip_ref.extractall('/content/med-deadend/lifegate/results/lifegate_1')\n",
        "    zip_ref.extractall('/content/Shaping/')"
      ],
      "metadata": {
        "id": "2noY6FOTdsmY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/med-deadend/lifegate\n",
        "\n",
        "\n",
        "# results_dir = 'results/lifegate_1/'\n",
        "results_dir = '/content/Shaping/'\n",
        "# Load the Q tables from the primary learning agent, Q_D and Q_R value functions\n",
        "with open(results_dir+'tabular_qnet.pkl', 'rb') as fq:\n",
        "    ai = pickle.load(fq)\n",
        "\n",
        "with open(results_dir+'tabular_qd.pkl', 'rb') as fd:\n",
        "    ai_d = pickle.load(fd)\n",
        "\n",
        "with open(results_dir+'tabular_qr.pkl', 'rb') as fr:\n",
        "    ai_r = pickle.load(fr)"
      ],
      "metadata": {
        "id": "7lv4ZIBkeLW3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "650613eb-1728-4d67-c790-d3295c9af4c9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/med-deadend/lifegate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q_table = np.zeros((10, 10, 5))\n",
        "q_d = np.zeros_like(q_table)\n",
        "q_r = np.zeros_like(q_table)\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    for j in range(10):\n",
        "        for a in range(5):\n",
        "            key = tuple([j, i, a])\n",
        "            try:\n",
        "                q_table[i,j,a] = ai.q[key]\n",
        "                q_d[i,j,a] = ai_d.q[key]\n",
        "                q_r[i,j,a] = ai_r.q[key]\n",
        "            except:\n",
        "                pass"
      ],
      "metadata": {
        "id": "Rk0Z42sNebl4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "import random"
      ],
      "metadata": {
        "id": "4uTTjsWNfK21"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from lifegate import LifeGate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZDw5-YMfMSM",
        "outputId": "f3898f5f-2c5d-4084-e26f-fc7f69959dd4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pygame 2.5.2 (SDL 2.28.2, Python 3.10.12)\n",
            "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params = yaml.safe_load(open('config.yaml', 'r'))"
      ],
      "metadata": {
        "id": "pzii8SOefSCm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(seed=params['random_seed'])\n",
        "random.seed(params['random_seed'])\n",
        "random_state = np.random.RandomState(params['random_seed'])"
      ],
      "metadata": {
        "id": "ircWaFyzfVZr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = LifeGate(max_steps=params['episode_max_len'], state_mode='tabular',\n",
        "                        rendering=True, image_saving=False, render_dir=None, rng=random_state, death_drag = 0.4)"
      ],
      "metadata": {
        "id": "XUoJuLN0fabn"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KZp-8-f7far2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import Shaping"
      ],
      "metadata": {
        "id": "hS65UmL5Yu_K"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from Shaping import *"
      ],
      "metadata": {
        "id": "FwGOFhh0ZeGx"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Shaping\n",
        "\n",
        "from choose_actions import action_probs_top_n_epsilon\n",
        "from shaping_features import *\n",
        "from gen_policies import *\n",
        "from IS import *\n",
        "from subset_policies import *\n",
        "from v_pi_e import *\n",
        "from optimization import *\n",
        "from neural_net import *\n",
        "from prep_variance import *\n",
        "from SCOPE_variance import SCOPE_variance"
      ],
      "metadata": {
        "id": "NYtD9mJOadhF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b659ba8-8ad2-4062-8628-1e8f1d97dd99"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Shaping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating policies"
      ],
      "metadata": {
        "id": "0fwQz6Zfke5i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b = action_probs_top_n_epsilon(q_table, 1, 0.4)\n",
        "pi_b = experiment_actions(1000, env, P_pi_b)"
      ],
      "metadata": {
        "id": "wW1SGejBZZlb"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_e = action_probs_top_n_epsilon(q_table, 2, 0.05)\n",
        "pi_e = experiment_actions(1000, env, P_pi_e)"
      ],
      "metadata": {
        "id": "J41LskdFjPaT"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prep"
      ],
      "metadata": {
        "id": "03SCZEAMnGeY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = CustomizableFeatureNet(input_dim=2, hidden_dims=[16, 32], output_dim=1, dtype = torch.float64)"
      ],
      "metadata": {
        "id": "LRcpZ6zAowqJ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test1 = SCOPE_variance(model, 0.9, 10000, pi_b, P_pi_b, P_pi_e, dtype = torch.float64)"
      ],
      "metadata": {
        "id": "jqKcMhNSnRTC"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples_IS, padded_state_tensors, padded_weight_diff_tensors, gamma_weights_last_tensor, states_first_tensor, states_last_tensor = test1.prepare()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uftstgp1nRTP",
        "outputId": "7998bc44-ec4f-49c8-cc2f-0678da1c9bcb"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/Shaping/SCOPE_variance.py:89: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  padded_weight_diff_tensors = torch.tensor(padded_weights_difference, dtype = self.dtype)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clamp_large_terms(tensor):\n",
        "  clamped_tensor = torch.clamp(tensor, min = -1e38, max = 1e38)\n",
        "  return clamped_tensor"
      ],
      "metadata": {
        "id": "pHvWigy5tCVY"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clamp_large_terms(tensor):\n",
        "  return tensor"
      ],
      "metadata": {
        "id": "Wvm8ekEuwQIj"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "states_output, states_first_output, states_last_output = test1.pass_states(model, padded_state_tensors, states_first_tensor, states_last_tensor)\n",
        "sums_states_weight_diff = test1.states_weight_diff_sums(states_output, padded_weight_diff_tensors)\n",
        "gamma_weights_states_last_sub_states_first = test1.last_first_terms_operations(gamma_weights_last_tensor, states_last_output, states_first_output)\n",
        "sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first = test1.bootstrap_shaping_terms(sums_states_weight_diff, gamma_weights_states_last_sub_states_first)"
      ],
      "metadata": {
        "id": "-AlHoAZwi9Dr"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the min and max values of tensors\n",
        "print(\"padded_weight_diff_tensors - Min:\", padded_weight_diff_tensors.min().item(), \" Max:\", padded_weight_diff_tensors.max().item())\n",
        "print(\"sums_states_weight_diff - Min:\", sums_states_weight_diff.min().item(), \" Max:\", sums_states_weight_diff.max().item())\n",
        "print(\"gamma_weights_last_tensor - Min:\", gamma_weights_last_tensor.min().item(), \" Max:\", gamma_weights_last_tensor.max().item())\n",
        "print(\"samples_IS - Min:\", samples_IS.min().item(), \" Max:\", samples_IS.max().item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RZCBfD9vwRx",
        "outputId": "848ff536-461e-47d2-a673-228c566be871"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "padded_weight_diff_tensors - Min: -7.550129734505424e+42  Max: 6.991006254054227e+42\n",
            "sums_states_weight_diff - Min: -3.3466686316947584e+17  Max: 5.410147133435166e+41\n",
            "gamma_weights_last_tensor - Min: 0.0  Max: 9.232375374691587e+41\n",
            "samples_IS - Min: -1.025819486076843e+42  Max: 1.0028234611748854e+17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_shaped_variance(samples_IS, sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first):\n",
        "\n",
        "  # states_output, states_first_output, states_last_output = pass_states(model, padded_state_tensors, states_first_tensor, states_last_tensor)\n",
        "\n",
        "  # Begin calcs without clamping\n",
        "\n",
        "  # IS\n",
        "  E_IS_sq = torch.mean(torch.mean(samples_IS, dim = 1)**2)\n",
        "  E_IS_all_sq = torch.mean(torch.mean(samples_IS, dim = 1))**2\n",
        "\n",
        "  # states_weight_diff\n",
        "  E_s_wdiff_sq = torch.mean(torch.mean(sample_sums_states_weight_diff, dim =1)**2)\n",
        "  E_s_wdiff_all_sq = torch.mean(torch.mean(sample_sums_states_weight_diff, dim = 1))**2\n",
        "\n",
        "  # all terms\n",
        "  SCOPE = sample_sums_states_weight_diff+samples_gamma_weight_states_last_sub_states_first\n",
        "  E_IS_SCOPE = torch.mean(torch.mean(samples_IS, dim =1) * torch.mean(SCOPE, dim =1))\n",
        "  E_IS_E_SCOPE = torch.mean(torch.mean(samples_IS,dim = 1 ))*torch.mean(torch.mean(SCOPE, dim =1))\n",
        "\n",
        "  SCOPE_variance = E_IS_sq + 2*E_IS_SCOPE + E_s_wdiff_sq - E_IS_all_sq - 2*E_IS_E_SCOPE - E_IS_E_SCOPE\n",
        "\n",
        "  IS_variance = E_IS_sq - E_IS_all_sq\n",
        "\n",
        "  return IS_variance, SCOPE_variance\n"
      ],
      "metadata": {
        "id": "WlDazbYPvvrg"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IS_variance, SCOPE_variance = calculate_shaped_variance(samples_IS, sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first)"
      ],
      "metadata": {
        "id": "yWcJ_iSFvvru"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SCOPE_variance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42b8e146-8d1f-4707-92a7-aa8a519226dc",
        "id": "aGXswiRNvvrv"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7.0500e+77, dtype=torch.float64, grad_fn=<SubBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IS_variance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2b28ff7-f885-4fde-ad51-5acdb4898378",
        "id": "7Id4_3YPvvrv"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.0786e+78, dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1V2lMOPkxpDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimizing"
      ],
      "metadata": {
        "id": "InzaU1hEzXaK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "wEeNxHjkz9Gx"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_var(model, num_epochs, learning_rate, samples_IS, sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first):\n",
        "    model.train()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        _, variance_loss = calculate_shaped_variance(samples_IS, sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}\")\n",
        "        print(\"Var loss: \", variance_loss)\n",
        "\n",
        "        tot = variance_loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        tot.backward(retain_graph=True)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += tot.item()\n",
        "\n",
        "        print(f\"Total Loss: {total_loss}\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            print(f\"Parameter name: {name}\")\n",
        "            print(f\"Weights: {param.data}\")\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "g8Y0CtCi6hWZ"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = train_var(model, 10, 0.01, samples_IS, sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "yvkJGlBs0M8M",
        "outputId": "3ca228ab-05d6-43a3-c4e0-e98a36264ceb"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Var loss:  tensor(7.0500e+77, dtype=torch.float64, grad_fn=<SubBackward0>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-9c298a7f59db>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_IS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_sums_states_weight_diff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_gamma_weight_states_last_sub_states_first\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-58-910d34c05f44>\u001b[0m in \u001b[0;36mtrain_var\u001b[0;34m(model, num_epochs, learning_rate, samples_IS, sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Backpropagation and optimization for the trajectory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mtot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Working on prep"
      ],
      "metadata": {
        "id": "O36PGywGna2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Working on padding trajectories to allow for easier optimization\n",
        "\n",
        "# def pad_trajectories(pi_b):\n",
        "#     # Find the maximum length among all trajectories\n",
        "#     max_length = max(len(traj) for traj in pi_b)\n",
        "\n",
        "#     # Define the padding value\n",
        "#     padding_value = np.array([np.array([0, 0]), 0, 0, np.array([0, 0]), 0, 0], dtype=object)\n",
        "\n",
        "#     # Pad each trajectory to match the maximum length\n",
        "#     padded_pi_b = [traj + [padding_value] * (max_length - len(traj)) for traj in pi_b]\n",
        "\n",
        "#     return padded_pi_b"
      ],
      "metadata": {
        "id": "ErjhWCq3czmx"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pi_b_padded = pad_trajectories(pi_b)"
      ],
      "metadata": {
        "id": "31TWTP7Eb1sC"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def variance_terms_tens(eval_policy, behav_policy, behavior_policies):\n",
        "  # Initialize lists to store axis data for each policy\n",
        "  timesteps = []\n",
        "  states = []\n",
        "  state_first = []\n",
        "  state_last = []\n",
        "  actions = []\n",
        "  rewards = []\n",
        "  gamma_last = []\n",
        "  weight_last = []\n",
        "  weights = calculate_importance_weights(eval_policy, behav_policy, behavior_policies)\n",
        "  psi = []\n",
        "\n",
        "  for index, policy in enumerate(behavior_policies):\n",
        "      policy_array = np.array(policy)\n",
        "      timesteps.append(policy_array[:, 4].astype(int))\n",
        "      # s.append(policy_array[:, 0])\n",
        "\n",
        "      # last timestep for gamma\n",
        "      gamma_last.append(len(policy))\n",
        "      # last importance weight\n",
        "      weight_last.append(weights[index][-1])\n",
        "\n",
        "\n",
        "      states.append(policy_array[:, 0][1:])\n",
        "      psi.append(policy_array[:,5][1:])\n",
        "      state_first.append(policy_array[:,0][0])\n",
        "      state_last.append(policy_array[:,0][-1])\n",
        "      actions.append(policy_array[:, 1])\n",
        "      rewards.append(policy_array[:, 2].astype(float))\n",
        "\n",
        "  weights_difference = []\n",
        "  for index, weight in enumerate(weights):\n",
        "    # diff = np.array(w[index][:-1]) - np.array(w[index][1:])\n",
        "    diff = np.array(weight[:-1]) - np.array(weight[1:])\n",
        "    weights_difference.append(diff)\n",
        "\n",
        "  return timesteps, states, state_first, state_last, actions, rewards, gamma_last, weight_last, weights, weights_difference"
      ],
      "metadata": {
        "id": "Kcx483JVfDWA"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# t, s, s_f, s_l, a, r, g_l, w_l, w, w_diff = variance_terms_tens(P_pi_e, P_pi_b, pi_b)"
      ],
      "metadata": {
        "id": "q8d3KfusfsZ4"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "timesteps, states, states_first, states_last, actions, rewards, gamma_last, weights_last, weights, weights_difference = variance_terms_tens(P_pi_e, P_pi_b, pi_b)"
      ],
      "metadata": {
        "id": "BAqNV3alEAjQ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def padding_IS_terms(timesteps, actions, rewards, weights):\n",
        "    # Find the maximum length among all lists\n",
        "    max_length = max(len(traj) for traj in timesteps)\n",
        "\n",
        "    # Define the padding values\n",
        "    zero_padding = 0\n",
        "\n",
        "    # Pad each list to match the maximum length\n",
        "    padded_timesteps = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in timesteps]\n",
        "    padded_rewards = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in rewards]\n",
        "    padded_actions = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in actions]\n",
        "    padded_weights = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in weights]\n",
        "\n",
        "    return padded_timesteps, padded_rewards, padded_actions, padded_weights"
      ],
      "metadata": {
        "id": "AuuBKl0joAEk"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_timesteps, padded_rewards, padded_actions, padded_weights = padding_IS_terms(timesteps, actions, rewards, weights)"
      ],
      "metadata": {
        "id": "xD675spBnrP9"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def padding_states_weights_difference(states, weights_difference):\n",
        "    # Find the maximum length of trajectories\n",
        "    max_length = max(len(trajectory) for trajectory in states)\n",
        "\n",
        "    zero_padding = 0\n",
        "\n",
        "    # Pad each trajectory to make them all the same length\n",
        "    padded_states = [\n",
        "        [list(item) for item in trajectory] + [[0, 0]] * (max_length - len(trajectory))\n",
        "        for trajectory in states\n",
        "    ]\n",
        "\n",
        "    padded_weights_difference = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in weights_difference]\n",
        "\n",
        "    return padded_states, padded_weights_difference"
      ],
      "metadata": {
        "id": "4DekSrOTzLAn"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_states, padded_weights_difference = padding_states_weights_difference(states, weights_difference)"
      ],
      "metadata": {
        "id": "aX6DIhEQTCVR"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tensorize_padded_terms(padded_states, padded_weights_difference):\n",
        "  padded_state_tensors = torch.tensor(padded_states, dtype = torch.float64)\n",
        "  padded_weight_diff_tensors = torch.tensor(padded_weights_difference, dtype = torch.float64)\n",
        "  padded_weight_diff_tensors = padded_weight_diff_tensors.unsqueeze(-1)\n",
        "\n",
        "  return padded_state_tensors, padded_weight_diff_tensors\n"
      ],
      "metadata": {
        "id": "hHZhHnuUzHFr"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_state_tensors, padded_weight_diff_tensors = tensorize_padded_terms(padded_states, padded_weights_difference)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5kb1vOxTZSu",
        "outputId": "6b5b983d-35ca-4d5f-9ff4-1cba9d74450b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-3c22136e8020>:3: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  padded_weight_diff_tensors = torch.tensor(padded_weights_difference, dtype = torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tensorize_last_and_first_terms(states_first, states_last, gamma_last, weights_last):\n",
        "  states_first_tensor = torch.tensor(states_first, dtype = torch.float64)\n",
        "  states_last_tensor = torch.tensor(states_last, dtype = torch.float64)\n",
        "  gamma_last_tensor = torch.tensor(gamma_last, dtype = torch.float64)\n",
        "  weights_last_tensor = torch.tensor(weights_last, dtype = torch.float64)\n",
        "\n",
        "  return states_first_tensor, states_last_tensor, gamma_last_tensor, weights_last_tensor"
      ],
      "metadata": {
        "id": "AqtoK6MEmPWJ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "states_first_tensor, states_last_tensor, gamma_last_tensor, weights_last_tensor = tensorize_last_and_first_terms(states_first, states_last, gamma_last, weights_last)"
      ],
      "metadata": {
        "id": "gvE-AddhDTkx"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_IS_terms(gamma, timesteps, rewards, weights):\n",
        "  gtrw = np.power(gamma, timesteps)*rewards*weights\n",
        "\n",
        "  IS_tensor = torch.sum(torch.tensor(gtrw, dtype = torch.float32), dim = 1, keepdim = True)\n",
        "\n",
        "  return IS_tensor\n"
      ],
      "metadata": {
        "id": "YVpa0bTwd3HX"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IS_tensor = calc_IS_terms(0.9, padded_timesteps, padded_rewards, padded_weights)"
      ],
      "metadata": {
        "id": "xjRU7xlj89PY"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.finfo(torch.float64).max"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGtcFc-YY9SK",
        "outputId": "ce82a7a6-848c-4034-f260-6a3bf7702324"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.7976931348623157e+308"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# samples_IS[0]"
      ],
      "metadata": {
        "id": "s_JAi7apXuJ2"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_gamma_weight_last(gamma, gamma_last, weights_last):\n",
        "  gamma_weight_last = np.power(gamma, gamma_last)*weights_last\n",
        "\n",
        "  gamma_weight_last_tensor = torch.tensor(gamma_weight_last, dtype = torch.float64).unsqueeze(-1)\n",
        "\n",
        "  return gamma_weight_last_tensor"
      ],
      "metadata": {
        "id": "8I3qisEpsYzB"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gamma_weights_last_tensor = calc_gamma_weight_last(0.9, gamma_last, weights_last)"
      ],
      "metadata": {
        "id": "XHDztxg4C3So"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bootstrap_IS_terms(IS_tensor, num_samples):\n",
        "  seed = 42\n",
        "  torch.manual_seed(seed)\n",
        "\n",
        "  num_bootstraps = num_samples*len(IS_tensor)\n",
        "\n",
        "  # Sample indices with replacement\n",
        "  sampled_indices = torch.randint(0, len(IS_tensor), size=(num_bootstraps,), dtype=torch.long)\n",
        "\n",
        "  # new_size = (num_samples, IS_tensor.shape[0], IS_tensor.shape[1])\n",
        "  new_size = (num_samples, IS_tensor.shape[0])\n",
        "\n",
        "  IS_bootstraps = IS_tensor[sampled_indices].view(new_size)\n",
        "\n",
        "  # sampled_tensor = IS_bootstraps.view(new_size)\n",
        "\n",
        "  return IS_bootstraps"
      ],
      "metadata": {
        "id": "rdqtMRAT35lW"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples_IS = bootstrap_IS_terms(IS_tensor, 10000)"
      ],
      "metadata": {
        "id": "MHOyNeJ-UdcS"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clamp_large_terms(input_term):\n",
        "  max_float64 = torch.finfo(torch.float64).max\n",
        "  return torch.clamp(input_term, min=-max_float64, max=max_float64)\n"
      ],
      "metadata": {
        "id": "ng9lLOfsGvdb"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clamp_large_terms(input_term):\n",
        "    max_float64 = torch.tensor(torch.finfo(torch.float64).max, dtype=torch.float64)\n",
        "    min_value = torch.tensor(-1e50, dtype=torch.float64)\n",
        "    return torch.clamp(input_term, min=min_value, max=max_float64)\n",
        "\n",
        "    # return torch.clamp(input_term, min=-max_float64, max=max_float64)\n"
      ],
      "metadata": {
        "id": "C1Su5BQ0cfUV"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CustomizableFeatureNet_d(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dims, output_dim, dropout_prob=0.2, dtype=torch.float32):\n",
        "        super(CustomizableFeatureNet_d, self).__init__()\n",
        "        self.hidden_layers = nn.ModuleList()\n",
        "\n",
        "        # Create the hidden layers based on the provided sizes\n",
        "        for in_dim, out_dim in zip([input_dim] + hidden_dims, hidden_dims):\n",
        "            self.hidden_layers.append(nn.Linear(in_dim, out_dim).to(dtype))\n",
        "\n",
        "        self.output_layer = nn.Linear(hidden_dims[-1], output_dim).to(dtype)\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.hidden_layers:\n",
        "            x = F.relu(layer(x))\n",
        "            x = self.dropout(x)\n",
        "        x = self.output_layer(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "YFqvRa0LS7OF"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CustomizableFeatureNet_d(input_dim=2, hidden_dims=[16, 32], output_dim=1, dtype = torch.float64)"
      ],
      "metadata": {
        "id": "udif1c2cTBzV"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = CustomizableFeatureNet(input_dim=2, hidden_dims=[16, 32], output_dim=1)"
      ],
      "metadata": {
        "id": "ct8DQIU6rUvw"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pass_states(model, padded_state_tensors, states_first_tensor, states_last_tensor):\n",
        "  # Get model outputs for states\n",
        "  states_output = model(padded_state_tensors)\n",
        "  states_first_output = model(states_first_tensor)\n",
        "  states_last_output = model(states_last_tensor)\n",
        "  return states_output, states_first_output, states_last_output"
      ],
      "metadata": {
        "id": "0JNHRYkBmZ5Q"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "states_output, states_first_output, states_last_output = pass_states(model, padded_state_tensors, states_first_tensor, states_last_tensor)"
      ],
      "metadata": {
        "id": "duNRe00YE34A"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def states_weight_diff_sums(states_output, padded_weight_diff_tensors):\n",
        "  states_weight_diff = states_output * padded_weight_diff_tensors\n",
        "  sums_states_weight_diff = torch.sum(states_weight_diff, dim =1)\n",
        "\n",
        "  return sums_states_weight_diff"
      ],
      "metadata": {
        "id": "8nZkrdWPW5AQ"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sums_states_weight_diff = states_weight_diff_sums(states_output, padded_weight_diff_tensors)"
      ],
      "metadata": {
        "id": "nlxvS4QpYW0s"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def last_first_terms_operations(gamma_weights_last_tensor, states_last_output, states_first_output):\n",
        "  gamma_weights_states_last_sub_states_first = gamma_weights_last_tensor*states_last_output -  states_first_output\n",
        "\n",
        "  return gamma_weights_states_last_sub_states_first"
      ],
      "metadata": {
        "id": "fDDD0NcUaxpk"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gamma_weights_states_last_sub_states_first = last_first_terms_operations(gamma_weights_last_tensor, states_last_output, states_first_output)"
      ],
      "metadata": {
        "id": "ScpV8dhaCqHc"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gamma_weights_states_last_sub_states_first.shape"
      ],
      "metadata": {
        "id": "oC-P2rDqFIwP"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bootstrap_shaping_terms(sums_states_weight_diff, gamma_weights_states_last_sub_states_first, num_samples):\n",
        "\n",
        "  seed = 42\n",
        "  torch.manual_seed(seed)\n",
        "\n",
        "  num_bootstraps = num_samples*sums_states_weight_diff.shape[0]\n",
        "\n",
        "  # Sample indices with replacement\n",
        "  sampled_indices = torch.randint(0, len(sums_states_weight_diff), size=(num_bootstraps,), dtype=torch.long)\n",
        "\n",
        "  # sizes\n",
        "  # size_states_weights_diff = (num_samples, states_output.shape[0], states_output.shape[1])\n",
        "  reshaped_size = (num_samples, sums_states_weight_diff.shape[0])\n",
        "\n",
        "  # Resize samples to shape num_samples x num_trajectories x length_padded_trajectories\n",
        "  # samples_states_output = states_output[sampled_indices].view(size_states_weights_diff)\n",
        "  # samples_weight_diff = padded_weight_diff_tensors[sampled_indices].view(size_states_weights_diff)\n",
        "\n",
        "  # Resize samples to shape num_samples x num_trajectories\n",
        "  sample_sums_states_weight_diff = sums_states_weight_diff[sampled_indices].view(reshaped_size)\n",
        "  # samples_states_first_output = sums_states_weight_diff[sampled_indices].view(reshaped_size)\n",
        "  # samples_states_last_output = states_last_output[sampled_indices].view(reshaped_size)\n",
        "  samples_gamma_weight_states_last_sub_states_first = gamma_weights_states_last_sub_states_first[sampled_indices].view(reshaped_size)\n",
        "\n",
        "\n",
        "  return sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first\n"
      ],
      "metadata": {
        "id": "d3UM9eUGeQdq"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first = bootstrap_shaping_terms(sums_states_weight_diff, gamma_weights_states_last_sub_states_first, 10000)"
      ],
      "metadata": {
        "id": "whCU0iyDCi8U"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def gtrw_plus_states_weight_diff_min_last_firsts_terms(gtrw_tensor, sums_states_weight_diff, gamma_weights_states_last_sub_states_first):\n",
        "#   sum_IS_and_shaping = gtrw_tensor + sums_states_weight_diff + gamma_weights_states_last_sub_states_first\n",
        "\n",
        "#   return sum_IS_and_shaping"
      ],
      "metadata": {
        "id": "sIw1SreEnUpM"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def bootstrap_IS_shaping_terms(gtrw_tensor, sums_states_weight_diff, gamma_weights_states_last_sub_states_first):\n",
        "#   seed = 42\n",
        "#   torch.manual_seed(seed)\n",
        "\n",
        "#   num_bootstraps = num_samples*sums_states_weight_diff.shape[0]\n",
        "\n",
        "#   # Sample indices with replacement\n",
        "#   sampled_indices = torch.randint(0, len(sums_states_weight_diff), size=(num_bootstraps,), dtype=torch.long)\n",
        "\n"
      ],
      "metadata": {
        "id": "OZHZzE6d58xQ"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wTVuyCVBB4-8"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clamp_large_terms(torch.mean(clamp_large_terms(torch.mean(samples_IS, dim = 1))))"
      ],
      "metadata": {
        "id": "tdFIzbNUgx94"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clamp_large_terms(torch.mean(clamp_large_terms(torch.mean(samples_IS, dim =1)**2)))"
      ],
      "metadata": {
        "id": "4dLA0DBLh-pV"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clamp_large_terms(torch.mean(clamp_large_terms(torch.mean(samples_IS, dim =1))**2) - torch.mean(clamp_large_terms(torch.mean(samples_IS, dim = 1))))"
      ],
      "metadata": {
        "id": "7pfgg5rZlakd"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SCOPE = sample_sums_states_weight_diff+samples_gamma_weight_states_last_sub_states_first"
      ],
      "metadata": {
        "id": "MWwuJS4En1ll"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.mean(SCOPE,dim =1).shape"
      ],
      "metadata": {
        "id": "ECEj-Lhooh8M"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mean(clamp_large_terms(samples_IS), dim = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6YXvZmXYUKd",
        "outputId": "d5a030e2-5c73-48bd-b58f-8e4970fbe046"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([      -inf, 2.0056e+14,       -inf,  ...,       -inf,       -inf,\n",
              "        1.0028e+14])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_shaped_variance(samples_IS, sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first):\n",
        "\n",
        "\n",
        "  # states_output, states_first_output, states_last_output = pass_states(model, padded_state_tensors, states_first_tensor, states_last_tensor)\n",
        "\n",
        "\n",
        "\n",
        "  # Begin calcs without clamping\n",
        "\n",
        "  # IS\n",
        "  E_IS_sq = torch.mean(torch.mean(clamp_large_terms(samples_IS), dim = 1)**2)\n",
        "  E_IS_all_sq = torch.mean(torch.mean(clamp_large_terms(samples_IS), dim = 1))**2\n",
        "\n",
        "  # states_weight_diff\n",
        "  E_s_wdiff_sq = torch.mean(torch.mean(clamp_large_terms(sample_sums_states_weight_diff), dim =1)**2)\n",
        "  E_s_wdiff_all_sq = torch.mean(torch.mean(clamp_large_terms(sample_sums_states_weight_diff), dim = 1))**2\n",
        "\n",
        "  # all terms\n",
        "  SCOPE = clamp_large_terms(sample_sums_states_weight_diff)+clamp_large_terms(samples_gamma_weight_states_last_sub_states_first)\n",
        "  E_IS_SCOPE = torch.mean(torch.mean(clamp_large_terms(samples_IS), dim =1) * torch.mean(SCOPE, dim =1))\n",
        "  E_IS_E_SCOPE = torch.mean(torch.mean(clamp_large_terms(samples_IS),dim = 1 ))*torch.mean(torch.mean(SCOPE, dim =1))\n",
        "\n",
        "  SCOPE_variance = E_IS_sq + 2*E_IS_SCOPE + E_s_wdiff_sq - E_IS_all_sq - 2*E_IS_E_SCOPE - E_IS_E_SCOPE\n",
        "\n",
        "  IS_variance = E_IS_sq - E_IS_all_sq\n",
        "\n",
        "  return IS_variance, SCOPE_variance\n"
      ],
      "metadata": {
        "id": "LLuzewmQ3DR6"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IS_variance, SCOPE_variance = calculate_shaped_variance(samples_IS, sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first)"
      ],
      "metadata": {
        "id": "Nz9ApTk-qnx9"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mean(torch.mean(clamp_large_terms(samples_IS), dim = 1)**2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qN1zDrJWo4wZ",
        "outputId": "548dc965-3831-4791-9077-d8d8de7062d5"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(inf)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SCOPE_variance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBjjOVEggKhd",
        "outputId": "fdeba7f8-0ed2-498d-f842-25fe37e45dcd"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(nan, dtype=torch.float64, grad_fn=<SubBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IS_variance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyMAdyWjgb4b",
        "outputId": "fcadf31c-726b-4846-b87e-576e2d0c1d59"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(nan)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def clamp_large_terms(input_term):\n",
        "    max_float64 = torch.tensor(torch.finfo(torch.float64).max, dtype=torch.float64)\n",
        "    # min_value = torch.tensor(-1e38, dtype=torch.float64)\n",
        "    min_value = torch.tensor(-9e-38, dtype=torch.float64)\n",
        "\n",
        "    # min_value = torch.tensor(-1.7e+308, dtype = torch.float64)\n",
        "    # min_value = torch.tensor(torch.finfo(torch.float64).min, dtype=torch.float64)\n",
        "\n",
        "\n",
        "    # Using torch.where to explicitly set values outside the desired range\n",
        "    clamped_result = torch.where(input_term < min_value, min_value, input_term)\n",
        "    clamped_result = torch.where(clamped_result > max_float64, max_float64, clamped_result)\n",
        "\n",
        "    return clamped_result\n",
        "clamp_large_terms(samples_IS)[0].min()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDs0epOwdjjK",
        "outputId": "70d2de61-11b2-465f-a114-7527e815ead9"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-9.0000e-38)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "samples_IS[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGlLqnsIhLAr",
        "outputId": "dbacfd91-4d5b-48ae-8d2b-c36b24042d6d"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.0000e+00, -9.5567e-34, -1.1020e-12, -5.7703e-20,  0.0000e+00,\n",
              "        -6.6609e-06,  0.0000e+00,  0.0000e+00,  0.0000e+00, -7.4562e-17,\n",
              "        -1.3518e-33, -6.3068e-29, -1.1566e-08,  0.0000e+00, -3.2522e-24,\n",
              "         0.0000e+00,  0.0000e+00, -4.0924e-02,  0.0000e+00,  0.0000e+00,\n",
              "        -6.0833e-21, -1.1020e-12,  0.0000e+00, -3.5032e-43, -3.4013e-37,\n",
              "        -7.9832e-23,  0.0000e+00, -2.2156e-12,  0.0000e+00, -7.3671e-27,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -3.0953e-12,  0.0000e+00, -7.1745e-11,  0.0000e+00,\n",
              "        -1.2184e+02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -4.8370e-19,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -1.7865e-25, -3.0953e-12, -3.1972e-14,\n",
              "         0.0000e+00, -3.9939e-21,  0.0000e+00, -4.2383e-17,  0.0000e+00,\n",
              "         0.0000e+00, -9.5567e-34,  0.0000e+00,  0.0000e+00, -5.4262e-07,\n",
              "        -3.7487e-37, -2.6165e-41,  0.0000e+00, -1.0701e-07,  0.0000e+00,\n",
              "         0.0000e+00, -6.6945e-22,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -1.3046e-34, -1.7190e-19,  0.0000e+00,\n",
              "         9.6867e-18, -4.6108e-20,  1.3313e-32, -4.5634e-22,  0.0000e+00,\n",
              "         0.0000e+00, -1.9068e-20, -3.2430e-22, -8.2104e-17,  0.0000e+00,\n",
              "        -1.0108e-29,  0.0000e+00, -8.4772e-20,  0.0000e+00, -2.0319e-39,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -6.3362e-38,  0.0000e+00,\n",
              "         4.7220e-16,  0.0000e+00, -1.5748e-17,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -1.3046e-34,  3.4275e-23,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.2642e-11,\n",
              "        -2.0774e-08,  0.0000e+00, -2.4060e-40, -3.5032e-43,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "        -9.3884e-01, -8.4772e-20, -2.5036e-39,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -1.3247e-35,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -3.8730e-15, -1.0150e-03, -2.0038e-36,  0.0000e+00,\n",
              "         0.0000e+00, -8.4655e-19,  0.0000e+00, -7.3035e-20, -6.6609e-06,\n",
              "         0.0000e+00,  0.0000e+00, -1.6692e-14, -2.6013e-38,  0.0000e+00,\n",
              "         0.0000e+00, -5.6024e-35, -4.5634e-22,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -2.8727e-10, -2.2156e-12,\n",
              "         0.0000e+00,  0.0000e+00,  5.1149e-40,  0.0000e+00,  0.0000e+00,\n",
              "        -1.3400e-08,  0.0000e+00, -2.6687e-08,  0.0000e+00, -4.5020e-30,\n",
              "        -1.0701e-07, -1.0052e-13,  0.0000e+00,  0.0000e+00, -4.5720e-36,\n",
              "        -2.7511e-36,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -9.6992e-23,  0.0000e+00,  0.0000e+00,  1.1169e-32,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -1.2418e-12,  3.4265e-14,\n",
              "         0.0000e+00,  0.0000e+00, -1.6255e-43, -1.1568e-11,  0.0000e+00,\n",
              "        -2.5918e-04, -4.2958e-02, -1.4635e-26,  0.0000e+00, -8.7134e-11,\n",
              "         3.6282e-29,  0.0000e+00,  0.0000e+00, -1.2983e-17,  0.0000e+00,\n",
              "         0.0000e+00, -1.2418e-12, -1.6759e-21,  0.0000e+00,  0.0000e+00,\n",
              "        -1.9035e-38, -2.1801e-26,  0.0000e+00, -1.2909e-23, -4.1059e-16,\n",
              "        -2.4789e-27, -1.0616e-20,  0.0000e+00, -2.5688e-29, -5.9457e-04,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -1.4309e-17,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "        -3.0097e+06,  0.0000e+00, -3.9645e-25, -8.8058e-20,  1.9898e-43,\n",
              "        -2.2156e-12,  0.0000e+00,  0.0000e+00, -3.8730e-15,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -2.4202e-34,  0.0000e+00,  0.0000e+00, -3.2028e-23,\n",
              "         0.0000e+00,  0.0000e+00, -3.9735e-34,  0.0000e+00, -3.8966e-08,\n",
              "         0.0000e+00, -2.2030e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -3.5367e-40,  0.0000e+00,  0.0000e+00,\n",
              "        -7.4222e-38,  0.0000e+00,  0.0000e+00, -9.4159e-16,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -2.1972e-42, -8.4772e-20,  0.0000e+00,\n",
              "         0.0000e+00, -2.0903e-15,  0.0000e+00,  0.0000e+00, -2.5223e-44,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -1.4013e-45,  0.0000e+00,\n",
              "        -1.7457e-24,  0.0000e+00, -1.0543e-37, -1.6182e-33, -3.5188e-28,\n",
              "        -8.2104e-17,  0.0000e+00, -3.8662e-06,  0.0000e+00,  0.0000e+00,\n",
              "        -2.4441e-09, -8.4772e-20,  0.0000e+00,  0.0000e+00, -9.1102e-12,\n",
              "         0.0000e+00, -3.0097e+06,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "        -4.5720e-36,  0.0000e+00, -3.6430e-12,  0.0000e+00,  0.0000e+00,\n",
              "        -1.6816e-44,  1.9004e-41, -4.8050e-26, -2.8832e-06, -1.4013e-45,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -4.4110e-04,\n",
              "         0.0000e+00,  0.0000e+00, -5.9390e-13,  0.0000e+00,  0.0000e+00,\n",
              "        -4.5634e-22,  0.0000e+00, -3.4013e-37,  0.0000e+00,  0.0000e+00,\n",
              "         1.9898e-43,  0.0000e+00, -4.2383e-17,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -1.2412e-14, -5.9457e-04,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -1.0701e-07,  5.1149e-40,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.5719e-17,\n",
              "         0.0000e+00,  0.0000e+00, -6.4470e-14, -1.3247e-35,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "        -9.8613e-27, -3.9645e-25, -1.5112e-30, -1.1566e-08,  0.0000e+00,\n",
              "         0.0000e+00, -1.5719e-17,  0.0000e+00, -1.3828e-31,  0.0000e+00,\n",
              "        -4.5551e-22, -1.6255e-43, -1.9179e-27,  4.6289e-17, -6.6137e-04,\n",
              "        -8.4772e-20,  0.0000e+00,  0.0000e+00, -8.2205e-14, -1.2163e-08,\n",
              "         0.0000e+00,  0.0000e+00, -1.2418e-12, -1.0543e-37,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  2.8294e-34, -4.5634e-22,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -7.7118e-30,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -1.3518e-33,  0.0000e+00,  0.0000e+00,\n",
              "        -1.8627e-28, -3.9645e-25,  0.0000e+00,  0.0000e+00, -2.1972e-42,\n",
              "         0.0000e+00, -2.4485e-09, -1.0150e-03,  0.0000e+00, -1.7865e-25,\n",
              "         0.0000e+00,        -inf,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -6.7035e-32,  0.0000e+00,  0.0000e+00, -6.3710e-32,\n",
              "        -6.6137e-04, -6.5706e-01,  0.0000e+00, -1.5719e-17,  0.0000e+00,\n",
              "         0.0000e+00,  5.1149e-40,  0.0000e+00, -7.1308e-38, -1.3518e-33,\n",
              "         0.0000e+00,  0.0000e+00, -1.0150e-03,  0.0000e+00, -5.4345e-13,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -9.3034e-30,\n",
              "        -8.1634e-13,  0.0000e+00,  1.7343e-39,  0.0000e+00, -3.7737e+01,\n",
              "        -1.6692e-14,  0.0000e+00,  0.0000e+00, -1.1301e-18,  0.0000e+00,\n",
              "        -1.0095e-10, -8.0009e-07,  0.0000e+00, -2.4070e-08, -2.6165e-41,\n",
              "        -3.0533e-07,  0.0000e+00, -2.6325e-14,  0.0000e+00,  0.0000e+00,\n",
              "        -6.7686e-14,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -1.3188e+01,  0.0000e+00, -3.4013e-37,\n",
              "         0.0000e+00,  7.1993e-41, -2.2864e-35, -6.5861e-44, -4.9438e-23,\n",
              "        -2.0903e-15,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "        -4.6133e-21,  0.0000e+00,  0.0000e+00,  0.0000e+00, -5.8006e-24,\n",
              "         0.0000e+00,  0.0000e+00, -6.3710e-32,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -6.0236e-15,  0.0000e+00, -2.5559e-05, -3.8831e-13,\n",
              "         0.0000e+00,  0.0000e+00, -1.2184e+02,  0.0000e+00, -1.0090e+01,\n",
              "        -5.2582e-35, -1.3873e-42,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         1.6419e-27, -8.8237e-12, -1.2808e-33, -4.6133e-21,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  9.6867e-18,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -2.4571e-31,  0.0000e+00,  1.3201e-38,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -4.1568e-11,  0.0000e+00,\n",
              "        -1.4013e-45, -1.0701e-07,  3.2638e-35,  0.0000e+00,  0.0000e+00,\n",
              "         3.4265e-14, -2.5223e-44,  0.0000e+00, -1.7958e-41, -2.4441e-09,\n",
              "         0.0000e+00, -8.0009e-07, -1.4125e-01, -1.0090e+01,  0.0000e+00,\n",
              "        -2.2156e-12,  0.0000e+00,  0.0000e+00,  0.0000e+00, -2.4070e-08,\n",
              "        -4.5634e-22, -1.3188e+01,  0.0000e+00,  0.0000e+00, -5.0588e-29,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.3046e-34,\n",
              "        -2.3189e-15,  0.0000e+00, -2.9159e+00, -4.8370e-19, -1.0197e-32,\n",
              "         0.0000e+00, -4.2383e-17,  1.0241e-28,  0.0000e+00, -3.0533e-07,\n",
              "         0.0000e+00,  0.0000e+00, -1.0150e-03,  0.0000e+00, -9.1102e-12,\n",
              "         0.0000e+00, -2.6325e-14, -1.4617e-36, -3.8065e-38,  0.0000e+00,\n",
              "        -5.4262e-07, -1.0095e-10,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -6.6729e-06,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -4.5634e-22,  0.0000e+00, -9.8748e-13,  0.0000e+00,\n",
              "        -1.8556e-23,  0.0000e+00, -5.4529e-33,  0.0000e+00, -3.2522e-24,\n",
              "         1.1032e-38, -1.5748e-17,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "        -7.9976e-23, -3.2028e-23, -9.3884e-01,  0.0000e+00,  0.0000e+00,\n",
              "        -3.4013e-37,  2.8026e-45,  0.0000e+00, -6.8054e-14,  0.0000e+00,\n",
              "        -1.0145e-30, -4.4114e-29, -6.0833e-21,  0.0000e+00, -1.2272e+09,\n",
              "         0.0000e+00, -8.2104e-17,  0.0000e+00, -6.1665e+15, -1.7958e-41,\n",
              "        -2.5223e-44, -6.8813e-12, -3.8615e-09,  0.0000e+00, -4.6133e-21,\n",
              "         0.0000e+00,  0.0000e+00, -3.5367e-40, -5.1789e+02, -7.3035e-20,\n",
              "         0.0000e+00, -2.3485e-09, -1.0284e-27, -4.5693e-33,  0.0000e+00,\n",
              "        -2.0038e-36, -1.5719e-17,  0.0000e+00, -5.8006e-24, -1.7944e-15,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.8730e-15,\n",
              "         0.0000e+00,  0.0000e+00, -1.0701e-07,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -1.4013e-45, -7.9832e-23,  0.0000e+00, -1.3046e-34,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.5112e-30,\n",
              "        -5.8855e-44,  0.0000e+00,  0.0000e+00,  0.0000e+00, -6.7035e-32,\n",
              "         3.4275e-23,  0.0000e+00, -3.5486e-18,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -1.4617e-36,  0.0000e+00,\n",
              "         0.0000e+00, -3.0533e-07, -1.4830e-20, -8.4772e-20,  0.0000e+00,\n",
              "        -6.8054e-14,  0.0000e+00, -2.0976e-10,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -1.0095e-10, -8.4655e-19, -9.5567e-34,  0.0000e+00,\n",
              "        -2.5559e-05, -1.4857e-20,  0.0000e+00,  0.0000e+00, -2.2156e-12,\n",
              "        -1.5748e-17,  0.0000e+00, -2.2156e-12, -2.8727e-10,  0.0000e+00,\n",
              "        -6.2816e-41,  0.0000e+00,  0.0000e+00,  0.0000e+00, -4.6129e-11,\n",
              "        -1.2412e-14,  0.0000e+00, -4.7570e-17,  0.0000e+00, -2.4571e-31,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -4.5551e-22,\n",
              "        -1.0701e-07,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -5.6052e-45, -3.8615e-09,  0.0000e+00, -6.6945e-22,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -1.4857e-20,  0.0000e+00,\n",
              "        -1.9068e-20, -1.4830e-20,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "        -1.4309e-17, -1.7958e-41,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -4.9438e-23, -5.4529e-33,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -8.4772e-20,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -2.8727e-10,  0.0000e+00, -9.0216e-24, -1.2184e+02,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "        -4.2036e-30, -2.2960e-18,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -2.3133e-27,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -7.9832e-23,  0.0000e+00, -1.3400e-08, -2.4060e-40,\n",
              "        -9.5567e-34, -2.6038e-21,  0.0000e+00, -9.8748e-13,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -9.8091e-45,  0.0000e+00,\n",
              "         0.0000e+00, -1.3046e-34,  1.1169e-32,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -4.2383e-17, -2.2156e-12,  0.0000e+00,  0.0000e+00,\n",
              "        -3.7737e+01,  0.0000e+00,  0.0000e+00,  0.0000e+00, -5.1789e+02,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -2.2141e-04, -7.1308e-38,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -2.7511e-36,\n",
              "         0.0000e+00, -2.3189e-15,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -5.9457e-04,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -1.5112e-30,  0.0000e+00, -1.4125e-01,\n",
              "        -3.2425e-18,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -1.0095e-10,  0.0000e+00, -7.4033e-39,\n",
              "        -1.7015e-18, -6.6945e-22,  0.0000e+00, -1.9035e-38, -4.2974e-25,\n",
              "        -1.1244e-36,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.6816e-44,\n",
              "        -1.0052e-13,  0.0000e+00,  0.0000e+00, -2.5688e-29,  0.0000e+00,\n",
              "         0.0000e+00, -7.1308e-38, -1.3400e-08,  0.0000e+00, -8.7134e-11,\n",
              "         0.0000e+00, -1.7944e-15,  0.0000e+00, -2.5462e-42,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -1.2808e-33, -2.6687e-08,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -3.5322e-01, -2.0774e-08,\n",
              "        -1.4013e-45, -1.0095e-10,  0.0000e+00, -9.5567e-34,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -2.4202e-34, -3.3704e-28,  0.0000e+00,\n",
              "        -1.8556e-23, -3.0591e-21,  0.0000e+00,  0.0000e+00,  2.1787e-40,\n",
              "        -1.4635e-26,  0.0000e+00,  0.0000e+00,  0.0000e+00, -2.4565e-24,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -4.2036e-30,  0.0000e+00,\n",
              "        -1.4309e-17,  0.0000e+00, -2.4565e-24,  0.0000e+00,  0.0000e+00,\n",
              "        -5.4262e-07,  0.0000e+00, -2.8903e-30,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -2.4789e-27,\n",
              "        -2.4789e-27,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.4645e-07,\n",
              "         0.0000e+00, -4.7570e-17,  0.0000e+00, -1.2418e-12,  0.0000e+00,\n",
              "        -2.6013e-38,  0.0000e+00, -4.5020e-30,  0.0000e+00,  0.0000e+00,\n",
              "        -1.1129e-17,  0.0000e+00,  0.0000e+00,  0.0000e+00, -4.6108e-20,\n",
              "        -1.6266e-28,  0.0000e+00,  0.0000e+00, -9.0216e-24, -7.9832e-23,\n",
              "         0.0000e+00, -1.6816e-44,  0.0000e+00,  0.0000e+00, -3.5032e-43,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -2.8558e-42, -4.0543e-28,\n",
              "        -1.6182e-33,  0.0000e+00, -1.3873e-42,  0.0000e+00, -3.0953e-12,\n",
              "         0.0000e+00,  0.0000e+00,  1.8187e-35, -1.3828e-31, -1.6692e-14])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clamp_large_terms(samples_IS)[0].min()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xg4Fy5iQcqnl",
        "outputId": "534b197d-a951-470c-d848-9b9d74a2121f"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-9.0000e-38)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clamp_large_terms(tensor):\n",
        "    max_float64 = torch.finfo(torch.float64).max\n",
        "    min_float64 = torch.finfo(torch.float64).min\n",
        "\n",
        "    tensor[tensor == float('inf')] = 1e38  # Choose a large finite value\n",
        "    tensor[tensor == float('-inf')] = -1e38  # Choose a small finite value\n",
        "\n",
        "    return tensor\n",
        "\n",
        "# Example usage:\n",
        "# samples_IS_clamped = clamp_tensor(samples_IS)"
      ],
      "metadata": {
        "id": "5I1eVRAvlZK5"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# samples_IS_clamped[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "fMWanHX9l-kL",
        "outputId": "d8453853-77ac-49e1-fca3-d1760b015b58"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'samples_IS_clamped' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-5babce667c95>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msamples_IS_clamped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'samples_IS_clamped' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tensor(torch.finfo(torch.float64).min, dtype=torch.float64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZvLUFyNeJBo",
        "outputId": "c35697a7-262f-427d-d331-dfc87a2c111b"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-1.7977e+308, dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "MHWCgv3e3fSs",
        "outputId": "f1041452-2c44-40ad-fd87-8a903fee57eb"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomizableFeatureNet_d(\n",
              "  (hidden_layers): ModuleList(\n",
              "    (0): Linear(in_features=2, out_features=16, bias=True)\n",
              "    (1): Linear(in_features=16, out_features=32, bias=True)\n",
              "  )\n",
              "  (output_layer): Linear(in_features=32, out_features=1, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = model(state_tensors)"
      ],
      "metadata": {
        "id": "HkIlYqmg25KD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "651d0a8b-af25-4e2f-a721-0b694511e29f"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 must have the same dtype, but got Float and Double",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-602b7502521b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-45-0c890199681a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 must have the same dtype, but got Float and Double"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output.shape"
      ],
      "metadata": {
        "id": "Tukv3iQZ3ekc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FltSKPtH8TAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CustomizableFeatureNet(input_dim=2, hidden_dims=[16, 32], output_dim=1)"
      ],
      "metadata": {
        "id": "pG06s2t_0gZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3PZWZk4GqndI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scope_set, phi_set = subset_policies(pi_b, 0.3)"
      ],
      "metadata": {
        "id": "OFF9HKErgm34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IS, state_tensors, w_diff, f, st_og, psi_res, sample_last_tensors = variance_terms_tens(P_pi_e, P_pi_b, phi_set)"
      ],
      "metadata": {
        "id": "inVdxVMRjT4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CustomizableFeatureNet(input_dim=2, hidden_dims=[16, 32], output_dim=1)"
      ],
      "metadata": {
        "id": "qq1dLzLCjUp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = train_mse_var(model, 40, 0.001, 1, 1, IS, state_tensors, w_diff, f, sample_last_tensors, phi_set, st_og, psi_res)"
      ],
      "metadata": {
        "id": "TYKlf1urD34t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test class"
      ],
      "metadata": {
        "id": "72Fy4L1cuitK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SCOPE_variance(object):\n",
        "    def __init__(self, model, gamma, num_bootstraps, pi_b, P_pi_b, P_pi_e):\n",
        "        self.model = model\n",
        "        self.gamma = gamma\n",
        "        self.num_bootstraps = num_bootstraps\n",
        "        self.pi_b = pi_b\n",
        "        self.P_pi_b = P_pi_b\n",
        "        self.P_pi_e = P_pi_e\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def prep_policies(self):\n",
        "        # Initialize lists to store axis data for each policy\n",
        "        timesteps = []\n",
        "        states = []\n",
        "        state_first = []\n",
        "        state_last = []\n",
        "        actions = []\n",
        "        rewards = []\n",
        "        gamma_last = []\n",
        "        weight_last = []\n",
        "        weights = calculate_importance_weights(self.P_pi_e, self.P_pi_b, self.pi_b)\n",
        "        psi = []\n",
        "\n",
        "        for index, policy in enumerate(pi_b):\n",
        "            policy_array = np.array(policy)\n",
        "            timesteps.append(policy_array[:, 4].astype(int))\n",
        "            # s.append(policy_array[:, 0])\n",
        "\n",
        "            # last timestep for gamma\n",
        "            gamma_last.append(len(policy))\n",
        "            # last importance weight\n",
        "            weight_last.append(weights[index][-1])\n",
        "\n",
        "\n",
        "            states.append(policy_array[:, 0][1:])\n",
        "            psi.append(policy_array[:,5][1:])\n",
        "            state_first.append(policy_array[:,0][0])\n",
        "            state_last.append(policy_array[:,0][-1])\n",
        "            actions.append(policy_array[:, 1])\n",
        "            rewards.append(policy_array[:, 2].astype(float))\n",
        "\n",
        "        weights_difference = []\n",
        "        for index, weight in enumerate(weights):\n",
        "            # diff = np.array(w[index][:-1]) - np.array(w[index][1:])\n",
        "            diff = np.array(weight[:-1]) - np.array(weight[1:])\n",
        "            weights_difference.append(diff)\n",
        "\n",
        "        return timesteps, states, state_first, state_last, actions, rewards, gamma_last, weight_last, weights, weights_difference\n",
        "\n",
        "    def padding_IS_terms(self,timesteps, actions, rewards, weights):\n",
        "        # Find the maximum length among all lists\n",
        "        max_length = max(len(traj) for traj in timesteps)\n",
        "\n",
        "        # Define the padding values\n",
        "        zero_padding = 0\n",
        "\n",
        "        # Pad each list to match the maximum length\n",
        "        padded_timesteps = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in timesteps]\n",
        "        padded_rewards = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in rewards]\n",
        "        padded_actions = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in actions]\n",
        "        padded_weights = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in weights]\n",
        "\n",
        "        return padded_timesteps, padded_rewards, padded_actions, padded_weights\n",
        "\n",
        "    def padding_states_weights_difference(self, states, weights_difference):\n",
        "        # Find the maximum length of trajectories\n",
        "        max_length = max(len(trajectory) for trajectory in states)\n",
        "\n",
        "        zero_padding = 0\n",
        "\n",
        "        # Pad each trajectory to make them all the same length\n",
        "        padded_states = [\n",
        "            [list(item) for item in trajectory] + [[0, 0]] * (max_length - len(trajectory))\n",
        "            for trajectory in states\n",
        "        ]\n",
        "\n",
        "        padded_weights_difference = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in weights_difference]\n",
        "\n",
        "        return padded_states, padded_weights_difference\n",
        "\n",
        "    def tensorize_padded_terms(self, padded_states, padded_weights_difference):\n",
        "        padded_state_tensors = torch.tensor(padded_states, dtype = torch.float32)\n",
        "        padded_weight_diff_tensors = torch.tensor(padded_weights_difference, dtype = torch.float32)\n",
        "        padded_weight_diff_tensors = padded_weight_diff_tensors.unsqueeze(-1)\n",
        "\n",
        "        return padded_state_tensors, padded_weight_diff_tensors\n",
        "\n",
        "    def tensorize_last_and_first_terms(self, states_first, states_last, gamma_last, weights_last):\n",
        "        states_first_tensor = torch.tensor(states_first, dtype = torch.float32)\n",
        "        states_last_tensor = torch.tensor(states_last, dtype = torch.float32)\n",
        "        gamma_last_tensor = torch.tensor(gamma_last, dtype = torch.float32)\n",
        "        weights_last_tensor = torch.tensor(weights_last, dtype = torch.float32)\n",
        "\n",
        "        return states_first_tensor, states_last_tensor, gamma_last_tensor, weights_last_tensor\n",
        "\n",
        "    def calc_IS_terms(self, gamma, timesteps, rewards, weights):\n",
        "        gtrw = np.power(gamma, timesteps)*rewards*weights\n",
        "\n",
        "        IS_tensor = torch.sum(torch.tensor(gtrw, dtype = torch.float32), dim = 1, keepdim = True)\n",
        "\n",
        "        return IS_tensor\n",
        "\n",
        "    def calc_gamma_weight_last(self, gamma, gamma_last, weights_last):\n",
        "        gamma_weight_last = np.power(gamma, gamma_last)*weights_last\n",
        "\n",
        "        gamma_weight_last_tensor = torch.tensor(gamma_weight_last, dtype = torch.float32).unsqueeze(-1)\n",
        "\n",
        "        return gamma_weight_last_tensor\n",
        "    def bootstrap_IS_terms(self, IS_tensor, num_samples):\n",
        "        seed = 42\n",
        "        torch.manual_seed(seed)\n",
        "\n",
        "        num_bootstraps = num_samples*len(IS_tensor)\n",
        "\n",
        "        # Sample indices with replacement\n",
        "        sampled_indices = torch.randint(0, len(IS_tensor), size=(num_bootstraps,), dtype=torch.long)\n",
        "\n",
        "        # new_size = (num_samples, IS_tensor.shape[0], IS_tensor.shape[1])\n",
        "        new_size = (num_samples, IS_tensor.shape[0])\n",
        "\n",
        "        IS_bootstraps = IS_tensor[sampled_indices].view(new_size)\n",
        "\n",
        "        # sampled_tensor = IS_bootstraps.view(new_size)\n",
        "\n",
        "        return IS_bootstraps\n",
        "\n",
        "    def states_weight_diff_sums(self, states_output, padded_weight_diff_tensors):\n",
        "        states_weight_diff = states_output * padded_weight_diff_tensors\n",
        "        sums_states_weight_diff = torch.sum(states_weight_diff, dim =1)\n",
        "\n",
        "        return sums_states_weight_diff\n",
        "\n",
        "    def bootstrap_shaping_terms(self, sums_states_weight_diff, gamma_weights_states_last_sub_states_first, num_samples):\n",
        "\n",
        "        seed = 42\n",
        "        torch.manual_seed(seed)\n",
        "\n",
        "        num_bootstraps = num_samples*sums_states_weight_diff.shape[0]\n",
        "\n",
        "        # Sample indices with replacement\n",
        "        sampled_indices = torch.randint(0, len(sums_states_weight_diff), size=(num_bootstraps,), dtype=torch.long)\n",
        "\n",
        "        reshaped_size = (num_samples, sums_states_weight_diff.shape[0])\n",
        "\n",
        "        # Resize samples to shape num_samples x num_trajectories\n",
        "        sample_sums_states_weight_diff = sums_states_weight_diff[sampled_indices].view(reshaped_size)\n",
        "        samples_gamma_weight_states_last_sub_states_first = gamma_weights_states_last_sub_states_first[sampled_indices].view(reshaped_size)\n",
        "\n",
        "\n",
        "        return sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first\n",
        "\n",
        "    def pass_states(self,model, padded_state_tensors, states_first_tensor, states_last_tensor):\n",
        "        # Get model outputs for states\n",
        "        states_output = model(padded_state_tensors)\n",
        "        states_first_output = model(states_first_tensor)\n",
        "        states_last_output = model(states_last_tensor)\n",
        "        return states_output, states_first_output, states_last_output\n",
        "\n",
        "\n",
        "    def prepare(self):\n",
        "        timesteps, states, states_first, states_last, actions, rewards, gamma_last, weights_last, weights, weights_difference = self.prep_policies()\n",
        "        padded_timesteps, padded_rewards, padded_actions, padded_weights = self.padding_IS_terms(timesteps, actions, rewards, weights)\n",
        "        padded_states, padded_weights_difference = self.padding_states_weights_difference(states, weights_difference)\n",
        "        padded_state_tensors, padded_weight_diff_tensors = self.tensorize_padded_terms(padded_states, padded_weights_difference)\n",
        "        states_first_tensor, states_last_tensor, gamma_last_tensor, weights_last_tensor = self.tensorize_last_and_first_terms(states_first, states_last, gamma_last, weights_last)\n",
        "        IS_tensor = self.calc_IS_terms(self.gamma, padded_timesteps, padded_rewards, padded_weights)\n",
        "        gamma_weights_last_tensor = self.calc_gamma_weight_last(self.gamma, gamma_last, weights_last)\n",
        "        samples_IS = self.bootstrap_IS_terms(IS_tensor, self.num_bootstraps)\n",
        "\n",
        "        return samples_IS, padded_state_tensors, padded_weight_diff_tensors, gamma_weights_last_tensor, states_first_tensor, states_last_tensor\n"
      ],
      "metadata": {
        "id": "1vZCWSiPum0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test1 = SCOPE_variance(model, 0.9, 10000, pi_b, P_pi_b, P_pi_e)"
      ],
      "metadata": {
        "id": "1fEf2grNuo0q"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s,p_s, p_w, g_w_l, s_f, s_l = test1.prepare()"
      ],
      "metadata": {
        "id": "QLqIwtmVu6Co"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}