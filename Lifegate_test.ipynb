{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [
        "0fwQz6Zfke5i",
        "d4uOoMlDEv-1"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNdkeGx/toT+JeI3ZlOh+N+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ai4ai-lab/Reward-Shaping/blob/main/Lifegate_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "zZ2S2CI8K_jT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jsHzrhmfpiTr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from google.colab import drive\n",
        "import pickle\n",
        "# np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)\n",
        "from scipy.optimize import minimize\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.lines import Line2D\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# deadend dependencies"
      ],
      "metadata": {
        "id": "UMj8NNrGfwu8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/microsoft/med-deadend.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KStXBTWK3f64",
        "outputId": "5860d238-45df-432d-ed90-9f0a247898f7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'med-deadend'...\n",
            "remote: Enumerating objects: 130, done.\u001b[K\n",
            "remote: Counting objects: 100% (130/130), done.\u001b[K\n",
            "remote: Compressing objects: 100% (105/105), done.\u001b[K\n",
            "remote: Total 130 (delta 52), reused 77 (delta 22), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (130/130), 395.48 KiB | 2.40 MiB/s, done.\n",
            "Resolving deltas: 100% (52/52), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# shaping dependencies"
      ],
      "metadata": {
        "id": "AsZMw4C0f2K-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ajagota7/Shaping.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wu7X59dK3hqk",
        "outputId": "96d659af-603a-4db6-9c40-91be6ebb7431"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Shaping'...\n",
            "remote: Enumerating objects: 101, done.\u001b[K\n",
            "remote: Counting objects: 100% (101/101), done.\u001b[K\n",
            "remote: Compressing objects: 100% (72/72), done.\u001b[K\n",
            "remote: Total 101 (delta 49), reused 74 (delta 28), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (101/101), 11.74 MiB | 19.42 MiB/s, done.\n",
            "Resolving deltas: 100% (49/49), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/Shaping"
      ],
      "metadata": {
        "id": "5SkpvWFqz631"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !git pull origin main"
      ],
      "metadata": {
        "id": "8QRHhC-G0AiH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cd /content/"
      ],
      "metadata": {
        "id": "hZ8dnFnidxL_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/Shaping\n",
        "\n",
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile('/content/Shaping/lifegate_1.zip', 'r') as zip_ref:\n",
        "    # zip_ref.extractall('/content/med-deadend/lifegate/results/lifegate_1')\n",
        "    zip_ref.extractall('/content/Shaping/')"
      ],
      "metadata": {
        "id": "2noY6FOTdsmY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/med-deadend/lifegate\n",
        "\n",
        "\n",
        "# results_dir = 'results/lifegate_1/'\n",
        "results_dir = '/content/Shaping/'\n",
        "# Load the Q tables from the primary learning agent, Q_D and Q_R value functions\n",
        "with open(results_dir+'tabular_qnet.pkl', 'rb') as fq:\n",
        "    ai = pickle.load(fq)\n",
        "\n",
        "with open(results_dir+'tabular_qd.pkl', 'rb') as fd:\n",
        "    ai_d = pickle.load(fd)\n",
        "\n",
        "with open(results_dir+'tabular_qr.pkl', 'rb') as fr:\n",
        "    ai_r = pickle.load(fr)"
      ],
      "metadata": {
        "id": "7lv4ZIBkeLW3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42327c69-2475-42a7-e121-c6dcd6e5b265"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/med-deadend/lifegate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q_table = np.zeros((10, 10, 5))\n",
        "q_d = np.zeros_like(q_table)\n",
        "q_r = np.zeros_like(q_table)\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    for j in range(10):\n",
        "        for a in range(5):\n",
        "            key = tuple([j, i, a])\n",
        "            try:\n",
        "                q_table[i,j,a] = ai.q[key]\n",
        "                q_d[i,j,a] = ai_d.q[key]\n",
        "                q_r[i,j,a] = ai_r.q[key]\n",
        "            except:\n",
        "                pass"
      ],
      "metadata": {
        "id": "Rk0Z42sNebl4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "import random"
      ],
      "metadata": {
        "id": "4uTTjsWNfK21"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from lifegate import LifeGate"
      ],
      "metadata": {
        "id": "WZDw5-YMfMSM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce918b61-018d-43ed-96cf-2e14a8520180"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pygame 2.5.2 (SDL 2.28.2, Python 3.10.12)\n",
            "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params = yaml.safe_load(open('config.yaml', 'r'))"
      ],
      "metadata": {
        "id": "pzii8SOefSCm"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(seed=params['random_seed'])\n",
        "random.seed(params['random_seed'])\n",
        "random_state = np.random.RandomState(params['random_seed'])"
      ],
      "metadata": {
        "id": "ircWaFyzfVZr"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = LifeGate(max_steps=params['episode_max_len'], state_mode='tabular',\n",
        "                        rendering=True, image_saving=False, render_dir=None, rng=random_state, death_drag = 0.1)"
      ],
      "metadata": {
        "id": "XUoJuLN0fabn"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env_30 = LifeGate(max_steps=30, state_mode='tabular',\n",
        "                        rendering=True, image_saving=False, render_dir=None, rng=random_state, death_drag = 0.1)"
      ],
      "metadata": {
        "id": "7wG_zU6SM3xY"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KZp-8-f7far2"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import Shaping"
      ],
      "metadata": {
        "id": "hS65UmL5Yu_K"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from Shaping import *"
      ],
      "metadata": {
        "id": "FwGOFhh0ZeGx"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Shaping\n",
        "\n",
        "from choose_actions import action_probs_top_n_epsilon\n",
        "from shaping_features import *\n",
        "from gen_policies import *\n",
        "from IS import *\n",
        "from subset_policies import *\n",
        "from v_pi_e import *\n",
        "from optimization import *\n",
        "from neural_net import *\n",
        "from prep_variance import *\n",
        "from SCOPE_variance import SCOPE_variance"
      ],
      "metadata": {
        "id": "NYtD9mJOadhF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6b186f3-8cd0-4dc0-e57a-d511845b6eb2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Shaping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating policies"
      ],
      "metadata": {
        "id": "0fwQz6Zfke5i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## interm updates"
      ],
      "metadata": {
        "id": "d4uOoMlDEv-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def experiment_actions(nb_episodes, env, action_probs):\n",
        "    \"\"\"\n",
        "    Run the experiment for a specified number of episodes.\n",
        "\n",
        "    Parameters:\n",
        "    - nb_episodes: Number of episodes\n",
        "    - env: Experiment environment\n",
        "    - action_probs: Action probabilities\n",
        "\n",
        "    Returns:\n",
        "    - policies: List of policies (pi_b or pi_e)\n",
        "    \"\"\"\n",
        "    # Define the dtype for the structured array\n",
        "    dtype = [\n",
        "        ('state_last', np.float64, (2,)),\n",
        "        ('action', np.int64),\n",
        "        ('reward', np.float64),\n",
        "        ('state', np.float64, (2,)),\n",
        "        ('timestep', np.int64),\n",
        "        ('psi', np.float64)\n",
        "    ]\n",
        "\n",
        "    policies = []\n",
        "    for i in range(nb_episodes):\n",
        "        trajectory = np.empty(0, dtype=dtype)\n",
        "        s = env.reset()\n",
        "        env.render()\n",
        "        term = False\n",
        "        timestep = 0\n",
        "        while not term:\n",
        "            state_last = s\n",
        "            print(s)\n",
        "            action = choose_action(tuple(s), action_probs)\n",
        "            s, r, term, _ = env.step(action)\n",
        "\n",
        "            psi = smallest_distance_to_deadend(state_last, env)\n",
        "            data_point = np.array([(state_last, action, r, s, timestep, psi)], dtype=dtype)\n",
        "            trajectory = np.append(trajectory, data_point)\n",
        "            timestep += 1\n",
        "\n",
        "        policies.append(trajectory)\n",
        "\n",
        "    with open('policies.pkl', 'wb') as f:\n",
        "        pickle.dump(policies, f)\n",
        "\n",
        "    return policies"
      ],
      "metadata": {
        "id": "Xh2UezkqHisR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b_good = np.zeros((10, 10, 5))\n",
        "\n",
        "P_pi_b_good[2,9,3] = 1\n",
        "P_pi_b_good[1,9,3] = 1\n",
        "P_pi_b_good[0,9,1] = 1\n",
        "P_pi_b_good[0,8,1] = 1\n",
        "P_pi_b_good[0,7,1] = 1\n",
        "P_pi_b_good[0,6,1] = 1\n",
        "P_pi_b_good[0,5,1] = 1\n",
        "P_pi_b_good[0,4,4] = 1\n",
        "P_pi_b_good[1,4,4] = 1\n",
        "P_pi_b_good[2,4,4] = 1\n",
        "P_pi_b_good[3,4,4] = 1\n",
        "P_pi_b_good[4,4,4] = 1\n",
        "P_pi_b_good[5,4,1] = 1\n",
        "P_pi_b_good[5,5,1] = 1\n",
        "P_pi_b_good[5,4,1] = 1\n",
        "P_pi_b_good[5,3,1] = 1\n",
        "P_pi_b_good[5,2,1] = 1\n",
        "P_pi_b_good[5,1,1] = 1"
      ],
      "metadata": {
        "id": "PYLauaUbIq6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b_good_stoch = np.zeros((10, 10, 5))\n",
        "\n",
        "P_pi_b_good_stoch[2,9,3] = 0.5\n",
        "P_pi_b_good_stoch[2,9,1] = 0.5\n",
        "\n",
        "P_pi_b_good_stoch[2,8,3] = 0.5\n",
        "P_pi_b_good_stoch[2,8,1] = 0.5\n",
        "\n",
        "P_pi_b_good_stoch[2,7,3] = 0.5\n",
        "P_pi_b_good_stoch[2,7,1] = 0.5\n",
        "\n",
        "P_pi_b_good_stoch[1,9,3] = 0.5\n",
        "P_pi_b_good_stoch[1,9,1] = 0.5\n",
        "\n",
        "P_pi_b_good_stoch[1,8,3] = 0.5\n",
        "P_pi_b_good_stoch[1,8,1] = 0.5\n",
        "\n",
        "P_pi_b_good_stoch[1,7,3] = 0.5\n",
        "P_pi_b_good_stoch[1,7,1] = 0.5\n",
        "\n",
        "P_pi_b_good_stoch[2,6,3] = 1\n",
        "P_pi_b_good_stoch[1,6,3] = 1\n",
        "P_pi_b_good_stoch[1,5,3] = 1\n",
        "\n",
        "\n",
        "P_pi_b_good_stoch[0,9,1] = 1\n",
        "P_pi_b_good_stoch[0,8,1] = 1\n",
        "P_pi_b_good_stoch[0,7,1] = 1\n",
        "P_pi_b_good_stoch[0,6,1] = 1\n",
        "P_pi_b_good_stoch[0,5,1] = 1\n",
        "\n",
        "P_pi_b_good_stoch[0,4,1] = 0.5\n",
        "P_pi_b_good_stoch[0,4,4] = 0.5\n",
        "P_pi_b_good_stoch[0,4,1] = 0.5\n",
        "P_pi_b_good_stoch[0,4,4] = 0.5\n",
        "P_pi_b_good_stoch[0,3,1] = 0.5\n",
        "P_pi_b_good_stoch[0,3,4] = 0.5\n",
        "P_pi_b_good_stoch[0,2,1] = 0.5\n",
        "P_pi_b_good_stoch[0,2,4] = 0.5\n",
        "\n",
        "P_pi_b_good_stoch[1,4,1] = 0.5\n",
        "P_pi_b_good_stoch[1,4,4] = 0.5\n",
        "P_pi_b_good_stoch[1,4,1] = 0.5\n",
        "P_pi_b_good_stoch[1,4,4] = 0.5\n",
        "P_pi_b_good_stoch[1,3,1] = 0.5\n",
        "P_pi_b_good_stoch[1,3,4] = 0.5\n",
        "P_pi_b_good_stoch[1,2,1] = 0.5\n",
        "P_pi_b_good_stoch[1,2,4] = 0.5\n",
        "\n",
        "P_pi_b_good_stoch[2,4,1] = 0.5\n",
        "P_pi_b_good_stoch[2,4,4] = 0.5\n",
        "P_pi_b_good_stoch[2,4,1] = 0.5\n",
        "P_pi_b_good_stoch[2,4,4] = 0.5\n",
        "P_pi_b_good_stoch[2,3,1] = 0.5\n",
        "P_pi_b_good_stoch[2,3,4] = 0.5\n",
        "P_pi_b_good_stoch[2,2,1] = 0.5\n",
        "P_pi_b_good_stoch[2,2,4] = 0.5\n",
        "\n",
        "P_pi_b_good_stoch[3,4,1] = 0.5\n",
        "P_pi_b_good_stoch[3,4,4] = 0.5\n",
        "P_pi_b_good_stoch[3,4,1] = 0.5\n",
        "P_pi_b_good_stoch[3,4,4] = 0.5\n",
        "P_pi_b_good_stoch[3,3,1] = 0.5\n",
        "P_pi_b_good_stoch[3,3,4] = 0.5\n",
        "P_pi_b_good_stoch[3,2,1] = 0.5\n",
        "P_pi_b_good_stoch[3,2,4] = 0.5\n",
        "\n",
        "P_pi_b_good_stoch[4,4,1] = 0.5\n",
        "P_pi_b_good_stoch[4,4,4] = 0.5\n",
        "P_pi_b_good_stoch[4,4,1] = 0.5\n",
        "P_pi_b_good_stoch[4,4,4] = 0.5\n",
        "P_pi_b_good_stoch[4,3,1] = 0.5\n",
        "P_pi_b_good_stoch[4,3,4] = 0.5\n",
        "P_pi_b_good_stoch[4,2,1] = 0.5\n",
        "P_pi_b_good_stoch[4,2,4] = 0.5\n",
        "\n",
        "P_pi_b_good_stoch[0,1,4] = 1\n",
        "P_pi_b_good_stoch[1,1,4] = 1\n",
        "P_pi_b_good_stoch[2,1,4] = 1\n",
        "P_pi_b_good_stoch[3,1,4] = 1\n",
        "P_pi_b_good_stoch[4,1,4] = 1\n",
        "\n",
        "P_pi_b_good_stoch[5,4,1] = 1\n",
        "P_pi_b_good_stoch[5,3,1] = 1\n",
        "P_pi_b_good_stoch[5,2,1] = 1\n",
        "P_pi_b_good_stoch[5,1,1] = 1\n",
        "\n"
      ],
      "metadata": {
        "id": "t5GNtT3tPttg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b_bad = np.zeros((10, 10, 5))\n",
        "\n",
        "P_pi_b_bad[2,9,4] = 1\n",
        "\n",
        "P_pi_b_bad[3,9,1] = 1\n",
        "P_pi_b_bad[3,8,1] = 1\n",
        "P_pi_b_bad[3,7,1] = 1\n",
        "P_pi_b_bad[3,6,4] = 1\n",
        "\n",
        "P_pi_b_bad[4,6,2] = 1\n",
        "P_pi_b_bad[4,7,2] = 1\n",
        "P_pi_b_bad[4,8,2] = 1\n",
        "P_pi_b_bad[4,9,4] = 1\n",
        "\n",
        "P_pi_b_bad[5,9,1] = 1\n",
        "P_pi_b_bad[5,8,1] = 1\n",
        "P_pi_b_bad[5,7,1] = 1\n",
        "P_pi_b_bad[5,6,4] = 1\n",
        "\n",
        "P_pi_b_bad[6,6,4] = 1\n",
        "P_pi_b_bad[7,6,4] = 1\n",
        "P_pi_b_bad[8,6,4] = 1\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kuKtHy7UgHwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env.main_deaths"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1B0ogRtNlRu6",
        "outputId": "01841628-6c3d-4127-e489-96b0ebdb6cb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[9, 0],\n",
              " [9, 1],\n",
              " [9, 2],\n",
              " [9, 3],\n",
              " [9, 4],\n",
              " [9, 5],\n",
              " [9, 6],\n",
              " [9, 7],\n",
              " [9, 8],\n",
              " [9, 9],\n",
              " [8, 0]]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gen Policies"
      ],
      "metadata": {
        "id": "RBlY1w9aJppv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b = action_probs_top_n_epsilon(q_table, 1, 0.4)\n",
        "pi_b = experiment_actions(1000, env, P_pi_b)\n",
        "P_pi_e = action_probs_top_n_epsilon(q_table, 2, 0.05)\n",
        "pi_e = experiment_actions(1000, env, P_pi_e)"
      ],
      "metadata": {
        "id": "wW1SGejBZZlb"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b = action_probs_top_n_epsilon(q_table, 1, 0.4)\n",
        "pi_b = experiment_actions(1000, env_30, P_pi_b)\n",
        "\n",
        "P_pi_e = action_probs_top_n_epsilon(q_table, 2, 0.05)\n",
        "pi_e = experiment_actions(1000, env_30, P_pi_e)"
      ],
      "metadata": {
        "id": "1KqavLn-NERh"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prep"
      ],
      "metadata": {
        "id": "03SCZEAMnGeY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b = action_probs_top_n_epsilon(q_table, 1, 0.4)\n",
        "pi_b = experiment_actions(1000, env, P_pi_b)\n",
        "P_pi_e = action_probs_top_n_epsilon(q_table, 2, 0.05)\n",
        "pi_e = experiment_actions(1000, env, P_pi_e)"
      ],
      "metadata": {
        "id": "rgnL6zIcmmz6"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CustomizableFeatureNet(input_dim=2, hidden_dims=[16, 32], output_dim=1, dtype = torch.float64)"
      ],
      "metadata": {
        "id": "2Xqh735Bmm0D"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing = SCOPE_variance(model, 0.9, 10000, pi_b, P_pi_b, P_pi_e, dtype = torch.float64)"
      ],
      "metadata": {
        "id": "j9pQwTQtmm0D"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IS_tensor, padded_state_tensors, padded_weight_diff_tensors, gamma_weights_last_tensor, states_first_tensor, states_last_tensor, weight_first_tensor = testing.prepare()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef77d54f-a678-4a03-c722-44c5eb9b2500",
        "id": "Lezerfi0mm0D"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/Shaping/SCOPE_variance.py:92: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  padded_weight_diff_tensors = torch.tensor(padded_weights_difference, dtype = self.dtype)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1000 = train_var(model, 100, 0.001, padded_state_tensors, states_first_tensor, states_last_tensor, testing)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ce9e15f-246d-44cc-e9e2-438dedc944f5",
        "id": "FwOFIQCbmm0D"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Var loss:  tensor(0.0998, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.24141247356427334\n",
            "E_s_wdiff_all_sq: 0.14142863628335298\n",
            "E_IS_SCOPE: -0.0017230963821165332\n",
            "E_IS_E_SCOPE: -0.0016126965713371732\n",
            "Total Loss: 0.09976416278242806\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "Var loss:  tensor(0.0848, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.2316856550412188\n",
            "E_s_wdiff_all_sq: 0.14670070607329533\n",
            "E_IS_SCOPE: -0.0016323729192394868\n",
            "E_IS_E_SCOPE: -0.0015294829381487425\n",
            "Total Loss: 0.08478029412880841\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "Var loss:  tensor(0.0715, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.22324671679199845\n",
            "E_s_wdiff_all_sq: 0.1515315713222341\n",
            "E_IS_SCOPE: -0.001544206371644443\n",
            "E_IS_E_SCOPE: -0.0014486263603351954\n",
            "Total Loss: 0.0715251105702123\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "Var loss:  tensor(0.0597, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.21649511167249902\n",
            "E_s_wdiff_all_sq: 0.1565818909786442\n",
            "E_IS_SCOPE: -0.0014578661037718795\n",
            "E_IS_E_SCOPE: -0.0013694885850670606\n",
            "Total Loss: 0.05973759077951163\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "Var loss:  tensor(0.0493, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.21193045225169221\n",
            "E_s_wdiff_all_sq: 0.16242399144899658\n",
            "E_IS_SCOPE: -0.0013727002222011428\n",
            "E_IS_E_SCOPE: -0.0012913962516446595\n",
            "Total Loss: 0.049344977984649124\n",
            "----------------------------------------\n",
            "Epoch 6\n",
            "Var loss:  tensor(0.0404, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.20942787307780664\n",
            "E_s_wdiff_all_sq: 0.16887778667285044\n",
            "E_IS_SCOPE: -0.001288806990774453\n",
            "E_IS_E_SCOPE: -0.0012143571269486986\n",
            "Total Loss: 0.04040231180037113\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "Var loss:  tensor(0.0329, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.20857770407178022\n",
            "E_s_wdiff_all_sq: 0.17557975477899623\n",
            "E_IS_SCOPE: -0.001206381459413283\n",
            "E_IS_E_SCOPE: -0.0011385638505934362\n",
            "Total Loss: 0.03286343919821075\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "Var loss:  tensor(0.0268, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.20890779417504837\n",
            "E_s_wdiff_all_sq: 0.1820126734451352\n",
            "E_IS_SCOPE: -0.0011284066925799753\n",
            "E_IS_E_SCOPE: -0.0010667802345805685\n",
            "Total Loss: 0.026772992936980794\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "Var loss:  tensor(0.0218, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.21024904112909004\n",
            "E_s_wdiff_all_sq: 0.18838408692920094\n",
            "E_IS_SCOPE: -0.0010534253369909705\n",
            "E_IS_E_SCOPE: -0.0009978210170384354\n",
            "Total Loss: 0.02175487068305046\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "Var loss:  tensor(0.0178, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.21211040108414964\n",
            "E_s_wdiff_all_sq: 0.19423116564985557\n",
            "E_IS_SCOPE: -0.0009832254001383364\n",
            "E_IS_E_SCOPE: -0.0009333614126033999\n",
            "Total Loss: 0.017780632582290623\n",
            "----------------------------------------\n",
            "Epoch 11\n",
            "Var loss:  tensor(0.0147, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.21398564802381279\n",
            "E_s_wdiff_all_sq: 0.19918901611590664\n",
            "E_IS_SCOPE: -0.0009184622879752105\n",
            "E_IS_E_SCOPE: -0.0008740819071255257\n",
            "Total Loss: 0.014708996269273217\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "Var loss:  tensor(0.0124, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.21633702456087017\n",
            "E_s_wdiff_all_sq: 0.20381667595541836\n",
            "E_IS_SCOPE: -0.0008573841404969549\n",
            "E_IS_E_SCOPE: -0.0008181815092564727\n",
            "Total Loss: 0.012443068466037294\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "Var loss:  tensor(0.0109, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.21952777656981706\n",
            "E_s_wdiff_all_sq: 0.20859747350131477\n",
            "E_IS_SCOPE: -0.0007985532043099262\n",
            "E_IS_E_SCOPE: -0.0007642132211143019\n",
            "Total Loss: 0.010862748225177493\n",
            "----------------------------------------\n",
            "Epoch 14\n",
            "Var loss:  tensor(0.0099, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.22298221960510037\n",
            "E_s_wdiff_all_sq: 0.21304906779538701\n",
            "E_IS_SCOPE: -0.0007433067881523638\n",
            "E_IS_E_SCOPE: -0.0007134306734131851\n",
            "Total Loss: 0.00987452470330144\n",
            "----------------------------------------\n",
            "Epoch 15\n",
            "Var loss:  tensor(0.0093, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.22622469053180666\n",
            "E_s_wdiff_all_sq: 0.21683116157761448\n",
            "E_IS_SCOPE: -0.000691882277645548\n",
            "E_IS_E_SCOPE: -0.0006660864195343156\n",
            "Total Loss: 0.009343062361036159\n",
            "----------------------------------------\n",
            "Epoch 16\n",
            "Var loss:  tensor(0.0092, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.22846493211205335\n",
            "E_s_wdiff_all_sq: 0.21927106517757158\n",
            "E_IS_SCOPE: -0.0006459074838033535\n",
            "E_IS_E_SCOPE: -0.0006237830120650928\n",
            "Total Loss: 0.009150743114071658\n",
            "----------------------------------------\n",
            "Epoch 17\n",
            "Var loss:  tensor(0.0092, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.2295464661510757\n",
            "E_s_wdiff_all_sq: 0.22032802261116236\n",
            "E_IS_SCOPE: -0.0006052260049506224\n",
            "E_IS_E_SCOPE: -0.0005863471792167534\n",
            "Total Loss: 0.009181811011512053\n",
            "----------------------------------------\n",
            "Epoch 18\n",
            "Var loss:  tensor(0.0093, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.22924119122048073\n",
            "E_s_wdiff_all_sq: 0.21987058832087125\n",
            "E_IS_SCOPE: -0.0005699793198315967\n",
            "E_IS_E_SCOPE: -0.0005539139802066157\n",
            "Total Loss: 0.009339597343425932\n",
            "----------------------------------------\n",
            "Epoch 19\n",
            "Var loss:  tensor(0.0095, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.22780648182175997\n",
            "E_s_wdiff_all_sq: 0.21823085631642025\n",
            "E_IS_SCOPE: -0.0005392203956952773\n",
            "E_IS_E_SCOPE: -0.0005255510259564686\n",
            "Total Loss: 0.00954941188892855\n",
            "----------------------------------------\n",
            "Epoch 20\n",
            "Var loss:  tensor(0.0098, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.22593363738849975\n",
            "E_s_wdiff_all_sq: 0.21615951365544755\n",
            "E_IS_SCOPE: -0.000511096770198247\n",
            "E_IS_E_SCOPE: -0.0004993951785331163\n",
            "Total Loss: 0.00975184567278839\n",
            "----------------------------------------\n",
            "Epoch 21\n",
            "Var loss:  tensor(0.0099, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.2232491886491363\n",
            "E_s_wdiff_all_sq: 0.2133487008924154\n",
            "E_IS_SCOPE: -0.0004866590546683225\n",
            "E_IS_E_SCOPE: -0.0004764959956243449\n",
            "Total Loss: 0.00988128676169936\n",
            "----------------------------------------\n",
            "Epoch 22\n",
            "Var loss:  tensor(0.0099, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.2194337569292942\n",
            "E_s_wdiff_all_sq: 0.2095140702275116\n",
            "E_IS_SCOPE: -0.0004667053171186954\n",
            "E_IS_E_SCOPE: -0.0004576649708100834\n",
            "Total Loss: 0.009902731132231835\n",
            "----------------------------------------\n",
            "Epoch 23\n",
            "Var loss:  tensor(0.0098, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.21480380560952836\n",
            "E_s_wdiff_all_sq: 0.2049683850754149\n",
            "E_IS_SCOPE: -0.000450361417957674\n",
            "E_IS_E_SCOPE: -0.00044207589414566175\n",
            "Total Loss: 0.00981997460955586\n",
            "----------------------------------------\n",
            "Epoch 24\n",
            "Var loss:  tensor(0.0096, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.2095502437415395\n",
            "E_s_wdiff_all_sq: 0.19991368777746668\n",
            "E_IS_SCOPE: -0.0004373019066969806\n",
            "E_IS_E_SCOPE: -0.00042942271736824884\n",
            "Total Loss: 0.009621922708481778\n",
            "----------------------------------------\n",
            "Epoch 25\n",
            "Var loss:  tensor(0.0093, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.2035603522249491\n",
            "E_s_wdiff_all_sq: 0.19423101833877868\n",
            "E_IS_SCOPE: -0.0004278438248692549\n",
            "E_IS_E_SCOPE: -0.0004200502879580155\n",
            "Total Loss: 0.00931487193541436\n",
            "----------------------------------------\n",
            "Epoch 26\n",
            "Var loss:  tensor(0.0089, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.19685345369915608\n",
            "E_s_wdiff_all_sq: 0.18792058015843852\n",
            "E_IS_SCOPE: -0.0004221296899338677\n",
            "E_IS_E_SCOPE: -0.0004141369160245881\n",
            "Total Loss: 0.008918013115965434\n",
            "----------------------------------------\n",
            "Epoch 27\n",
            "Var loss:  tensor(0.0085, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.18958478262498424\n",
            "E_s_wdiff_all_sq: 0.18110930252903876\n",
            "E_IS_SCOPE: -0.0004197296576097447\n",
            "E_IS_E_SCOPE: -0.00041128492410891503\n",
            "Total Loss: 0.008459715752010238\n",
            "----------------------------------------\n",
            "Epoch 28\n",
            "Var loss:  tensor(0.0080, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.18189253193957555\n",
            "E_s_wdiff_all_sq: 0.17391894152944798\n",
            "E_IS_SCOPE: -0.0004203941730730536\n",
            "E_IS_E_SCOPE: -0.0004112656034387069\n",
            "Total Loss: 0.007956458393925309\n",
            "----------------------------------------\n",
            "Epoch 29\n",
            "Var loss:  tensor(0.0074, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.1742354405495446\n",
            "E_s_wdiff_all_sq: 0.16677777334878985\n",
            "E_IS_SCOPE: -0.0004227258999226896\n",
            "E_IS_E_SCOPE: -0.000412739644020968\n",
            "Total Loss: 0.007438819812017744\n",
            "----------------------------------------\n",
            "Epoch 30\n",
            "Var loss:  tensor(0.0069, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.16681301272518248\n",
            "E_s_wdiff_all_sq: 0.1598613499715189\n",
            "E_IS_SCOPE: -0.0004260238131956182\n",
            "E_IS_E_SCOPE: -0.000415040519871986\n",
            "Total Loss: 0.006930821290082739\n",
            "----------------------------------------\n",
            "Epoch 31\n",
            "Var loss:  tensor(0.0065, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.15935171273416418\n",
            "E_s_wdiff_all_sq: 0.15287731853023614\n",
            "E_IS_SCOPE: -0.00043120472393833606\n",
            "E_IS_E_SCOPE: -0.00041911182463854723\n",
            "Total Loss: 0.006451333528394915\n",
            "----------------------------------------\n",
            "Epoch 32\n",
            "Var loss:  tensor(0.0060, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.15186664636400857\n",
            "E_s_wdiff_all_sq: 0.1458270449140871\n",
            "E_IS_SCOPE: -0.00043799531031679494\n",
            "E_IS_E_SCOPE: -0.00042472823387886086\n",
            "Total Loss: 0.00601419242011203\n",
            "----------------------------------------\n",
            "Epoch 33\n",
            "Var loss:  tensor(0.0056, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.1445347325300944\n",
            "E_s_wdiff_all_sq: 0.1388732313850292\n",
            "E_IS_SCOPE: -0.0004456880966584318\n",
            "E_IS_E_SCOPE: -0.0004312129424998313\n",
            "Total Loss: 0.005633675959814455\n",
            "----------------------------------------\n",
            "Epoch 34\n",
            "Var loss:  tensor(0.0053, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.1377115384358592\n",
            "E_s_wdiff_all_sq: 0.13236479513422514\n",
            "E_IS_SCOPE: -0.00045259546607098777\n",
            "E_IS_E_SCOPE: -0.0004369071535300866\n",
            "Total Loss: 0.005316491799618711\n",
            "----------------------------------------\n",
            "Epoch 35\n",
            "Var loss:  tensor(0.0051, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.131175877227604\n",
            "E_s_wdiff_all_sq: 0.12608780454149218\n",
            "E_IS_SCOPE: -0.00045925406041252777\n",
            "E_IS_E_SCOPE: -0.0004423804052107891\n",
            "Total Loss: 0.005055450498774761\n",
            "----------------------------------------\n",
            "Epoch 36\n",
            "Var loss:  tensor(0.0049, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.12496423427044756\n",
            "E_s_wdiff_all_sq: 0.12007933680239422\n",
            "E_IS_SCOPE: -0.0004654042128721106\n",
            "E_IS_E_SCOPE: -0.0004473933029926459\n",
            "Total Loss: 0.004850000771360857\n",
            "----------------------------------------\n",
            "Epoch 37\n",
            "Var loss:  tensor(0.0047, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.11910941212645018\n",
            "E_s_wdiff_all_sq: 0.11437605214545658\n",
            "E_IS_SCOPE: -0.00047078809881054723\n",
            "E_IS_E_SCOPE: -0.00045170785726882426\n",
            "Total Loss: 0.0046963246209765774\n",
            "----------------------------------------\n",
            "Epoch 38\n",
            "Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.11341889661938889\n",
            "E_s_wdiff_all_sq: 0.1087947685761967\n",
            "E_IS_SCOPE: -0.0004762381883195253\n",
            "E_IS_E_SCOPE: -0.0004561765475034546\n",
            "Total Loss: 0.00458512988462649\n",
            "----------------------------------------\n",
            "Epoch 39\n",
            "Var loss:  tensor(0.0045, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.1079037131645297\n",
            "E_s_wdiff_all_sq: 0.10335420941936953\n",
            "E_IS_SCOPE: -0.0004814772095233045\n",
            "E_IS_E_SCOPE: -0.00046054686660967046\n",
            "Total Loss: 0.004508768182399342\n",
            "----------------------------------------\n",
            "Epoch 40\n",
            "Var loss:  tensor(0.0045, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.10293383840185795\n",
            "E_s_wdiff_all_sq: 0.09843719565428999\n",
            "E_IS_SCOPE: -0.00048489417202218446\n",
            "E_IS_E_SCOPE: -0.0004632144168886827\n",
            "Total Loss: 0.004454408360367382\n",
            "----------------------------------------\n",
            "Epoch 41\n",
            "Var loss:  tensor(0.0044, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.09853037433236012\n",
            "E_s_wdiff_all_sq: 0.09407273855627735\n",
            "E_IS_SCOPE: -0.00048636701963750736\n",
            "E_IS_E_SCOPE: -0.0004640650555803339\n",
            "Total Loss: 0.004414156971034852\n",
            "----------------------------------------\n",
            "Epoch 42\n",
            "Var loss:  tensor(0.0044, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.09465569142241512\n",
            "E_s_wdiff_all_sq: 0.09023238058257216\n",
            "E_IS_SCOPE: -0.00048592625506935824\n",
            "E_IS_E_SCOPE: -0.00046312965284017347\n",
            "Total Loss: 0.004378842758451018\n",
            "----------------------------------------\n",
            "Epoch 43\n",
            "Var loss:  tensor(0.0043, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.09130524106929172\n",
            "E_s_wdiff_all_sq: 0.08691948480542176\n",
            "E_IS_SCOPE: -0.00048336479701005503\n",
            "E_IS_E_SCOPE: -0.0004602034605541347\n",
            "Total Loss: 0.004340558714024556\n",
            "----------------------------------------\n",
            "Epoch 44\n",
            "Var loss:  tensor(0.0043, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.08824546263474006\n",
            "E_s_wdiff_all_sq: 0.083904779153834\n",
            "E_IS_SCOPE: -0.00047963452456339413\n",
            "E_IS_E_SCOPE: -0.00045624012168074877\n",
            "Total Loss: 0.004295019798207206\n",
            "----------------------------------------\n",
            "Epoch 45\n",
            "Var loss:  tensor(0.0042, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.08552304471735048\n",
            "E_s_wdiff_all_sq: 0.0812365822925214\n",
            "E_IS_SCOPE: -0.00047465291681332344\n",
            "E_IS_E_SCOPE: -0.0004511512107862903\n",
            "Total Loss: 0.004240584135841441\n",
            "----------------------------------------\n",
            "Epoch 46\n",
            "Var loss:  tensor(0.0042, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.08295581467053503\n",
            "E_s_wdiff_all_sq: 0.07873690435294436\n",
            "E_IS_SCOPE: -0.0004692008265683277\n",
            "E_IS_E_SCOPE: -0.00044570421141010546\n",
            "Total Loss: 0.0041730422103406495\n",
            "----------------------------------------\n",
            "Epoch 47\n",
            "Var loss:  tensor(0.0041, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.08051819538382783\n",
            "E_s_wdiff_all_sq: 0.07637640782459948\n",
            "E_IS_SCOPE: -0.0004635683162882579\n",
            "E_IS_E_SCOPE: -0.00044016002268724405\n",
            "Total Loss: 0.0040960960950927605\n",
            "----------------------------------------\n",
            "Epoch 48\n",
            "Var loss:  tensor(0.0040, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.07845313274557682\n",
            "E_s_wdiff_all_sq: 0.0744002572606218\n",
            "E_IS_SCOPE: -0.00045671796482165626\n",
            "E_IS_E_SCOPE: -0.0004335003188268255\n",
            "Total Loss: 0.004007565316031789\n",
            "----------------------------------------\n",
            "Epoch 49\n",
            "Var loss:  tensor(0.0039, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.07668429935726674\n",
            "E_s_wdiff_all_sq: 0.07273140031297283\n",
            "E_IS_SCOPE: -0.00044884014256762724\n",
            "E_IS_E_SCOPE: -0.00042590577108563205\n",
            "Total Loss: 0.003908155424396348\n",
            "----------------------------------------\n",
            "Epoch 50\n",
            "Var loss:  tensor(0.0038, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.0749673694516731\n",
            "E_s_wdiff_all_sq: 0.07111736797813971\n",
            "E_IS_SCOPE: -0.0004409525528810356\n",
            "E_IS_E_SCOPE: -0.00041838001321306117\n",
            "Total Loss: 0.0038059815172638706\n",
            "----------------------------------------\n",
            "Epoch 51\n",
            "Var loss:  tensor(0.0037, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.07375367545249764\n",
            "E_s_wdiff_all_sq: 0.07001761123171249\n",
            "E_IS_SCOPE: -0.0004306464846704027\n",
            "E_IS_E_SCOPE: -0.00040850123999575425\n",
            "Total Loss: 0.0036928988545022884\n",
            "----------------------------------------\n",
            "Epoch 52\n",
            "Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.0726706214343269\n",
            "E_s_wdiff_all_sq: 0.06904702335471359\n",
            "E_IS_SCOPE: -0.00041993073200206703\n",
            "E_IS_E_SCOPE: -0.0003982644634877912\n",
            "Total Loss: 0.0035813906656511907\n",
            "----------------------------------------\n",
            "Epoch 53\n",
            "Var loss:  tensor(0.0035, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.07156107866131907\n",
            "E_s_wdiff_all_sq: 0.06804503572636282\n",
            "E_IS_SCOPE: -0.00040983339926631865\n",
            "E_IS_E_SCOPE: -0.0003886848656855454\n",
            "Total Loss: 0.003474870990861134\n",
            "----------------------------------------\n",
            "Epoch 54\n",
            "Var loss:  tensor(0.0034, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.07053263345900038\n",
            "E_s_wdiff_all_sq: 0.06711912363349473\n",
            "E_IS_SCOPE: -0.0003997373682837343\n",
            "E_IS_E_SCOPE: -0.00037912926893673396\n",
            "Total Loss: 0.0033734187498780793\n",
            "----------------------------------------\n",
            "Epoch 55\n",
            "Var loss:  tensor(0.0033, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.06960634325933497\n",
            "E_s_wdiff_all_sq: 0.06628670553989618\n",
            "E_IS_SCOPE: -0.0003897108194846398\n",
            "E_IS_E_SCOPE: -0.00036963503503035405\n",
            "Total Loss: 0.003280611273596648\n",
            "----------------------------------------\n",
            "Epoch 56\n",
            "Var loss:  tensor(0.0032, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.06871483201414244\n",
            "E_s_wdiff_all_sq: 0.06548307855167187\n",
            "E_IS_SCOPE: -0.00037994288805592234\n",
            "E_IS_E_SCOPE: -0.00036040007731476964\n",
            "Total Loss: 0.003193792964054698\n",
            "----------------------------------------\n",
            "Epoch 57\n",
            "Var loss:  tensor(0.0031, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.06777479747980951\n",
            "E_s_wdiff_all_sq: 0.06462529685924989\n",
            "E_IS_SCOPE: -0.0003708862543217057\n",
            "E_IS_E_SCOPE: -0.00035186444565743713\n",
            "Total Loss: 0.0031125821262975167\n",
            "----------------------------------------\n",
            "Epoch 58\n",
            "Var loss:  tensor(0.0030, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.06680167477549023\n",
            "E_s_wdiff_all_sq: 0.06372629910746412\n",
            "E_IS_SCOPE: -0.0003623133654064911\n",
            "E_IS_E_SCOPE: -0.000343791788568659\n",
            "Total Loss: 0.0030394576374168786\n",
            "----------------------------------------\n",
            "Epoch 59\n",
            "Var loss:  tensor(0.0030, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.06592727816724707\n",
            "E_s_wdiff_all_sq: 0.06291865494462513\n",
            "E_IS_SCOPE: -0.00035360211208891406\n",
            "E_IS_E_SCOPE: -0.0003355448929780882\n",
            "Total Loss: 0.002973633907466716\n",
            "----------------------------------------\n",
            "Epoch 60\n",
            "Var loss:  tensor(0.0029, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.06510859863268145\n",
            "E_s_wdiff_all_sq: 0.062161337776324675\n",
            "E_IS_SCOPE: -0.00034489978374941505\n",
            "E_IS_E_SCOPE: -0.0003272648576067613\n",
            "Total Loss: 0.0029131161271379116\n",
            "----------------------------------------\n",
            "Epoch 61\n",
            "Var loss:  tensor(0.0029, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.0642900489958599\n",
            "E_s_wdiff_all_sq: 0.061399482284138766\n",
            "E_IS_SCOPE: -0.0003363782939836332\n",
            "E_IS_E_SCOPE: -0.0003191209899675172\n",
            "Total Loss: 0.002857177226755332\n",
            "----------------------------------------\n",
            "Epoch 62\n",
            "Var loss:  tensor(0.0028, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.0633998152033599\n",
            "E_s_wdiff_all_sq: 0.060561984937756115\n",
            "E_IS_SCOPE: -0.0003284274743802588\n",
            "E_IS_E_SCOPE: -0.00031149896167104765\n",
            "Total Loss: 0.0028050983632518026\n",
            "----------------------------------------\n",
            "Epoch 63\n",
            "Var loss:  tensor(0.0028, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.062376958957635883\n",
            "E_s_wdiff_all_sq: 0.059589619852664595\n",
            "E_IS_SCOPE: -0.0003212821242581527\n",
            "E_IS_E_SCOPE: -0.0003046309177550428\n",
            "Total Loss: 0.0027551618150315066\n",
            "----------------------------------------\n",
            "Epoch 64\n",
            "Var loss:  tensor(0.0027, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.06121635414412847\n",
            "E_s_wdiff_all_sq: 0.05847869230775607\n",
            "E_IS_SCOPE: -0.00031498601370355225\n",
            "E_IS_E_SCOPE: -0.0002985592335333944\n",
            "Total Loss: 0.0027059333990985188\n",
            "----------------------------------------\n",
            "Epoch 65\n",
            "Var loss:  tensor(0.0027, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.05991290926612974\n",
            "E_s_wdiff_all_sq: 0.05722444240515671\n",
            "E_IS_SCOPE: -0.00030956090021701314\n",
            "E_IS_E_SCOPE: -0.0002933059403256923\n",
            "Total Loss: 0.002657082064256827\n",
            "----------------------------------------\n",
            "Epoch 66\n",
            "Var loss:  tensor(0.0026, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.05842824672510399\n",
            "E_s_wdiff_all_sq: 0.05578891173796383\n",
            "E_IS_SCOPE: -0.00030541962833383095\n",
            "E_IS_E_SCOPE: -0.000289284938993973\n",
            "Total Loss: 0.002608190731526877\n",
            "----------------------------------------\n",
            "Epoch 67\n",
            "Var loss:  tensor(0.0026, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.05685476347316247\n",
            "E_s_wdiff_all_sq: 0.054265914564098516\n",
            "E_IS_SCOPE: -0.00030199124308407364\n",
            "E_IS_E_SCOPE: -0.00028592801176194105\n",
            "Total Loss: 0.00255784756948612\n",
            "----------------------------------------\n",
            "Epoch 68\n",
            "Var loss:  tensor(0.0025, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.055283377264845036\n",
            "E_s_wdiff_all_sq: 0.05274600081678584\n",
            "E_IS_SCOPE: -0.00029886898311409885\n",
            "E_IS_E_SCOPE: -0.0002828353694008256\n",
            "Total Loss: 0.002506434343699085\n",
            "----------------------------------------\n",
            "Epoch 69\n",
            "Var loss:  tensor(0.0025, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.05378603538949577\n",
            "E_s_wdiff_all_sq: 0.05130090465328009\n",
            "E_IS_SCOPE: -0.0002956756311590616\n",
            "E_IS_E_SCOPE: -0.0002796348112610803\n",
            "Total Loss: 0.002454174219486155\n",
            "----------------------------------------\n",
            "Epoch 70\n",
            "Var loss:  tensor(0.0024, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.0523284939776212\n",
            "E_s_wdiff_all_sq: 0.04989594960548566\n",
            "E_IS_SCOPE: -0.0002924984400751785\n",
            "E_IS_E_SCOPE: -0.00027641846157967255\n",
            "Total Loss: 0.002401509538210972\n",
            "----------------------------------------\n",
            "Epoch 71\n",
            "Var loss:  tensor(0.0023, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.05085095198869151\n",
            "E_s_wdiff_all_sq: 0.048470733921986836\n",
            "E_IS_SCOPE: -0.0002896001792697528\n",
            "E_IS_E_SCOPE: -0.00027345599596460726\n",
            "Total Loss: 0.0023490548231608205\n",
            "----------------------------------------\n",
            "Epoch 72\n",
            "Var loss:  tensor(0.0023, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.049290939249529445\n",
            "E_s_wdiff_all_sq: 0.046961312305510636\n",
            "E_IS_SCOPE: -0.0002872910722668553\n",
            "E_IS_E_SCOPE: -0.0002710630224321204\n",
            "Total Loss: 0.0022982959674157782\n",
            "----------------------------------------\n",
            "Epoch 73\n",
            "Var loss:  tensor(0.0022, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.047615341068391714\n",
            "E_s_wdiff_all_sq: 0.045334966043757724\n",
            "E_IS_SCOPE: -0.00028586266828571605\n",
            "E_IS_E_SCOPE: -0.00026953611051414223\n",
            "Total Loss: 0.002248847032157282\n",
            "----------------------------------------\n",
            "Epoch 74\n",
            "Var loss:  tensor(0.0022, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.04592102246114508\n",
            "E_s_wdiff_all_sq: 0.04368853598985454\n",
            "E_IS_SCOPE: -0.0002848024769142086\n",
            "E_IS_E_SCOPE: -0.00026836926763288056\n",
            "Total Loss: 0.0022007451757943206\n",
            "----------------------------------------\n",
            "Epoch 75\n",
            "Var loss:  tensor(0.0022, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.04432614986575635\n",
            "E_s_wdiff_all_sq: 0.04214064526872814\n",
            "E_IS_SCOPE: -0.0002830016851609429\n",
            "E_IS_E_SCOPE: -0.00026646186262726395\n",
            "Total Loss: 0.002153550075027287\n",
            "----------------------------------------\n",
            "Epoch 76\n",
            "Var loss:  tensor(0.0021, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.042873347091445906\n",
            "E_s_wdiff_all_sq: 0.04073323502626583\n",
            "E_IS_SCOPE: -0.0002802771155302685\n",
            "E_IS_E_SCOPE: -0.00026366780212604536\n",
            "Total Loss: 0.002108018561438066\n",
            "----------------------------------------\n",
            "Epoch 77\n",
            "Var loss:  tensor(0.0021, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.041523225147753785\n",
            "E_s_wdiff_all_sq: 0.039426488771079765\n",
            "E_IS_SCOPE: -0.00027693137897789286\n",
            "E_IS_E_SCOPE: -0.00026026441792888937\n",
            "Total Loss: 0.0020645275776424513\n",
            "----------------------------------------\n",
            "Epoch 78\n",
            "Var loss:  tensor(0.0020, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.04024202993953263\n",
            "E_s_wdiff_all_sq: 0.03818562681450427\n",
            "E_IS_SCOPE: -0.0002733937861327085\n",
            "E_IS_E_SCOPE: -0.00025667160217429294\n",
            "Total Loss: 0.002024083880177968\n",
            "----------------------------------------\n",
            "Epoch 79\n",
            "Var loss:  tensor(0.0020, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.03902909366836748\n",
            "E_s_wdiff_all_sq: 0.03701191590688505\n",
            "E_IS_SCOPE: -0.00026959041545896096\n",
            "E_IS_E_SCOPE: -0.0002528213049877895\n",
            "Total Loss: 0.001984764663606517\n",
            "----------------------------------------\n",
            "Epoch 80\n",
            "Var loss:  tensor(0.0019, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.0378103711532624\n",
            "E_s_wdiff_all_sq: 0.035829664945481524\n",
            "E_IS_SCOPE: -0.000266026947015214\n",
            "E_IS_E_SCOPE: -0.0002492067995259982\n",
            "Total Loss: 0.0019481910358688792\n",
            "----------------------------------------\n",
            "Epoch 81\n",
            "Var loss:  tensor(0.0019, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.03655330917836941\n",
            "E_s_wdiff_all_sq: 0.03460586814470176\n",
            "E_IS_SCOPE: -0.0002630470540343247\n",
            "E_IS_E_SCOPE: -0.000246188156581048\n",
            "Total Loss: 0.00191484836182753\n",
            "----------------------------------------\n",
            "Epoch 82\n",
            "Var loss:  tensor(0.0019, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.03518435769891247\n",
            "E_s_wdiff_all_sq: 0.033269692459622045\n",
            "E_IS_SCOPE: -0.0002612429796981623\n",
            "E_IS_E_SCOPE: -0.00024433919880755196\n",
            "Total Loss: 0.0018819828005756448\n",
            "----------------------------------------\n",
            "Epoch 83\n",
            "Var loss:  tensor(0.0019, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.03391736485006427\n",
            "E_s_wdiff_all_sq: 0.032033172963438585\n",
            "E_IS_SCOPE: -0.00025901382009117205\n",
            "E_IS_E_SCOPE: -0.00024208030242950284\n",
            "Total Loss: 0.0018514499743687851\n",
            "----------------------------------------\n",
            "Epoch 84\n",
            "Var loss:  tensor(0.0018, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.0327668136925091\n",
            "E_s_wdiff_all_sq: 0.030911949462634435\n",
            "E_IS_SCOPE: -0.0002561866803143079\n",
            "E_IS_E_SCOPE: -0.00023923774856725777\n",
            "Total Loss: 0.0018220914894469982\n",
            "----------------------------------------\n",
            "Epoch 85\n",
            "Var loss:  tensor(0.0018, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.031716961614201934\n",
            "E_s_wdiff_all_sq: 0.029891028213427446\n",
            "E_IS_SCOPE: -0.0002528386077984253\n",
            "E_IS_E_SCOPE: -0.0002358953387087267\n",
            "Total Loss: 0.0017931719856615243\n",
            "----------------------------------------\n",
            "Epoch 86\n",
            "Var loss:  tensor(0.0018, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.030760854584949475\n",
            "E_s_wdiff_all_sq: 0.02896389720365469\n",
            "E_IS_SCOPE: -0.00024908529715412386\n",
            "E_IS_E_SCOPE: -0.00023217282727881612\n",
            "Total Loss: 0.001764257564610603\n",
            "----------------------------------------\n",
            "Epoch 87\n",
            "Var loss:  tensor(0.0017, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.029855838065336888\n",
            "E_s_wdiff_all_sq: 0.02808747482086212\n",
            "E_IS_SCOPE: -0.00024518716363602233\n",
            "E_IS_E_SCOPE: -0.00022832717064631767\n",
            "Total Loss: 0.0017357683815617912\n",
            "----------------------------------------\n",
            "Epoch 88\n",
            "Var loss:  tensor(0.0017, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.02898894112928546\n",
            "E_s_wdiff_all_sq: 0.02724898566226211\n",
            "E_IS_SCOPE: -0.00024127147819645267\n",
            "E_IS_E_SCOPE: -0.00022448857492038334\n",
            "Total Loss: 0.0017075147835376482\n",
            "----------------------------------------\n",
            "Epoch 89\n",
            "Var loss:  tensor(0.0017, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.028134736523807602\n",
            "E_s_wdiff_all_sq: 0.02642320122626632\n",
            "E_IS_SCOPE: -0.0002375025035656533\n",
            "E_IS_E_SCOPE: -0.00022081852553849476\n",
            "Total Loss: 0.0016792924645533981\n",
            "----------------------------------------\n",
            "Epoch 90\n",
            "Var loss:  tensor(0.0017, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.027253066381788853\n",
            "E_s_wdiff_all_sq: 0.025569872941324803\n",
            "E_IS_SCOPE: -0.00023421911475058374\n",
            "E_IS_E_SCOPE: -0.00021765279272387825\n",
            "Total Loss: 0.0016511859194770703\n",
            "----------------------------------------\n",
            "Epoch 91\n",
            "Var loss:  tensor(0.0016, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.026423280362535172\n",
            "E_s_wdiff_all_sq: 0.024768363670667953\n",
            "E_IS_SCOPE: -0.00023075765046307923\n",
            "E_IS_E_SCOPE: -0.0002143286982664885\n",
            "Total Loss: 0.0016231839105404697\n",
            "----------------------------------------\n",
            "Epoch 92\n",
            "Var loss:  tensor(0.0016, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.025680230583556556\n",
            "E_s_wdiff_all_sq: 0.024052601215741178\n",
            "E_IS_SCOPE: -0.00022694246677384272\n",
            "E_IS_E_SCOPE: -0.00021065677238515536\n",
            "Total Loss: 0.001596183102104437\n",
            "----------------------------------------\n",
            "Epoch 93\n",
            "Var loss:  tensor(0.0016, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.02507529731031736\n",
            "E_s_wdiff_all_sq: 0.023474512685340464\n",
            "E_IS_SCOPE: -0.00022227938377270475\n",
            "E_IS_E_SCOPE: -0.00020615033767206733\n",
            "Total Loss: 0.0015696516558420526\n",
            "----------------------------------------\n",
            "Epoch 94\n",
            "Var loss:  tensor(0.0015, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.024547450640712565\n",
            "E_s_wdiff_all_sq: 0.022972233509695242\n",
            "E_IS_SCOPE: -0.0002173031176512196\n",
            "E_IS_E_SCOPE: -0.00020133489200449043\n",
            "Total Loss: 0.0015444058027902947\n",
            "----------------------------------------\n",
            "Epoch 95\n",
            "Var loss:  tensor(0.0015, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.02401668459409135\n",
            "E_s_wdiff_all_sq: 0.022466112952788598\n",
            "E_IS_SCOPE: -0.00021273873101471628\n",
            "E_IS_E_SCOPE: -0.00019693064613345693\n",
            "Total Loss: 0.001520080594606666\n",
            "----------------------------------------\n",
            "Epoch 96\n",
            "Var loss:  tensor(0.0015, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.023535839196641192\n",
            "E_s_wdiff_all_sq: 0.02200905956056488\n",
            "E_IS_SCOPE: -0.00020819755690397487\n",
            "E_IS_E_SCOPE: -0.00019254887290815178\n",
            "Total Loss: 0.0014966073911510981\n",
            "----------------------------------------\n",
            "Epoch 97\n",
            "Var loss:  tensor(0.0015, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.023089636127759775\n",
            "E_s_wdiff_all_sq: 0.021586034766205964\n",
            "E_IS_SCOPE: -0.0002037888094405747\n",
            "E_IS_E_SCOPE: -0.0001882992977604027\n",
            "Total Loss: 0.0014737474612598993\n",
            "----------------------------------------\n",
            "Epoch 98\n",
            "Var loss:  tensor(0.0015, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.022657624827853516\n",
            "E_s_wdiff_all_sq: 0.02117662041414926\n",
            "E_IS_SCOPE: -0.0001996397104785106\n",
            "E_IS_E_SCOPE: -0.00018430474507052843\n",
            "Total Loss: 0.0014514596059547226\n",
            "----------------------------------------\n",
            "Epoch 99\n",
            "Var loss:  tensor(0.0014, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.022228225927874042\n",
            "E_s_wdiff_all_sq: 0.020769292564519398\n",
            "E_IS_SCOPE: -0.00019582462654419477\n",
            "E_IS_E_SCOPE: -0.00018063844589869714\n",
            "Total Loss: 0.0014296861251300794\n",
            "----------------------------------------\n",
            "Epoch 100\n",
            "Var loss:  tensor(0.0014, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.021796800272875293\n",
            "E_s_wdiff_all_sq: 0.0203587337727213\n",
            "E_IS_SCOPE: -0.00019221910838322743\n",
            "E_IS_E_SCOPE: -0.00017716986410508842\n",
            "Total Loss: 0.001409093134664148\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[-0.7777,  0.3059],\n",
            "        [ 0.1571,  0.5321],\n",
            "        [-0.3986,  0.1854],\n",
            "        [-0.4127, -0.4704],\n",
            "        [ 0.6016,  0.0216],\n",
            "        [-0.4938,  0.5036],\n",
            "        [ 0.5565,  0.2495],\n",
            "        [ 0.4114,  0.1416],\n",
            "        [ 0.2947,  0.6070],\n",
            "        [-0.4179, -0.5460],\n",
            "        [ 0.6237, -0.0826],\n",
            "        [-0.6531, -0.4247],\n",
            "        [ 0.7598, -0.3762],\n",
            "        [-0.3453, -0.0498],\n",
            "        [ 0.3205,  0.4151],\n",
            "        [ 0.5034,  0.4584]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([ 0.1711,  0.1393, -0.6065, -0.3858,  0.3027, -0.6703,  0.5644, -0.3654,\n",
            "        -0.0457,  0.0983,  0.0548, -0.1078,  0.0852, -0.3275, -0.2573, -0.3640],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[ 0.1506,  0.2117, -0.1280,  0.1274,  0.1846, -0.0611, -0.2407, -0.1279,\n",
            "          0.1438,  0.0343, -0.1677, -0.1838,  0.0195,  0.1629,  0.1588,  0.0610],\n",
            "        [ 0.2496, -0.3613,  0.2460,  0.1369,  0.1857, -0.0816, -0.2257, -0.0807,\n",
            "          0.0420,  0.2366, -0.0859,  0.1445,  0.1005,  0.2319, -0.0642,  0.1460],\n",
            "        [-0.0431, -0.0010, -0.0077, -0.0924,  0.1767, -0.0865, -0.1959,  0.1704,\n",
            "         -0.1823, -0.2091,  0.0130,  0.1759, -0.1773, -0.2159,  0.0980,  0.2080],\n",
            "        [-0.0288,  0.1643,  0.0026,  0.0773, -0.0751,  0.1299, -0.1610,  0.1402,\n",
            "          0.0414, -0.1859,  0.2083,  0.0836,  0.2896,  0.1285, -0.1731, -0.1325],\n",
            "        [-0.2204,  0.0373, -0.1025, -0.2390, -0.2285, -0.1589,  0.2870,  0.0983,\n",
            "         -0.1633, -0.1946,  0.3408, -0.0229, -0.2172,  0.0853,  0.0502, -0.0842],\n",
            "        [ 0.1722,  0.0729, -0.1175,  0.1742,  0.0305, -0.1269,  0.0334,  0.0828,\n",
            "         -0.1195,  0.1123,  0.1710,  0.2296,  0.0680,  0.2276, -0.0481,  0.1595],\n",
            "        [ 0.0231,  0.1546,  0.0715, -0.0856, -0.1055,  0.1152,  0.1312,  0.2225,\n",
            "         -0.1918,  0.1613, -0.1581,  0.1669, -0.2796, -0.2028, -0.1153,  0.1327],\n",
            "        [ 0.0496, -0.1883,  0.2253,  0.1165, -0.1206,  0.0080,  0.0933, -0.1568,\n",
            "          0.1227,  0.2337,  0.2483, -0.1304, -0.1670,  0.1320, -0.0074, -0.1501],\n",
            "        [-0.2357, -0.2967, -0.1501, -0.0619, -0.1233,  0.0445, -0.1153,  0.0852,\n",
            "          0.0117, -0.1696,  0.0486, -0.2046, -0.1219,  0.2411,  0.0110,  0.2098],\n",
            "        [ 0.1801, -0.0938, -0.0026, -0.1210,  0.2397, -0.0081, -0.1386, -0.0746,\n",
            "         -0.2004, -0.2426,  0.0730, -0.2092,  0.1332, -0.0998, -0.1382,  0.0711],\n",
            "        [ 0.0189,  0.1452,  0.1722,  0.2401, -0.0634,  0.0786,  0.0945,  0.0089,\n",
            "          0.0514,  0.0963,  0.2613, -0.0721, -0.0235,  0.2348, -0.1079, -0.0923],\n",
            "        [-0.0590, -0.1129, -0.2224,  0.0090, -0.1187, -0.2538, -0.1709,  0.0607,\n",
            "         -0.1288,  0.2315,  0.1453, -0.2303,  0.0361,  0.2278,  0.1067,  0.1099],\n",
            "        [-0.2422, -0.1532,  0.1302, -0.0384, -0.2576,  0.0525, -0.2081,  0.0992,\n",
            "          0.0208, -0.0901, -0.0325, -0.1017, -0.2021,  0.0026, -0.2152, -0.0780],\n",
            "        [ 0.0748, -0.2829,  0.3474, -0.0721, -0.1019, -0.2906, -0.1932,  0.1902,\n",
            "         -0.3076, -0.1929,  0.1094, -0.1122,  0.2442, -0.0075,  0.1771, -0.1366],\n",
            "        [-0.1502,  0.0710,  0.1172, -0.0786,  0.0442, -0.0519,  0.1472, -0.2850,\n",
            "         -0.2336, -0.0358,  0.2103, -0.2385,  0.0615, -0.0809,  0.0735,  0.1869],\n",
            "        [ 0.0631, -0.0939, -0.2394,  0.2376,  0.0627,  0.1326, -0.0956, -0.1506,\n",
            "         -0.0982,  0.0098,  0.0101,  0.0143, -0.1091,  0.2251, -0.1425,  0.1245],\n",
            "        [ 0.1161, -0.1429,  0.0225, -0.1103, -0.2309, -0.0020, -0.3429, -0.0735,\n",
            "         -0.1055,  0.0320,  0.2303, -0.0123,  0.0747,  0.2238,  0.2965, -0.1080],\n",
            "        [ 0.1820, -0.2471, -0.0514,  0.1939, -0.2281,  0.0914, -0.2055,  0.1723,\n",
            "         -0.1251,  0.1888,  0.1818, -0.2439,  0.1295,  0.1338,  0.1238,  0.2815],\n",
            "        [-0.0336,  0.1937, -0.0590, -0.1850, -0.1637, -0.0689, -0.1136, -0.0068,\n",
            "         -0.0807,  0.1982,  0.2153, -0.1195,  0.1987, -0.0919, -0.1703, -0.0797],\n",
            "        [ 0.1432,  0.0465,  0.1881,  0.0652, -0.0080, -0.1138,  0.1430,  0.2734,\n",
            "         -0.0321, -0.2477,  0.0657, -0.1125,  0.0083, -0.1310,  0.1267, -0.0162],\n",
            "        [-0.1290, -0.2047,  0.1475, -0.1572, -0.1643,  0.1900,  0.0612, -0.1922,\n",
            "          0.2018, -0.2126, -0.0541, -0.1018,  0.2933, -0.1016,  0.1270,  0.1445],\n",
            "        [ 0.0686, -0.1312, -0.0694, -0.2000,  0.2026, -0.1157,  0.2425, -0.1857,\n",
            "          0.1491,  0.2381,  0.1749, -0.1771,  0.3152,  0.1456, -0.0756,  0.0394],\n",
            "        [-0.0296, -0.1688, -0.1727, -0.2160, -0.1795,  0.0286,  0.1888,  0.1532,\n",
            "          0.1564, -0.1103,  0.1710,  0.0552,  0.1225, -0.2125,  0.0703, -0.0194],\n",
            "        [ 0.1847,  0.2370,  0.1885,  0.2068,  0.0487, -0.0579, -0.0615,  0.2214,\n",
            "         -0.0959, -0.2498, -0.0008, -0.1612,  0.0555,  0.0621,  0.0625, -0.1905],\n",
            "        [ 0.0178, -0.1060, -0.1251,  0.0649,  0.1584, -0.0861,  0.0614, -0.0272,\n",
            "          0.1499,  0.2353,  0.2473,  0.1980, -0.0860, -0.1167,  0.1806, -0.1472],\n",
            "        [-0.2260,  0.1398, -0.1234,  0.2040, -0.1329, -0.0401,  0.1884,  0.1170,\n",
            "          0.1394, -0.0778,  0.0037,  0.1076, -0.2246, -0.0155, -0.1701, -0.0022],\n",
            "        [-0.1771,  0.1220,  0.1581,  0.0166, -0.1368,  0.1882, -0.2664, -0.0324,\n",
            "         -0.1479, -0.2198, -0.0375,  0.0343,  0.0245, -0.0906,  0.0534, -0.2336],\n",
            "        [ 0.1262,  0.1445,  0.1559,  0.2178,  0.2216,  0.0204, -0.1279, -0.1028,\n",
            "         -0.0896,  0.0324, -0.1252, -0.0807, -0.2765, -0.2428,  0.1117, -0.2117],\n",
            "        [ 0.1957, -0.0635,  0.1518,  0.0718,  0.0073,  0.1235, -0.0351, -0.1767,\n",
            "          0.1276, -0.2127, -0.0011, -0.1007, -0.0607,  0.0622, -0.2056,  0.1893],\n",
            "        [-0.0020, -0.0778,  0.1391, -0.1155,  0.2710,  0.1672, -0.2635,  0.1125,\n",
            "         -0.0639,  0.1472,  0.0360, -0.2218, -0.1721,  0.0088, -0.0685,  0.1673],\n",
            "        [ 0.0027,  0.0943,  0.0203, -0.2022,  0.1183, -0.1171, -0.0923, -0.2485,\n",
            "         -0.1763, -0.0872,  0.0147, -0.1396, -0.0725, -0.1415,  0.1644,  0.1914],\n",
            "        [ 0.1709, -0.0976, -0.2419,  0.0728,  0.0099, -0.1100,  0.2059, -0.2157,\n",
            "          0.1073, -0.2444, -0.0416, -0.1568, -0.0487, -0.2243, -0.0275,  0.1397]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([-0.1611, -0.1177,  0.1489, -0.1462, -0.1481,  0.0392, -0.1520, -0.1055,\n",
            "        -0.0882, -0.1258,  0.0597,  0.0022,  0.0508,  0.1701, -0.1540, -0.0950,\n",
            "         0.1668,  0.2374, -0.1179, -0.1160, -0.0355,  0.0902, -0.1110, -0.2222,\n",
            "         0.1367,  0.0367, -0.1529,  0.0293, -0.3027, -0.2663,  0.1992,  0.1211],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[ 0.1293,  0.0335,  0.0402, -0.1298,  0.1115,  0.1253, -0.1054,  0.0673,\n",
            "          0.0844, -0.2808,  0.0233,  0.1193,  0.0321, -0.1480,  0.1299, -0.0819,\n",
            "         -0.3052,  0.1699,  0.2533, -0.1310, -0.0861, -0.1526, -0.1007,  0.0589,\n",
            "          0.1703,  0.1214, -0.0065, -0.0789,  0.1398, -0.1719, -0.1463,  0.0359]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([0.0885], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare input data\n",
        "input_data = torch.tensor([0, 6], dtype=torch.float64)\n",
        "\n",
        "# Pass input through the model\n",
        "model(input_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrrRKkHjp9UJ",
        "outputId": "d9a4d58c-404b-4c87-b34e-1d6032faa3a2"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1457], dtype=torch.float64, grad_fn=<ViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = CustomizableFeatureNet(input_dim=2, hidden_dims=[16, 32], output_dim=1, dtype = torch.float64)"
      ],
      "metadata": {
        "id": "LRcpZ6zAowqJ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test1 = SCOPE_variance(model, 0.9, 10000, pi_b, P_pi_b, P_pi_e, dtype = torch.float64)"
      ],
      "metadata": {
        "id": "jqKcMhNSnRTC"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# IS_tensor, samples_IS, padded_state_tensors, padded_weight_diff_tensors, gamma_weights_last_tensor, states_first_tensor, states_last_tensor = test1.prepare()\n",
        "\n",
        "# Modified class with bootstrap_all_terms\n",
        "IS_tensor, padded_state_tensors, padded_weight_diff_tensors, gamma_weights_last_tensor, states_first_tensor, states_last_tensor = test1.prepare()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "uftstgp1nRTP",
        "outputId": "37784d3c-0119-4de4-b402-83f755d3e636"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "too many values to unpack (expected 6)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-085bf38dcdb8>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Modified class with bootstrap_all_terms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mIS_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded_state_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded_weight_diff_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma_weights_last_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates_first_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates_last_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 6)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "timesteps, states, states_first, states_last, actions, rewards, gamma_last, weights_last, weights, weights_difference = test1.prep_policies()"
      ],
      "metadata": {
        "id": "IG7OqI1kuQ7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "states_output, states_first_output, states_last_output = test1.pass_states(model, padded_state_tensors, states_first_tensor, states_last_tensor)\n",
        "sums_states_weight_diff = test1.states_weight_diff_sums(states_output, padded_weight_diff_tensors)\n",
        "gamma_weights_states_last_sub_states_first = test1.last_first_terms_operations(gamma_weights_last_tensor, states_last_output, states_first_output)\n",
        "\n",
        "\n",
        "# sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, samples_all_shaping, samples_IS_SCOPE = test1.bootstrap_shaping_terms(sums_states_weight_diff, gamma_weights_states_last_sub_states_first, IS_tensor)\n",
        "samples_IS, sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, samples_all_shaping, samples_IS_SCOPE = test1.bootstrap_all_terms(sums_states_weight_diff, gamma_weights_states_last_sub_states_first, IS_tensor)\n"
      ],
      "metadata": {
        "id": "-AlHoAZwi9Dr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum_terms = sums_states_weight_diff + gamma_weights_states_last_sub_states_first\n",
        "IS_SCOPE_1 = IS_tensor*sum_terms"
      ],
      "metadata": {
        "id": "Gspo0QLFDzTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CdImElYSD_rx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SCOPE = sample_sums_states_weight_diff+samples_gamma_weight_states_last_sub_states_first\n",
        "E_IS_SCOPE = torch.mean(torch.mean(samples_IS, dim =1) * torch.mean(SCOPE, dim =1))\n",
        "E_IS_E_SCOPE = torch.mean(torch.mean(samples_IS,dim = 1 ))*torch.mean(torch.mean(SCOPE, dim =1))\n",
        "\n",
        "E_IS_SCOPE_2 = torch.mean(torch.mean(samples_IS_SCOPE, dim =1))\n",
        "E_IS_E_SCOPE_2 = torch.mean(torch.mean(samples_IS,dim = 1 )) * torch.mean(torch.mean(samples_all_shaping, dim =1))"
      ],
      "metadata": {
        "id": "mZ_xYyhiCxe9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "E_IS_SCOPE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGY9Jt3FDHKZ",
        "outputId": "4806bfd5-cc2a-40dc-9cf1-f9e471dfaf85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-1.1470e+24, dtype=torch.float64, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "E_IS_SCOPE_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbttxO_jDJGy",
        "outputId": "a0767c9a-54f3-4b4a-878c-f97fde383d23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-1.5943e+26, dtype=torch.float64, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "samples_IS_SCOPE[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtJJjUv-Ctv9",
        "outputId": "30a2eb29-85cd-42f7-913a-422b80b5c82d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ -2.5405e-85,  -0.0000e+00,   7.9024e-62,  -2.9790e-61,  -3.1831e-75,\n",
              "         -1.5365e-64,  -0.0000e+00,  -8.3521e-71,   9.1314e-24,  -6.9648e-66,\n",
              "        -2.0605e-135,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -1.5136e-54,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "          0.0000e+00,   7.9024e-62,   0.0000e+00,  -0.0000e+00,  2.1164e-111,\n",
              "        -9.5684e-135,  -0.0000e+00, -1.4140e-116,  -3.3219e-82,  -0.0000e+00,\n",
              "         -1.5197e-87,  -2.5695e-67,   5.3077e-82,  -0.0000e+00,   2.3741e-47,\n",
              "         -0.0000e+00,  -1.8253e-71,  -3.4879e+11,  -0.0000e+00,  -0.0000e+00,\n",
              "         3.8146e-114,  -0.0000e+00,  -7.5975e-31,  1.2321e-124,  -0.0000e+00,\n",
              "         -0.0000e+00, -2.0958e-170,   0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00, -1.0845e-110,  -1.8398e-69,  -1.8253e-71,   0.0000e+00,\n",
              "         -1.0142e-82,  -3.8087e-71, -4.7846e-116,  -0.0000e+00,  -1.1575e+14,\n",
              "         -8.3983e-61,  -0.0000e+00,  -3.5652e-20,  -4.5806e-83,  -4.3459e-47,\n",
              "         -8.4544e-60,  -0.0000e+00,  -8.8170e-22,  -0.0000e+00,  -0.0000e+00,\n",
              "          1.2354e-36,  -1.5363e-35,  -0.0000e+00, -4.9603e-128,  -0.0000e+00,\n",
              "         -6.3533e-43,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -1.5943e-87,\n",
              "         -3.5388e-13,  -0.0000e+00,  -4.5280e-49,  -1.8006e-40,  -1.9589e-72,\n",
              "         -0.0000e+00,  -1.6958e-50,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "        -6.2039e-105,  -0.0000e+00, -2.1867e-103, -5.2111e-109,  -9.0234e-81,\n",
              "        -7.3637e-125,  -0.0000e+00, -4.3031e-114,  -0.0000e+00,  -0.0000e+00,\n",
              "         -9.0569e-20, -4.9603e-128,  -0.0000e+00,  -0.0000e+00,  -1.2844e-50,\n",
              "          6.8821e-47,  -0.0000e+00,  -0.0000e+00,  -3.6297e-43,  -1.2560e-81,\n",
              "         -0.0000e+00,  -9.6121e-75,  -0.0000e+00,  -0.0000e+00,  -4.7752e-22,\n",
              "         -0.0000e+00,  -8.8170e-22,  -0.0000e+00,  -0.0000e+00,  -3.1837e-84,\n",
              "         -1.1765e-76,  -0.0000e+00,  -1.2844e-50, -7.3798e-163,  -2.0995e-92,\n",
              "         -0.0000e+00, -2.1867e-103,  -0.0000e+00,  -5.9858e-99,  -0.0000e+00,\n",
              "        -3.8876e-136,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -5.4505e-63,\n",
              "         -1.7515e-70,  -0.0000e+00,  -4.5557e-54,  -0.0000e+00,   1.7970e-29,\n",
              "         -4.4059e-35,  -1.8068e-87,  -4.7919e-84,  -1.2284e-23,  -1.5365e-64,\n",
              "          7.8287e-64,  -0.0000e+00,   0.0000e+00,  -2.5680e-16,  1.0151e-134,\n",
              "          5.4627e-50,  -2.1715e-71,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,   2.3966e-44, -4.9603e-128,  -8.2095e-86,  -2.6167e-27,\n",
              "         -6.9755e-72,  -2.5695e-67,  -1.7051e-55, -3.8876e-136,  -1.0863e-21,\n",
              "         9.3247e-114,  -4.4059e-35, -5.3088e-177,  -1.7168e-40,  -0.0000e+00,\n",
              "         -9.1651e-07,  -0.0000e+00,  -0.0000e+00,  -5.1282e-98,  -2.1147e-36,\n",
              "         -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,   3.2571e-55,\n",
              "          0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -2.5695e-67,\n",
              "         -3.3292e-89,  -0.0000e+00,  -0.0000e+00,   0.0000e+00, -5.9574e-107,\n",
              "         -6.7180e-81,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00, -2.2899e-120,\n",
              "         -1.2131e-90,  -1.1847e-05,  -0.0000e+00,  -0.0000e+00,   5.6168e-64,\n",
              "         -0.0000e+00,  -0.0000e+00,  -7.5275e-79,  -3.9772e-98, -1.4124e-115,\n",
              "          6.7779e-24,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -3.4915e-62,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -4.7835e-21,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00, -7.4818e-121,  -1.4379e-56,  -5.9858e-99,   6.5353e-19,\n",
              "         -0.0000e+00, -1.0845e-110,  -1.6331e-73,  -0.0000e+00,  -3.3794e-44,\n",
              "         -0.0000e+00,  -0.0000e+00,  -1.4403e-82,  -0.0000e+00,  -8.2958e-38,\n",
              "         -0.0000e+00,  -2.1267e-31,  -2.0919e-39,  -6.2543e-89,  -7.2344e-89,\n",
              "         -0.0000e+00, -7.4410e-122,  -0.0000e+00,  -9.2244e-29,  -7.6267e-28,\n",
              "         -0.0000e+00,  -1.4441e-84,  -3.4686e-46,  -0.0000e+00,   1.5539e-32,\n",
              "         -0.0000e+00,   2.8584e-70,  -0.0000e+00, -6.7465e-145,   2.3744e-38,\n",
              "         -1.0969e-41,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -2.6507e-76,  -0.0000e+00, -6.5637e-111,  -0.0000e+00,  -1.0553e-59,\n",
              "         -6.3674e-30,  -0.0000e+00,  -1.1992e-76, -8.8087e-109,  -0.0000e+00,\n",
              "         -0.0000e+00,  -2.0183e-60,   2.3741e-47,  -0.0000e+00,   6.4848e-87,\n",
              "         -5.4107e-35,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -9.3262e-46,  -0.0000e+00,  -1.0841e-42,  -0.0000e+00,  -3.2018e-02,\n",
              "         -0.0000e+00,  -1.1614e-91,  -0.0000e+00,  -7.3072e-92,  -0.0000e+00,\n",
              "          1.7396e-15, -8.8087e-109,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -3.3292e-89,  -0.0000e+00,  -1.8096e-45,   1.6171e-12,   2.3741e-47,\n",
              "         -2.1147e-36, -7.3798e-163,  -0.0000e+00,   2.4396e-88,  -0.0000e+00,\n",
              "         -0.0000e+00, -1.7320e-101,   3.5779e-27,  -0.0000e+00,  -3.9346e-91,\n",
              "         -1.4120e-71,  -0.0000e+00,  -0.0000e+00,  -1.1299e-90,  -0.0000e+00,\n",
              "         -0.0000e+00,  -5.2727e-61,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -1.0228e-11,  2.1164e-111,  -0.0000e+00,  -0.0000e+00,\n",
              "         -3.3794e-44, -2.3564e-152,  -0.0000e+00,  -2.5200e-98,  -1.4403e-82,\n",
              "         -0.0000e+00, -1.6503e-110,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -2.5405e-85,  -0.0000e+00,  -0.0000e+00,  -1.7051e-55,  -1.1579e-96,\n",
              "        -1.6503e-110,  -0.0000e+00, -7.9975e-114,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -2.5266e-42,  -3.2963e-38,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00, -1.3348e-146,  -7.9739e-71,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -1.6331e-73,  -1.2096e-60,  -4.9155e-49,  -0.0000e+00,\n",
              "         -8.5756e-93,  -0.0000e+00, -2.3319e-135,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,   2.0816e+09,  -3.3419e-33,  -0.0000e+00,\n",
              "         -9.5822e-03,  -0.0000e+00, -3.0795e-106,  -0.0000e+00,  -0.0000e+00,\n",
              "         -1.1765e-76,  -0.0000e+00,  -0.0000e+00,  -1.0841e-42,  -0.0000e+00,\n",
              "         -4.1517e-59,  -1.0295e-65,  -0.0000e+00,  -1.8006e-40,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -8.4740e-76,   0.0000e+00,\n",
              "        -2.9514e-101,  -2.5200e-98, -2.0605e-135,   2.3977e-39,  -0.0000e+00,\n",
              "         -0.0000e+00,  -1.6331e-73, -5.5873e-109,  -0.0000e+00,  -1.1992e-76,\n",
              "         -3.1831e-75,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -1.8398e-69,\n",
              "        -1.0896e-137,  -0.0000e+00,  -1.1847e-05,  -0.0000e+00,  -0.0000e+00,\n",
              "         -2.8369e-95,  -6.2692e-86,  -0.0000e+00,  -0.0000e+00,   1.9911e-59,\n",
              "         -2.3919e-79, -5.9400e-117,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -1.3256e-29,  -0.0000e+00,  -0.0000e+00,  -2.9009e-36,\n",
              "        -5.9194e-108,  -1.7051e-55,  -4.4059e-35,  -0.0000e+00, -2.0605e-135,\n",
              "         -1.5469e-21,  -4.4059e-35,  -4.5557e-54,  -0.0000e+00,  -8.7108e-62,\n",
              "         -1.1976e-94,  -1.8848e-48,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "        -5.2070e-107,  -0.0000e+00,  -2.0882e-86,  -0.0000e+00,  -5.1132e-04,\n",
              "          0.0000e+00,   9.1906e-19,  -3.1091e-65,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "        -3.7267e-107,  -0.0000e+00,  -4.9777e-77,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,  -4.1925e-25, -3.0795e-106,  -0.0000e+00,\n",
              "         -0.0000e+00,   0.0000e+00,  -0.0000e+00,  -4.5806e-83,  2.1164e-111,\n",
              "         -2.5200e-98, -4.3088e-113,  -0.0000e+00,  -3.6404e-32,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -9.1264e-43,  -0.0000e+00,\n",
              "         -2.4591e-89,  -0.0000e+00,  -0.0000e+00,   1.9275e-45,  -1.1543e-33,\n",
              "         -1.2560e-81,  -0.0000e+00,  -0.0000e+00,   2.3977e-39, -3.3028e-112,\n",
              "          7.8287e-64,  -0.0000e+00,  -0.0000e+00, -7.7889e-104, -6.3394e-172,\n",
              "         -8.8170e-22, -5.5873e-109,  3.8146e-114,  -0.0000e+00,  3.4576e-143,\n",
              "        -1.3164e-160,  -0.0000e+00,  -1.1579e-96,  -0.0000e+00,  -1.1299e-90,\n",
              "         -0.0000e+00,  -0.0000e+00,  -1.1997e-38,  -2.4591e-89,   9.1690e-44,\n",
              "         -2.2622e-69,  -1.2560e-81,  -3.2067e-77,  -3.5388e-13,   2.4880e-25,\n",
              "         -3.5370e-23,   5.4627e-50,  -0.0000e+00, -2.4613e-126,  -0.0000e+00,\n",
              "        -7.9975e-114,  -4.0313e-39,  -0.0000e+00,  -5.2680e-78, -6.3760e-128,\n",
              "         -5.0730e-73,  -9.1651e-07,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "        -2.2899e-120,   6.4848e-87,  -0.0000e+00,  -0.0000e+00,   1.7396e-15,\n",
              "         -2.4878e-79,  -0.0000e+00, -6.7220e-124,  3.4576e-143,  -5.4505e-63,\n",
              "          0.0000e+00,  -0.0000e+00,  -9.2244e-29,  -0.0000e+00,  -0.0000e+00,\n",
              "         -1.8006e-40,  -0.0000e+00,  -0.0000e+00, -3.9715e-111, -7.8048e-109,\n",
              "         -0.0000e+00,  -0.0000e+00,  -6.0378e-78,  -6.9027e-64,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,  -0.0000e+00,   0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,  -4.6446e+26,  -2.8369e-95, -3.7267e-107,\n",
              "         -0.0000e+00,   5.9283e-29,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "        -5.2111e-109,  -4.9777e-77,  -2.5057e-97,  -0.0000e+00,  -0.0000e+00,\n",
              "         -4.3459e-47,  -0.0000e+00,  -9.6952e-11,  -0.0000e+00,  -0.0000e+00,\n",
              "         -1.0423e-88,  -0.0000e+00,  -9.7803e-64,  -0.0000e+00,  -2.6108e-10,\n",
              "         -1.1245e-32,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -1.1614e-91,\n",
              "          5.9283e-29,  -1.8006e-40,  -0.0000e+00,  -1.4581e-42,  -1.9457e-84,\n",
              "          0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,  -1.2597e-64,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -7.6267e-28,  -1.1340e-54,  -0.0000e+00,   5.6168e-64,\n",
              "         2.1164e-111,  -1.6117e-70, -1.6001e-142, -7.4188e-119,  -1.6297e-40,\n",
              "         -0.0000e+00, -9.6814e-148,   0.0000e+00,  -4.9886e-56,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,  -3.5652e-20, -5.6374e-108,  -0.0000e+00,\n",
              "          6.4848e-87,  -0.0000e+00, -1.2228e-108,   9.1690e-44,  -2.4591e-89,\n",
              "        -5.2111e-109, -1.0845e-110,  -0.0000e+00,  -0.0000e+00,  -1.2284e-23,\n",
              "        -1.3276e-126,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,  -2.5405e-85,  -1.1543e-33,  -6.5620e-73,\n",
              "          9.6998e-75,   2.3966e-44,  -0.0000e+00,  -1.5943e-87,   6.8821e-47,\n",
              "         -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -2.5695e-67,  -3.9346e-91, -9.5684e-135,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00, -1.6503e-110,  -2.4878e-79,  -0.0000e+00,  -1.2096e-60,\n",
              "         -4.9154e-65,  -0.0000e+00,  -0.0000e+00,  -1.6205e-31, -5.9400e-117,\n",
              "         -3.6297e-43, -3.8447e-105,  -2.1245e-84,  -0.0000e+00,  -0.0000e+00,\n",
              "         -5.9911e-37,  -0.0000e+00,  -0.0000e+00,  -2.5057e-97, -2.6928e-118,\n",
              "         -0.0000e+00, -3.7267e-107,  -2.7470e-44, -2.1867e-103,  -5.0835e-67,\n",
              "        -7.4188e-119, -2.9514e-101,  -8.8828e-84, -3.9715e-111,  -5.5407e-09,\n",
              "         -8.3866e-92,  -0.0000e+00,  -3.7204e-20,   1.1578e-36,  -0.0000e+00,\n",
              "         -4.2977e-22,  -4.1575e-21,  -1.8068e-87,  -0.0000e+00,  -0.0000e+00,\n",
              "        -7.7889e-104,  -5.8622e-39,  -1.5944e+29,  -0.0000e+00,  -2.6167e-27,\n",
              "         -0.0000e+00,  -0.0000e+00,  -2.6167e-27,  -8.2095e-86,  -0.0000e+00,\n",
              "         -1.8470e-62,  -0.0000e+00,  -1.0278e-42,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -1.0553e-59,  -0.0000e+00, -6.5637e-111,  -0.0000e+00,\n",
              "         -4.6573e-78,  -1.3726e-66,  -1.7515e-70,  -2.3103e-40,  -0.0000e+00,\n",
              "         -4.9064e-04,   1.9275e-45,  -0.0000e+00,  -0.0000e+00,  -6.7637e-94,\n",
              "         -1.1299e-90,  -0.0000e+00, -1.2228e-108,  -0.0000e+00,  -1.5363e-35,\n",
              "        -2.6557e-114,  -7.6029e-46,  -2.7147e-61,  -1.9612e-45,  -1.2844e-50,\n",
              "         -1.6958e-50,  -2.7470e-44,  -0.0000e+00, -8.3040e-105,   0.0000e+00,\n",
              "        -7.4818e-121,  -0.0000e+00,   0.0000e+00,   6.8821e-47,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "          5.9283e-29,  -0.0000e+00, -8.8087e-109,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -8.2095e-86,  -0.0000e+00,  -0.0000e+00,  3.8146e-114,\n",
              "         -0.0000e+00,  -0.0000e+00, -5.7092e-133,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -3.1256e-52,  -0.0000e+00,\n",
              "          0.0000e+00,  -2.1977e-38,  -9.2244e-29,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,  -6.3676e+00,  -3.4200e-45,  -0.0000e+00,\n",
              "         -9.1264e-43, -9.5684e-135,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,   0.0000e+00,  -1.4581e-42,  -0.0000e+00,\n",
              "         -0.0000e+00,   2.0581e-29,   1.7970e-29,  -4.6949e-62, -4.3031e-114,\n",
              "         -0.0000e+00,  -0.0000e+00,  -4.1925e-25,  -0.0000e+00,  -0.0000e+00,\n",
              "        -1.6001e-142,  -0.0000e+00, -5.9574e-107, -1.6001e-142,  -3.7204e-20,\n",
              "        -8.0555e-127,  -0.0000e+00,  -0.0000e+00,  -1.4441e-84,  -0.0000e+00,\n",
              "         -5.1132e-04,   5.9283e-29,  -0.0000e+00,  -8.4817e-65,  -0.0000e+00,\n",
              "         -1.0142e-82,  -0.0000e+00,   0.0000e+00,  -0.0000e+00,  -1.6297e-40,\n",
              "         -1.1806e-76,  -0.0000e+00,   8.8334e-65,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,  -1.2844e-50,  -6.9755e-72,  -0.0000e+00,\n",
              "        -1.6001e-142,  -0.0000e+00,  -2.7082e-39, -2.3923e-123,  -1.2560e-81,\n",
              "         -5.5725e-99,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -6.2249e-32,\n",
              "         -0.0000e+00,  -3.4879e+11,  -1.2096e-60,  -1.2131e-90, -6.7220e-124,\n",
              "          7.6016e-81,  -5.5407e-09,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -2.0995e-92, -5.7092e-133,  -4.1575e-21,  -9.1264e-43, -1.8313e-144,\n",
              "         -0.0000e+00,  -1.5363e-35,  -0.0000e+00,  -3.4915e-62,  -0.0000e+00,\n",
              "         -0.0000e+00,  -3.2067e-77,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -1.5469e-21,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,  9.3247e-114,  -0.0000e+00, -1.4124e-115,\n",
              "         -0.0000e+00,  -6.5620e-73, -1.6503e-110,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00, -3.0795e-106,  -1.1997e-38, -5.3088e-177,  -0.0000e+00,\n",
              "         -7.8034e-88,  -0.0000e+00,   2.0581e-29,  -2.5405e-85,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -3.9346e-91,  -4.1575e-21,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00, -7.4410e-122,  -0.0000e+00,  -0.0000e+00,\n",
              "          0.0000e+00,  -2.0389e-21,  -1.3726e-66, -7.3637e-125,  -0.0000e+00,\n",
              "         -7.5275e-79,  -0.0000e+00,  -7.9739e-71,  -0.0000e+00,  -0.0000e+00,\n",
              "        -4.7846e-116,  -0.0000e+00, -5.7104e-117,   0.0000e+00,  -0.0000e+00,\n",
              "        -7.4818e-121,  -1.5197e-87,  -0.0000e+00,  -0.0000e+00, -1.4183e-111,\n",
              "         -4.3459e-47,  -0.0000e+00, -3.6588e-102,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -4.7835e-21,\n",
              "         -4.7835e-21,  -0.0000e+00,  -1.0228e-11,  -0.0000e+00,  -0.0000e+00,\n",
              "         -3.9772e-98,  -0.0000e+00,  -4.2977e-22,  -0.0000e+00,  -0.0000e+00,\n",
              "         -2.5680e-16, -1.4183e-111,  -0.0000e+00,  -4.2977e-22,  -1.2793e-97,\n",
              "         -6.8366e-36,  -0.0000e+00,   2.3977e-39,  -9.6952e-11,  -0.0000e+00,\n",
              "         -0.0000e+00,   1.9911e-59,  -1.4120e-71,  -0.0000e+00, -9.5684e-135,\n",
              "        -3.1407e-107,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -2.5266e-42,  -2.6108e-10,  -0.0000e+00,  -0.0000e+00,  -5.3309e-32,\n",
              "         -0.0000e+00, -3.4482e-108,  -0.0000e+00, -3.3028e-112,  -1.8253e-71,\n",
              "         -1.5197e-87,  -0.0000e+00,  -1.2319e-33,  -0.0000e+00,   0.0000e+00],\n",
              "       dtype=torch.float64, grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_sums_states_weight_diff[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Orvqs0-IwoN4",
        "outputId": "82af141d-6b75-47cc-f39e-77dccf6c0612"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 5.1683e-01,  5.2720e-01,  2.3982e+00,  5.2951e-01,  5.1357e-01,\n",
              "         5.1364e-01, -1.1535e+00,  5.1631e-01,  5.1753e-01,  5.1325e-01,\n",
              "         9.0952e-02,  3.6275e-01,  5.2720e-01,  7.6119e-02,  7.6752e-02,\n",
              "         5.3759e-01,  9.0952e-02,  7.6337e-02,  9.0952e-02,  9.0657e-02,\n",
              "         5.7605e+00,  2.3982e+00,  3.6205e+00,  9.0436e-02,  3.9866e+00,\n",
              "         7.6361e-02,  5.1632e-01,  7.7653e-02,  1.2674e-01,  9.0436e-02,\n",
              "         7.6119e-02,  5.1709e-01,  3.6920e+00,  5.1663e-01,  9.0973e-02,\n",
              "         5.3759e-01,  5.3762e-01, -2.9977e+06,  5.1357e-01,  5.3602e-01,\n",
              "         4.1946e+00,  5.2720e-01, -6.4696e+01,  5.2645e-01,  5.1683e-01,\n",
              "         5.2907e-01,  5.2645e-01,  3.6920e+00,  5.3771e-01,  4.8009e-01,\n",
              "         4.2201e-01,  9.0952e-02,  8.3283e-02,  5.3762e-01,  4.2676e+00,\n",
              "         5.1366e-01,  7.7653e-02,  5.3583e-01,  5.3728e-01, -5.6362e+07,\n",
              "         2.5242e-01, -1.5415e+10, -1.8276e-02,  8.9459e-02,  9.0952e-02,\n",
              "         5.1665e-01, -2.1687e+00, -4.6237e+01,  5.2644e-01,  5.3773e-01,\n",
              "         9.0433e-02, -3.7703e-01,  5.1365e-01,  7.7653e-02,  5.3583e-01,\n",
              "         5.1357e-01,  9.0955e-02,  9.0431e-02,  7.7654e-02,  5.1709e-01,\n",
              "         4.2142e-01,  5.3759e-01,  5.3759e-01,  5.1357e-01, -2.4942e+01,\n",
              "         8.9367e-02,  5.3773e-01,  5.2656e-01,  9.0952e-02,  5.3583e-01,\n",
              "         5.1364e-01,  5.2901e-01,  5.2644e-01,  7.7619e-02,  9.0952e-02,\n",
              "         9.0952e-02,  4.7722e-01,  5.2653e-01,  5.3771e-01,  5.3759e-01,\n",
              "        -2.7596e-01,  7.7653e-02,  9.0952e-02,  7.6361e-02,  9.0952e-02,\n",
              "         5.1728e-01,  9.0952e-02,  9.0431e-02,  4.7655e-01,  5.3759e-01,\n",
              "         5.2644e-01,  9.0657e-02,  7.6361e-02,  1.3149e-01,  5.1357e-01,\n",
              "         7.7556e-02, -4.6237e+01,  5.2653e-01,  9.0436e-02,  4.3616e-01,\n",
              "         7.7633e-02,  9.0433e-02,  9.0952e-02,  9.0952e-02,  5.1665e-01,\n",
              "         5.3547e-01,  5.2644e-01,  7.6105e-02,  9.0952e-02, -1.3443e+00,\n",
              "         5.0960e-01,  5.3761e-01,  9.0952e-02,  5.3591e-01,  5.1357e-01,\n",
              "         5.2714e-01,  4.7650e-01,  8.2442e-02,  5.2920e-01,  7.4989e-02,\n",
              "         5.1428e-01, -9.2283e-01,  5.3759e-01,  5.2900e-01,  5.1364e-01,\n",
              "         1.3196e+00,  5.3602e-01,  3.5049e+00, -1.3996e+03,  1.0444e+01,\n",
              "         7.6121e-02,  9.0949e-02,  7.7556e-02,  9.0952e-02,  5.1711e-01,\n",
              "         9.0955e-02,  4.2595e+00,  7.7653e-02,  5.1357e-01,  5.2900e-01,\n",
              "         5.1782e-01,  5.1709e-01, -2.5074e+01,  5.0960e-01, -1.8205e+00,\n",
              "         5.2652e-01,  5.1428e-01,  5.3773e-01,  5.3771e-01,  5.2720e-01,\n",
              "        -6.8967e+05,  5.3583e-01, -5.6433e-01,  5.3761e-01,  5.2720e-01,\n",
              "         7.7653e-02,  8.9262e-02, -4.4482e+00,  9.0956e-02,  9.0436e-02,\n",
              "         5.4839e+00,  5.2644e-01,  2.3645e-01,  5.1589e-01,  5.1709e-01,\n",
              "         5.3759e-01,  5.1916e-01,  9.0657e-02,  3.6926e+00,  5.2720e-01,\n",
              "         3.5348e-01,  7.6119e-02,  9.0433e-02,  5.2481e-01,  9.0952e-02,\n",
              "         3.9951e-01,  5.1318e-01,  9.0976e-02,  7.6361e-02,  7.4962e-02,\n",
              "         9.0436e-02,  9.0955e-02,  5.2644e-01,  5.1364e-01,  5.2656e-01,\n",
              "         7.6119e-02,  9.0954e-02,  5.3771e-01,  5.1724e-01,  4.3459e-01,\n",
              "         4.7453e-01,  5.2481e-01,  5.3093e-01,  5.2720e-01,  4.7947e-01,\n",
              "         5.1357e-01,  9.0654e-02,  4.0053e-01,  9.0954e-02,  5.3761e-01,\n",
              "         9.0974e-02,  2.5289e-01,  5.3583e-01,  5.1370e-01,  4.7938e-01,\n",
              "         8.3403e-02,  5.3602e-01,  2.3645e-01,  9.0973e-02,  5.2973e-01,\n",
              "         8.9367e-02,  7.7653e-02,  5.1366e-01,  9.0952e-02,  7.4973e-02,\n",
              "         4.7722e-01,  9.0952e-02,  9.0952e-02,  5.3583e-01,  4.8604e-02,\n",
              "         7.7653e-02,  5.1711e-01,  4.1136e-01,  4.7650e-01,  5.2264e-01,\n",
              "         5.3544e-01,  7.7653e-02,  5.2720e-01,  5.2720e-01,  5.1683e-01,\n",
              "         5.2643e-01,  9.0954e-02,  9.0952e-02,  5.1562e-01, -3.3918e-01,\n",
              "         7.7633e-02,  5.1665e-01,  5.3759e-01,  5.1364e-01,  2.8980e+00,\n",
              "        -1.2457e+01,  1.3655e+06,  5.1364e-01,  9.0952e-02,  7.7619e-02,\n",
              "         7.7653e-02,  5.2907e-01,  5.2481e-01,  8.4154e-02,  7.7633e-02,\n",
              "         5.3602e-01,  5.2644e-01,  5.3773e-01,  4.7939e-01,  7.7246e-02,\n",
              "        -4.3690e+00, -1.0027e+00, -8.2078e+00,  9.0973e-02,  5.2723e-01,\n",
              "         5.3330e-01,  5.1357e-01,  9.0973e-02,  4.2201e-01,  3.9321e+00,\n",
              "         4.7938e-01,  4.4394e-01,  5.1665e-01,  9.0436e-02, -7.3013e+01,\n",
              "         8.3361e-02,  5.1414e-01,  4.2142e-01,  5.1504e-01, -1.6895e+10,\n",
              "         9.0952e-02,  4.7722e-01,  7.7633e-02,  5.1357e-01,  9.0952e-02,\n",
              "         5.1815e+00,  9.0973e-02,  5.2644e-01,  4.8009e-01, -2.7487e+10,\n",
              "         5.3759e-01,  4.7722e-01,  7.5000e-02,  6.7563e-02,  9.0973e-02,\n",
              "         5.2720e-01,  9.0952e-02,  5.3058e-01,  5.1724e-01,  5.1364e-01,\n",
              "         9.0973e-02,  7.7627e-02,  5.3583e-01, -9.8881e+02,  5.2714e-01,\n",
              "         5.1683e-01,  5.3340e-01,  9.0952e-02,  5.2644e-01,  7.7653e-02,\n",
              "         5.1724e-01,  5.3759e-01,  5.3602e-01,  9.0418e-02,  5.3602e-01,\n",
              "         7.7556e-02, -4.9233e+04,  3.9866e+00, -4.4482e+00,  5.3602e-01,\n",
              "         4.8604e-02,  5.3761e-01,  5.3728e-01,  9.0952e-02,  4.1136e-01,\n",
              "         5.3759e-01,  9.0973e-02,  5.3591e-01,  4.7938e-01,  4.8097e-01,\n",
              "         5.1683e-01,  7.6119e-02,  5.2644e-01, -2.5074e+01,  5.3602e-01,\n",
              "         9.0973e-02,  9.0956e-02,  5.2652e-01,  5.2481e-01, -1.1318e+06,\n",
              "         5.1666e-01,  5.2720e-01,  5.1665e-01,  9.0952e-02,  7.6119e-02,\n",
              "         7.7653e-02,  7.6121e-02, -3.0503e+00,  4.7722e-01,  5.2901e-01,\n",
              "         5.2907e-01,  9.0952e-02,  5.1893e-01,  5.3058e-01,  5.2901e-01,\n",
              "         5.2900e-01, -1.1318e+06,  5.1728e-01,  5.1365e-01,  4.7708e-01,\n",
              "         7.7243e-02,  9.0976e-02, -2.0596e+05,  3.9834e-01, -1.1694e+00,\n",
              "        -7.6578e+01,  5.1632e-01,  5.3444e-01,  7.7627e-02,  5.2653e-01,\n",
              "         7.7633e-02, -1.2990e-01,  5.2481e-01,  4.2142e-01,  4.7708e-01,\n",
              "         5.1298e-01,  9.0948e-02,  3.3077e-01,  5.1357e-01,  7.6361e-02,\n",
              "         5.3771e-01,  5.3602e-01,  8.5267e-02,  5.1411e-01,  3.3376e+00,\n",
              "         5.3602e-01,  9.0952e-02,  9.0952e-02,  5.3761e-01,  5.3761e-01,\n",
              "         5.2720e-01,  9.0952e-02,  5.1364e-01,  5.1665e-01, -8.2078e+00,\n",
              "         5.1357e-01,  9.0656e-02,  5.1631e-01,  9.0433e-02,  8.3283e-02,\n",
              "         7.6361e-02,  5.3773e-01,  5.1318e-01,  9.0657e-02,  7.7619e-02,\n",
              "         5.1709e-01,  4.9870e-01,  8.1049e-02,  5.3602e-01,  5.3583e-01,\n",
              "         5.1414e-01,  5.1366e-01,  9.0436e-02,  4.3569e-01,  5.3408e-01,\n",
              "        -1.1694e+00,  5.1357e-01,  5.3005e-01, -1.1318e+06,  5.3771e-01,\n",
              "         5.3602e-01, -2.5074e+01,  5.1428e-01,  9.0952e-02,  9.0952e-02,\n",
              "         1.3058e+01,  5.1428e-01,  8.2442e-02,  5.1364e-01,  7.7574e-02,\n",
              "         4.7995e-01,  5.3602e-01,  6.9435e-02,  9.0657e-02,  9.0973e-02,\n",
              "         5.1709e-01,  5.3404e-01,  7.7653e-02,  5.1357e-01, -1.1658e+06,\n",
              "         3.5049e+00,  4.5514e-01,  5.1665e-01,  5.1047e-01, -7.2190e+10,\n",
              "         5.2653e-01, -2.0584e-01,  5.3602e-01,  5.3544e-01, -2.1687e+00,\n",
              "         5.3773e-01,  7.6361e-02,  5.2644e-01,  5.1770e-01,  4.3616e-01,\n",
              "        -3.4605e+02,  3.8834e-01, -5.7075e-01,  5.3444e-01,  4.3616e-01,\n",
              "         5.2724e-01,  5.4799e+00,  5.2993e-01,  8.9459e-02,  3.9866e+00,\n",
              "         9.0952e-02,  5.3761e-01, -2.2314e+00,  5.1792e-01,  4.7939e-01,\n",
              "         4.3616e-01,  8.9367e-02,  5.1683e-01, -5.4331e+00,  5.2973e-01,\n",
              "         5.1367e-01,  5.3602e-01,  9.0954e-02,  7.6118e-02,  5.1357e-01,\n",
              "         5.3759e-01,  4.3616e-01,  5.3408e-01,  5.3761e-01,  5.1414e-01,\n",
              "         1.3196e+00,  5.3591e-01, -7.5061e-02,  4.8096e-01,  7.6361e-02,\n",
              "        -4.6237e+01,  5.1364e-01,  4.1946e+00,  5.2481e-01,  5.1357e-01,\n",
              "         9.0976e-02,  5.1419e-01,  5.3602e-01,  5.2638e-01,  5.2644e-01,\n",
              "         5.2720e-01, -1.3566e+07, -2.2910e+00,  5.1367e-01,  4.2555e+00,\n",
              "         5.3759e-01,  5.3759e-01,  7.7653e-02,  4.2142e-01,  7.4973e-02,\n",
              "         2.5229e-01,  7.6121e-02,  4.3569e-01,  9.0657e-02,  5.3058e-01,\n",
              "         5.2652e-01,  4.7938e-01,  5.3762e-01,  5.2951e-01,  5.1709e-01,\n",
              "        -4.4662e-01, -6.8967e+05,  5.1605e-01,  5.2973e-01, -2.7469e+03,\n",
              "         9.0952e-02,  3.9321e+00,  5.2907e-01,  5.1297e-01,  5.1815e+00,\n",
              "         5.1411e-01, -2.0584e-01,  7.7633e-02,  5.1357e-01,  5.1357e-01,\n",
              "         4.4238e+00, -2.6895e+01,  5.1562e-01,  7.6361e-02,  5.3544e-01,\n",
              "         5.1357e-01,  5.2993e-01,  5.2653e-01,  5.1665e-01,  5.1711e-01,\n",
              "         5.3771e-01,  5.1364e-01,  5.1365e-01,  5.3583e-01,  9.0431e-02,\n",
              "         5.3759e-01,  9.0657e-02, -4.7566e-02,  3.6920e+00,  5.2652e-01,\n",
              "         5.2799e-01,  5.3728e-01, -5.2253e+15,  5.1709e-01,  5.3773e-01,\n",
              "         5.3544e-01,  7.6356e-02,  5.1631e-01,  5.1685e-01, -2.7487e+10,\n",
              "         7.7619e-02,  5.2644e-01,  5.1366e-01,  5.3759e-01,  5.2720e-01,\n",
              "         9.0952e-02,  8.6001e-02, -6.6563e+03, -3.5506e+00,  5.2973e-01,\n",
              "         5.3602e-01,  5.3759e-01,  5.3759e-01,  7.5080e-02,  3.0557e+00,\n",
              "        -2.5344e-01,  5.3762e-01,  9.0952e-02,  5.2901e-01,  4.7722e-01,\n",
              "         7.6356e-02,  5.1357e-01,  7.7653e-02,  5.1325e-01,  7.7556e-02,\n",
              "         1.3330e+00,  7.6104e-02,  5.2644e-01,  5.2901e-01,  7.6752e-02,\n",
              "         5.1711e-01,  9.0952e-02, -1.1708e+00,  5.2900e-01, -3.2846e+01,\n",
              "         5.2600e-01, -3.3918e-01,  5.1357e-01,  7.7653e-02,  7.4962e-02,\n",
              "         3.9866e+00,  9.0948e-02,  5.3773e-01,  5.3771e-01,  4.7939e-01,\n",
              "         5.1419e-01,  5.3761e-01,  5.7605e+00,  3.8131e-01,  5.2644e-01,\n",
              "         9.0973e-02,  9.0952e-02, -1.8276e-02,  7.6361e-02,  5.1297e-01,\n",
              "         3.9321e+00,  5.2653e-01,  9.0952e-02,  4.2555e+00,  5.1367e-01,\n",
              "         7.7619e-02,  9.0952e-02,  5.2481e-01,  5.1444e-01,  5.2900e-01,\n",
              "         4.3569e-01, -1.0532e+07,  5.1419e-01,  9.0955e-02,  7.7246e-02,\n",
              "         5.2920e-01, -1.1318e+06,  5.1683e-01,  5.1357e-01,  5.1357e-01,\n",
              "         7.4989e-02,  4.2595e+00,  7.6361e-02,  5.1709e-01,  5.1728e-01,\n",
              "         5.3761e-01,  9.0952e-02,  4.0053e-01,  8.1049e-02,  4.7650e-01,\n",
              "         4.2840e-01,  9.0952e-02,  5.2644e-01,  5.3588e-01,  5.1411e-01,\n",
              "         5.1709e-01,  5.2714e-01,  7.6361e-02,  5.3771e-01,  9.0431e-02,\n",
              "         5.1364e-01,  9.0973e-02,  5.1411e-01, -8.0030e+06,  5.1893e-01,\n",
              "         9.0952e-02,  5.1357e-01,  5.1711e-01,  5.3005e-01,  5.1366e-01,\n",
              "         4.7655e-01,  5.3759e-01,  8.4499e-02,  5.2720e-01,  9.0955e-02,\n",
              "         5.1357e-01, -1.8447e-01,  9.0433e-02,  5.1366e-01,  5.2721e-01,\n",
              "         9.0656e-02,  5.3773e-01,  5.1364e-01,  5.2644e-01,  5.3055e-01,\n",
              "         5.3771e-01,  5.3602e-01,  5.2631e-01,  5.1665e-01, -8.5441e+00,\n",
              "         4.7468e-01,  9.0973e-02, -6.4931e+01,  1.9185e+00,  9.0952e-02,\n",
              "         8.3283e-02,  5.1357e-01, -9.2283e-01,  5.2720e-01,  5.2720e-01,\n",
              "         4.8096e-01,  5.1357e-01, -9.3440e+14, -7.3013e+01,  5.2900e-01,\n",
              "         9.0952e-02,  7.7654e-02,  5.2900e-01,  5.1357e-01,  5.3547e-01,\n",
              "         5.0987e-01,  4.3616e-01,  9.0657e-02,  5.3583e-01,  5.1770e-01,\n",
              "         5.3591e-01,  7.7246e-02, -3.6693e+06,  5.3773e-01,  4.3569e-01,\n",
              "         4.8324e-01,  4.7938e-01,  5.2714e-01,  7.6345e-02,  7.7243e-02,\n",
              "        -2.4566e+05,  7.6118e-02,  5.3771e-01,  5.2907e-01,  9.0952e-02,\n",
              "         5.2644e-01,  9.0976e-02,  9.0952e-02,  9.0954e-02, -3.7703e-01,\n",
              "         5.1357e-01,  5.1411e-01,  7.7653e-02,  5.1665e-01,  9.0952e-02,\n",
              "         5.3773e-01,  5.1364e-01,  5.2644e-01,  5.1364e-01,  1.0034e+00,\n",
              "         7.7653e-02,  5.1297e-01,  5.4839e+00,  5.1728e-01,  5.3759e-01,\n",
              "        -2.6111e+01,  4.7939e-01,  5.2644e-01,  2.7664e-01,  5.1477e-01,\n",
              "         7.6356e-02,  5.3588e-01,  9.0973e-02,  9.0952e-02,  5.3583e-01,\n",
              "         5.3340e-01,  5.1357e-01,  5.3761e-01,  9.0957e-02,  4.1946e+00,\n",
              "         5.1365e-01,  5.3602e-01,  5.1683e-01,  4.3616e-01, -8.0030e+06,\n",
              "         4.3569e-01,  7.7556e-02,  9.0952e-02,  5.1665e-01,  5.1782e-01,\n",
              "         3.3888e+00,  5.1357e-01,  5.1562e-01,  5.1683e-01,  5.3602e-01,\n",
              "         5.1666e-01,  5.3759e-01, -1.5824e+02,  5.1357e-01,  5.2644e-01,\n",
              "        -5.4331e+00,  7.6361e-02,  5.3591e-01,  9.0433e-02,  5.2653e-01,\n",
              "         5.2720e-01,  7.7618e-02,  5.6180e+00,  5.1325e-01,  5.1711e-01,\n",
              "         3.6519e-01,  4.3561e-01,  7.4989e-02,  9.0952e-02,  5.2653e-01,\n",
              "         7.7637e-02,  5.3773e-01, -5.7075e-01,  9.0973e-02,  5.1365e-01,\n",
              "         5.3773e-01,  9.0431e-02,  5.2720e-01,  5.3773e-01, -6.4931e+01,\n",
              "         7.7633e-02,  5.3728e-01,  7.7653e-02,  5.1665e-01,  5.2481e-01,\n",
              "        -1.1658e+06,  7.6356e-02, -5.6433e-01,  4.3616e-01,  5.1444e-01,\n",
              "         5.1366e-01,  5.3759e-01,  5.4839e+00,  5.3602e-01,  4.7939e-01,\n",
              "         5.2644e-01,  5.2720e-01,  3.6919e+00,  9.0952e-02,  5.3762e-01,\n",
              "         5.1414e-01,  4.2835e-01,  9.0952e-02,  5.1782e-01,  7.7653e-02,\n",
              "         5.3773e-01,  5.3759e-01, -7.8570e-01,  9.0952e-02,  5.3759e-01,\n",
              "         7.5382e-02,  8.9367e-02, -4.4482e+00,  4.7938e-01,  5.1357e-01,\n",
              "         9.0656e-02, -2.9977e+06,  5.1893e-01,  3.9951e-01,  7.7633e-02,\n",
              "         7.7619e-02, -8.5441e+00,  5.3773e-01,  4.7453e-01,  5.1724e-01,\n",
              "         5.1665e-01,  5.1683e-01,  5.1357e-01, -5.4331e+00,  5.3420e-01,\n",
              "         5.3773e-01, -3.7703e-01,  5.2952e-01,  5.1357e-01,  1.9632e-01,\n",
              "         9.0952e-02,  7.7653e-02,  8.9262e-02,  5.2953e-01,  9.0973e-02,\n",
              "         5.3583e-01,  1.3058e+01,  5.2952e-01,  5.1370e-01,  5.3547e-01,\n",
              "         5.2644e-01,  9.0952e-02,  5.2652e-01,  5.1364e-01,  5.2656e-01,\n",
              "         5.2724e-01,  5.1357e-01,  9.0973e-02,  9.0952e-02,  7.6119e-02,\n",
              "         5.3602e-01,  5.3444e-01, -2.2910e+00,  5.3773e-01,  7.7654e-02,\n",
              "        -2.2579e-01,  4.6518e-01,  4.3561e-01,  5.1683e-01,  4.1597e-01,\n",
              "         9.0657e-02,  9.0436e-02,  7.7246e-02,  9.0436e-02,  7.7556e-02,\n",
              "         5.2714e-01,  5.1357e-01,  5.1367e-01,  5.2720e-01, -3.8281e+02,\n",
              "         5.2973e-01,  5.2644e-01,  9.0954e-02,  5.3537e-01,  4.7708e-01,\n",
              "         1.3330e+00,  5.1356e-01,  4.7938e-01,  9.0952e-02,  9.0657e-02,\n",
              "         5.2644e-01,  9.0952e-02, -3.0503e+00,  4.4394e-01,  9.0973e-02,\n",
              "         5.3583e-01,  5.1357e-01,  5.2951e-01,  3.3888e+00,  4.2835e-01,\n",
              "         7.7653e-02,  7.6119e-02,  9.0973e-02,  5.3761e-01,  5.2959e-01,\n",
              "         9.0952e-02,  5.3583e-01,  5.1724e-01,  5.3404e-01,  5.1357e-01,\n",
              "         7.7633e-02,  7.5080e-02,  5.3340e-01,  9.0955e-02,  9.0974e-02,\n",
              "         9.0974e-02,  5.1683e-01, -4.9233e+04,  5.3771e-01,  5.3110e-01,\n",
              "         5.1364e-01, -3.6693e+06,  8.3283e-02,  5.2481e-01, -3.4611e+00,\n",
              "        -1.3996e+03,  5.2959e-01,  5.2720e-01,  8.3283e-02,  7.7653e-02,\n",
              "         5.1355e-01,  5.1412e-01,  5.3761e-01, -6.6563e+03,  5.3759e-01,\n",
              "         4.7938e-01,  5.3583e-01,  5.1683e-01,  9.0957e-02,  7.6361e-02,\n",
              "         5.1357e-01,  9.0973e-02, -1.3134e+06,  4.2840e-01,  9.0436e-02,\n",
              "         5.2720e-01,  3.0557e+00,  5.2901e-01,  5.3602e-01,  5.1297e-01,\n",
              "         5.1504e-01,  5.1411e-01,  5.1419e-01,  5.1414e-01,  5.3762e-01,\n",
              "         7.6119e-02,  9.0955e-02, -3.0039e+04,  5.1365e-01,  3.5049e+00],\n",
              "       dtype=torch.float64, grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sums_shaping = sums_states_weight_diff + gamma_weights_states_last_sub_states_first"
      ],
      "metadata": {
        "id": "cQwdg78It-sd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mean(sums_shaping)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpNY7q-guFCA",
        "outputId": "21738905-c107-4f20-9480-a0e1cead242f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-9.7904e+39, dtype=torch.float64, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the min and max values of tensors\n",
        "print(\"padded_weight_diff_tensors - Min:\", padded_weight_diff_tensors.min().item(), \" Max:\", padded_weight_diff_tensors.max().item())\n",
        "print(\"sums_states_weight_diff - Min:\", sums_states_weight_diff.min().item(), \" Max:\", sums_states_weight_diff.max().item())\n",
        "print(\"gamma_weights_last_tensor - Min:\", gamma_weights_last_tensor.min().item(), \" Max:\", gamma_weights_last_tensor.max().item())\n",
        "print(\"samples_IS - Min:\", samples_IS.min().item(), \" Max:\", samples_IS.max().item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RZCBfD9vwRx",
        "outputId": "ebaecd5c-ec6a-430d-f578-ee4fc5fe8ddd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "padded_weight_diff_tensors - Min: -6979572071212940.0  Max: 1.839130399958296e+16\n",
            "sums_states_weight_diff - Min: -5225342891061462.0  Max: 1365487.6953395614\n",
            "gamma_weights_last_tensor - Min: 1.846463839642936e-238  Max: 143894458319084.28\n",
            "samples_IS - Min: -10076.89890923087  Max: 159882731465649.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mean(sample_sums_states_weight_diff,dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lj6mSyUmUqqp",
        "outputId": "21a53d42-836a-4dc8-d67f-ba381264b891"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-9.9641e+39, -2.6692e+27, -9.9641e+39,  ..., -1.9928e+40,\n",
              "        -2.9892e+40, -1.3346e+27], dtype=torch.float64,\n",
              "       grad_fn=<MeanBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mean(samples_gamma_weight_states_last_sub_states_first, dim =1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYJ0CkAeUxYJ",
        "outputId": "9c9fe1d0-8246-427a-e25a-4704db91823d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.7368e+38, 5.5852e+13, 1.7368e+38,  ..., 3.4735e+38, 5.2103e+38,\n",
              "        2.7925e+13], dtype=torch.float64, grad_fn=<MeanBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fpf1bgqIRAzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calc Variance"
      ],
      "metadata": {
        "id": "wwmn8QMhO5QN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_shaped_variance(samples_IS, sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, samples_all_shaping, samples_IS_SCOPE):\n",
        "\n",
        "  # states_output, states_first_output, states_last_output = pass_states(model, padded_state_tensors, states_first_tensor, states_last_tensor)\n",
        "\n",
        "  # Begin calcs without clamping\n",
        "\n",
        "  # IS\n",
        "  E_IS_sq = torch.mean(torch.mean(samples_IS, dim = 1)**2)\n",
        "  E_IS_all_sq = torch.mean(torch.mean(samples_IS, dim = 1))**2\n",
        "\n",
        "  # states_weight_diff\n",
        "  E_s_wdiff_sq = torch.mean(torch.mean(sample_sums_states_weight_diff, dim =1)**2)\n",
        "  E_s_wdiff_all_sq = torch.mean(torch.mean(sample_sums_states_weight_diff, dim = 1))**2\n",
        "\n",
        "  # all terms\n",
        "  SCOPE = sample_sums_states_weight_diff+samples_gamma_weight_states_last_sub_states_first\n",
        "  E_IS_SCOPE = torch.mean(torch.mean(samples_IS, dim =1) * torch.mean(SCOPE, dim =1))\n",
        "  E_IS_E_SCOPE = torch.mean(torch.mean(samples_IS,dim = 1 ))*torch.mean(torch.mean(SCOPE, dim =1))\n",
        "\n",
        "  # E_IS_SCOPE = torch.mean(torch.mean(samples_IS_SCOPE, dim =1))\n",
        "  # E_IS_E_SCOPE = torch.mean(torch.mean(samples_IS,dim = 1 )) * torch.mean(torch.mean(samples_all_shaping, dim =1))\n",
        "\n",
        "\n",
        "\n",
        "  # SCOPE_variance = E_IS_sq + 2*E_IS_SCOPE + E_s_wdiff_sq - E_IS_all_sq - 2*E_IS_E_SCOPE - E_IS_E_SCOPE\n",
        "  SCOPE_variance = E_IS_sq + 2*E_IS_SCOPE + E_s_wdiff_sq - E_IS_all_sq - 2*E_IS_E_SCOPE - E_s_wdiff_all_sq\n",
        "\n",
        "  IS_variance = E_IS_sq - E_IS_all_sq\n",
        "\n",
        "  return E_IS_sq, E_IS_all_sq, E_s_wdiff_sq, E_s_wdiff_all_sq, E_IS_SCOPE, E_IS_E_SCOPE, IS_variance, SCOPE_variance\n"
      ],
      "metadata": {
        "id": "WlDazbYPvvrg"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SCOPE = sample_sums_states_weight_diff-samples_gamma_weight_states_last_sub_states_first\n"
      ],
      "metadata": {
        "id": "ut3fyQ4s1l-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_,_,_,_,_,_,IS_variance, SCOPE_variance = calculate_shaped_variance(samples_IS, sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, samples_all_shaping, samples_IS_SCOPE)"
      ],
      "metadata": {
        "id": "yWcJ_iSFvvru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'IS Variance: {IS_variance.item()} SCOPE Variance: {SCOPE_variance.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ecraXkwWRcI",
        "outputId": "0b7a14e9-64a6-4c20-98a0-f958228fad62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IS Variance: 2.514807940970177e+22 SCOPE Variance: 5.892057226414652e+25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SCOPE_variance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJtda6na7iFY",
        "outputId": "ce79b72f-e4fc-4ab7-c2b7-6e09fb2db4ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2.0262e+82, 1.7582e+80, 2.0262e+82,  ..., 4.0349e+82, 6.0435e+82,\n",
              "        1.7582e+80], dtype=torch.float64, grad_fn=<SubBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimizing"
      ],
      "metadata": {
        "id": "InzaU1hEzXaK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "wEeNxHjkz9Gx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "def train_var(model, num_epochs, learning_rate, padded_state_tensors, states_first_tensor, states_last_tensor, test1):\n",
        "    model.train()\n",
        "\n",
        "    # Enable anomaly detection\n",
        "    torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "\n",
        "        # Forward pass\n",
        "        states_output, states_first_output, states_last_output = test1.pass_states(model, padded_state_tensors, states_first_tensor, states_last_tensor)\n",
        "        sums_states_weight_diff = test1.states_weight_diff_sums(states_output, padded_weight_diff_tensors)\n",
        "        gamma_weights_states_last_sub_states_first = test1.last_first_terms_operations(gamma_weights_last_tensor, states_last_output, states_first_output, weight_first_tensor)\n",
        "        # sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, samples_all_shaping, samples_IS_SCOPE = test1.bootstrap_shaping_terms(sums_states_weight_diff, gamma_weights_states_last_sub_states_first, IS_tensor)\n",
        "\n",
        "        samples_IS, sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, samples_all_shaping, samples_IS_SCOPE = test1.bootstrap_all_terms(sums_states_weight_diff, gamma_weights_states_last_sub_states_first, IS_tensor)\n",
        "\n",
        "\n",
        "        E_IS_sq, E_IS_all_sq, E_s_wdiff_sq, E_s_wdiff_all_sq, E_IS_SCOPE, E_IS_E_SCOPE, _, variance_loss = calculate_shaped_variance(samples_IS, sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, samples_all_shaping, samples_IS_SCOPE)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}\")\n",
        "        print(\"Var loss: \", variance_loss)\n",
        "\n",
        "        # Print each term\n",
        "        print(f\"E_IS_sq: {E_IS_sq}\")\n",
        "        print(f\"E_IS_all_sq: {E_IS_all_sq}\")\n",
        "        print(f\"E_s_wdiff_sq: {E_s_wdiff_sq}\")\n",
        "        print(f\"E_s_wdiff_all_sq: {E_s_wdiff_all_sq}\")\n",
        "        print(f\"E_IS_SCOPE: {E_IS_SCOPE}\")\n",
        "        print(f\"E_IS_E_SCOPE: {E_IS_E_SCOPE}\")\n",
        "\n",
        "        tot = variance_loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Retain the graph to avoid clearing it before backward pass\n",
        "        tot.backward(retain_graph=True)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += tot.item()\n",
        "\n",
        "        print(f\"Total Loss: {total_loss}\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "    # Disable anomaly detection after running the code\n",
        "    torch.autograd.set_detect_anomaly(False)\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            print(f\"Parameter name: {name}\")\n",
        "            print(f\"Weights: {param.data}\")\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "lEfGUHfGNwiJ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = train_var(model, 20, 0.0001, samples_IS, padded_state_tensors, states_first_tensor, states_last_tensor, samples_all_shaping, samples_IS_SCOPE, test1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0zmGSWkVyC_",
        "outputId": "18597fc2-7ea7-4000-98c0-75ccad13417b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Var loss:  tensor(-3.0838e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 5.210967549166126e+22\n",
            "E_s_wdiff_all_sq: 2.5172984363039316e+22\n",
            "E_IS_SCOPE: -1.5459488896936224e+25\n",
            "E_IS_E_SCOPE: -1.4417566494849713e+22\n",
            "Total Loss: -3.0838057890344423e+25\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "Var loss:  tensor(-3.3585e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 6.546944000346388e+22\n",
            "E_s_wdiff_all_sq: 3.517525168586692e+22\n",
            "E_IS_SCOPE: -1.6839284068856547e+25\n",
            "E_IS_E_SCOPE: -1.8983210591791954e+22\n",
            "Total Loss: -3.358515944880221e+25\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "Var loss:  tensor(-3.6329e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 8.127328468140865e+22\n",
            "E_s_wdiff_all_sq: 4.669789629828819e+22\n",
            "E_IS_SCOPE: -1.8217910544502339e+25\n",
            "E_IS_E_SCOPE: -2.3493888489215494e+22\n",
            "Total Loss: -3.632910984423342e+25\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "Var loss:  tensor(-3.9072e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 9.956227907220597e+22\n",
            "E_s_wdiff_all_sq: 5.9793486972912325e+22\n",
            "E_IS_SCOPE: -1.959656202176037e+25\n",
            "E_IS_E_SCOPE: -2.7986036228854552e+22\n",
            "Total Loss: -3.907223509955403e+25\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "Var loss:  tensor(-4.1814e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2030804144930232e+23\n",
            "E_s_wdiff_all_sq: 7.444645256087994e+22\n",
            "E_IS_SCOPE: -2.0974953048619344e+25\n",
            "E_IS_E_SCOPE: -3.2460902003401042e+22\n",
            "Total Loss: -4.1813974624933755e+25\n",
            "----------------------------------------\n",
            "Epoch 6\n",
            "Var loss:  tensor(-4.4554e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.4346387559415976e+23\n",
            "E_s_wdiff_all_sq: 9.062655780558345e+22\n",
            "E_IS_SCOPE: -2.235296219189662e+25\n",
            "E_IS_E_SCOPE: -3.6915356807178387e+22\n",
            "Total Loss: -4.4554108272980605e+25\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "Var loss:  tensor(-4.7293e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.6896450448835388e+23\n",
            "E_s_wdiff_all_sq: 1.08290772380101e+23\n",
            "E_IS_SCOPE: -2.3730518621395594e+25\n",
            "E_IS_E_SCOPE: -4.134422009246762e+22\n",
            "Total Loss: -4.72925269910883e+25\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "Var loss:  tensor(-5.0029e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.9673881915757514e+23\n",
            "E_s_wdiff_all_sq: 1.2739332729182658e+23\n",
            "E_IS_SCOPE: -2.5107576940337e+25\n",
            "E_IS_E_SCOPE: -4.574329549359406e+22\n",
            "Total Loss: -5.0029173718411355e+25\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "Var loss:  tensor(-5.2764e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 2.267249722521212e+23\n",
            "E_s_wdiff_all_sq: 1.4789613654870718e+23\n",
            "E_IS_SCOPE: -2.6484105436396702e+25\n",
            "E_IS_E_SCOPE: -5.011115472982626e+22\n",
            "Total Loss: -5.276401164822063e+25\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "Var loss:  tensor(-5.5497e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 2.5887526111029046e+23\n",
            "E_s_wdiff_all_sq: 1.6977134979120384e+23\n",
            "E_IS_SCOPE: -2.786008235633142e+25\n",
            "E_IS_E_SCOPE: -5.444868998604533e+22\n",
            "Total Loss: -5.549701534196196e+25\n",
            "----------------------------------------\n",
            "Epoch 11\n",
            "Var loss:  tensor(-5.8228e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 2.93150580846501e+23\n",
            "E_s_wdiff_all_sq: 1.9299681728485064e+23\n",
            "E_IS_SCOPE: -2.9235491360209344e+25\n",
            "E_IS_E_SCOPE: -5.875756424517042e+22\n",
            "Total Loss: -5.822816574895699e+25\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "Var loss:  tensor(-6.0957e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 3.2951384287536245e+23\n",
            "E_s_wdiff_all_sq: 2.1755135214562837e+23\n",
            "E_IS_SCOPE: -3.061031877917925e+25\n",
            "E_IS_E_SCOPE: -6.303918086962085e+22\n",
            "Total Loss: -6.095744862647982e+25\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "Var loss:  tensor(-6.3685e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 3.67926590345648e+23\n",
            "E_s_wdiff_all_sq: 2.434124883277089e+23\n",
            "E_IS_SCOPE: -3.1984552495154813e+25\n",
            "E_IS_E_SCOPE: -6.729439799700456e+22\n",
            "Total Loss: -6.368485401288798e+25\n",
            "----------------------------------------\n",
            "Epoch 14\n",
            "Var loss:  tensor(-6.6411e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 4.083511343418876e+23\n",
            "E_s_wdiff_all_sq: 2.7055798170633747e+23\n",
            "E_IS_SCOPE: -3.3358493269605055e+25\n",
            "E_IS_E_SCOPE: -7.152390355712248e+22\n",
            "Total Loss: -6.641099750005061e+25\n",
            "----------------------------------------\n",
            "Epoch 15\n",
            "Var loss:  tensor(-6.9135e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 4.507797613123608e+23\n",
            "E_s_wdiff_all_sq: 2.9898588786408246e+23\n",
            "E_IS_SCOPE: -3.47318020008451e+25\n",
            "E_IS_E_SCOPE: -7.573118707256295e+22\n",
            "Total Loss: -6.91351996746871e+25\n",
            "----------------------------------------\n",
            "Epoch 16\n",
            "Var loss:  tensor(-7.1858e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 4.9525968530722806e+23\n",
            "E_s_wdiff_all_sq: 3.287304205334282e+23\n",
            "E_IS_SCOPE: -3.6104516466931023e+25\n",
            "E_IS_E_SCOPE: -7.992410040288414e+22\n",
            "Total Loss: -7.185750738887278e+25\n",
            "----------------------------------------\n",
            "Epoch 17\n",
            "Var loss:  tensor(-7.4578e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 5.422597581911685e+23\n",
            "E_s_wdiff_all_sq: 3.6010637596031907e+23\n",
            "E_IS_SCOPE: -3.7476645794703584e+25\n",
            "E_IS_E_SCOPE: -8.414638867962763e+22\n",
            "Total Loss: -7.457769735040736e+25\n",
            "----------------------------------------\n",
            "Epoch 18\n",
            "Var loss:  tensor(-7.7296e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 5.912088932901162e+23\n",
            "E_s_wdiff_all_sq: 3.9273065020191513e+23\n",
            "E_IS_SCOPE: -3.884814950188801e+25\n",
            "E_IS_E_SCOPE: -8.834554946761315e+22\n",
            "Total Loss: -7.7295981582342884e+25\n",
            "----------------------------------------\n",
            "Epoch 19\n",
            "Var loss:  tensor(-8.0012e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 6.420042041666823e+23\n",
            "E_s_wdiff_all_sq: 4.2653734809269504e+23\n",
            "E_IS_SCOPE: -4.021901783374139e+25\n",
            "E_IS_E_SCOPE: -9.251635569965136e+22\n",
            "Total Loss: -8.001238802059979e+25\n",
            "----------------------------------------\n",
            "Epoch 20\n",
            "Var loss:  tensor(-8.2727e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 6.945934268931316e+23\n",
            "E_s_wdiff_all_sq: 4.614945900147421e+23\n",
            "E_IS_SCOPE: -4.158924544997166e+25\n",
            "E_IS_E_SCOPE: -9.665836613397322e+22\n",
            "Total Loss: -8.272692725138728e+25\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[-0.4510,  0.0021],\n",
            "        [ 0.3396,  0.6556],\n",
            "        [-0.0427,  0.1722],\n",
            "        [-0.1050, -0.3208],\n",
            "        [ 0.6667,  0.6256],\n",
            "        [ 0.0633, -0.0869],\n",
            "        [-0.5012,  0.5401],\n",
            "        [-0.2295, -0.6730],\n",
            "        [-0.2369, -0.6463],\n",
            "        [-0.3752, -0.3359],\n",
            "        [-0.6697,  0.5156],\n",
            "        [-0.2812,  0.2000],\n",
            "        [-0.1604,  0.5577],\n",
            "        [-0.5985, -0.1328],\n",
            "        [-0.4052, -0.3473],\n",
            "        [-0.2117,  0.0203]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([-0.5800,  0.0521,  0.6555,  0.4989, -0.2725,  0.2633, -0.4585,  0.6680,\n",
            "         0.4422,  0.6497,  0.6227,  0.4099, -0.5805,  0.7856,  0.5691,  0.2211],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[ 1.7559e-01,  1.6233e-01,  2.3772e-01,  2.2629e-01,  1.8467e-01,\n",
            "          3.0120e-01, -2.3406e-01, -1.8666e-01,  7.2061e-02,  2.3042e-01,\n",
            "         -3.1664e-02, -1.7317e-01, -5.9300e-02,  2.1983e-01, -2.3025e-01,\n",
            "         -2.5168e-01],\n",
            "        [ 7.1529e-03,  2.4635e-01, -1.0106e-01, -1.2429e-01, -1.5923e-01,\n",
            "         -1.8235e-02,  1.4430e-02, -1.5267e-01,  1.9970e-01, -2.2146e-02,\n",
            "         -2.2856e-01, -1.7931e-01,  1.9001e-01,  2.4006e-02,  2.1272e-01,\n",
            "          9.1185e-02],\n",
            "        [-6.1545e-02, -1.6846e-01, -1.9149e-01,  9.8640e-02, -2.1220e-01,\n",
            "          1.1819e-01,  9.9572e-02, -1.0969e-01,  1.8555e-01,  2.3056e-01,\n",
            "         -7.3723e-02, -6.4354e-02,  1.8917e-01,  1.4870e-01, -1.2193e-01,\n",
            "          1.9635e-01],\n",
            "        [ 1.9140e-01,  5.9702e-02,  2.0254e-01, -5.3336e-02, -1.2643e-01,\n",
            "          1.1372e-01, -2.2702e-01, -1.5411e-01,  1.7170e-01, -1.0972e-01,\n",
            "         -6.0289e-02,  1.4019e-01, -1.7271e-01,  3.9220e-01, -8.3202e-02,\n",
            "         -1.3331e-01],\n",
            "        [-2.2063e-01, -2.3476e-01, -2.0329e-01,  1.1068e-02,  2.1729e-01,\n",
            "         -2.8234e-01,  8.6570e-02, -9.5660e-02, -1.9528e-01,  8.0604e-02,\n",
            "          7.2492e-02, -1.7119e-01, -1.3159e-01,  9.6841e-02,  1.2702e-01,\n",
            "         -2.1615e-01],\n",
            "        [-1.5366e-01,  1.9952e-01, -3.9314e-02, -1.4778e-01, -1.5110e-01,\n",
            "          8.4972e-02, -2.8361e-01,  6.8140e-02, -1.6945e-01,  2.4092e-02,\n",
            "         -1.8115e-01, -2.7334e-02, -3.8245e-02,  7.6595e-02, -6.4935e-02,\n",
            "          2.7648e-01],\n",
            "        [ 7.1929e-03, -8.6183e-02,  1.9110e-01,  1.1232e-01,  1.7308e-01,\n",
            "         -5.8804e-02, -2.2953e-01, -2.3573e-02, -2.7324e-02,  1.1141e-01,\n",
            "         -2.1644e-01,  2.0180e-01,  1.1418e-02, -1.7533e-01,  1.6569e-01,\n",
            "          1.9179e-01],\n",
            "        [ 3.6563e-02,  2.7998e-02,  2.6304e-01, -1.8567e-01,  1.8540e-01,\n",
            "         -1.3270e-01,  7.6032e-02, -2.9636e-02, -2.1079e-04, -1.0609e-01,\n",
            "          2.2287e-01, -2.2479e-01,  1.1056e-01, -2.3385e-01, -1.6760e-01,\n",
            "          9.9343e-02],\n",
            "        [ 1.7877e-01, -1.1848e-01,  2.7068e-02,  9.9388e-02,  2.4131e-01,\n",
            "         -1.5313e-01,  2.0315e-01, -1.8985e-01, -1.1247e-01, -1.1768e-02,\n",
            "         -2.8191e-02, -7.7164e-02,  1.1229e-01, -2.7218e-01, -9.0932e-02,\n",
            "         -1.9059e-01],\n",
            "        [ 1.5427e-01, -1.1397e-01,  2.4423e-01,  6.1690e-02, -2.4008e-03,\n",
            "          5.1089e-02,  1.0899e-01,  1.0263e-01, -1.7723e-02,  7.6825e-02,\n",
            "          4.6833e-02,  1.8567e-01,  6.8519e-03, -5.1221e-02,  7.3215e-02,\n",
            "          2.1663e-02],\n",
            "        [ 3.0704e-02,  1.6847e-01,  1.9887e-01, -1.9659e-01,  1.6256e-03,\n",
            "          2.7731e-01, -4.4841e-02, -1.0408e-01, -2.2601e-01, -1.8564e-01,\n",
            "          1.8752e-01, -1.7683e-01, -1.8726e-01,  1.9871e-01, -3.5240e-02,\n",
            "         -1.3091e-01],\n",
            "        [ 3.1929e-02,  3.2215e-02,  1.5373e-01, -2.2811e-01, -5.2812e-02,\n",
            "          1.1565e-01, -1.0283e-01,  1.9907e-01,  3.4308e-02, -1.2375e-01,\n",
            "          1.0030e-01,  7.0572e-02, -7.3479e-02, -5.4203e-02, -4.8761e-02,\n",
            "         -1.7009e-01],\n",
            "        [ 1.8268e-01, -3.1818e-02, -2.7465e-01,  2.0304e-01, -2.5103e-01,\n",
            "          1.3380e-01,  5.7078e-02, -1.6024e-01,  2.3616e-01,  1.3602e-01,\n",
            "          1.8643e-01, -1.7847e-01, -1.6410e-01,  2.1505e-01, -1.4369e-01,\n",
            "         -4.8390e-02],\n",
            "        [-1.3087e-01,  1.1866e-01,  3.6743e-02, -1.4394e-01, -1.1981e-01,\n",
            "         -7.0510e-02,  8.3873e-03,  1.4202e-01,  5.7004e-02,  2.4725e-01,\n",
            "          1.7666e-02, -2.3482e-01, -2.2211e-01,  2.0162e-01,  8.6532e-02,\n",
            "          7.8177e-02],\n",
            "        [-1.4544e-01, -3.7057e-01,  3.0520e-01, -7.4018e-02, -3.4248e-02,\n",
            "         -3.6749e-02, -5.1584e-02, -1.4300e-01,  7.9773e-02, -1.7701e-01,\n",
            "          2.3044e-01, -4.2904e-01, -1.0584e-01, -1.3126e-01,  1.9303e-02,\n",
            "          2.8921e-01],\n",
            "        [-2.4521e-01,  2.4946e-01, -3.0612e-01,  4.3380e-02, -1.0360e-02,\n",
            "          4.2349e-02,  7.6393e-02, -1.4996e-01,  2.6837e-02, -1.2947e-01,\n",
            "         -6.0119e-02, -1.2891e-01, -2.9666e-01,  7.5903e-03,  1.1003e-01,\n",
            "         -1.3607e-01],\n",
            "        [-2.3086e-01,  1.2024e-01, -1.7377e-01,  1.9102e-01, -1.4026e-01,\n",
            "         -2.1704e-01,  2.3345e-01,  1.8437e-01, -3.6461e-02, -2.4583e-01,\n",
            "         -4.0944e-01, -3.2514e-01, -3.4505e-01,  2.2425e-01,  2.4350e-03,\n",
            "          2.9624e-01],\n",
            "        [ 1.7996e-01,  6.2290e-03,  4.7523e-02,  1.1118e-02,  1.6657e-01,\n",
            "         -9.6748e-03,  1.1051e-01, -2.2243e-01,  7.2220e-02, -1.1556e-01,\n",
            "          3.8988e-02, -2.0665e-01,  5.8580e-02,  1.9515e-01, -1.9692e-01,\n",
            "         -1.6146e-01],\n",
            "        [-2.4386e-01, -1.9133e-01,  3.3801e-02, -2.1412e-01,  1.1644e-01,\n",
            "         -3.6942e-01, -1.6242e-01, -1.4523e-01,  1.8902e-01,  8.2447e-02,\n",
            "         -4.7722e-01,  5.2936e-02, -9.7944e-02,  9.3941e-02,  5.6936e-02,\n",
            "         -2.5046e-01],\n",
            "        [-2.1121e-02, -3.0001e-01, -4.9378e-02,  1.1902e-01,  7.8042e-02,\n",
            "          3.1770e-01,  3.9925e-02,  2.2312e-01,  5.2246e-02,  9.3138e-02,\n",
            "          1.1217e-01,  5.3098e-02,  2.2271e-01,  3.9138e-01,  5.3523e-02,\n",
            "         -1.2653e-01],\n",
            "        [ 1.9650e-01, -1.4172e-01,  2.8714e-02, -2.9400e-02,  2.3476e-01,\n",
            "          2.9832e-01,  1.4017e-01,  2.4546e-01,  9.2309e-03,  1.0585e-01,\n",
            "         -1.4108e-01, -1.6467e-01, -2.5441e-01,  1.3023e-01,  5.3941e-02,\n",
            "          3.4543e-02],\n",
            "        [ 6.2436e-02, -8.1427e-02,  6.8004e-03, -2.4202e-01, -6.0287e-02,\n",
            "         -1.4947e-01,  1.9532e-01, -2.4530e-01, -2.7072e-02,  1.3022e-01,\n",
            "          3.4743e-01,  1.9774e-01,  5.8964e-02, -4.1659e-02,  1.8627e-01,\n",
            "         -1.6851e-01],\n",
            "        [-2.3660e-01,  1.4217e-01, -2.7298e-01, -2.3568e-01,  1.8135e-01,\n",
            "         -9.9376e-02, -2.1404e-01, -7.8582e-02, -7.0298e-02, -1.0721e-02,\n",
            "          1.1153e-01,  1.2434e-01,  1.4717e-01,  1.4747e-01,  1.7566e-01,\n",
            "          1.6961e-01],\n",
            "        [-2.1504e-01, -5.6804e-02,  1.2303e-01, -1.2970e-01, -9.0758e-04,\n",
            "          9.0054e-02, -1.4854e-01, -5.5772e-03, -3.3620e-02, -1.3572e-01,\n",
            "         -1.2283e-01, -3.5842e-02,  2.0300e-01,  1.7445e-01,  1.9926e-01,\n",
            "          1.4480e-02],\n",
            "        [-1.8815e-02, -8.8772e-02,  1.6216e-01,  3.7306e-02,  1.0765e-01,\n",
            "         -2.1936e-02,  1.8456e-01,  1.4760e-01, -7.9331e-02,  1.5561e-01,\n",
            "          2.0303e-01, -1.4509e-01, -8.1366e-02, -3.1612e-01,  5.6964e-02,\n",
            "         -1.7146e-01],\n",
            "        [ 2.7233e-04,  2.0508e-01,  2.3661e-01,  3.0674e-02,  1.2631e-01,\n",
            "          7.2449e-02, -2.0767e-01,  6.0481e-02,  5.9943e-02,  1.2595e-01,\n",
            "         -1.5610e-01, -1.2661e-01,  2.0987e-01, -2.9389e-01, -2.3863e-01,\n",
            "          1.8265e-01],\n",
            "        [-2.3910e-01,  2.7046e-01,  1.7394e-01,  1.4304e-01,  2.2724e-01,\n",
            "          1.5284e-01,  6.0089e-02, -2.4203e-02,  1.4016e-01,  1.2150e-01,\n",
            "          1.1739e-01,  4.5788e-02, -2.4074e-01,  7.2400e-02, -1.8276e-01,\n",
            "         -1.9739e-01],\n",
            "        [ 3.0014e-02,  8.0140e-03, -3.5501e-02,  1.3929e-01, -2.8273e-01,\n",
            "         -8.2736e-02, -2.0914e-01, -1.9566e-01,  1.4068e-01, -2.0598e-01,\n",
            "          1.6162e-01,  1.1231e-01,  1.1277e-01, -6.3876e-02, -5.7794e-02,\n",
            "         -4.4601e-02],\n",
            "        [-6.8022e-02,  1.2553e-01, -7.4896e-02,  5.8154e-02,  1.5711e-01,\n",
            "         -2.2227e-01,  1.3049e-01, -1.2746e-01, -2.7043e-02, -7.6503e-03,\n",
            "          2.5763e-02,  7.0767e-02, -5.9477e-03, -4.2300e-01, -9.2563e-02,\n",
            "          1.0574e-01],\n",
            "        [ 2.4462e-01, -4.4803e-02,  6.5335e-02,  2.1805e-01,  2.5980e-01,\n",
            "          1.4863e-02,  1.3684e-01,  1.9241e-01, -1.3083e-01,  1.8042e-01,\n",
            "         -9.6065e-02,  1.9216e-01,  1.2768e-01, -3.9125e-02,  8.0967e-02,\n",
            "          6.9863e-02],\n",
            "        [-2.0339e-01, -1.3332e-01,  1.2844e-02, -2.4017e-01,  1.1610e-01,\n",
            "         -1.6190e-01, -5.8829e-02,  1.3671e-01, -6.2188e-02,  1.3888e-01,\n",
            "          1.7607e-01,  1.4970e-01,  6.7824e-02,  7.6705e-02,  7.5816e-02,\n",
            "         -1.3883e-01],\n",
            "        [-8.8667e-02, -9.7587e-02,  7.9214e-02, -1.6263e-01, -3.5249e-02,\n",
            "          5.5645e-02, -2.3595e-02,  7.8961e-02, -1.2570e-01,  2.1665e-01,\n",
            "          2.7871e-02,  1.2805e-01,  4.8840e-02,  7.5699e-02, -1.5474e-01,\n",
            "         -1.3606e-01]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([ 0.0152, -0.0980,  0.0864,  0.0689,  0.2498, -0.0135,  0.1991,  0.1723,\n",
            "         0.1992, -0.0625,  0.1075, -0.0684,  0.2318, -0.0104, -0.2247, -0.0120,\n",
            "        -0.1201,  0.2344,  0.0327,  0.0824,  0.2338,  0.0025, -0.0555, -0.2357,\n",
            "         0.0321, -0.2639,  0.1652,  0.0119,  0.0660,  0.0135, -0.1878, -0.2406],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[ 0.0168,  0.1780,  0.1248,  0.0681, -0.1202, -0.0241,  0.1450, -0.0256,\n",
            "         -0.0325, -0.1131,  0.1277, -0.0804,  0.0521,  0.0330,  0.1509,  0.0562,\n",
            "         -0.1326,  0.0699, -0.1098,  0.1518,  0.1084, -0.3186,  0.1366, -0.1010,\n",
            "         -0.0525, -0.0417,  0.0804, -0.0123, -0.1114, -0.0858, -0.1678,  0.1389]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([-0.0005], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model5 = train_var(model4, 500, 0.0001, samples_IS, padded_state_tensors, states_first_tensor, states_last_tensor, samples_all_shaping, samples_IS_SCOPE, test1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "K7RunrrFPEy7",
        "outputId": "fa9e6784-1b9a-4a4f-be7b-e7e99b2b6a1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Var loss:  tensor(1.6838e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2080531216272573e+22\n",
            "E_s_wdiff_all_sq: 7.854446300022197e+18\n",
            "E_IS_SCOPE: -3.2924307594909997e+22\n",
            "E_IS_E_SCOPE: -1.0101281026055919e+22\n",
            "Total Loss: 1.683838514322106e+21\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "Var loss:  tensor(2.4018e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.5681370975049804e+22\n",
            "E_s_wdiff_all_sq: 5.3651102132735515e+20\n",
            "E_IS_SCOPE: -2.958920317364135e+22\n",
            "E_IS_E_SCOPE: -6.916923741107582e+21\n",
            "Total Loss: 2.401815260791626e+21\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "Var loss:  tensor(2.3126e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.060980670643068e+22\n",
            "E_s_wdiff_all_sq: 2.9444178650483524e+20\n",
            "E_IS_SCOPE: -3.670629845441955e+22\n",
            "E_IS_E_SCOPE: -1.3322424158069409e+22\n",
            "Total Loss: 2.3125616815015744e+21\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "Var loss:  tensor(2.2341e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.0633852358230838e+22\n",
            "E_s_wdiff_all_sq: 2.5690002961311597e+20\n",
            "E_IS_SCOPE: -3.649677342924772e+22\n",
            "E_IS_E_SCOPE: -1.3148560016495734e+22\n",
            "Total Loss: 2.2340649589243705e+21\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "Var loss:  tensor(1.6178e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2198354392569919e+22\n",
            "E_s_wdiff_all_sq: 3.652535509560464e+18\n",
            "E_IS_SCOPE: -3.332237717470749e+22\n",
            "E_IS_E_SCOPE: -1.0305375073970072e+22\n",
            "Total Loss: 1.6178046747669262e+21\n",
            "----------------------------------------\n",
            "Epoch 6\n",
            "Var loss:  tensor(2.0155e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.4497548452943698e+22\n",
            "E_s_wdiff_all_sq: 3.101753381008754e+20\n",
            "E_IS_SCOPE: -3.054246607770964e+22\n",
            "E_IS_E_SCOPE: -7.818279936741865e+21\n",
            "Total Loss: 2.0155355174517866e+21\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "Var loss:  tensor(2.0581e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.4616360950367095e+22\n",
            "E_s_wdiff_all_sq: 3.4398198073409634e+20\n",
            "E_IS_SCOPE: -3.036719256598841e+22\n",
            "E_IS_E_SCOPE: -7.676013074519667e+21\n",
            "Total Loss: 2.0580944516510541e+21\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "Var loss:  tensor(1.6603e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2939949932413746e+22\n",
            "E_s_wdiff_all_sq: 7.213751316865191e+19\n",
            "E_IS_SCOPE: -3.213132082516763e+22\n",
            "E_IS_E_SCOPE: -9.278309953212547e+21\n",
            "Total Loss: 1.6603175514178983e+21\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "Var loss:  tensor(1.6789e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.1369778160525388e+22\n",
            "E_s_wdiff_all_sq: 1.6735233495303238e+19\n",
            "E_IS_SCOPE: -3.4343132217582195e+22\n",
            "E_IS_E_SCOPE: -1.1282428200323708e+22\n",
            "Total Loss: 1.6788777360338956e+21\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "Var loss:  tensor(1.9160e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.0759040073523123e+22\n",
            "E_s_wdiff_all_sq: 1.146480960753118e+20\n",
            "E_IS_SCOPE: -3.550444204464186e+22\n",
            "E_IS_E_SCOPE: -1.2339266693254665e+22\n",
            "Total Loss: 1.9160354737051664e+21\n",
            "----------------------------------------\n",
            "Epoch 11\n",
            "Var loss:  tensor(1.7996e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.0934688991814363e+22\n",
            "E_s_wdiff_all_sq: 6.6358570149114085e+19\n",
            "E_IS_SCOPE: -3.5050020881405305e+22\n",
            "E_IS_E_SCOPE: -1.1938953376668441e+22\n",
            "Total Loss: 1.7995867687108477e+21\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "Var loss:  tensor(1.5873e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.177134347775273e+22\n",
            "E_s_wdiff_all_sq: 2.4829363686499043e+17\n",
            "E_IS_SCOPE: -3.352526279960078e+22\n",
            "E_IS_E_SCOPE: -1.057280545146834e+22\n",
            "Total Loss: 1.5873136426579615e+21\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "Var loss:  tensor(1.6518e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2952111814378758e+22\n",
            "E_s_wdiff_all_sq: 9.31244535538539e+19\n",
            "E_IS_SCOPE: -3.191352877889636e+22\n",
            "E_IS_E_SCOPE: -9.126238020662737e+21\n",
            "Total Loss: 1.6518477282760217e+21\n",
            "----------------------------------------\n",
            "Epoch 14\n",
            "Var loss:  tensor(1.7801e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.359938149685174e+22\n",
            "E_s_wdiff_all_sq: 1.9379745607524398e+20\n",
            "E_IS_SCOPE: -3.1165569678760726e+22\n",
            "E_IS_E_SCOPE: -8.454597465652572e+21\n",
            "Total Loss: 1.780113945989774e+21\n",
            "----------------------------------------\n",
            "Epoch 15\n",
            "Var loss:  tensor(1.6882e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.3203151331044018e+22\n",
            "E_s_wdiff_all_sq: 1.319710181949291e+20\n",
            "E_IS_SCOPE: -3.1602686497240834e+22\n",
            "E_IS_E_SCOPE: -8.847446901451736e+21\n",
            "Total Loss: 1.688198450619331e+21\n",
            "----------------------------------------\n",
            "Epoch 16\n",
            "Var loss:  tensor(1.5562e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2215919712213322e+22\n",
            "E_s_wdiff_all_sq: 2.0899687616620753e+19\n",
            "E_IS_SCOPE: -3.283190220996491e+22\n",
            "E_IS_E_SCOPE: -9.951990093450058e+21\n",
            "Total Loss: 1.5561649823354454e+21\n",
            "----------------------------------------\n",
            "Epoch 17\n",
            "Var loss:  tensor(1.6003e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.1377950739780977e+22\n",
            "E_s_wdiff_all_sq: 6.728656834605102e+18\n",
            "E_IS_SCOPE: -3.4107211151752986e+22\n",
            "E_IS_E_SCOPE: -1.1096232306045503e+22\n",
            "Total Loss: 1.6003047641132869e+21\n",
            "----------------------------------------\n",
            "Epoch 18\n",
            "Var loss:  tensor(1.6798e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.1052807949431192e+22\n",
            "E_s_wdiff_all_sq: 3.5202491836908536e+19\n",
            "E_IS_SCOPE: -3.471015741715299e+22\n",
            "E_IS_E_SCOPE: -1.163307656577775e+22\n",
            "Total Loss: 1.6798022221602352e+21\n",
            "----------------------------------------\n",
            "Epoch 19\n",
            "Var loss:  tensor(1.6168e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.1245231656492002e+22\n",
            "E_s_wdiff_all_sq: 1.5721640040077249e+19\n",
            "E_IS_SCOPE: -3.43792134152922e+22\n",
            "E_IS_E_SCOPE: -1.1327314441601773e+22\n",
            "Total Loss: 1.6168275604146917e+21\n",
            "----------------------------------------\n",
            "Epoch 20\n",
            "Var loss:  tensor(1.5268e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.186523423103466e+22\n",
            "E_s_wdiff_all_sq: 2.7415667138166825e+18\n",
            "E_IS_SCOPE: -3.3405647924408474e+22\n",
            "E_IS_E_SCOPE: -1.0441599899703955e+22\n",
            "Total Loss: 1.5268174910313474e+21\n",
            "----------------------------------------\n",
            "Epoch 21\n",
            "Var loss:  tensor(1.5536e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.263193783444266e+22\n",
            "E_s_wdiff_all_sq: 5.60570436459224e+19\n",
            "E_IS_SCOPE: -3.2396879704542404e+22\n",
            "E_IS_E_SCOPE: -9.522452985415874e+21\n",
            "Total Loss: 1.5536167913072424e+21\n",
            "----------------------------------------\n",
            "Epoch 22\n",
            "Var loss:  tensor(1.6038e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.3038238778747116e+22\n",
            "E_s_wdiff_all_sq: 1.038464977379727e+20\n",
            "E_IS_SCOPE: -3.1941390037369942e+22\n",
            "E_IS_E_SCOPE: -9.100087115917017e+21\n",
            "Total Loss: 1.603799461460053e+21\n",
            "----------------------------------------\n",
            "Epoch 23\n",
            "Var loss:  tensor(1.5579e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.280744616265086e+22\n",
            "E_s_wdiff_all_sq: 7.232327063685525e+19\n",
            "E_IS_SCOPE: -3.226097241733373e+22\n",
            "E_IS_E_SCOPE: -9.374780287438828e+21\n",
            "Total Loss: 1.5579216000016533e+21\n",
            "----------------------------------------\n",
            "Epoch 24\n",
            "Var loss:  tensor(1.4955e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2186054363945735e+22\n",
            "E_s_wdiff_all_sq: 1.4320783436180496e+19\n",
            "E_IS_SCOPE: -3.311621804425452e+22\n",
            "E_IS_E_SCOPE: -1.0131275611539864e+22\n",
            "Total Loss: 1.4955245197580546e+21\n",
            "----------------------------------------\n",
            "Epoch 25\n",
            "Var loss:  tensor(1.5135e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.1632689759298687e+22\n",
            "E_s_wdiff_all_sq: 1.084200194891547e+18\n",
            "E_IS_SCOPE: -3.399041051449923e+22\n",
            "E_IS_E_SCOPE: -1.0904521428491936e+22\n",
            "Total Loss: 1.5135124254778102e+21\n",
            "----------------------------------------\n",
            "Epoch 26\n",
            "Var loss:  tensor(1.5428e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.1424102425190768e+22\n",
            "E_s_wdiff_all_sq: 9.995917013511735e+18\n",
            "E_IS_SCOPE: -3.438730299143147e+22\n",
            "E_IS_E_SCOPE: -1.1248423262188292e+22\n",
            "Total Loss: 1.5428456385944727e+21\n",
            "----------------------------------------\n",
            "Epoch 27\n",
            "Var loss:  tensor(1.5052e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.1604771700615028e+22\n",
            "E_s_wdiff_all_sq: 2.497813187449078e+18\n",
            "E_IS_SCOPE: -3.41309817677249e+22\n",
            "E_IS_E_SCOPE: -1.10047754887802e+22\n",
            "Total Loss: 1.5052140412075927e+21\n",
            "----------------------------------------\n",
            "Epoch 28\n",
            "Var loss:  tensor(1.4629e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2080736777878213e+22\n",
            "E_s_wdiff_all_sq: 5.962303699342489e+18\n",
            "E_IS_SCOPE: -3.344352078594305e+22\n",
            "E_IS_E_SCOPE: -1.0373720528271083e+22\n",
            "Total Loss: 1.4629362005071322e+21\n",
            "----------------------------------------\n",
            "Epoch 29\n",
            "Var loss:  tensor(1.4770e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2592625258055936e+22\n",
            "E_s_wdiff_all_sq: 3.991967222209619e+19\n",
            "E_IS_SCOPE: -3.2780876560970264e+22\n",
            "E_IS_E_SCOPE: -9.766007546533942e+21\n",
            "Total Loss: 1.4769741854190055e+21\n",
            "----------------------------------------\n",
            "Epoch 30\n",
            "Var loss:  tensor(1.4901e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2793876705606977e+22\n",
            "E_s_wdiff_all_sq: 5.9502027677624975e+19\n",
            "E_IS_SCOPE: -3.2554403762262136e+22\n",
            "E_IS_E_SCOPE: -9.552317118832756e+21\n",
            "Total Loss: 1.490099947282744e+21\n",
            "----------------------------------------\n",
            "Epoch 31\n",
            "Var loss:  tensor(1.4566e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.255984103315449e+22\n",
            "E_s_wdiff_all_sq: 3.5746662274154856e+19\n",
            "E_IS_SCOPE: -3.2879345052357864e+22\n",
            "E_IS_E_SCOPE: -9.83578305695054e+21\n",
            "Total Loss: 1.4565795089921522e+21\n",
            "----------------------------------------\n",
            "Epoch 32\n",
            "Var loss:  tensor(1.4298e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.21067556028737e+22\n",
            "E_s_wdiff_all_sq: 5.902081057804411e+18\n",
            "E_IS_SCOPE: -3.3523765883237877e+22\n",
            "E_IS_E_SCOPE: -1.0407510391118763e+22\n",
            "Total Loss: 1.4298344194560062e+21\n",
            "----------------------------------------\n",
            "Epoch 33\n",
            "Var loss:  tensor(1.4413e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.175482671195341e+22\n",
            "E_s_wdiff_all_sq: 3.608061351989825e+17\n",
            "E_IS_SCOPE: -3.4076115135540777e+22\n",
            "E_IS_E_SCOPE: -1.0896870497663756e+22\n",
            "Total Loss: 1.4412873435648958e+21\n",
            "----------------------------------------\n",
            "Epoch 34\n",
            "Var loss:  tensor(1.4412e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.1683486231838048e+22\n",
            "E_s_wdiff_all_sq: 1.556677069839308e+18\n",
            "E_IS_SCOPE: -3.420723472477327e+22\n",
            "E_IS_E_SCOPE: -1.100803445272771e+22\n",
            "Total Loss: 1.4411995501764154e+21\n",
            "----------------------------------------\n",
            "Epoch 35\n",
            "Var loss:  tensor(1.4114e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.1899953007459526e+22\n",
            "E_s_wdiff_all_sq: 5.0133590337038566e+17\n",
            "E_IS_SCOPE: -3.3877475235530344e+22\n",
            "E_IS_E_SCOPE: -1.0706104847560193e+22\n",
            "Total Loss: 1.411396488781185e+21\n",
            "----------------------------------------\n",
            "Epoch 36\n",
            "Var loss:  tensor(1.3971e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2270487781157556e+22\n",
            "E_s_wdiff_all_sq: 1.452261542540968e+19\n",
            "E_IS_SCOPE: -3.334386714471336e+22\n",
            "E_IS_E_SCOPE: -1.0222092984288681e+22\n",
            "Total Loss: 1.3971118542986527e+21\n",
            "----------------------------------------\n",
            "Epoch 37\n",
            "Var loss:  tensor(1.4043e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.25455514272645e+22\n",
            "E_s_wdiff_all_sq: 3.5443729775789773e+19\n",
            "E_IS_SCOPE: -3.2980659698734673e+22\n",
            "E_IS_E_SCOPE: -9.890679039300559e+21\n",
            "Total Loss: 1.4043485573986008e+21\n",
            "----------------------------------------\n",
            "Epoch 38\n",
            "Var loss:  tensor(1.3937e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2523128111479212e+22\n",
            "E_s_wdiff_all_sq: 3.3737923484991574e+19\n",
            "E_IS_SCOPE: -3.302263786840805e+22\n",
            "E_IS_E_SCOPE: -9.92258909122313e+21\n",
            "Total Loss: 1.393699058034271e+21\n",
            "----------------------------------------\n",
            "Epoch 39\n",
            "Var loss:  tensor(1.3697e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2241589554837774e+22\n",
            "E_s_wdiff_all_sq: 1.3463824661238282e+19\n",
            "E_IS_SCOPE: -3.341677226186248e+22\n",
            "E_IS_E_SCOPE: -1.0271178566861467e+22\n",
            "Total Loss: 1.3696601413989884e+21\n",
            "----------------------------------------\n",
            "Epoch 40\n",
            "Var loss:  tensor(1.3640e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.1928459720067207e+22\n",
            "E_s_wdiff_all_sq: 1.2785224077778248e+18\n",
            "E_IS_SCOPE: -3.3881247263236477e+22\n",
            "E_IS_E_SCOPE: -1.0683328741037868e+22\n",
            "Total Loss: 1.3640308264096256e+21\n",
            "----------------------------------------\n",
            "Epoch 41\n",
            "Var loss:  tensor(1.3643e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.1786838981563338e+22\n",
            "E_s_wdiff_all_sq: 2550734243817073.0\n",
            "E_IS_SCOPE: -3.410544001229776e+22\n",
            "E_IS_E_SCOPE: -1.0880103563929582e+22\n",
            "Total Loss: 1.3643490584583356e+21\n",
            "----------------------------------------\n",
            "Epoch 42\n",
            "Var loss:  tensor(1.3475e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.1880218899585343e+22\n",
            "E_s_wdiff_all_sq: 6.887443066764826e+17\n",
            "E_IS_SCOPE: -3.3964912908349544e+22\n",
            "E_IS_E_SCOPE: -1.0749667745270736e+22\n",
            "Total Loss: 1.347475728400235e+21\n",
            "----------------------------------------\n",
            "Epoch 43\n",
            "Var loss:  tensor(1.3311e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2132323808601113e+22\n",
            "E_s_wdiff_all_sq: 9.0125476743935e+18\n",
            "E_IS_SCOPE: -3.3596038639327665e+22\n",
            "E_IS_E_SCOPE: -1.04142431226007e+22\n",
            "Total Loss: 1.3310553074496543e+21\n",
            "----------------------------------------\n",
            "Epoch 44\n",
            "Var loss:  tensor(1.3288e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2359518219820369e+22\n",
            "E_s_wdiff_all_sq: 2.355155912170939e+19\n",
            "E_IS_SCOPE: -3.3284183456581075e+22\n",
            "E_IS_E_SCOPE: -1.0129853799297874e+22\n",
            "Total Loss: 1.3287921142536088e+21\n",
            "----------------------------------------\n",
            "Epoch 45\n",
            "Var loss:  tensor(1.3210e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.238773829114204e+22\n",
            "E_s_wdiff_all_sq: 2.6027424365793227e+19\n",
            "E_IS_SCOPE: -3.325724543577118e+22\n",
            "E_IS_E_SCOPE: -1.0099905093363302e+22\n",
            "Total Loss: 1.3210421093913623e+21\n",
            "----------------------------------------\n",
            "Epoch 46\n",
            "Var loss:  tensor(1.3036e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2205940343263744e+22\n",
            "E_s_wdiff_all_sq: 1.3827445038710628e+19\n",
            "E_IS_SCOPE: -3.351893605020439e+22\n",
            "E_IS_E_SCOPE: -1.0329141024401517e+22\n",
            "Total Loss: 1.3035707257612906e+21\n",
            "----------------------------------------\n",
            "Epoch 47\n",
            "Var loss:  tensor(1.2943e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.1971769088341126e+22\n",
            "E_s_wdiff_all_sq: 3.3808223308120694e+18\n",
            "E_IS_SCOPE: -3.3868683983787127e+22\n",
            "E_IS_E_SCOPE: -1.0637275207129033e+22\n",
            "Total Loss: 1.2943061518557412e+21\n",
            "----------------------------------------\n",
            "Epoch 48\n",
            "Var loss:  tensor(1.2897e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.1854936498453332e+22\n",
            "E_s_wdiff_all_sq: 7.516945630442011e+17\n",
            "E_IS_SCOPE: -3.405854906542557e+22\n",
            "E_IS_E_SCOPE: -1.080127225483636e+22\n",
            "Total Loss: 1.289734541813041e+21\n",
            "----------------------------------------\n",
            "Epoch 49\n",
            "Var loss:  tensor(1.2763e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.1921079734718163e+22\n",
            "E_s_wdiff_all_sq: 2.076841512173565e+18\n",
            "E_IS_SCOPE: -3.397632371078965e+22\n",
            "E_IS_E_SCOPE: -1.071993393085295e+22\n",
            "Total Loss: 1.2763135153994832e+21\n",
            "----------------------------------------\n",
            "Epoch 50\n",
            "Var loss:  tensor(1.2627e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2110884012131495e+22\n",
            "E_s_wdiff_all_sq: 9.069685530858882e+18\n",
            "E_IS_SCOPE: -3.3718835790941866e+22\n",
            "E_IS_E_SCOPE: -1.0480477852306265e+22\n",
            "Total Loss: 1.2627253968683265e+21\n",
            "----------------------------------------\n",
            "Epoch 51\n",
            "Var loss:  tensor(1.2564e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2278191404034225e+22\n",
            "E_s_wdiff_all_sq: 1.8685241388524634e+19\n",
            "E_IS_SCOPE: -3.350828240418175e+22\n",
            "E_IS_E_SCOPE: -1.0282236121184601e+22\n",
            "Total Loss: 1.256414368926305e+21\n",
            "----------------------------------------\n",
            "Epoch 52\n",
            "Var loss:  tensor(1.2467e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2292507139117263e+22\n",
            "E_s_wdiff_all_sq: 1.943348264484393e+19\n",
            "E_IS_SCOPE: -3.351490470015154e+22\n",
            "E_IS_E_SCOPE: -1.0278635985077858e+22\n",
            "Total Loss: 1.246685103749526e+21\n",
            "----------------------------------------\n",
            "Epoch 53\n",
            "Var loss:  tensor(1.2325e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2156577494832555e+22\n",
            "E_s_wdiff_all_sq: 1.0911978081941123e+19\n",
            "E_IS_SCOPE: -3.3732205758776047e+22\n",
            "E_IS_E_SCOPE: -1.0464088822638019e+22\n",
            "Total Loss: 1.2325118548962894e+21\n",
            "----------------------------------------\n",
            "Epoch 54\n",
            "Var loss:  tensor(1.2232e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.199476757834252e+22\n",
            "E_s_wdiff_all_sq: 3.8209152072431867e+18\n",
            "E_IS_SCOPE: -3.399230348502566e+22\n",
            "E_IS_E_SCOPE: -1.0688333226491356e+22\n",
            "Total Loss: 1.2232396974670364e+21\n",
            "----------------------------------------\n",
            "Epoch 55\n",
            "Var loss:  tensor(1.2150e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.1934386231559609e+22\n",
            "E_s_wdiff_all_sq: 2.0219336569202732e+18\n",
            "E_IS_SCOPE: -3.4108479363212556e+22\n",
            "E_IS_E_SCOPE: -1.0783161025489789e+22\n",
            "Total Loss: 1.2149899913056339e+21\n",
            "----------------------------------------\n",
            "Epoch 56\n",
            "Var loss:  tensor(1.2020e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2012212744656058e+22\n",
            "E_s_wdiff_all_sq: 4.200909866380894e+18\n",
            "E_IS_SCOPE: -3.4019954462078697e+22\n",
            "E_IS_E_SCOPE: -1.0693855981469404e+22\n",
            "Total Loss: 1.2019511746086463e+21\n",
            "----------------------------------------\n",
            "Epoch 57\n",
            "Var loss:  tensor(1.1903e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.214390478637759e+22\n",
            "E_s_wdiff_all_sq: 9.84692014117684e+18\n",
            "E_IS_SCOPE: -3.3848198683308272e+22\n",
            "E_IS_E_SCOPE: -1.0531587344468344e+22\n",
            "Total Loss: 1.1903488628678501e+21\n",
            "----------------------------------------\n",
            "Epoch 58\n",
            "Var loss:  tensor(1.1801e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.216407197502897e+22\n",
            "E_s_wdiff_all_sq: 1.1790627644726143e+19\n",
            "E_IS_SCOPE: -3.3809238666236645e+22\n",
            "E_IS_E_SCOPE: -1.049547874794727e+22\n",
            "Total Loss: 1.1801102960992631e+21\n",
            "----------------------------------------\n",
            "Epoch 59\n",
            "Var loss:  tensor(1.1689e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2084167305902185e+22\n",
            "E_s_wdiff_all_sq: 8.847664656674314e+18\n",
            "E_IS_SCOPE: -3.3900875979975534e+22\n",
            "E_IS_E_SCOPE: -1.0579472643091774e+22\n",
            "Total Loss: 1.1689126849282069e+21\n",
            "----------------------------------------\n",
            "Epoch 60\n",
            "Var loss:  tensor(1.1585e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2001962823171067e+22\n",
            "E_s_wdiff_all_sq: 6.025374071502084e+18\n",
            "E_IS_SCOPE: -3.4005369668284935e+22\n",
            "E_IS_E_SCOPE: -1.0673082323603003e+22\n",
            "Total Loss: 1.1585498671119744e+21\n",
            "----------------------------------------\n",
            "Epoch 61\n",
            "Var loss:  tensor(1.1473e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2064932943767403e+22\n",
            "E_s_wdiff_all_sq: 8.533814493309938e+18\n",
            "E_IS_SCOPE: -3.3947366417133333e+22\n",
            "E_IS_E_SCOPE: -1.0609657567980491e+22\n",
            "Total Loss: 1.1472522231439824e+21\n",
            "----------------------------------------\n",
            "Epoch 62\n",
            "Var loss:  tensor(1.1367e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.212830196089783e+22\n",
            "E_s_wdiff_all_sq: 1.1377345801781285e+19\n",
            "E_IS_SCOPE: -3.3892766133473864e+22\n",
            "E_IS_E_SCOPE: -1.0548613427595294e+22\n",
            "Total Loss: 1.1366893864377574e+21\n",
            "----------------------------------------\n",
            "Epoch 63\n",
            "Var loss:  tensor(1.1254e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2092257992794534e+22\n",
            "E_s_wdiff_all_sq: 9.581448977066113e+18\n",
            "E_IS_SCOPE: -3.3962956285604794e+22\n",
            "E_IS_E_SCOPE: -1.0603645791052633e+22\n",
            "Total Loss: 1.1253622044446163e+21\n",
            "----------------------------------------\n",
            "Epoch 64\n",
            "Var loss:  tensor(1.1144e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2028444769477068e+22\n",
            "E_s_wdiff_all_sq: 6.633882610849539e+18\n",
            "E_IS_SCOPE: -3.407678218877208e+22\n",
            "E_IS_E_SCOPE: -1.0697158144042446e+22\n",
            "Total Loss: 1.1144342337620206e+21\n",
            "----------------------------------------\n",
            "Epoch 65\n",
            "Var loss:  tensor(1.1031e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2051917330869666e+22\n",
            "E_s_wdiff_all_sq: 7.10035377010985e+18\n",
            "E_IS_SCOPE: -3.4089221360463743e+22\n",
            "E_IS_E_SCOPE: -1.0693856547036306e+22\n",
            "Total Loss: 1.1031236607528665e+21\n",
            "----------------------------------------\n",
            "Epoch 66\n",
            "Var loss:  tensor(1.0918e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2127351467841742e+22\n",
            "E_s_wdiff_all_sq: 9.71706088519e+18\n",
            "E_IS_SCOPE: -3.404097726408538e+22\n",
            "E_IS_E_SCOPE: -1.0632784592245564e+22\n",
            "Total Loss: 1.0918301261094464e+21\n",
            "----------------------------------------\n",
            "Epoch 67\n",
            "Var loss:  tensor(1.0806e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2146223448982945e+22\n",
            "E_s_wdiff_all_sq: 1.0052183228978827e+19\n",
            "E_IS_SCOPE: -3.4059757960315407e+22\n",
            "E_IS_E_SCOPE: -1.0635270460826664e+22\n",
            "Total Loss: 1.0805983205338907e+21\n",
            "----------------------------------------\n",
            "Epoch 68\n",
            "Var loss:  tensor(1.0691e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2101062659164732e+22\n",
            "E_s_wdiff_all_sq: 7.609704325882423e+18\n",
            "E_IS_SCOPE: -3.4157812232006274e+22\n",
            "E_IS_E_SCOPE: -1.0711846053681341e+22\n",
            "Total Loss: 1.0690557658979799e+21\n",
            "----------------------------------------\n",
            "Epoch 69\n",
            "Var loss:  tensor(1.0577e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2082168099871543e+22\n",
            "E_s_wdiff_all_sq: 6.393003270357774e+18\n",
            "E_IS_SCOPE: -3.422562451272381e+22\n",
            "E_IS_E_SCOPE: -1.075957872307528e+22\n",
            "Total Loss: 1.0577346533515382e+21\n",
            "----------------------------------------\n",
            "Epoch 70\n",
            "Var loss:  tensor(1.0460e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.213020326599022e+22\n",
            "E_s_wdiff_all_sq: 7.831166897434421e+18\n",
            "E_IS_SCOPE: -3.4207913238684225e+22\n",
            "E_IS_E_SCOPE: -1.0727856352283935e+22\n",
            "Total Loss: 1.0460252551753446e+21\n",
            "----------------------------------------\n",
            "Epoch 71\n",
            "Var loss:  tensor(1.0346e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2177250193971446e+22\n",
            "E_s_wdiff_all_sq: 9.487218270428697e+18\n",
            "E_IS_SCOPE: -3.418695069608659e+22\n",
            "E_IS_E_SCOPE: -1.0694381326064123e+22\n",
            "Total Loss: 1.0345721896924076e+21\n",
            "----------------------------------------\n",
            "Epoch 72\n",
            "Var loss:  tensor(1.0228e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2161087009954743e+22\n",
            "E_s_wdiff_all_sq: 8.49785090682553e+18\n",
            "E_IS_SCOPE: -3.4241322838926444e+22\n",
            "E_IS_E_SCOPE: -1.0732085248959202e+22\n",
            "Total Loss: 1.0227764886812314e+21\n",
            "----------------------------------------\n",
            "Epoch 73\n",
            "Var loss:  tensor(1.0111e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2121070845041656e+22\n",
            "E_s_wdiff_all_sq: 6.68449501634125e+18\n",
            "E_IS_SCOPE: -3.432317794684397e+22\n",
            "E_IS_E_SCOPE: -1.0796089635684118e+22\n",
            "Total Loss: 1.0110632681078386e+21\n",
            "----------------------------------------\n",
            "Epoch 74\n",
            "Var loss:  tensor(9.9918e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2127058158385526e+22\n",
            "E_s_wdiff_all_sq: 6.826442545100489e+18\n",
            "E_IS_SCOPE: -3.434318336583652e+22\n",
            "E_IS_E_SCOPE: -1.0803469958265608e+22\n",
            "Total Loss: 9.991807112110827e+20\n",
            "----------------------------------------\n",
            "Epoch 75\n",
            "Var loss:  tensor(9.8722e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2168073481343449e+22\n",
            "E_s_wdiff_all_sq: 8.508589829581772e+18\n",
            "E_IS_SCOPE: -3.4314882434000207e+22\n",
            "E_IS_E_SCOPE: -1.0766942331751084e+22\n",
            "Total Loss: 9.872150182980559e+20\n",
            "----------------------------------------\n",
            "Epoch 76\n",
            "Var loss:  tensor(9.7525e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2176684387901119e+22\n",
            "E_s_wdiff_all_sq: 8.980974322210485e+18\n",
            "E_IS_SCOPE: -3.43240522518299e+22\n",
            "E_IS_E_SCOPE: -1.0766197186037736e+22\n",
            "Total Loss: 9.752508520563013e+20\n",
            "----------------------------------------\n",
            "Epoch 77\n",
            "Var loss:  tensor(9.6309e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2139674910767213e+22\n",
            "E_s_wdiff_all_sq: 7.545514491885366e+18\n",
            "E_IS_SCOPE: -3.438931357036018e+22\n",
            "E_IS_E_SCOPE: -1.0817988395033115e+22\n",
            "Total Loss: 9.630923648479758e+20\n",
            "----------------------------------------\n",
            "Epoch 78\n",
            "Var loss:  tensor(9.5101e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2115370444249251e+22\n",
            "E_s_wdiff_all_sq: 6.778270906114173e+18\n",
            "E_IS_SCOPE: -3.4435642213529958e+22\n",
            "E_IS_E_SCOPE: -1.0852947379384148e+22\n",
            "Total Loss: 9.510075650435543e+20\n",
            "----------------------------------------\n",
            "Epoch 79\n",
            "Var loss:  tensor(9.3868e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.21355216942951e+22\n",
            "E_s_wdiff_all_sq: 7.81528263127965e+18\n",
            "E_IS_SCOPE: -3.442446713968044e+22\n",
            "E_IS_E_SCOPE: -1.0834671522602918e+22\n",
            "Total Loss: 9.38681392444746e+20\n",
            "----------------------------------------\n",
            "Epoch 80\n",
            "Var loss:  tensor(9.2643e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2156487501320747e+22\n",
            "E_s_wdiff_all_sq: 9.02246369271829e+18\n",
            "E_IS_SCOPE: -3.440994847517194e+22\n",
            "E_IS_E_SCOPE: -1.081392153187406e+22\n",
            "Total Loss: 9.26434556300822e+20\n",
            "----------------------------------------\n",
            "Epoch 81\n",
            "Var loss:  tensor(9.1402e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2136907593662983e+22\n",
            "E_s_wdiff_all_sq: 8.473657060423804e+18\n",
            "E_IS_SCOPE: -3.444711980633373e+22\n",
            "E_IS_E_SCOPE: -1.0841089739270146e+22\n",
            "Total Loss: 9.140166085077337e+20\n",
            "----------------------------------------\n",
            "Epoch 82\n",
            "Var loss:  tensor(9.0160e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2104044271443062e+22\n",
            "E_s_wdiff_all_sq: 7.335639167722385e+18\n",
            "E_IS_SCOPE: -3.450389617466081e+22\n",
            "E_IS_E_SCOPE: -1.088575519237585e+22\n",
            "Total Loss: 9.015969089507662e+20\n",
            "----------------------------------------\n",
            "Epoch 83\n",
            "Var loss:  tensor(8.8908e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.210462980474097e+22\n",
            "E_s_wdiff_all_sq: 7.573405599137854e+18\n",
            "E_IS_SCOPE: -3.451885488122717e+22\n",
            "E_IS_E_SCOPE: -1.0891360132994127e+22\n",
            "Total Loss: 8.890798509707808e+20\n",
            "----------------------------------------\n",
            "Epoch 84\n",
            "Var loss:  tensor(8.7648e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2128173657756937e+22\n",
            "E_s_wdiff_all_sq: 8.77376816568012e+18\n",
            "E_IS_SCOPE: -3.450570525847417e+22\n",
            "E_IS_E_SCOPE: -1.0870547232488094e+22\n",
            "Total Loss: 8.764842479746516e+20\n",
            "----------------------------------------\n",
            "Epoch 85\n",
            "Var loss:  tensor(8.6383e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.212906469517107e+22\n",
            "E_s_wdiff_all_sq: 8.930388870312846e+18\n",
            "E_IS_SCOPE: -3.4525139627025638e+22\n",
            "E_IS_E_SCOPE: -1.0878989833763344e+22\n",
            "Total Loss: 8.638343521115979e+20\n",
            "----------------------------------------\n",
            "Epoch 86\n",
            "Var loss:  tensor(8.5112e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2104141925470454e+22\n",
            "E_s_wdiff_all_sq: 7.879041544775077e+18\n",
            "E_IS_SCOPE: -3.458123738420071e+22\n",
            "E_IS_E_SCOPE: -1.0920456986651288e+22\n",
            "Total Loss: 8.511175267246743e+20\n",
            "----------------------------------------\n",
            "Epoch 87\n",
            "Var loss:  tensor(8.3837e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2095989539369612e+22\n",
            "E_s_wdiff_all_sq: 7.551307781983021e+18\n",
            "E_IS_SCOPE: -3.4616653838467564e+22\n",
            "E_IS_E_SCOPE: -1.0942534790485513e+22\n",
            "Total Loss: 8.383656435927986e+20\n",
            "----------------------------------------\n",
            "Epoch 88\n",
            "Var loss:  tensor(8.2549e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2116214096607895e+22\n",
            "E_s_wdiff_all_sq: 8.415079779994917e+18\n",
            "E_IS_SCOPE: -3.4615901098296012e+22\n",
            "E_IS_E_SCOPE: -1.0930998201774231e+22\n",
            "Total Loss: 8.254859150403358e+20\n",
            "----------------------------------------\n",
            "Epoch 89\n",
            "Var loss:  tensor(8.1257e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2127881795100419e+22\n",
            "E_s_wdiff_all_sq: 8.926240639637699e+18\n",
            "E_IS_SCOPE: -3.4626769304095033e+22\n",
            "E_IS_E_SCOPE: -1.0930050732786012e+22\n",
            "Total Loss: 8.125747949701599e+20\n",
            "----------------------------------------\n",
            "Epoch 90\n",
            "Var loss:  tensor(7.9961e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2112026495103854e+22\n",
            "E_s_wdiff_all_sq: 8.237318787873422e+18\n",
            "E_IS_SCOPE: -3.4672668280155697e+22\n",
            "E_IS_E_SCOPE: -1.0961612287202992e+22\n",
            "Total Loss: 7.996062061032081e+20\n",
            "----------------------------------------\n",
            "Epoch 91\n",
            "Var loss:  tensor(7.8658e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2099940651323695e+22\n",
            "E_s_wdiff_all_sq: 7.605545050523092e+18\n",
            "E_IS_SCOPE: -3.4719271398748027e+22\n",
            "E_IS_E_SCOPE: -1.0992368307587204e+22\n",
            "Total Loss: 7.865821862910241e+20\n",
            "----------------------------------------\n",
            "Epoch 92\n",
            "Var loss:  tensor(7.7343e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2116220275722086e+22\n",
            "E_s_wdiff_all_sq: 8.067148890868569e+18\n",
            "E_IS_SCOPE: -3.473374738855318e+22\n",
            "E_IS_E_SCOPE: -1.099220797935788e+22\n",
            "Total Loss: 7.734288463911348e+20\n",
            "----------------------------------------\n",
            "Epoch 93\n",
            "Var loss:  tensor(7.6028e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2137587735952986e+22\n",
            "E_s_wdiff_all_sq: 8.68580370972083e+18\n",
            "E_IS_SCOPE: -3.474494150470191e+22\n",
            "E_IS_E_SCOPE: -1.0988164678149632e+22\n",
            "Total Loss: 7.602781706998356e+20\n",
            "----------------------------------------\n",
            "Epoch 94\n",
            "Var loss:  tensor(7.4706e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2134175266144829e+22\n",
            "E_s_wdiff_all_sq: 8.33367465602258e+18\n",
            "E_IS_SCOPE: -3.4783819423621598e+22\n",
            "E_IS_E_SCOPE: -1.1010813608694362e+22\n",
            "Total Loss: 7.470566546864897e+20\n",
            "----------------------------------------\n",
            "Epoch 95\n",
            "Var loss:  tensor(7.3375e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2120698413984216e+22\n",
            "E_s_wdiff_all_sq: 7.654825889031122e+18\n",
            "E_IS_SCOPE: -3.4832144012901597e+22\n",
            "E_IS_E_SCOPE: -1.1043087591814073e+22\n",
            "Total Loss: 7.337525733250145e+20\n",
            "----------------------------------------\n",
            "Epoch 96\n",
            "Var loss:  tensor(7.2035e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2125549607379469e+22\n",
            "E_s_wdiff_all_sq: 7.800669340819894e+18\n",
            "E_IS_SCOPE: -3.4854958292456954e+22\n",
            "E_IS_E_SCOPE: -1.1052213694925352e+22\n",
            "Total Loss: 7.203535169433905e+20\n",
            "----------------------------------------\n",
            "Epoch 97\n",
            "Var loss:  tensor(7.0694e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.214051485679126e+22\n",
            "E_s_wdiff_all_sq: 8.436832673704211e+18\n",
            "E_IS_SCOPE: -3.4862528911040294e+22\n",
            "E_IS_E_SCOPE: -1.1047802340738316e+22\n",
            "Total Loss: 7.069434666273871e+20\n",
            "----------------------------------------\n",
            "Epoch 98\n",
            "Var loss:  tensor(6.9349e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2138996324570675e+22\n",
            "E_s_wdiff_all_sq: 8.40636883391521e+18\n",
            "E_IS_SCOPE: -3.488983493688199e+22\n",
            "E_IS_E_SCOPE: -1.1062028830543643e+22\n",
            "Total Loss: 6.93492352139393e+20\n",
            "----------------------------------------\n",
            "Epoch 99\n",
            "Var loss:  tensor(6.7992e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.212507933697997e+22\n",
            "E_s_wdiff_all_sq: 7.759711596577149e+18\n",
            "E_IS_SCOPE: -3.493699909694722e+22\n",
            "E_IS_E_SCOPE: -1.1093587469670529e+22\n",
            "Total Loss: 6.799229617988908e+20\n",
            "----------------------------------------\n",
            "Epoch 100\n",
            "Var loss:  tensor(6.6627e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2126933425903955e+22\n",
            "E_s_wdiff_all_sq: 7.675937753143454e+18\n",
            "E_IS_SCOPE: -3.4968613877174485e+22\n",
            "E_IS_E_SCOPE: -1.110949578580027e+22\n",
            "Total Loss: 6.662724386575708e+20\n",
            "----------------------------------------\n",
            "Epoch 101\n",
            "Var loss:  tensor(6.5265e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2118295601655837e+22\n",
            "E_s_wdiff_all_sq: 7.393457080459871e+18\n",
            "E_IS_SCOPE: -3.5003825086458283e+22\n",
            "E_IS_E_SCOPE: -1.1131307214810055e+22\n",
            "Total Loss: 6.526464828712073e+20\n",
            "----------------------------------------\n",
            "Epoch 102\n",
            "Var loss:  tensor(6.3911e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2185973985349649e+22\n",
            "E_s_wdiff_all_sq: 1.01791643920203e+19\n",
            "E_IS_SCOPE: -3.495239374762885e+22\n",
            "E_IS_E_SCOPE: -1.106994767943105e+22\n",
            "Total Loss: 6.391089380868657e+20\n",
            "----------------------------------------\n",
            "Epoch 103\n",
            "Var loss:  tensor(6.2507e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2136319738575835e+22\n",
            "E_s_wdiff_all_sq: 8.142100704686345e+18\n",
            "E_IS_SCOPE: -3.503571868745321e+22\n",
            "E_IS_E_SCOPE: -1.113736891045439e+22\n",
            "Total Loss: 6.250685047343541e+20\n",
            "----------------------------------------\n",
            "Epoch 104\n",
            "Var loss:  tensor(6.1144e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2087617619006325e+22\n",
            "E_s_wdiff_all_sq: 6.422063779349371e+18\n",
            "E_IS_SCOPE: -3.511513274938363e+22\n",
            "E_IS_E_SCOPE: -1.120200239658005e+22\n",
            "Total Loss: 6.11438719680987e+20\n",
            "----------------------------------------\n",
            "Epoch 105\n",
            "Var loss:  tensor(5.9739e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2120737570239967e+22\n",
            "E_s_wdiff_all_sq: 7.808324648228662e+18\n",
            "E_IS_SCOPE: -3.509748065004141e+22\n",
            "E_IS_E_SCOPE: -1.1174510754122558e+22\n",
            "Total Loss: 5.973879422265946e+20\n",
            "----------------------------------------\n",
            "Epoch 106\n",
            "Var loss:  tensor(5.8353e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2162968083986043e+22\n",
            "E_s_wdiff_all_sq: 9.638060411956275e+18\n",
            "E_IS_SCOPE: -3.5072453658775975e+22\n",
            "E_IS_E_SCOPE: -1.1139129005088728e+22\n",
            "Total Loss: 5.835271914020489e+20\n",
            "----------------------------------------\n",
            "Epoch 107\n",
            "Var loss:  tensor(5.6940e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2137580062259297e+22\n",
            "E_s_wdiff_all_sq: 8.512270176500157e+18\n",
            "E_IS_SCOPE: -3.513236770320805e+22\n",
            "E_IS_E_SCOPE: -1.1182825869870771e+22\n",
            "Total Loss: 5.6940167515728354e+20\n",
            "----------------------------------------\n",
            "Epoch 108\n",
            "Var loss:  tensor(5.5543e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2095684426043654e+22\n",
            "E_s_wdiff_all_sq: 6.873550518731116e+18\n",
            "E_IS_SCOPE: -3.521004777742553e+22\n",
            "E_IS_E_SCOPE: -1.1243921260508644e+22\n",
            "Total Loss: 5.5543206242029666e+20\n",
            "----------------------------------------\n",
            "Epoch 109\n",
            "Var loss:  tensor(5.4122e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.211184758891624e+22\n",
            "E_s_wdiff_all_sq: 7.617602314669122e+18\n",
            "E_IS_SCOPE: -3.5213492215301592e+22\n",
            "E_IS_E_SCOPE: -1.1236091168822407e+22\n",
            "Total Loss: 5.412160744820467e+20\n",
            "----------------------------------------\n",
            "Epoch 110\n",
            "Var loss:  tensor(5.2705e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.214812585238545e+22\n",
            "E_s_wdiff_all_sq: 9.313738670386946e+18\n",
            "E_IS_SCOPE: -3.5190487640541667e+22\n",
            "E_IS_E_SCOPE: -1.120393945465897e+22\n",
            "Total Loss: 5.2704834498079595e+20\n",
            "----------------------------------------\n",
            "Epoch 111\n",
            "Var loss:  tensor(5.1279e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2131420756020654e+22\n",
            "E_s_wdiff_all_sq: 8.851903681805893e+18\n",
            "E_IS_SCOPE: -3.522899041069885e+22\n",
            "E_IS_E_SCOPE: -1.1230423947615305e+22\n",
            "Total Loss: 5.1279118717063633e+20\n",
            "----------------------------------------\n",
            "Epoch 112\n",
            "Var loss:  tensor(4.9853e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2091093760979184e+22\n",
            "E_s_wdiff_all_sq: 7.273800898953008e+18\n",
            "E_IS_SCOPE: -3.530378582897494e+22\n",
            "E_IS_E_SCOPE: -1.128897779932501e+22\n",
            "Total Loss: 4.9853491070610964e+20\n",
            "----------------------------------------\n",
            "Epoch 113\n",
            "Var loss:  tensor(4.8414e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2098322663072957e+22\n",
            "E_s_wdiff_all_sq: 7.567748981419239e+18\n",
            "E_IS_SCOPE: -3.532324057333828e+22\n",
            "E_IS_E_SCOPE: -1.1294739428627817e+22\n",
            "Total Loss: 4.841392119816158e+20\n",
            "----------------------------------------\n",
            "Epoch 114\n",
            "Var loss:  tensor(4.6980e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2135996318699995e+22\n",
            "E_s_wdiff_all_sq: 9.036747450801875e+18\n",
            "E_IS_SCOPE: -3.530978938996114e+22\n",
            "E_IS_E_SCOPE: -1.126843288614729e+22\n",
            "Total Loss: 4.697956069213607e+20\n",
            "----------------------------------------\n",
            "Epoch 115\n",
            "Var loss:  tensor(4.5539e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2134749561741143e+22\n",
            "E_s_wdiff_all_sq: 8.947076666151327e+18\n",
            "E_IS_SCOPE: -3.534148910052979e+22\n",
            "E_IS_E_SCOPE: -1.128517897897711e+22\n",
            "Total Loss: 4.553877073146602e+20\n",
            "----------------------------------------\n",
            "Epoch 116\n",
            "Var loss:  tensor(4.4090e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2102280523613894e+22\n",
            "E_s_wdiff_all_sq: 7.58825348756846e+18\n",
            "E_IS_SCOPE: -3.541062934509949e+22\n",
            "E_IS_E_SCOPE: -1.1337265590590505e+22\n",
            "Total Loss: 4.408980148882034e+20\n",
            "----------------------------------------\n",
            "Epoch 117\n",
            "Var loss:  tensor(4.2635e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2101040142819569e+22\n",
            "E_s_wdiff_all_sq: 7.573095252815326e+18\n",
            "E_IS_SCOPE: -3.543980535359371e+22\n",
            "E_IS_E_SCOPE: -1.135227882976325e+22\n",
            "Total Loss: 4.263453346236759e+20\n",
            "----------------------------------------\n",
            "Epoch 118\n",
            "Var loss:  tensor(4.1168e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2129312227831413e+22\n",
            "E_s_wdiff_all_sq: 8.815906185424067e+18\n",
            "E_IS_SCOPE: -3.543145657752981e+22\n",
            "E_IS_E_SCOPE: -1.1332399964825884e+22\n",
            "Total Loss: 4.116783769512145e+20\n",
            "----------------------------------------\n",
            "Epoch 119\n",
            "Var loss:  tensor(3.9707e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2129276424265883e+22\n",
            "E_s_wdiff_all_sq: 8.973023490845377e+18\n",
            "E_IS_SCOPE: -3.5454495983748543e+22\n",
            "E_IS_E_SCOPE: -1.134290140752373e+22\n",
            "Total Loss: 3.970680890417595e+20\n",
            "----------------------------------------\n",
            "Epoch 120\n",
            "Var loss:  tensor(3.8237e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2101396448771196e+22\n",
            "E_s_wdiff_all_sq: 7.757830553102307e+18\n",
            "E_IS_SCOPE: -3.5520072943078486e+22\n",
            "E_IS_E_SCOPE: -1.1391013150754131e+22\n",
            "Total Loss: 3.823694245783887e+20\n",
            "----------------------------------------\n",
            "Epoch 121\n",
            "Var loss:  tensor(3.6757e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2101589800352104e+22\n",
            "E_s_wdiff_all_sq: 7.568626379815266e+18\n",
            "E_IS_SCOPE: -3.555780874143794e+22\n",
            "E_IS_E_SCOPE: -1.141117389001589e+22\n",
            "Total Loss: 3.675733972256639e+20\n",
            "----------------------------------------\n",
            "Epoch 122\n",
            "Var loss:  tensor(3.5272e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2133500199739933e+22\n",
            "E_s_wdiff_all_sq: 8.599337443984928e+18\n",
            "E_IS_SCOPE: -3.5560002140252473e+22\n",
            "E_IS_E_SCOPE: -1.1397047848270029e+22\n",
            "Total Loss: 3.5271887374684206e+20\n",
            "----------------------------------------\n",
            "Epoch 123\n",
            "Var loss:  tensor(3.3789e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2142785055565522e+22\n",
            "E_s_wdiff_all_sq: 8.817136149464127e+18\n",
            "E_IS_SCOPE: -3.5585433688957807e+22\n",
            "E_IS_E_SCOPE: -1.1405964049542711e+22\n",
            "Total Loss: 3.3788923597981064e+20\n",
            "----------------------------------------\n",
            "Epoch 124\n",
            "Var loss:  tensor(3.2294e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2120776852312835e+22\n",
            "E_s_wdiff_all_sq: 7.797444480348061e+18\n",
            "E_IS_SCOPE: -3.5646489801883994e+22\n",
            "E_IS_E_SCOPE: -1.1449021931728665e+22\n",
            "Total Loss: 3.2294245343261046e+20\n",
            "----------------------------------------\n",
            "Epoch 125\n",
            "Var loss:  tensor(3.0794e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2115403123188319e+22\n",
            "E_s_wdiff_all_sq: 7.568939925811033e+18\n",
            "E_IS_SCOPE: -3.5683686433781696e+22\n",
            "E_IS_E_SCOPE: -1.1470610342222066e+22\n",
            "Total Loss: 3.079406919928932e+20\n",
            "----------------------------------------\n",
            "Epoch 126\n",
            "Var loss:  tensor(2.9286e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2135820367177324e+22\n",
            "E_s_wdiff_all_sq: 8.478356919777422e+18\n",
            "E_IS_SCOPE: -3.5685792951848042e+22\n",
            "E_IS_E_SCOPE: -1.1460183369630207e+22\n",
            "Total Loss: 2.928639820736307e+20\n",
            "----------------------------------------\n",
            "Epoch 127\n",
            "Var loss:  tensor(2.7779e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2140165405517856e+22\n",
            "E_s_wdiff_all_sq: 8.69040690733726e+18\n",
            "E_IS_SCOPE: -3.5709542682080307e+22\n",
            "E_IS_E_SCOPE: -1.1469543959836764e+22\n",
            "Total Loss: 2.777913305693044e+20\n",
            "----------------------------------------\n",
            "Epoch 128\n",
            "Var loss:  tensor(2.6258e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2121119769083255e+22\n",
            "E_s_wdiff_all_sq: 7.798521990456603e+18\n",
            "E_IS_SCOPE: -3.5767462779568483e+22\n",
            "E_IS_E_SCOPE: -1.150943692666e+22\n",
            "Total Loss: 2.6258439962805823e+20\n",
            "----------------------------------------\n",
            "Epoch 129\n",
            "Var loss:  tensor(2.4743e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2120516103250008e+22\n",
            "E_s_wdiff_all_sq: 7.614902570840139e+18\n",
            "E_IS_SCOPE: -3.5805307264536462e+22\n",
            "E_IS_E_SCOPE: -1.15298148631276e+22\n",
            "Total Loss: 2.4742557326165148e+20\n",
            "----------------------------------------\n",
            "Epoch 130\n",
            "Var loss:  tensor(2.3217e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2142033045783449e+22\n",
            "E_s_wdiff_all_sq: 8.463252554697501e+18\n",
            "E_IS_SCOPE: -3.58108669594462e+22\n",
            "E_IS_E_SCOPE: -1.152126423133578e+22\n",
            "Total Loss: 2.321712306001606e+20\n",
            "----------------------------------------\n",
            "Epoch 131\n",
            "Var loss:  tensor(2.1685e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2143886463254502e+22\n",
            "E_s_wdiff_all_sq: 8.594348642653532e+18\n",
            "E_IS_SCOPE: -3.5837171162239233e+22\n",
            "E_IS_E_SCOPE: -1.1533074111513965e+22\n",
            "Total Loss: 2.1684588301970204e+20\n",
            "----------------------------------------\n",
            "Epoch 132\n",
            "Var loss:  tensor(2.0145e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2122656214780607e+22\n",
            "E_s_wdiff_all_sq: 7.835351096493454e+18\n",
            "E_IS_SCOPE: -3.588909749357273e+22\n",
            "E_IS_E_SCOPE: -1.156963725164919e+22\n",
            "Total Loss: 2.0145239228449345e+20\n",
            "----------------------------------------\n",
            "Epoch 133\n",
            "Var loss:  tensor(1.8598e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2116587504463832e+22\n",
            "E_s_wdiff_all_sq: 7.842054687835633e+18\n",
            "E_IS_SCOPE: -3.591691991489834e+22\n",
            "E_IS_E_SCOPE: -1.1585051820466264e+22\n",
            "Total Loss: 1.859825457677174e+20\n",
            "----------------------------------------\n",
            "Epoch 134\n",
            "Var loss:  tensor(1.7054e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2127241736386242e+22\n",
            "E_s_wdiff_all_sq: 8.555112100219276e+18\n",
            "E_IS_SCOPE: -3.5923674091904486e+22\n",
            "E_IS_E_SCOPE: -1.15808567177009e+22\n",
            "Total Loss: 1.7054311538174093e+20\n",
            "----------------------------------------\n",
            "Epoch 135\n",
            "Var loss:  tensor(1.5501e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2125134238247589e+22\n",
            "E_s_wdiff_all_sq: 8.533636510262068e+18\n",
            "E_IS_SCOPE: -3.5954667843890572e+22\n",
            "E_IS_E_SCOPE: -1.159704359178439e+22\n",
            "Total Loss: 1.5500873552138705e+20\n",
            "----------------------------------------\n",
            "Epoch 136\n",
            "Var loss:  tensor(1.3934e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2113305957379978e+22\n",
            "E_s_wdiff_all_sq: 7.918880979269823e+18\n",
            "E_IS_SCOPE: -3.6005627774352402e+22\n",
            "E_IS_E_SCOPE: -1.1629738387696611e+22\n",
            "Total Loss: 1.3934498146678106e+20\n",
            "----------------------------------------\n",
            "Epoch 137\n",
            "Var loss:  tensor(1.2372e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2119076915685639e+22\n",
            "E_s_wdiff_all_sq: 8.005162939135414e+18\n",
            "E_IS_SCOPE: -3.6036068511186265e+22\n",
            "E_IS_E_SCOPE: -1.1642901561206362e+22\n",
            "Total Loss: 1.2372398663396858e+20\n",
            "----------------------------------------\n",
            "Epoch 138\n",
            "Var loss:  tensor(1.0809e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.213297720219529e+22\n",
            "E_s_wdiff_all_sq: 8.55781666713699e+18\n",
            "E_IS_SCOPE: -3.6051434308650897e+22\n",
            "E_IS_E_SCOPE: -1.164329958974709e+22\n",
            "Total Loss: 1.0808676383653993e+20\n",
            "----------------------------------------\n",
            "Epoch 139\n",
            "Var loss:  tensor(9.2405e+19, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2128708857438969e+22\n",
            "E_s_wdiff_all_sq: 8.48763461236741e+18\n",
            "E_IS_SCOPE: -3.608367032371898e+22\n",
            "E_IS_E_SCOPE: -1.1660985745921e+22\n",
            "Total Loss: 9.240485746577926e+19\n",
            "----------------------------------------\n",
            "Epoch 140\n",
            "Var loss:  tensor(7.6648e+19, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2117665998150513e+22\n",
            "E_s_wdiff_all_sq: 8.14955694662722e+18\n",
            "E_IS_SCOPE: -3.6123798920388103e+22\n",
            "E_IS_E_SCOPE: -1.1686166742476337e+22\n",
            "Total Loss: 7.664779450509165e+19\n",
            "----------------------------------------\n",
            "Epoch 141\n",
            "Var loss:  tensor(6.0822e+19, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2111003667703475e+22\n",
            "E_s_wdiff_all_sq: 8.045203847492336e+18\n",
            "E_IS_SCOPE: -3.6156687509448928e+22\n",
            "E_IS_E_SCOPE: -1.1705037969994805e+22\n",
            "Total Loss: 6.0821968491808555e+19\n",
            "----------------------------------------\n",
            "Epoch 142\n",
            "Var loss:  tensor(4.5004e+19, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2112585362610982e+22\n",
            "E_s_wdiff_all_sq: 8.33121977073828e+18\n",
            "E_IS_SCOPE: -3.617740301194891e+22\n",
            "E_IS_E_SCOPE: -1.171304828703877e+22\n",
            "Total Loss: 4.500360953124094e+19\n",
            "----------------------------------------\n",
            "Epoch 143\n",
            "Var loss:  tensor(2.9147e+19, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2117110253448205e+22\n",
            "E_s_wdiff_all_sq: 8.591672382237137e+18\n",
            "E_IS_SCOPE: -3.6200836211480593e+22\n",
            "E_IS_E_SCOPE: -1.172187660925064e+22\n",
            "Total Loss: 2.9147067940710908e+19\n",
            "----------------------------------------\n",
            "Epoch 144\n",
            "Var loss:  tensor(1.3173e+19, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2117068352872522e+22\n",
            "E_s_wdiff_all_sq: 8.493027115927862e+18\n",
            "E_IS_SCOPE: -3.6236785327513887e+22\n",
            "E_IS_E_SCOPE: -1.1740531847299932e+22\n",
            "Total Loss: 1.3172649446315393e+19\n",
            "----------------------------------------\n",
            "Epoch 145\n",
            "Var loss:  tensor(-2.8655e+18, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2115045973815909e+22\n",
            "E_s_wdiff_all_sq: 8.204898352980747e+18\n",
            "E_IS_SCOPE: -3.6279690314680703e+22\n",
            "E_IS_E_SCOPE: -1.1764463259738832e+22\n",
            "Total Loss: -2.865466627227386e+18\n",
            "----------------------------------------\n",
            "Epoch 146\n",
            "Var loss:  tensor(-1.8837e+19, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.21182928109298e+22\n",
            "E_s_wdiff_all_sq: 8.016914411021243e+18\n",
            "E_IS_SCOPE: -3.63209903236539e+22\n",
            "E_IS_E_SCOPE: -1.1785590517616624e+22\n",
            "Total Loss: -1.8836873826359312e+19\n",
            "----------------------------------------\n",
            "Epoch 147\n",
            "Var loss:  tensor(-3.4878e+19, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2127278674333649e+22\n",
            "E_s_wdiff_all_sq: 8.165706400204357e+18\n",
            "E_IS_SCOPE: -3.635125478450819e+22\n",
            "E_IS_E_SCOPE: -1.1797424419202824e+22\n",
            "Total Loss: -3.487822737248669e+19\n",
            "----------------------------------------\n",
            "Epoch 148\n",
            "Var loss:  tensor(-5.0993e+19, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2135913387610308e+22\n",
            "E_s_wdiff_all_sq: 8.430319069066772e+18\n",
            "E_IS_SCOPE: -3.637685334953238e+22\n",
            "E_IS_E_SCOPE: -1.180624032837817e+22\n",
            "Total Loss: -5.09929166181761e+19\n",
            "----------------------------------------\n",
            "Epoch 149\n",
            "Var loss:  tensor(-6.7169e+19, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2135347018513852e+22\n",
            "E_s_wdiff_all_sq: 8.367625721076847e+18\n",
            "E_IS_SCOPE: -3.641155817954212e+22\n",
            "E_IS_E_SCOPE: -1.182417368615821e+22\n",
            "Total Loss: -6.71688723939889e+19\n",
            "----------------------------------------\n",
            "Epoch 150\n",
            "Var loss:  tensor(-8.3421e+19, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2128855530491697e+22\n",
            "E_s_wdiff_all_sq: 8.131162501062754e+18\n",
            "E_IS_SCOPE: -3.6450744394082956e+22\n",
            "E_IS_E_SCOPE: -1.1847044150901915e+22\n",
            "Total Loss: -8.342139526669612e+19\n",
            "----------------------------------------\n",
            "Epoch 151\n",
            "Var loss:  tensor(-9.9733e+19, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2123977943652638e+22\n",
            "E_s_wdiff_all_sq: 8.085648236205699e+18\n",
            "E_IS_SCOPE: -3.648302565185138e+22\n",
            "E_IS_E_SCOPE: -1.1864753728287364e+22\n",
            "Total Loss: -9.973276548626016e+19\n",
            "----------------------------------------\n",
            "Epoch 152\n",
            "Var loss:  tensor(-1.1610e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2122836464148526e+22\n",
            "E_s_wdiff_all_sq: 8.255304982092833e+18\n",
            "E_IS_SCOPE: -3.6508355153682198e+22\n",
            "E_IS_E_SCOPE: -1.1876563661881833e+22\n",
            "Total Loss: -1.1610344786860232e+20\n",
            "----------------------------------------\n",
            "Epoch 153\n",
            "Var loss:  tensor(-1.3250e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.21218220693654e+22\n",
            "E_s_wdiff_all_sq: 8.437896556983168e+18\n",
            "E_IS_SCOPE: -3.653336550031556e+22\n",
            "E_IS_E_SCOPE: -1.1888109242496026e+22\n",
            "Total Loss: -1.3250179407587102e+20\n",
            "----------------------------------------\n",
            "Epoch 154\n",
            "Var loss:  tensor(-1.4892e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2119185830499483e+22\n",
            "E_s_wdiff_all_sq: 8.382579473740544e+18\n",
            "E_IS_SCOPE: -3.656727125519529e+22\n",
            "E_IS_E_SCOPE: -1.1906118321752961e+22\n",
            "Total Loss: -1.489223049304395e+20\n",
            "----------------------------------------\n",
            "Epoch 155\n",
            "Var loss:  tensor(-1.6541e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2117650689385132e+22\n",
            "E_s_wdiff_all_sq: 8.26333388347596e+18\n",
            "E_IS_SCOPE: -3.6604477559866455e+22\n",
            "E_IS_E_SCOPE: -1.1925937647230688e+22\n",
            "Total Loss: -1.6541207895394065e+20\n",
            "----------------------------------------\n",
            "Epoch 156\n",
            "Var loss:  tensor(-1.8192e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2120739593354765e+22\n",
            "E_s_wdiff_all_sq: 8.229488802725618e+18\n",
            "E_IS_SCOPE: -3.664043847529751e+22\n",
            "E_IS_E_SCOPE: -1.194337817449285e+22\n",
            "Total Loss: -1.819234240599341e+20\n",
            "----------------------------------------\n",
            "Epoch 157\n",
            "Var loss:  tensor(-1.9848e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2125690287053961e+22\n",
            "E_s_wdiff_all_sq: 8.348566220547242e+18\n",
            "E_IS_SCOPE: -3.6671138775860448e+22\n",
            "E_IS_E_SCOPE: -1.1956674411768094e+22\n",
            "Total Loss: -1.9848461966088182e+20\n",
            "----------------------------------------\n",
            "Epoch 158\n",
            "Var loss:  tensor(-2.1512e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2128147442954976e+22\n",
            "E_s_wdiff_all_sq: 8.420738146647486e+18\n",
            "E_IS_SCOPE: -3.670274869727986e+22\n",
            "E_IS_E_SCOPE: -1.1971382361353921e+22\n",
            "Total Loss: -2.151234578412051e+20\n",
            "----------------------------------------\n",
            "Epoch 159\n",
            "Var loss:  tensor(-2.3184e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2126009066524512e+22\n",
            "E_s_wdiff_all_sq: 8.344881417173497e+18\n",
            "E_IS_SCOPE: -3.673834145068559e+22\n",
            "E_IS_E_SCOPE: -1.199025233810653e+22\n",
            "Total Loss: -2.3183741082530533e+20\n",
            "----------------------------------------\n",
            "Epoch 160\n",
            "Var loss:  tensor(-2.4857e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.212222862724474e+22\n",
            "E_s_wdiff_all_sq: 8.248367842994133e+18\n",
            "E_IS_SCOPE: -3.677405529269655e+22\n",
            "E_IS_E_SCOPE: -1.2009744608298323e+22\n",
            "Total Loss: -2.485687235516249e+20\n",
            "----------------------------------------\n",
            "Epoch 161\n",
            "Var loss:  tensor(-2.6531e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2121951517397496e+22\n",
            "E_s_wdiff_all_sq: 8.258280085326128e+18\n",
            "E_IS_SCOPE: -3.6807117129377695e+22\n",
            "E_IS_E_SCOPE: -1.202629835048986e+22\n",
            "Total Loss: -2.653082801865375e+20\n",
            "----------------------------------------\n",
            "Epoch 162\n",
            "Var loss:  tensor(-2.8219e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2125247681776715e+22\n",
            "E_s_wdiff_all_sq: 8.264314752660881e+18\n",
            "E_IS_SCOPE: -3.6842280926602175e+22\n",
            "E_IS_E_SCOPE: -1.204301443460597e+22\n",
            "Total Loss: -2.8219145790795284e+20\n",
            "----------------------------------------\n",
            "Epoch 163\n",
            "Var loss:  tensor(-2.9902e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2130926858498822e+22\n",
            "E_s_wdiff_all_sq: 8.219817826283616e+18\n",
            "E_IS_SCOPE: -3.688056087900254e+22\n",
            "E_IS_E_SCOPE: -1.2061030600384847e+22\n",
            "Total Loss: -2.990236886499391e+20\n",
            "----------------------------------------\n",
            "Epoch 164\n",
            "Var loss:  tensor(-3.1591e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.213479631084819e+22\n",
            "E_s_wdiff_all_sq: 8.23389938709003e+18\n",
            "E_IS_SCOPE: -3.6915697644503143e+22\n",
            "E_IS_E_SCOPE: -1.207753652447686e+22\n",
            "Total Loss: -3.1590999502574374e+20\n",
            "----------------------------------------\n",
            "Epoch 165\n",
            "Var loss:  tensor(-3.3286e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2136468634913175e+22\n",
            "E_s_wdiff_all_sq: 8.289467987627777e+18\n",
            "E_IS_SCOPE: -3.694824043785155e+22\n",
            "E_IS_E_SCOPE: -1.2093024621805932e+22\n",
            "Total Loss: -3.328589656703579e+20\n",
            "----------------------------------------\n",
            "Epoch 166\n",
            "Var loss:  tensor(-3.4989e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2134705751119041e+22\n",
            "E_s_wdiff_all_sq: 8.291764886023741e+18\n",
            "E_IS_SCOPE: -3.698149670076634e+22\n",
            "E_IS_E_SCOPE: -1.2110106369742548e+22\n",
            "Total Loss: -3.4988913148421997e+20\n",
            "----------------------------------------\n",
            "Epoch 167\n",
            "Var loss:  tensor(-3.6700e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.213039316564978e+22\n",
            "E_s_wdiff_all_sq: 8.264366484504631e+18\n",
            "E_IS_SCOPE: -3.701491381174132e+22\n",
            "E_IS_E_SCOPE: -1.2128119695772934e+22\n",
            "Total Loss: -3.6699596081228415e+20\n",
            "----------------------------------------\n",
            "Epoch 168\n",
            "Var loss:  tensor(-3.8416e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2123261165467863e+22\n",
            "E_s_wdiff_all_sq: 8.239663391580307e+18\n",
            "E_IS_SCOPE: -3.704699648541147e+22\n",
            "E_IS_E_SCOPE: -1.214616576249274e+22\n",
            "Total Loss: -3.8415510817507954e+20\n",
            "----------------------------------------\n",
            "Epoch 169\n",
            "Var loss:  tensor(-4.0132e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2116852350069638e+22\n",
            "E_s_wdiff_all_sq: 8.291866007374452e+18\n",
            "E_IS_SCOPE: -3.7076294944289123e+22\n",
            "E_IS_E_SCOPE: -1.2162111886370726e+22\n",
            "Total Loss: -4.013224696946591e+20\n",
            "----------------------------------------\n",
            "Epoch 170\n",
            "Var loss:  tensor(-4.1853e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.210642780049374e+22\n",
            "E_s_wdiff_all_sq: 8.01366323478059e+18\n",
            "E_IS_SCOPE: -3.711735197027742e+22\n",
            "E_IS_E_SCOPE: -1.2187223125450188e+22\n",
            "Total Loss: -4.1852735400876546e+20\n",
            "----------------------------------------\n",
            "Epoch 171\n",
            "Var loss:  tensor(-4.3586e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2109008702331886e+22\n",
            "E_s_wdiff_all_sq: 8.16398986667352e+18\n",
            "E_IS_SCOPE: -3.714713199838404e+22\n",
            "E_IS_E_SCOPE: -1.2200439302998408e+22\n",
            "Total Loss: -4.3585797573920267e+20\n",
            "----------------------------------------\n",
            "Epoch 172\n",
            "Var loss:  tensor(-4.5314e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.212087637752977e+22\n",
            "E_s_wdiff_all_sq: 8.638088036883652e+18\n",
            "E_IS_SCOPE: -3.71681940797954e+22\n",
            "E_IS_E_SCOPE: -1.2204764859696138e+22\n",
            "Total Loss: -4.531377932708474e+20\n",
            "----------------------------------------\n",
            "Epoch 173\n",
            "Var loss:  tensor(-4.7048e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2123902708499142e+22\n",
            "E_s_wdiff_all_sq: 8.733292606359138e+18\n",
            "E_IS_SCOPE: -3.7200627660297574e+22\n",
            "E_IS_E_SCOPE: -1.2219597293820418e+22\n",
            "Total Loss: -4.704813209329766e+20\n",
            "----------------------------------------\n",
            "Epoch 174\n",
            "Var loss:  tensor(-4.8790e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2115666260143678e+22\n",
            "E_s_wdiff_all_sq: 8.331541217390411e+18\n",
            "E_IS_SCOPE: -3.724784002286469e+22\n",
            "E_IS_E_SCOPE: -1.2248011196940373e+22\n",
            "Total Loss: -4.8790078506281625e+20\n",
            "----------------------------------------\n",
            "Epoch 175\n",
            "Var loss:  tensor(-5.0527e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2106786529175245e+22\n",
            "E_s_wdiff_all_sq: 8.213216407732219e+18\n",
            "E_IS_SCOPE: -3.728333488111103e+22\n",
            "E_IS_E_SCOPE: -1.2268844606422237e+22\n",
            "Total Loss: -5.0527000407833156e+20\n",
            "----------------------------------------\n",
            "Epoch 176\n",
            "Var loss:  tensor(-5.2267e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2104740401032292e+22\n",
            "E_s_wdiff_all_sq: 8.510874854617543e+18\n",
            "E_IS_SCOPE: -3.7305213053481672e+22\n",
            "E_IS_E_SCOPE: -1.2278310889669188e+22\n",
            "Total Loss: -5.226736272217169e+20\n",
            "----------------------------------------\n",
            "Epoch 177\n",
            "Var loss:  tensor(-5.4007e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2100940052908405e+22\n",
            "E_s_wdiff_all_sq: 8.792421467982654e+18\n",
            "E_IS_SCOPE: -3.7327119683469124e+22\n",
            "E_IS_E_SCOPE: -1.2288382970208966e+22\n",
            "Total Loss: -5.400709937011706e+20\n",
            "----------------------------------------\n",
            "Epoch 178\n",
            "Var loss:  tensor(-5.5752e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2093763765539095e+22\n",
            "E_s_wdiff_all_sq: 8.614067751322986e+18\n",
            "E_IS_SCOPE: -3.7365843230369256e+22\n",
            "E_IS_E_SCOPE: -1.2310774985500672e+22\n",
            "Total Loss: -5.5751832899562766e+20\n",
            "----------------------------------------\n",
            "Epoch 179\n",
            "Var loss:  tensor(-5.7494e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.208933879273105e+22\n",
            "E_s_wdiff_all_sq: 8.377411254038716e+18\n",
            "E_IS_SCOPE: -3.7408247779311686e+22\n",
            "E_IS_E_SCOPE: -1.2334712859416265e+22\n",
            "Total Loss: -5.7493877794175504e+20\n",
            "----------------------------------------\n",
            "Epoch 180\n",
            "Var loss:  tensor(-5.9243e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2093801035991972e+22\n",
            "E_s_wdiff_all_sq: 8.56574149282789e+18\n",
            "E_IS_SCOPE: -3.7437849953760174e+22\n",
            "E_IS_E_SCOPE: -1.2347130385251166e+22\n",
            "Total Loss: -5.924283060731039e+20\n",
            "----------------------------------------\n",
            "Epoch 181\n",
            "Var loss:  tensor(-6.0998e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2100305099436887e+22\n",
            "E_s_wdiff_all_sq: 8.85042078515889e+18\n",
            "E_IS_SCOPE: -3.746482005382111e+22\n",
            "E_IS_E_SCOPE: -1.2357091174867993e+22\n",
            "Total Loss: -6.099820738995814e+20\n",
            "----------------------------------------\n",
            "Epoch 182\n",
            "Var loss:  tensor(-6.2760e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2099466959183845e+22\n",
            "E_s_wdiff_all_sq: 8.780537904300356e+18\n",
            "E_IS_SCOPE: -3.7502545657424113e+22\n",
            "E_IS_E_SCOPE: -1.2376647901713424e+22\n",
            "Total Loss: -6.276012408223386e+20\n",
            "----------------------------------------\n",
            "Epoch 183\n",
            "Var loss:  tensor(-6.4528e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2093927200575749e+22\n",
            "E_s_wdiff_all_sq: 8.502721682101603e+18\n",
            "E_IS_SCOPE: -3.7546498660110006e+22\n",
            "E_IS_E_SCOPE: -1.2401904736392521e+22\n",
            "Total Loss: -6.452765007649303e+20\n",
            "----------------------------------------\n",
            "Epoch 184\n",
            "Var loss:  tensor(-6.6288e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2091641687126665e+22\n",
            "E_s_wdiff_all_sq: 8.421209012866424e+18\n",
            "E_IS_SCOPE: -3.758405071735987e+22\n",
            "E_IS_E_SCOPE: -1.2421832478324517e+22\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-01d57a9c684f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_IS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded_state_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates_first_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates_last_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_all_shaping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_IS_SCOPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-30-5d294114b799>\u001b[0m in \u001b[0;36mtrain_var\u001b[0;34m(model, num_epochs, learning_rate, samples_IS, padded_state_tensors, states_first_tensor, states_last_tensor, samples_all_shaping, samples_IS_SCOPE, test1)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# Retain the graph to avoid clearing it before backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mtot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = train_var(model, 200, 0.0001, samples_IS, padded_state_tensors, states_first_tensor, states_last_tensor, samples_all_shaping, samples_IS_SCOPE, test1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "V5HankiakEiu",
        "outputId": "6616ce3c-94b2-4fdf-9833-cd1af30ac8fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Var loss:  tensor(-5.0872e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2091641687126665e+22\n",
            "E_s_wdiff_all_sq: 8.421209012866424e+18\n",
            "E_IS_SCOPE: -2.547315218031649e+25\n",
            "E_IS_E_SCOPE: -1.2421832478324517e+22\n",
            "Total Loss: -5.087179914210118e+25\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "Var loss:  tensor(-5.3797e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.1588018418409055e+22\n",
            "E_s_wdiff_all_sq: 8.04536804186359e+20\n",
            "E_IS_SCOPE: -2.694291367756086e+25\n",
            "E_IS_E_SCOPE: -1.7349946687008094e+22\n",
            "Total Loss: -5.379704141723259e+25\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "Var loss:  tensor(-5.6711e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.4111873352395464e+22\n",
            "E_s_wdiff_all_sq: 3.463374565893483e+21\n",
            "E_IS_SCOPE: -2.8408122806833696e+25\n",
            "E_IS_E_SCOPE: -2.215367046350286e+22\n",
            "Total Loss: -5.671052464951478e+25\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "Var loss:  tensor(-5.9621e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.9427952560721845e+22\n",
            "E_s_wdiff_all_sq: 7.837952653226776e+21\n",
            "E_IS_SCOPE: -2.987325832672755e+25\n",
            "E_IS_E_SCOPE: -2.682911211818654e+22\n",
            "Total Loss: -5.962145328513011e+25\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "Var loss:  tensor(-6.2530e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 2.7263608969798527e+22\n",
            "E_s_wdiff_all_sq: 1.375398874050293e+22\n",
            "E_IS_SCOPE: -3.1338148723437466e+25\n",
            "E_IS_E_SCOPE: -3.1355187507019592e+22\n",
            "Total Loss: -6.252982019597437e+25\n",
            "----------------------------------------\n",
            "Epoch 6\n",
            "Var loss:  tensor(-6.5435e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 3.748339183415563e+22\n",
            "E_s_wdiff_all_sq: 2.116529777547345e+22\n",
            "E_IS_SCOPE: -3.280275788491791e+25\n",
            "E_IS_E_SCOPE: -3.5795217994547766e+22\n",
            "Total Loss: -6.543549864460832e+25\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "Var loss:  tensor(-6.8338e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 5.004461314920678e+22\n",
            "E_s_wdiff_all_sq: 3.0068462342649105e+22\n",
            "E_IS_SCOPE: -3.4266963700336215e+25\n",
            "E_IS_E_SCOPE: -4.018966356332541e+22\n",
            "Total Loss: -6.833816571742354e+25\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "Var loss:  tensor(-7.1238e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 6.481053799005235e+22\n",
            "E_s_wdiff_all_sq: 4.037113835105185e+22\n",
            "E_IS_SCOPE: -3.57308221505971e+25\n",
            "E_IS_E_SCOPE: -4.452089429979757e+22\n",
            "Total Loss: -7.1238123000895045e+25\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "Var loss:  tensor(-7.4135e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 8.170428479059414e+22\n",
            "E_s_wdiff_all_sq: 5.203125263787489e+22\n",
            "E_IS_SCOPE: -3.7194150366745127e+25\n",
            "E_IS_E_SCOPE: -4.879709737567206e+22\n",
            "Total Loss: -7.413505707716294e+25\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "Var loss:  tensor(-7.7029e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.006562379984491e+23\n",
            "E_s_wdiff_all_sq: 6.5009257231549674e+22\n",
            "E_IS_SCOPE: -3.8656945868055057e+25\n",
            "E_IS_E_SCOPE: -5.302351238455299e+22\n",
            "Total Loss: -7.702901688154831e+25\n",
            "----------------------------------------\n",
            "Epoch 11\n",
            "Var loss:  tensor(-7.9920e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.215950259010862e+23\n",
            "E_s_wdiff_all_sq: 7.926284934170995e+22\n",
            "E_IS_SCOPE: -4.0119165595627445e+25\n",
            "E_IS_E_SCOPE: -5.720242133076124e+22\n",
            "Total Loss: -7.991998082195182e+25\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "Var loss:  tensor(-8.2808e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.4444713311004935e+23\n",
            "E_s_wdiff_all_sq: 9.47475141144426e+22\n",
            "E_IS_SCOPE: -4.158076958043214e+25\n",
            "E_IS_E_SCOPE: -6.133460319520498e+22\n",
            "Total Loss: -8.280794013875891e+25\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "Var loss:  tensor(-8.5693e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.691368025139844e+23\n",
            "E_s_wdiff_all_sq: 1.1141678394072568e+23\n",
            "E_IS_SCOPE: -4.3041720954261145e+25\n",
            "E_IS_E_SCOPE: -6.5420000998008646e+22\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-5d2902af0be1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_IS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded_state_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates_first_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates_last_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_all_shaping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_IS_SCOPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-38-5d294114b799>\u001b[0m in \u001b[0;36mtrain_var\u001b[0;34m(model, num_epochs, learning_rate, samples_IS, padded_state_tensors, states_first_tensor, states_last_tensor, samples_all_shaping, samples_IS_SCOPE, test1)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# Retain the graph to avoid clearing it before backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mtot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = train_var(model, 20, 0.001, samples_IS, padded_state_tensors, states_first_tensor, states_last_tensor, samples_all_shaping, samples_IS_SCOPE, test1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHLpALXBN40b",
        "outputId": "8cffe722-37df-4139-8ebf-3479a805cb23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Var loss:  tensor(-1.3998e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 2.7000520983736854e+26\n",
            "E_s_wdiff_all_sq: 1.1991158006418987e+26\n",
            "E_IS_SCOPE: -2.0238984353616566e+26\n",
            "E_IS_E_SCOPE: 1.7432066784634587e+24\n",
            "Total Loss: -1.3997894919094345e+26\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "Var loss:  tensor(-1.8930e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 2.4851380256092592e+26\n",
            "E_s_wdiff_all_sq: 1.0868796875981285e+26\n",
            "E_IS_SCOPE: -2.1642866384407017e+26\n",
            "E_IS_E_SCOPE: 1.6592145943890643e+24\n",
            "Total Loss: -1.892960208309719e+26\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "Var loss:  tensor(-2.3750e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 2.2864222596610805e+26\n",
            "E_s_wdiff_all_sq: 9.831123864853387e+25\n",
            "E_IS_SCOPE: -2.3071556879644427e+26\n",
            "E_IS_E_SCOPE: 1.5775847477927258e+24\n",
            "Total Loss: -2.3749651779074894e+26\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "Var loss:  tensor(-2.8423e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 2.1107685666169942e+26\n",
            "E_s_wdiff_all_sq: 8.908178298603343e+25\n",
            "E_IS_SCOPE: -2.454130057488368e+26\n",
            "E_IS_E_SCOPE: 1.5012467817496386e+24\n",
            "Total Loss: -2.842277471018134e+26\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "Var loss:  tensor(-3.2993e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.95377408787041e+26\n",
            "E_s_wdiff_all_sq: 8.078126017319421e+25\n",
            "E_IS_SCOPE: -2.6052506542281885e+26\n",
            "E_IS_E_SCOPE: 1.4291329785199847e+24\n",
            "Total Loss: -3.299349729147468e+26\n",
            "----------------------------------------\n",
            "Epoch 6\n",
            "Var loss:  tensor(-3.7487e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.8132467079007727e+26\n",
            "E_s_wdiff_all_sq: 7.329651482777037e+25\n",
            "E_IS_SCOPE: -2.7606843344170066e+26\n",
            "E_IS_E_SCOPE: 1.360869471486018e+24\n",
            "Total Loss: -3.748696564283724e+26\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "Var loss:  tensor(-4.1896e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.688620283159106e+26\n",
            "E_s_wdiff_all_sq: 6.659493094301345e+25\n",
            "E_IS_SCOPE: -2.9198032751618074e+26\n",
            "E_IS_E_SCOPE: 1.2967482268817199e+24\n",
            "Total Loss: -4.189637233176863e+26\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "Var loss:  tensor(-4.6262e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.576707664912865e+26\n",
            "E_s_wdiff_all_sq: 6.052083489607422e+25\n",
            "E_IS_SCOPE: -3.08305451841946e+26\n",
            "E_IS_E_SCOPE: 1.2357861039386222e+24\n",
            "Total Loss: -4.626223474250116e+26\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "Var loss:  tensor(-5.0587e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.4763612808585628e+26\n",
            "E_s_wdiff_all_sq: 5.50174234409973e+25\n",
            "E_IS_SCOPE: -3.2499784261118546e+26\n",
            "E_IS_E_SCOPE: 1.1778527193751983e+24\n",
            "Total Loss: -5.058679672152305e+26\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "Var loss:  tensor(-5.4889e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.3848700547605917e+26\n",
            "E_s_wdiff_all_sq: 4.995988928518009e+25\n",
            "E_IS_SCOPE: -3.420172749344094e+26\n",
            "E_IS_E_SCOPE: 1.1220005061754078e+24\n",
            "Total Loss: -5.488883978318761e+26\n",
            "----------------------------------------\n",
            "Epoch 11\n",
            "Var loss:  tensor(-5.9179e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.3006442730443957e+26\n",
            "E_s_wdiff_all_sq: 4.527488207429612e+25\n",
            "E_IS_SCOPE: -3.593391101377815e+26\n",
            "E_IS_E_SCOPE: 1.067680399123898e+24\n",
            "Total Loss: -5.917916860890854e+26\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "Var loss:  tensor(-6.3462e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2229417912969604e+26\n",
            "E_s_wdiff_all_sq: 4.092707164503446e+25\n",
            "E_IS_SCOPE: -3.769466846843736e+26\n",
            "E_IS_E_SCOPE: 1.0146928561134615e+24\n",
            "Total Loss: -6.346181207279818e+26\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "Var loss:  tensor(-6.7612e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.1518335335596193e+26\n",
            "E_s_wdiff_all_sq: 3.6950381982478167e+25\n",
            "E_IS_SCOPE: -3.9421864533730626e+26\n",
            "E_IS_E_SCOPE: 9.636992190084379e+23\n",
            "Total Loss: -6.761198868962662e+26\n",
            "----------------------------------------\n",
            "Epoch 14\n",
            "Var loss:  tensor(-7.1583e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.0875381753628806e+26\n",
            "E_s_wdiff_all_sq: 3.3357822679325225e+25\n",
            "E_IS_SCOPE: -4.10933498575679e+26\n",
            "E_IS_E_SCOPE: 9.152111976069571e+23\n",
            "Total Loss: -7.158336651284811e+26\n",
            "----------------------------------------\n",
            "Epoch 15\n",
            "Var loss:  tensor(-7.5579e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.0300003666921198e+26\n",
            "E_s_wdiff_all_sq: 3.008197928388507e+25\n",
            "E_IS_SCOPE: -4.281029201156582e+26\n",
            "E_IS_E_SCOPE: 8.686640466504931e+23\n",
            "Total Loss: -7.557866476226461e+26\n",
            "----------------------------------------\n",
            "Epoch 16\n",
            "Var loss:  tensor(-7.9625e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 9.780866290057678e+25\n",
            "E_s_wdiff_all_sq: 2.706676561722053e+25\n",
            "E_IS_SCOPE: -4.458086666377223e+26\n",
            "E_IS_E_SCOPE: 8.235217772818606e+23\n",
            "Total Loss: -7.962540876273037e+26\n",
            "----------------------------------------\n",
            "Epoch 17\n",
            "Var loss:  tensor(-8.3770e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 9.25864062540654e+25\n",
            "E_s_wdiff_all_sq: 2.408043092938196e+25\n",
            "E_IS_SCOPE: -4.639890551795465e+26\n",
            "E_IS_E_SCOPE: 7.762667967592406e+23\n",
            "Total Loss: -8.376953564158955e+26\n",
            "----------------------------------------\n",
            "Epoch 18\n",
            "Var loss:  tensor(-8.7964e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 8.772145597482964e+25\n",
            "E_s_wdiff_all_sq: 2.128158973430442e+25\n",
            "E_IS_SCOPE: -4.826000005768793e+26\n",
            "E_IS_E_SCOPE: 7.292373507211456e+23\n",
            "Total Loss: -8.796411091516826e+26\n",
            "----------------------------------------\n",
            "Epoch 19\n",
            "Var loss:  tensor(-9.2201e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 8.332681175269682e+25\n",
            "E_s_wdiff_all_sq: 1.8710506668717508e+25\n",
            "E_IS_SCOPE: -5.016565446564469e+26\n",
            "E_IS_E_SCOPE: 6.832218590962401e+23\n",
            "Total Loss: -9.220107950580761e+26\n",
            "----------------------------------------\n",
            "Epoch 20\n",
            "Var loss:  tensor(-9.6468e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 7.938632829251062e+25\n",
            "E_s_wdiff_all_sq: 1.636020374096819e+25\n",
            "E_IS_SCOPE: -5.210907454597642e+26\n",
            "E_IS_E_SCOPE: 6.382979689732807e+23\n",
            "Total Loss: -9.64684908454528e+26\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[ 0.6824,  0.3805],\n",
            "        [ 0.6172,  0.3862],\n",
            "        [-0.0410, -0.2904],\n",
            "        [ 0.3265, -0.6162],\n",
            "        [-0.4672,  0.3825],\n",
            "        [-0.4019,  0.5381],\n",
            "        [-0.0941, -0.5162],\n",
            "        [-0.5809,  0.0319],\n",
            "        [-0.1979,  0.2670],\n",
            "        [-0.4053, -0.3357],\n",
            "        [ 0.0179,  0.6101],\n",
            "        [ 0.3949,  0.0047],\n",
            "        [ 0.7054,  0.4417],\n",
            "        [-0.3734, -0.1384],\n",
            "        [ 0.1148,  0.4802],\n",
            "        [ 0.3828, -0.3846]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([-0.2569,  0.1246,  0.6364, -0.6841, -0.2801, -0.0636, -0.0846, -0.5966,\n",
            "         0.2269, -0.0934,  0.5676, -0.6006,  0.3885, -0.4913, -0.3735,  0.0440],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[ 4.8119e-02, -4.0558e-02,  2.2185e-01,  1.7136e-01,  2.0620e-01,\n",
            "         -7.6490e-02, -4.9387e-03,  1.0780e-01, -9.7940e-02, -5.2611e-02,\n",
            "          8.6816e-02,  2.0431e-01, -1.1189e-01, -2.3857e-01,  4.5704e-02,\n",
            "         -2.4755e-02],\n",
            "        [-1.1661e-01,  1.6673e-01, -1.2172e-01, -1.7377e-02, -1.9116e-01,\n",
            "          2.1572e-01,  1.8230e-01, -3.6067e-02, -4.8273e-02,  2.0668e-01,\n",
            "          1.8825e-01, -2.2010e-01,  3.0955e-02, -2.3602e-01,  1.6450e-01,\n",
            "         -1.9474e-01],\n",
            "        [-2.3669e-01, -8.8660e-02,  1.5782e-01,  5.4865e-02, -3.7314e-02,\n",
            "         -2.2701e-01, -1.7717e-01,  1.0917e-01, -1.3188e-01, -2.3322e-01,\n",
            "         -2.0656e-01, -6.6348e-02,  2.9485e-03, -1.5408e-01,  4.4631e-02,\n",
            "          5.9431e-03],\n",
            "        [-3.1699e-02,  2.1269e-01,  6.5254e-02,  1.6674e-01,  1.0271e-01,\n",
            "         -1.5640e-01, -1.1433e-01,  9.1803e-02,  4.8161e-02,  6.3060e-02,\n",
            "         -1.2206e-01,  1.8972e-01, -1.1215e-01, -6.9293e-02, -1.9905e-01,\n",
            "         -8.7023e-05],\n",
            "        [-5.5292e-02, -2.1445e-01,  1.0447e-01,  1.9652e-01, -2.0886e-01,\n",
            "          8.6149e-02, -6.7564e-02,  1.6284e-01,  1.8813e-01,  1.2977e-01,\n",
            "         -1.8909e-03,  1.5335e-01,  2.2191e-01, -2.0367e-01, -1.9575e-01,\n",
            "         -1.1563e-02],\n",
            "        [-1.5999e-01,  3.4475e-02,  1.4412e-01, -2.0440e-01, -2.4086e-01,\n",
            "          4.3020e-03,  7.6393e-02,  2.0897e-01,  6.2470e-02, -1.5482e-01,\n",
            "          1.8559e-01,  1.2675e-01, -3.5940e-02,  1.3949e-01, -2.4669e-01,\n",
            "         -1.6998e-01],\n",
            "        [-1.4121e-03,  9.2029e-02,  1.6774e-02,  2.4159e-01, -1.8972e-01,\n",
            "          2.2045e-01,  2.4686e-01, -1.0914e-02, -1.4103e-01,  9.1213e-02,\n",
            "         -4.3784e-02, -1.6879e-01,  4.5783e-02,  1.8536e-01,  6.9759e-02,\n",
            "          2.2215e-01],\n",
            "        [-1.2859e-01, -9.0884e-02,  5.4626e-02, -3.8355e-02,  1.1648e-01,\n",
            "          7.5265e-02,  2.2921e-01,  2.3633e-01,  1.0943e-01,  9.5796e-02,\n",
            "          9.7141e-02,  1.2300e-01, -2.5879e-01, -1.2350e-01, -1.5009e-02,\n",
            "          1.3043e-02],\n",
            "        [-1.6694e-02,  1.5965e-01, -4.7113e-02, -2.1283e-01,  7.2415e-02,\n",
            "         -1.0634e-01,  7.0834e-02,  1.0853e-01, -1.9885e-01, -2.0899e-01,\n",
            "         -8.6902e-02,  6.2196e-02,  4.3863e-02,  2.2491e-01,  6.7579e-02,\n",
            "         -2.4318e-01],\n",
            "        [ 1.6246e-02, -1.8128e-01, -1.9994e-01,  7.6150e-02, -2.1505e-01,\n",
            "         -2.4253e-01, -7.8125e-02, -2.0187e-01,  7.0338e-03,  5.8107e-02,\n",
            "         -2.5847e-03, -1.5630e-01, -6.0726e-02, -1.1809e-01, -1.6551e-01,\n",
            "         -5.4297e-02],\n",
            "        [ 2.4383e-01,  4.2616e-02,  5.6662e-02,  1.3916e-01,  2.2539e-01,\n",
            "          1.9607e-01, -1.7537e-01, -1.8012e-01, -1.2684e-01, -1.7179e-01,\n",
            "         -3.5418e-02,  1.2716e-01,  1.2756e-01, -5.8339e-02,  9.8414e-02,\n",
            "          2.5362e-02],\n",
            "        [ 1.6507e-01,  1.7497e-01,  6.1446e-02, -9.7664e-02,  1.8058e-01,\n",
            "         -2.5965e-01, -3.1194e-02, -1.4002e-01,  1.0309e-01,  4.9587e-02,\n",
            "          1.3151e-01,  6.2520e-02, -1.0080e-01,  1.8290e-01, -2.2798e-03,\n",
            "          2.0217e-03],\n",
            "        [-1.5221e-01,  1.4097e-01, -7.1615e-04, -6.8548e-02,  2.2222e-01,\n",
            "          1.2362e-01,  1.8278e-01, -2.1061e-01, -7.6397e-02,  1.7362e-01,\n",
            "          4.3270e-02, -2.1091e-01,  4.2701e-02,  1.2101e-01, -4.7703e-02,\n",
            "         -2.0536e-01],\n",
            "        [-6.6673e-02, -4.6614e-02, -2.1227e-01,  2.9418e-02, -2.1981e-01,\n",
            "          1.3636e-01,  1.7628e-01, -1.8667e-02, -1.4600e-01,  1.7796e-01,\n",
            "         -8.2919e-02, -2.2852e-01, -1.9402e-02, -1.0765e-01,  1.1574e-01,\n",
            "         -1.5714e-01],\n",
            "        [-1.0918e-01, -1.9517e-01,  9.8679e-02,  1.5596e-01, -4.4319e-02,\n",
            "         -1.7486e-01, -1.5448e-01,  2.9712e-02, -3.3289e-03,  1.5767e-01,\n",
            "          1.1929e-01, -2.6514e-01, -1.0920e-03,  8.7649e-02,  7.2158e-02,\n",
            "          6.2090e-02],\n",
            "        [-8.3881e-03,  6.5977e-02,  2.1695e-01,  1.9215e-01, -2.9525e-02,\n",
            "          1.7588e-01, -5.8884e-02,  8.2231e-03,  5.6097e-02, -1.6881e-01,\n",
            "         -1.4676e-01, -1.2744e-01, -1.5995e-01, -1.6587e-02, -2.8196e-02,\n",
            "          2.3959e-01],\n",
            "        [ 9.9272e-02, -8.2990e-02, -1.1069e-01,  1.9435e-01,  2.0021e-01,\n",
            "          1.6971e-01,  5.8639e-02, -1.3337e-01, -1.8521e-02,  2.2435e-01,\n",
            "          6.4262e-02,  5.9340e-02, -5.0475e-02, -5.0460e-03,  1.2239e-01,\n",
            "          1.1172e-01],\n",
            "        [ 8.1245e-02,  1.7842e-01, -1.4347e-01, -1.9353e-01, -9.7532e-02,\n",
            "          3.3191e-02,  9.2401e-02,  3.2447e-02, -7.3296e-02,  4.2897e-02,\n",
            "         -5.4902e-03, -1.7552e-01,  2.3623e-01,  1.8997e-01,  1.3470e-01,\n",
            "         -2.2129e-01],\n",
            "        [-1.9724e-01, -8.5698e-02,  4.3844e-02,  1.9982e-01,  2.4789e-01,\n",
            "         -2.3965e-01, -1.8726e-01,  2.2428e-01, -1.4151e-01,  1.6169e-02,\n",
            "          1.3268e-01,  1.4430e-01, -5.2540e-02, -2.0882e-01, -1.0297e-01,\n",
            "          7.5755e-02],\n",
            "        [-1.3038e-01, -2.1669e-01, -5.8820e-02, -9.0053e-02,  2.5145e-01,\n",
            "         -2.2259e-01,  2.0062e-01, -6.5883e-02,  2.1339e-01,  6.7655e-02,\n",
            "         -1.5339e-01,  1.2299e-01, -6.6090e-02, -9.7631e-02,  2.4591e-01,\n",
            "          1.6375e-02],\n",
            "        [ 2.0833e-01,  2.2925e-01, -8.1671e-02, -7.4458e-02,  2.4689e-01,\n",
            "         -1.7912e-01, -3.0479e-02,  2.2088e-01,  4.1135e-02, -1.4143e-01,\n",
            "          1.4276e-02, -4.4181e-02,  2.1406e-02, -8.7408e-02, -2.6004e-02,\n",
            "         -3.1061e-02],\n",
            "        [ 2.7277e-02, -9.2468e-02, -1.8294e-01, -2.0342e-01,  1.7406e-01,\n",
            "          6.5903e-02,  8.9643e-02, -5.2062e-02,  2.6414e-01, -1.2718e-01,\n",
            "         -2.3894e-01,  1.6539e-01,  1.8297e-02,  6.2260e-02, -9.3196e-02,\n",
            "          4.3673e-03],\n",
            "        [-5.9226e-02, -1.7806e-01, -1.5932e-01,  2.5755e-02,  1.8840e-01,\n",
            "         -2.3118e-01,  4.6522e-02, -1.5184e-01,  5.4040e-03, -6.1534e-03,\n",
            "         -7.5576e-02,  1.5076e-01,  1.9803e-01, -5.7331e-02,  1.2015e-03,\n",
            "         -2.8805e-02],\n",
            "        [ 9.5230e-02, -5.9195e-02,  5.9797e-02, -1.4853e-01,  2.2916e-01,\n",
            "          6.8206e-03, -1.0452e-02, -6.4086e-02,  1.3535e-01,  2.1016e-01,\n",
            "         -1.2791e-01,  1.3874e-01,  2.4114e-01,  1.8081e-01,  1.3184e-01,\n",
            "         -2.1979e-01],\n",
            "        [ 1.9239e-01,  3.5063e-02, -1.7934e-01,  1.7502e-01,  8.2594e-02,\n",
            "          1.0295e-01,  2.3758e-01,  1.2021e-01, -5.1508e-02,  1.5860e-01,\n",
            "          1.1935e-01, -7.2050e-02, -1.4643e-01,  2.2494e-01, -1.6159e-01,\n",
            "         -1.2161e-02],\n",
            "        [-1.1569e-01,  2.4863e-01,  8.7303e-02, -4.0421e-02,  1.6243e-01,\n",
            "          1.6153e-02,  2.2084e-01, -1.5133e-01, -3.1824e-02,  1.2209e-01,\n",
            "          2.3849e-01,  3.1212e-02, -4.0532e-02,  1.5685e-01, -1.0802e-02,\n",
            "         -7.3412e-02],\n",
            "        [ 2.5694e-01, -3.9981e-02, -5.8586e-03,  2.5751e-01, -9.3908e-02,\n",
            "         -2.6468e-01, -6.8448e-02,  5.6993e-02, -8.4784e-02,  1.0977e-01,\n",
            "         -9.5266e-03, -4.4528e-02,  5.6235e-02, -3.2194e-02, -1.3303e-01,\n",
            "          7.7084e-02],\n",
            "        [-1.2107e-01, -4.9455e-02, -1.0928e-01, -1.4182e-01, -2.1752e-01,\n",
            "         -1.3493e-01, -2.4229e-01,  6.4488e-02, -6.0827e-02, -9.6155e-02,\n",
            "          4.3416e-02, -1.0943e-01, -8.7071e-02,  1.0680e-01, -1.9074e-01,\n",
            "          1.8180e-01],\n",
            "        [ 1.1885e-01, -1.3959e-01,  1.3637e-01, -1.7812e-01,  1.7236e-01,\n",
            "          1.7322e-01,  1.5212e-01, -4.9635e-02,  1.2627e-02, -1.7094e-01,\n",
            "          5.6883e-02,  1.1782e-01,  2.6690e-01,  1.5117e-01, -1.3883e-01,\n",
            "         -7.5040e-02],\n",
            "        [ 1.7444e-02, -3.5884e-02, -1.8073e-01, -4.8182e-02,  5.1672e-02,\n",
            "         -2.1597e-01,  1.5905e-02, -2.4473e-01,  2.2163e-01,  6.5373e-02,\n",
            "          1.5828e-01,  4.6021e-02,  2.7998e-02,  1.6024e-01,  2.1393e-01,\n",
            "          1.7622e-02],\n",
            "        [-2.4343e-02,  1.6148e-02,  1.8917e-02,  4.6976e-02,  8.1570e-02,\n",
            "         -7.2976e-02, -8.2241e-02,  9.8812e-02,  1.2289e-01,  1.7245e-01,\n",
            "         -1.7320e-01, -2.4167e-01,  1.7690e-01, -7.3494e-02,  1.4066e-01,\n",
            "         -2.3803e-01],\n",
            "        [-1.9888e-01, -1.8503e-01,  8.4259e-02,  2.4136e-01,  5.5319e-02,\n",
            "         -1.5181e-01,  8.2156e-02, -1.8184e-01, -7.5127e-02, -2.1625e-01,\n",
            "          1.1747e-01, -4.3509e-02, -2.2899e-01,  9.2018e-02,  1.9127e-01,\n",
            "         -1.1790e-01]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([-0.0860, -0.2362, -0.2142,  0.1716,  0.1689,  0.2149, -0.0474, -0.1591,\n",
            "        -0.1497, -0.0224, -0.1051, -0.1015,  0.1446,  0.1406,  0.2544, -0.1735,\n",
            "        -0.1481, -0.1807,  0.0241, -0.2079,  0.2115,  0.0250,  0.1389,  0.2335,\n",
            "         0.2197,  0.1802,  0.2623, -0.1372,  0.0478,  0.2256,  0.0486, -0.0534],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[ 0.1721,  0.0623, -0.0768,  0.1644,  0.0325, -0.0332, -0.0931,  0.0436,\n",
            "          0.0268, -0.0838, -0.1538, -0.0204,  0.0539, -0.0472,  0.1059, -0.0720,\n",
            "          0.1543, -0.0265,  0.0777,  0.1012,  0.1266,  0.0518, -0.1264, -0.1316,\n",
            "         -0.0902, -0.0639, -0.1390,  0.0065,  0.1957, -0.0794,  0.0822,  0.1624]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([0.1091], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Working on prep"
      ],
      "metadata": {
        "id": "O36PGywGna2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Working on padding trajectories to allow for easier optimization\n",
        "\n",
        "# def pad_trajectories(pi_b):\n",
        "#     # Find the maximum length among all trajectories\n",
        "#     max_length = max(len(traj) for traj in pi_b)\n",
        "\n",
        "#     # Define the padding value\n",
        "#     padding_value = np.array([np.array([0, 0]), 0, 0, np.array([0, 0]), 0, 0], dtype=object)\n",
        "\n",
        "#     # Pad each trajectory to match the maximum length\n",
        "#     padded_pi_b = [traj + [padding_value] * (max_length - len(traj)) for traj in pi_b]\n",
        "\n",
        "#     return padded_pi_b"
      ],
      "metadata": {
        "id": "ErjhWCq3czmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pi_b_padded = pad_trajectories(pi_b)"
      ],
      "metadata": {
        "id": "31TWTP7Eb1sC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def variance_terms_tens(eval_policy, behav_policy, behavior_policies):\n",
        "  # Initialize lists to store axis data for each policy\n",
        "  timesteps = []\n",
        "  states = []\n",
        "  state_first = []\n",
        "  state_last = []\n",
        "  actions = []\n",
        "  rewards = []\n",
        "  gamma_last = []\n",
        "  weight_last = []\n",
        "  weights = calculate_importance_weights(eval_policy, behav_policy, behavior_policies)\n",
        "  psi = []\n",
        "\n",
        "  for index, policy in enumerate(behavior_policies):\n",
        "      policy_array = np.array(policy)\n",
        "      timesteps.append(policy_array[:, 4].astype(int))\n",
        "      # s.append(policy_array[:, 0])\n",
        "\n",
        "      # last timestep for gamma\n",
        "      gamma_last.append(len(policy))\n",
        "      # last importance weight\n",
        "      weight_last.append(weights[index][-1])\n",
        "\n",
        "\n",
        "      states.append(policy_array[:, 0][1:])\n",
        "      psi.append(policy_array[:,5][1:])\n",
        "      state_first.append(policy_array[:,0][0])\n",
        "      state_last.append(policy_array[:,0][-1])\n",
        "      actions.append(policy_array[:, 1])\n",
        "      rewards.append(policy_array[:, 2].astype(float))\n",
        "\n",
        "  weights_difference = []\n",
        "  for index, weight in enumerate(weights):\n",
        "    # diff = np.array(w[index][:-1]) - np.array(w[index][1:])\n",
        "    diff = np.array(weight[:-1]) - np.array(weight[1:])\n",
        "    weights_difference.append(diff)\n",
        "\n",
        "  return timesteps, states, state_first, state_last, actions, rewards, gamma_last, weight_last, weights, weights_difference"
      ],
      "metadata": {
        "id": "Kcx483JVfDWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# t, s, s_f, s_l, a, r, g_l, w_l, w, w_diff = variance_terms_tens(P_pi_e, P_pi_b, pi_b)"
      ],
      "metadata": {
        "id": "q8d3KfusfsZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "timesteps, states, states_first, states_last, actions, rewards, gamma_last, weights_last, weights, weights_difference = variance_terms_tens(P_pi_e, P_pi_b, pi_b)"
      ],
      "metadata": {
        "id": "BAqNV3alEAjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def padding_IS_terms(timesteps, actions, rewards, weights):\n",
        "    # Find the maximum length among all lists\n",
        "    max_length = max(len(traj) for traj in timesteps)\n",
        "\n",
        "    # Define the padding values\n",
        "    zero_padding = 0\n",
        "\n",
        "    # Pad each list to match the maximum length\n",
        "    padded_timesteps = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in timesteps]\n",
        "    padded_rewards = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in rewards]\n",
        "    padded_actions = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in actions]\n",
        "    padded_weights = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in weights]\n",
        "\n",
        "    return padded_timesteps, padded_rewards, padded_actions, padded_weights"
      ],
      "metadata": {
        "id": "AuuBKl0joAEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_timesteps, padded_rewards, padded_actions, padded_weights = padding_IS_terms(timesteps, actions, rewards, weights)"
      ],
      "metadata": {
        "id": "xD675spBnrP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def padding_states_weights_difference(states, weights_difference):\n",
        "    # Find the maximum length of trajectories\n",
        "    max_length = max(len(trajectory) for trajectory in states)\n",
        "\n",
        "    zero_padding = 0\n",
        "\n",
        "    # Pad each trajectory to make them all the same length\n",
        "    padded_states = [\n",
        "        [list(item) for item in trajectory] + [[0, 0]] * (max_length - len(trajectory))\n",
        "        for trajectory in states\n",
        "    ]\n",
        "\n",
        "    padded_weights_difference = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in weights_difference]\n",
        "\n",
        "    return padded_states, padded_weights_difference"
      ],
      "metadata": {
        "id": "4DekSrOTzLAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_states, padded_weights_difference = padding_states_weights_difference(states, weights_difference)"
      ],
      "metadata": {
        "id": "aX6DIhEQTCVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tensorize_padded_terms(padded_states, padded_weights_difference):\n",
        "  padded_state_tensors = torch.tensor(padded_states, dtype = torch.float64)\n",
        "  padded_weight_diff_tensors = torch.tensor(padded_weights_difference, dtype = torch.float64)\n",
        "  padded_weight_diff_tensors = padded_weight_diff_tensors.unsqueeze(-1)\n",
        "\n",
        "  return padded_state_tensors, padded_weight_diff_tensors\n"
      ],
      "metadata": {
        "id": "hHZhHnuUzHFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_state_tensors, padded_weight_diff_tensors = tensorize_padded_terms(padded_states, padded_weights_difference)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5kb1vOxTZSu",
        "outputId": "6b5b983d-35ca-4d5f-9ff4-1cba9d74450b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-3c22136e8020>:3: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  padded_weight_diff_tensors = torch.tensor(padded_weights_difference, dtype = torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tensorize_last_and_first_terms(states_first, states_last, gamma_last, weights_last):\n",
        "  states_first_tensor = torch.tensor(states_first, dtype = torch.float64)\n",
        "  states_last_tensor = torch.tensor(states_last, dtype = torch.float64)\n",
        "  gamma_last_tensor = torch.tensor(gamma_last, dtype = torch.float64)\n",
        "  weights_last_tensor = torch.tensor(weights_last, dtype = torch.float64)\n",
        "\n",
        "  return states_first_tensor, states_last_tensor, gamma_last_tensor, weights_last_tensor"
      ],
      "metadata": {
        "id": "AqtoK6MEmPWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "states_first_tensor, states_last_tensor, gamma_last_tensor, weights_last_tensor = tensorize_last_and_first_terms(states_first, states_last, gamma_last, weights_last)"
      ],
      "metadata": {
        "id": "gvE-AddhDTkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_IS_terms(gamma, timesteps, rewards, weights):\n",
        "  gtrw = np.power(gamma, timesteps)*rewards*weights\n",
        "\n",
        "  IS_tensor = torch.sum(torch.tensor(gtrw, dtype = torch.float32), dim = 1, keepdim = True)\n",
        "\n",
        "  return IS_tensor\n"
      ],
      "metadata": {
        "id": "YVpa0bTwd3HX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IS_tensor = calc_IS_terms(0.9, padded_timesteps, padded_rewards, padded_weights)"
      ],
      "metadata": {
        "id": "xjRU7xlj89PY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.finfo(torch.float64).max"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGtcFc-YY9SK",
        "outputId": "ce82a7a6-848c-4034-f260-6a3bf7702324"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.7976931348623157e+308"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# samples_IS[0]"
      ],
      "metadata": {
        "id": "s_JAi7apXuJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_gamma_weight_last(gamma, gamma_last, weights_last):\n",
        "  gamma_weight_last = np.power(gamma, gamma_last)*weights_last\n",
        "\n",
        "  gamma_weight_last_tensor = torch.tensor(gamma_weight_last, dtype = torch.float64).unsqueeze(-1)\n",
        "\n",
        "  return gamma_weight_last_tensor"
      ],
      "metadata": {
        "id": "8I3qisEpsYzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gamma_weights_last_tensor = calc_gamma_weight_last(0.9, gamma_last, weights_last)"
      ],
      "metadata": {
        "id": "XHDztxg4C3So"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bootstrap_IS_terms(IS_tensor, num_samples):\n",
        "  seed = 42\n",
        "  torch.manual_seed(seed)\n",
        "\n",
        "  num_bootstraps = num_samples*len(IS_tensor)\n",
        "\n",
        "  # Sample indices with replacement\n",
        "  sampled_indices = torch.randint(0, len(IS_tensor), size=(num_bootstraps,), dtype=torch.long)\n",
        "\n",
        "  # new_size = (num_samples, IS_tensor.shape[0], IS_tensor.shape[1])\n",
        "  new_size = (num_samples, IS_tensor.shape[0])\n",
        "\n",
        "  IS_bootstraps = IS_tensor[sampled_indices].view(new_size)\n",
        "\n",
        "  # sampled_tensor = IS_bootstraps.view(new_size)\n",
        "\n",
        "  return IS_bootstraps"
      ],
      "metadata": {
        "id": "rdqtMRAT35lW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples_IS = bootstrap_IS_terms(IS_tensor, 10000)"
      ],
      "metadata": {
        "id": "MHOyNeJ-UdcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clamp_large_terms(input_term):\n",
        "  max_float64 = torch.finfo(torch.float64).max\n",
        "  return torch.clamp(input_term, min=-max_float64, max=max_float64)\n"
      ],
      "metadata": {
        "id": "ng9lLOfsGvdb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clamp_large_terms(input_term):\n",
        "    max_float64 = torch.tensor(torch.finfo(torch.float64).max, dtype=torch.float64)\n",
        "    min_value = torch.tensor(-1e50, dtype=torch.float64)\n",
        "    return torch.clamp(input_term, min=min_value, max=max_float64)\n",
        "\n",
        "    # return torch.clamp(input_term, min=-max_float64, max=max_float64)\n"
      ],
      "metadata": {
        "id": "C1Su5BQ0cfUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CustomizableFeatureNet_d(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dims, output_dim, dropout_prob=0.2, dtype=torch.float32):\n",
        "        super(CustomizableFeatureNet_d, self).__init__()\n",
        "        self.hidden_layers = nn.ModuleList()\n",
        "\n",
        "        # Create the hidden layers based on the provided sizes\n",
        "        for in_dim, out_dim in zip([input_dim] + hidden_dims, hidden_dims):\n",
        "            self.hidden_layers.append(nn.Linear(in_dim, out_dim).to(dtype))\n",
        "\n",
        "        self.output_layer = nn.Linear(hidden_dims[-1], output_dim).to(dtype)\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.hidden_layers:\n",
        "            x = F.relu(layer(x))\n",
        "            x = self.dropout(x)\n",
        "        x = self.output_layer(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "YFqvRa0LS7OF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CustomizableFeatureNet_d(input_dim=2, hidden_dims=[16, 32], output_dim=1, dtype = torch.float64)"
      ],
      "metadata": {
        "id": "udif1c2cTBzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = CustomizableFeatureNet(input_dim=2, hidden_dims=[16, 32], output_dim=1)"
      ],
      "metadata": {
        "id": "ct8DQIU6rUvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pass_states(model, padded_state_tensors, states_first_tensor, states_last_tensor):\n",
        "  # Get model outputs for states\n",
        "  states_output = model(padded_state_tensors)\n",
        "  states_first_output = model(states_first_tensor)\n",
        "  states_last_output = model(states_last_tensor)\n",
        "  return states_output, states_first_output, states_last_output"
      ],
      "metadata": {
        "id": "0JNHRYkBmZ5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "states_output, states_first_output, states_last_output = pass_states(model, padded_state_tensors, states_first_tensor, states_last_tensor)"
      ],
      "metadata": {
        "id": "duNRe00YE34A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def states_weight_diff_sums(states_output, padded_weight_diff_tensors):\n",
        "  states_weight_diff = states_output * padded_weight_diff_tensors\n",
        "  sums_states_weight_diff = torch.sum(states_weight_diff, dim =1)\n",
        "\n",
        "  return sums_states_weight_diff"
      ],
      "metadata": {
        "id": "8nZkrdWPW5AQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sums_states_weight_diff = states_weight_diff_sums(states_output, padded_weight_diff_tensors)"
      ],
      "metadata": {
        "id": "nlxvS4QpYW0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def last_first_terms_operations(gamma_weights_last_tensor, states_last_output, states_first_output):\n",
        "  gamma_weights_states_last_sub_states_first = gamma_weights_last_tensor*states_last_output -  states_first_output\n",
        "\n",
        "  return gamma_weights_states_last_sub_states_first"
      ],
      "metadata": {
        "id": "fDDD0NcUaxpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gamma_weights_states_last_sub_states_first = last_first_terms_operations(gamma_weights_last_tensor, states_last_output, states_first_output)"
      ],
      "metadata": {
        "id": "ScpV8dhaCqHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gamma_weights_states_last_sub_states_first.shape"
      ],
      "metadata": {
        "id": "oC-P2rDqFIwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bootstrap_shaping_terms(sums_states_weight_diff, gamma_weights_states_last_sub_states_first, num_samples):\n",
        "\n",
        "  seed = 42\n",
        "  torch.manual_seed(seed)\n",
        "\n",
        "  num_bootstraps = num_samples*sums_states_weight_diff.shape[0]\n",
        "\n",
        "  # Sample indices with replacement\n",
        "  sampled_indices = torch.randint(0, len(sums_states_weight_diff), size=(num_bootstraps,), dtype=torch.long)\n",
        "\n",
        "  # sizes\n",
        "  # size_states_weights_diff = (num_samples, states_output.shape[0], states_output.shape[1])\n",
        "  reshaped_size = (num_samples, sums_states_weight_diff.shape[0])\n",
        "\n",
        "  # Resize samples to shape num_samples x num_trajectories x length_padded_trajectories\n",
        "  # samples_states_output = states_output[sampled_indices].view(size_states_weights_diff)\n",
        "  # samples_weight_diff = padded_weight_diff_tensors[sampled_indices].view(size_states_weights_diff)\n",
        "\n",
        "  # Resize samples to shape num_samples x num_trajectories\n",
        "  sample_sums_states_weight_diff = sums_states_weight_diff[sampled_indices].view(reshaped_size)\n",
        "  # samples_states_first_output = sums_states_weight_diff[sampled_indices].view(reshaped_size)\n",
        "  # samples_states_last_output = states_last_output[sampled_indices].view(reshaped_size)\n",
        "  samples_gamma_weight_states_last_sub_states_first = gamma_weights_states_last_sub_states_first[sampled_indices].view(reshaped_size)\n",
        "\n",
        "\n",
        "  return sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first\n"
      ],
      "metadata": {
        "id": "d3UM9eUGeQdq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first = bootstrap_shaping_terms(sums_states_weight_diff, gamma_weights_states_last_sub_states_first, 10000)"
      ],
      "metadata": {
        "id": "whCU0iyDCi8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def gtrw_plus_states_weight_diff_min_last_firsts_terms(gtrw_tensor, sums_states_weight_diff, gamma_weights_states_last_sub_states_first):\n",
        "#   sum_IS_and_shaping = gtrw_tensor + sums_states_weight_diff + gamma_weights_states_last_sub_states_first\n",
        "\n",
        "#   return sum_IS_and_shaping"
      ],
      "metadata": {
        "id": "sIw1SreEnUpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def bootstrap_IS_shaping_terms(gtrw_tensor, sums_states_weight_diff, gamma_weights_states_last_sub_states_first):\n",
        "#   seed = 42\n",
        "#   torch.manual_seed(seed)\n",
        "\n",
        "#   num_bootstraps = num_samples*sums_states_weight_diff.shape[0]\n",
        "\n",
        "#   # Sample indices with replacement\n",
        "#   sampled_indices = torch.randint(0, len(sums_states_weight_diff), size=(num_bootstraps,), dtype=torch.long)\n",
        "\n"
      ],
      "metadata": {
        "id": "OZHZzE6d58xQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wTVuyCVBB4-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clamp_large_terms(torch.mean(clamp_large_terms(torch.mean(samples_IS, dim = 1))))"
      ],
      "metadata": {
        "id": "tdFIzbNUgx94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clamp_large_terms(torch.mean(clamp_large_terms(torch.mean(samples_IS, dim =1)**2)))"
      ],
      "metadata": {
        "id": "4dLA0DBLh-pV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clamp_large_terms(torch.mean(clamp_large_terms(torch.mean(samples_IS, dim =1))**2) - torch.mean(clamp_large_terms(torch.mean(samples_IS, dim = 1))))"
      ],
      "metadata": {
        "id": "7pfgg5rZlakd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SCOPE = sample_sums_states_weight_diff+samples_gamma_weight_states_last_sub_states_first"
      ],
      "metadata": {
        "id": "MWwuJS4En1ll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.mean(SCOPE,dim =1).shape"
      ],
      "metadata": {
        "id": "ECEj-Lhooh8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mean(clamp_large_terms(samples_IS), dim = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6YXvZmXYUKd",
        "outputId": "d5a030e2-5c73-48bd-b58f-8e4970fbe046"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([      -inf, 2.0056e+14,       -inf,  ...,       -inf,       -inf,\n",
              "        1.0028e+14])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_shaped_variance(samples_IS, sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first):\n",
        "\n",
        "\n",
        "  # states_output, states_first_output, states_last_output = pass_states(model, padded_state_tensors, states_first_tensor, states_last_tensor)\n",
        "\n",
        "\n",
        "\n",
        "  # Begin calcs without clamping\n",
        "\n",
        "  # IS\n",
        "  E_IS_sq = torch.mean(torch.mean(clamp_large_terms(samples_IS), dim = 1)**2)\n",
        "  E_IS_all_sq = torch.mean(torch.mean(clamp_large_terms(samples_IS), dim = 1))**2\n",
        "\n",
        "  # states_weight_diff\n",
        "  E_s_wdiff_sq = torch.mean(torch.mean(clamp_large_terms(sample_sums_states_weight_diff), dim =1)**2)\n",
        "  E_s_wdiff_all_sq = torch.mean(torch.mean(clamp_large_terms(sample_sums_states_weight_diff), dim = 1))**2\n",
        "\n",
        "  # all terms\n",
        "  SCOPE = clamp_large_terms(sample_sums_states_weight_diff)+clamp_large_terms(samples_gamma_weight_states_last_sub_states_first)\n",
        "  E_IS_SCOPE = torch.mean(torch.mean(clamp_large_terms(samples_IS), dim =1) * torch.mean(SCOPE, dim =1))\n",
        "  E_IS_E_SCOPE = torch.mean(torch.mean(clamp_large_terms(samples_IS),dim = 1 ))*torch.mean(torch.mean(SCOPE, dim =1))\n",
        "\n",
        "  SCOPE_variance = E_IS_sq + 2*E_IS_SCOPE + E_s_wdiff_sq - E_IS_all_sq - 2*E_IS_E_SCOPE - E_IS_E_SCOPE\n",
        "\n",
        "  IS_variance = E_IS_sq - E_IS_all_sq\n",
        "\n",
        "  return IS_variance, SCOPE_variance\n"
      ],
      "metadata": {
        "id": "LLuzewmQ3DR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IS_variance, SCOPE_variance = calculate_shaped_variance(samples_IS, sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first)"
      ],
      "metadata": {
        "id": "Nz9ApTk-qnx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mean(torch.mean(clamp_large_terms(samples_IS), dim = 1)**2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qN1zDrJWo4wZ",
        "outputId": "548dc965-3831-4791-9077-d8d8de7062d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(inf)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SCOPE_variance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBjjOVEggKhd",
        "outputId": "fdeba7f8-0ed2-498d-f842-25fe37e45dcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(nan, dtype=torch.float64, grad_fn=<SubBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IS_variance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyMAdyWjgb4b",
        "outputId": "fcadf31c-726b-4846-b87e-576e2d0c1d59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(nan)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def clamp_large_terms(input_term):\n",
        "    max_float64 = torch.tensor(torch.finfo(torch.float64).max, dtype=torch.float64)\n",
        "    # min_value = torch.tensor(-1e38, dtype=torch.float64)\n",
        "    min_value = torch.tensor(-9e-38, dtype=torch.float64)\n",
        "\n",
        "    # min_value = torch.tensor(-1.7e+308, dtype = torch.float64)\n",
        "    # min_value = torch.tensor(torch.finfo(torch.float64).min, dtype=torch.float64)\n",
        "\n",
        "\n",
        "    # Using torch.where to explicitly set values outside the desired range\n",
        "    clamped_result = torch.where(input_term < min_value, min_value, input_term)\n",
        "    clamped_result = torch.where(clamped_result > max_float64, max_float64, clamped_result)\n",
        "\n",
        "    return clamped_result\n",
        "clamp_large_terms(samples_IS)[0].min()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDs0epOwdjjK",
        "outputId": "70d2de61-11b2-465f-a114-7527e815ead9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-9.0000e-38)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "samples_IS[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGlLqnsIhLAr",
        "outputId": "dbacfd91-4d5b-48ae-8d2b-c36b24042d6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.0000e+00, -9.5567e-34, -1.1020e-12, -5.7703e-20,  0.0000e+00,\n",
              "        -6.6609e-06,  0.0000e+00,  0.0000e+00,  0.0000e+00, -7.4562e-17,\n",
              "        -1.3518e-33, -6.3068e-29, -1.1566e-08,  0.0000e+00, -3.2522e-24,\n",
              "         0.0000e+00,  0.0000e+00, -4.0924e-02,  0.0000e+00,  0.0000e+00,\n",
              "        -6.0833e-21, -1.1020e-12,  0.0000e+00, -3.5032e-43, -3.4013e-37,\n",
              "        -7.9832e-23,  0.0000e+00, -2.2156e-12,  0.0000e+00, -7.3671e-27,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -3.0953e-12,  0.0000e+00, -7.1745e-11,  0.0000e+00,\n",
              "        -1.2184e+02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -4.8370e-19,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -1.7865e-25, -3.0953e-12, -3.1972e-14,\n",
              "         0.0000e+00, -3.9939e-21,  0.0000e+00, -4.2383e-17,  0.0000e+00,\n",
              "         0.0000e+00, -9.5567e-34,  0.0000e+00,  0.0000e+00, -5.4262e-07,\n",
              "        -3.7487e-37, -2.6165e-41,  0.0000e+00, -1.0701e-07,  0.0000e+00,\n",
              "         0.0000e+00, -6.6945e-22,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -1.3046e-34, -1.7190e-19,  0.0000e+00,\n",
              "         9.6867e-18, -4.6108e-20,  1.3313e-32, -4.5634e-22,  0.0000e+00,\n",
              "         0.0000e+00, -1.9068e-20, -3.2430e-22, -8.2104e-17,  0.0000e+00,\n",
              "        -1.0108e-29,  0.0000e+00, -8.4772e-20,  0.0000e+00, -2.0319e-39,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -6.3362e-38,  0.0000e+00,\n",
              "         4.7220e-16,  0.0000e+00, -1.5748e-17,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -1.3046e-34,  3.4275e-23,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.2642e-11,\n",
              "        -2.0774e-08,  0.0000e+00, -2.4060e-40, -3.5032e-43,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "        -9.3884e-01, -8.4772e-20, -2.5036e-39,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -1.3247e-35,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -3.8730e-15, -1.0150e-03, -2.0038e-36,  0.0000e+00,\n",
              "         0.0000e+00, -8.4655e-19,  0.0000e+00, -7.3035e-20, -6.6609e-06,\n",
              "         0.0000e+00,  0.0000e+00, -1.6692e-14, -2.6013e-38,  0.0000e+00,\n",
              "         0.0000e+00, -5.6024e-35, -4.5634e-22,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -2.8727e-10, -2.2156e-12,\n",
              "         0.0000e+00,  0.0000e+00,  5.1149e-40,  0.0000e+00,  0.0000e+00,\n",
              "        -1.3400e-08,  0.0000e+00, -2.6687e-08,  0.0000e+00, -4.5020e-30,\n",
              "        -1.0701e-07, -1.0052e-13,  0.0000e+00,  0.0000e+00, -4.5720e-36,\n",
              "        -2.7511e-36,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -9.6992e-23,  0.0000e+00,  0.0000e+00,  1.1169e-32,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -1.2418e-12,  3.4265e-14,\n",
              "         0.0000e+00,  0.0000e+00, -1.6255e-43, -1.1568e-11,  0.0000e+00,\n",
              "        -2.5918e-04, -4.2958e-02, -1.4635e-26,  0.0000e+00, -8.7134e-11,\n",
              "         3.6282e-29,  0.0000e+00,  0.0000e+00, -1.2983e-17,  0.0000e+00,\n",
              "         0.0000e+00, -1.2418e-12, -1.6759e-21,  0.0000e+00,  0.0000e+00,\n",
              "        -1.9035e-38, -2.1801e-26,  0.0000e+00, -1.2909e-23, -4.1059e-16,\n",
              "        -2.4789e-27, -1.0616e-20,  0.0000e+00, -2.5688e-29, -5.9457e-04,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -1.4309e-17,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "        -3.0097e+06,  0.0000e+00, -3.9645e-25, -8.8058e-20,  1.9898e-43,\n",
              "        -2.2156e-12,  0.0000e+00,  0.0000e+00, -3.8730e-15,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -2.4202e-34,  0.0000e+00,  0.0000e+00, -3.2028e-23,\n",
              "         0.0000e+00,  0.0000e+00, -3.9735e-34,  0.0000e+00, -3.8966e-08,\n",
              "         0.0000e+00, -2.2030e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -3.5367e-40,  0.0000e+00,  0.0000e+00,\n",
              "        -7.4222e-38,  0.0000e+00,  0.0000e+00, -9.4159e-16,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -2.1972e-42, -8.4772e-20,  0.0000e+00,\n",
              "         0.0000e+00, -2.0903e-15,  0.0000e+00,  0.0000e+00, -2.5223e-44,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -1.4013e-45,  0.0000e+00,\n",
              "        -1.7457e-24,  0.0000e+00, -1.0543e-37, -1.6182e-33, -3.5188e-28,\n",
              "        -8.2104e-17,  0.0000e+00, -3.8662e-06,  0.0000e+00,  0.0000e+00,\n",
              "        -2.4441e-09, -8.4772e-20,  0.0000e+00,  0.0000e+00, -9.1102e-12,\n",
              "         0.0000e+00, -3.0097e+06,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "        -4.5720e-36,  0.0000e+00, -3.6430e-12,  0.0000e+00,  0.0000e+00,\n",
              "        -1.6816e-44,  1.9004e-41, -4.8050e-26, -2.8832e-06, -1.4013e-45,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -4.4110e-04,\n",
              "         0.0000e+00,  0.0000e+00, -5.9390e-13,  0.0000e+00,  0.0000e+00,\n",
              "        -4.5634e-22,  0.0000e+00, -3.4013e-37,  0.0000e+00,  0.0000e+00,\n",
              "         1.9898e-43,  0.0000e+00, -4.2383e-17,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -1.2412e-14, -5.9457e-04,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -1.0701e-07,  5.1149e-40,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.5719e-17,\n",
              "         0.0000e+00,  0.0000e+00, -6.4470e-14, -1.3247e-35,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "        -9.8613e-27, -3.9645e-25, -1.5112e-30, -1.1566e-08,  0.0000e+00,\n",
              "         0.0000e+00, -1.5719e-17,  0.0000e+00, -1.3828e-31,  0.0000e+00,\n",
              "        -4.5551e-22, -1.6255e-43, -1.9179e-27,  4.6289e-17, -6.6137e-04,\n",
              "        -8.4772e-20,  0.0000e+00,  0.0000e+00, -8.2205e-14, -1.2163e-08,\n",
              "         0.0000e+00,  0.0000e+00, -1.2418e-12, -1.0543e-37,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  2.8294e-34, -4.5634e-22,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -7.7118e-30,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -1.3518e-33,  0.0000e+00,  0.0000e+00,\n",
              "        -1.8627e-28, -3.9645e-25,  0.0000e+00,  0.0000e+00, -2.1972e-42,\n",
              "         0.0000e+00, -2.4485e-09, -1.0150e-03,  0.0000e+00, -1.7865e-25,\n",
              "         0.0000e+00,        -inf,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -6.7035e-32,  0.0000e+00,  0.0000e+00, -6.3710e-32,\n",
              "        -6.6137e-04, -6.5706e-01,  0.0000e+00, -1.5719e-17,  0.0000e+00,\n",
              "         0.0000e+00,  5.1149e-40,  0.0000e+00, -7.1308e-38, -1.3518e-33,\n",
              "         0.0000e+00,  0.0000e+00, -1.0150e-03,  0.0000e+00, -5.4345e-13,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -9.3034e-30,\n",
              "        -8.1634e-13,  0.0000e+00,  1.7343e-39,  0.0000e+00, -3.7737e+01,\n",
              "        -1.6692e-14,  0.0000e+00,  0.0000e+00, -1.1301e-18,  0.0000e+00,\n",
              "        -1.0095e-10, -8.0009e-07,  0.0000e+00, -2.4070e-08, -2.6165e-41,\n",
              "        -3.0533e-07,  0.0000e+00, -2.6325e-14,  0.0000e+00,  0.0000e+00,\n",
              "        -6.7686e-14,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -1.3188e+01,  0.0000e+00, -3.4013e-37,\n",
              "         0.0000e+00,  7.1993e-41, -2.2864e-35, -6.5861e-44, -4.9438e-23,\n",
              "        -2.0903e-15,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "        -4.6133e-21,  0.0000e+00,  0.0000e+00,  0.0000e+00, -5.8006e-24,\n",
              "         0.0000e+00,  0.0000e+00, -6.3710e-32,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -6.0236e-15,  0.0000e+00, -2.5559e-05, -3.8831e-13,\n",
              "         0.0000e+00,  0.0000e+00, -1.2184e+02,  0.0000e+00, -1.0090e+01,\n",
              "        -5.2582e-35, -1.3873e-42,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         1.6419e-27, -8.8237e-12, -1.2808e-33, -4.6133e-21,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  9.6867e-18,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -2.4571e-31,  0.0000e+00,  1.3201e-38,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -4.1568e-11,  0.0000e+00,\n",
              "        -1.4013e-45, -1.0701e-07,  3.2638e-35,  0.0000e+00,  0.0000e+00,\n",
              "         3.4265e-14, -2.5223e-44,  0.0000e+00, -1.7958e-41, -2.4441e-09,\n",
              "         0.0000e+00, -8.0009e-07, -1.4125e-01, -1.0090e+01,  0.0000e+00,\n",
              "        -2.2156e-12,  0.0000e+00,  0.0000e+00,  0.0000e+00, -2.4070e-08,\n",
              "        -4.5634e-22, -1.3188e+01,  0.0000e+00,  0.0000e+00, -5.0588e-29,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.3046e-34,\n",
              "        -2.3189e-15,  0.0000e+00, -2.9159e+00, -4.8370e-19, -1.0197e-32,\n",
              "         0.0000e+00, -4.2383e-17,  1.0241e-28,  0.0000e+00, -3.0533e-07,\n",
              "         0.0000e+00,  0.0000e+00, -1.0150e-03,  0.0000e+00, -9.1102e-12,\n",
              "         0.0000e+00, -2.6325e-14, -1.4617e-36, -3.8065e-38,  0.0000e+00,\n",
              "        -5.4262e-07, -1.0095e-10,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -6.6729e-06,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -4.5634e-22,  0.0000e+00, -9.8748e-13,  0.0000e+00,\n",
              "        -1.8556e-23,  0.0000e+00, -5.4529e-33,  0.0000e+00, -3.2522e-24,\n",
              "         1.1032e-38, -1.5748e-17,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "        -7.9976e-23, -3.2028e-23, -9.3884e-01,  0.0000e+00,  0.0000e+00,\n",
              "        -3.4013e-37,  2.8026e-45,  0.0000e+00, -6.8054e-14,  0.0000e+00,\n",
              "        -1.0145e-30, -4.4114e-29, -6.0833e-21,  0.0000e+00, -1.2272e+09,\n",
              "         0.0000e+00, -8.2104e-17,  0.0000e+00, -6.1665e+15, -1.7958e-41,\n",
              "        -2.5223e-44, -6.8813e-12, -3.8615e-09,  0.0000e+00, -4.6133e-21,\n",
              "         0.0000e+00,  0.0000e+00, -3.5367e-40, -5.1789e+02, -7.3035e-20,\n",
              "         0.0000e+00, -2.3485e-09, -1.0284e-27, -4.5693e-33,  0.0000e+00,\n",
              "        -2.0038e-36, -1.5719e-17,  0.0000e+00, -5.8006e-24, -1.7944e-15,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.8730e-15,\n",
              "         0.0000e+00,  0.0000e+00, -1.0701e-07,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -1.4013e-45, -7.9832e-23,  0.0000e+00, -1.3046e-34,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.5112e-30,\n",
              "        -5.8855e-44,  0.0000e+00,  0.0000e+00,  0.0000e+00, -6.7035e-32,\n",
              "         3.4275e-23,  0.0000e+00, -3.5486e-18,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -1.4617e-36,  0.0000e+00,\n",
              "         0.0000e+00, -3.0533e-07, -1.4830e-20, -8.4772e-20,  0.0000e+00,\n",
              "        -6.8054e-14,  0.0000e+00, -2.0976e-10,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -1.0095e-10, -8.4655e-19, -9.5567e-34,  0.0000e+00,\n",
              "        -2.5559e-05, -1.4857e-20,  0.0000e+00,  0.0000e+00, -2.2156e-12,\n",
              "        -1.5748e-17,  0.0000e+00, -2.2156e-12, -2.8727e-10,  0.0000e+00,\n",
              "        -6.2816e-41,  0.0000e+00,  0.0000e+00,  0.0000e+00, -4.6129e-11,\n",
              "        -1.2412e-14,  0.0000e+00, -4.7570e-17,  0.0000e+00, -2.4571e-31,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -4.5551e-22,\n",
              "        -1.0701e-07,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -5.6052e-45, -3.8615e-09,  0.0000e+00, -6.6945e-22,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -1.4857e-20,  0.0000e+00,\n",
              "        -1.9068e-20, -1.4830e-20,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "        -1.4309e-17, -1.7958e-41,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -4.9438e-23, -5.4529e-33,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -8.4772e-20,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -2.8727e-10,  0.0000e+00, -9.0216e-24, -1.2184e+02,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "        -4.2036e-30, -2.2960e-18,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -2.3133e-27,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -7.9832e-23,  0.0000e+00, -1.3400e-08, -2.4060e-40,\n",
              "        -9.5567e-34, -2.6038e-21,  0.0000e+00, -9.8748e-13,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -9.8091e-45,  0.0000e+00,\n",
              "         0.0000e+00, -1.3046e-34,  1.1169e-32,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -4.2383e-17, -2.2156e-12,  0.0000e+00,  0.0000e+00,\n",
              "        -3.7737e+01,  0.0000e+00,  0.0000e+00,  0.0000e+00, -5.1789e+02,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -2.2141e-04, -7.1308e-38,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -2.7511e-36,\n",
              "         0.0000e+00, -2.3189e-15,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -5.9457e-04,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -1.5112e-30,  0.0000e+00, -1.4125e-01,\n",
              "        -3.2425e-18,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -1.0095e-10,  0.0000e+00, -7.4033e-39,\n",
              "        -1.7015e-18, -6.6945e-22,  0.0000e+00, -1.9035e-38, -4.2974e-25,\n",
              "        -1.1244e-36,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.6816e-44,\n",
              "        -1.0052e-13,  0.0000e+00,  0.0000e+00, -2.5688e-29,  0.0000e+00,\n",
              "         0.0000e+00, -7.1308e-38, -1.3400e-08,  0.0000e+00, -8.7134e-11,\n",
              "         0.0000e+00, -1.7944e-15,  0.0000e+00, -2.5462e-42,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -1.2808e-33, -2.6687e-08,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -3.5322e-01, -2.0774e-08,\n",
              "        -1.4013e-45, -1.0095e-10,  0.0000e+00, -9.5567e-34,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -2.4202e-34, -3.3704e-28,  0.0000e+00,\n",
              "        -1.8556e-23, -3.0591e-21,  0.0000e+00,  0.0000e+00,  2.1787e-40,\n",
              "        -1.4635e-26,  0.0000e+00,  0.0000e+00,  0.0000e+00, -2.4565e-24,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -4.2036e-30,  0.0000e+00,\n",
              "        -1.4309e-17,  0.0000e+00, -2.4565e-24,  0.0000e+00,  0.0000e+00,\n",
              "        -5.4262e-07,  0.0000e+00, -2.8903e-30,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -2.4789e-27,\n",
              "        -2.4789e-27,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.4645e-07,\n",
              "         0.0000e+00, -4.7570e-17,  0.0000e+00, -1.2418e-12,  0.0000e+00,\n",
              "        -2.6013e-38,  0.0000e+00, -4.5020e-30,  0.0000e+00,  0.0000e+00,\n",
              "        -1.1129e-17,  0.0000e+00,  0.0000e+00,  0.0000e+00, -4.6108e-20,\n",
              "        -1.6266e-28,  0.0000e+00,  0.0000e+00, -9.0216e-24, -7.9832e-23,\n",
              "         0.0000e+00, -1.6816e-44,  0.0000e+00,  0.0000e+00, -3.5032e-43,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -2.8558e-42, -4.0543e-28,\n",
              "        -1.6182e-33,  0.0000e+00, -1.3873e-42,  0.0000e+00, -3.0953e-12,\n",
              "         0.0000e+00,  0.0000e+00,  1.8187e-35, -1.3828e-31, -1.6692e-14])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clamp_large_terms(samples_IS)[0].min()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xg4Fy5iQcqnl",
        "outputId": "534b197d-a951-470c-d848-9b9d74a2121f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-9.0000e-38)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clamp_large_terms(tensor):\n",
        "    max_float64 = torch.finfo(torch.float64).max\n",
        "    min_float64 = torch.finfo(torch.float64).min\n",
        "\n",
        "    tensor[tensor == float('inf')] = 1e38  # Choose a large finite value\n",
        "    tensor[tensor == float('-inf')] = -1e38  # Choose a small finite value\n",
        "\n",
        "    return tensor\n",
        "\n",
        "# Example usage:\n",
        "# samples_IS_clamped = clamp_tensor(samples_IS)"
      ],
      "metadata": {
        "id": "5I1eVRAvlZK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# samples_IS_clamped[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "fMWanHX9l-kL",
        "outputId": "d8453853-77ac-49e1-fca3-d1760b015b58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'samples_IS_clamped' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-5babce667c95>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msamples_IS_clamped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'samples_IS_clamped' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tensor(torch.finfo(torch.float64).min, dtype=torch.float64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZvLUFyNeJBo",
        "outputId": "c35697a7-262f-427d-d331-dfc87a2c111b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-1.7977e+308, dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "MHWCgv3e3fSs",
        "outputId": "f1041452-2c44-40ad-fd87-8a903fee57eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomizableFeatureNet_d(\n",
              "  (hidden_layers): ModuleList(\n",
              "    (0): Linear(in_features=2, out_features=16, bias=True)\n",
              "    (1): Linear(in_features=16, out_features=32, bias=True)\n",
              "  )\n",
              "  (output_layer): Linear(in_features=32, out_features=1, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = model(state_tensors)"
      ],
      "metadata": {
        "id": "HkIlYqmg25KD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "651d0a8b-af25-4e2f-a721-0b694511e29f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 must have the same dtype, but got Float and Double",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-602b7502521b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-45-0c890199681a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 must have the same dtype, but got Float and Double"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output.shape"
      ],
      "metadata": {
        "id": "Tukv3iQZ3ekc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FltSKPtH8TAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CustomizableFeatureNet(input_dim=2, hidden_dims=[16, 32], output_dim=1)"
      ],
      "metadata": {
        "id": "pG06s2t_0gZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3PZWZk4GqndI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scope_set, phi_set = subset_policies(pi_b, 0.3)"
      ],
      "metadata": {
        "id": "OFF9HKErgm34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IS, state_tensors, w_diff, f, st_og, psi_res, sample_last_tensors = variance_terms_tens(P_pi_e, P_pi_b, phi_set)"
      ],
      "metadata": {
        "id": "inVdxVMRjT4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CustomizableFeatureNet(input_dim=2, hidden_dims=[16, 32], output_dim=1)"
      ],
      "metadata": {
        "id": "qq1dLzLCjUp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = train_mse_var(model, 40, 0.001, 1, 1, IS, state_tensors, w_diff, f, sample_last_tensors, phi_set, st_og, psi_res)"
      ],
      "metadata": {
        "id": "TYKlf1urD34t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test class"
      ],
      "metadata": {
        "id": "72Fy4L1cuitK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# from IS import calculate_importance_weights\n",
        "\n",
        "# import torch\n",
        "\n",
        "class SCOPE_variance_play(object):\n",
        "    def __init__(self, model, gamma, num_bootstraps, pi_b, P_pi_b, P_pi_e, dtype):\n",
        "        self.model = model\n",
        "        self.gamma = gamma\n",
        "        self.num_bootstraps = num_bootstraps\n",
        "        self.pi_b = pi_b\n",
        "        self.P_pi_b = P_pi_b\n",
        "        self.P_pi_e = P_pi_e\n",
        "        self.dtype = dtype\n",
        "\n",
        "\n",
        "    def prep_policies(self):\n",
        "        # Initialize lists to store axis data for each policy\n",
        "        timesteps = []\n",
        "        states = []\n",
        "        state_first = []\n",
        "        state_last = []\n",
        "        actions = []\n",
        "        rewards = []\n",
        "        gamma_last = []\n",
        "        weight_last = []\n",
        "        weight_first = []\n",
        "        # all_weights_temp, weights = calculate_importance_weights(self.P_pi_e, self.P_pi_b, self.pi_b)\n",
        "        weights, all_weights_temp = calculate_importance_weights(self.P_pi_e, self.P_pi_b, self.pi_b)\n",
        "        psi = []\n",
        "\n",
        "        for index, policy in enumerate(self.pi_b):\n",
        "            policy_array = np.array(policy)\n",
        "            timesteps.append(policy_array['timestep'].astype(int))\n",
        "            # s.append(policy_array[:, 0])\n",
        "\n",
        "            # last timestep for gamma\n",
        "            gamma_last.append(len(policy))\n",
        "            # last importance weight\n",
        "            weight_last.append(weights[index][-1])\n",
        "            weight_first.append(weights[index][0])\n",
        "\n",
        "\n",
        "            states.append(policy_array['state'][1:])\n",
        "            psi.append(policy_array['psi'][1:])\n",
        "            state_first.append(policy_array['state'][0])\n",
        "            state_last.append(policy_array['state'][-1])\n",
        "            actions.append(policy_array['action'])\n",
        "            rewards.append(policy_array['reward'].astype(float))\n",
        "\n",
        "        weights_difference = []\n",
        "        for index, weight in enumerate(weights):\n",
        "            # diff = np.array(w[index][:-1]) - np.array(w[index][1:])\n",
        "            diff = np.array(weight[:-1]) - np.array(weight[1:])\n",
        "            weights_difference.append(diff)\n",
        "\n",
        "        return timesteps, states, state_first, state_last, actions, rewards, gamma_last, weight_last, weights, weights_difference, weight_first\n",
        "\n",
        "    def padding_IS_terms(self,timesteps, actions, rewards, weights):\n",
        "        # Find the maximum length among all lists\n",
        "        max_length = max(len(traj) for traj in timesteps)\n",
        "\n",
        "        # Define the padding values\n",
        "        zero_padding = 0\n",
        "\n",
        "        # Pad each list to match the maximum length\n",
        "        padded_timesteps = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in timesteps]\n",
        "        padded_rewards = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in rewards]\n",
        "        padded_actions = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in actions]\n",
        "        padded_weights = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in weights]\n",
        "\n",
        "        return padded_timesteps, padded_rewards, padded_actions, padded_weights\n",
        "\n",
        "    def padding_states_weights_difference(self, states, weights_difference):\n",
        "        # Find the maximum length of trajectories\n",
        "        max_length = max(len(trajectory) for trajectory in states)\n",
        "\n",
        "        zero_padding = 0\n",
        "\n",
        "        # Pad each trajectory to make them all the same length\n",
        "        padded_states = [\n",
        "            [list(item) for item in trajectory] + [[0, 0]] * (max_length - len(trajectory))\n",
        "            for trajectory in states\n",
        "        ]\n",
        "\n",
        "        padded_weights_difference = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in weights_difference]\n",
        "\n",
        "        return padded_states, padded_weights_difference\n",
        "\n",
        "    def tensorize_padded_terms(self, padded_states, padded_weights_difference):\n",
        "        padded_state_tensors = torch.tensor(padded_states, dtype = self.dtype)\n",
        "        padded_weight_diff_tensors = torch.tensor(padded_weights_difference, dtype = self.dtype)\n",
        "        padded_weight_diff_tensors = padded_weight_diff_tensors.unsqueeze(-1)\n",
        "\n",
        "        return padded_state_tensors, padded_weight_diff_tensors\n",
        "\n",
        "    def tensorize_last_and_first_terms(self, states_first, states_last, gamma_last, weights_last):\n",
        "        states_first_tensor = torch.tensor(states_first, dtype = self.dtype)\n",
        "        states_last_tensor = torch.tensor(states_last, dtype = self.dtype)\n",
        "        gamma_last_tensor = torch.tensor(gamma_last, dtype = self.dtype)\n",
        "        weights_last_tensor = torch.tensor(weights_last, dtype = self.dtype)\n",
        "\n",
        "        return states_first_tensor, states_last_tensor, gamma_last_tensor, weights_last_tensor\n",
        "\n",
        "    def calc_IS_terms(self, gamma, timesteps, rewards, weights):\n",
        "        gtrw = np.power(gamma, timesteps)*rewards*weights\n",
        "\n",
        "        IS_tensor = torch.sum(torch.tensor(gtrw, dtype = self.dtype), dim = 1, keepdim = True)\n",
        "\n",
        "        return IS_tensor\n",
        "\n",
        "    def calc_gamma_weight_last(self, gamma, gamma_last, weights_last):\n",
        "        gamma_weight_last = np.power(gamma, gamma_last)*weights_last\n",
        "\n",
        "        gamma_weight_last_tensor = torch.tensor(gamma_weight_last, dtype = self.dtype).unsqueeze(-1)\n",
        "\n",
        "        return gamma_weight_last_tensor\n",
        "\n",
        "    def tensorize_weight_first(self, weights_first):\n",
        "\n",
        "      weight_first_tensor = torch.tensor(weights_first, dtype = torch.float64).unsqueeze(-1)\n",
        "\n",
        "      return weight_first_tensor\n",
        "    def bootstrap_IS_terms(self, IS_tensor, num_samples):\n",
        "        seed = 42\n",
        "        torch.manual_seed(seed)\n",
        "\n",
        "        num_bootstraps = num_samples*len(IS_tensor)\n",
        "\n",
        "        # Sample indices with replacement\n",
        "        sampled_indices = torch.randint(0, len(IS_tensor), size=(num_bootstraps,), dtype=torch.long)\n",
        "\n",
        "        # new_size = (num_samples, IS_tensor.shape[0], IS_tensor.shape[1])\n",
        "        new_size = (num_samples, IS_tensor.shape[0])\n",
        "\n",
        "        IS_bootstraps = IS_tensor[sampled_indices].view(new_size)\n",
        "\n",
        "        # sampled_tensor = IS_bootstraps.view(new_size)\n",
        "\n",
        "        return IS_bootstraps\n",
        "\n",
        "    def states_weight_diff_sums(self, states_output, padded_weight_diff_tensors):\n",
        "        states_weight_diff = states_output * padded_weight_diff_tensors\n",
        "        sums_states_weight_diff = torch.sum(states_weight_diff, dim =1)\n",
        "\n",
        "        return sums_states_weight_diff\n",
        "\n",
        "    def last_first_terms_operations(self, gamma_weights_last_tensor, states_last_output, states_first_output, weight_first_tensor):\n",
        "        gamma_weights_states_last_sub_states_first = gamma_weights_last_tensor*states_last_output -  weight_first_tensor*states_first_output\n",
        "\n",
        "        return gamma_weights_states_last_sub_states_first\n",
        "\n",
        "\n",
        "    def bootstrap_shaping_terms(self, sums_states_weight_diff, gamma_weights_states_last_sub_states_first, IS_tensor):\n",
        "\n",
        "        seed = 42\n",
        "        torch.manual_seed(seed)\n",
        "\n",
        "        num_samples = self.num_bootstraps\n",
        "\n",
        "        num_bootstraps_lin = num_samples*sums_states_weight_diff.shape[0]\n",
        "\n",
        "        # Sample indices with replacement\n",
        "        sampled_indices = torch.randint(0, len(sums_states_weight_diff), size=(num_bootstraps_lin,), dtype=torch.long)\n",
        "\n",
        "        reshaped_size = (num_samples, sums_states_weight_diff.shape[0])\n",
        "\n",
        "        # Resize samples to shape num_samples x num_trajectories\n",
        "        sample_sums_states_weight_diff = sums_states_weight_diff[sampled_indices].view(reshaped_size)\n",
        "        samples_gamma_weight_states_last_sub_states_first = gamma_weights_states_last_sub_states_first[sampled_indices].view(reshaped_size)\n",
        "\n",
        "        # Sum states_weight_diff and gamma_weights-states_last_sub_states_first\n",
        "        sum_terms = sums_states_weight_diff + gamma_weights_states_last_sub_states_first\n",
        "\n",
        "        # sample IS terms\n",
        "\n",
        "        IS_SCOPE = IS_tensor * sum_terms\n",
        "\n",
        "        samples_IS_SCOPE = IS_SCOPE[sampled_indices].view(reshaped_size)\n",
        "\n",
        "\n",
        "        sample_all_shaping = sum_terms[sampled_indices].view(reshaped_size)\n",
        "\n",
        "        return sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, sample_all_shaping, samples_IS_SCOPE\n",
        "\n",
        "    def bootstrap_all_terms(self, sums_states_weight_diff, gamma_weights_states_last_sub_states_first, IS_tensor):\n",
        "        seed = 42\n",
        "        torch.manual_seed(seed)\n",
        "\n",
        "        # num_bootstraps = num_samples*len(IS_tensor)\n",
        "\n",
        "        # Sample indices with replacement\n",
        "        # sampled_indices = torch.randint(0, len(IS_tensor), size=(num_bootstraps,), dtype=torch.long)\n",
        "\n",
        "        # new_size = (num_samples, IS_tensor.shape[0], IS_tensor.shape[1])\n",
        "        # new_size = (num_samples, IS_tensor.shape[0])\n",
        "\n",
        "        # IS_bootstraps = IS_tensor[sampled_indices].view(new_size)\n",
        "\n",
        "        num_samples = self.num_bootstraps\n",
        "        num_bootstraps_lin = num_samples*sums_states_weight_diff.shape[0]\n",
        "\n",
        "\n",
        "        # Sample indices with replacement\n",
        "        sampled_indices = torch.randint(0, len(sums_states_weight_diff), size=(num_bootstraps_lin,), dtype=torch.long)\n",
        "\n",
        "        reshaped_size = (num_samples, sums_states_weight_diff.shape[0])\n",
        "\n",
        "        IS_bootstraps = IS_tensor[sampled_indices].view(reshaped_size)\n",
        "\n",
        "        # Resize samples to shape num_samples x num_trajectories\n",
        "        sample_sums_states_weight_diff = sums_states_weight_diff[sampled_indices].view(reshaped_size)\n",
        "        samples_gamma_weight_states_last_sub_states_first = gamma_weights_states_last_sub_states_first[sampled_indices].view(reshaped_size)\n",
        "\n",
        "        # Sum states_weight_diff and gamma_weights-states_last_sub_states_first\n",
        "        sum_terms = sums_states_weight_diff + gamma_weights_states_last_sub_states_first\n",
        "\n",
        "        # sample IS terms\n",
        "\n",
        "        IS_SCOPE = IS_tensor * sum_terms\n",
        "\n",
        "        samples_IS_SCOPE = IS_SCOPE[sampled_indices].view(reshaped_size)\n",
        "\n",
        "        sample_all_shaping = sum_terms[sampled_indices].view(reshaped_size)\n",
        "\n",
        "        return IS_bootstraps, sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, sample_all_shaping, samples_IS_SCOPE\n",
        "\n",
        "\n",
        "\n",
        "    def pass_states(self,model, padded_state_tensors, states_first_tensor, states_last_tensor):\n",
        "        # Get model outputs for states\n",
        "        states_output = model(padded_state_tensors)\n",
        "        states_first_output = model(states_first_tensor)\n",
        "        states_last_output = model(states_last_tensor)\n",
        "        return states_output, states_first_output, states_last_output\n",
        "\n",
        "\n",
        "    # def prepare(self):\n",
        "    #     timesteps, states, states_first, states_last, actions, rewards, gamma_last, weights_last, weights, weights_difference = self.prep_policies()\n",
        "    #     padded_timesteps, padded_rewards, padded_actions, padded_weights = self.padding_IS_terms(timesteps, actions, rewards, weights)\n",
        "    #     padded_states, padded_weights_difference = self.padding_states_weights_difference(states, weights_difference)\n",
        "    #     padded_state_tensors, padded_weight_diff_tensors = self.tensorize_padded_terms(padded_states, padded_weights_difference)\n",
        "    #     states_first_tensor, states_last_tensor, gamma_last_tensor, weights_last_tensor = self.tensorize_last_and_first_terms(states_first, states_last, gamma_last, weights_last)\n",
        "    #     IS_tensor = self.calc_IS_terms(self.gamma, padded_timesteps, padded_rewards, padded_weights)\n",
        "    #     gamma_weights_last_tensor = self.calc_gamma_weight_last(self.gamma, gamma_last, weights_last)\n",
        "    #     samples_IS = self.bootstrap_IS_terms(IS_tensor, self.num_bootstraps)\n",
        "\n",
        "    #     return IS_tensor, samples_IS, padded_state_tensors, padded_weight_diff_tensors, gamma_weights_last_tensor, states_first_tensor, states_last_tensor\n",
        "\n",
        "\n",
        "    def prepare(self):\n",
        "        timesteps, states, states_first, states_last, actions, rewards, gamma_last, weights_last, weights, weights_difference, weight_first = self.prep_policies()\n",
        "        padded_timesteps, padded_rewards, padded_actions, padded_weights = self.padding_IS_terms(timesteps, actions, rewards, weights)\n",
        "        padded_states, padded_weights_difference = self.padding_states_weights_difference(states, weights_difference)\n",
        "        padded_state_tensors, padded_weight_diff_tensors = self.tensorize_padded_terms(padded_states, padded_weights_difference)\n",
        "        states_first_tensor, states_last_tensor, gamma_last_tensor, weights_last_tensor = self.tensorize_last_and_first_terms(states_first, states_last, gamma_last, weights_last)\n",
        "        IS_tensor = self.calc_IS_terms(self.gamma, padded_timesteps, padded_rewards, padded_weights)\n",
        "        gamma_weights_last_tensor = self.calc_gamma_weight_last(self.gamma, gamma_last, weights_last)\n",
        "        weight_first_tensor = self.tensorize_weight_first(weight_first)\n",
        "        # samples_IS = self.bootstrap_IS_terms(IS_tensor, self.num_bootstraps)\n",
        "\n",
        "        return IS_tensor, padded_state_tensors, padded_weight_diff_tensors, gamma_weights_last_tensor, states_first_tensor, states_last_tensor, weight_first_tensor"
      ],
      "metadata": {
        "id": "1vZCWSiPum0K"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_importance_weights(eval_policy, behav_policy, behavior_policies):\n",
        "    \"\"\"\n",
        "    Calculate importance weights for behavior policies.\n",
        "\n",
        "    Parameters:\n",
        "    - eval_policy: Evaluation policy\n",
        "    - behav_policy: Behavior policy\n",
        "    - behavior_policies: List of behavior policies\n",
        "\n",
        "    Returns:\n",
        "    - all_weights: List of importance weights\n",
        "    \"\"\"\n",
        "    all_weights_temp = []\n",
        "    for trajectory in behavior_policies:\n",
        "        cum_ratio = 1\n",
        "        cumul_weights = []\n",
        "        for step in trajectory:\n",
        "            # eval_action_probs = get_quadrant_policy(step[0], eval_policy)\n",
        "            # behav_action_probs = get_quadrant_policy(step[0], behav_policy)\n",
        "\n",
        "            P_pi_b = behav_policy[tuple(np.append(step[0].astype(int) , (step[1],)))]\n",
        "            P_pi_e = eval_policy[tuple(np.append(step[0].astype(int) , (step[1],)))]\n",
        "\n",
        "            # ratio = (0.8*eval_action_probs[step[1]] +0.2*0.25)/ (0.8*behav_action_probs[step[1]]+0.2*0.25)\n",
        "            ratio = P_pi_e/P_pi_b\n",
        "            cum_ratio *= ratio\n",
        "            cumul_weights.append(cum_ratio)\n",
        "        all_weights_temp.append(cumul_weights)\n",
        "\n",
        "        all_weights = [list(np.cumprod(i)) for i in all_weights_temp]\n",
        "\n",
        "    return all_weights_temp, all_weights"
      ],
      "metadata": {
        "id": "qRsjTJiS5cYe"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test variance"
      ],
      "metadata": {
        "id": "x6L6-NZfHdt_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_shaped_variance_play(samples_IS, sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, samples_all_shaping, samples_IS_SCOPE):\n",
        "\n",
        "  # states_output, states_first_output, states_last_output = pass_states(model, padded_state_tensors, states_first_tensor, states_last_tensor)\n",
        "\n",
        "  # Begin calcs without clamping\n",
        "\n",
        "  # IS\n",
        "  E_IS_sq = torch.mean(torch.mean(samples_IS, dim = 1)**2)\n",
        "  E_IS_all_sq = torch.mean(torch.mean(samples_IS, dim = 1))**2\n",
        "\n",
        "  # states_weight_diff\n",
        "  E_s_wdiff_sq = torch.mean(torch.mean(sample_sums_states_weight_diff, dim =1)**2)\n",
        "  E_s_wdiff_all_sq = torch.mean(torch.mean(sample_sums_states_weight_diff, dim = 1))**2\n",
        "\n",
        "  # all terms\n",
        "  SCOPE = sample_sums_states_weight_diff+samples_gamma_weight_states_last_sub_states_first\n",
        "  E_IS_SCOPE = torch.mean(torch.mean(samples_IS, dim =1) * torch.mean(SCOPE, dim =1))\n",
        "  E_IS_E_SCOPE = torch.mean(torch.mean(samples_IS,dim = 1 ))*torch.mean(torch.mean(SCOPE, dim =1))\n",
        "\n",
        "  # samples_IS_SCOPE seems to be wrong, get means and then multiply\n",
        "  # E_IS_SCOPE = torch.mean(torch.mean(samples_IS_SCOPE, dim =1))\n",
        "  # E_IS_E_SCOPE = torch.mean(torch.mean(samples_IS,dim = 1 )) * torch.mean(torch.mean(samples_all_shaping, dim =1))\n",
        "\n",
        "\n",
        "\n",
        "  # SCOPE_variance = E_IS_sq + 2*E_IS_SCOPE + E_s_wdiff_sq - E_IS_all_sq - 2*E_IS_E_SCOPE - E_IS_E_SCOPE\n",
        "  SCOPE_variance = E_IS_sq + 2*E_IS_SCOPE + E_s_wdiff_sq - E_IS_all_sq - 2*E_IS_E_SCOPE - E_s_wdiff_all_sq\n",
        "\n",
        "  IS_variance = E_IS_sq - E_IS_all_sq\n",
        "\n",
        "  return E_IS_sq, E_IS_all_sq, E_s_wdiff_sq, E_s_wdiff_all_sq, E_IS_SCOPE, E_IS_E_SCOPE, IS_variance, SCOPE_variance\n"
      ],
      "metadata": {
        "id": "2c4zRUmqHfz2"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimizing play"
      ],
      "metadata": {
        "id": "ScU_mVSALakh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "def train_var_play(model, num_epochs, learning_rate, padded_state_tensors, states_first_tensor, states_last_tensor, test1):\n",
        "    model.train()\n",
        "\n",
        "    # Enable anomaly detection\n",
        "    torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "\n",
        "        # Forward pass\n",
        "        states_output, states_first_output, states_last_output = test1.pass_states(model, padded_state_tensors, states_first_tensor, states_last_tensor)\n",
        "        sums_states_weight_diff = test1.states_weight_diff_sums(states_output, padded_weight_diff_tensors)\n",
        "        gamma_weights_states_last_sub_states_first = test1.last_first_terms_operations(gamma_weights_last_tensor, states_last_output, states_first_output, weight_first_tensor)\n",
        "        # sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, samples_all_shaping, samples_IS_SCOPE = test1.bootstrap_shaping_terms(sums_states_weight_diff, gamma_weights_states_last_sub_states_first, IS_tensor)\n",
        "\n",
        "        samples_IS, sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, samples_all_shaping, samples_IS_SCOPE = test1.bootstrap_all_terms(sums_states_weight_diff, gamma_weights_states_last_sub_states_first, IS_tensor)\n",
        "\n",
        "\n",
        "        E_IS_sq, E_IS_all_sq, E_s_wdiff_sq, E_s_wdiff_all_sq, E_IS_SCOPE, E_IS_E_SCOPE, _, variance_loss = calculate_shaped_variance_play(samples_IS, sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, samples_all_shaping, samples_IS_SCOPE)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}\")\n",
        "        print(\"Var loss: \", variance_loss)\n",
        "\n",
        "        # Print each term\n",
        "        print(f\"E_IS_sq: {E_IS_sq}\")\n",
        "        print(f\"E_IS_all_sq: {E_IS_all_sq}\")\n",
        "        print(f\"E_s_wdiff_sq: {E_s_wdiff_sq}\")\n",
        "        print(f\"E_s_wdiff_all_sq: {E_s_wdiff_all_sq}\")\n",
        "        print(f\"E_IS_SCOPE: {E_IS_SCOPE}\")\n",
        "        print(f\"E_IS_E_SCOPE: {E_IS_E_SCOPE}\")\n",
        "\n",
        "        tot = variance_loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Retain the graph to avoid clearing it before backward pass\n",
        "        tot.backward(retain_graph=True)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += tot.item()\n",
        "\n",
        "        print(f\"Total Loss: {total_loss}\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "    # Disable anomaly detection after running the code\n",
        "    torch.autograd.set_detect_anomaly(False)\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            print(f\"Parameter name: {name}\")\n",
        "            print(f\"Weights: {param.data}\")\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "6Dk99vwwLcPN"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "states_output, states_first_output, states_last_output = testing.pass_states(model, padded_state_tensors, states_first_tensor, states_last_tensor)\n",
        "sums_states_weight_diff = testing.states_weight_diff_sums(states_output, padded_weight_diff_tensors)\n",
        "gamma_weights_states_last_sub_states_first = testing.last_first_terms_operations(gamma_weights_last_tensor, states_last_output, states_first_output, weight_first_tensor)\n",
        "\n",
        "\n",
        "# sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, samples_all_shaping, samples_IS_SCOPE = testing.bootstrap_shaping_terms(sums_states_weight_diff, gamma_weights_states_last_sub_states_first, IS_tensor)\n",
        "samples_IS, sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, samples_all_shaping, samples_IS_SCOPE = testing.bootstrap_all_terms(sums_states_weight_diff, gamma_weights_states_last_sub_states_first, IS_tensor)\n"
      ],
      "metadata": {
        "id": "fHvR4UmfMh6h"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5EdwiZbW0cPA"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum_SCOPE = sums_states_weight_diff + gamma_weights_states_last_sub_states_first\n",
        "\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "# num_bootstraps = num_samples*len(IS_tensor)\n",
        "\n",
        "# Sample indices with replacement\n",
        "# sampled_indices = torch.randint(0, len(IS_tensor), size=(num_bootstraps,), dtype=torch.long)\n",
        "\n",
        "# new_size = (num_samples, IS_tensor.shape[0], IS_tensor.shape[1])\n",
        "# new_size = (num_samples, IS_tensor.shape[0])\n",
        "\n",
        "# IS_bootstraps = IS_tensor[sampled_indices].view(new_size)\n",
        "\n",
        "num_samples = 10000\n",
        "num_bootstraps_lin = num_samples*sums_states_weight_diff.shape[0]\n",
        "\n",
        "\n",
        "# Sample indices with replacement\n",
        "sampled_indices = torch.randint(0, len(sums_states_weight_diff), size=(num_bootstraps_lin,), dtype=torch.long)\n",
        "\n",
        "reshaped_size = (num_samples, sums_states_weight_diff.shape[0])\n",
        "\n",
        "# IS_bootstraps = IS_tensor[sampled_indices].view(reshaped_size)\n",
        "\n",
        "# # Resize samples to shape num_samples x num_trajectories\n",
        "# sample_sums_states_weight_diff = sums_states_weight_diff[sampled_indices].view(reshaped_size)\n",
        "# samples_gamma_weight_states_last_sub_states_first = gamma_weights_states_last_sub_states_first[sampled_indices].view(reshaped_size)\n",
        "\n",
        "# Sum states_weight_diff and gamma_weights-states_last_sub_states_first\n",
        "sum_terms = sums_states_weight_diff + gamma_weights_states_last_sub_states_first\n",
        "\n",
        "\n",
        "samples_sum_terms = sum_terms[sampled_indices].view(reshaped_size)\n",
        "# sample IS terms\n",
        "\n",
        "IS_SCOPE = IS_tensor * sum_terms\n",
        "\n",
        "samples_IS_SCOPE = IS_SCOPE[sampled_indices].view(reshaped_size)\n",
        "\n",
        "sample_all_shaping = sum_terms[sampled_indices].view(reshaped_size)\n",
        "\n"
      ],
      "metadata": {
        "id": "3n0LFWhfzw1q"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_sums_states_weight_diff + samples_gamma_weight_states_last_sub_states_first"
      ],
      "metadata": {
        "id": "ze7OQ2Gmz_Ju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SCOPE = sample_sums_states_weight_diff+samples_gamma_weight_states_last_sub_states_first\n",
        "E_IS_SCOPE = torch.mean(torch.mean(samples_IS, dim =1) * torch.mean(SCOPE, dim =1))\n",
        "E_IS_E_SCOPE = torch.mean(torch.mean(samples_IS,dim = 1 ))*torch.mean(torch.mean(SCOPE, dim =1))\n",
        "\n",
        "# I believe this is wrong, need to get means for full samples first then expected value\n",
        "E_IS_SCOPE_2 = torch.mean(torch.mean(samples_IS_SCOPE, dim =1))\n",
        "E_IS_E_SCOPE_2 = torch.mean(torch.mean(samples_IS,dim = 1 )) * torch.mean(torch.mean(samples_all_shaping, dim =1))"
      ],
      "metadata": {
        "id": "KS9W2QBbxaAR"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples_IS[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJ--fCnzfqiP",
        "outputId": "0c3fb638-e79c-4c09-f64a-61df13f7de45"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1000])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SCOPE.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70T4d5TUfw53",
        "outputId": "4817d316-ffff-4e75-845e-708f5e560f96"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10000, 1000])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mean(torch.mean(samples_IS*SCOPE, dim = 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4bIivIL6a_w",
        "outputId": "4677859b-b2a7-42af-cce5-6c8634c9419a"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1475, dtype=torch.float64, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mean(torch.mean(IS_tensor*sum_terms))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0D6NmpCN2qn6",
        "outputId": "d282953a-f0f4-4b6a-eff6-ba44cef40cd3"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1482, dtype=torch.float64, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mean(torch.mean(samples_IS, dim =1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tsy6Ei4R2lSg",
        "outputId": "7b90369b-c186-4cc3-a982-ea06d3ff8e9d"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0044, dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mean(torch.mean(samples_IS_SCOPE, dim =1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rl2FQXTo2c86",
        "outputId": "92046c51-06bd-4601-e019-e264738757a8"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1475, dtype=torch.float64, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mean(torch.mean(samples_sum_terms, dim =1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEXHNRtU1MQ_",
        "outputId": "a8e20f5f-e8e7-4c25-ccb5-5cc3ab5b216e"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.3184, dtype=torch.float64, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mean"
      ],
      "metadata": {
        "id": "xBrxbL2j1mrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mean(torch.mean(SCOPE, dim =1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEHEGqddyEtn",
        "outputId": "806ed392-ccee-4d4c-a247-114bc0be26d4"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.3184, dtype=torch.float64, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mean(torch.mean(samples_all_shaping, dim =1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78G2yHu6yFgy",
        "outputId": "9e85a406-22ba-4615-b7e0-293403c4f153"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.3184, dtype=torch.float64, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "E_IS_SCOPE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pgIK7pqxH7n",
        "outputId": "cb4f2b75-dcec-4313-e318-a429e84d0890"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0015, dtype=torch.float64, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "E_IS_SCOPE_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVdR3bVMxlXq",
        "outputId": "88b13c07-d8be-4702-bf86-a51aa531f524"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1475, dtype=torch.float64, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "E_IS_E_SCOPE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFU4WYuJxhOg",
        "outputId": "b8704738-fdce-47ad-8f1f-5d3367ef75e3"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0014, dtype=torch.float64, grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "E_IS_E_SCOPE_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vzjRzVfxoXV",
        "outputId": "8efcebb9-0d64-4e28-cb99-6fcb9b8c13a8"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0014, dtype=torch.float64, grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Class play"
      ],
      "metadata": {
        "id": "GKFk2XRHQeQ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b = action_probs_top_n_epsilon(q_table, 1, 0.4)\n",
        "pi_b = experiment_actions(1000, env, P_pi_b)\n",
        "P_pi_e = action_probs_top_n_epsilon(q_table, 2, 0.05)\n",
        "pi_e = experiment_actions(1000, env, P_pi_e)"
      ],
      "metadata": {
        "id": "TnCDINz7AoG1"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CustomizableFeatureNet(input_dim=2, hidden_dims=[16, 32], output_dim=1, dtype = torch.float64)"
      ],
      "metadata": {
        "id": "gEgO1QxNLnCZ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing = SCOPE_variance_play(model, 0.9, 10000, pi_b, P_pi_b, P_pi_e, dtype = torch.float64)"
      ],
      "metadata": {
        "id": "I2S6fvyWQgjM"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IS_tensor, padded_state_tensors, padded_weight_diff_tensors, gamma_weights_last_tensor, states_first_tensor, states_last_tensor, weight_first_tensor = testing.prepare()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uz6hDK3ZJjM6",
        "outputId": "fb83e747-3ec6-46b7-f7c2-2732a5628ffb"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-41662d94a8d9>:92: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  padded_weight_diff_tensors = torch.tensor(padded_weights_difference, dtype = self.dtype)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1000 = train_var_play(model, 100, 0.001, padded_state_tensors, states_first_tensor, states_last_tensor, testing)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6B7y3q-Xjtpy",
        "outputId": "878d6336-c857-4a97-b446-dbe5fdde90d3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Var loss:  tensor(0.4364, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.91612813590345\n",
            "E_s_wdiff_all_sq: 0.47977377573226215\n",
            "E_IS_SCOPE: 0.0018630194424027102\n",
            "E_IS_E_SCOPE: 0.0018434664174459066\n",
            "Total Loss: 0.43639459134416786\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "Var loss:  tensor(0.0953, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.10377027388910455\n",
            "E_s_wdiff_all_sq: 0.00848972906796978\n",
            "E_IS_SCOPE: -0.0002716328863720476\n",
            "E_IS_E_SCOPE: -0.00026625847027983576\n",
            "Total Loss: 0.09527092111201678\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "Var loss:  tensor(0.0876, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.09273451330953343\n",
            "E_s_wdiff_all_sq: 0.005075734755404952\n",
            "E_IS_SCOPE: -0.00023341896140770455\n",
            "E_IS_E_SCOPE: -0.00022784492566733285\n",
            "Total Loss: 0.08764875560571417\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "Var loss:  tensor(0.0791, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.08132886587014147\n",
            "E_s_wdiff_all_sq: 0.0021883635850759526\n",
            "E_IS_SCOPE: -0.00018601687001004106\n",
            "E_IS_E_SCOPE: -0.00018030005141584092\n",
            "Total Loss: 0.07913019377094355\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "Var loss:  tensor(0.0706, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.071032391331592\n",
            "E_s_wdiff_all_sq: 0.0004147307649607041\n",
            "E_IS_SCOPE: -0.00013300607224001144\n",
            "E_IS_E_SCOPE: -0.00012726564015150342\n",
            "Total Loss: 0.07060730482552072\n",
            "----------------------------------------\n",
            "Epoch 6\n",
            "Var loss:  tensor(0.0624, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.0624413959860953\n",
            "E_s_wdiff_all_sq: 4.973075033803511e-05\n",
            "E_IS_SCOPE: -7.732244445190367e-05\n",
            "E_IS_E_SCOPE: -7.162573197204863e-05\n",
            "Total Loss: 0.06238139693386399\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "Var loss:  tensor(0.0537, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.0551337285828942\n",
            "E_s_wdiff_all_sq: 0.001390025889742699\n",
            "E_IS_SCOPE: -1.4220526037030317e-05\n",
            "E_IS_E_SCOPE: -8.594540055994792e-06\n",
            "Total Loss: 0.05373357584425586\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "Var loss:  tensor(0.0458, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.0504123122634963\n",
            "E_s_wdiff_all_sq: 0.004594387678063869\n",
            "E_IS_SCOPE: 4.994035759673149e-05\n",
            "E_IS_E_SCOPE: 5.543781151084006e-05\n",
            "Total Loss: 0.045808054800670656\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "Var loss:  tensor(0.0389, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.048515872656841715\n",
            "E_s_wdiff_all_sq: 0.009582613863139158\n",
            "E_IS_SCOPE: 0.00011337560882700084\n",
            "E_IS_E_SCOPE: 0.00011870225494622833\n",
            "Total Loss: 0.03892373062453054\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "Var loss:  tensor(0.0341, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.04950488927357401\n",
            "E_s_wdiff_all_sq: 0.015386559139357287\n",
            "E_IS_SCOPE: 0.00016646643441788316\n",
            "E_IS_E_SCOPE: 0.00017161545398003815\n",
            "Total Loss: 0.03410915721815885\n",
            "----------------------------------------\n",
            "Epoch 11\n",
            "Var loss:  tensor(0.0299, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.05234703835465415\n",
            "E_s_wdiff_all_sq: 0.022390642577197396\n",
            "E_IS_SCOPE: 0.00021817072671318174\n",
            "E_IS_E_SCOPE: 0.00022315749374691508\n",
            "Total Loss: 0.029947547366455725\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "Var loss:  tensor(0.0263, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.0569632752586208\n",
            "E_s_wdiff_all_sq: 0.030634205779846418\n",
            "E_IS_SCOPE: 0.0002695396784779753\n",
            "E_IS_E_SCOPE: 0.00027434676599848715\n",
            "Total Loss: 0.02632058042679979\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "Var loss:  tensor(0.0233, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.06321574139382483\n",
            "E_s_wdiff_all_sq: 0.03993184424256603\n",
            "E_IS_SCOPE: 0.0003197964958500142\n",
            "E_IS_E_SCOPE: 0.0003243912983452474\n",
            "Total Loss: 0.023275832669334764\n",
            "----------------------------------------\n",
            "Epoch 14\n",
            "Var loss:  tensor(0.0208, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.07077811203035576\n",
            "E_s_wdiff_all_sq: 0.04995584483465661\n",
            "E_IS_SCOPE: 0.00036798485978724164\n",
            "E_IS_E_SCOPE: 0.0003723377888989095\n",
            "Total Loss: 0.020814686460542256\n",
            "----------------------------------------\n",
            "Epoch 15\n",
            "Var loss:  tensor(0.0189, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.0793085919755429\n",
            "E_s_wdiff_all_sq: 0.06039850122952358\n",
            "E_IS_SCOPE: 0.0004134152678751711\n",
            "E_IS_E_SCOPE: 0.00041750881420025374\n",
            "Total Loss: 0.01890302877643559\n",
            "----------------------------------------\n",
            "Epoch 16\n",
            "Var loss:  tensor(0.0175, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.08846424225442905\n",
            "E_s_wdiff_all_sq: 0.07097461945883708\n",
            "E_IS_SCOPE: 0.00045580352366264944\n",
            "E_IS_E_SCOPE: 0.0004596221890870441\n",
            "Total Loss: 0.017483110587809603\n",
            "----------------------------------------\n",
            "Epoch 17\n",
            "Var loss:  tensor(0.0165, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.09769536624212337\n",
            "E_s_wdiff_all_sq: 0.08123409527225472\n",
            "E_IS_SCOPE: 0.0004942089200272758\n",
            "E_IS_E_SCOPE: 0.0004977367640809867\n",
            "Total Loss: 0.016455340404827656\n",
            "----------------------------------------\n",
            "Epoch 18\n",
            "Var loss:  tensor(0.0158, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.10672146615707488\n",
            "E_s_wdiff_all_sq: 0.09095097090991745\n",
            "E_IS_SCOPE: 0.0005290266073228855\n",
            "E_IS_E_SCOPE: 0.0005321991348745425\n",
            "Total Loss: 0.015765275315120564\n",
            "----------------------------------------\n",
            "Epoch 19\n",
            "Var loss:  tensor(0.0154, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.11523150839064138\n",
            "E_s_wdiff_all_sq: 0.0998746482486804\n",
            "E_IS_SCOPE: 0.0005602125165639581\n",
            "E_IS_E_SCOPE: 0.0005630182791410967\n",
            "Total Loss: 0.015352373739873124\n",
            "----------------------------------------\n",
            "Epoch 20\n",
            "Var loss:  tensor(0.0151, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.1228997639045931\n",
            "E_s_wdiff_all_sq: 0.10774675470546063\n",
            "E_IS_SCOPE: 0.000587511790980629\n",
            "E_IS_E_SCOPE: 0.0005899504260743376\n",
            "Total Loss: 0.015149257052011492\n",
            "----------------------------------------\n",
            "Epoch 21\n",
            "Var loss:  tensor(0.0151, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.12939065808812644\n",
            "E_s_wdiff_all_sq: 0.11431017292684988\n",
            "E_IS_SCOPE: 0.0006105297884030049\n",
            "E_IS_E_SCOPE: 0.0006126166866516021\n",
            "Total Loss: 0.015077436487845805\n",
            "----------------------------------------\n",
            "Epoch 22\n",
            "Var loss:  tensor(0.0151, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.13452292513357333\n",
            "E_s_wdiff_all_sq: 0.11944390807755928\n",
            "E_IS_SCOPE: 0.0006293534481527638\n",
            "E_IS_E_SCOPE: 0.0006311046671788489\n",
            "Total Loss: 0.015076639741028325\n",
            "----------------------------------------\n",
            "Epoch 23\n",
            "Var loss:  tensor(0.0151, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.1381697901437851\n",
            "E_s_wdiff_all_sq: 0.12307553131082917\n",
            "E_IS_SCOPE: 0.0006440631700123626\n",
            "E_IS_E_SCOPE: 0.0006454929486758053\n",
            "Total Loss: 0.015092524398695503\n",
            "----------------------------------------\n",
            "Epoch 24\n",
            "Var loss:  tensor(0.0151, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.14025435623748944\n",
            "E_s_wdiff_all_sq: 0.12517200301504958\n",
            "E_IS_SCOPE: 0.0006547388476835425\n",
            "E_IS_E_SCOPE: 0.0006558683594635652\n",
            "Total Loss: 0.015081219321946254\n",
            "----------------------------------------\n",
            "Epoch 25\n",
            "Var loss:  tensor(0.0150, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.14075832825977388\n",
            "E_s_wdiff_all_sq: 0.12574657946510517\n",
            "E_IS_SCOPE: 0.0006617166283364141\n",
            "E_IS_E_SCOPE: 0.0006625689841587855\n",
            "Total Loss: 0.015011169206090413\n",
            "----------------------------------------\n",
            "Epoch 26\n",
            "Var loss:  tensor(0.0149, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.13970832461982804\n",
            "E_s_wdiff_all_sq: 0.12484510919561963\n",
            "E_IS_SCOPE: 0.0006647198466471599\n",
            "E_IS_E_SCOPE: 0.0006653208451685685\n",
            "Total Loss: 0.014863138550232038\n",
            "----------------------------------------\n",
            "Epoch 27\n",
            "Var loss:  tensor(0.0146, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.13726218722544753\n",
            "E_s_wdiff_all_sq: 0.1226334607225394\n",
            "E_IS_SCOPE: 0.0006642705965718272\n",
            "E_IS_E_SCOPE: 0.0006646482952402545\n",
            "Total Loss: 0.014629096228637714\n",
            "----------------------------------------\n",
            "Epoch 28\n",
            "Var loss:  tensor(0.0143, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.13353579432308188\n",
            "E_s_wdiff_all_sq: 0.11922872111858607\n",
            "E_IS_SCOPE: 0.0006606111745987252\n",
            "E_IS_E_SCOPE: 0.0006607982551451171\n",
            "Total Loss: 0.014307824166469474\n",
            "----------------------------------------\n",
            "Epoch 29\n",
            "Var loss:  tensor(0.0139, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.12869547597066078\n",
            "E_s_wdiff_all_sq: 0.11479169752388439\n",
            "E_IS_SCOPE: 0.0006541425804998462\n",
            "E_IS_E_SCOPE: 0.0006541707997583372\n",
            "Total Loss: 0.013904847131325823\n",
            "----------------------------------------\n",
            "Epoch 30\n",
            "Var loss:  tensor(0.0134, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.12296005484405509\n",
            "E_s_wdiff_all_sq: 0.10952465785483498\n",
            "E_IS_SCOPE: 0.0006451689497578333\n",
            "E_IS_E_SCOPE: 0.0006450707242915479\n",
            "Total Loss: 0.01343671856321911\n",
            "----------------------------------------\n",
            "Epoch 31\n",
            "Var loss:  tensor(0.0129, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.11656705223068252\n",
            "E_s_wdiff_all_sq: 0.1036447805234519\n",
            "E_IS_SCOPE: 0.0006340489980968916\n",
            "E_IS_E_SCOPE: 0.0006338501625595316\n",
            "Total Loss: 0.012923794501371766\n",
            "----------------------------------------\n",
            "Epoch 32\n",
            "Var loss:  tensor(0.0124, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.1096972935346874\n",
            "E_s_wdiff_all_sq: 0.09732649816710795\n",
            "E_IS_SCOPE: 0.0006212014605605339\n",
            "E_IS_E_SCOPE: 0.0006209148108541839\n",
            "Total Loss: 0.0123724937900586\n",
            "----------------------------------------\n",
            "Epoch 33\n",
            "Var loss:  tensor(0.0118, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.10252623230531457\n",
            "E_s_wdiff_all_sq: 0.09072406962516637\n",
            "E_IS_SCOPE: 0.0006067578276412343\n",
            "E_IS_E_SCOPE: 0.0006063956278411918\n",
            "Total Loss: 0.011804012202814726\n",
            "----------------------------------------\n",
            "Epoch 34\n",
            "Var loss:  tensor(0.0112, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.09518493309471086\n",
            "E_s_wdiff_all_sq: 0.08395227224210194\n",
            "E_IS_SCOPE: 0.0005908899110144122\n",
            "E_IS_E_SCOPE: 0.000590480234134969\n",
            "Total Loss: 0.011234605329434252\n",
            "----------------------------------------\n",
            "Epoch 35\n",
            "Var loss:  tensor(0.0107, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.08782738884762503\n",
            "E_s_wdiff_all_sq: 0.07714970917994547\n",
            "E_IS_SCOPE: 0.0005739173614441375\n",
            "E_IS_E_SCOPE: 0.0005734855168339148\n",
            "Total Loss: 0.010679668479966445\n",
            "----------------------------------------\n",
            "Epoch 36\n",
            "Var loss:  tensor(0.0102, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.08060641426730712\n",
            "E_s_wdiff_all_sq: 0.07045594499066074\n",
            "E_IS_SCOPE: 0.0005562252990201838\n",
            "E_IS_E_SCOPE: 0.0005557820754269913\n",
            "Total Loss: 0.010152480846899209\n",
            "----------------------------------------\n",
            "Epoch 37\n",
            "Var loss:  tensor(0.0097, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.07364903217570176\n",
            "E_s_wdiff_all_sq: 0.06398550181581818\n",
            "E_IS_SCOPE: 0.0005381594140114158\n",
            "E_IS_E_SCOPE: 0.0005377216179733293\n",
            "Total Loss: 0.009665531075026199\n",
            "----------------------------------------\n",
            "Epoch 38\n",
            "Var loss:  tensor(0.0092, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.06704607140190602\n",
            "E_s_wdiff_all_sq: 0.05782829374240399\n",
            "E_IS_SCOPE: 0.0005199532597512808\n",
            "E_IS_E_SCOPE: 0.0005195431840519399\n",
            "Total Loss: 0.009219722933967153\n",
            "----------------------------------------\n",
            "Epoch 39\n",
            "Var loss:  tensor(0.0088, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.060851631021386174\n",
            "E_s_wdiff_all_sq: 0.05203656550846089\n",
            "E_IS_SCOPE: 0.000502085730377354\n",
            "E_IS_E_SCOPE: 0.0005017274120744586\n",
            "Total Loss: 0.008816907272597513\n",
            "----------------------------------------\n",
            "Epoch 40\n",
            "Var loss:  tensor(0.0085, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.05510726665927724\n",
            "E_s_wdiff_all_sq: 0.04664912441505664\n",
            "E_IS_SCOPE: 0.00048455651652294857\n",
            "E_IS_E_SCOPE: 0.0004842669450594438\n",
            "Total Loss: 0.008459846510214038\n",
            "----------------------------------------\n",
            "Epoch 41\n",
            "Var loss:  tensor(0.0081, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.049831324978314114\n",
            "E_s_wdiff_all_sq: 0.04168616634026927\n",
            "E_IS_SCOPE: 0.00046755531116912365\n",
            "E_IS_E_SCOPE: 0.00046734959222684416\n",
            "Total Loss: 0.008146695198995843\n",
            "----------------------------------------\n",
            "Epoch 42\n",
            "Var loss:  tensor(0.0079, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.04503345527054377\n",
            "E_s_wdiff_all_sq: 0.03716105902878415\n",
            "E_IS_SCOPE: 0.00045124032058162873\n",
            "E_IS_E_SCOPE: 0.0004511306204056378\n",
            "Total Loss: 0.007873740765178036\n",
            "----------------------------------------\n",
            "Epoch 43\n",
            "Var loss:  tensor(0.0076, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.04071917518708896\n",
            "E_s_wdiff_all_sq: 0.03308456189465976\n",
            "E_IS_SCOPE: 0.00043581185807951286\n",
            "E_IS_E_SCOPE: 0.0004358086535694071\n",
            "Total Loss: 0.007635744824515844\n",
            "----------------------------------------\n",
            "Epoch 44\n",
            "Var loss:  tensor(0.0074, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.03687006603934186\n",
            "E_s_wdiff_all_sq: 0.029443166531977115\n",
            "E_IS_SCOPE: 0.0004214204415014725\n",
            "E_IS_E_SCOPE: 0.00042152940818290015\n",
            "Total Loss: 0.007427806697068329\n",
            "----------------------------------------\n",
            "Epoch 45\n",
            "Var loss:  tensor(0.0072, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.033460296592982684\n",
            "E_s_wdiff_all_sq: 0.02621689535377135\n",
            "E_IS_SCOPE: 0.0004082326325838883\n",
            "E_IS_E_SCOPE: 0.0004084567745120869\n",
            "Total Loss: 0.007244078078421368\n",
            "----------------------------------------\n",
            "Epoch 46\n",
            "Var loss:  tensor(0.0071, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.030459607790362223\n",
            "E_s_wdiff_all_sq: 0.023381532383757595\n",
            "E_IS_SCOPE: 0.00039621202771657524\n",
            "E_IS_E_SCOPE: 0.0003965527631215214\n",
            "Total Loss: 0.007078519058861168\n",
            "----------------------------------------\n",
            "Epoch 47\n",
            "Var loss:  tensor(0.0069, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.027835388209585983\n",
            "E_s_wdiff_all_sq: 0.02090933692266301\n",
            "E_IS_SCOPE: 0.00038540490218007115\n",
            "E_IS_E_SCOPE: 0.00038586771904216925\n",
            "Total Loss: 0.00692625077626521\n",
            "----------------------------------------\n",
            "Epoch 48\n",
            "Var loss:  tensor(0.0068, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.025545132524872154\n",
            "E_s_wdiff_all_sq: 0.018763323201636768\n",
            "E_IS_SCOPE: 0.00037579562476641916\n",
            "E_IS_E_SCOPE: 0.0003763782920297131\n",
            "Total Loss: 0.006781769111775231\n",
            "----------------------------------------\n",
            "Epoch 49\n",
            "Var loss:  tensor(0.0066, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.02355787177510137\n",
            "E_s_wdiff_all_sq: 0.01691637330059643\n",
            "E_IS_SCOPE: 0.0003674201354001065\n",
            "E_IS_E_SCOPE: 0.000368117680158597\n",
            "Total Loss: 0.006641228508054389\n",
            "----------------------------------------\n",
            "Epoch 50\n",
            "Var loss:  tensor(0.0065, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.021846839033319552\n",
            "E_s_wdiff_all_sq: 0.015344033075692128\n",
            "E_IS_SCOPE: 0.00036034068433630633\n",
            "E_IS_E_SCOPE: 0.0003611462890959928\n",
            "Total Loss: 0.006502319871174481\n",
            "----------------------------------------\n",
            "Epoch 51\n",
            "Var loss:  tensor(0.0064, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.020369553692523922\n",
            "E_s_wdiff_all_sq: 0.014006469277111222\n",
            "E_IS_SCOPE: 0.0003544335485147866\n",
            "E_IS_E_SCOPE: 0.00035534056112929396\n",
            "Total Loss: 0.006362395513250121\n",
            "----------------------------------------\n",
            "Epoch 52\n",
            "Var loss:  tensor(0.0062, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.019092600218665632\n",
            "E_s_wdiff_all_sq: 0.012871232531858904\n",
            "E_IS_SCOPE: 0.00034959583577815856\n",
            "E_IS_E_SCOPE: 0.0003505972058056035\n",
            "Total Loss: 0.006220490069818271\n",
            "----------------------------------------\n",
            "Epoch 53\n",
            "Var loss:  tensor(0.0061, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.018002808908375863\n",
            "E_s_wdiff_all_sq: 0.011924113588473402\n",
            "E_IS_SCOPE: 0.00034592659780299356\n",
            "E_IS_E_SCOPE: 0.00034701325275206024\n",
            "Total Loss: 0.006077647133070758\n",
            "----------------------------------------\n",
            "Epoch 54\n",
            "Var loss:  tensor(0.0059, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.01707463186836262\n",
            "E_s_wdiff_all_sq: 0.011139150281763922\n",
            "E_IS_SCOPE: 0.0003433335062096914\n",
            "E_IS_E_SCOPE: 0.0003444944901438544\n",
            "Total Loss: 0.005934284741796806\n",
            "----------------------------------------\n",
            "Epoch 55\n",
            "Var loss:  tensor(0.0058, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.016282250721570263\n",
            "E_s_wdiff_all_sq: 0.010490793715210762\n",
            "E_IS_SCOPE: 0.00034170493809580033\n",
            "E_IS_E_SCOPE: 0.0003429311883867716\n",
            "Total Loss: 0.0057901296288439905\n",
            "----------------------------------------\n",
            "Epoch 56\n",
            "Var loss:  tensor(0.0056, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.01558309286996791\n",
            "E_s_wdiff_all_sq: 0.009938476752041252\n",
            "E_IS_SCOPE: 0.00034075441941519346\n",
            "E_IS_E_SCOPE: 0.0003420406410002784\n",
            "Total Loss: 0.005643168797822919\n",
            "----------------------------------------\n",
            "Epoch 57\n",
            "Var loss:  tensor(0.0055, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.015090695900328887\n",
            "E_s_wdiff_all_sq: 0.009615755479097293\n",
            "E_IS_SCOPE: 0.0003429535444466902\n",
            "E_IS_E_SCOPE: 0.00034429713652351485\n",
            "Total Loss: 0.005473378360144377\n",
            "----------------------------------------\n",
            "Epoch 58\n",
            "Var loss:  tensor(0.0053, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.014697834342306877\n",
            "E_s_wdiff_all_sq: 0.009381531354162219\n",
            "E_IS_SCOPE: 0.00034606412319170953\n",
            "E_IS_E_SCOPE: 0.00034746095853127335\n",
            "Total Loss: 0.005314634440531964\n",
            "----------------------------------------\n",
            "Epoch 59\n",
            "Var loss:  tensor(0.0052, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.014373973727138906\n",
            "E_s_wdiff_all_sq: 0.009201950018571837\n",
            "E_IS_SCOPE: 0.00034971756923699395\n",
            "E_IS_E_SCOPE: 0.00035116255284229513\n",
            "Total Loss: 0.005170258864422902\n",
            "----------------------------------------\n",
            "Epoch 60\n",
            "Var loss:  tensor(0.0050, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.01409473514687836\n",
            "E_s_wdiff_all_sq: 0.009048892901178116\n",
            "E_IS_SCOPE: 0.0003536149744808655\n",
            "E_IS_E_SCOPE: 0.0003551019443809888\n",
            "Total Loss: 0.005043993428966434\n",
            "----------------------------------------\n",
            "Epoch 61\n",
            "Var loss:  tensor(0.0049, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.013844683245555796\n",
            "E_s_wdiff_all_sq: 0.008905398021757603\n",
            "E_IS_SCOPE: 0.0003574008598681113\n",
            "E_IS_E_SCOPE: 0.0003589207347105837\n",
            "Total Loss: 0.004937370597179682\n",
            "----------------------------------------\n",
            "Epoch 62\n",
            "Var loss:  tensor(0.0048, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.0136024923157964\n",
            "E_s_wdiff_all_sq: 0.008751282402029412\n",
            "E_IS_SCOPE: 0.0003608091371339045\n",
            "E_IS_E_SCOPE: 0.000362352782027908\n",
            "Total Loss: 0.004849247747045414\n",
            "----------------------------------------\n",
            "Epoch 63\n",
            "Var loss:  tensor(0.0048, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.013331931607751812\n",
            "E_s_wdiff_all_sq: 0.008554041833265148\n",
            "E_IS_SCOPE: 0.0003636140482961245\n",
            "E_IS_E_SCOPE: 0.00036517285300706064\n",
            "Total Loss: 0.004775897288131227\n",
            "----------------------------------------\n",
            "Epoch 64\n",
            "Var loss:  tensor(0.0047, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.01292204805659021\n",
            "E_s_wdiff_all_sq: 0.008209413258973466\n",
            "E_IS_SCOPE: 0.00036435521875047814\n",
            "E_IS_E_SCOPE: 0.00036592023246146793\n",
            "Total Loss: 0.0047106298932611985\n",
            "----------------------------------------\n",
            "Epoch 65\n",
            "Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.012327187384937299\n",
            "E_s_wdiff_all_sq: 0.007679449670478537\n",
            "E_IS_SCOPE: 0.0003624026869585557\n",
            "E_IS_E_SCOPE: 0.00036397083698921413\n",
            "Total Loss: 0.00464572653746388\n",
            "----------------------------------------\n",
            "Epoch 66\n",
            "Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.011641767619024567\n",
            "E_s_wdiff_all_sq: 0.00705998507561085\n",
            "E_IS_SCOPE: 0.00035888770717816104\n",
            "E_IS_E_SCOPE: 0.00036045640906800776\n",
            "Total Loss: 0.004579770262700456\n",
            "----------------------------------------\n",
            "Epoch 67\n",
            "Var loss:  tensor(0.0045, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.010916261344749137\n",
            "E_s_wdiff_all_sq: 0.006399280207747667\n",
            "E_IS_SCOPE: 0.0003543615660858103\n",
            "E_IS_E_SCOPE: 0.0003559322248064307\n",
            "Total Loss: 0.004514964942626661\n",
            "----------------------------------------\n",
            "Epoch 68\n",
            "Var loss:  tensor(0.0045, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.010219151949191846\n",
            "E_s_wdiff_all_sq: 0.005762754166968863\n",
            "E_IS_SCOPE: 0.0003494868092154718\n",
            "E_IS_E_SCOPE: 0.00035105574482906086\n",
            "Total Loss: 0.004454385034062238\n",
            "----------------------------------------\n",
            "Epoch 69\n",
            "Var loss:  tensor(0.0044, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.009585241391823618\n",
            "E_s_wdiff_all_sq: 0.0051866963524843475\n",
            "E_IS_SCOPE: 0.0003446939023859514\n",
            "E_IS_E_SCOPE: 0.0003462545518829453\n",
            "Total Loss: 0.004396548863411716\n",
            "----------------------------------------\n",
            "Epoch 70\n",
            "Var loss:  tensor(0.0043, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.009027924701307628\n",
            "E_s_wdiff_all_sq: 0.004685912756500788\n",
            "E_IS_SCOPE: 0.0003402441280326053\n",
            "E_IS_E_SCOPE: 0.00034179103438031357\n",
            "Total Loss: 0.004340043255177856\n",
            "----------------------------------------\n",
            "Epoch 71\n",
            "Var loss:  tensor(0.0043, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.008563846343288727\n",
            "E_s_wdiff_all_sq: 0.004277002180948894\n",
            "E_IS_SCOPE: 0.00033652777190890657\n",
            "E_IS_E_SCOPE: 0.0003380564628114167\n",
            "Total Loss: 0.004284911903601247\n",
            "----------------------------------------\n",
            "Epoch 72\n",
            "Var loss:  tensor(0.0042, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.008208273690172383\n",
            "E_s_wdiff_all_sq: 0.00397884934966099\n",
            "E_IS_SCOPE: 0.0003340195999925944\n",
            "E_IS_E_SCOPE: 0.0003355286676491658\n",
            "Total Loss: 0.004227531328264683\n",
            "----------------------------------------\n",
            "Epoch 73\n",
            "Var loss:  tensor(0.0042, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.00793515347682762\n",
            "E_s_wdiff_all_sq: 0.003763588789927591\n",
            "E_IS_SCOPE: 0.0003324583675959316\n",
            "E_IS_E_SCOPE: 0.0003339468754733705\n",
            "Total Loss: 0.004169712794211584\n",
            "----------------------------------------\n",
            "Epoch 74\n",
            "Var loss:  tensor(0.0041, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.0077082143960846596\n",
            "E_s_wdiff_all_sq: 0.0035916048577938455\n",
            "E_IS_SCOPE: 0.00033128913762055944\n",
            "E_IS_E_SCOPE: 0.0003327560192033841\n",
            "Total Loss: 0.004114800898191599\n",
            "----------------------------------------\n",
            "Epoch 75\n",
            "Var loss:  tensor(0.0041, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.007484704253024982\n",
            "E_s_wdiff_all_sq: 0.0034185809933272968\n",
            "E_IS_SCOPE: 0.0003297735813530524\n",
            "E_IS_E_SCOPE: 0.00033122212415713\n",
            "Total Loss: 0.0040643512971559655\n",
            "----------------------------------------\n",
            "Epoch 76\n",
            "Var loss:  tensor(0.0040, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.007240860558559237\n",
            "E_s_wdiff_all_sq: 0.0032240777326951408\n",
            "E_IS_SCOPE: 0.00032757962855704006\n",
            "E_IS_E_SCOPE: 0.00032900978012682155\n",
            "Total Loss: 0.004015047645790967\n",
            "----------------------------------------\n",
            "Epoch 77\n",
            "Var loss:  tensor(0.0040, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.006979422630294758\n",
            "E_s_wdiff_all_sq: 0.003011557741644556\n",
            "E_IS_SCOPE: 0.00032470660126135225\n",
            "E_IS_E_SCOPE: 0.0003261184027025264\n",
            "Total Loss: 0.003966166408834288\n",
            "----------------------------------------\n",
            "Epoch 78\n",
            "Var loss:  tensor(0.0039, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.0067113177758735135\n",
            "E_s_wdiff_all_sq: 0.002791524054462898\n",
            "E_IS_SCOPE: 0.0003213424476694919\n",
            "E_IS_E_SCOPE: 0.0003227340950860501\n",
            "Total Loss: 0.003918135549643933\n",
            "----------------------------------------\n",
            "Epoch 79\n",
            "Var loss:  tensor(0.0039, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.006447835233454535\n",
            "E_s_wdiff_all_sq: 0.002574821444572861\n",
            "E_IS_SCOPE: 0.0003176922755539199\n",
            "E_IS_E_SCOPE: 0.00031906497919659195\n",
            "Total Loss: 0.0038713935046627637\n",
            "----------------------------------------\n",
            "Epoch 80\n",
            "Var loss:  tensor(0.0038, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.006201877607733952\n",
            "E_s_wdiff_all_sq: 0.002373963574160789\n",
            "E_IS_SCOPE: 0.00031401918317040806\n",
            "E_IS_E_SCOPE: 0.00031537497107917215\n",
            "Total Loss: 0.0038263275808220693\n",
            "----------------------------------------\n",
            "Epoch 81\n",
            "Var loss:  tensor(0.0038, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.005987797994605537\n",
            "E_s_wdiff_all_sq: 0.002203578956221644\n",
            "E_IS_SCOPE: 0.0003107420342818258\n",
            "E_IS_E_SCOPE: 0.00031206575049514535\n",
            "Total Loss: 0.003782696729023688\n",
            "----------------------------------------\n",
            "Epoch 82\n",
            "Var loss:  tensor(0.0037, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.005810721025780044\n",
            "E_s_wdiff_all_sq: 0.0020691189464985722\n",
            "E_IS_SCOPE: 0.0003080571836583361\n",
            "E_IS_E_SCOPE: 0.00030933903392561714\n",
            "Total Loss: 0.003740163501813344\n",
            "----------------------------------------\n",
            "Epoch 83\n",
            "Var loss:  tensor(0.0037, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.005664955034010021\n",
            "E_s_wdiff_all_sq: 0.0019647691901534506\n",
            "E_IS_SCOPE: 0.00030591240445649844\n",
            "E_IS_E_SCOPE: 0.00030715569746104024\n",
            "Total Loss: 0.0036988243809139205\n",
            "----------------------------------------\n",
            "Epoch 84\n",
            "Var loss:  tensor(0.0037, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.005546839543450366\n",
            "E_s_wdiff_all_sq: 0.0018863713403155912\n",
            "E_IS_SCOPE: 0.0003042651210074962\n",
            "E_IS_E_SCOPE: 0.00030547451648233094\n",
            "Total Loss: 0.0036591745352515387\n",
            "----------------------------------------\n",
            "Epoch 85\n",
            "Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.00544364099782422\n",
            "E_s_wdiff_all_sq: 0.0018219545909874935\n",
            "E_IS_SCOPE: 0.00030293586066468085\n",
            "E_IS_E_SCOPE: 0.0003041171705437067\n",
            "Total Loss: 0.003620448910145109\n",
            "----------------------------------------\n",
            "Epoch 86\n",
            "Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.005331150909892116\n",
            "E_s_wdiff_all_sq: 0.0017471589767959744\n",
            "E_IS_SCOPE: 0.0003012430029190858\n",
            "E_IS_E_SCOPE: 0.00030239329117806097\n",
            "Total Loss: 0.003582816479644625\n",
            "----------------------------------------\n",
            "Epoch 87\n",
            "Var loss:  tensor(0.0035, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.005154437889830231\n",
            "E_s_wdiff_all_sq: 0.0016051010872319726\n",
            "E_IS_SCOPE: 0.0002974528424718552\n",
            "E_IS_E_SCOPE: 0.0002985652004955169\n",
            "Total Loss: 0.003548237209617368\n",
            "----------------------------------------\n",
            "Epoch 88\n",
            "Var loss:  tensor(0.0035, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.0049899532274222955\n",
            "E_s_wdiff_all_sq: 0.0014736694193556\n",
            "E_IS_SCOPE: 0.0002938946021185957\n",
            "E_IS_E_SCOPE: 0.00029496819040062034\n",
            "Total Loss: 0.0035152617545690804\n",
            "----------------------------------------\n",
            "Epoch 89\n",
            "Var loss:  tensor(0.0035, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.004837414959578078\n",
            "E_s_wdiff_all_sq: 0.0013528547022474363\n",
            "E_IS_SCOPE: 0.0002905792268313363\n",
            "E_IS_E_SCOPE: 0.0002916200009191387\n",
            "Total Loss: 0.0034836038322214715\n",
            "----------------------------------------\n",
            "Epoch 90\n",
            "Var loss:  tensor(0.0035, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.004697623319309264\n",
            "E_s_wdiff_all_sq: 0.001243785452595476\n",
            "E_IS_SCOPE: 0.0002875304751435228\n",
            "E_IS_E_SCOPE: 0.0002885454813812173\n",
            "Total Loss: 0.003452932977304833\n",
            "----------------------------------------\n",
            "Epoch 91\n",
            "Var loss:  tensor(0.0034, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.004570785512760991\n",
            "E_s_wdiff_all_sq: 0.0011470071604600682\n",
            "E_IS_SCOPE: 0.0002848759470677444\n",
            "E_IS_E_SCOPE: 0.0002858716066256076\n",
            "Total Loss: 0.0034229121562516307\n",
            "----------------------------------------\n",
            "Epoch 92\n",
            "Var loss:  tensor(0.0034, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.004456341276362587\n",
            "E_s_wdiff_all_sq: 0.0010622647678557515\n",
            "E_IS_SCOPE: 0.00028254493938619223\n",
            "E_IS_E_SCOPE: 0.0002835272934322516\n",
            "Total Loss: 0.003393236923481151\n",
            "----------------------------------------\n",
            "Epoch 93\n",
            "Var loss:  tensor(0.0034, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.004353356020422386\n",
            "E_s_wdiff_all_sq: 0.0009888186723630997\n",
            "E_IS_SCOPE: 0.0002805295590759807\n",
            "E_IS_E_SCOPE: 0.00028150463152687866\n",
            "Total Loss: 0.003363712326223924\n",
            "----------------------------------------\n",
            "Epoch 94\n",
            "Var loss:  tensor(0.0033, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.004261752359474844\n",
            "E_s_wdiff_all_sq: 0.0009263055687244455\n",
            "E_IS_SCOPE: 0.0002788551115124601\n",
            "E_IS_E_SCOPE: 0.0002798291567532099\n",
            "Total Loss: 0.0033346238233353323\n",
            "----------------------------------------\n",
            "Epoch 95\n",
            "Var loss:  tensor(0.0033, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.004181557094295289\n",
            "E_s_wdiff_all_sq: 0.0008745929968227259\n",
            "E_IS_SCOPE: 0.0002775429446410165\n",
            "E_IS_E_SCOPE: 0.0002785195681194593\n",
            "Total Loss: 0.003306135973582112\n",
            "----------------------------------------\n",
            "Epoch 96\n",
            "Var loss:  tensor(0.0033, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.004109885719853463\n",
            "E_s_wdiff_all_sq: 0.0008312354798769383\n",
            "E_IS_SCOPE: 0.0002765063688131618\n",
            "E_IS_E_SCOPE: 0.0002774887063359298\n",
            "Total Loss: 0.003277810687997423\n",
            "----------------------------------------\n",
            "Epoch 97\n",
            "Var loss:  tensor(0.0032, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.004045104316372374\n",
            "E_s_wdiff_all_sq: 0.0007944505461247694\n",
            "E_IS_SCOPE: 0.0002757004696401811\n",
            "E_IS_E_SCOPE: 0.00027669159817488964\n",
            "Total Loss: 0.0032497966362446218\n",
            "----------------------------------------\n",
            "Epoch 98\n",
            "Var loss:  tensor(0.0032, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.003985727607939652\n",
            "E_s_wdiff_all_sq: 0.0007626242429272893\n",
            "E_IS_SCOPE: 0.00027503963035422984\n",
            "E_IS_E_SCOPE: 0.00027604184943446855\n",
            "Total Loss: 0.0032222240499183196\n",
            "----------------------------------------\n",
            "Epoch 99\n",
            "Var loss:  tensor(0.0032, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.003929667385998214\n",
            "E_s_wdiff_all_sq: 0.0007332116937730933\n",
            "E_IS_SCOPE: 0.000274446027611878\n",
            "E_IS_E_SCOPE: 0.00027546078784154384\n",
            "Total Loss: 0.003195551294832223\n",
            "----------------------------------------\n",
            "Epoch 100\n",
            "Var loss:  tensor(0.0032, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 0.0038766636658137585\n",
            "E_s_wdiff_all_sq: 0.0007062275085991669\n",
            "E_IS_SCOPE: 0.0002739092519125207\n",
            "E_IS_E_SCOPE: 0.0002749363678194191\n",
            "Total Loss: 0.0031695070484672287\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[ 0.2165,  0.1824],\n",
            "        [ 0.1057, -0.4369],\n",
            "        [-0.5297, -0.2837],\n",
            "        [ 0.2928,  0.3621],\n",
            "        [ 0.1498,  0.2231],\n",
            "        [ 0.5104, -0.4407],\n",
            "        [-0.3571,  0.2021],\n",
            "        [ 0.3101, -0.2008],\n",
            "        [-0.4288, -0.6201],\n",
            "        [-0.2209,  0.4062],\n",
            "        [-0.0940, -0.2111],\n",
            "        [-0.6620,  0.0024],\n",
            "        [ 0.1370, -0.5095],\n",
            "        [ 0.0414, -0.1268],\n",
            "        [-0.3401,  0.3611],\n",
            "        [ 0.4502,  0.4955]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([ 0.2590, -0.6539,  0.5999,  0.3264, -0.5191, -0.5932,  0.4432,  0.5988,\n",
            "        -0.1064, -0.0684,  0.0274, -0.4292, -0.7034,  0.1701, -0.1496, -0.2422],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[-0.1202,  0.1017, -0.0671, -0.1920,  0.1667,  0.3111,  0.0579, -0.1307,\n",
            "         -0.0131,  0.1041,  0.0329,  0.0436,  0.1578, -0.0170,  0.1095, -0.0599],\n",
            "        [-0.1380, -0.1483, -0.0294,  0.1491,  0.0353,  0.2037, -0.2511, -0.0186,\n",
            "          0.2349, -0.1940, -0.1982, -0.0407,  0.0064,  0.1178, -0.1044,  0.0981],\n",
            "        [ 0.2382,  0.1787, -0.0535, -0.1045,  0.0170,  0.2594,  0.1312, -0.1223,\n",
            "          0.0542, -0.1201, -0.0913, -0.0708,  0.0291, -0.0487,  0.0570, -0.1241],\n",
            "        [-0.0135,  0.0455, -0.1060, -0.1504,  0.0138,  0.0873,  0.1123,  0.1736,\n",
            "          0.1834,  0.0853,  0.1525,  0.1261,  0.1738,  0.1884,  0.1928, -0.1363],\n",
            "        [-0.1803, -0.1873,  0.0862,  0.0773, -0.1843,  0.2415, -0.1996,  0.1837,\n",
            "         -0.2287,  0.1907, -0.1608,  0.2066,  0.0172, -0.1272,  0.0143, -0.1417],\n",
            "        [-0.0671, -0.0873,  0.0118, -0.1958,  0.2151,  0.0347,  0.0332, -0.0912,\n",
            "         -0.2390, -0.2059,  0.2041, -0.2481, -0.0043, -0.2861,  0.1089,  0.2244],\n",
            "        [ 0.2249,  0.0813,  0.0149, -0.0385, -0.1740,  0.0409, -0.0838, -0.0093,\n",
            "         -0.2258, -0.0588,  0.2057,  0.0686,  0.1960, -0.0102, -0.0433,  0.0287],\n",
            "        [-0.1031, -0.1352,  0.0706,  0.2149,  0.0172, -0.1802, -0.2364,  0.0867,\n",
            "         -0.0941, -0.1533, -0.1061,  0.0900, -0.2077,  0.1008,  0.0029,  0.2143],\n",
            "        [ 0.1085, -0.0489, -0.1435, -0.0561,  0.0481,  0.1679,  0.1764, -0.1277,\n",
            "         -0.0971,  0.1566, -0.0940, -0.1636, -0.0375,  0.2488,  0.0376,  0.2310],\n",
            "        [-0.0662,  0.1713,  0.0006,  0.1844,  0.1895,  0.1986, -0.1038, -0.0559,\n",
            "          0.0507,  0.1294,  0.0306,  0.0647,  0.0835,  0.1939, -0.0121,  0.1681],\n",
            "        [ 0.1259, -0.0591, -0.2146, -0.1027, -0.0133, -0.0636,  0.1477,  0.1800,\n",
            "          0.0874,  0.1531,  0.0031, -0.2016,  0.0920, -0.2103,  0.0736, -0.0006],\n",
            "        [-0.2557, -0.1778,  0.0629,  0.0686, -0.2381,  0.1940, -0.1716, -0.1980,\n",
            "         -0.1985, -0.2137,  0.2257, -0.1361,  0.1222,  0.0494, -0.1675, -0.2158],\n",
            "        [-0.0831,  0.0709, -0.2017,  0.1086,  0.2124,  0.2201,  0.1749,  0.0725,\n",
            "         -0.0886,  0.2134,  0.0917,  0.1350,  0.1253, -0.0431,  0.0416,  0.2141],\n",
            "        [ 0.1291,  0.1348, -0.0498, -0.0741, -0.0627, -0.1251,  0.0767,  0.0613,\n",
            "         -0.1886,  0.0893, -0.2180, -0.0019, -0.1196, -0.0314, -0.0155,  0.1899],\n",
            "        [ 0.0418, -0.1517,  0.1819,  0.2133, -0.1023,  0.1967, -0.0569, -0.0994,\n",
            "         -0.0923, -0.0759,  0.1433,  0.0491,  0.1204, -0.1128,  0.0287, -0.2167],\n",
            "        [ 0.1818,  0.0141,  0.0982, -0.2132, -0.1249, -0.2748,  0.1027,  0.1993,\n",
            "          0.2049,  0.1003, -0.0117, -0.1837, -0.1601, -0.1306,  0.0420,  0.0473],\n",
            "        [-0.1893,  0.1670, -0.0325,  0.0084,  0.0246, -0.2045, -0.1985, -0.2100,\n",
            "          0.1194, -0.0222,  0.1009, -0.1538,  0.0808, -0.2470, -0.2145, -0.1102],\n",
            "        [ 0.2265,  0.2467,  0.1579,  0.1236, -0.1438, -0.0263,  0.0643, -0.0210,\n",
            "          0.2029, -0.1669,  0.0602, -0.1794,  0.1844,  0.0737,  0.0269, -0.1034],\n",
            "        [ 0.0244,  0.1083, -0.1823, -0.1257,  0.1370,  0.0381, -0.2375, -0.1633,\n",
            "         -0.2342,  0.1744,  0.1361, -0.0678,  0.2080, -0.0369, -0.0717,  0.0696],\n",
            "        [ 0.0070, -0.0064,  0.1709, -0.1914, -0.0066, -0.0036,  0.2500,  0.0034,\n",
            "         -0.1030, -0.1479, -0.0270, -0.2493,  0.0753, -0.0549, -0.1489, -0.1326],\n",
            "        [ 0.1943,  0.0679, -0.1120, -0.0876, -0.0412, -0.0796,  0.1821, -0.1811,\n",
            "         -0.2178, -0.1067,  0.0504,  0.2030,  0.1255, -0.0341,  0.1828, -0.0382],\n",
            "        [-0.2438, -0.2035, -0.0571,  0.0196,  0.1096, -0.1511,  0.0509, -0.1182,\n",
            "          0.0824, -0.1235,  0.1599,  0.1151, -0.2014, -0.0329, -0.1739, -0.0421],\n",
            "        [ 0.1567, -0.0499,  0.0880,  0.1795, -0.1368,  0.1184, -0.0163,  0.1732,\n",
            "         -0.1810, -0.0677, -0.0673, -0.0921, -0.1717, -0.2367,  0.1916, -0.0703],\n",
            "        [-0.0100, -0.1186,  0.0913,  0.2278, -0.0373,  0.1041, -0.2132, -0.1803,\n",
            "          0.0094, -0.0009,  0.0199,  0.2156,  0.0105, -0.0507,  0.2145,  0.2152],\n",
            "        [-0.1629, -0.2352, -0.2190,  0.1469,  0.1291, -0.1240, -0.0518, -0.1249,\n",
            "          0.0364, -0.0430,  0.2295, -0.0597, -0.1776,  0.0244,  0.2391, -0.2482],\n",
            "        [ 0.2557,  0.2339, -0.1477, -0.1718,  0.0093,  0.2345,  0.1637,  0.0214,\n",
            "          0.2231,  0.1529, -0.1756, -0.0229,  0.1534, -0.0598, -0.1096,  0.0333],\n",
            "        [ 0.1075, -0.0298,  0.1039,  0.0664,  0.0033, -0.2526,  0.1169,  0.1375,\n",
            "          0.1352,  0.1272,  0.0224,  0.0716,  0.0222,  0.1534,  0.1167,  0.0998],\n",
            "        [-0.0343,  0.2046, -0.1392,  0.1667,  0.0116, -0.1618, -0.2364,  0.1483,\n",
            "         -0.1424,  0.0375, -0.0719,  0.2118,  0.1254, -0.0958,  0.1509, -0.0903],\n",
            "        [-0.0219,  0.1919, -0.0056, -0.2381,  0.1627, -0.1609,  0.1913,  0.0217,\n",
            "          0.0185,  0.1205,  0.1241, -0.0141,  0.0497, -0.1412,  0.1221, -0.1867],\n",
            "        [ 0.2151,  0.1289,  0.0829,  0.0079,  0.2351,  0.0492,  0.1064,  0.1604,\n",
            "         -0.1835, -0.0360, -0.0151,  0.2104, -0.0305,  0.0426, -0.2075,  0.1820],\n",
            "        [ 0.1390, -0.1827, -0.1759,  0.0495, -0.0013,  0.2123, -0.2250,  0.0587,\n",
            "         -0.0550,  0.0887, -0.1730, -0.1354, -0.0049,  0.2302,  0.0661,  0.1076],\n",
            "        [ 0.2383,  0.2018, -0.1136, -0.0514,  0.0956,  0.1789, -0.1448,  0.1936,\n",
            "         -0.0237, -0.1457, -0.1746,  0.2433,  0.0124, -0.1484, -0.1188, -0.1749]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([ 0.2075,  0.1655, -0.1337,  0.0393, -0.2189,  0.1552,  0.1827,  0.1205,\n",
            "         0.1333,  0.0004,  0.2323, -0.0712, -0.1063,  0.2275, -0.1184,  0.0257,\n",
            "        -0.0581, -0.2027, -0.2404, -0.1763, -0.1866,  0.0307,  0.1148, -0.2608,\n",
            "        -0.1526,  0.1085,  0.1814, -0.0485,  0.0756,  0.1581,  0.0018, -0.0322],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[-0.0186, -0.0070, -0.1887, -0.0950,  0.0555,  0.0622, -0.0112,  0.0093,\n",
            "          0.0879, -0.1263,  0.0234,  0.1382,  0.0836, -0.0946, -0.0569, -0.0216,\n",
            "          0.1726, -0.1004,  0.1597, -0.2557, -0.1109,  0.0019,  0.1491, -0.0992,\n",
            "         -0.2216,  0.1503, -0.0702,  0.0411,  0.0430, -0.1156,  0.0589, -0.1216]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([0.0430], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# P_pi_b[tuple(np.append(pi_b[0]['state'][0].astype(int) , (pi_b[0]['action'][0],)))]"
      ],
      "metadata": {
        "id": "5WwYv6SGDudT"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# padded_timesteps, padded_rewards, padded_actions, padded_weights = testing.padding_IS_terms(timesteps, actions, rewards, weights)"
      ],
      "metadata": {
        "id": "dmpbvgzDRSlz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# padded_states, padded_weights_difference = testing.padding_states_weights_difference(states, weights_difference)\n",
        "# padded_state_tensors, padded_weight_diff_tensors = testing.tensorize_padded_terms(padded_states, padded_weights_difference)\n",
        "# states_first_tensor, states_last_tensor, gamma_last_tensor, weights_last_tensor = testing.tensorize_last_and_first_terms(states_first, states_last, gamma_last, weights_last)\n",
        "# IS_tensor = testing.calc_IS_terms(testing.gamma, padded_timesteps, padded_rewards, padded_weights)"
      ],
      "metadata": {
        "id": "x68IJ4fcRYjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# states_output, states_first_output, states_last_output = testing.pass_states(model, padded_state_tensors, states_first_tensor, states_last_tensor)\n",
        "# sums_states_weight_diff = testing.states_weight_diff_sums(states_output, padded_weight_diff_tensors)\n",
        "\n",
        "# gamma_weights_last_tensor = testing.calc_gamma_weight_last(testing.gamma, gamma_last, weights_last)\n",
        "\n",
        "# gamma_weights_states_last_sub_states_first = testing.last_first_terms_operations(gamma_weights_last_tensor, states_last_output, states_first_output, weight_first_tensor)\n"
      ],
      "metadata": {
        "id": "JTJBak1Gco7n"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "XBOko5a3I0y_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 200 trajectories"
      ],
      "metadata": {
        "id": "mP1Eorc7oaMn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "200 Trajectories:"
      ],
      "metadata": {
        "id": "QWksRYNyI5dG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b = action_probs_top_n_epsilon(q_table, 1, 0.4)\n",
        "pi_b = experiment_actions(200, env, P_pi_b)\n",
        "P_pi_e = action_probs_top_n_epsilon(q_table, 2, 0.05)\n",
        "pi_e = experiment_actions(200, env, P_pi_e)"
      ],
      "metadata": {
        "id": "v4PMaoImI8LA"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_200 = CustomizableFeatureNet(input_dim=2, hidden_dims=[16, 32], output_dim=1, dtype = torch.float64)"
      ],
      "metadata": {
        "id": "gdGaF6NLJKVS"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing = SCOPE_variance_play(model, 0.9, 10000, pi_b, P_pi_b, P_pi_e, dtype = torch.float64)"
      ],
      "metadata": {
        "id": "vjYDF_4AJ2_j"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IS_tensor, padded_state_tensors, padded_weight_diff_tensors, gamma_weights_last_tensor, states_first_tensor, states_last_tensor, weight_first_tensor = testing.prepare()"
      ],
      "metadata": {
        "id": "pCRa5GCXJrrs"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# single cumprod\n",
        "# 200 trajectories\n",
        "model_200_1 = train_var_play(model_200, 10000, 0.001, padded_state_tensors, states_first_tensor, states_last_tensor, testing)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-W1dMNu9G2LG",
        "outputId": "ea9f8afd-af2a-4f92-e95e-4ba9d6450f77"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Var loss:  tensor(0.3342, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.19240302141744486\n",
            "E_s_wdiff_all_sq: 0.018279117028370654\n",
            "E_IS_SCOPE: 0.08042899655323252\n",
            "E_IS_E_SCOPE: 0.00040847554319232933\n",
            "Total Loss: 0.3341666866322381\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "Var loss:  tensor(0.3110, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.18031519309864652\n",
            "E_s_wdiff_all_sq: 0.02094448154389672\n",
            "E_IS_SCOPE: 0.07617173294757792\n",
            "E_IS_E_SCOPE: 0.0003613200212326285\n",
            "Total Loss: 0.3109932776305239\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "Var loss:  tensor(0.2886, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.1686902209108127\n",
            "E_s_wdiff_all_sq: 0.02330613342299742\n",
            "E_IS_SCOPE: 0.0719275724152696\n",
            "E_IS_E_SCOPE: 0.0003163842112025963\n",
            "Total Loss: 0.2886082041190328\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "Var loss:  tensor(0.2672, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.1576459444052092\n",
            "E_s_wdiff_all_sq: 0.02538326609693005\n",
            "E_IS_SCOPE: 0.06773894121728997\n",
            "E_IS_E_SCOPE: 0.0002742096411423491\n",
            "Total Loss: 0.26719388168365793\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "Var loss:  tensor(0.2468, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.14778800411580292\n",
            "E_s_wdiff_all_sq: 0.02773522277717945\n",
            "E_IS_SCOPE: 0.06359046602750279\n",
            "E_IS_E_SCOPE: 0.0002314092234137797\n",
            "Total Loss: 0.246772635169885\n",
            "----------------------------------------\n",
            "Epoch 6\n",
            "Var loss:  tensor(0.2273, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.13920319639584772\n",
            "E_s_wdiff_all_sq: 0.03046712684237433\n",
            "E_IS_SCOPE: 0.059453699149902534\n",
            "E_IS_E_SCOPE: 0.00018772947288620099\n",
            "Total Loss: 0.22726974913058953\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "Var loss:  tensor(0.2085, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.13176754044532962\n",
            "E_s_wdiff_all_sq: 0.03361758619198431\n",
            "E_IS_SCOPE: 0.055305199108137505\n",
            "E_IS_E_SCOPE: 0.00014264991105157788\n",
            "Total Loss: 0.20847679287060072\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "Var loss:  tensor(0.1906, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.12573327349574942\n",
            "E_s_wdiff_all_sq: 0.037288915473662115\n",
            "E_IS_SCOPE: 0.05118804204810468\n",
            "E_IS_E_SCOPE: 9.600516839701419e-05\n",
            "Total Loss: 0.19063017200458618\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "Var loss:  tensor(0.1737, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.12060916166404247\n",
            "E_s_wdiff_all_sq: 0.041095755684013385\n",
            "E_IS_SCOPE: 0.04714695933316728\n",
            "E_IS_E_SCOPE: 5.0641033263790646e-05\n",
            "Total Loss: 0.1737077828029196\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "Var loss:  tensor(0.1576, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.1158019647872733\n",
            "E_s_wdiff_all_sq: 0.04445333282733626\n",
            "E_IS_SCOPE: 0.04315046103541928\n",
            "E_IS_E_SCOPE: 9.06319408623087e-06\n",
            "Total Loss: 0.15763316786568665\n",
            "----------------------------------------\n",
            "Epoch 11\n",
            "Var loss:  tensor(0.1422, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.11156587699567669\n",
            "E_s_wdiff_all_sq: 0.04771724890963127\n",
            "E_IS_SCOPE: 0.03915164184292274\n",
            "E_IS_E_SCOPE: -3.096438528670851e-05\n",
            "Total Loss: 0.14221558076554786\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "Var loss:  tensor(0.1274, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.10873323489485938\n",
            "E_s_wdiff_all_sq: 0.0517149759581286\n",
            "E_IS_SCOPE: 0.035127254806813946\n",
            "E_IS_E_SCOPE: -7.220637589619795e-05\n",
            "Total Loss: 0.1274189215252346\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "Var loss:  tensor(0.1134, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.10716737918025501\n",
            "E_s_wdiff_all_sq: 0.05623443569434512\n",
            "E_IS_SCOPE: 0.031130871483035435\n",
            "E_IS_E_SCOPE: -0.00011353566969626104\n",
            "Total Loss: 0.1134234980144568\n",
            "----------------------------------------\n",
            "Epoch 14\n",
            "Var loss:  tensor(0.1003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.10706043464641667\n",
            "E_s_wdiff_all_sq: 0.061435962352929085\n",
            "E_IS_SCOPE: 0.027192615982705295\n",
            "E_IS_E_SCOPE: -0.00015586341266889846\n",
            "Total Loss: 0.10032317130731952\n",
            "----------------------------------------\n",
            "Epoch 15\n",
            "Var loss:  tensor(0.0883, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.10768650292029704\n",
            "E_s_wdiff_all_sq: 0.06658807063598288\n",
            "E_IS_SCOPE: 0.02339242089215189\n",
            "E_IS_E_SCOPE: -0.00019454262751110685\n",
            "Total Loss: 0.08827409954672366\n",
            "----------------------------------------\n",
            "Epoch 16\n",
            "Var loss:  tensor(0.0772, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.10947441989278782\n",
            "E_s_wdiff_all_sq: 0.07216258804947231\n",
            "E_IS_SCOPE: 0.01970730418762836\n",
            "E_IS_E_SCOPE: -0.00023336673167278544\n",
            "Total Loss: 0.07719491390500133\n",
            "----------------------------------------\n",
            "Epoch 17\n",
            "Var loss:  tensor(0.0669, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.11220814536369061\n",
            "E_s_wdiff_all_sq: 0.07801787297310188\n",
            "E_IS_SCOPE: 0.016107705801814497\n",
            "E_IS_E_SCOPE: -0.000271057260377588\n",
            "Total Loss: 0.06694953873805641\n",
            "----------------------------------------\n",
            "Epoch 18\n",
            "Var loss:  tensor(0.0573, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.11537008860712562\n",
            "E_s_wdiff_all_sq: 0.08377860327247307\n",
            "E_IS_SCOPE: 0.012549980335709403\n",
            "E_IS_E_SCOPE: -0.00030550794890344925\n",
            "Total Loss: 0.05730420212696179\n",
            "----------------------------------------\n",
            "Epoch 19\n",
            "Var loss:  tensor(0.0482, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.11771183801836348\n",
            "E_s_wdiff_all_sq: 0.0882480200434493\n",
            "E_IS_SCOPE: 0.009050584085711275\n",
            "E_IS_E_SCOPE: -0.00033282480455363043\n",
            "Total Loss: 0.04823237597852752\n",
            "----------------------------------------\n",
            "Epoch 20\n",
            "Var loss:  tensor(0.0397, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.120837207866375\n",
            "E_s_wdiff_all_sq: 0.09293509517712643\n",
            "E_IS_SCOPE: 0.00554746055766672\n",
            "E_IS_E_SCOPE: -0.00035884622262057227\n",
            "Total Loss: 0.03971646647290668\n",
            "----------------------------------------\n",
            "Epoch 21\n",
            "Var loss:  tensor(0.0319, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.12373057355308238\n",
            "E_s_wdiff_all_sq: 0.09684893351215398\n",
            "E_IS_SCOPE: 0.0021238586819097194\n",
            "E_IS_E_SCOPE: -0.0003806789033470362\n",
            "Total Loss: 0.03189245543452543\n",
            "----------------------------------------\n",
            "Epoch 22\n",
            "Var loss:  tensor(0.0253, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.126668799111607\n",
            "E_s_wdiff_all_sq: 0.10030777397094182\n",
            "E_IS_SCOPE: -0.000943635175918191\n",
            "E_IS_E_SCOPE: -0.0004005850491790053\n",
            "Total Loss: 0.025276665110270324\n",
            "----------------------------------------\n",
            "Epoch 23\n",
            "Var loss:  tensor(0.0192, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.13139493600642668\n",
            "E_s_wdiff_all_sq: 0.10515894480159621\n",
            "E_IS_SCOPE: -0.003945263932599188\n",
            "E_IS_E_SCOPE: -0.0004248768259623099\n",
            "Total Loss: 0.019196957214640223\n",
            "----------------------------------------\n",
            "Epoch 24\n",
            "Var loss:  tensor(0.0136, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.1379299554348809\n",
            "E_s_wdiff_all_sq: 0.11143891620869953\n",
            "E_IS_SCOPE: -0.006916364304567669\n",
            "E_IS_E_SCOPE: -0.00045249399147807444\n",
            "Total Loss: 0.013565038823085684\n",
            "----------------------------------------\n",
            "Epoch 25\n",
            "Var loss:  tensor(0.0084, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.14597668001615133\n",
            "E_s_wdiff_all_sq: 0.11886387561175396\n",
            "E_IS_SCOPE: -0.009856274380838592\n",
            "E_IS_E_SCOPE: -0.0004822836880910304\n",
            "Total Loss: 0.008366563241985758\n",
            "----------------------------------------\n",
            "Epoch 26\n",
            "Var loss:  tensor(0.0041, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.15358054614192215\n",
            "E_s_wdiff_all_sq: 0.125717536315975\n",
            "E_IS_SCOPE: -0.012374915096679763\n",
            "E_IS_E_SCOPE: -0.0005086943413604304\n",
            "Total Loss: 0.004132308538392027\n",
            "----------------------------------------\n",
            "Epoch 27\n",
            "Var loss:  tensor(0.0002, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.16143099548262407\n",
            "E_s_wdiff_all_sq: 0.1326090100998725\n",
            "E_IS_SCOPE: -0.014823890234859015\n",
            "E_IS_E_SCOPE: -0.0005328344458281994\n",
            "Total Loss: 0.00024161402777347907\n",
            "----------------------------------------\n",
            "Epoch 28\n",
            "Var loss:  tensor(-0.0034, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.1694125136991083\n",
            "E_s_wdiff_all_sq: 0.1394291335349657\n",
            "E_IS_SCOPE: -0.01723381436178511\n",
            "E_IS_E_SCOPE: -0.000553997699861639\n",
            "Total Loss: -0.003374512936620777\n",
            "----------------------------------------\n",
            "Epoch 29\n",
            "Var loss:  tensor(-0.0067, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.17711013004488232\n",
            "E_s_wdiff_all_sq: 0.1458013902721891\n",
            "E_IS_SCOPE: -0.019587914967916002\n",
            "E_IS_E_SCOPE: -0.0005713614267325842\n",
            "Total Loss: -0.006722627086590105\n",
            "----------------------------------------\n",
            "Epoch 30\n",
            "Var loss:  tensor(-0.0098, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.18325545928575016\n",
            "E_s_wdiff_all_sq: 0.15050414625242858\n",
            "E_IS_SCOPE: -0.02186975513810725\n",
            "E_IS_E_SCOPE: -0.0005818121135587527\n",
            "Total Loss: -0.009822832792691916\n",
            "----------------------------------------\n",
            "Epoch 31\n",
            "Var loss:  tensor(-0.0126, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.1892139620996492\n",
            "E_s_wdiff_all_sq: 0.15486075631431548\n",
            "E_IS_SCOPE: -0.02408661960128736\n",
            "E_IS_E_SCOPE: -0.000589439936546266\n",
            "Total Loss: -0.01263941332106494\n",
            "----------------------------------------\n",
            "Epoch 32\n",
            "Var loss:  tensor(-0.0152, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.19586623162085093\n",
            "E_s_wdiff_all_sq: 0.15973596244240165\n",
            "E_IS_SCOPE: -0.026253967346033233\n",
            "E_IS_E_SCOPE: -0.000597248838232207\n",
            "Total Loss: -0.015181427614069265\n",
            "----------------------------------------\n",
            "Epoch 33\n",
            "Var loss:  tensor(-0.0175, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.20368281268754737\n",
            "E_s_wdiff_all_sq: 0.1656536338743232\n",
            "E_IS_SCOPE: -0.028350493430282484\n",
            "E_IS_E_SCOPE: -0.000606956111519419\n",
            "Total Loss: -0.01745615560121841\n",
            "----------------------------------------\n",
            "Epoch 34\n",
            "Var loss:  tensor(-0.0195, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.21275644655061574\n",
            "E_s_wdiff_all_sq: 0.17272959500759721\n",
            "E_IS_SCOPE: -0.0303816297872041\n",
            "E_IS_E_SCOPE: -0.0006192401792428354\n",
            "Total Loss: -0.019496187449820485\n",
            "----------------------------------------\n",
            "Epoch 35\n",
            "Var loss:  tensor(-0.0213, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.22308620606309681\n",
            "E_s_wdiff_all_sq: 0.18094875194116475\n",
            "E_IS_SCOPE: -0.03235706585327706\n",
            "E_IS_E_SCOPE: -0.0006339364845910479\n",
            "Total Loss: -0.02130706439235644\n",
            "----------------------------------------\n",
            "Epoch 36\n",
            "Var loss:  tensor(-0.0229, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.2341459216741666\n",
            "E_s_wdiff_all_sq: 0.18985682471112014\n",
            "E_IS_SCOPE: -0.034254865325400584\n",
            "E_IS_E_SCOPE: -0.0006496750016770152\n",
            "Total Loss: -0.022919543461317138\n",
            "----------------------------------------\n",
            "Epoch 37\n",
            "Var loss:  tensor(-0.0243, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.24554922330562373\n",
            "E_s_wdiff_all_sq: 0.1990957883236354\n",
            "E_IS_SCOPE: -0.03606571018336117\n",
            "E_IS_E_SCOPE: -0.0006653259078910807\n",
            "Total Loss: -0.024345593345868333\n",
            "----------------------------------------\n",
            "Epoch 38\n",
            "Var loss:  tensor(-0.0256, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.2568324222800498\n",
            "E_s_wdiff_all_sq: 0.20825658865355343\n",
            "E_IS_SCOPE: -0.03777149996573501\n",
            "E_IS_E_SCOPE: -0.0006796812389834248\n",
            "Total Loss: -0.025606063603923285\n",
            "----------------------------------------\n",
            "Epoch 39\n",
            "Var loss:  tensor(-0.0267, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.2669653799259245\n",
            "E_s_wdiff_all_sq: 0.21649014365923788\n",
            "E_IS_SCOPE: -0.039276761761622835\n",
            "E_IS_E_SCOPE: -0.0006905743521181836\n",
            "Total Loss: -0.026695398329239145\n",
            "----------------------------------------\n",
            "Epoch 40\n",
            "Var loss:  tensor(-0.0277, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.27589101353594153\n",
            "E_s_wdiff_all_sq: 0.22366505475502427\n",
            "E_IS_SCOPE: -0.040636419622638684\n",
            "E_IS_E_SCOPE: -0.00069750995699775\n",
            "Total Loss: -0.02765012032728109\n",
            "----------------------------------------\n",
            "Epoch 41\n",
            "Var loss:  tensor(-0.0285, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.2837337472935916\n",
            "E_s_wdiff_all_sq: 0.22987133076727473\n",
            "E_IS_SCOPE: -0.041889138520031795\n",
            "E_IS_E_SCOPE: -0.0007010858049849194\n",
            "Total Loss: -0.0285119486806934\n",
            "----------------------------------------\n",
            "Epoch 42\n",
            "Var loss:  tensor(-0.0293, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.2908557770905269\n",
            "E_s_wdiff_all_sq: 0.23547513884002702\n",
            "E_IS_SCOPE: -0.04303609083998426\n",
            "E_IS_E_SCOPE: -0.000702564040778353\n",
            "Total Loss: -0.029284675124828408\n",
            "----------------------------------------\n",
            "Epoch 43\n",
            "Var loss:  tensor(-0.0300, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.2976827917461025\n",
            "E_s_wdiff_all_sq: 0.24092547953782234\n",
            "E_IS_SCOPE: -0.044073347368870204\n",
            "E_IS_E_SCOPE: -0.0007034911426258557\n",
            "Total Loss: -0.02998066002112501\n",
            "----------------------------------------\n",
            "Epoch 44\n",
            "Var loss:  tensor(-0.0306, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.30456514946718005\n",
            "E_s_wdiff_all_sq: 0.24656046453351352\n",
            "E_IS_SCOPE: -0.04501778090875776\n",
            "E_IS_E_SCOPE: -0.0007050237223773037\n",
            "Total Loss: -0.030619089216010836\n",
            "----------------------------------------\n",
            "Epoch 45\n",
            "Var loss:  tensor(-0.0312, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.311619790042617\n",
            "E_s_wdiff_all_sq: 0.252513024246906\n",
            "E_IS_SCOPE: -0.04587116238643289\n",
            "E_IS_E_SCOPE: -0.000707659199969989\n",
            "Total Loss: -0.031218500354131345\n",
            "----------------------------------------\n",
            "Epoch 46\n",
            "Var loss:  tensor(-0.0318, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.31887392526390274\n",
            "E_s_wdiff_all_sq: 0.2588187655813673\n",
            "E_IS_SCOPE: -0.04663158107314872\n",
            "E_IS_E_SCOPE: -0.0007115155886248017\n",
            "Total Loss: -0.031783231063428896\n",
            "----------------------------------------\n",
            "Epoch 47\n",
            "Var loss:  tensor(-0.0323, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.3260267696182977\n",
            "E_s_wdiff_all_sq: 0.26519574661217804\n",
            "E_IS_SCOPE: -0.047291021142441436\n",
            "E_IS_E_SCOPE: -0.0007159316358445562\n",
            "Total Loss: -0.03231741578399058\n",
            "----------------------------------------\n",
            "Epoch 48\n",
            "Var loss:  tensor(-0.0328, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.33248306578208997\n",
            "E_s_wdiff_all_sq: 0.2710586197065556\n",
            "E_IS_SCOPE: -0.04784640945678042\n",
            "E_IS_E_SCOPE: -0.0007193630224281665\n",
            "Total Loss: -0.03282790657008658\n",
            "----------------------------------------\n",
            "Epoch 49\n",
            "Var loss:  tensor(-0.0333, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.3380946483428657\n",
            "E_s_wdiff_all_sq: 0.27623819502894753\n",
            "E_IS_SCOPE: -0.04830423879616755\n",
            "E_IS_E_SCOPE: -0.0007210408748366484\n",
            "Total Loss: -0.03330820230566012\n",
            "----------------------------------------\n",
            "Epoch 50\n",
            "Var loss:  tensor(-0.0338, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.3424297771679321\n",
            "E_s_wdiff_all_sq: 0.2803166448230292\n",
            "E_IS_SCOPE: -0.04866569896366928\n",
            "E_IS_E_SCOPE: -0.000720260957477556\n",
            "Total Loss: -0.03377600344439702\n",
            "----------------------------------------\n",
            "Epoch 51\n",
            "Var loss:  tensor(-0.0342, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.34520726977424776\n",
            "E_s_wdiff_all_sq: 0.2830045800023712\n",
            "E_IS_SCOPE: -0.04893241156948035\n",
            "E_IS_E_SCOPE: -0.0007166343960899582\n",
            "Total Loss: -0.03422712435182071\n",
            "----------------------------------------\n",
            "Epoch 52\n",
            "Var loss:  tensor(-0.0347, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.34683283922455566\n",
            "E_s_wdiff_all_sq: 0.284693100217338\n",
            "E_IS_SCOPE: -0.04911669958075695\n",
            "E_IS_E_SCOPE: -0.0007113446131812775\n",
            "Total Loss: -0.034669230704850174\n",
            "----------------------------------------\n",
            "Epoch 53\n",
            "Var loss:  tensor(-0.0351, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.347583725763109\n",
            "E_s_wdiff_all_sq: 0.2856647226795241\n",
            "E_IS_SCOPE: -0.049216610561902865\n",
            "E_IS_E_SCOPE: -0.0007050384097959935\n",
            "Total Loss: -0.03510240099754536\n",
            "----------------------------------------\n",
            "Epoch 54\n",
            "Var loss:  tensor(-0.0355, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.34782900443141607\n",
            "E_s_wdiff_all_sq: 0.28626183618597884\n",
            "E_IS_SCOPE: -0.049246477361832686\n",
            "E_IS_E_SCOPE: -0.0006986130623810343\n",
            "Total Loss: -0.03552682013038255\n",
            "----------------------------------------\n",
            "Epoch 55\n",
            "Var loss:  tensor(-0.0359, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.3479930425326178\n",
            "E_s_wdiff_all_sq: 0.28687895973844946\n",
            "E_IS_SCOPE: -0.04922096623202872\n",
            "E_IS_E_SCOPE: -0.0006930875431255253\n",
            "Total Loss: -0.03593993436055454\n",
            "----------------------------------------\n",
            "Epoch 56\n",
            "Var loss:  tensor(-0.0363, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.34813086656728853\n",
            "E_s_wdiff_all_sq: 0.28756828258478506\n",
            "E_IS_SCOPE: -0.04914376415517303\n",
            "E_IS_E_SCOPE: -0.000688574007891474\n",
            "Total Loss: -0.03634605608897612\n",
            "----------------------------------------\n",
            "Epoch 57\n",
            "Var loss:  tensor(-0.0367, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.3481863708838085\n",
            "E_s_wdiff_all_sq: 0.2882578800063904\n",
            "E_IS_SCOPE: -0.04902158338613501\n",
            "E_IS_E_SCOPE: -0.0006850370329881531\n",
            "Total Loss: -0.036742861605792154\n",
            "----------------------------------------\n",
            "Epoch 58\n",
            "Var loss:  tensor(-0.0371, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.3480258792704211\n",
            "E_s_wdiff_all_sq: 0.2888028163717051\n",
            "E_IS_SCOPE: -0.048859185783118146\n",
            "E_IS_E_SCOPE: -0.0006821176204422299\n",
            "Total Loss: -0.03712933320355227\n",
            "----------------------------------------\n",
            "Epoch 59\n",
            "Var loss:  tensor(-0.0375, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.3476643444507948\n",
            "E_s_wdiff_all_sq: 0.28911979986150305\n",
            "E_IS_SCOPE: -0.04870155760355147\n",
            "E_IS_E_SCOPE: -0.0006792038107601791\n",
            "Total Loss: -0.03749842277320736\n",
            "----------------------------------------\n",
            "Epoch 60\n",
            "Var loss:  tensor(-0.0378, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.3490036621028839\n",
            "E_s_wdiff_all_sq: 0.2904974034669401\n",
            "E_IS_SCOPE: -0.04884347308096004\n",
            "E_IS_E_SCOPE: -0.0006785914906651237\n",
            "Total Loss: -0.037821764321562534\n",
            "----------------------------------------\n",
            "Epoch 61\n",
            "Var loss:  tensor(-0.0381, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.34944948969351125\n",
            "E_s_wdiff_all_sq: 0.2910747768205382\n",
            "E_IS_SCOPE: -0.048930785609162065\n",
            "E_IS_E_SCOPE: -0.0006765463478084757\n",
            "Total Loss: -0.03813202542665062\n",
            "----------------------------------------\n",
            "Epoch 62\n",
            "Var loss:  tensor(-0.0384, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.34896054428913387\n",
            "E_s_wdiff_all_sq: 0.2908043764389953\n",
            "E_IS_SCOPE: -0.04896626507305907\n",
            "E_IS_E_SCOPE: -0.0006729378899865745\n",
            "Total Loss: -0.03842874629292292\n",
            "----------------------------------------\n",
            "Epoch 63\n",
            "Var loss:  tensor(-0.0387, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.34781952541138733\n",
            "E_s_wdiff_all_sq: 0.2899506897557346\n",
            "E_IS_SCOPE: -0.04896105396276515\n",
            "E_IS_E_SCOPE: -0.0006683218315560762\n",
            "Total Loss: -0.03871488838368192\n",
            "----------------------------------------\n",
            "Epoch 64\n",
            "Var loss:  tensor(-0.0390, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.3466547356457596\n",
            "E_s_wdiff_all_sq: 0.2890435523425003\n",
            "E_IS_SCOPE: -0.04896472688113583\n",
            "E_IS_E_SCOPE: -0.0006637611461351916\n",
            "Total Loss: -0.03898900794365845\n",
            "----------------------------------------\n",
            "Epoch 65\n",
            "Var loss:  tensor(-0.0393, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.34524988558533376\n",
            "E_s_wdiff_all_sq: 0.28797567262880036\n",
            "E_IS_SCOPE: -0.04892402895960043\n",
            "E_IS_E_SCOPE: -0.0006593488040720411\n",
            "Total Loss: -0.03925340713143985\n",
            "----------------------------------------\n",
            "Epoch 66\n",
            "Var loss:  tensor(-0.0395, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.34372980940069464\n",
            "E_s_wdiff_all_sq: 0.2868629226289999\n",
            "E_IS_SCOPE: -0.04884375241028747\n",
            "E_IS_E_SCOPE: -0.0006554201599426038\n",
            "Total Loss: -0.03950803750591145\n",
            "----------------------------------------\n",
            "Epoch 67\n",
            "Var loss:  tensor(-0.0398, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.3421448948055981\n",
            "E_s_wdiff_all_sq: 0.28574242836070435\n",
            "E_IS_SCOPE: -0.048730595901777654\n",
            "E_IS_E_SCOPE: -0.0006520257240158311\n",
            "Total Loss: -0.039752933687546343\n",
            "----------------------------------------\n",
            "Epoch 68\n",
            "Var loss:  tensor(-0.0400, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 6.232169163204178e-06\n",
            "E_IS_all_sq: 4.491946079694819e-06\n",
            "E_s_wdiff_sq: 0.3404290228321736\n",
            "E_s_wdiff_all_sq: 0.28453625557789614\n",
            "E_IS_SCOPE: -0.048589479250159405\n",
            "E_IS_E_SCOPE: -0.0006488638883779791\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-68f71a59e6a2>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# single cumprod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# 200 trajectories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel_200_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_var_play\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded_state_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates_first_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates_last_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-61-e9ba067cff32>\u001b[0m in \u001b[0;36mtrain_var_play\u001b[0;34m(model, num_epochs, learning_rate, padded_state_tensors, states_first_tensor, states_last_tensor, test1)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# Retain the graph to avoid clearing it before backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mtot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 400 Trajectories"
      ],
      "metadata": {
        "id": "yPC_HXwnofdg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "400 Trajectories:"
      ],
      "metadata": {
        "id": "Scyb9IqfnsrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b = action_probs_top_n_epsilon(q_table, 1, 0.4)\n",
        "pi_b = experiment_actions(400, env, P_pi_b)\n",
        "P_pi_e = action_probs_top_n_epsilon(q_table, 2, 0.05)\n",
        "pi_e = experiment_actions(400, env, P_pi_e)"
      ],
      "metadata": {
        "id": "doNhEhzfn1gg"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_400 = CustomizableFeatureNet(input_dim=2, hidden_dims=[16, 32], output_dim=1, dtype = torch.float64)"
      ],
      "metadata": {
        "id": "xdkFnhHDn1gz"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing_400 = SCOPE_variance_play(model_400, 0.9, 10000, pi_b, P_pi_b, P_pi_e, dtype = torch.float64)"
      ],
      "metadata": {
        "id": "hGLJ8iDxn1g0"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IS_tensor, padded_state_tensors, padded_weight_diff_tensors, gamma_weights_last_tensor, states_first_tensor, states_last_tensor, weight_first_tensor = testing_400.prepare()"
      ],
      "metadata": {
        "id": "yMk8bwNKn1g0"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_400 = train_var_play(model_400, 800, 0.0007, padded_state_tensors, states_first_tensor, states_last_tensor, testing_400)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCPsi8VmoFGu",
        "outputId": "6462a410-c38e-4c68-f343-3e8dc651c28c"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "E_s_wdiff_sq: 3.818623501816317e-06\n",
            "E_s_wdiff_all_sq: 5.1504677041227486e-08\n",
            "E_IS_SCOPE: -1.5581479430685247e-06\n",
            "E_IS_E_SCOPE: 4.658730291707227e-08\n",
            "Total Loss: 1.9661124687824543e-06\n",
            "----------------------------------------\n",
            "Epoch 318\n",
            "Var loss:  tensor(1.9614e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.820825995560044e-06\n",
            "E_s_wdiff_all_sq: 5.349843717599916e-08\n",
            "E_IS_SCOPE: -1.5618117588208178e-06\n",
            "E_IS_E_SCOPE: 4.537144321640203e-08\n",
            "Total Loss: 1.9614252902881636e-06\n",
            "----------------------------------------\n",
            "Epoch 319\n",
            "Var loss:  tensor(1.9567e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.817179748592323e-06\n",
            "E_s_wdiff_all_sq: 5.362001030560776e-08\n",
            "E_IS_SCOPE: -1.5574684865952953e-06\n",
            "E_IS_E_SCOPE: 5.019030585161591e-08\n",
            "Total Loss: 1.9567062893714516e-06\n",
            "----------------------------------------\n",
            "Epoch 320\n",
            "Var loss:  tensor(1.9520e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.8102695496245794e-06\n",
            "E_s_wdiff_all_sq: 5.351965390706791e-08\n",
            "E_IS_SCOPE: -1.5496881090180883e-06\n",
            "E_IS_E_SCOPE: 5.692225929859327e-08\n",
            "Total Loss: 1.951993295062707e-06\n",
            "----------------------------------------\n",
            "Epoch 321\n",
            "Var loss:  tensor(1.9473e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.8042120855996862e-06\n",
            "E_s_wdiff_all_sq: 5.426719255537616e-08\n",
            "E_IS_SCOPE: -1.5483929261767892e-06\n",
            "E_IS_E_SCOPE: 5.716407988774271e-08\n",
            "Total Loss: 1.9472950168938054e-06\n",
            "----------------------------------------\n",
            "Epoch 322\n",
            "Var loss:  tensor(1.9426e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.804982542069374e-06\n",
            "E_s_wdiff_all_sq: 5.652200043327136e-08\n",
            "E_IS_SCOPE: -1.5548999760581681e-06\n",
            "E_IS_E_SCOPE: 5.227641349899561e-08\n",
            "Total Loss: 1.942571898500334e-06\n",
            "----------------------------------------\n",
            "Epoch 323\n",
            "Var loss:  tensor(1.9378e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.8055618655664216e-06\n",
            "E_s_wdiff_all_sq: 5.757077220552158e-08\n",
            "E_IS_SCOPE: -1.5552189103616716e-06\n",
            "E_IS_E_SCOPE: 5.4087554592914954e-08\n",
            "Total Loss: 1.9378422994302857e-06\n",
            "----------------------------------------\n",
            "Epoch 324\n",
            "Var loss:  tensor(1.9331e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.798510727209711e-06\n",
            "E_s_wdiff_all_sq: 5.552828002125418e-08\n",
            "E_IS_SCOPE: -1.5405495333573405e-06\n",
            "E_IS_E_SCOPE: 6.862668615973915e-08\n",
            "Total Loss: 1.9330941441328564e-06\n",
            "----------------------------------------\n",
            "Epoch 325\n",
            "Var loss:  tensor(1.9283e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.790270148934778e-06\n",
            "E_s_wdiff_all_sq: 5.453871222568934e-08\n",
            "E_IS_SCOPE: -1.526064641576727e-06\n",
            "E_IS_E_SCOPE: 8.187589334726548e-08\n",
            "Total Loss: 1.9283145028396626e-06\n",
            "----------------------------------------\n",
            "Epoch 326\n",
            "Var loss:  tensor(1.9235e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7904909764953464e-06\n",
            "E_s_wdiff_all_sq: 5.804889935451536e-08\n",
            "E_IS_SCOPE: -1.525884690446034e-06\n",
            "E_IS_E_SCOPE: 8.282463292799453e-08\n",
            "Total Loss: 1.9234875663713328e-06\n",
            "----------------------------------------\n",
            "Epoch 327\n",
            "Var loss:  tensor(1.9187e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7955571837747704e-06\n",
            "E_s_wdiff_all_sq: 6.22212492840062e-08\n",
            "E_IS_SCOPE: -1.5302552007573844e-06\n",
            "E_IS_E_SCOPE: 8.130789834674959e-08\n",
            "Total Loss: 1.9186738722610547e-06\n",
            "----------------------------------------\n",
            "Epoch 328\n",
            "Var loss:  tensor(1.9138e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7961569280716486e-06\n",
            "E_s_wdiff_all_sq: 6.32911379046613e-08\n",
            "E_IS_SCOPE: -1.520454075290415e-06\n",
            "E_IS_E_SCOPE: 9.331385745585897e-08\n",
            "Total Loss: 1.9137940606529974e-06\n",
            "----------------------------------------\n",
            "Epoch 329\n",
            "Var loss:  tensor(1.9090e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.786826922531497e-06\n",
            "E_s_wdiff_all_sq: 6.279261447199095e-08\n",
            "E_IS_SCOPE: -1.5020486290623589e-06\n",
            "E_IS_E_SCOPE: 1.0972541021573765e-07\n",
            "Total Loss: 1.9089503654818712e-06\n",
            "----------------------------------------\n",
            "Epoch 330\n",
            "Var loss:  tensor(1.9041e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7803770914590023e-06\n",
            "E_s_wdiff_all_sq: 6.524564717558048e-08\n",
            "E_IS_SCOPE: -1.4966451475433453e-06\n",
            "E_IS_E_SCOPE: 1.1311330835956638e-07\n",
            "Total Loss: 1.9040786684561571e-06\n",
            "----------------------------------------\n",
            "Epoch 331\n",
            "Var loss:  tensor(1.8992e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7854346408474362e-06\n",
            "E_s_wdiff_all_sq: 7.059717420984574e-08\n",
            "E_IS_SCOPE: -1.509038371437111e-06\n",
            "E_IS_E_SCOPE: 1.0300913241957995e-07\n",
            "Total Loss: 1.899206594902767e-06\n",
            "----------------------------------------\n",
            "Epoch 332\n",
            "Var loss:  tensor(1.8943e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.790529699127186e-06\n",
            "E_s_wdiff_all_sq: 7.327126745700238e-08\n",
            "E_IS_SCOPE: -1.5142739244543384e-06\n",
            "E_IS_E_SCOPE: 1.0144351016462772e-07\n",
            "Total Loss: 1.8942876984108102e-06\n",
            "----------------------------------------\n",
            "Epoch 333\n",
            "Var loss:  tensor(1.8894e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.784337306223748e-06\n",
            "E_s_wdiff_all_sq: 7.185574116858227e-08\n",
            "E_IS_SCOPE: -1.5034674115412997e-06\n",
            "E_IS_E_SCOPE: 1.1231163642986695e-07\n",
            "Total Loss: 1.8893876050913911e-06\n",
            "----------------------------------------\n",
            "Epoch 334\n",
            "Var loss:  tensor(1.8845e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.775160057954662e-06\n",
            "E_s_wdiff_all_sq: 7.111456637286677e-08\n",
            "E_IS_SCOPE: -1.491516488524886e-06\n",
            "E_IS_E_SCOPE: 1.2250551507475027e-07\n",
            "Total Loss: 1.8844656203610816e-06\n",
            "----------------------------------------\n",
            "Epoch 335\n",
            "Var loss:  tensor(1.8796e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7721808310783007e-06\n",
            "E_s_wdiff_all_sq: 7.287105642659794e-08\n",
            "E_IS_SCOPE: -1.4879690464282344e-06\n",
            "E_IS_E_SCOPE: 1.2613027706393712e-07\n",
            "Total Loss: 1.8795752636459187e-06\n",
            "----------------------------------------\n",
            "Epoch 336\n",
            "Var loss:  tensor(1.8747e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.77234942339239e-06\n",
            "E_s_wdiff_all_sq: 7.42446496567738e-08\n",
            "E_IS_SCOPE: -1.4875964440226083e-06\n",
            "E_IS_E_SCOPE: 1.2834126577762234e-07\n",
            "Total Loss: 1.8746934901137132e-06\n",
            "----------------------------------------\n",
            "Epoch 337\n",
            "Var loss:  tensor(1.8698e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.770752326655044e-06\n",
            "E_s_wdiff_all_sq: 7.506216453541281e-08\n",
            "E_IS_SCOPE: -1.4864272481605577e-06\n",
            "E_IS_E_SCOPE: 1.307279170841289e-07\n",
            "Total Loss: 1.8698439676088166e-06\n",
            "----------------------------------------\n",
            "Epoch 338\n",
            "Var loss:  tensor(1.8650e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.767129891637057e-06\n",
            "E_s_wdiff_all_sq: 7.709446967845876e-08\n",
            "E_IS_SCOPE: -1.4842984384256124e-06\n",
            "E_IS_E_SCOPE: 1.324603360923526e-07\n",
            "Total Loss: 1.8649820089012273e-06\n",
            "----------------------------------------\n",
            "Epoch 339\n",
            "Var loss:  tensor(1.8601e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.765181548532679e-06\n",
            "E_s_wdiff_all_sq: 8.095025465855577e-08\n",
            "E_IS_SCOPE: -1.4844289737992038e-06\n",
            "E_IS_E_SCOPE: 1.3185627707224403e-07\n",
            "Total Loss: 1.860124928109786e-06\n",
            "----------------------------------------\n",
            "Epoch 340\n",
            "Var loss:  tensor(1.8553e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7658642025493426e-06\n",
            "E_s_wdiff_all_sq: 8.40229706435564e-08\n",
            "E_IS_SCOPE: -1.4798727318029115e-06\n",
            "E_IS_E_SCOPE: 1.3765119477300723e-07\n",
            "Total Loss: 1.8552575147325072e-06\n",
            "----------------------------------------\n",
            "Epoch 341\n",
            "Var loss:  tensor(1.8504e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7660326784611444e-06\n",
            "E_s_wdiff_all_sq: 8.497646873087636e-08\n",
            "E_IS_SCOPE: -1.468849553543189e-06\n",
            "E_IS_E_SCOPE: 1.5071685731312529e-07\n",
            "Total Loss: 1.8503875239961976e-06\n",
            "----------------------------------------\n",
            "Epoch 342\n",
            "Var loss:  tensor(1.8455e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7619343606472476e-06\n",
            "E_s_wdiff_all_sq: 8.544964234426646e-08\n",
            "E_IS_SCOPE: -1.4579249354077354e-06\n",
            "E_IS_E_SCOPE: 1.6178454674744187e-07\n",
            "Total Loss: 1.8455298899711852e-06\n",
            "----------------------------------------\n",
            "Epoch 343\n",
            "Var loss:  tensor(1.8406e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7600946228670487e-06\n",
            "E_s_wdiff_all_sq: 8.809450522234825e-08\n",
            "E_IS_SCOPE: -1.451416259351488e-06\n",
            "E_IS_E_SCOPE: 1.6849118292055114e-07\n",
            "Total Loss: 1.8406493690791807e-06\n",
            "----------------------------------------\n",
            "Epoch 344\n",
            "Var loss:  tensor(1.8359e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.757682342016531e-06\n",
            "E_s_wdiff_all_sq: 9.00458463095084e-08\n",
            "E_IS_SCOPE: -1.447039587416338e-06\n",
            "E_IS_E_SCOPE: 1.7306437678869136e-07\n",
            "Total Loss: 1.8358927032755224e-06\n",
            "----------------------------------------\n",
            "Epoch 345\n",
            "Var loss:  tensor(1.8312e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.75551507572102e-06\n",
            "E_s_wdiff_all_sq: 9.182863367047385e-08\n",
            "E_IS_SCOPE: -1.4435375108617628e-06\n",
            "E_IS_E_SCOPE: 1.7695480182390263e-07\n",
            "Total Loss: 1.8311659526577743e-06\n",
            "----------------------------------------\n",
            "Epoch 346\n",
            "Var loss:  tensor(1.8265e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7544158042732373e-06\n",
            "E_s_wdiff_all_sq: 9.472205138403982e-08\n",
            "E_IS_SCOPE: -1.4428416693245636e-06\n",
            "E_IS_E_SCOPE: 1.780022642462238e-07\n",
            "Total Loss: 1.826470021726181e-06\n",
            "----------------------------------------\n",
            "Epoch 347\n",
            "Var loss:  tensor(1.8218e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7575855619220727e-06\n",
            "E_s_wdiff_all_sq: 1.0064280470814462e-07\n",
            "E_IS_SCOPE: -1.4439179643524032e-06\n",
            "E_IS_E_SCOPE: 1.7790018014021756e-07\n",
            "Total Loss: 1.8217706042072454e-06\n",
            "----------------------------------------\n",
            "Epoch 348\n",
            "Var loss:  tensor(1.8171e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7575885667816687e-06\n",
            "E_s_wdiff_all_sq: 1.0474023214216893e-07\n",
            "E_IS_SCOPE: -1.4374300987860145e-06\n",
            "E_IS_E_SCOPE: 1.846938871137807e-07\n",
            "Total Loss: 1.8170644988184686e-06\n",
            "----------------------------------------\n",
            "Epoch 349\n",
            "Var loss:  tensor(1.8124e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7551798133805533e-06\n",
            "E_s_wdiff_all_sq: 1.0675741232987876e-07\n",
            "E_IS_SCOPE: -1.4272305366414886e-06\n",
            "E_IS_E_SCOPE: 1.9500581185486548e-07\n",
            "Total Loss: 1.8124138400365254e-06\n",
            "----------------------------------------\n",
            "Epoch 350\n",
            "Var loss:  tensor(1.8077e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7576141519037626e-06\n",
            "E_s_wdiff_all_sq: 1.1116752776569916e-07\n",
            "E_IS_SCOPE: -1.424151582533098e-06\n",
            "E_IS_E_SCOPE: 1.994640913343094e-07\n",
            "Total Loss: 1.8076794123818077e-06\n",
            "----------------------------------------\n",
            "Epoch 351\n",
            "Var loss:  tensor(1.8030e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7584396618938392e-06\n",
            "E_s_wdiff_all_sq: 1.1533044203138325e-07\n",
            "E_IS_SCOPE: -1.4223715772081997e-06\n",
            "E_IS_E_SCOPE: 2.0191730685428918e-07\n",
            "Total Loss: 1.8029955877160362e-06\n",
            "----------------------------------------\n",
            "Epoch 352\n",
            "Var loss:  tensor(1.7982e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7567478209384725e-06\n",
            "E_s_wdiff_all_sq: 1.1827526883093285e-07\n",
            "E_IS_SCOPE: -1.4217130358130593e-06\n",
            "E_IS_E_SCOPE: 2.026406721772029e-07\n",
            "Total Loss: 1.7982292721055736e-06\n",
            "----------------------------------------\n",
            "Epoch 353\n",
            "Var loss:  tensor(1.7935e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7556132728851553e-06\n",
            "E_s_wdiff_all_sq: 1.199461052158855e-07\n",
            "E_IS_SCOPE: -1.424675153612149e-06\n",
            "E_IS_E_SCOPE: 2.0065871131143753e-07\n",
            "Total Loss: 1.7934635738006547e-06\n",
            "----------------------------------------\n",
            "Epoch 354\n",
            "Var loss:  tensor(1.7887e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7584566417691074e-06\n",
            "E_s_wdiff_all_sq: 1.232436856877907e-07\n",
            "E_IS_SCOPE: -1.4321889419080717e-06\n",
            "E_IS_E_SCOPE: 1.953038850081046e-07\n",
            "Total Loss: 1.7886914382275232e-06\n",
            "----------------------------------------\n",
            "Epoch 355\n",
            "Var loss:  tensor(1.7839e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.751909393234119e-06\n",
            "E_s_wdiff_all_sq: 1.2300531513482188e-07\n",
            "E_IS_SCOPE: -1.4301044991237712e-06\n",
            "E_IS_E_SCOPE: 1.9661735392965532e-07\n",
            "Total Loss: 1.783924507971003e-06\n",
            "----------------------------------------\n",
            "Epoch 356\n",
            "Var loss:  tensor(1.7792e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7426702296057616e-06\n",
            "E_s_wdiff_all_sq: 1.2102976332236097e-07\n",
            "E_IS_SCOPE: -1.4225149171005258e-06\n",
            "E_IS_E_SCOPE: 2.0295571758882008e-07\n",
            "Total Loss: 1.7791633328832678e-06\n",
            "----------------------------------------\n",
            "Epoch 357\n",
            "Var loss:  tensor(1.7744e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.740613562403396e-06\n",
            "E_s_wdiff_all_sq: 1.2129520375643128e-07\n",
            "E_IS_SCOPE: -1.421493970805026e-06\n",
            "E_IS_E_SCOPE: 2.0520371671411655e-07\n",
            "Total Loss: 1.7743871195872385e-06\n",
            "----------------------------------------\n",
            "Epoch 358\n",
            "Var loss:  tensor(1.7696e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7454435670910924e-06\n",
            "E_s_wdiff_all_sq: 1.2530839961673778e-07\n",
            "E_IS_SCOPE: -1.4276185079663123e-06\n",
            "E_IS_E_SCOPE: 2.0187165068873773e-07\n",
            "Total Loss: 1.7696189861428132e-06\n",
            "----------------------------------------\n",
            "Epoch 359\n",
            "Var loss:  tensor(1.7648e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7459221415122328e-06\n",
            "E_s_wdiff_all_sq: 1.291212062427238e-07\n",
            "E_IS_SCOPE: -1.4272799753946659e-06\n",
            "E_IS_E_SCOPE: 2.0293544445274298e-07\n",
            "Total Loss: 1.7648342315532504e-06\n",
            "----------------------------------------\n",
            "Epoch 360\n",
            "Var loss:  tensor(1.7600e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7399299154704283e-06\n",
            "E_s_wdiff_all_sq: 1.3072748312426112e-07\n",
            "E_IS_SCOPE: -1.4184960631559778e-06\n",
            "E_IS_E_SCOPE: 2.1031858057901672e-07\n",
            "Total Loss: 1.760037280854737e-06\n",
            "----------------------------------------\n",
            "Epoch 361\n",
            "Var loss:  tensor(1.7552e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7406837829684978e-06\n",
            "E_s_wdiff_all_sq: 1.3506336664358868e-07\n",
            "E_IS_SCOPE: -1.4137671276307386e-06\n",
            "E_IS_E_SCOPE: 2.1565822352646195e-07\n",
            "Total Loss: 1.755233849989067e-06\n",
            "----------------------------------------\n",
            "Epoch 362\n",
            "Var loss:  tensor(1.7504e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.743654280630289e-06\n",
            "E_s_wdiff_all_sq: 1.3996351476917186e-07\n",
            "E_IS_SCOPE: -1.412867440924263e-06\n",
            "E_IS_E_SCOPE: 2.1798604547829635e-07\n",
            "Total Loss: 1.7504479290345572e-06\n",
            "----------------------------------------\n",
            "Epoch 363\n",
            "Var loss:  tensor(1.7456e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7452597737330147e-06\n",
            "E_s_wdiff_all_sq: 1.4489302309243449e-07\n",
            "E_IS_SCOPE: -1.411155266132268e-06\n",
            "E_IS_E_SCOPE: 2.2043579042434372e-07\n",
            "Total Loss: 1.7456487735059155e-06\n",
            "----------------------------------------\n",
            "Epoch 364\n",
            "Var loss:  tensor(1.7408e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.742935734773599e-06\n",
            "E_s_wdiff_all_sq: 1.4824170450959423e-07\n",
            "E_IS_SCOPE: -1.4071952729822862e-06\n",
            "E_IS_E_SCOPE: 2.2396555480479237e-07\n",
            "Total Loss: 1.7408365106684064e-06\n",
            "----------------------------------------\n",
            "Epoch 365\n",
            "Var loss:  tensor(1.7360e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.742488938219067e-06\n",
            "E_s_wdiff_all_sq: 1.5197996303608735e-07\n",
            "E_IS_SCOPE: -1.4070947990651948e-06\n",
            "E_IS_E_SCOPE: 2.2437819815570512e-07\n",
            "Total Loss: 1.736027116719738e-06\n",
            "----------------------------------------\n",
            "Epoch 366\n",
            "Var loss:  tensor(1.7312e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7472165992098974e-06\n",
            "E_s_wdiff_all_sq: 1.5714471267095792e-07\n",
            "E_IS_SCOPE: -1.4139285904421034e-06\n",
            "E_IS_E_SCOPE: 2.1973647611496104e-07\n",
            "Total Loss: 1.731205889403369e-06\n",
            "----------------------------------------\n",
            "Epoch 367\n",
            "Var loss:  tensor(1.7264e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7478797292148425e-06\n",
            "E_s_wdiff_all_sq: 1.603551335452879e-07\n",
            "E_IS_SCOPE: -1.416830747439832e-06\n",
            "E_IS_E_SCOPE: 2.1795558749652212e-07\n",
            "Total Loss: 1.7264160617754051e-06\n",
            "----------------------------------------\n",
            "Epoch 368\n",
            "Var loss:  tensor(1.7216e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.747125464557556e-06\n",
            "E_s_wdiff_all_sq: 1.6376491046864126e-07\n",
            "E_IS_SCOPE: -1.4171718278892545e-06\n",
            "E_IS_E_SCOPE: 2.1794605881402009e-07\n",
            "Total Loss: 1.7215889166609243e-06\n",
            "----------------------------------------\n",
            "Epoch 369\n",
            "Var loss:  tensor(1.7168e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.743677530338166e-06\n",
            "E_s_wdiff_all_sq: 1.6536708407784184e-07\n",
            "E_IS_SCOPE: -1.4133458031491908e-06\n",
            "E_IS_E_SCOPE: 2.2163739987140744e-07\n",
            "Total Loss: 1.7168081761976867e-06\n",
            "----------------------------------------\n",
            "Epoch 370\n",
            "Var loss:  tensor(1.7120e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.743135663728983e-06\n",
            "E_s_wdiff_all_sq: 1.6805534344425272e-07\n",
            "E_IS_SCOPE: -1.4103977949929978e-06\n",
            "E_IS_E_SCOPE: 2.25376434877616e-07\n",
            "Total Loss: 1.7119959965220617e-06\n",
            "----------------------------------------\n",
            "Epoch 371\n",
            "Var loss:  tensor(1.7072e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7464769811575023e-06\n",
            "E_s_wdiff_all_sq: 1.7297790838333208e-07\n",
            "E_IS_SCOPE: -1.411372401843724e-06\n",
            "E_IS_E_SCOPE: 2.2602025910766937e-07\n",
            "Total Loss: 1.7071778868499418e-06\n",
            "----------------------------------------\n",
            "Epoch 372\n",
            "Var loss:  tensor(1.7023e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.742690478060719e-06\n",
            "E_s_wdiff_all_sq: 1.7469352512173506e-07\n",
            "E_IS_SCOPE: -1.402651821751086e-06\n",
            "E_IS_E_SCOPE: 2.344387526909342e-07\n",
            "Total Loss: 1.702279940033502e-06\n",
            "----------------------------------------\n",
            "Epoch 373\n",
            "Var loss:  tensor(1.6974e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.740070497218484e-06\n",
            "E_s_wdiff_all_sq: 1.7689496259153805e-07\n",
            "E_IS_SCOPE: -1.3948534541085544e-06\n",
            "E_IS_E_SCOPE: 2.4225427373524025e-07\n",
            "Total Loss: 1.6974242149179154e-06\n",
            "----------------------------------------\n",
            "Epoch 374\n",
            "Var loss:  tensor(1.6925e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7459210321486768e-06\n",
            "E_s_wdiff_all_sq: 1.8417374814302758e-07\n",
            "E_IS_SCOPE: -1.396955224597356e-06\n",
            "E_IS_E_SCOPE: 2.4190074952931134e-07\n",
            "Total Loss: 1.692499471730873e-06\n",
            "----------------------------------------\n",
            "Epoch 375\n",
            "Var loss:  tensor(1.6877e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7502183338530655e-06\n",
            "E_s_wdiff_all_sq: 1.9073759554846822e-07\n",
            "E_IS_SCOPE: -1.3996379264033374e-06\n",
            "E_IS_E_SCOPE: 2.4050724203488344e-07\n",
            "Total Loss: 1.6876545374067142e-06\n",
            "----------------------------------------\n",
            "Epoch 376\n",
            "Var loss:  tensor(1.6828e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7463995776071264e-06\n",
            "E_s_wdiff_all_sq: 1.9217561524712215e-07\n",
            "E_IS_SCOPE: -1.3918575403442332e-06\n",
            "E_IS_E_SCOPE: 2.480801264846274e-07\n",
            "Total Loss: 1.6828127646808418e-06\n",
            "----------------------------------------\n",
            "Epoch 377\n",
            "Var loss:  tensor(1.6780e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.739305576892997e-06\n",
            "E_s_wdiff_all_sq: 1.9146786191367652e-07\n",
            "E_IS_SCOPE: -1.380567570855371e-06\n",
            "E_IS_E_SCOPE: 2.585787639672729e-07\n",
            "Total Loss: 1.6780091813125916e-06\n",
            "----------------------------------------\n",
            "Epoch 378\n",
            "Var loss:  tensor(1.6732e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7410151775673873e-06\n",
            "E_s_wdiff_all_sq: 1.9549242251886063e-07\n",
            "E_IS_SCOPE: -1.3779588562947253e-06\n",
            "E_IS_E_SCOPE: 2.624393516898577e-07\n",
            "Total Loss: 1.6731904750579195e-06\n",
            "----------------------------------------\n",
            "Epoch 379\n",
            "Var loss:  tensor(1.6684e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7455530745300376e-06\n",
            "E_s_wdiff_all_sq: 2.01158412097493e-07\n",
            "E_IS_SCOPE: -1.38334563855428e-06\n",
            "E_IS_E_SCOPE: 2.588716606512735e-07\n",
            "Total Loss: 1.668424199999996e-06\n",
            "----------------------------------------\n",
            "Epoch 380\n",
            "Var loss:  tensor(1.6636e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7501052772351773e-06\n",
            "E_s_wdiff_all_sq: 2.0742591861500623e-07\n",
            "E_IS_SCOPE: -1.3860683019681373e-06\n",
            "E_IS_E_SCOPE: 2.5770096230991907e-07\n",
            "Total Loss: 1.6636049660426175e-06\n",
            "----------------------------------------\n",
            "Epoch 381\n",
            "Var loss:  tensor(1.6588e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.751099399516157e-06\n",
            "E_s_wdiff_all_sq: 2.1262164529500984e-07\n",
            "E_IS_SCOPE: -1.3792124210670561e-06\n",
            "E_IS_E_SCOPE: 2.648487392210459e-07\n",
            "Total Loss: 1.6588195696235012e-06\n",
            "----------------------------------------\n",
            "Epoch 382\n",
            "Var loss:  tensor(1.6541e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7472180455995486e-06\n",
            "E_s_wdiff_all_sq: 2.1505658122803808e-07\n",
            "E_IS_SCOPE: -1.3668088352684067e-06\n",
            "E_IS_E_SCOPE: 2.7647569318881015e-07\n",
            "Total Loss: 1.6540565434356356e-06\n",
            "----------------------------------------\n",
            "Epoch 383\n",
            "Var loss:  tensor(1.6493e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7460206580818403e-06\n",
            "E_s_wdiff_all_sq: 2.1772452818406725e-07\n",
            "E_IS_SCOPE: -1.3593780695239962e-06\n",
            "E_IS_E_SCOPE: 2.8434016107163497e-07\n",
            "Total Loss: 1.6493238046850694e-06\n",
            "----------------------------------------\n",
            "Epoch 384\n",
            "Var loss:  tensor(1.6445e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.749322940113768e-06\n",
            "E_s_wdiff_all_sq: 2.213497710932818e-07\n",
            "E_IS_SCOPE: -1.359077015244714e-06\n",
            "E_IS_E_SCOPE: 2.868813943877622e-07\n",
            "Total Loss: 1.6445204857340927e-06\n",
            "----------------------------------------\n",
            "Epoch 385\n",
            "Var loss:  tensor(1.6397e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.751085476935327e-06\n",
            "E_s_wdiff_all_sq: 2.2440283954132547e-07\n",
            "E_IS_SCOPE: -1.3589898115617542e-06\n",
            "E_IS_E_SCOPE: 2.8871694145279737e-07\n",
            "Total Loss: 1.6397332673434577e-06\n",
            "----------------------------------------\n",
            "Epoch 386\n",
            "Var loss:  tensor(1.6350e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7488744400602235e-06\n",
            "E_s_wdiff_all_sq: 2.2706389181355593e-07\n",
            "E_IS_SCOPE: -1.3567963216485892e-06\n",
            "E_IS_E_SCOPE: 2.9086140833976304e-07\n",
            "Total Loss: 1.6349592242485213e-06\n",
            "----------------------------------------\n",
            "Epoch 387\n",
            "Var loss:  tensor(1.6302e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7453884821816675e-06\n",
            "E_s_wdiff_all_sq: 2.2967286991824668e-07\n",
            "E_IS_SCOPE: -1.354037450894136e-06\n",
            "E_IS_E_SCOPE: 2.9293482473688615e-07\n",
            "Total Loss: 1.6302351969799352e-06\n",
            "----------------------------------------\n",
            "Epoch 388\n",
            "Var loss:  tensor(1.6255e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.745579093843386e-06\n",
            "E_s_wdiff_all_sq: 2.3228658053430124e-07\n",
            "E_IS_SCOPE: -1.365751038023357e-06\n",
            "E_IS_E_SCOPE: 2.8238184335064324e-07\n",
            "Total Loss: 1.6254908865396433e-06\n",
            "----------------------------------------\n",
            "Epoch 389\n",
            "Var loss:  tensor(1.6208e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7466368694702266e-06\n",
            "E_s_wdiff_all_sq: 2.2705108223306518e-07\n",
            "E_IS_SCOPE: -1.3673089839566357e-06\n",
            "E_IS_E_SCOPE: 2.863336112846768e-07\n",
            "Total Loss: 1.6207647327330956e-06\n",
            "----------------------------------------\n",
            "Epoch 390\n",
            "Var loss:  tensor(1.6161e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7375278461262e-06\n",
            "E_s_wdiff_all_sq: 2.2098184848318766e-07\n",
            "E_IS_SCOPE: -1.3642222554430255e-06\n",
            "E_IS_E_SCOPE: 2.90256742464175e-07\n",
            "Total Loss: 1.61605213780717e-06\n",
            "----------------------------------------\n",
            "Epoch 391\n",
            "Var loss:  tensor(1.6113e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.720502086214623e-06\n",
            "E_s_wdiff_all_sq: 2.1725404238589962e-07\n",
            "E_IS_SCOPE: -1.353322662874933e-06\n",
            "E_IS_E_SCOPE: 2.9686151329541016e-07\n",
            "Total Loss: 1.6113438274665955e-06\n",
            "----------------------------------------\n",
            "Epoch 392\n",
            "Var loss:  tensor(1.6065e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.712703118201409e-06\n",
            "E_s_wdiff_all_sq: 2.149431397466573e-07\n",
            "E_IS_SCOPE: -1.3382770086223922e-06\n",
            "E_IS_E_SCOPE: 3.1156094268531476e-07\n",
            "Total Loss: 1.6065482118178968e-06\n",
            "----------------------------------------\n",
            "Epoch 393\n",
            "Var loss:  tensor(1.6019e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7251849971683343e-06\n",
            "E_s_wdiff_all_sq: 2.2349395161766086e-07\n",
            "E_IS_SCOPE: -1.3425902736630272e-06\n",
            "E_IS_E_SCOPE: 3.1154206701379904e-07\n",
            "Total Loss: 1.6018905001755793e-06\n",
            "----------------------------------------\n",
            "Epoch 394\n",
            "Var loss:  tensor(1.5971e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7373969395080364e-06\n",
            "E_s_wdiff_all_sq: 2.384194880786483e-07\n",
            "E_IS_SCOPE: -1.3512160726635145e-06\n",
            "E_IS_E_SCOPE: 3.0392982637468794e-07\n",
            "Total Loss: 1.5971497893315418e-06\n",
            "----------------------------------------\n",
            "Epoch 395\n",
            "Var loss:  tensor(1.5924e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7392545157030625e-06\n",
            "E_s_wdiff_all_sq: 2.495504532859129e-07\n",
            "E_IS_SCOPE: -1.3477076154061413e-06\n",
            "E_IS_E_SCOPE: 3.051568355030115e-07\n",
            "Total Loss: 1.592439296577403e-06\n",
            "----------------------------------------\n",
            "Epoch 396\n",
            "Var loss:  tensor(1.5877e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7409323118094446e-06\n",
            "E_s_wdiff_all_sq: 2.548608922213331e-07\n",
            "E_IS_SCOPE: -1.342025435620398e-06\n",
            "E_IS_E_SCOPE: 3.1139431764437166e-07\n",
            "Total Loss: 1.587696049037131e-06\n",
            "----------------------------------------\n",
            "Epoch 397\n",
            "Var loss:  tensor(1.5830e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.748567610954559e-06\n",
            "E_s_wdiff_all_sq: 2.615906875608306e-07\n",
            "E_IS_SCOPE: -1.3449718900186018e-06\n",
            "E_IS_E_SCOPE: 3.112651543621337e-07\n",
            "Total Loss: 1.5829669706108162e-06\n",
            "----------------------------------------\n",
            "Epoch 398\n",
            "Var loss:  tensor(1.5782e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.759652988542204e-06\n",
            "E_s_wdiff_all_sq: 2.7418898696117585e-07\n",
            "E_IS_SCOPE: -1.356542395276024e-06\n",
            "E_IS_E_SCOPE: 3.0132635434269886e-07\n",
            "Total Loss: 1.578190638322141e-06\n",
            "----------------------------------------\n",
            "Epoch 399\n",
            "Var loss:  tensor(1.5735e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7618154766621997e-06\n",
            "E_s_wdiff_all_sq: 2.8210032607811246e-07\n",
            "E_IS_SCOPE: -1.3560982069093842e-06\n",
            "E_IS_E_SCOPE: 3.012565088407858e-07\n",
            "Total Loss: 1.5734698550623055e-06\n",
            "----------------------------------------\n",
            "Epoch 400\n",
            "Var loss:  tensor(1.5687e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.758254989233864e-06\n",
            "E_s_wdiff_all_sq: 2.8183095522839206e-07\n",
            "E_IS_SCOPE: -1.3444956353737346e-06\n",
            "E_IS_E_SCOPE: 3.1359420840800636e-07\n",
            "Total Loss: 1.5687084824205487e-06\n",
            "----------------------------------------\n",
            "Epoch 401\n",
            "Var loss:  tensor(1.5640e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.755043489220429e-06\n",
            "E_s_wdiff_all_sq: 2.8067314710883147e-07\n",
            "E_IS_SCOPE: -1.3323661147600035e-06\n",
            "E_IS_E_SCOPE: 3.2704234041358693e-07\n",
            "Total Loss: 1.5640175677429752e-06\n",
            "----------------------------------------\n",
            "Epoch 402\n",
            "Var loss:  tensor(1.5594e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7625846336782344e-06\n",
            "E_s_wdiff_all_sq: 2.906330252911993e-07\n",
            "E_IS_SCOPE: -1.3437126650934921e-06\n",
            "E_IS_E_SCOPE: 3.1681796035712197e-07\n",
            "Total Loss: 1.5593544934643657e-06\n",
            "----------------------------------------\n",
            "Epoch 403\n",
            "Var loss:  tensor(1.5546e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.762547634438664e-06\n",
            "E_s_wdiff_all_sq: 2.922522754478302e-07\n",
            "E_IS_SCOPE: -1.3379844211646806e-06\n",
            "E_IS_E_SCOPE: 3.2408548016188727e-07\n",
            "Total Loss: 1.5546196923162562e-06\n",
            "----------------------------------------\n",
            "Epoch 404\n",
            "Var loss:  tensor(1.5499e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.753189705947865e-06\n",
            "E_s_wdiff_all_sq: 2.868534118545917e-07\n",
            "E_IS_SCOPE: -1.3147036320283895e-06\n",
            "E_IS_E_SCOPE: 3.4776432736449364e-07\n",
            "Total Loss: 1.5498645112860658e-06\n",
            "----------------------------------------\n",
            "Epoch 405\n",
            "Var loss:  tensor(1.5451e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.752215430533863e-06\n",
            "E_s_wdiff_all_sq: 2.9281913586413326e-07\n",
            "E_IS_SCOPE: -1.3134717719000487e-06\n",
            "E_IS_E_SCOPE: 3.47913784844198e-07\n",
            "Total Loss: 1.5450893171597948e-06\n",
            "----------------------------------------\n",
            "Epoch 406\n",
            "Var loss:  tensor(1.5403e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.75487814348829e-06\n",
            "E_s_wdiff_all_sq: 2.9831710795449065e-07\n",
            "E_IS_SCOPE: -1.3125516701270509e-06\n",
            "E_IS_E_SCOPE: 3.4980927764650574e-07\n",
            "Total Loss: 1.5403032759652447e-06\n",
            "----------------------------------------\n",
            "Epoch 407\n",
            "Var loss:  tensor(1.5355e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.755177046278001e-06\n",
            "E_s_wdiff_all_sq: 2.989732586061748e-07\n",
            "E_IS_SCOPE: -1.3062496971230502e-06\n",
            "E_IS_E_SCOPE: 3.58321502842614e-07\n",
            "Total Loss: 1.5355255237190563e-06\n",
            "----------------------------------------\n",
            "Epoch 408\n",
            "Var loss:  tensor(1.5308e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.752468427954843e-06\n",
            "E_s_wdiff_all_sq: 3.0089541563336845e-07\n",
            "E_IS_SCOPE: -1.3012178510730047e-06\n",
            "E_IS_E_SCOPE: 3.6342197609071736e-07\n",
            "Total Loss: 1.5307574939725887e-06\n",
            "----------------------------------------\n",
            "Epoch 409\n",
            "Var loss:  tensor(1.5259e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7600367114648257e-06\n",
            "E_s_wdiff_all_sq: 3.1236374093555465e-07\n",
            "E_IS_SCOPE: -1.309320581109729e-06\n",
            "E_IS_E_SCOPE: 3.5578475583458984e-07\n",
            "Total Loss: 1.5259264326191921e-06\n",
            "----------------------------------------\n",
            "Epoch 410\n",
            "Var loss:  tensor(1.5213e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.756094318116278e-06\n",
            "E_s_wdiff_all_sq: 3.121064595646069e-07\n",
            "E_IS_SCOPE: -1.302936584048671e-06\n",
            "E_IS_E_SCOPE: 3.626635461363251e-07\n",
            "Total Loss: 1.5212517341602377e-06\n",
            "----------------------------------------\n",
            "Epoch 411\n",
            "Var loss:  tensor(1.5166e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7474764836068174e-06\n",
            "E_s_wdiff_all_sq: 3.0397611191504755e-07\n",
            "E_IS_SCOPE: -1.2866927611447982e-06\n",
            "E_IS_E_SCOPE: 3.80983708024956e-07\n",
            "Total Loss: 1.5166115693308203e-06\n",
            "----------------------------------------\n",
            "Epoch 412\n",
            "Var loss:  tensor(1.5120e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7539559920475177e-06\n",
            "E_s_wdiff_all_sq: 3.0839886551085054e-07\n",
            "E_IS_SCOPE: -1.2872832263561059e-06\n",
            "E_IS_E_SCOPE: 3.837313864896423e-07\n",
            "Total Loss: 1.51199203682373e-06\n",
            "----------------------------------------\n",
            "Epoch 413\n",
            "Var loss:  tensor(1.5074e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.740737000661189e-06\n",
            "E_s_wdiff_all_sq: 3.0169994041305435e-07\n",
            "E_IS_SCOPE: -1.2636705185887066e-06\n",
            "E_IS_E_SCOPE: 4.064026897954621e-07\n",
            "Total Loss: 1.5073547794583557e-06\n",
            "----------------------------------------\n",
            "Epoch 414\n",
            "Var loss:  tensor(1.5028e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7278571314921667e-06\n",
            "E_s_wdiff_all_sq: 2.94747608294448e-07\n",
            "E_IS_SCOPE: -1.2466123027637484e-06\n",
            "E_IS_E_SCOPE: 4.2279484864373064e-07\n",
            "Total Loss: 1.502759356361319e-06\n",
            "----------------------------------------\n",
            "Epoch 415\n",
            "Var loss:  tensor(1.4981e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.725483374065858e-06\n",
            "E_s_wdiff_all_sq: 2.904339128789451e-07\n",
            "E_IS_SCOPE: -1.2323050473859563e-06\n",
            "E_IS_E_SCOPE: 4.403818091713779e-07\n",
            "Total Loss: 1.4981398840508035e-06\n",
            "----------------------------------------\n",
            "Epoch 416\n",
            "Var loss:  tensor(1.4935e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7366223147538553e-06\n",
            "E_s_wdiff_all_sq: 2.988428166898859e-07\n",
            "E_IS_SCOPE: -1.2349199781380993e-06\n",
            "E_IS_E_SCOPE: 4.414482696978233e-07\n",
            "Total Loss: 1.4935071383706828e-06\n",
            "----------------------------------------\n",
            "Epoch 417\n",
            "Var loss:  tensor(1.4888e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.722593824490437e-06\n",
            "E_s_wdiff_all_sq: 2.941718101689284e-07\n",
            "E_IS_SCOPE: -1.2064584311039298e-06\n",
            "E_IS_E_SCOPE: 4.6756157132480894e-07\n",
            "Total Loss: 1.4888461454425902e-06\n",
            "----------------------------------------\n",
            "Epoch 418\n",
            "Var loss:  tensor(1.4843e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7061335766712023e-06\n",
            "E_s_wdiff_all_sq: 2.866564002074007e-07\n",
            "E_IS_SCOPE: -1.1710859838790565e-06\n",
            "E_IS_E_SCOPE: 5.007566719636895e-07\n",
            "Total Loss: 1.4842560007568688e-06\n",
            "----------------------------------------\n",
            "Epoch 419\n",
            "Var loss:  tensor(1.4796e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7189337950232425e-06\n",
            "E_s_wdiff_all_sq: 2.9563104953641707e-07\n",
            "E_IS_SCOPE: -1.1770483979169515e-06\n",
            "E_IS_E_SCOPE: 4.990418264715687e-07\n",
            "Total Loss: 1.4795864326883438e-06\n",
            "----------------------------------------\n",
            "Epoch 420\n",
            "Var loss:  tensor(1.4749e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.72112850651415e-06\n",
            "E_s_wdiff_all_sq: 2.959918044232878e-07\n",
            "E_IS_SCOPE: -1.1692935334654473e-06\n",
            "E_IS_E_SCOPE: 5.100507928800983e-07\n",
            "Total Loss: 1.47491218537833e-06\n",
            "----------------------------------------\n",
            "Epoch 421\n",
            "Var loss:  tensor(1.4703e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.701307205934347e-06\n",
            "E_s_wdiff_all_sq: 2.8542510510415807e-07\n",
            "E_IS_SCOPE: -1.1362016822438057e-06\n",
            "E_IS_E_SCOPE: 5.408393081750521e-07\n",
            "Total Loss: 1.470264255971032e-06\n",
            "----------------------------------------\n",
            "Epoch 422\n",
            "Var loss:  tensor(1.4656e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7036067926532814e-06\n",
            "E_s_wdiff_all_sq: 2.927366336885657e-07\n",
            "E_IS_SCOPE: -1.1307752969213912e-06\n",
            "E_IS_E_SCOPE: 5.460997362049857e-07\n",
            "Total Loss: 1.4655842286905205e-06\n",
            "----------------------------------------\n",
            "Epoch 423\n",
            "Var loss:  tensor(1.4610e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7107308609997365e-06\n",
            "E_s_wdiff_all_sq: 2.998801820890259e-07\n",
            "E_IS_SCOPE: -1.112060850149784e-06\n",
            "E_IS_E_SCOPE: 5.671193485342748e-07\n",
            "Total Loss: 1.4609544175211516e-06\n",
            "----------------------------------------\n",
            "Epoch 424\n",
            "Var loss:  tensor(1.4563e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7073832957764196e-06\n",
            "E_s_wdiff_all_sq: 3.003135579709834e-07\n",
            "E_IS_SCOPE: -1.070969577014724e-06\n",
            "E_IS_E_SCOPE: 6.086241867557526e-07\n",
            "Total Loss: 1.456346346243042e-06\n",
            "----------------------------------------\n",
            "Epoch 425\n",
            "Var loss:  tensor(1.4517e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.711183108731413e-06\n",
            "E_s_wdiff_all_sq: 3.095989715065367e-07\n",
            "E_IS_SCOPE: -1.0403316321263186e-06\n",
            "E_IS_E_SCOPE: 6.388194344499697e-07\n",
            "Total Loss: 1.4517461400508576e-06\n",
            "----------------------------------------\n",
            "Epoch 426\n",
            "Var loss:  tensor(1.4471e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7138121633721766e-06\n",
            "E_s_wdiff_all_sq: 3.1595078627347233e-07\n",
            "E_IS_SCOPE: -1.0106825893833673e-06\n",
            "E_IS_E_SCOPE: 6.689095343399825e-07\n",
            "Total Loss: 1.4471412656305633e-06\n",
            "----------------------------------------\n",
            "Epoch 427\n",
            "Var loss:  tensor(1.4425e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.717041075296832e-06\n",
            "E_s_wdiff_all_sq: 3.1878800334639753e-07\n",
            "E_IS_SCOPE: -9.889551286483555e-07\n",
            "E_IS_E_SCOPE: 6.93148032694191e-07\n",
            "Total Loss: 1.4425108852439005e-06\n",
            "----------------------------------------\n",
            "Epoch 428\n",
            "Var loss:  tensor(1.4379e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7275789113781396e-06\n",
            "E_s_wdiff_all_sq: 3.296381045853426e-07\n",
            "E_IS_SCOPE: -9.8469828593951e-07\n",
            "E_IS_E_SCOPE: 6.995774071769918e-07\n",
            "Total Loss: 1.437853556538352e-06\n",
            "----------------------------------------\n",
            "Epoch 429\n",
            "Var loss:  tensor(1.4333e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.715838720156469e-06\n",
            "E_s_wdiff_all_sq: 3.257874921906111e-07\n",
            "E_IS_SCOPE: -9.584520895988967e-07\n",
            "E_IS_E_SCOPE: 7.241689071885246e-07\n",
            "Total Loss: 1.4332733703695735e-06\n",
            "----------------------------------------\n",
            "Epoch 430\n",
            "Var loss:  tensor(1.4286e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.708255918302871e-06\n",
            "E_s_wdiff_all_sq: 3.221182711131142e-07\n",
            "E_IS_SCOPE: -9.284794460953982e-07\n",
            "E_IS_E_SCOPE: 7.54497271866315e-07\n",
            "Total Loss: 1.4286483472448896e-06\n",
            "----------------------------------------\n",
            "Epoch 431\n",
            "Var loss:  tensor(1.4240e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7251369517226818e-06\n",
            "E_s_wdiff_all_sq: 3.365281045530681e-07\n",
            "E_IS_SCOPE: -9.292150582936742e-07\n",
            "E_IS_E_SCOPE: 7.5730880232476e-07\n",
            "Total Loss: 1.4240252619113036e-06\n",
            "----------------------------------------\n",
            "Epoch 432\n",
            "Var loss:  tensor(1.4194e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.72744964036164e-06\n",
            "E_s_wdiff_all_sq: 3.413379691140472e-07\n",
            "E_IS_SCOPE: -9.088756325548706e-07\n",
            "E_IS_E_SCOPE: 7.787148994098935e-07\n",
            "Total Loss: 1.4193947432966233e-06\n",
            "----------------------------------------\n",
            "Epoch 433\n",
            "Var loss:  tensor(1.4148e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7174960765215632e-06\n",
            "E_s_wdiff_all_sq: 3.3905800039700267e-07\n",
            "E_IS_SCOPE: -8.735584500414855e-07\n",
            "E_IS_E_SCOPE: 8.125051535324349e-07\n",
            "Total Loss: 1.4147750049552784e-06\n",
            "----------------------------------------\n",
            "Epoch 434\n",
            "Var loss:  tensor(1.4101e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7247134728654896e-06\n",
            "E_s_wdiff_all_sq: 3.4964853697414283e-07\n",
            "E_IS_SCOPE: -8.596682622577166e-07\n",
            "E_IS_E_SCOPE: 8.270379061569652e-07\n",
            "Total Loss: 1.4101167350405418e-06\n",
            "----------------------------------------\n",
            "Epoch 435\n",
            "Var loss:  tensor(1.4055e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7453445371596323e-06\n",
            "E_s_wdiff_all_sq: 3.6754034482146097e-07\n",
            "E_IS_SCOPE: -8.612777410335783e-07\n",
            "E_IS_E_SCOPE: 8.291069435615396e-07\n",
            "Total Loss: 1.405498959126494e-06\n",
            "----------------------------------------\n",
            "Epoch 436\n",
            "Var loss:  tensor(1.4009e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.745564364312256e-06\n",
            "E_s_wdiff_all_sq: 3.69290933310109e-07\n",
            "E_IS_SCOPE: -8.471947699105281e-07\n",
            "E_IS_E_SCOPE: 8.447198839361625e-07\n",
            "Total Loss: 1.400908259287324e-06\n",
            "----------------------------------------\n",
            "Epoch 437\n",
            "Var loss:  tensor(1.3962e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.743307666757351e-06\n",
            "E_s_wdiff_all_sq: 3.71329037774109e-07\n",
            "E_IS_SCOPE: -8.40325914106005e-07\n",
            "E_IS_E_SCOPE: 8.517784403424936e-07\n",
            "Total Loss: 1.3962340560648037e-06\n",
            "----------------------------------------\n",
            "Epoch 438\n",
            "Var loss:  tensor(1.3915e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.740737120430676e-06\n",
            "E_s_wdiff_all_sq: 3.7436745475053383e-07\n",
            "E_IS_SCOPE: -8.304732731095192e-07\n",
            "E_IS_E_SCOPE: 8.611840247497515e-07\n",
            "Total Loss: 1.3915192059401594e-06\n",
            "----------------------------------------\n",
            "Epoch 439\n",
            "Var loss:  tensor(1.3868e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.722972043391154e-06\n",
            "E_s_wdiff_all_sq: 3.627565786164752e-07\n",
            "E_IS_SCOPE: -7.967301987972164e-07\n",
            "E_IS_E_SCOPE: 8.941869815145724e-07\n",
            "Total Loss: 1.3868452401296596e-06\n",
            "----------------------------------------\n",
            "Epoch 440\n",
            "Var loss:  tensor(1.3821e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7234338088890284e-06\n",
            "E_s_wdiff_all_sq: 3.636145233051429e-07\n",
            "E_IS_SCOPE: -7.864448866277558e-07\n",
            "E_IS_E_SCOPE: 9.066366692220122e-07\n",
            "Total Loss: 1.3821203098629088e-06\n",
            "----------------------------------------\n",
            "Epoch 441\n",
            "Var loss:  tensor(1.3774e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7196165205281044e-06\n",
            "E_s_wdiff_all_sq: 3.605660297946987e-07\n",
            "E_IS_SCOPE: -7.672509450290234e-07\n",
            "E_IS_E_SCOPE: 9.278102227404734e-07\n",
            "Total Loss: 1.3773922911729707e-06\n",
            "----------------------------------------\n",
            "Epoch 442\n",
            "Var loss:  tensor(1.3727e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.709122403254167e-06\n",
            "E_s_wdiff_all_sq: 3.5315071270738495e-07\n",
            "E_IS_SCOPE: -7.384426585372165e-07\n",
            "E_IS_E_SCOPE: 9.5742099995424e-07\n",
            "Total Loss: 1.3727085095424283e-06\n",
            "----------------------------------------\n",
            "Epoch 443\n",
            "Var loss:  tensor(1.3680e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7052186909483435e-06\n",
            "E_s_wdiff_all_sq: 3.5090121267833935e-07\n",
            "E_IS_SCOPE: -7.172211194756187e-07\n",
            "E_IS_E_SCOPE: 9.801821453638037e-07\n",
            "Total Loss: 1.367975084569718e-06\n",
            "----------------------------------------\n",
            "Epoch 444\n",
            "Var loss:  tensor(1.3632e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7053520543423403e-06\n",
            "E_s_wdiff_all_sq: 3.540269779905107e-07\n",
            "E_IS_SCOPE: -7.019967594788145e-07\n",
            "E_IS_E_SCOPE: 9.962859068039721e-07\n",
            "Total Loss: 1.3632238797648153e-06\n",
            "----------------------------------------\n",
            "Epoch 445\n",
            "Var loss:  tensor(1.3587e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7049906949673404e-06\n",
            "E_s_wdiff_all_sq: 3.594510382908651e-07\n",
            "E_IS_SCOPE: -6.927479029122061e-07\n",
            "E_IS_E_SCOPE: 1.004922125467472e-06\n",
            "Total Loss: 1.3586637358956783e-06\n",
            "----------------------------------------\n",
            "Epoch 446\n",
            "Var loss:  tensor(1.3540e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.684894341476923e-06\n",
            "E_s_wdiff_all_sq: 3.444793092830471e-07\n",
            "E_IS_SCOPE: -6.609904172128256e-07\n",
            "E_IS_E_SCOPE: 1.0364532849590214e-06\n",
            "Total Loss: 1.35399176382874e-06\n",
            "----------------------------------------\n",
            "Epoch 447\n",
            "Var loss:  tensor(1.3493e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6842293358547605e-06\n",
            "E_s_wdiff_all_sq: 3.4278917735311077e-07\n",
            "E_IS_SCOPE: -6.527745853790643e-07\n",
            "E_IS_E_SCOPE: 1.0475354877759652e-06\n",
            "Total Loss: 1.3492841481701497e-06\n",
            "----------------------------------------\n",
            "Epoch 448\n",
            "Var loss:  tensor(1.3447e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6931913604960196e-06\n",
            "E_s_wdiff_all_sq: 3.5117272378026866e-07\n",
            "E_IS_SCOPE: -6.55310041063344e-07\n",
            "E_IS_E_SCOPE: 1.0475709943210972e-06\n",
            "Total Loss: 1.344720701925427e-06\n",
            "----------------------------------------\n",
            "Epoch 449\n",
            "Var loss:  tensor(1.3400e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6688525884057924e-06\n",
            "E_s_wdiff_all_sq: 3.3454902167581115e-07\n",
            "E_IS_SCOPE: -6.20728128629836e-07\n",
            "E_IS_E_SCOPE: 1.0806689627654011e-06\n",
            "Total Loss: 1.3399735199180662e-06\n",
            "----------------------------------------\n",
            "Epoch 450\n",
            "Var loss:  tensor(1.3354e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6506737067700954e-06\n",
            "E_s_wdiff_all_sq: 3.225442689258651e-07\n",
            "E_IS_SCOPE: -5.904343829066517e-07\n",
            "E_IS_E_SCOPE: 1.1101762266275103e-06\n",
            "Total Loss: 1.3353723547544648e-06\n",
            "----------------------------------------\n",
            "Epoch 451\n",
            "Var loss:  tensor(1.3307e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.67012449735074e-06\n",
            "E_s_wdiff_all_sq: 3.388453089776718e-07\n",
            "E_IS_SCOPE: -5.988028461405958e-07\n",
            "E_IS_E_SCOPE: 1.1057354207249696e-06\n",
            "Total Loss: 1.330666790620496e-06\n",
            "----------------------------------------\n",
            "Epoch 452\n",
            "Var loss:  tensor(1.3260e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6764452517959514e-06\n",
            "E_s_wdiff_all_sq: 3.464867799201417e-07\n",
            "E_IS_SCOPE: -5.980970440678996e-07\n",
            "E_IS_E_SCOPE: 1.1080969099132497e-06\n",
            "Total Loss: 1.3260346998920704e-06\n",
            "----------------------------------------\n",
            "Epoch 453\n",
            "Var loss:  tensor(1.3213e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6602887153357954e-06\n",
            "E_s_wdiff_all_sq: 3.384652210883837e-07\n",
            "E_IS_SCOPE: -5.697098015919344e-07\n",
            "E_IS_E_SCOPE: 1.1347735428484275e-06\n",
            "Total Loss: 1.3213209413452468e-06\n",
            "----------------------------------------\n",
            "Epoch 454\n",
            "Var loss:  tensor(1.3167e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6518039988815964e-06\n",
            "E_s_wdiff_all_sq: 3.358485190144739e-07\n",
            "E_IS_SCOPE: -5.494345060661692e-07\n",
            "E_IS_E_SCOPE: 1.154416602163211e-06\n",
            "Total Loss: 1.3167173993869206e-06\n",
            "----------------------------------------\n",
            "Epoch 455\n",
            "Var loss:  tensor(1.3121e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6734349789204215e-06\n",
            "E_s_wdiff_all_sq: 3.542595761603766e-07\n",
            "E_IS_SCOPE: -5.690013307291845e-07\n",
            "E_IS_E_SCOPE: 1.1387916937001761e-06\n",
            "Total Loss: 1.3120534898798826e-06\n",
            "----------------------------------------\n",
            "Epoch 456\n",
            "Var loss:  tensor(1.3073e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.67665439723695e-06\n",
            "E_s_wdiff_all_sq: 3.553254703187007e-07\n",
            "E_IS_SCOPE: -5.597407204733542e-07\n",
            "E_IS_E_SCOPE: 1.1514923032417123e-06\n",
            "Total Loss: 1.3073270154666756e-06\n",
            "----------------------------------------\n",
            "Epoch 457\n",
            "Var loss:  tensor(1.3028e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.656420350347485e-06\n",
            "E_s_wdiff_all_sq: 3.43169780077778e-07\n",
            "E_IS_SCOPE: -5.207055724448497e-07\n",
            "E_IS_E_SCOPE: 1.188765962374532e-06\n",
            "Total Loss: 1.3027716366095021e-06\n",
            "----------------------------------------\n",
            "Epoch 458\n",
            "Var loss:  tensor(1.2980e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.657639173793408e-06\n",
            "E_s_wdiff_all_sq: 3.5260250044506715e-07\n",
            "E_IS_SCOPE: -5.161867804789939e-07\n",
            "E_IS_E_SCOPE: 1.191563267272757e-06\n",
            "Total Loss: 1.2980007138233978e-06\n",
            "----------------------------------------\n",
            "Epoch 459\n",
            "Var loss:  tensor(1.2934e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6658378971273284e-06\n",
            "E_s_wdiff_all_sq: 3.589546642980271e-07\n",
            "E_IS_SCOPE: -5.137367652874253e-07\n",
            "E_IS_E_SCOPE: 1.1972563830260448e-06\n",
            "Total Loss: 1.2933610721809207e-06\n",
            "----------------------------------------\n",
            "Epoch 460\n",
            "Var loss:  tensor(1.2887e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.665170767759705e-06\n",
            "E_s_wdiff_all_sq: 3.547676503966962e-07\n",
            "E_IS_SCOPE: -4.98137472450447e-07\n",
            "E_IS_E_SCOPE: 1.2169301764082806e-06\n",
            "Total Loss: 1.2887319556241125e-06\n",
            "----------------------------------------\n",
            "Epoch 461\n",
            "Var loss:  tensor(1.2841e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.66337748467118e-06\n",
            "E_s_wdiff_all_sq: 3.593580316941041e-07\n",
            "E_IS_SCOPE: -4.930735032023892e-07\n",
            "E_IS_E_SCOPE: 1.2211358927371779e-06\n",
            "Total Loss: 1.2840647970765002e-06\n",
            "----------------------------------------\n",
            "Epoch 462\n",
            "Var loss:  tensor(1.2794e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6481303306288423e-06\n",
            "E_s_wdiff_all_sq: 3.5446873981014144e-07\n",
            "E_IS_SCOPE: -4.7517195383065676e-07\n",
            "E_IS_E_SCOPE: 1.2361773360811475e-06\n",
            "Total Loss: 1.2794271469736514e-06\n",
            "----------------------------------------\n",
            "Epoch 463\n",
            "Var loss:  tensor(1.2748e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6484291868625776e-06\n",
            "E_s_wdiff_all_sq: 3.5194010206331017e-07\n",
            "E_IS_SCOPE: -4.681770176758478e-07\n",
            "E_IS_E_SCOPE: 1.2469015048648512e-06\n",
            "Total Loss: 1.2747961756964282e-06\n",
            "----------------------------------------\n",
            "Epoch 464\n",
            "Var loss:  tensor(1.2701e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.655330293986913e-06\n",
            "E_s_wdiff_all_sq: 3.5588760831577515e-07\n",
            "E_IS_SCOPE: -4.770702681223267e-07\n",
            "E_IS_E_SCOPE: 1.2418190311004153e-06\n",
            "Total Loss: 1.2701282232042117e-06\n",
            "----------------------------------------\n",
            "Epoch 465\n",
            "Var loss:  tensor(1.2654e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6380200122257304e-06\n",
            "E_s_wdiff_all_sq: 3.453374052018818e-07\n",
            "E_IS_SCOPE: -4.542794409011055e-07\n",
            "E_IS_E_SCOPE: 1.2635779705779653e-06\n",
            "Total Loss: 1.2654319200442663e-06\n",
            "----------------------------------------\n",
            "Epoch 466\n",
            "Var loss:  tensor(1.2609e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6127329069354105e-06\n",
            "E_s_wdiff_all_sq: 3.296337368249763e-07\n",
            "E_IS_SCOPE: -4.1985657318941675e-07\n",
            "E_IS_E_SCOPE: 1.2954949301673838e-06\n",
            "Total Loss: 1.2608602993753916e-06\n",
            "----------------------------------------\n",
            "Epoch 467\n",
            "Var loss:  tensor(1.2561e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.624626709786013e-06\n",
            "E_s_wdiff_all_sq: 3.384330782440186e-07\n",
            "E_IS_SCOPE: -4.350812319838775e-07\n",
            "E_IS_E_SCOPE: 1.2841925473810677e-06\n",
            "Total Loss: 1.2561102087906624e-06\n",
            "----------------------------------------\n",
            "Epoch 468\n",
            "Var loss:  tensor(1.2514e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6274774965519695e-06\n",
            "E_s_wdiff_all_sq: 3.371782655468369e-07\n",
            "E_IS_SCOPE: -4.3615717909493693e-07\n",
            "E_IS_E_SCOPE: 1.287510435784748e-06\n",
            "Total Loss: 1.2514281372243222e-06\n",
            "----------------------------------------\n",
            "Epoch 469\n",
            "Var loss:  tensor(1.2467e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6090682181265514e-06\n",
            "E_s_wdiff_all_sq: 3.2606445907943604e-07\n",
            "E_IS_SCOPE: -4.112748865842019e-07\n",
            "E_IS_E_SCOPE: 1.3110980477202574e-06\n",
            "Total Loss: 1.2467220264167562e-06\n",
            "----------------------------------------\n",
            "Epoch 470\n",
            "Var loss:  tensor(1.2420e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6043023738013406e-06\n",
            "E_s_wdiff_all_sq: 3.306992658496966e-07\n",
            "E_IS_SCOPE: -4.093905695203989e-07\n",
            "E_IS_E_SCOPE: 1.310630979272599e-06\n",
            "Total Loss: 1.2420241463442078e-06\n",
            "----------------------------------------\n",
            "Epoch 471\n",
            "Var loss:  tensor(1.2373e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6028323969153168e-06\n",
            "E_s_wdiff_all_sq: 3.301461512934993e-07\n",
            "E_IS_SCOPE: -4.027179353864232e-07\n",
            "E_IS_E_SCOPE: 1.3191946959029834e-06\n",
            "Total Loss: 1.2373251190215627e-06\n",
            "----------------------------------------\n",
            "Epoch 472\n",
            "Var loss:  tensor(1.2326e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.602423585482048e-06\n",
            "E_s_wdiff_all_sq: 3.2613945801074136e-07\n",
            "E_IS_SCOPE: -3.894080461043317e-07\n",
            "E_IS_E_SCOPE: 1.3366518294729172e-06\n",
            "Total Loss: 1.2326285122953682e-06\n",
            "----------------------------------------\n",
            "Epoch 473\n",
            "Var loss:  tensor(1.2279e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6002941348766907e-06\n",
            "E_s_wdiff_all_sq: 3.2914595761856106e-07\n",
            "E_IS_SCOPE: -3.776772494163136e-07\n",
            "E_IS_E_SCOPE: 1.348196492851575e-06\n",
            "Total Loss: 1.227864828700911e-06\n",
            "----------------------------------------\n",
            "Epoch 474\n",
            "Var loss:  tensor(1.2233e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6062507022259564e-06\n",
            "E_s_wdiff_all_sq: 3.406286059980217e-07\n",
            "E_IS_SCOPE: -3.833109980330767e-07\n",
            "E_IS_E_SCOPE: 1.342087704079982e-06\n",
            "Total Loss: 1.2232888279803754e-06\n",
            "----------------------------------------\n",
            "Epoch 475\n",
            "Var loss:  tensor(1.2185e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5944311783900964e-06\n",
            "E_s_wdiff_all_sq: 3.260843579370695e-07\n",
            "E_IS_SCOPE: -3.6624450968369543e-07\n",
            "E_IS_E_SCOPE: 1.3629349348629589e-06\n",
            "Total Loss: 1.218452067338277e-06\n",
            "----------------------------------------\n",
            "Epoch 476\n",
            "Var loss:  tensor(1.2139e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.588392377153539e-06\n",
            "E_s_wdiff_all_sq: 3.1460288260310413e-07\n",
            "E_IS_SCOPE: -3.566548733662667e-07\n",
            "E_IS_E_SCOPE: 1.3774993597158968e-06\n",
            "Total Loss: 1.2139451643646664e-06\n",
            "----------------------------------------\n",
            "Epoch 477\n",
            "Var loss:  tensor(1.2091e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5858137149028245e-06\n",
            "E_s_wdiff_all_sq: 3.248301013552922e-07\n",
            "E_IS_SCOPE: -3.6759749803127946e-07\n",
            "E_IS_E_SCOPE: 1.3625722379761376e-06\n",
            "Total Loss: 1.2091082775112562e-06\n",
            "----------------------------------------\n",
            "Epoch 478\n",
            "Var loss:  tensor(1.2044e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5676226845114784e-06\n",
            "E_s_wdiff_all_sq: 3.1724046796797173e-07\n",
            "E_IS_SCOPE: -3.4928904516306433e-07\n",
            "E_IS_E_SCOPE: 1.3779278617553458e-06\n",
            "Total Loss: 1.2044125386852446e-06\n",
            "----------------------------------------\n",
            "Epoch 479\n",
            "Var loss:  tensor(1.1998e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.552115093582697e-06\n",
            "E_s_wdiff_all_sq: 2.9671958057661634e-07\n",
            "E_IS_SCOPE: -3.251725548647698e-07\n",
            "E_IS_E_SCOPE: 1.4068794512567106e-06\n",
            "Total Loss: 1.199755636741678e-06\n",
            "----------------------------------------\n",
            "Epoch 480\n",
            "Var loss:  tensor(1.1949e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5670716365731242e-06\n",
            "E_s_wdiff_all_sq: 3.058961915772816e-07\n",
            "E_IS_SCOPE: -3.4649380644341864e-07\n",
            "E_IS_E_SCOPE: 1.3908754326247297e-06\n",
            "Total Loss: 1.1949011028381054e-06\n",
            "----------------------------------------\n",
            "Epoch 481\n",
            "Var loss:  tensor(1.1903e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5522815306847804e-06\n",
            "E_s_wdiff_all_sq: 3.0303673931773955e-07\n",
            "E_IS_SCOPE: -3.3883030984845536e-07\n",
            "E_IS_E_SCOPE: 1.394873639808846e-06\n",
            "Total Loss: 1.1903010280309976e-06\n",
            "----------------------------------------\n",
            "Epoch 482\n",
            "Var loss:  tensor(1.1854e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5307691197474295e-06\n",
            "E_s_wdiff_all_sq: 2.8861386466366956e-07\n",
            "E_IS_SCOPE: -3.1332336215917054e-07\n",
            "E_IS_E_SCOPE: 1.4192689708507235e-06\n",
            "Total Loss: 1.1854347250425312e-06\n",
            "----------------------------------------\n",
            "Epoch 483\n",
            "Var loss:  tensor(1.1807e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5310952663841764e-06\n",
            "E_s_wdiff_all_sq: 2.856752674045547e-07\n",
            "E_IS_SCOPE: -3.112673245747488e-07\n",
            "E_IS_E_SCOPE: 1.4253444780443323e-06\n",
            "Total Loss: 1.1806605297200177e-06\n",
            "----------------------------------------\n",
            "Epoch 484\n",
            "Var loss:  tensor(1.1763e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5439879118109864e-06\n",
            "E_s_wdiff_all_sq: 2.9833835268361765e-07\n",
            "E_IS_SCOPE: -3.398376464326774e-07\n",
            "E_IS_E_SCOPE: 1.3990499782035256e-06\n",
            "Total Loss: 1.1763384458335222e-06\n",
            "----------------------------------------\n",
            "Epoch 485\n",
            "Var loss:  tensor(1.1717e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.523267616828793e-06\n",
            "E_s_wdiff_all_sq: 2.858504248740101e-07\n",
            "E_IS_SCOPE: -3.147568598110546e-07\n",
            "E_IS_E_SCOPE: 1.4223536613818165e-06\n",
            "Total Loss: 1.1716602855476002e-06\n",
            "----------------------------------------\n",
            "Epoch 486\n",
            "Var loss:  tensor(1.1669e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5111527833469365e-06\n",
            "E_s_wdiff_all_sq: 2.76095715784863e-07\n",
            "E_IS_SCOPE: -2.7971585854232595e-07\n",
            "E_IS_E_SCOPE: 1.4585743269271751e-06\n",
            "Total Loss: 1.1669408326016309e-06\n",
            "----------------------------------------\n",
            "Epoch 487\n",
            "Var loss:  tensor(1.1619e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5452715477127113e-06\n",
            "E_s_wdiff_all_sq: 3.063036292871815e-07\n",
            "E_IS_SCOPE: -3.035400612288751e-07\n",
            "E_IS_E_SCOPE: 1.4392440902151802e-06\n",
            "Total Loss: 1.1618637515159777e-06\n",
            "----------------------------------------\n",
            "Epoch 488\n",
            "Var loss:  tensor(1.1568e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5666294062931416e-06\n",
            "E_s_wdiff_all_sq: 3.313364607337118e-07\n",
            "E_IS_SCOPE: -2.9901660533893945e-07\n",
            "E_IS_E_SCOPE: 1.4444703338020722e-06\n",
            "Total Loss: 1.1567832032559658e-06\n",
            "----------------------------------------\n",
            "Epoch 489\n",
            "Var loss:  tensor(1.1520e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5522898352250197e-06\n",
            "E_s_wdiff_all_sq: 3.300578559025089e-07\n",
            "E_IS_SCOPE: -2.545240438189341e-07\n",
            "E_IS_E_SCOPE: 1.484806468037377e-06\n",
            "Total Loss: 1.152035091588448e-06\n",
            "----------------------------------------\n",
            "Epoch 490\n",
            "Var loss:  tensor(1.1472e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.574759226415247e-06\n",
            "E_s_wdiff_all_sq: 3.5124092545962335e-07\n",
            "E_IS_SCOPE: -2.560800460447048e-07\n",
            "E_IS_E_SCOPE: 1.486322406816008e-06\n",
            "Total Loss: 1.1471775312127564e-06\n",
            "----------------------------------------\n",
            "Epoch 491\n",
            "Var loss:  tensor(1.1425e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6151598375966348e-06\n",
            "E_s_wdiff_all_sq: 3.837623745627552e-07\n",
            "E_IS_SCOPE: -2.7164040315312084e-07\n",
            "E_IS_E_SCOPE: 1.4770583163841091e-06\n",
            "Total Loss: 1.1424641599379786e-06\n",
            "----------------------------------------\n",
            "Epoch 492\n",
            "Var loss:  tensor(1.1377e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5966670072784368e-06\n",
            "E_s_wdiff_all_sq: 3.749540017223243e-07\n",
            "E_IS_SCOPE: -2.300635852588895e-07\n",
            "E_IS_E_SCOPE: 1.5161990752487697e-06\n",
            "Total Loss: 1.1376518205193522e-06\n",
            "----------------------------------------\n",
            "Epoch 493\n",
            "Var loss:  tensor(1.1329e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.563717018182249e-06\n",
            "E_s_wdiff_all_sq: 3.5065680614558654e-07\n",
            "E_IS_SCOPE: -1.753706522282408e-07\n",
            "E_IS_E_SCOPE: 1.5689563040878393e-06\n",
            "Total Loss: 1.1328704353830611e-06\n",
            "----------------------------------------\n",
            "Epoch 494\n",
            "Var loss:  tensor(1.1279e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5775804686306615e-06\n",
            "E_s_wdiff_all_sq: 3.5708371471849924e-07\n",
            "E_IS_SCOPE: -1.8871209763990661e-07\n",
            "E_IS_E_SCOPE: 1.5617980374542223e-06\n",
            "Total Loss: 1.1279406197024632e-06\n",
            "----------------------------------------\n",
            "Epoch 495\n",
            "Var loss:  tensor(1.1231e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5785497299628545e-06\n",
            "E_s_wdiff_all_sq: 3.554789180354352e-07\n",
            "E_IS_SCOPE: -1.9421090597116048e-07\n",
            "E_IS_E_SCOPE: 1.5600016057719315e-06\n",
            "Total Loss: 1.1231099244197943e-06\n",
            "----------------------------------------\n",
            "Epoch 496\n",
            "Var loss:  tensor(1.1181e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5383568396543407e-06\n",
            "E_s_wdiff_all_sq: 3.294208887378156e-07\n",
            "E_IS_SCOPE: -1.630648650978581e-07\n",
            "E_IS_E_SCOPE: 1.586567600342272e-06\n",
            "Total Loss: 1.1181351560148237e-06\n",
            "----------------------------------------\n",
            "Epoch 497\n",
            "Var loss:  tensor(1.1132e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5279845343856435e-06\n",
            "E_s_wdiff_all_sq: 3.2309526926079003e-07\n",
            "E_IS_SCOPE: -1.589709907138961e-07\n",
            "E_IS_E_SCOPE: 1.5910911524173708e-06\n",
            "Total Loss: 1.113229114840879e-06\n",
            "----------------------------------------\n",
            "Epoch 498\n",
            "Var loss:  tensor(1.1085e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5439871784071778e-06\n",
            "E_s_wdiff_all_sq: 3.3321895674672623e-07\n",
            "E_IS_SCOPE: -1.88579701816442e-07\n",
            "E_IS_E_SCOPE: 1.5667987083756743e-06\n",
            "Total Loss: 1.108475537254778e-06\n",
            "----------------------------------------\n",
            "Epoch 499\n",
            "Var loss:  tensor(1.1034e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5164694099650797e-06\n",
            "E_s_wdiff_all_sq: 3.115646712449736e-07\n",
            "E_IS_SCOPE: -1.578153267550474e-07\n",
            "E_IS_E_SCOPE: 1.5971700489893454e-06\n",
            "Total Loss: 1.1033981232098801e-06\n",
            "----------------------------------------\n",
            "Epoch 500\n",
            "Var loss:  tensor(1.0985e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.483104198168579e-06\n",
            "E_s_wdiff_all_sq: 2.8778581097846616e-07\n",
            "E_IS_SCOPE: -1.2972428091473122e-07\n",
            "E_IS_E_SCOPE: 1.622906243743605e-06\n",
            "Total Loss: 1.0985214738519987e-06\n",
            "----------------------------------------\n",
            "Epoch 501\n",
            "Var loss:  tensor(1.0936e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.4849916467112685e-06\n",
            "E_s_wdiff_all_sq: 2.872598495613236e-07\n",
            "E_IS_SCOPE: -1.452391977904693e-07\n",
            "E_IS_E_SCOPE: 1.6110820540271775e-06\n",
            "Total Loss: 1.09355342949321e-06\n",
            "----------------------------------------\n",
            "Epoch 502\n",
            "Var loss:  tensor(1.0886e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.478667769516438e-06\n",
            "E_s_wdiff_all_sq: 2.7883543588256686e-07\n",
            "E_IS_SCOPE: -1.432553024370776e-07\n",
            "E_IS_E_SCOPE: 1.6165959351903953e-06\n",
            "Total Loss: 1.088593994357484e-06\n",
            "----------------------------------------\n",
            "Epoch 503\n",
            "Var loss:  tensor(1.0837e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.4565458640844045e-06\n",
            "E_s_wdiff_all_sq: 2.631715958131597e-07\n",
            "E_IS_SCOPE: -1.1956570898491096e-07\n",
            "E_IS_E_SCOPE: 1.6395166137309017e-06\n",
            "Total Loss: 1.083673758818178e-06\n",
            "----------------------------------------\n",
            "Epoch 504\n",
            "Var loss:  tensor(1.0787e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.4548831351813566e-06\n",
            "E_s_wdiff_all_sq: 2.650946240422019e-07\n",
            "E_IS_SCOPE: -1.155052288157122e-07\n",
            "E_IS_E_SCOPE: 1.6442569100500567e-06\n",
            "Total Loss: 1.0787283693861757e-06\n",
            "----------------------------------------\n",
            "Epoch 505\n",
            "Var loss:  tensor(1.0738e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.465087808469193e-06\n",
            "E_s_wdiff_all_sq: 2.758110009278863e-07\n",
            "E_IS_SCOPE: -1.113295887784626e-07\n",
            "E_IS_E_SCOPE: 1.650629754236833e-06\n",
            "Total Loss: 1.073822257489274e-06\n",
            "----------------------------------------\n",
            "Epoch 506\n",
            "Var loss:  tensor(1.0688e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.4701431272946627e-06\n",
            "E_s_wdiff_all_sq: 2.8297003950673194e-07\n",
            "E_IS_SCOPE: -8.883718003764979e-08\n",
            "E_IS_E_SCOPE: 1.6745620430586162e-06\n",
            "Total Loss: 1.0688387775739574e-06\n",
            "----------------------------------------\n",
            "Epoch 507\n",
            "Var loss:  tensor(1.0639e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.479558632450947e-06\n",
            "E_s_wdiff_all_sq: 2.9625651263771743e-07\n",
            "E_IS_SCOPE: -7.411651194172792e-08\n",
            "E_IS_E_SCOPE: 1.689816200102954e-06\n",
            "Total Loss: 1.0639008317024248e-06\n",
            "----------------------------------------\n",
            "Epoch 508\n",
            "Var loss:  tensor(1.0589e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.494518711439973e-06\n",
            "E_s_wdiff_all_sq: 3.1697249082094597e-07\n",
            "E_IS_SCOPE: -7.161354398856198e-08\n",
            "E_IS_E_SCOPE: 1.6919241144335295e-06\n",
            "Total Loss: 1.0589350397534022e-06\n",
            "----------------------------------------\n",
            "Epoch 509\n",
            "Var loss:  tensor(1.0541e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5182283382487674e-06\n",
            "E_s_wdiff_all_sq: 3.4082589421245063e-07\n",
            "E_IS_SCOPE: -8.384262878065107e-08\n",
            "E_IS_E_SCOPE: 1.6820374974735112e-06\n",
            "Total Loss: 1.054106327506551e-06\n",
            "----------------------------------------\n",
            "Epoch 510\n",
            "Var loss:  tensor(1.0491e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.508065782611709e-06\n",
            "E_s_wdiff_all_sq: 3.326114617527011e-07\n",
            "E_IS_SCOPE: -4.860318181738458e-08\n",
            "E_IS_E_SCOPE: 1.7188263603833655e-06\n",
            "Total Loss: 1.0490593724360664e-06\n",
            "----------------------------------------\n",
            "Epoch 511\n",
            "Var loss:  tensor(1.0440e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.4972270238243245e-06\n",
            "E_s_wdiff_all_sq: 3.245245732985573e-07\n",
            "E_IS_SCOPE: -2.0794457659769346e-08\n",
            "E_IS_E_SCOPE: 1.7477772843165786e-06\n",
            "Total Loss: 1.0440231025516304e-06\n",
            "----------------------------------------\n",
            "Epoch 512\n",
            "Var loss:  tensor(1.0390e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5040246122140136e-06\n",
            "E_s_wdiff_all_sq: 3.2979533141986e-07\n",
            "E_IS_SCOPE: 1.7583021453380573e-09\n",
            "E_IS_E_SCOPE: 1.7735934405987265e-06\n",
            "Total Loss: 1.0390231398659363e-06\n",
            "----------------------------------------\n",
            "Epoch 513\n",
            "Var loss:  tensor(1.0338e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.511331025423321e-06\n",
            "E_s_wdiff_all_sq: 3.395054552692379e-07\n",
            "E_IS_SCOPE: 3.8476661175087284e-08\n",
            "E_IS_E_SCOPE: 1.8117166591286964e-06\n",
            "Total Loss: 1.033809710225424e-06\n",
            "----------------------------------------\n",
            "Epoch 514\n",
            "Var loss:  tensor(1.0286e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5241897883428174e-06\n",
            "E_s_wdiff_all_sq: 3.5620939611105895e-07\n",
            "E_IS_SCOPE: 6.920002924773044e-08\n",
            "E_IS_E_SCOPE: 1.8431176398549179e-06\n",
            "Total Loss: 1.028609306995943e-06\n",
            "----------------------------------------\n",
            "Epoch 515\n",
            "Var loss:  tensor(1.0233e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.529468609956791e-06\n",
            "E_s_wdiff_all_sq: 3.7248924205169757e-07\n",
            "E_IS_SCOPE: 9.132871273982721e-08\n",
            "E_IS_E_SCOPE: 1.8623799509293993e-06\n",
            "Total Loss: 1.0233410275045073e-06\n",
            "----------------------------------------\n",
            "Epoch 516\n",
            "Var loss:  tensor(1.0182e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5359721053216926e-06\n",
            "E_s_wdiff_all_sq: 3.755604612772865e-07\n",
            "E_IS_SCOPE: 1.0861843096253558e-07\n",
            "E_IS_E_SCOPE: 1.883935739862553e-06\n",
            "Total Loss: 1.0182411622229307e-06\n",
            "----------------------------------------\n",
            "Epoch 517\n",
            "Var loss:  tensor(1.0131e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5167741066266598e-06\n",
            "E_s_wdiff_all_sq: 3.5432769309532145e-07\n",
            "E_IS_SCOPE: 1.6390066609524085e-07\n",
            "E_IS_E_SCOPE: 1.942788625242543e-06\n",
            "Total Loss: 1.0131346312152934e-06\n",
            "----------------------------------------\n",
            "Epoch 518\n",
            "Var loss:  tensor(1.0078e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.4989745680307993e-06\n",
            "E_s_wdiff_all_sq: 3.437604540204291e-07\n",
            "E_IS_SCOPE: 1.9395057051719974e-07\n",
            "E_IS_E_SCOPE: 1.971895286643644e-06\n",
            "Total Loss: 1.007788817736041e-06\n",
            "----------------------------------------\n",
            "Epoch 519\n",
            "Var loss:  tensor(1.0026e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.477694584050073e-06\n",
            "E_s_wdiff_all_sq: 3.2995746663107966e-07\n",
            "E_IS_SCOPE: 2.2807655885630748e-07\n",
            "E_IS_E_SCOPE: 2.0048924803563488e-06\n",
            "Total Loss: 1.002569410397469e-06\n",
            "----------------------------------------\n",
            "Epoch 520\n",
            "Var loss:  tensor(9.9739e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.4648311696786713e-06\n",
            "E_s_wdiff_all_sq: 3.1410498897722506e-07\n",
            "E_IS_SCOPE: 2.6342053454882864e-07\n",
            "E_IS_E_SCOPE: 2.0443224765256672e-06\n",
            "Total Loss: 9.973864327263275e-07\n",
            "----------------------------------------\n",
            "Epoch 521\n",
            "Var loss:  tensor(9.9241e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.4493259041314948e-06\n",
            "E_s_wdiff_all_sq: 2.998450127260865e-07\n",
            "E_IS_SCOPE: 2.9151293984649727e-07\n",
            "E_IS_E_SCOPE: 2.0742814270167033e-06\n",
            "Total Loss: 9.924080530435554e-07\n",
            "----------------------------------------\n",
            "Epoch 522\n",
            "Var loss:  tensor(9.8730e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.4340537426367405e-06\n",
            "E_s_wdiff_all_sq: 2.92550120950839e-07\n",
            "E_IS_SCOPE: 3.136378635543762e-07\n",
            "E_IS_E_SCOPE: 2.0949726417353936e-06\n",
            "Total Loss: 9.872982013024261e-07\n",
            "----------------------------------------\n",
            "Epoch 523\n",
            "Var loss:  tensor(9.8222e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.4107512852180625e-06\n",
            "E_s_wdiff_all_sq: 2.749367678009918e-07\n",
            "E_IS_SCOPE: 3.4875055307737153e-07\n",
            "E_IS_E_SCOPE: 2.129781434059878e-06\n",
            "Total Loss: 9.82216891430616e-07\n",
            "----------------------------------------\n",
            "Epoch 524\n",
            "Var loss:  tensor(9.7714e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.3881162221668003e-06\n",
            "E_s_wdiff_all_sq: 2.49648914192941e-07\n",
            "E_IS_SCOPE: 3.878757895189034e-07\n",
            "E_IS_E_SCOPE: 2.1727737457859645e-06\n",
            "Total Loss: 9.771355314182957e-07\n",
            "----------------------------------------\n",
            "Epoch 525\n",
            "Var loss:  tensor(9.7211e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.375535360053185e-06\n",
            "E_s_wdiff_all_sq: 2.3624399751505148e-07\n",
            "E_IS_SCOPE: 4.180962125437981e-07\n",
            "E_IS_E_SCOPE: 2.205921092099959e-06\n",
            "Total Loss: 9.721057394043713e-07\n",
            "----------------------------------------\n",
            "Epoch 526\n",
            "Var loss:  tensor(9.6697e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.374041214750001e-06\n",
            "E_s_wdiff_all_sq: 2.397109233794132e-07\n",
            "E_IS_SCOPE: 4.2220140820767134e-07\n",
            "E_IS_E_SCOPE: 2.2101135157819226e-06\n",
            "Total Loss: 9.669702122006458e-07\n",
            "----------------------------------------\n",
            "Epoch 527\n",
            "Var loss:  tensor(9.6186e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.3684811263663434e-06\n",
            "E_s_wdiff_all_sq: 2.406802859674399e-07\n",
            "E_IS_SCOPE: 4.303277070029541e-07\n",
            "E_IS_E_SCOPE: 2.2175326488834573e-06\n",
            "Total Loss: 9.618550926164564e-07\n",
            "----------------------------------------\n",
            "Epoch 528\n",
            "Var loss:  tensor(9.5683e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.358535269797179e-06\n",
            "E_s_wdiff_all_sq: 2.323200046314562e-07\n",
            "E_IS_SCOPE: 4.5110311429922485e-07\n",
            "E_IS_E_SCOPE: 2.240026973126505e-06\n",
            "Total Loss: 9.568316834897216e-07\n",
            "----------------------------------------\n",
            "Epoch 529\n",
            "Var loss:  tensor(9.5170e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.3620020369289875e-06\n",
            "E_s_wdiff_all_sq: 2.3250695195186088e-07\n",
            "E_IS_SCOPE: 4.504298982350662e-07\n",
            "E_IS_E_SCOPE: 2.2435584879318826e-06\n",
            "Total Loss: 9.51702041562053e-07\n",
            "----------------------------------------\n",
            "Epoch 530\n",
            "Var loss:  tensor(9.4662e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.3500387913000986e-06\n",
            "E_s_wdiff_all_sq: 2.2563479422573821e-07\n",
            "E_IS_SCOPE: 4.747231070875723e-07\n",
            "E_IS_E_SCOPE: 2.2678462701723916e-06\n",
            "Total Loss: 9.466218068832802e-07\n",
            "----------------------------------------\n",
            "Epoch 531\n",
            "Var loss:  tensor(9.4147e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.3196778271908347e-06\n",
            "E_s_wdiff_all_sq: 2.0390468247378302e-07\n",
            "E_IS_SCOPE: 5.249494163242715e-07\n",
            "E_IS_E_SCOPE: 2.316334840994085e-06\n",
            "Total Loss: 9.414664313559847e-07\n",
            "----------------------------------------\n",
            "Epoch 532\n",
            "Var loss:  tensor(9.3634e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.3218431358265216e-06\n",
            "E_s_wdiff_all_sq: 2.0243242527511517e-07\n",
            "E_IS_SCOPE: 5.280742812763871e-07\n",
            "E_IS_E_SCOPE: 2.323840154996881e-06\n",
            "Total Loss: 9.363430990889774e-07\n",
            "----------------------------------------\n",
            "Epoch 533\n",
            "Var loss:  tensor(9.3115e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.342172868691773e-06\n",
            "E_s_wdiff_all_sq: 2.194594294825539e-07\n",
            "E_IS_SCOPE: 4.967995098551083e-07\n",
            "E_IS_E_SCOPE: 2.296815094714371e-06\n",
            "Total Loss: 9.31146405469253e-07\n",
            "----------------------------------------\n",
            "Epoch 534\n",
            "Var loss:  tensor(9.2598e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.327762116871752e-06\n",
            "E_s_wdiff_all_sq: 2.170625207192059e-07\n",
            "E_IS_SCOPE: 5.13309360879156e-07\n",
            "E_IS_E_SCOPE: 2.309899750934738e-06\n",
            "Total Loss: 9.259829520199418e-07\n",
            "----------------------------------------\n",
            "Epoch 535\n",
            "Var loss:  tensor(9.2078e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.3119972708255965e-06\n",
            "E_s_wdiff_all_sq: 2.0564178625416984e-07\n",
            "E_IS_SCOPE: 5.501371890321096e-07\n",
            "E_IS_E_SCOPE: 2.3471558553751172e-06\n",
            "Total Loss: 9.207822878639707e-07\n",
            "----------------------------------------\n",
            "Epoch 536\n",
            "Var loss:  tensor(9.1558e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.3253801975728497e-06\n",
            "E_s_wdiff_all_sq: 2.109767497081109e-07\n",
            "E_IS_SCOPE: 5.562859486609559e-07\n",
            "E_IS_E_SCOPE: 2.3599284475257275e-06\n",
            "Total Loss: 9.155825861137541e-07\n",
            "----------------------------------------\n",
            "Epoch 537\n",
            "Var loss:  tensor(9.1059e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.337550332161378e-06\n",
            "E_s_wdiff_all_sq: 2.2528703872876508e-07\n",
            "E_IS_SCOPE: 5.46760145956851e-07\n",
            "E_IS_E_SCOPE: 2.3518266021462456e-06\n",
            "Total Loss: 9.105945170323835e-07\n",
            "----------------------------------------\n",
            "Epoch 538\n",
            "Var loss:  tensor(9.0516e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.314824321668004e-06\n",
            "E_s_wdiff_all_sq: 2.1680207403452635e-07\n",
            "E_IS_SCOPE: 5.844538868358498e-07\n",
            "E_IS_E_SCOPE: 2.3851159495944985e-06\n",
            "Total Loss: 9.051622580947388e-07\n",
            "----------------------------------------\n",
            "Epoch 539\n",
            "Var loss:  tensor(9.0024e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.321349796331393e-06\n",
            "E_s_wdiff_all_sq: 2.2059596149437426e-07\n",
            "E_IS_SCOPE: 5.964055187885204e-07\n",
            "E_IS_E_SCOPE: 2.4008938099048138e-06\n",
            "Total Loss: 9.002413885829908e-07\n",
            "----------------------------------------\n",
            "Epoch 540\n",
            "Var loss:  tensor(8.9482e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.363158581773909e-06\n",
            "E_s_wdiff_all_sq: 2.553644584754136e-07\n",
            "E_IS_SCOPE: 5.624322985627716e-07\n",
            "E_IS_E_SCOPE: 2.3731490307337948e-06\n",
            "Total Loss: 8.948247949350081e-07\n",
            "----------------------------------------\n",
            "Epoch 541\n",
            "Var loss:  tensor(8.8967e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.360509131830154e-06\n",
            "E_s_wdiff_all_sq: 2.671528440987714e-07\n",
            "E_IS_SCOPE: 5.925885455038943e-07\n",
            "E_IS_E_SCOPE: 2.3986643423545854e-06\n",
            "Total Loss: 8.896688300085596e-07\n",
            "----------------------------------------\n",
            "Epoch 542\n",
            "Var loss:  tensor(8.8446e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.3485736396592803e-06\n",
            "E_s_wdiff_all_sq: 2.6366212927795933e-07\n",
            "E_IS_SCOPE: 6.383123001918757e-07\n",
            "E_IS_E_SCOPE: 2.44277206711968e-06\n",
            "Total Loss: 8.84456112504271e-07\n",
            "----------------------------------------\n",
            "Epoch 543\n",
            "Var loss:  tensor(8.7920e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.382536755359707e-06\n",
            "E_s_wdiff_all_sq: 2.855849285969228e-07\n",
            "E_IS_SCOPE: 6.26025592869842e-07\n",
            "E_IS_E_SCOPE: 2.4391355105526775e-06\n",
            "Total Loss: 8.791961273756725e-07\n",
            "----------------------------------------\n",
            "Epoch 544\n",
            "Var loss:  tensor(8.7395e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.4111496776856536e-06\n",
            "E_s_wdiff_all_sq: 3.1385171851739187e-07\n",
            "E_IS_SCOPE: 6.07573696435432e-07\n",
            "E_IS_E_SCOPE: 2.4234816174814246e-06\n",
            "Total Loss: 8.739462530548367e-07\n",
            "----------------------------------------\n",
            "Epoch 545\n",
            "Var loss:  tensor(8.6865e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.39190018510043e-06\n",
            "E_s_wdiff_all_sq: 3.11750779570572e-07\n",
            "E_IS_SCOPE: 6.385865772324036e-07\n",
            "E_IS_E_SCOPE: 2.4485703763529165e-06\n",
            "Total Loss: 8.686459432673921e-07\n",
            "----------------------------------------\n",
            "Epoch 546\n",
            "Var loss:  tensor(8.6339e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.385550073317731e-06\n",
            "E_s_wdiff_all_sq: 3.049868780979512e-07\n",
            "E_IS_SCOPE: 6.631253473645205e-07\n",
            "E_IS_E_SCOPE: 2.475946060957529e-06\n",
            "Total Loss: 8.633859040123226e-07\n",
            "----------------------------------------\n",
            "Epoch 547\n",
            "Var loss:  tensor(8.5816e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.4136156409642333e-06\n",
            "E_s_wdiff_all_sq: 3.203966626129653e-07\n",
            "E_IS_SCOPE: 6.358985878724776e-07\n",
            "E_IS_E_SCOPE: 2.457660941943333e-06\n",
            "Total Loss: 8.581584061881171e-07\n",
            "----------------------------------------\n",
            "Epoch 548\n",
            "Var loss:  tensor(8.5293e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.4028237450551566e-06\n",
            "E_s_wdiff_all_sq: 3.181367955926596e-07\n",
            "E_IS_SCOPE: 6.598797607274771e-07\n",
            "E_IS_E_SCOPE: 2.479989448063332e-06\n",
            "Total Loss: 8.529317107693466e-07\n",
            "----------------------------------------\n",
            "Epoch 549\n",
            "Var loss:  tensor(8.4758e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.3742837054722646e-06\n",
            "E_s_wdiff_all_sq: 3.041193285133988e-07\n",
            "E_IS_SCOPE: 7.145141413028322e-07\n",
            "E_IS_E_SCOPE: 2.5300398215614535e-06\n",
            "Total Loss: 8.475771524201818e-07\n",
            "----------------------------------------\n",
            "Epoch 550\n",
            "Var loss:  tensor(8.4228e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.3886530909878345e-06\n",
            "E_s_wdiff_all_sq: 3.127574044352277e-07\n",
            "E_IS_SCOPE: 7.287337673638515e-07\n",
            "E_IS_E_SCOPE: 2.5497760318600706e-06\n",
            "Total Loss: 8.422752935387266e-07\n",
            "----------------------------------------\n",
            "Epoch 551\n",
            "Var loss:  tensor(8.3717e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.4096685433341626e-06\n",
            "E_s_wdiff_all_sq: 3.283089858929502e-07\n",
            "E_IS_SCOPE: 7.133035892236453e-07\n",
            "E_IS_E_SCOPE: 2.5396288049708485e-06\n",
            "Total Loss: 8.371732619253656e-07\n",
            "----------------------------------------\n",
            "Epoch 552\n",
            "Var loss:  tensor(8.3168e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.365715142557619e-06\n",
            "E_s_wdiff_all_sq: 3.001793636042781e-07\n",
            "E_IS_SCOPE: 7.635050298302513e-07\n",
            "E_IS_E_SCOPE: 2.5846628890965473e-06\n",
            "Total Loss: 8.316841963993083e-07\n",
            "----------------------------------------\n",
            "Epoch 553\n",
            "Var loss:  tensor(8.2655e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.3357859880676876e-06\n",
            "E_s_wdiff_all_sq: 2.7473434659939234e-07\n",
            "E_IS_SCOPE: 7.98510586119516e-07\n",
            "E_IS_E_SCOPE: 2.619993395727129e-06\n",
            "Total Loss: 8.265501582316279e-07\n",
            "----------------------------------------\n",
            "Epoch 554\n",
            "Var loss:  tensor(8.2112e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.360619460922551e-06\n",
            "E_s_wdiff_all_sq: 2.8695176854611784e-07\n",
            "E_IS_SCOPE: 7.580564628876725e-07\n",
            "E_IS_E_SCOPE: 2.588562026033967e-06\n",
            "Total Loss: 8.211207020624032e-07\n",
            "----------------------------------------\n",
            "Epoch 555\n",
            "Var loss:  tensor(8.1582e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.3360509003450214e-06\n",
            "E_s_wdiff_all_sq: 2.71697104015717e-07\n",
            "E_IS_SCOPE: 7.724734973689556e-07\n",
            "E_IS_E_SCOPE: 2.600971226624614e-06\n",
            "Total Loss: 8.158224737965464e-07\n",
            "----------------------------------------\n",
            "Epoch 556\n",
            "Var loss:  tensor(8.1054e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.293044923825829e-06\n",
            "E_s_wdiff_all_sq: 2.433512101694557e-07\n",
            "E_IS_SCOPE: 8.247794193773799e-07\n",
            "E_IS_E_SCOPE: 2.6485878266891566e-06\n",
            "Total Loss: 8.10541035011379e-07\n",
            "----------------------------------------\n",
            "Epoch 557\n",
            "Var loss:  tensor(8.0509e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.3237435271787477e-06\n",
            "E_s_wdiff_all_sq: 2.6078814302389933e-07\n",
            "E_IS_SCOPE: 8.093561853480716e-07\n",
            "E_IS_E_SCOPE: 2.6425205287706166e-06\n",
            "Total Loss: 8.050908332883164e-07\n",
            "----------------------------------------\n",
            "Epoch 558\n",
            "Var loss:  tensor(7.9986e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.3481078208938927e-06\n",
            "E_s_wdiff_all_sq: 2.835182640307836e-07\n",
            "E_IS_SCOPE: 7.974583444265722e-07\n",
            "E_IS_E_SCOPE: 2.6340576728982256e-06\n",
            "Total Loss: 7.998550358983602e-07\n",
            "----------------------------------------\n",
            "Epoch 559\n",
            "Var loss:  tensor(7.9425e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.3152878849611015e-06\n",
            "E_s_wdiff_all_sq: 2.7368967796703703e-07\n",
            "E_IS_SCOPE: 8.565788856113689e-07\n",
            "E_IS_E_SCOPE: 2.6844830769333082e-06\n",
            "Total Loss: 7.942539603287457e-07\n",
            "----------------------------------------\n",
            "Epoch 560\n",
            "Var loss:  tensor(7.8877e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.3196744874502874e-06\n",
            "E_s_wdiff_all_sq: 2.7581113541973036e-07\n",
            "E_IS_SCOPE: 8.801671849796558e-07\n",
            "E_IS_E_SCOPE: 2.7119456810305083e-06\n",
            "Total Loss: 7.887704959074106e-07\n",
            "----------------------------------------\n",
            "Epoch 561\n",
            "Var loss:  tensor(7.8307e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.359977945636433e-06\n",
            "E_s_wdiff_all_sq: 3.0120599238277874e-07\n",
            "E_IS_SCOPE: 8.540437190806817e-07\n",
            "E_IS_E_SCOPE: 2.696126083290906e-06\n",
            "Total Loss: 7.830713608117638e-07\n",
            "----------------------------------------\n",
            "Epoch 562\n",
            "Var loss:  tensor(7.7737e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.3434260313169704e-06\n",
            "E_s_wdiff_all_sq: 3.004792332012123e-07\n",
            "E_IS_SCOPE: 8.767247077018864e-07\n",
            "E_IS_E_SCOPE: 2.713744536288786e-06\n",
            "Total Loss: 7.773712769205187e-07\n",
            "----------------------------------------\n",
            "Epoch 563\n",
            "Var loss:  tensor(7.7156e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.3132141055767504e-06\n",
            "E_s_wdiff_all_sq: 2.839358197315507e-07\n",
            "E_IS_SCOPE: 9.284779350008981e-07\n",
            "E_IS_E_SCOPE: 2.7615714038299336e-06\n",
            "Total Loss: 7.715554841656873e-07\n",
            "----------------------------------------\n",
            "Epoch 564\n",
            "Var loss:  tensor(7.6568e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.327260328666214e-06\n",
            "E_s_wdiff_all_sq: 2.8459144578216434e-07\n",
            "E_IS_SCOPE: 9.183533886726573e-07\n",
            "E_IS_E_SCOPE: 2.7610791942494697e-06\n",
            "Total Loss: 7.656814077089839e-07\n",
            "----------------------------------------\n",
            "Epoch 565\n",
            "Var loss:  tensor(7.5985e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.313065907773008e-06\n",
            "E_s_wdiff_all_sq: 2.7111636150155737e-07\n",
            "E_IS_SCOPE: 9.275580941112353e-07\n",
            "E_IS_E_SCOPE: 2.772841870614562e-06\n",
            "Total Loss: 7.598461292433556e-07\n",
            "----------------------------------------\n",
            "Epoch 566\n",
            "Var loss:  tensor(7.5400e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2747675496398786e-06\n",
            "E_s_wdiff_all_sq: 2.4966599967107475e-07\n",
            "E_IS_SCOPE: 9.54882593483937e-07\n",
            "E_IS_E_SCOPE: 2.794666691557691e-06\n",
            "Total Loss: 7.539974897998555e-07\n",
            "----------------------------------------\n",
            "Epoch 567\n",
            "Var loss:  tensor(7.4809e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2758471234957413e-06\n",
            "E_s_wdiff_all_sq: 2.4919380508846974e-07\n",
            "E_IS_SCOPE: 9.528831033253221e-07\n",
            "E_IS_E_SCOPE: 2.796399307660811e-06\n",
            "Total Loss: 7.480850457148536e-07\n",
            "----------------------------------------\n",
            "Epoch 568\n",
            "Var loss:  tensor(7.4222e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.28534784546399e-06\n",
            "E_s_wdiff_all_sq: 2.5328436686638846e-07\n",
            "E_IS_SCOPE: 9.521969573341137e-07\n",
            "E_IS_E_SCOPE: 2.8013516714726305e-06\n",
            "Total Loss: 7.42218186299128e-07\n",
            "----------------------------------------\n",
            "Epoch 569\n",
            "Var loss:  tensor(7.3642e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.26876202014923e-06\n",
            "E_s_wdiff_all_sq: 2.474010169668449e-07\n",
            "E_IS_SCOPE: 9.620718804151543e-07\n",
            "E_IS_E_SCOPE: 2.8087732421960435e-06\n",
            "Total Loss: 7.364224155991663e-07\n",
            "----------------------------------------\n",
            "Epoch 570\n",
            "Var loss:  tensor(7.3059e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2380850026762347e-06\n",
            "E_s_wdiff_all_sq: 2.2708536917950652e-07\n",
            "E_IS_SCOPE: 9.879423762282973e-07\n",
            "E_IS_E_SCOPE: 2.8323774983897072e-06\n",
            "Total Loss: 7.305935251524686e-07\n",
            "----------------------------------------\n",
            "Epoch 571\n",
            "Var loss:  tensor(7.2476e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.242436625429426e-06\n",
            "E_s_wdiff_all_sq: 2.2283247953127813e-07\n",
            "E_IS_SCOPE: 9.719357859589976e-07\n",
            "E_IS_E_SCOPE: 2.8235881377075237e-06\n",
            "Total Loss: 7.247635783796555e-07\n",
            "----------------------------------------\n",
            "Epoch 572\n",
            "Var loss:  tensor(7.1895e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.245431335916404e-06\n",
            "E_s_wdiff_all_sq: 2.253343637762248e-07\n",
            "E_IS_SCOPE: 9.479160903770389e-07\n",
            "E_IS_E_SCOPE: 2.8027207618430355e-06\n",
            "Total Loss: 7.189517651867441e-07\n",
            "----------------------------------------\n",
            "Epoch 573\n",
            "Var loss:  tensor(7.1316e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2242145034961603e-06\n",
            "E_s_wdiff_all_sq: 2.179519422330686e-07\n",
            "E_IS_SCOPE: 9.536334886719746e-07\n",
            "E_IS_E_SCOPE: 2.8044152235614846e-06\n",
            "Total Loss: 7.131632274626307e-07\n",
            "----------------------------------------\n",
            "Epoch 574\n",
            "Var loss:  tensor(7.0751e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2175548987348582e-06\n",
            "E_s_wdiff_all_sq: 2.1357076724375218e-07\n",
            "E_IS_SCOPE: 9.55035417457024e-07\n",
            "E_IS_E_SCOPE: 2.8075069580042206e-06\n",
            "Total Loss: 7.075051863752712e-07\n",
            "----------------------------------------\n",
            "Epoch 575\n",
            "Var loss:  tensor(7.0162e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2443120809384886e-06\n",
            "E_s_wdiff_all_sq: 2.303126884631337e-07\n",
            "E_IS_SCOPE: 9.460544644619706e-07\n",
            "E_IS_E_SCOPE: 2.8064753725579298e-06\n",
            "Total Loss: 7.016217122619957e-07\n",
            "----------------------------------------\n",
            "Epoch 576\n",
            "Var loss:  tensor(6.9590e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.256966186647496e-06\n",
            "E_s_wdiff_all_sq: 2.4853295466455e-07\n",
            "E_IS_SCOPE: 9.605822843952324e-07\n",
            "E_IS_E_SCOPE: 2.8210821803351186e-06\n",
            "Total Loss: 6.958975760817337e-07\n",
            "----------------------------------------\n",
            "Epoch 577\n",
            "Var loss:  tensor(6.9018e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2481963600095037e-06\n",
            "E_s_wdiff_all_sq: 2.5245817604058577e-07\n",
            "E_IS_SCOPE: 9.953626566780299e-07\n",
            "E_IS_E_SCOPE: 2.8523734069939096e-06\n",
            "Total Loss: 6.901808193157171e-07\n",
            "----------------------------------------\n",
            "Epoch 578\n",
            "Var loss:  tensor(6.8444e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2630195807514883e-06\n",
            "E_s_wdiff_all_sq: 2.620398413360083e-07\n",
            "E_IS_SCOPE: 9.86636227250106e-07\n",
            "E_IS_E_SCOPE: 2.8491384384127056e-06\n",
            "Total Loss: 6.844394530688394e-07\n",
            "----------------------------------------\n",
            "Epoch 579\n",
            "Var loss:  tensor(6.7866e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.259966896968272e-06\n",
            "E_s_wdiff_all_sq: 2.5726983027610436e-07\n",
            "E_IS_SCOPE: 9.91336332246803e-07\n",
            "E_IS_E_SCOPE: 2.8575879645287056e-06\n",
            "Total Loss: 6.786579381069211e-07\n",
            "----------------------------------------\n",
            "Epoch 580\n",
            "Var loss:  tensor(6.7292e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2377891808439822e-06\n",
            "E_s_wdiff_all_sq: 2.460655023019545e-07\n",
            "E_IS_SCOPE: 1.0069740327810735e-06\n",
            "E_IS_E_SCOPE: 2.870607562117859e-06\n",
            "Total Loss: 6.729207558470156e-07\n",
            "----------------------------------------\n",
            "Epoch 581\n",
            "Var loss:  tensor(6.6717e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2396206617120114e-06\n",
            "E_s_wdiff_all_sq: 2.4896257524898126e-07\n",
            "E_IS_SCOPE: 1.0103404212662166e-06\n",
            "E_IS_E_SCOPE: 2.876318513696291e-06\n",
            "Total Loss: 6.671660375814393e-07\n",
            "----------------------------------------\n",
            "Epoch 582\n",
            "Var loss:  tensor(6.6145e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2515026209267924e-06\n",
            "E_s_wdiff_all_sq: 2.5508822580974487e-07\n",
            "E_IS_SCOPE: 1.0217880822326667e-06\n",
            "E_IS_E_SCOPE: 2.8935019958460915e-06\n",
            "Total Loss: 6.614507038687561e-07\n",
            "----------------------------------------\n",
            "Epoch 583\n",
            "Var loss:  tensor(6.5569e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2386554800298082e-06\n",
            "E_s_wdiff_all_sq: 2.496319742964593e-07\n",
            "E_IS_SCOPE: 1.056521790259119e-06\n",
            "E_IS_E_SCOPE: 2.9274197008362333e-06\n",
            "Total Loss: 6.556918205576788e-07\n",
            "----------------------------------------\n",
            "Epoch 584\n",
            "Var loss:  tensor(6.4997e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2346614154506105e-06\n",
            "E_s_wdiff_all_sq: 2.5247205584933055e-07\n",
            "E_IS_SCOPE: 1.0739716834098287e-06\n",
            "E_IS_E_SCOPE: 2.944314608438794e-06\n",
            "Total Loss: 6.499676455219086e-07\n",
            "----------------------------------------\n",
            "Epoch 585\n",
            "Var loss:  tensor(6.4424e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2544586100178715e-06\n",
            "E_s_wdiff_all_sq: 2.671753970777127e-07\n",
            "E_IS_SCOPE: 1.0605874796125552e-06\n",
            "E_IS_E_SCOPE: 2.9363394351522946e-06\n",
            "Total Loss: 6.442434378392392e-07\n",
            "----------------------------------------\n",
            "Epoch 586\n",
            "Var loss:  tensor(6.3832e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2328612122660064e-06\n",
            "E_s_wdiff_all_sq: 2.5190805239984467e-07\n",
            "E_IS_SCOPE: 1.091219356054754e-06\n",
            "E_IS_E_SCOPE: 2.9667690462757404e-06\n",
            "Total Loss: 6.383179154027489e-07\n",
            "----------------------------------------\n",
            "Epoch 587\n",
            "Var loss:  tensor(6.3260e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2186032915325535e-06\n",
            "E_s_wdiff_all_sq: 2.4297226274069125e-07\n",
            "E_IS_SCOPE: 1.1066325904542337e-06\n",
            "E_IS_E_SCOPE: 2.982381391458476e-06\n",
            "Total Loss: 6.325975627619371e-07\n",
            "----------------------------------------\n",
            "Epoch 588\n",
            "Var loss:  tensor(6.2667e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.245450229569289e-06\n",
            "E_s_wdiff_all_sq: 2.643781986539962e-07\n",
            "E_IS_SCOPE: 1.0828514917318629e-06\n",
            "E_IS_E_SCOPE: 2.9642866123561433e-06\n",
            "Total Loss: 6.26665925645291e-07\n",
            "----------------------------------------\n",
            "Epoch 589\n",
            "Var loss:  tensor(6.2087e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2506931005722597e-06\n",
            "E_s_wdiff_all_sq: 2.731598519289033e-07\n",
            "E_IS_SCOPE: 1.1001358648993774e-06\n",
            "E_IS_E_SCOPE: 2.9826987669571877e-06\n",
            "Total Loss: 6.208715805062946e-07\n",
            "----------------------------------------\n",
            "Epoch 590\n",
            "Var loss:  tensor(6.1496e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.224578514839616e-06\n",
            "E_s_wdiff_all_sq: 2.5776070367807746e-07\n",
            "E_IS_SCOPE: 1.1526845079833364e-06\n",
            "E_IS_E_SCOPE: 3.0328451075844708e-06\n",
            "Total Loss: 6.1496074793783e-07\n",
            "----------------------------------------\n",
            "Epoch 591\n",
            "Var loss:  tensor(6.0907e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2338171935493808e-06\n",
            "E_s_wdiff_all_sq: 2.6247295333835034e-07\n",
            "E_IS_SCOPE: 1.1577970066024917e-06\n",
            "E_IS_E_SCOPE: 3.0431653404325645e-06\n",
            "Total Loss: 6.090717085294444e-07\n",
            "----------------------------------------\n",
            "Epoch 592\n",
            "Var loss:  tensor(6.0319e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.255812124927235e-06\n",
            "E_s_wdiff_all_sq: 2.8037102912613373e-07\n",
            "E_IS_SCOPE: 1.1407861260691787e-06\n",
            "E_IS_E_SCOPE: 3.031144127141823e-06\n",
            "Total Loss: 6.031892296343713e-07\n",
            "----------------------------------------\n",
            "Epoch 593\n",
            "Var loss:  tensor(5.9724e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2373597155475642e-06\n",
            "E_s_wdiff_all_sq: 2.751042362829088e-07\n",
            "E_IS_SCOPE: 1.1687487227325792e-06\n",
            "E_IS_E_SCOPE: 3.0554879458425094e-06\n",
            "Total Loss: 5.972411690233541e-07\n",
            "----------------------------------------\n",
            "Epoch 594\n",
            "Var loss:  tensor(5.9135e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.236311794409092e-06\n",
            "E_s_wdiff_all_sq: 2.7554724281664347e-07\n",
            "E_IS_SCOPE: 1.1999130952292998e-06\n",
            "E_IS_E_SCOPE: 3.088854478596763e-06\n",
            "Total Loss: 5.913459208360809e-07\n",
            "----------------------------------------\n",
            "Epoch 595\n",
            "Var loss:  tensor(5.8534e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.259056513968531e-06\n",
            "E_s_wdiff_all_sq: 2.921823138868684e-07\n",
            "E_IS_SCOPE: 1.2016164648519363e-06\n",
            "E_IS_E_SCOPE: 3.096614818317503e-06\n",
            "Total Loss: 5.853416291290886e-07\n",
            "----------------------------------------\n",
            "Epoch 596\n",
            "Var loss:  tensor(5.7946e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2603674142689595e-06\n",
            "E_s_wdiff_all_sq: 2.9862288665872444e-07\n",
            "E_IS_SCOPE: 1.2186685531483593e-06\n",
            "E_IS_E_SCOPE: 3.1140406149983536e-06\n",
            "Total Loss: 5.794645398888054e-07\n",
            "----------------------------------------\n",
            "Epoch 597\n",
            "Var loss:  tensor(5.7351e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2493606345147583e-06\n",
            "E_s_wdiff_all_sq: 2.94017530014984e-07\n",
            "E_IS_SCOPE: 1.2583283525569934e-06\n",
            "E_IS_E_SCOPE: 3.1534770755035275e-06\n",
            "Total Loss: 5.735097945852653e-07\n",
            "----------------------------------------\n",
            "Epoch 598\n",
            "Var loss:  tensor(5.6760e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2648275807414475e-06\n",
            "E_s_wdiff_all_sq: 3.059412412976035e-07\n",
            "E_IS_SCOPE: 1.2515249232587657e-06\n",
            "E_IS_E_SCOPE: 3.1513992129459098e-06\n",
            "Total Loss: 5.67601896048115e-07\n",
            "----------------------------------------\n",
            "Epoch 599\n",
            "Var loss:  tensor(5.6170e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2683119282771434e-06\n",
            "E_s_wdiff_all_sq: 3.1193924330705117e-07\n",
            "E_IS_SCOPE: 1.2651455914750896e-06\n",
            "E_IS_E_SCOPE: 3.1667149436453927e-06\n",
            "Total Loss: 5.616981166080451e-07\n",
            "----------------------------------------\n",
            "Epoch 600\n",
            "Var loss:  tensor(5.5566e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.262860249660549e-06\n",
            "E_s_wdiff_all_sq: 3.1366037323848016e-07\n",
            "E_IS_SCOPE: 1.297199785871814e-06\n",
            "E_IS_E_SCOPE: 3.1982020546143883e-06\n",
            "Total Loss: 5.556594749154793e-07\n",
            "----------------------------------------\n",
            "Epoch 601\n",
            "Var loss:  tensor(5.4969e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2703606043011167e-06\n",
            "E_s_wdiff_all_sq: 3.2060713648989347e-07\n",
            "E_IS_SCOPE: 1.3235397288968974e-06\n",
            "E_IS_E_SCOPE: 3.2278022194288265e-06\n",
            "Total Loss: 5.496926227259242e-07\n",
            "----------------------------------------\n",
            "Epoch 602\n",
            "Var loss:  tensor(5.4372e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2697680734298e-06\n",
            "E_s_wdiff_all_sq: 3.196204264181271e-07\n",
            "E_IS_SCOPE: 1.3480231068186936e-06\n",
            "E_IS_E_SCOPE: 3.2554711827819735e-06\n",
            "Total Loss: 5.437156310636709e-07\n",
            "----------------------------------------\n",
            "Epoch 603\n",
            "Var loss:  tensor(5.3771e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2524601652807135e-06\n",
            "E_s_wdiff_all_sq: 3.073298066734993e-07\n",
            "E_IS_SCOPE: 1.3772414289651956e-06\n",
            "E_IS_E_SCOPE: 3.285184003140716e-06\n",
            "Total Loss: 5.377093462347327e-07\n",
            "----------------------------------------\n",
            "Epoch 604\n",
            "Var loss:  tensor(5.3169e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.24185760120832e-06\n",
            "E_s_wdiff_all_sq: 2.994421034708892e-07\n",
            "E_IS_SCOPE: 1.3884126024038948e-06\n",
            "E_IS_E_SCOPE: 3.2980070785378944e-06\n",
            "Total Loss: 5.316906814479915e-07\n",
            "----------------------------------------\n",
            "Epoch 605\n",
            "Var loss:  tensor(5.2563e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.248607857830798e-06\n",
            "E_s_wdiff_all_sq: 3.0396387269468115e-07\n",
            "E_IS_SCOPE: 1.3774438794764842e-06\n",
            "E_IS_E_SCOPE: 3.2911825218383936e-06\n",
            "Total Loss: 5.25630836390858e-07\n",
            "----------------------------------------\n",
            "Epoch 606\n",
            "Var loss:  tensor(5.1966e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2445200607587246e-06\n",
            "E_s_wdiff_all_sq: 3.0443667617570873e-07\n",
            "E_IS_SCOPE: 1.3795284815736202e-06\n",
            "E_IS_E_SCOPE: 3.2939715949572012e-06\n",
            "Total Loss: 5.196612937944133e-07\n",
            "----------------------------------------\n",
            "Epoch 607\n",
            "Var loss:  tensor(5.1370e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2339100196109417e-06\n",
            "E_s_wdiff_all_sq: 2.999064497742989e-07\n",
            "E_IS_SCOPE: 1.4005414695064846e-06\n",
            "E_IS_E_SCOPE: 3.3149260067031952e-06\n",
            "Total Loss: 5.13698631421781e-07\n",
            "----------------------------------------\n",
            "Epoch 608\n",
            "Var loss:  tensor(5.0767e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2474089085945262e-06\n",
            "E_s_wdiff_all_sq: 3.090719138220447e-07\n",
            "E_IS_SCOPE: 1.4111958381512922e-06\n",
            "E_IS_E_SCOPE: 3.330759768156135e-06\n",
            "Total Loss: 5.076732707413548e-07\n",
            "----------------------------------------\n",
            "Epoch 609\n",
            "Var loss:  tensor(5.0157e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2283751821163657e-06\n",
            "E_s_wdiff_all_sq: 2.941630005280119e-07\n",
            "E_IS_SCOPE: 1.461473452852798e-06\n",
            "E_IS_E_SCOPE: 3.3820260028339968e-06\n",
            "Total Loss: 5.015712176045159e-07\n",
            "----------------------------------------\n",
            "Epoch 610\n",
            "Var loss:  tensor(4.9555e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2253938355385383e-06\n",
            "E_s_wdiff_all_sq: 2.916215801783846e-07\n",
            "E_IS_SCOPE: 1.5021794932598151e-06\n",
            "E_IS_E_SCOPE: 3.4255246355886665e-06\n",
            "Total Loss: 4.955461066810106e-07\n",
            "----------------------------------------\n",
            "Epoch 611\n",
            "Var loss:  tensor(4.8957e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2369926623585634e-06\n",
            "E_s_wdiff_all_sq: 3.0349467552556477e-07\n",
            "E_IS_SCOPE: 1.509484363856347e-06\n",
            "E_IS_E_SCOPE: 3.435682227540257e-06\n",
            "Total Loss: 4.895663954437371e-07\n",
            "----------------------------------------\n",
            "Epoch 612\n",
            "Var loss:  tensor(4.8344e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2411539812723383e-06\n",
            "E_s_wdiff_all_sq: 3.1038036726619944e-07\n",
            "E_IS_SCOPE: 1.5276020175121659e-06\n",
            "E_IS_E_SCOPE: 3.4555013077409027e-06\n",
            "Total Loss: 4.834391695272244e-07\n",
            "----------------------------------------\n",
            "Epoch 613\n",
            "Var loss:  tensor(4.7742e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.236210509755638e-06\n",
            "E_s_wdiff_all_sq: 3.093381307434432e-07\n",
            "E_IS_SCOPE: 1.5509363462286457e-06\n",
            "E_IS_E_SCOPE: 3.4798957107565637e-06\n",
            "Total Loss: 4.77417785934918e-07\n",
            "----------------------------------------\n",
            "Epoch 614\n",
            "Var loss:  tensor(4.7144e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2411157037868107e-06\n",
            "E_s_wdiff_all_sq: 3.154044169670031e-07\n",
            "E_IS_SCOPE: 1.5601004371754655e-06\n",
            "E_IS_E_SCOPE: 3.491467353143743e-06\n",
            "Total Loss: 4.7144159086181054e-07\n",
            "----------------------------------------\n",
            "Epoch 615\n",
            "Var loss:  tensor(4.6542e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.255977162871443e-06\n",
            "E_s_wdiff_all_sq: 3.3002967116542693e-07\n",
            "E_IS_SCOPE: 1.5758054723984116e-06\n",
            "E_IS_E_SCOPE: 3.5103031986305652e-06\n",
            "Total Loss: 4.654161752202675e-07\n",
            "----------------------------------------\n",
            "Epoch 616\n",
            "Var loss:  tensor(4.5936e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.262139180139065e-06\n",
            "E_s_wdiff_all_sq: 3.3824121584286047e-07\n",
            "E_IS_SCOPE: 1.6241902957967752e-06\n",
            "E_IS_E_SCOPE: 3.560692986682212e-06\n",
            "Total Loss: 4.5935671850388954e-07\n",
            "----------------------------------------\n",
            "Epoch 617\n",
            "Var loss:  tensor(4.5343e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.258246892995184e-06\n",
            "E_s_wdiff_all_sq: 3.392610865360801e-07\n",
            "E_IS_SCOPE: 1.6825371484604408e-06\n",
            "E_IS_E_SCOPE: 3.619548082462443e-06\n",
            "Total Loss: 4.5342807443365795e-07\n",
            "----------------------------------------\n",
            "Epoch 618\n",
            "Var loss:  tensor(4.4742e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.271098463660864e-06\n",
            "E_s_wdiff_all_sq: 3.519092089353212e-07\n",
            "E_IS_SCOPE: 1.7017096076100197e-06\n",
            "E_IS_E_SCOPE: 3.6418239847815672e-06\n",
            "Total Loss: 4.474246363610073e-07\n",
            "----------------------------------------\n",
            "Epoch 619\n",
            "Var loss:  tensor(4.4137e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.260784366413786e-06\n",
            "E_s_wdiff_all_sq: 3.433957072542021e-07\n",
            "E_IS_SCOPE: 1.7395763553163468e-06\n",
            "E_IS_E_SCOPE: 3.6818182077071913e-06\n",
            "Total Loss: 4.4136909035645504e-07\n",
            "----------------------------------------\n",
            "Epoch 620\n",
            "Var loss:  tensor(4.3540e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.244331577786646e-06\n",
            "E_s_wdiff_all_sq: 3.2985247931569267e-07\n",
            "E_IS_SCOPE: 1.7742486251398483e-06\n",
            "E_IS_E_SCOPE: 3.7180184475059403e-06\n",
            "Total Loss: 4.3540358971732795e-07\n",
            "----------------------------------------\n",
            "Epoch 621\n",
            "Var loss:  tensor(4.2926e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2462736541017063e-06\n",
            "E_s_wdiff_all_sq: 3.328562377262064e-07\n",
            "E_IS_SCOPE: 1.7756284541919687e-06\n",
            "E_IS_E_SCOPE: 3.7219368639357985e-06\n",
            "Total Loss: 4.292647328663994e-07\n",
            "----------------------------------------\n",
            "Epoch 622\n",
            "Var loss:  tensor(4.2323e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2426472388389147e-06\n",
            "E_s_wdiff_all_sq: 3.3209011374722853e-07\n",
            "E_IS_SCOPE: 1.7713313656761881e-06\n",
            "E_IS_E_SCOPE: 3.7192249391182126e-06\n",
            "Total Loss: 4.232341141861951e-07\n",
            "----------------------------------------\n",
            "Epoch 623\n",
            "Var loss:  tensor(4.1723e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.225430846563035e-06\n",
            "E_s_wdiff_all_sq: 3.1664773408779603e-07\n",
            "E_IS_SCOPE: 1.7868687048432554e-06\n",
            "E_IS_E_SCOPE: 3.7368767815882548e-06\n",
            "Total Loss: 4.1723109496379933e-07\n",
            "----------------------------------------\n",
            "Epoch 624\n",
            "Var loss:  tensor(4.1117e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2266819022807336e-06\n",
            "E_s_wdiff_all_sq: 3.1524439814264154e-07\n",
            "E_IS_SCOPE: 1.800910216802975e-06\n",
            "E_IS_E_SCOPE: 3.755278054555724e-06\n",
            "Total Loss: 4.1116596461115303e-07\n",
            "----------------------------------------\n",
            "Epoch 625\n",
            "Var loss:  tensor(4.0515e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.232707061654333e-06\n",
            "E_s_wdiff_all_sq: 3.244018384611563e-07\n",
            "E_IS_SCOPE: 1.8212656364516573e-06\n",
            "E_IS_E_SCOPE: 3.7770748579451977e-06\n",
            "Total Loss: 4.0515091618465476e-07\n",
            "----------------------------------------\n",
            "Epoch 626\n",
            "Var loss:  tensor(3.9902e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2344898824431702e-06\n",
            "E_s_wdiff_all_sq: 3.307909705194295e-07\n",
            "E_IS_SCOPE: 1.8552415168141906e-06\n",
            "E_IS_E_SCOPE: 3.8118136778402394e-06\n",
            "Total Loss: 3.990187258502019e-07\n",
            "----------------------------------------\n",
            "Epoch 627\n",
            "Var loss:  tensor(3.9292e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.248367576496485e-06\n",
            "E_s_wdiff_all_sq: 3.43862129643813e-07\n",
            "E_IS_SCOPE: 1.8726897216058854e-06\n",
            "E_IS_E_SCOPE: 3.8327137779035945e-06\n",
            "Total Loss: 3.929214702358144e-07\n",
            "----------------------------------------\n",
            "Epoch 628\n",
            "Var loss:  tensor(3.8679e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.260869063382661e-06\n",
            "E_s_wdiff_all_sq: 3.6069737381370897e-07\n",
            "E_IS_SCOPE: 1.8801491230879224e-06\n",
            "E_IS_E_SCOPE: 3.8410706121151966e-06\n",
            "Total Loss: 3.8679284749296443e-07\n",
            "----------------------------------------\n",
            "Epoch 629\n",
            "Var loss:  tensor(3.8067e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.264616896994879e-06\n",
            "E_s_wdiff_all_sq: 3.682851366391215e-07\n",
            "E_IS_SCOPE: 1.8943935062112193e-06\n",
            "E_IS_E_SCOPE: 3.856456126225359e-06\n",
            "Total Loss: 3.8067065630603817e-07\n",
            "----------------------------------------\n",
            "Epoch 630\n",
            "Var loss:  tensor(3.7452e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2572150824266753e-06\n",
            "E_s_wdiff_all_sq: 3.607300366438496e-07\n",
            "E_IS_SCOPE: 1.9206233529533897e-06\n",
            "E_IS_E_SCOPE: 3.885836010835969e-06\n",
            "Total Loss: 3.745238659962272e-07\n",
            "----------------------------------------\n",
            "Epoch 631\n",
            "Var loss:  tensor(3.6834e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2580045290487592e-06\n",
            "E_s_wdiff_all_sq: 3.59086048450775e-07\n",
            "E_IS_SCOPE: 1.951631221834988e-06\n",
            "E_IS_E_SCOPE: 3.921153279813743e-06\n",
            "Total Loss: 3.683385006190324e-07\n",
            "----------------------------------------\n",
            "Epoch 632\n",
            "Var loss:  tensor(3.6217e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2549791378680485e-06\n",
            "E_s_wdiff_all_sq: 3.5994234711898803e-07\n",
            "E_IS_SCOPE: 1.9768041458399792e-06\n",
            "E_IS_E_SCOPE: 3.947470724443539e-06\n",
            "Total Loss: 3.621677695205016e-07\n",
            "----------------------------------------\n",
            "Epoch 633\n",
            "Var loss:  tensor(3.5599e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.245187905299043e-06\n",
            "E_s_wdiff_all_sq: 3.551960195024832e-07\n",
            "E_IS_SCOPE: 2.00172149623202e-06\n",
            "E_IS_E_SCOPE: 3.972956032475408e-06\n",
            "Total Loss: 3.559869492883433e-07\n",
            "----------------------------------------\n",
            "Epoch 634\n",
            "Var loss:  tensor(3.4981e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2465072993399152e-06\n",
            "E_s_wdiff_all_sq: 3.541057065301905e-07\n",
            "E_IS_SCOPE: 2.0272032385386057e-06\n",
            "E_IS_E_SCOPE: 4.002731448984982e-06\n",
            "Total Loss: 3.4980930789553057e-07\n",
            "----------------------------------------\n",
            "Epoch 635\n",
            "Var loss:  tensor(3.4356e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2491637759123156e-06\n",
            "E_s_wdiff_all_sq: 3.5752096802892586e-07\n",
            "E_IS_SCOPE: 2.029248788347472e-06\n",
            "E_IS_E_SCOPE: 4.007522705921879e-06\n",
            "Total Loss: 3.435591087131344e-07\n",
            "----------------------------------------\n",
            "Epoch 636\n",
            "Var loss:  tensor(3.3715e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.218155327345463e-06\n",
            "E_s_wdiff_all_sq: 3.3565485004275365e-07\n",
            "E_IS_SCOPE: 2.0627585028486317e-06\n",
            "E_IS_E_SCOPE: 4.039667479989844e-06\n",
            "Total Loss: 3.3714665899884415e-07\n",
            "----------------------------------------\n",
            "Epoch 637\n",
            "Var loss:  tensor(3.3083e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.214276610319048e-06\n",
            "E_s_wdiff_all_sq: 3.276810249641645e-07\n",
            "E_IS_SCOPE: 2.0687528059994885e-06\n",
            "E_IS_E_SCOPE: 4.0508692251862965e-06\n",
            "Total Loss: 3.3082688295982615e-07\n",
            "----------------------------------------\n",
            "Epoch 638\n",
            "Var loss:  tensor(3.2436e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.223425138507047e-06\n",
            "E_s_wdiff_all_sq: 3.367636720942219e-07\n",
            "E_IS_SCOPE: 2.0686714879413473e-06\n",
            "E_IS_E_SCOPE: 4.05405444516103e-06\n",
            "Total Loss: 3.243596879520188e-07\n",
            "----------------------------------------\n",
            "Epoch 639\n",
            "Var loss:  tensor(3.1793e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2005812260195713e-06\n",
            "E_s_wdiff_all_sq: 3.2630361330439466e-07\n",
            "E_IS_SCOPE: 2.097007097911657e-06\n",
            "E_IS_E_SCOPE: 4.079411682920377e-06\n",
            "Total Loss: 3.179325786762952e-07\n",
            "----------------------------------------\n",
            "Epoch 640\n",
            "Var loss:  tensor(3.1147e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2032392870881816e-06\n",
            "E_s_wdiff_all_sq: 3.2223829777810466e-07\n",
            "E_IS_SCOPE: 2.106631353276159e-06\n",
            "E_IS_E_SCOPE: 4.095627284646267e-06\n",
            "Total Loss: 3.114732625484206e-07\n",
            "----------------------------------------\n",
            "Epoch 641\n",
            "Var loss:  tensor(3.0500e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2165749105955744e-06\n",
            "E_s_wdiff_all_sq: 3.3160252721753573e-07\n",
            "E_IS_SCOPE: 2.1168202711440745e-06\n",
            "E_IS_E_SCOPE: 4.111037282931814e-06\n",
            "Total Loss: 3.050024957811201e-07\n",
            "----------------------------------------\n",
            "Epoch 642\n",
            "Var loss:  tensor(2.9852e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1985805243726655e-06\n",
            "E_s_wdiff_all_sq: 3.2944675124329226e-07\n",
            "E_IS_SCOPE: 2.151706422022086e-06\n",
            "E_IS_E_SCOPE: 4.141244383912663e-06\n",
            "Total Loss: 2.985219853267777e-07\n",
            "----------------------------------------\n",
            "Epoch 643\n",
            "Var loss:  tensor(2.9196e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2014093753835503e-06\n",
            "E_s_wdiff_all_sq: 3.2927412838136677e-07\n",
            "E_IS_SCOPE: 2.1714671013577705e-06\n",
            "E_IS_E_SCOPE: 4.165784430989039e-06\n",
            "Total Loss: 2.9196472371820533e-07\n",
            "----------------------------------------\n",
            "Epoch 644\n",
            "Var loss:  tensor(2.8548e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2153522326579296e-06\n",
            "E_s_wdiff_all_sq: 3.3625427255201523e-07\n",
            "E_IS_SCOPE: 2.176964936786311e-06\n",
            "E_IS_E_SCOPE: 4.1780076569731285e-06\n",
            "Total Loss: 2.854766557108393e-07\n",
            "----------------------------------------\n",
            "Epoch 645\n",
            "Var loss:  tensor(2.7891e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.207290320937804e-06\n",
            "E_s_wdiff_all_sq: 3.409992874475864e-07\n",
            "E_IS_SCOPE: 2.202420876625219e-06\n",
            "E_IS_E_SCOPE: 4.20034544887669e-06\n",
            "Total Loss: 2.789060249658347e-07\n",
            "----------------------------------------\n",
            "Epoch 646\n",
            "Var loss:  tensor(2.7237e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2219898924947574e-06\n",
            "E_s_wdiff_all_sq: 3.55972586045192e-07\n",
            "E_IS_SCOPE: 2.2196038711529585e-06\n",
            "E_IS_E_SCOPE: 4.220660610605615e-06\n",
            "Total Loss: 2.7236796352281136e-07\n",
            "----------------------------------------\n",
            "Epoch 647\n",
            "Var loss:  tensor(2.6578e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.242007600763104e-06\n",
            "E_s_wdiff_all_sq: 3.704228191913165e-07\n",
            "E_IS_SCOPE: 2.2257822598856357e-06\n",
            "E_IS_E_SCOPE: 4.2329164882856714e-06\n",
            "Total Loss: 2.6578046075027464e-07\n",
            "----------------------------------------\n",
            "Epoch 648\n",
            "Var loss:  tensor(2.5917e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.234759966936325e-06\n",
            "E_s_wdiff_all_sq: 3.711542004520499e-07\n",
            "E_IS_SCOPE: 2.247656604695954e-06\n",
            "E_IS_E_SCOPE: 4.254107199829561e-06\n",
            "Total Loss: 2.591687121956201e-07\n",
            "----------------------------------------\n",
            "Epoch 649\n",
            "Var loss:  tensor(2.5249e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2389468845821076e-06\n",
            "E_s_wdiff_all_sq: 3.772520219882266e-07\n",
            "E_IS_SCOPE: 2.270816283522902e-06\n",
            "E_IS_E_SCOPE: 4.27964868209955e-06\n",
            "Total Loss: 2.5249420141914345e-07\n",
            "----------------------------------------\n",
            "Epoch 650\n",
            "Var loss:  tensor(2.4587e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.246734408239045e-06\n",
            "E_s_wdiff_all_sq: 3.8188370945548316e-07\n",
            "E_IS_SCOPE: 2.284497072633958e-06\n",
            "E_IS_E_SCOPE: 4.298220488394748e-06\n",
            "Total Loss: 2.458680032405411e-07\n",
            "----------------------------------------\n",
            "Epoch 651\n",
            "Var loss:  tensor(2.3921e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2398732584382196e-06\n",
            "E_s_wdiff_all_sq: 3.8049429669704534e-07\n",
            "E_IS_SCOPE: 2.303701660149864e-06\n",
            "E_IS_E_SCOPE: 4.3180202019836855e-06\n",
            "Total Loss: 2.3920601405209076e-07\n",
            "----------------------------------------\n",
            "Epoch 652\n",
            "Var loss:  tensor(2.3257e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2570998837393893e-06\n",
            "E_s_wdiff_all_sq: 3.9763588834061256e-07\n",
            "E_IS_SCOPE: 2.302122399532701e-06\n",
            "E_IS_E_SCOPE: 4.319799633003183e-06\n",
            "Total Loss: 2.3257366443637271e-07\n",
            "----------------------------------------\n",
            "Epoch 653\n",
            "Var loss:  tensor(2.2572e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2487263200924656e-06\n",
            "E_s_wdiff_all_sq: 3.9350040767359296e-07\n",
            "E_IS_SCOPE: 2.325695806428968e-06\n",
            "E_IS_E_SCOPE: 4.344683054459093e-06\n",
            "Total Loss: 2.2571555233718153e-07\n",
            "----------------------------------------\n",
            "Epoch 654\n",
            "Var loss:  tensor(2.1893e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2412212393661758e-06\n",
            "E_s_wdiff_all_sq: 3.8879511596531374e-07\n",
            "E_IS_SCOPE: 2.3414048259137336e-06\n",
            "E_IS_E_SCOPE: 4.3623850673042e-06\n",
            "Total Loss: 2.1892977659848854e-07\n",
            "----------------------------------------\n",
            "Epoch 655\n",
            "Var loss:  tensor(2.1206e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2479970421876607e-06\n",
            "E_s_wdiff_all_sq: 3.947274892870171e-07\n",
            "E_IS_SCOPE: 2.3348581666094702e-06\n",
            "E_IS_E_SCOPE: 4.3596944993372585e-06\n",
            "Total Loss: 2.1206102342362628e-07\n",
            "----------------------------------------\n",
            "Epoch 656\n",
            "Var loss:  tensor(2.0520e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2339635315825162e-06\n",
            "E_s_wdiff_all_sq: 3.844018133698357e-07\n",
            "E_IS_SCOPE: 2.346557263040534e-06\n",
            "E_IS_E_SCOPE: 4.372971564161654e-06\n",
            "Total Loss: 2.0519725194900078e-07\n",
            "----------------------------------------\n",
            "Epoch 657\n",
            "Var loss:  tensor(1.9833e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2205388662363778e-06\n",
            "E_s_wdiff_all_sq: 3.7274134122040383e-07\n",
            "E_IS_SCOPE: 2.3740470411101714e-06\n",
            "E_IS_E_SCOPE: 4.403012227765751e-06\n",
            "Total Loss: 1.9833128768337412e-07\n",
            "----------------------------------------\n",
            "Epoch 658\n",
            "Var loss:  tensor(1.9140e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2248885560726926e-06\n",
            "E_s_wdiff_all_sq: 3.7549395818298113e-07\n",
            "E_IS_SCOPE: 2.379264954457476e-06\n",
            "E_IS_E_SCOPE: 4.412492695295546e-06\n",
            "Total Loss: 1.9140325219213023e-07\n",
            "----------------------------------------\n",
            "Epoch 659\n",
            "Var loss:  tensor(1.8447e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2205181739947852e-06\n",
            "E_s_wdiff_all_sq: 3.7681578702998515e-07\n",
            "E_IS_SCOPE: 2.3915451687938433e-06\n",
            "E_IS_E_SCOPE: 4.425391640058188e-06\n",
            "Total Loss: 1.8447358041466998e-07\n",
            "----------------------------------------\n",
            "Epoch 660\n",
            "Var loss:  tensor(1.7753e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2066982178729144e-06\n",
            "E_s_wdiff_all_sq: 3.657486106293631e-07\n",
            "E_IS_SCOPE: 2.417758113108464e-06\n",
            "E_IS_E_SCOPE: 4.4536987405378595e-06\n",
            "Total Loss: 1.7753248836331821e-07\n",
            "----------------------------------------\n",
            "Epoch 661\n",
            "Var loss:  tensor(1.7053e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.214022114399888e-06\n",
            "E_s_wdiff_all_sq: 3.6733575601006134e-07\n",
            "E_IS_SCOPE: 2.4426972488885567e-06\n",
            "E_IS_E_SCOPE: 4.485005305041184e-06\n",
            "Total Loss: 1.7053438206313275e-07\n",
            "----------------------------------------\n",
            "Epoch 662\n",
            "Var loss:  tensor(1.6354e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.206137412145002e-06\n",
            "E_s_wdiff_all_sq: 3.6865937071009277e-07\n",
            "E_IS_SCOPE: 2.468569393324447e-06\n",
            "E_IS_E_SCOPE: 4.509772171447652e-06\n",
            "Total Loss: 1.6353662116705657e-07\n",
            "----------------------------------------\n",
            "Epoch 663\n",
            "Var loss:  tensor(1.5649e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2124525750186468e-06\n",
            "E_s_wdiff_all_sq: 3.767388825823589e-07\n",
            "E_IS_SCOPE: 2.4754162560248673e-06\n",
            "E_IS_E_SCOPE: 4.519258361521757e-06\n",
            "Total Loss: 1.5649361742106732e-07\n",
            "----------------------------------------\n",
            "Epoch 664\n",
            "Var loss:  tensor(1.4945e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2248339704008734e-06\n",
            "E_s_wdiff_all_sq: 3.8490516519282626e-07\n",
            "E_IS_SCOPE: 2.474739778043193e-06\n",
            "E_IS_E_SCOPE: 4.524210960346207e-06\n",
            "Total Loss: 1.494505765805798e-07\n",
            "----------------------------------------\n",
            "Epoch 665\n",
            "Var loss:  tensor(1.4239e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2269800221462008e-06\n",
            "E_s_wdiff_all_sq: 3.9261517892597944e-07\n",
            "E_IS_SCOPE: 2.4994624871682766e-06\n",
            "E_IS_E_SCOPE: 4.549683695255213e-06\n",
            "Total Loss: 1.423865630249059e-07\n",
            "----------------------------------------\n",
            "Epoch 666\n",
            "Var loss:  tensor(1.3528e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.221661133561339e-06\n",
            "E_s_wdiff_all_sq: 3.944651808145178e-07\n",
            "E_IS_SCOPE: 2.528040470007649e-06\n",
            "E_IS_E_SCOPE: 4.578231325275946e-06\n",
            "Total Loss: 1.3527837818878599e-07\n",
            "----------------------------------------\n",
            "Epoch 667\n",
            "Var loss:  tensor(1.2816e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.230141934987435e-06\n",
            "E_s_wdiff_all_sq: 3.970999121424454e-07\n",
            "E_IS_SCOPE: 2.540352555526112e-06\n",
            "E_IS_E_SCOPE: 4.5970231660103335e-06\n",
            "Total Loss: 1.2816493785510673e-07\n",
            "----------------------------------------\n",
            "Epoch 668\n",
            "Var loss:  tensor(1.2104e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.222622133813054e-06\n",
            "E_s_wdiff_all_sq: 3.9312473121636056e-07\n",
            "E_IS_SCOPE: 2.5560931543532927e-06\n",
            "E_IS_E_SCOPE: 4.614554102840906e-06\n",
            "Total Loss: 1.2103964160002676e-07\n",
            "----------------------------------------\n",
            "Epoch 669\n",
            "Var loss:  tensor(1.1394e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.237442028358048e-06\n",
            "E_s_wdiff_all_sq: 4.085595275811587e-07\n",
            "E_IS_SCOPE: 2.5562405120262396e-06\n",
            "E_IS_E_SCOPE: 4.6179433188798005e-06\n",
            "Total Loss: 1.139410230483267e-07\n",
            "----------------------------------------\n",
            "Epoch 670\n",
            "Var loss:  tensor(1.0670e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.219833436629302e-06\n",
            "E_s_wdiff_all_sq: 3.9519493939255096e-07\n",
            "E_IS_SCOPE: 2.5888784987358574e-06\n",
            "E_IS_E_SCOPE: 4.652079872229377e-06\n",
            "Total Loss: 1.0669988622827038e-07\n",
            "----------------------------------------\n",
            "Epoch 671\n",
            "Var loss:  tensor(9.9560e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2179417698391487e-06\n",
            "E_s_wdiff_all_sq: 3.912730294567337e-07\n",
            "E_IS_SCOPE: 2.604621424182304e-06\n",
            "E_IS_E_SCOPE: 4.672407824936846e-06\n",
            "Total Loss: 9.956007485188981e-08\n",
            "----------------------------------------\n",
            "Epoch 672\n",
            "Var loss:  tensor(9.2390e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.239969242618583e-06\n",
            "E_s_wdiff_all_sq: 4.120811604776457e-07\n",
            "E_IS_SCOPE: 2.6093328720222905e-06\n",
            "E_IS_E_SCOPE: 4.681313856339143e-06\n",
            "Total Loss: 9.239024948578986e-08\n",
            "----------------------------------------\n",
            "Epoch 673\n",
            "Var loss:  tensor(8.5174e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.218249656883264e-06\n",
            "E_s_wdiff_all_sq: 4.0388497269451034e-07\n",
            "E_IS_SCOPE: 2.648579602258282e-06\n",
            "E_IS_E_SCOPE: 4.717406843806228e-06\n",
            "Total Loss: 8.517433707141983e-08\n",
            "----------------------------------------\n",
            "Epoch 674\n",
            "Var loss:  tensor(7.8165e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.219244329124313e-06\n",
            "E_s_wdiff_all_sq: 3.9907255397436496e-07\n",
            "E_IS_SCOPE: 2.6618092943317736e-06\n",
            "E_IS_E_SCOPE: 4.737044733077263e-06\n",
            "Total Loss: 7.816503363752776e-08\n",
            "----------------------------------------\n",
            "Epoch 675\n",
            "Var loss:  tensor(7.1034e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2311028027516063e-06\n",
            "E_s_wdiff_all_sq: 4.0752270807000004e-07\n",
            "E_IS_SCOPE: 2.6497953447688235e-06\n",
            "E_IS_E_SCOPE: 4.7303003501949066e-06\n",
            "Total Loss: 7.103421980800053e-08\n",
            "----------------------------------------\n",
            "Epoch 676\n",
            "Var loss:  tensor(6.4026e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2136506769488574e-06\n",
            "E_s_wdiff_all_sq: 4.019766030158652e-07\n",
            "E_IS_SCOPE: 2.658413986767181e-06\n",
            "E_IS_E_SCOPE: 4.736470318388636e-06\n",
            "Total Loss: 6.402554666864195e-08\n",
            "----------------------------------------\n",
            "Epoch 677\n",
            "Var loss:  tensor(5.6904e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.217226240723488e-06\n",
            "E_s_wdiff_all_sq: 3.991001956603457e-07\n",
            "E_IS_SCOPE: 2.677503019811535e-06\n",
            "E_IS_E_SCOPE: 4.762345948756039e-06\n",
            "Total Loss: 5.690432315269246e-08\n",
            "----------------------------------------\n",
            "Epoch 678\n",
            "Var loss:  tensor(4.9829e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2259802611471376e-06\n",
            "E_s_wdiff_all_sq: 4.0558208641675033e-07\n",
            "E_IS_SCOPE: 2.7181638404328417e-06\n",
            "E_IS_E_SCOPE: 4.8076806572741305e-06\n",
            "Total Loss: 4.9828677026369124e-08\n",
            "----------------------------------------\n",
            "Epoch 679\n",
            "Var loss:  tensor(4.2727e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2160419020424935e-06\n",
            "E_s_wdiff_all_sq: 4.1104971141012735e-07\n",
            "E_IS_SCOPE: 2.755885116637818e-06\n",
            "E_IS_E_SCOPE: 4.84124982964535e-06\n",
            "Total Loss: 4.272690059586125e-08\n",
            "----------------------------------------\n",
            "Epoch 680\n",
            "Var loss:  tensor(3.5568e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.232510576964226e-06\n",
            "E_s_wdiff_all_sq: 4.2220155578569636e-07\n",
            "E_IS_SCOPE: 2.7600485524319895e-06\n",
            "E_IS_E_SCOPE: 4.85165121203897e-06\n",
            "Total Loss: 3.55678379431267e-08\n",
            "----------------------------------------\n",
            "Epoch 681\n",
            "Var loss:  tensor(2.8353e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.234523568397558e-06\n",
            "E_s_wdiff_all_sq: 4.1878277227783956e-07\n",
            "E_IS_SCOPE: 2.765806558426553e-06\n",
            "E_IS_E_SCOPE: 4.863732584522189e-06\n",
            "Total Loss: 2.8352879907004707e-08\n",
            "----------------------------------------\n",
            "Epoch 682\n",
            "Var loss:  tensor(2.1068e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2138873931998373e-06\n",
            "E_s_wdiff_all_sq: 4.1079884777412644e-07\n",
            "E_IS_SCOPE: 2.7784712623707886e-06\n",
            "E_IS_E_SCOPE: 4.873713697461967e-06\n",
            "Total Loss: 2.1067811221913172e-08\n",
            "----------------------------------------\n",
            "Epoch 683\n",
            "Var loss:  tensor(1.3764e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.218517778787585e-06\n",
            "E_s_wdiff_all_sq: 4.1361715760921757e-07\n",
            "E_IS_SCOPE: 2.7657590317054747e-06\n",
            "E_IS_E_SCOPE: 4.865559470430571e-06\n",
            "Total Loss: 1.3763879706734249e-08\n",
            "----------------------------------------\n",
            "Epoch 684\n",
            "Var loss:  tensor(6.4754e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.216419957893575e-06\n",
            "E_s_wdiff_all_sq: 4.0593360974084905e-07\n",
            "E_IS_SCOPE: 2.764133565171533e-06\n",
            "E_IS_E_SCOPE: 4.870371088192987e-06\n",
            "Total Loss: 6.4754380883766755e-09\n",
            "----------------------------------------\n",
            "Epoch 685\n",
            "Var loss:  tensor(-8.7346e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.192023810815136e-06\n",
            "E_s_wdiff_all_sq: 3.917722140356828e-07\n",
            "E_IS_SCOPE: 2.8005205297130975e-06\n",
            "E_IS_E_SCOPE: 4.905315125480908e-06\n",
            "Total Loss: -8.734587776073519e-10\n",
            "----------------------------------------\n",
            "Epoch 686\n",
            "Var loss:  tensor(-8.1300e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.198966065080738e-06\n",
            "E_s_wdiff_all_sq: 3.9721632945296996e-07\n",
            "E_IS_SCOPE: 2.8222695926208903e-06\n",
            "E_IS_E_SCOPE: 4.931441543804423e-06\n",
            "Total Loss: -8.130030760738776e-09\n",
            "----------------------------------------\n",
            "Epoch 687\n",
            "Var loss:  tensor(-1.5540e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.19664384581796e-06\n",
            "E_s_wdiff_all_sq: 3.9372311542898034e-07\n",
            "E_IS_SCOPE: 2.842225184623148e-06\n",
            "E_IS_E_SCOPE: 4.955687696675159e-06\n",
            "Total Loss: -1.5540157736482686e-08\n",
            "----------------------------------------\n",
            "Epoch 688\n",
            "Var loss:  tensor(-2.2913e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1758770228611676e-06\n",
            "E_s_wdiff_all_sq: 3.7833399758750514e-07\n",
            "E_IS_SCOPE: 2.8642699617149128e-06\n",
            "E_IS_E_SCOPE: 4.978730044557252e-06\n",
            "Total Loss: -2.2913004432458894e-08\n",
            "----------------------------------------\n",
            "Epoch 689\n",
            "Var loss:  tensor(-3.0377e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.165711171252185e-06\n",
            "E_s_wdiff_all_sq: 3.701717544263617e-07\n",
            "E_IS_SCOPE: 2.8625782464171955e-06\n",
            "E_IS_E_SCOPE: 4.979768379703445e-06\n",
            "Total Loss: -3.0376713768115125e-08\n",
            "----------------------------------------\n",
            "Epoch 690\n",
            "Var loss:  tensor(-3.7802e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1578267367809873e-06\n",
            "E_s_wdiff_all_sq: 3.611305089646108e-07\n",
            "E_IS_SCOPE: 2.8568876364340063e-06\n",
            "E_IS_E_SCOPE: 4.978368821670012e-06\n",
            "Total Loss: -3.780200667707595e-08\n",
            "----------------------------------------\n",
            "Epoch 691\n",
            "Var loss:  tensor(-4.5234e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.142587040652238e-06\n",
            "E_s_wdiff_all_sq: 3.48900420131752e-07\n",
            "E_IS_SCOPE: 2.8638578739285097e-06\n",
            "E_IS_E_SCOPE: 4.987550066043329e-06\n",
            "Total Loss: -4.523362773059468e-08\n",
            "----------------------------------------\n",
            "Epoch 692\n",
            "Var loss:  tensor(-5.2582e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1343480863200594e-06\n",
            "E_s_wdiff_all_sq: 3.44549991828731e-07\n",
            "E_IS_SCOPE: 2.8698952818452054e-06\n",
            "E_IS_E_SCOPE: 4.995317220430851e-06\n",
            "Total Loss: -5.258164670140358e-08\n",
            "----------------------------------------\n",
            "Epoch 693\n",
            "Var loss:  tensor(-6.0074e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1532292420893308e-06\n",
            "E_s_wdiff_all_sq: 3.588089947823437e-07\n",
            "E_IS_SCOPE: 2.8770197534503663e-06\n",
            "E_IS_E_SCOPE: 5.008499089993374e-06\n",
            "Total Loss: -6.007428980046829e-08\n",
            "----------------------------------------\n",
            "Epoch 694\n",
            "Var loss:  tensor(-6.7624e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1540187497757097e-06\n",
            "E_s_wdiff_all_sq: 3.647603869189331e-07\n",
            "E_IS_SCOPE: 2.925601228676869e-06\n",
            "E_IS_E_SCOPE: 5.058274287775611e-06\n",
            "Total Loss: -6.762361936214938e-08\n",
            "----------------------------------------\n",
            "Epoch 695\n",
            "Var loss:  tensor(-7.5057e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1461448107593807e-06\n",
            "E_s_wdiff_all_sq: 3.627639499753416e-07\n",
            "E_IS_SCOPE: 2.9727680416739703e-06\n",
            "E_IS_E_SCOPE: 5.106218838060197e-06\n",
            "Total Loss: -7.505659600985647e-08\n",
            "----------------------------------------\n",
            "Epoch 696\n",
            "Var loss:  tensor(-8.2509e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.168610354038713e-06\n",
            "E_s_wdiff_all_sq: 3.771637732812805e-07\n",
            "E_IS_SCOPE: 2.9760128338689633e-06\n",
            "E_IS_E_SCOPE: 5.117222726946844e-06\n",
            "Total Loss: -8.250906941977129e-08\n",
            "----------------------------------------\n",
            "Epoch 697\n",
            "Var loss:  tensor(-9.0098e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1631263389906168e-06\n",
            "E_s_wdiff_all_sq: 3.7886717648543557e-07\n",
            "E_IS_SCOPE: 2.9903937979974394e-06\n",
            "E_IS_E_SCOPE: 5.131804516063354e-06\n",
            "Total Loss: -9.009813764808906e-08\n",
            "----------------------------------------\n",
            "Epoch 698\n",
            "Var loss:  tensor(-9.7598e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1513108983343003e-06\n",
            "E_s_wdiff_all_sq: 3.7246799101047157e-07\n",
            "E_IS_SCOPE: 3.003060633319871e-06\n",
            "E_IS_E_SCOPE: 5.1455130753156614e-06\n",
            "Total Loss: -9.759784068919363e-08\n",
            "----------------------------------------\n",
            "Epoch 699\n",
            "Var loss:  tensor(-1.0518e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1694999826964936e-06\n",
            "E_s_wdiff_all_sq: 3.824302165580049e-07\n",
            "E_IS_SCOPE: 2.986393996952071e-06\n",
            "E_IS_E_SCOPE: 5.136752657404982e-06\n",
            "Total Loss: -1.0518341878877455e-07\n",
            "----------------------------------------\n",
            "Epoch 700\n",
            "Var loss:  tensor(-1.1276e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1634131803429882e-06\n",
            "E_s_wdiff_all_sq: 3.849534748473212e-07\n",
            "E_IS_SCOPE: 2.991501467808162e-06\n",
            "E_IS_E_SCOPE: 5.141343473501514e-06\n",
            "Total Loss: -1.1276016991247555e-07\n",
            "----------------------------------------\n",
            "Epoch 701\n",
            "Var loss:  tensor(-1.2051e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.168711884278917e-06\n",
            "E_s_wdiff_all_sq: 3.909251585004982e-07\n",
            "E_IS_SCOPE: 3.017478458870808e-06\n",
            "E_IS_E_SCOPE: 5.170856621322277e-06\n",
            "Total Loss: -1.2050546314596074e-07\n",
            "----------------------------------------\n",
            "Epoch 702\n",
            "Var loss:  tensor(-1.2818e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.187866968294477e-06\n",
            "E_s_wdiff_all_sq: 4.036823321257661e-07\n",
            "E_IS_SCOPE: 3.05396627639253e-06\n",
            "E_IS_E_SCOPE: 5.214383083334594e-06\n",
            "Total Loss: -1.2818484173686007e-07\n",
            "----------------------------------------\n",
            "Epoch 703\n",
            "Var loss:  tensor(-1.3586e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.176922352476698e-06\n",
            "E_s_wdiff_all_sq: 4.0422159818280197e-07\n",
            "E_IS_SCOPE: 3.0968558740180356e-06\n",
            "E_IS_E_SCOPE: 5.25536605419755e-06\n",
            "Total Loss: -1.3585547008657246e-07\n",
            "----------------------------------------\n",
            "Epoch 704\n",
            "Var loss:  tensor(-1.4361e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.186610518042121e-06\n",
            "E_s_wdiff_all_sq: 4.102687798323156e-07\n",
            "E_IS_SCOPE: 3.1049086105441973e-06\n",
            "E_IS_E_SCOPE: 5.269117003515328e-06\n",
            "Total Loss: -1.4361091175389688e-07\n",
            "----------------------------------------\n",
            "Epoch 705\n",
            "Var loss:  tensor(-1.5143e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1802172087106727e-06\n",
            "E_s_wdiff_all_sq: 4.0188429889342385e-07\n",
            "E_IS_SCOPE: 3.1130656673006285e-06\n",
            "E_IS_E_SCOPE: 5.282177455153178e-06\n",
            "Total Loss: -1.5142652990929133e-07\n",
            "----------------------------------------\n",
            "Epoch 706\n",
            "Var loss:  tensor(-1.5928e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1452255888893165e-06\n",
            "E_s_wdiff_all_sq: 3.803186916924095e-07\n",
            "E_IS_SCOPE: 3.1314473245382724e-06\n",
            "E_IS_E_SCOPE: 5.297772148867724e-06\n",
            "Total Loss: -1.592786154834378e-07\n",
            "----------------------------------------\n",
            "Epoch 707\n",
            "Var loss:  tensor(-1.6709e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.155409829654846e-06\n",
            "E_s_wdiff_all_sq: 3.81153807022229e-07\n",
            "E_IS_SCOPE: 3.106863489872129e-06\n",
            "E_IS_E_SCOPE: 5.281770723597994e-06\n",
            "Total Loss: -1.6709430884055352e-07\n",
            "----------------------------------------\n",
            "Epoch 708\n",
            "Var loss:  tensor(-1.7503e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.136453626385599e-06\n",
            "E_s_wdiff_all_sq: 3.667476783225624e-07\n",
            "E_IS_SCOPE: 3.1179172153262666e-06\n",
            "E_IS_E_SCOPE: 5.294516746641607e-06\n",
            "Total Loss: -1.7502897858908568e-07\n",
            "----------------------------------------\n",
            "Epoch 709\n",
            "Var loss:  tensor(-1.8296e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1241163914761923e-06\n",
            "E_s_wdiff_all_sq: 3.592087020909724e-07\n",
            "E_IS_SCOPE: 3.1573390198471316e-06\n",
            "E_IS_E_SCOPE: 5.335505638050516e-06\n",
            "Total Loss: -1.8296141104298901e-07\n",
            "----------------------------------------\n",
            "Epoch 710\n",
            "Var loss:  tensor(-1.9092e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.124286545389344e-06\n",
            "E_s_wdiff_all_sq: 3.587385404126041e-07\n",
            "E_IS_SCOPE: 3.185488271773368e-06\n",
            "E_IS_E_SCOPE: 5.367954355410877e-06\n",
            "Total Loss: -1.909200263197181e-07\n",
            "----------------------------------------\n",
            "Epoch 711\n",
            "Var loss:  tensor(-1.9889e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1226179705285843e-06\n",
            "E_s_wdiff_all_sq: 3.5597927412710063e-07\n",
            "E_IS_SCOPE: 3.2109899538314583e-06\n",
            "E_IS_E_SCOPE: 5.39798661134649e-06\n",
            "Total Loss: -1.9889048265002177e-07\n",
            "----------------------------------------\n",
            "Epoch 712\n",
            "Var loss:  tensor(-2.0691e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.105652481774636e-06\n",
            "E_s_wdiff_all_sq: 3.4397952088840187e-07\n",
            "E_IS_SCOPE: 3.243341585794253e-06\n",
            "E_IS_E_SCOPE: 5.431867492194809e-06\n",
            "Total Loss: -2.0691471593631847e-07\n",
            "----------------------------------------\n",
            "Epoch 713\n",
            "Var loss:  tensor(-2.1498e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1075416311182507e-06\n",
            "E_s_wdiff_all_sq: 3.4246578648589413e-07\n",
            "E_IS_SCOPE: 3.2501495293829724e-06\n",
            "E_IS_E_SCOPE: 5.444409016254061e-06\n",
            "Total Loss: -2.1497899313126103e-07\n",
            "----------------------------------------\n",
            "Epoch 714\n",
            "Var loss:  tensor(-2.2301e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1099030756869733e-06\n",
            "E_s_wdiff_all_sq: 3.459868492970389e-07\n",
            "E_IS_SCOPE: 3.25275936805232e-06\n",
            "E_IS_E_SCOPE: 5.450453954421132e-06\n",
            "Total Loss: -2.2300881036913072e-07\n",
            "----------------------------------------\n",
            "Epoch 715\n",
            "Var loss:  tensor(-2.3103e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.107323640706436e-06\n",
            "E_s_wdiff_all_sq: 3.499325185512293e-07\n",
            "E_IS_SCOPE: 3.2849624682961487e-06\n",
            "E_IS_E_SCOPE: 5.483403854393409e-06\n",
            "Total Loss: -2.3102751406075509e-07\n",
            "----------------------------------------\n",
            "Epoch 716\n",
            "Var loss:  tensor(-2.3922e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1179054726252854e-06\n",
            "E_s_wdiff_all_sq: 3.5883367818620923e-07\n",
            "E_IS_SCOPE: 3.3230168410047516e-06\n",
            "E_IS_E_SCOPE: 5.526396628866261e-06\n",
            "Total Loss: -2.3922364530538257e-07\n",
            "----------------------------------------\n",
            "Epoch 717\n",
            "Var loss:  tensor(-2.4732e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1245205834678274e-06\n",
            "E_s_wdiff_all_sq: 3.648458748225593e-07\n",
            "E_IS_SCOPE: 3.3538746536054863e-06\n",
            "E_IS_E_SCOPE: 5.561605623315239e-06\n",
            "Total Loss: -2.4732309479567937e-07\n",
            "----------------------------------------\n",
            "Epoch 718\n",
            "Var loss:  tensor(-2.5533e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.127594949515942e-06\n",
            "E_s_wdiff_all_sq: 3.7319424596456715e-07\n",
            "E_IS_SCOPE: 3.3713082442443526e-06\n",
            "E_IS_E_SCOPE: 5.580407739513489e-06\n",
            "Total Loss: -2.5533415100834017e-07\n",
            "----------------------------------------\n",
            "Epoch 719\n",
            "Var loss:  tensor(-2.6350e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.109224818069403e-06\n",
            "E_s_wdiff_all_sq: 3.674608664147079e-07\n",
            "E_IS_SCOPE: 3.382674124659334e-06\n",
            "E_IS_E_SCOPE: 5.589537529161913e-06\n",
            "Total Loss: -2.634987213719061e-07\n",
            "----------------------------------------\n",
            "Epoch 720\n",
            "Var loss:  tensor(-2.7188e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1238002692976843e-06\n",
            "E_s_wdiff_all_sq: 3.6924797287982615e-07\n",
            "E_IS_SCOPE: 3.3558921797260775e-06\n",
            "E_IS_E_SCOPE: 5.573341382589681e-06\n",
            "Total Loss: -2.7188197333078773e-07\n",
            "----------------------------------------\n",
            "Epoch 721\n",
            "Var loss:  tensor(-2.8014e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.103008914657725e-06\n",
            "E_s_wdiff_all_sq: 3.524267890220313e-07\n",
            "E_IS_SCOPE: 3.3669356175350163e-06\n",
            "E_IS_E_SCOPE: 5.586526320379058e-06\n",
            "Total Loss: -2.8013514407383055e-07\n",
            "----------------------------------------\n",
            "Epoch 722\n",
            "Var loss:  tensor(-2.8843e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0786766142257008e-06\n",
            "E_s_wdiff_all_sq: 3.3244651114402825e-07\n",
            "E_IS_SCOPE: 3.401397183307897e-06\n",
            "E_IS_E_SCOPE: 5.622961262198842e-06\n",
            "Total Loss: -2.884339187216588e-07\n",
            "----------------------------------------\n",
            "Epoch 723\n",
            "Var loss:  tensor(-2.9685e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0761669359793313e-06\n",
            "E_s_wdiff_all_sq: 3.2404463718489614e-07\n",
            "E_IS_SCOPE: 3.4294435872171873e-06\n",
            "E_IS_E_SCOPE: 5.6581608671347e-06\n",
            "Total Loss: -2.9684812506203107e-07\n",
            "----------------------------------------\n",
            "Epoch 724\n",
            "Var loss:  tensor(-3.0512e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.062894178701117e-06\n",
            "E_s_wdiff_all_sq: 3.1945953827691666e-07\n",
            "E_IS_SCOPE: 3.4800837625988977e-06\n",
            "E_IS_E_SCOPE: 5.708595257357734e-06\n",
            "Total Loss: -3.0512421311491384e-07\n",
            "----------------------------------------\n",
            "Epoch 725\n",
            "Var loss:  tensor(-3.1352e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.057828298933219e-06\n",
            "E_s_wdiff_all_sq: 3.167609887407062e-07\n",
            "E_IS_SCOPE: 3.5125891269353406e-06\n",
            "E_IS_E_SCOPE: 5.744114261752265e-06\n",
            "Total Loss: -3.135188234627771e-07\n",
            "----------------------------------------\n",
            "Epoch 726\n",
            "Var loss:  tensor(-3.2196e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0686168680589623e-06\n",
            "E_s_wdiff_all_sq: 3.173708441928323e-07\n",
            "E_IS_SCOPE: 3.5188134865739183e-06\n",
            "E_IS_E_SCOPE: 5.759648174094778e-06\n",
            "Total Loss: -3.2195921519702957e-07\n",
            "----------------------------------------\n",
            "Epoch 727\n",
            "Var loss:  tensor(-3.3041e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.047781534838904e-06\n",
            "E_s_wdiff_all_sq: 3.0420771208301935e-07\n",
            "E_IS_SCOPE: 3.5447682185362727e-06\n",
            "E_IS_E_SCOPE: 5.785993119921861e-06\n",
            "Total Loss: -3.3041184403673155e-07\n",
            "----------------------------------------\n",
            "Epoch 728\n",
            "Var loss:  tensor(-3.3895e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0383349548343983e-06\n",
            "E_s_wdiff_all_sq: 2.978050985821209e-07\n",
            "E_IS_SCOPE: 3.5574460679082086e-06\n",
            "E_IS_E_SCOPE: 5.8014176852758055e-06\n",
            "Total Loss: -3.389492425043577e-07\n",
            "----------------------------------------\n",
            "Epoch 729\n",
            "Var loss:  tensor(-3.4748e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0319265106654663e-06\n",
            "E_s_wdiff_all_sq: 2.94510434230972e-07\n",
            "E_IS_SCOPE: 3.5589077610890363e-06\n",
            "E_IS_E_SCOPE: 5.805585375263834e-06\n",
            "Total Loss: -3.4747501593654147e-07\n",
            "----------------------------------------\n",
            "Epoch 730\n",
            "Var loss:  tensor(-3.5601e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0319111465337423e-06\n",
            "E_s_wdiff_all_sq: 2.995058499450461e-07\n",
            "E_IS_SCOPE: 3.560268357163045e-06\n",
            "E_IS_E_SCOPE: 5.808707839807212e-06\n",
            "Total Loss: -3.560095327210797e-07\n",
            "----------------------------------------\n",
            "Epoch 731\n",
            "Var loss:  tensor(-3.6455e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0447726832261414e-06\n",
            "E_s_wdiff_all_sq: 3.101694441526059e-07\n",
            "E_IS_SCOPE: 3.564110529182254e-06\n",
            "E_IS_E_SCOPE: 5.817919078255877e-06\n",
            "Total Loss: -3.6454972309515247e-07\n",
            "----------------------------------------\n",
            "Epoch 732\n",
            "Var loss:  tensor(-3.7316e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0400345920438134e-06\n",
            "E_s_wdiff_all_sq: 3.0633408419870785e-07\n",
            "E_IS_SCOPE: 3.587066553742199e-06\n",
            "E_IS_E_SCOPE: 5.8447266774264856e-06\n",
            "Total Loss: -3.7315560354490776e-07\n",
            "----------------------------------------\n",
            "Epoch 733\n",
            "Var loss:  tensor(-3.8180e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0471060803784323e-06\n",
            "E_s_wdiff_all_sq: 3.0897245822012535e-07\n",
            "E_IS_SCOPE: 3.6006079186489196e-06\n",
            "E_IS_E_SCOPE: 5.86480856749889e-06\n",
            "Total Loss: -3.8180353956307454e-07\n",
            "----------------------------------------\n",
            "Epoch 734\n",
            "Var loss:  tensor(-3.9044e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0413076141775414e-06\n",
            "E_s_wdiff_all_sq: 3.1051617571744453e-07\n",
            "E_IS_SCOPE: 3.62115977546814e-06\n",
            "E_IS_E_SCOPE: 5.886006356256191e-06\n",
            "Total Loss: -3.904375871374455e-07\n",
            "----------------------------------------\n",
            "Epoch 735\n",
            "Var loss:  tensor(-3.9915e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.052332140002009e-06\n",
            "E_s_wdiff_all_sq: 3.218573869325448e-07\n",
            "E_IS_SCOPE: 3.623395575816802e-06\n",
            "E_IS_E_SCOPE: 5.8924410077439845e-06\n",
            "Total Loss: -3.9915197480634147e-07\n",
            "----------------------------------------\n",
            "Epoch 736\n",
            "Var loss:  tensor(-4.0779e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0743407879542705e-06\n",
            "E_s_wdiff_all_sq: 3.4361902913480013e-07\n",
            "E_IS_SCOPE: 3.6069181728785595e-06\n",
            "E_IS_E_SCOPE: 5.880406116508807e-06\n",
            "Total Loss: -4.077899924624655e-07\n",
            "----------------------------------------\n",
            "Epoch 737\n",
            "Var loss:  tensor(-4.1648e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0786159991261933e-06\n",
            "E_s_wdiff_all_sq: 3.5505263720969733e-07\n",
            "E_IS_SCOPE: 3.62265510825836e-06\n",
            "E_IS_E_SCOPE: 5.896909376658757e-06\n",
            "Total Loss: -4.164810389057407e-07\n",
            "----------------------------------------\n",
            "Epoch 738\n",
            "Var loss:  tensor(-4.2530e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0882113208343096e-06\n",
            "E_s_wdiff_all_sq: 3.602326821572391e-07\n",
            "E_IS_SCOPE: 3.6528662796464826e-06\n",
            "E_IS_E_SCOPE: 5.933737262962837e-06\n",
            "Total Loss: -4.2529919197708057e-07\n",
            "----------------------------------------\n",
            "Epoch 739\n",
            "Var loss:  tensor(-4.3411e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0642948391944915e-06\n",
            "E_s_wdiff_all_sq: 3.4236332246993466e-07\n",
            "E_IS_SCOPE: 3.6979202389928883e-06\n",
            "E_IS_E_SCOPE: 5.980172160093632e-06\n",
            "Total Loss: -4.341081894983701e-07\n",
            "----------------------------------------\n",
            "Epoch 740\n",
            "Var loss:  tensor(-4.4291e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0652530072399695e-06\n",
            "E_s_wdiff_all_sq: 3.376169002655587e-07\n",
            "E_IS_SCOPE: 3.7022957209876627e-06\n",
            "E_IS_E_SCOPE: 5.991798666360888e-06\n",
            "Total Loss: -4.429056477934809e-07\n",
            "----------------------------------------\n",
            "Epoch 741\n",
            "Var loss:  tensor(-4.5178e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0537555122186042e-06\n",
            "E_s_wdiff_all_sq: 3.3029125673973804e-07\n",
            "E_IS_SCOPE: 3.705163304286882e-06\n",
            "E_IS_E_SCOPE: 5.997015048402889e-06\n",
            "Total Loss: -4.517750967745895e-07\n",
            "----------------------------------------\n",
            "Epoch 742\n",
            "Var loss:  tensor(-4.6060e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.03900920917432e-06\n",
            "E_s_wdiff_all_sq: 3.2316636454005534e-07\n",
            "E_IS_SCOPE: 3.703140054801031e-06\n",
            "E_IS_E_SCOPE: 5.995595972794404e-06\n",
            "Total Loss: -4.6060485537392393e-07\n",
            "----------------------------------------\n",
            "Epoch 743\n",
            "Var loss:  tensor(-4.6951e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0783177025873812e-06\n",
            "E_s_wdiff_all_sq: 3.4575741338047373e-07\n",
            "E_IS_SCOPE: 3.680149975731143e-06\n",
            "E_IS_E_SCOPE: 5.98541819377382e-06\n",
            "Total Loss: -4.695120108998878e-07\n",
            "----------------------------------------\n",
            "Epoch 744\n",
            "Var loss:  tensor(-4.7844e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.027732188777844e-06\n",
            "E_s_wdiff_all_sq: 3.262678370164713e-07\n",
            "E_IS_SCOPE: 3.7617703530210137e-06\n",
            "E_IS_E_SCOPE: 6.055954382135507e-06\n",
            "Total Loss: -4.784395704890537e-07\n",
            "----------------------------------------\n",
            "Epoch 745\n",
            "Var loss:  tensor(-4.8739e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.055411551874332e-06\n",
            "E_s_wdiff_all_sq: 3.3458214470726427e-07\n",
            "E_IS_SCOPE: 3.7704412606527694e-06\n",
            "E_IS_E_SCOPE: 6.078783723847466e-06\n",
            "Total Loss: -4.873913832437676e-07\n",
            "----------------------------------------\n",
            "Epoch 746\n",
            "Var loss:  tensor(-4.9638e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0512168625873768e-06\n",
            "E_s_wdiff_all_sq: 3.33163438920146e-07\n",
            "E_IS_SCOPE: 3.78868974206363e-06\n",
            "E_IS_E_SCOPE: 6.100140050768993e-06\n",
            "Total Loss: -4.963830577649354e-07\n",
            "----------------------------------------\n",
            "Epoch 747\n",
            "Var loss:  tensor(-5.0533e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0313573659213543e-06\n",
            "E_s_wdiff_all_sq: 3.264368681271281e-07\n",
            "E_IS_SCOPE: 3.8121620147823774e-06\n",
            "E_IS_E_SCOPE: 6.1215188311129815e-06\n",
            "Total Loss: -5.053289988884228e-07\n",
            "----------------------------------------\n",
            "Epoch 748\n",
            "Var loss:  tensor(-5.1432e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0744923706999868e-06\n",
            "E_s_wdiff_all_sq: 3.46938199612164e-07\n",
            "E_IS_SCOPE: 3.7833857218673302e-06\n",
            "E_IS_E_SCOPE: 6.108553759398549e-06\n",
            "Total Loss: -5.143177679960562e-07\n",
            "----------------------------------------\n",
            "Epoch 749\n",
            "Var loss:  tensor(-5.2335e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0386783087216076e-06\n",
            "E_s_wdiff_all_sq: 3.381153400866165e-07\n",
            "E_IS_SCOPE: 3.819235245775253e-06\n",
            "E_IS_E_SCOPE: 6.13542399047777e-06\n",
            "Total Loss: -5.233503847914826e-07\n",
            "----------------------------------------\n",
            "Epoch 750\n",
            "Var loss:  tensor(-5.3238e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.059994697913937e-06\n",
            "E_s_wdiff_all_sq: 3.519304239747502e-07\n",
            "E_IS_SCOPE: 3.80836076133578e-06\n",
            "E_IS_E_SCOPE: 6.132815692177749e-06\n",
            "Total Loss: -5.323814517661912e-07\n",
            "----------------------------------------\n",
            "Epoch 751\n",
            "Var loss:  tensor(-5.4133e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.070301346742258e-06\n",
            "E_s_wdiff_all_sq: 3.565867574786752e-07\n",
            "E_IS_SCOPE: 3.810397379214318e-06\n",
            "E_IS_E_SCOPE: 6.142149766366932e-06\n",
            "Total Loss: -5.41326049063086e-07\n",
            "----------------------------------------\n",
            "Epoch 752\n",
            "Var loss:  tensor(-5.5034e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0521703936787464e-06\n",
            "E_s_wdiff_all_sq: 3.521147000170833e-07\n",
            "E_IS_SCOPE: 3.850546963449476e-06\n",
            "E_IS_E_SCOPE: 6.179975632902327e-06\n",
            "Total Loss: -5.503375092654792e-07\n",
            "----------------------------------------\n",
            "Epoch 753\n",
            "Var loss:  tensor(-5.5944e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0846144797706574e-06\n",
            "E_s_wdiff_all_sq: 3.6975960542903886e-07\n",
            "E_IS_SCOPE: 3.86519459060483e-06\n",
            "E_IS_E_SCOPE: 6.206574606928937e-06\n",
            "Total Loss: -5.594410223280377e-07\n",
            "----------------------------------------\n",
            "Epoch 754\n",
            "Var loss:  tensor(-5.6851e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0361606432999415e-06\n",
            "E_s_wdiff_all_sq: 3.435527471985542e-07\n",
            "E_IS_SCOPE: 3.929959647182713e-06\n",
            "E_IS_E_SCOPE: 6.2647496623949235e-06\n",
            "Total Loss: -5.685079983444743e-07\n",
            "----------------------------------------\n",
            "Epoch 755\n",
            "Var loss:  tensor(-5.7761e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0778771995937987e-06\n",
            "E_s_wdiff_all_sq: 3.5948439261209797e-07\n",
            "E_IS_SCOPE: 3.90165337162576e-06\n",
            "E_IS_E_SCOPE: 6.253885553565891e-06\n",
            "Total Loss: -5.776074209200019e-07\n",
            "----------------------------------------\n",
            "Epoch 756\n",
            "Var loss:  tensor(-5.8683e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0379451623391963e-06\n",
            "E_s_wdiff_all_sq: 3.412981827102453e-07\n",
            "E_IS_SCOPE: 3.935093503820433e-06\n",
            "E_IS_E_SCOPE: 6.281061904643728e-06\n",
            "Total Loss: -5.868256860390779e-07\n",
            "----------------------------------------\n",
            "Epoch 757\n",
            "Var loss:  tensor(-5.9600e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.038319496816368e-06\n",
            "E_s_wdiff_all_sq: 3.375432256615336e-07\n",
            "E_IS_SCOPE: 3.936436839013202e-06\n",
            "E_IS_E_SCOPE: 6.289056852939141e-06\n",
            "Total Loss: -5.959996207184835e-07\n",
            "----------------------------------------\n",
            "Epoch 758\n",
            "Var loss:  tensor(-6.0516e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0640838014452687e-06\n",
            "E_s_wdiff_all_sq: 3.521273868603615e-07\n",
            "E_IS_SCOPE: 3.919839491785449e-06\n",
            "E_IS_E_SCOPE: 6.282630881107641e-06\n",
            "Total Loss: -6.051622280809183e-07\n",
            "----------------------------------------\n",
            "Epoch 759\n",
            "Var loss:  tensor(-6.1437e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0088320476867788e-06\n",
            "E_s_wdiff_all_sq: 3.309480713339651e-07\n",
            "E_IS_SCOPE: 3.975953413339222e-06\n",
            "E_IS_E_SCOPE: 6.326310847171899e-06\n",
            "Total Loss: -6.143667553339804e-07\n",
            "----------------------------------------\n",
            "Epoch 760\n",
            "Var loss:  tensor(-6.2357e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0808448131253804e-06\n",
            "E_s_wdiff_all_sq: 3.6516256061058247e-07\n",
            "E_IS_SCOPE: 3.948899070839503e-06\n",
            "E_IS_E_SCOPE: 6.322755425777901e-06\n",
            "Total Loss: -6.235663213834382e-07\n",
            "----------------------------------------\n",
            "Epoch 761\n",
            "Var loss:  tensor(-6.3289e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0174085972526533e-06\n",
            "E_s_wdiff_all_sq: 3.383472904444125e-07\n",
            "E_IS_SCOPE: 4.025271317685544e-06\n",
            "E_IS_E_SCOPE: 6.385479921541343e-06\n",
            "Total Loss: -6.328917649247992e-07\n",
            "----------------------------------------\n",
            "Epoch 762\n",
            "Var loss:  tensor(-6.4227e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.068098922457691e-06\n",
            "E_s_wdiff_all_sq: 3.6191634774684413e-07\n",
            "E_IS_SCOPE: 4.00150455722143e-06\n",
            "E_IS_E_SCOPE: 6.379962217026623e-06\n",
            "Total Loss: -6.4226860892098e-07\n",
            "----------------------------------------\n",
            "Epoch 763\n",
            "Var loss:  tensor(-6.5161e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.045923490519792e-06\n",
            "E_s_wdiff_all_sq: 3.503289610563573e-07\n",
            "E_IS_SCOPE: 4.034391232533908e-06\n",
            "E_IS_E_SCOPE: 6.412225052916715e-06\n",
            "Total Loss: -6.516089753236196e-07\n",
            "----------------------------------------\n",
            "Epoch 764\n",
            "Var loss:  tensor(-6.6098e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.032554056536242e-06\n",
            "E_s_wdiff_all_sq: 3.4313920637561816e-07\n",
            "E_IS_SCOPE: 4.0586818170206864e-06\n",
            "E_IS_E_SCOPE: 6.438112073353694e-06\n",
            "Total Loss: -6.609815265268321e-07\n",
            "----------------------------------------\n",
            "Epoch 765\n",
            "Var loss:  tensor(-6.7052e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.034854670523985e-06\n",
            "E_s_wdiff_all_sq: 3.502246619691924e-07\n",
            "E_IS_SCOPE: 4.062111169146976e-06\n",
            "E_IS_E_SCOPE: 6.443919297300515e-06\n",
            "Total Loss: -6.70522111773726e-07\n",
            "----------------------------------------\n",
            "Epoch 766\n",
            "Var loss:  tensor(-6.8001e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.066876412807272e-06\n",
            "E_s_wdiff_all_sq: 3.6713648371796174e-07\n",
            "E_IS_SCOPE: 4.04105858349118e-06\n",
            "E_IS_E_SCOPE: 6.4351667041354534e-06\n",
            "Total Loss: -6.800121762206762e-07\n",
            "----------------------------------------\n",
            "Epoch 767\n",
            "Var loss:  tensor(-6.8968e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0500978691180493e-06\n",
            "E_s_wdiff_all_sq: 3.636693538338914e-07\n",
            "E_IS_SCOPE: 4.081218621374629e-06\n",
            "E_IS_E_SCOPE: 6.473506817170802e-06\n",
            "Total Loss: -6.896837403296295e-07\n",
            "----------------------------------------\n",
            "Epoch 768\n",
            "Var loss:  tensor(-6.9936e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0387106811367784e-06\n",
            "E_s_wdiff_all_sq: 3.5905047796792627e-07\n",
            "E_IS_SCOPE: 4.112049156263923e-06\n",
            "E_IS_E_SCOPE: 6.5057922519417e-06\n",
            "Total Loss: -6.993618522081422e-07\n",
            "----------------------------------------\n",
            "Epoch 769\n",
            "Var loss:  tensor(-7.0910e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0675448197973273e-06\n",
            "E_s_wdiff_all_sq: 3.685929263658305e-07\n",
            "E_IS_SCOPE: 4.112753908574567e-06\n",
            "E_IS_E_SCOPE: 6.521012915330103e-06\n",
            "Total Loss: -7.091019841010166e-07\n",
            "----------------------------------------\n",
            "Epoch 770\n",
            "Var loss:  tensor(-7.1879e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.033958944222384e-06\n",
            "E_s_wdiff_all_sq: 3.516758197577221e-07\n",
            "E_IS_SCOPE: 4.161718787332086e-06\n",
            "E_IS_E_SCOPE: 6.566488948714031e-06\n",
            "Total Loss: -7.187930623206686e-07\n",
            "----------------------------------------\n",
            "Epoch 771\n",
            "Var loss:  tensor(-7.2867e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0602669333541986e-06\n",
            "E_s_wdiff_all_sq: 3.732567687349644e-07\n",
            "E_IS_SCOPE: 4.168844129144753e-06\n",
            "E_IS_E_SCOPE: 6.580918431599129e-06\n",
            "Total Loss: -7.286743043109576e-07\n",
            "----------------------------------------\n",
            "Epoch 772\n",
            "Var loss:  tensor(-7.3851e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.063643731465503e-06\n",
            "E_s_wdiff_all_sq: 3.7778048760762687e-07\n",
            "E_IS_SCOPE: 4.188846306924983e-06\n",
            "E_IS_E_SCOPE: 6.6052628771347706e-06\n",
            "Total Loss: -7.385057605831386e-07\n",
            "----------------------------------------\n",
            "Epoch 773\n",
            "Var loss:  tensor(-7.4831e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.053578707676068e-06\n",
            "E_s_wdiff_all_sq: 3.7379372268945334e-07\n",
            "E_IS_SCOPE: 4.208789234631935e-06\n",
            "E_IS_E_SCOPE: 6.627070065296009e-06\n",
            "Total Loss: -7.483125403629736e-07\n",
            "----------------------------------------\n",
            "Epoch 774\n",
            "Var loss:  tensor(-7.5806e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0605687061960756e-06\n",
            "E_s_wdiff_all_sq: 3.7733101838150575e-07\n",
            "E_IS_SCOPE: 4.2047444729654745e-06\n",
            "E_IS_E_SCOPE: 6.6296263485037105e-06\n",
            "Total Loss: -7.580619272833421e-07\n",
            "----------------------------------------\n",
            "Epoch 775\n",
            "Var loss:  tensor(-7.6780e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.037281486752338e-06\n",
            "E_s_wdiff_all_sq: 3.598870244396641e-07\n",
            "E_IS_SCOPE: 4.223802736145082e-06\n",
            "E_IS_E_SCOPE: 6.650630805532408e-06\n",
            "Total Loss: -7.677975404834171e-07\n",
            "----------------------------------------\n",
            "Epoch 776\n",
            "Var loss:  tensor(-7.7760e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0469147495204895e-06\n",
            "E_s_wdiff_all_sq: 3.6378422746896024e-07\n",
            "E_IS_SCOPE: 4.235551414327332e-06\n",
            "E_IS_E_SCOPE: 6.670146915876548e-06\n",
            "Total Loss: -7.77596345068342e-07\n",
            "----------------------------------------\n",
            "Epoch 777\n",
            "Var loss:  tensor(-7.8740e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0417879956615836e-06\n",
            "E_s_wdiff_all_sq: 3.643132118868019e-07\n",
            "E_IS_SCOPE: 4.257923970658039e-06\n",
            "E_IS_E_SCOPE: 6.694595883989451e-06\n",
            "Total Loss: -7.874049069094815e-07\n",
            "----------------------------------------\n",
            "Epoch 778\n",
            "Var loss:  tensor(-7.9728e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0456905814243524e-06\n",
            "E_s_wdiff_all_sq: 3.6829748977334657e-07\n",
            "E_IS_SCOPE: 4.279311790877318e-06\n",
            "E_IS_E_SCOPE: 6.720880273398584e-06\n",
            "Total Loss: -7.972797374129676e-07\n",
            "----------------------------------------\n",
            "Epoch 779\n",
            "Var loss:  tensor(-8.0718e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.047025358808702e-06\n",
            "E_s_wdiff_all_sq: 3.697834083077351e-07\n",
            "E_IS_SCOPE: 4.301610919141212e-06\n",
            "E_IS_E_SCOPE: 6.748052578133692e-06\n",
            "Total Loss: -8.071772315054321e-07\n",
            "----------------------------------------\n",
            "Epoch 780\n",
            "Var loss:  tensor(-8.1707e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0461294213040288e-06\n",
            "E_s_wdiff_all_sq: 3.7153755311488405e-07\n",
            "E_IS_SCOPE: 4.314251990000706e-06\n",
            "E_IS_E_SCOPE: 6.764313370064592e-06\n",
            "Total Loss: -8.17066755960068e-07\n",
            "----------------------------------------\n",
            "Epoch 781\n",
            "Var loss:  tensor(-8.2702e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0378265482864607e-06\n",
            "E_s_wdiff_all_sq: 3.656290915995199e-07\n",
            "E_IS_SCOPE: 4.3316311791046965e-06\n",
            "E_IS_E_SCOPE: 6.785473505728808e-06\n",
            "Total Loss: -8.270230605827223e-07\n",
            "----------------------------------------\n",
            "Epoch 782\n",
            "Var loss:  tensor(-8.3700e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0540634187364966e-06\n",
            "E_s_wdiff_all_sq: 3.730796519704696e-07\n",
            "E_IS_SCOPE: 4.349047450982452e-06\n",
            "E_IS_E_SCOPE: 6.812272602353364e-06\n",
            "Total Loss: -8.370023999972383e-07\n",
            "----------------------------------------\n",
            "Epoch 783\n",
            "Var loss:  tensor(-8.4693e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.025820587393504e-06\n",
            "E_s_wdiff_all_sq: 3.5779382016998275e-07\n",
            "E_IS_SCOPE: 4.402405167748186e-06\n",
            "E_IS_E_SCOPE: 6.864117201469917e-06\n",
            "Total Loss: -8.469331642413797e-07\n",
            "----------------------------------------\n",
            "Epoch 784\n",
            "Var loss:  tensor(-8.5700e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.040870792478602e-06\n",
            "E_s_wdiff_all_sq: 3.6551280855800986e-07\n",
            "E_IS_SCOPE: 4.402904312010249e-06\n",
            "E_IS_E_SCOPE: 6.873312944806299e-06\n",
            "Total Loss: -8.569951456929499e-07\n",
            "----------------------------------------\n",
            "Epoch 785\n",
            "Var loss:  tensor(-8.6702e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.040750094335649e-06\n",
            "E_s_wdiff_all_sq: 3.674692639166787e-07\n",
            "E_IS_SCOPE: 4.411050847861418e-06\n",
            "E_IS_E_SCOPE: 6.885435553072269e-06\n",
            "Total Loss: -8.670244440241705e-07\n",
            "----------------------------------------\n",
            "Epoch 786\n",
            "Var loss:  tensor(-8.7715e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0123251882406296e-06\n",
            "E_s_wdiff_all_sq: 3.5396420514422423e-07\n",
            "E_IS_SCOPE: 4.44209508743256e-06\n",
            "E_IS_E_SCOPE: 6.9140823146932825e-06\n",
            "Total Loss: -8.771493354464799e-07\n",
            "----------------------------------------\n",
            "Epoch 787\n",
            "Var loss:  tensor(-8.8725e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.055684304113495e-06\n",
            "E_s_wdiff_all_sq: 3.7780670135583337e-07\n",
            "E_IS_SCOPE: 4.411957899075286e-06\n",
            "E_IS_E_SCOPE: 6.898752324498526e-06\n",
            "Total Loss: -8.87247112110258e-07\n",
            "----------------------------------------\n",
            "Epoch 788\n",
            "Var loss:  tensor(-8.9743e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0252919242764872e-06\n",
            "E_s_wdiff_all_sq: 3.6571292117889163e-07\n",
            "E_IS_SCOPE: 4.449863126438341e-06\n",
            "E_IS_E_SCOPE: 6.9325985394216905e-06\n",
            "Total Loss: -8.974276868905454e-07\n",
            "----------------------------------------\n",
            "Epoch 789\n",
            "Var loss:  tensor(-9.0765e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0301619336670165e-06\n",
            "E_s_wdiff_all_sq: 3.668977394341801e-07\n",
            "E_IS_SCOPE: 4.468705782773913e-06\n",
            "E_IS_E_SCOPE: 6.958394407759049e-06\n",
            "Total Loss: -9.076489197588761e-07\n",
            "----------------------------------------\n",
            "Epoch 790\n",
            "Var loss:  tensor(-9.1781e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0536565231403957e-06\n",
            "E_s_wdiff_all_sq: 3.770607403085796e-07\n",
            "E_IS_SCOPE: 4.480029674728229e-06\n",
            "E_IS_E_SCOPE: 6.9814664315787665e-06\n",
            "Total Loss: -9.178135948906999e-07\n",
            "----------------------------------------\n",
            "Epoch 791\n",
            "Var loss:  tensor(-9.2812e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0210649696846432e-06\n",
            "E_s_wdiff_all_sq: 3.6463538609427086e-07\n",
            "E_IS_SCOPE: 4.53656558186158e-06\n",
            "E_IS_E_SCOPE: 7.033071291371119e-06\n",
            "Total Loss: -9.281176994501453e-07\n",
            "----------------------------------------\n",
            "Epoch 792\n",
            "Var loss:  tensor(-9.3841e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.047564159354765e-06\n",
            "E_s_wdiff_all_sq: 3.8029164952458495e-07\n",
            "E_IS_SCOPE: 4.533444915923928e-06\n",
            "E_IS_E_SCOPE: 7.0405192489034726e-06\n",
            "Total Loss: -9.384120201503481e-07\n",
            "----------------------------------------\n",
            "Epoch 793\n",
            "Var loss:  tensor(-9.4872e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.049996955768787e-06\n",
            "E_s_wdiff_all_sq: 3.8343599880537776e-07\n",
            "E_IS_SCOPE: 4.54529371596278e-06\n",
            "E_IS_E_SCOPE: 7.057166333054909e-06\n",
            "Total Loss: -9.487201412422898e-07\n",
            "----------------------------------------\n",
            "Epoch 794\n",
            "Var loss:  tensor(-9.5903e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0395068576079766e-06\n",
            "E_s_wdiff_all_sq: 3.827065524153703e-07\n",
            "E_IS_SCOPE: 4.568952787874859e-06\n",
            "E_IS_E_SCOPE: 7.081099462047242e-06\n",
            "Total Loss: -9.590289071736007e-07\n",
            "----------------------------------------\n",
            "Epoch 795\n",
            "Var loss:  tensor(-9.6941e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0746225349984714e-06\n",
            "E_s_wdiff_all_sq: 4.04933745229206e-07\n",
            "E_IS_SCOPE: 4.569498240934756e-06\n",
            "E_IS_E_SCOPE: 7.093278765512181e-06\n",
            "Total Loss: -9.694081234070247e-07\n",
            "----------------------------------------\n",
            "Epoch 796\n",
            "Var loss:  tensor(-9.7987e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.043896229358623e-06\n",
            "E_s_wdiff_all_sq: 3.9214733516951315e-07\n",
            "E_IS_SCOPE: 4.6367800458094015e-06\n",
            "E_IS_E_SCOPE: 7.156819749051491e-06\n",
            "Total Loss: -9.798663763165084e-07\n",
            "----------------------------------------\n",
            "Epoch 797\n",
            "Var loss:  tensor(-9.9034e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.07928840870102e-06\n",
            "E_s_wdiff_all_sq: 4.144918568912612e-07\n",
            "E_IS_SCOPE: 4.648476512774259e-06\n",
            "E_IS_E_SCOPE: 7.180276656975907e-06\n",
            "Total Loss: -9.903396006149787e-07\n",
            "----------------------------------------\n",
            "Epoch 798\n",
            "Var loss:  tensor(-1.0008e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0780719935220448e-06\n",
            "E_s_wdiff_all_sq: 4.1902959465881336e-07\n",
            "E_IS_SCOPE: 4.68180222620281e-06\n",
            "E_IS_E_SCOPE: 7.215977640868414e-06\n",
            "Total Loss: -1.0008442944894167e-06\n",
            "----------------------------------------\n",
            "Epoch 799\n",
            "Var loss:  tensor(-1.0114e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0661765077220837e-06\n",
            "E_s_wdiff_all_sq: 4.142220359928117e-07\n",
            "E_IS_SCOPE: 4.717416946911178e-06\n",
            "E_IS_E_SCOPE: 7.253311642677324e-06\n",
            "Total Loss: -1.0113707838244597e-06\n",
            "----------------------------------------\n",
            "Epoch 800\n",
            "Var loss:  tensor(-1.0219e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.091108202447605e-06\n",
            "E_s_wdiff_all_sq: 4.260959702009109e-07\n",
            "E_IS_SCOPE: 4.7175237866153015e-06\n",
            "E_IS_E_SCOPE: 7.2652323297086695e-06\n",
            "Total Loss: -1.021940717961484e-06\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[-0.8062,  0.5339],\n",
            "        [-0.1972, -0.4208],\n",
            "        [ 0.6107,  0.1833],\n",
            "        [ 0.1100, -0.3393],\n",
            "        [-0.0469,  0.4383],\n",
            "        [ 0.1967,  0.3041],\n",
            "        [-0.0265, -0.4809],\n",
            "        [ 0.6737, -0.2494],\n",
            "        [ 0.1594, -0.6898],\n",
            "        [-0.3210,  0.0304],\n",
            "        [ 0.3898,  0.0076],\n",
            "        [ 0.1543,  0.5288],\n",
            "        [-0.6948, -0.0398],\n",
            "        [-0.2316,  0.1893],\n",
            "        [-0.2966, -0.2733],\n",
            "        [ 0.0087, -0.1834]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([ 0.3518, -0.0830, -0.0474,  0.5771,  0.3440, -0.1348,  0.3951, -0.3842,\n",
            "        -0.4929, -0.6301,  0.5189,  0.0884,  0.2289,  0.2196, -0.0453, -0.4175],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[-8.0332e-02, -9.6393e-02, -3.0631e-01, -5.3021e-02, -6.4791e-02,\n",
            "          1.5885e-01,  1.7243e-01, -1.9679e-01,  8.0992e-02, -3.4376e-02,\n",
            "          8.6558e-02,  6.0149e-02, -1.5966e-01, -1.9643e-01,  2.6262e-02,\n",
            "          9.7768e-02],\n",
            "        [-1.8631e-01, -4.7563e-02,  1.0468e-01,  7.8847e-02, -1.8044e-01,\n",
            "          9.0671e-02,  1.6094e-01,  1.6128e-01,  1.0846e-01,  7.4880e-02,\n",
            "          1.3432e-01,  1.1134e-01,  1.9639e-01,  2.1434e-01, -8.8973e-02,\n",
            "          5.1494e-02],\n",
            "        [-8.3696e-02,  2.3390e-02, -1.9553e-01,  2.0819e-01,  3.3464e-02,\n",
            "          9.1040e-02, -2.2174e-01, -4.0349e-02, -1.7039e-01, -1.2196e-01,\n",
            "          2.3892e-01,  4.4670e-02,  9.1598e-02, -1.4442e-01, -9.2240e-03,\n",
            "         -1.5019e-01],\n",
            "        [ 1.6635e-01,  1.3661e-01,  4.7544e-02, -1.2729e-01, -1.9802e-01,\n",
            "          1.0363e-01,  2.1950e-01,  1.1609e-01, -9.6209e-02,  1.6007e-01,\n",
            "          1.9251e-02, -9.7342e-02, -3.6885e-02, -9.6853e-02,  2.4558e-01,\n",
            "         -2.0681e-01],\n",
            "        [-4.0992e-01, -2.0711e-01, -3.3693e-02,  2.6252e-01,  1.2579e-01,\n",
            "          1.3540e-01,  1.0068e-01,  1.5353e-01,  2.2798e-01,  2.0321e-01,\n",
            "          1.2280e-02, -8.3059e-02, -2.9253e-02,  1.4174e-01, -6.7642e-02,\n",
            "          5.7888e-03],\n",
            "        [-1.2552e-01,  1.9502e-01,  1.5227e-01, -2.1612e-01,  1.2873e-01,\n",
            "         -2.4643e-01, -1.4887e-01,  5.0036e-02, -7.1466e-02,  7.1605e-02,\n",
            "         -8.6758e-04,  1.8790e-01, -2.4318e-01,  7.5170e-02, -2.1491e-01,\n",
            "          2.4828e-01],\n",
            "        [ 4.5420e-02, -9.1232e-02,  2.7557e-01,  5.1251e-01,  2.1220e-02,\n",
            "         -1.7437e-01,  1.9662e-03,  6.1231e-01,  1.6596e-01,  9.9712e-02,\n",
            "         -2.2019e-01, -4.1986e-01, -7.0665e-02, -1.3922e-01,  2.9088e-02,\n",
            "         -1.1662e-04],\n",
            "        [-1.0585e-01,  1.3251e-02, -1.9701e-01, -9.0187e-02,  1.0414e-01,\n",
            "         -3.2789e-01,  7.0949e-02, -7.2965e-02,  1.0380e-01, -2.0536e-01,\n",
            "         -5.2456e-02, -2.2061e-01,  1.8478e-01,  8.2254e-02, -2.2522e-01,\n",
            "         -2.3713e-01],\n",
            "        [ 1.2925e-01,  7.9379e-02, -2.2730e-01, -2.0200e-01, -2.1043e-01,\n",
            "         -1.3539e-01, -1.5416e-01,  2.3083e-01, -1.4306e-01,  1.7335e-01,\n",
            "          1.6987e-01,  1.8717e-01, -2.1875e-01, -2.0191e-01,  4.6794e-02,\n",
            "          7.6969e-02],\n",
            "        [ 8.7817e-02, -2.2005e-01,  4.2939e-02,  3.7799e-01, -3.1136e-01,\n",
            "          1.2048e-01, -1.4484e-01,  1.7240e-01,  1.0482e-01,  1.3989e-01,\n",
            "         -7.7966e-02,  1.7182e-01,  8.7622e-02, -6.1079e-02,  1.6320e-01,\n",
            "          1.0936e-01],\n",
            "        [ 1.6316e-01,  1.0953e-01, -1.8309e-01, -2.4273e-01, -2.3144e-01,\n",
            "          1.1643e-01,  1.4265e-02, -4.2267e-01, -4.9015e-02,  2.4643e-01,\n",
            "         -1.5186e-01,  1.2151e-01,  1.0054e-01, -7.1616e-02,  7.7135e-02,\n",
            "         -1.9369e-01],\n",
            "        [ 1.3604e-01, -1.6816e-01,  2.9183e-02,  1.0745e-02, -6.1637e-02,\n",
            "         -2.4122e-01,  9.9546e-02,  1.1543e-01,  2.1404e-01,  6.1753e-02,\n",
            "          1.7705e-01, -1.0031e-01,  1.3965e-01, -8.4073e-02, -1.6164e-02,\n",
            "          4.7825e-02],\n",
            "        [-3.9372e-02, -1.2222e-01, -1.0357e-01,  2.2564e-01,  1.3276e-01,\n",
            "          1.7604e-01, -4.6910e-03, -1.7045e-01, -2.1251e-01,  1.6377e-01,\n",
            "         -2.0832e-01, -6.5124e-04, -2.2523e-01,  5.1690e-03,  8.2869e-02,\n",
            "          2.9326e-03],\n",
            "        [ 1.4313e-01,  6.1983e-02, -1.7447e-01,  1.0219e-01,  3.5456e-03,\n",
            "         -9.1232e-02,  5.5059e-02,  1.2665e-02, -9.5868e-02,  2.0192e-01,\n",
            "          1.8017e-02, -1.1104e-01,  1.7337e-01,  2.1884e-01, -9.2691e-02,\n",
            "         -1.8502e-01],\n",
            "        [-2.8324e-02,  1.0509e-01, -2.3856e-01,  2.2916e-02, -1.5650e-01,\n",
            "          8.7366e-03, -1.3547e-02,  8.6640e-02,  2.4301e-01,  1.2325e-01,\n",
            "         -1.4718e-01,  2.4406e-01,  3.1490e-01,  5.0178e-02,  1.1804e-01,\n",
            "         -9.6842e-03],\n",
            "        [ 8.1960e-02,  1.7264e-01,  2.3116e-02,  5.1466e-02, -1.7134e-02,\n",
            "         -2.5587e-01, -3.5853e-02, -2.7169e-01, -1.9165e-01, -1.4184e-01,\n",
            "          1.3712e-01,  3.2616e-02, -1.5610e-01, -5.0204e-02,  1.3383e-02,\n",
            "         -1.4695e-01],\n",
            "        [ 1.1471e-01, -1.2229e-01, -7.9304e-02,  1.6964e-01,  8.6664e-02,\n",
            "          2.1409e-01, -1.5925e-01, -1.0394e-01,  2.0021e-01,  1.4388e-01,\n",
            "          4.4371e-02, -1.0489e-01, -5.4600e-02, -1.5409e-01,  2.2961e-02,\n",
            "         -4.8558e-02],\n",
            "        [ 4.2582e-02, -1.1919e-01, -2.0727e-01,  2.8174e-01,  1.2924e-01,\n",
            "         -6.2074e-02,  1.9561e-01,  2.2852e-01, -2.1636e-01, -6.1592e-02,\n",
            "          8.9014e-02, -1.6651e-01,  3.0950e-01,  1.6304e-01, -2.8709e-02,\n",
            "         -1.5392e-01],\n",
            "        [-1.9705e-02,  1.0558e-02,  1.1735e-02, -3.7344e-02, -1.7287e-01,\n",
            "          3.6988e-02,  8.8957e-02, -2.0629e-01,  1.1976e-01,  1.4371e-01,\n",
            "          6.3613e-03,  1.5588e-01, -1.6702e-01, -1.0444e-01, -1.5333e-01,\n",
            "         -2.4597e-01],\n",
            "        [-3.0996e-01, -1.1673e-01,  5.0675e-02, -1.5127e-01,  1.3807e-01,\n",
            "         -4.8340e-02, -1.4436e-01,  6.4084e-02, -2.0163e-01, -1.1742e-01,\n",
            "         -4.6827e-02,  1.4351e-01, -1.3174e-02,  1.4764e-01,  6.0138e-02,\n",
            "         -1.8953e-01],\n",
            "        [-2.0683e-01, -5.6450e-02, -5.8739e-02,  7.7284e-02, -4.1912e-02,\n",
            "         -9.8821e-02, -1.1429e-01, -3.5937e-01,  8.7345e-02, -1.7022e-01,\n",
            "         -1.2511e-01,  1.5426e-01,  3.2253e-01, -1.4470e-02, -2.4544e-01,\n",
            "          1.5933e-01],\n",
            "        [ 1.1519e-01, -5.0207e-02, -8.2738e-02, -8.1500e-02, -2.7266e-01,\n",
            "          1.2192e-01,  1.8188e-01, -9.8487e-02,  1.8022e-01,  8.9168e-02,\n",
            "         -1.7937e-01, -8.3197e-02, -1.2280e-01,  2.0865e-01,  2.4836e-01,\n",
            "         -3.9604e-02],\n",
            "        [ 8.1174e-03, -1.1488e-01,  1.8652e-02, -1.7440e-01, -7.7156e-02,\n",
            "         -1.4428e-01,  7.9087e-02,  3.8629e-02, -1.1265e-01, -1.1626e-01,\n",
            "          2.6143e-01,  7.3711e-02,  4.5519e-01, -1.4862e-01,  8.1638e-02,\n",
            "          1.8737e-01],\n",
            "        [-2.2407e-01, -1.5138e-01,  6.2191e-02, -1.4322e-01,  1.6100e-01,\n",
            "         -1.7743e-01, -1.8073e-01, -2.1175e-01, -2.2617e-02, -2.2088e-01,\n",
            "         -1.0865e-01,  3.7797e-02,  3.4240e-01, -2.3606e-02, -6.7025e-02,\n",
            "         -1.2654e-01],\n",
            "        [ 1.1590e-01,  1.4031e-01, -3.1718e-02, -1.8930e-01, -2.0172e-01,\n",
            "          1.6705e-01, -3.9715e-03,  1.4416e-02, -1.4847e-01, -8.5948e-02,\n",
            "         -1.5479e-01, -2.0814e-01, -1.0915e-01, -6.4937e-02,  1.3536e-01,\n",
            "         -1.1252e-01],\n",
            "        [ 1.1400e-01,  1.2670e-01, -9.4142e-02,  2.2125e-01,  8.7769e-02,\n",
            "         -1.4122e-01, -2.1704e-01,  2.5342e-01, -2.3804e-01, -2.2721e-01,\n",
            "          1.4857e-01, -6.4671e-02,  1.9436e-01,  1.2261e-02, -1.0116e-01,\n",
            "          1.2413e-01],\n",
            "        [ 1.4834e-01,  8.0033e-02, -2.4048e-01,  1.7771e-01, -2.3158e-01,\n",
            "         -7.6329e-02, -2.0996e-01, -6.3100e-02,  1.5372e-02,  1.3870e-01,\n",
            "         -1.4880e-01, -2.1168e-01,  2.0207e-01,  1.1287e-01,  1.4759e-01,\n",
            "         -6.6902e-02],\n",
            "        [-3.4798e-01,  1.6081e-01,  2.0357e-02,  1.9081e-01,  5.0584e-02,\n",
            "          1.9415e-03,  1.7567e-01, -6.2626e-03, -2.0720e-01, -1.1828e-01,\n",
            "          5.8440e-03,  6.1712e-02,  3.9281e-01, -2.9780e-01, -5.9036e-02,\n",
            "         -1.2758e-01],\n",
            "        [-2.0107e-01,  1.6456e-01,  1.8407e-01, -1.2933e-01,  6.4227e-02,\n",
            "         -1.3238e-01,  2.1583e-01,  1.3864e-01,  2.6785e-02,  1.4554e-01,\n",
            "          1.4246e-01, -2.1732e-01,  3.6441e-01,  1.5745e-01, -2.2281e-01,\n",
            "         -7.5553e-02],\n",
            "        [ 9.3545e-02, -1.8865e-01,  8.2021e-02,  2.0978e-01,  4.2600e-02,\n",
            "         -9.7730e-03, -1.8544e-01, -2.1497e-01,  6.3763e-02, -1.5792e-01,\n",
            "          1.3635e-01, -8.8699e-02, -1.5875e-02, -2.1054e-01, -2.1461e-01,\n",
            "          9.2810e-02],\n",
            "        [-1.9315e-01,  1.2705e-02,  1.6118e-02, -8.3285e-02,  2.0793e-01,\n",
            "          9.9304e-02,  1.7240e-01,  9.4548e-02,  2.2899e-01, -1.2062e-01,\n",
            "         -1.3881e-01,  2.5905e-01, -6.1791e-02, -2.7566e-02, -7.4084e-02,\n",
            "         -1.7856e-01],\n",
            "        [-1.4232e-01, -6.0751e-02, -7.0747e-02,  9.9476e-02,  6.8895e-03,\n",
            "          9.1614e-02,  2.3037e-01,  2.6472e-01,  1.1738e-01, -2.1740e-02,\n",
            "         -3.0149e-01, -7.2115e-02,  6.7484e-02, -3.1745e-02, -2.1295e-01,\n",
            "         -1.7590e-01]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([ 0.1089,  0.0497, -0.2502,  0.0047, -0.0178,  0.0242, -0.1570,  0.1806,\n",
            "        -0.1977,  0.1025,  0.1536, -0.1971,  0.0304, -0.0693, -0.1604, -0.0634,\n",
            "         0.1852, -0.2088,  0.0131, -0.3451, -0.0474, -0.0816, -0.1148, -0.2092,\n",
            "         0.1305,  0.0433, -0.0430, -0.0532, -0.3834,  0.0726, -0.1029, -0.0379],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[ 0.0968, -0.0247, -0.0150, -0.0238, -0.0143, -0.0005, -0.1188,  0.2026,\n",
            "          0.0780, -0.0192, -0.0174,  0.1575,  0.0075,  0.0150, -0.0807, -0.0064,\n",
            "         -0.0051, -0.0360,  0.1045,  0.0205,  0.0333,  0.0411, -0.1346, -0.0768,\n",
            "          0.0724,  0.0403, -0.1625, -0.0562,  0.0378, -0.0261,  0.0085, -0.1008]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([-0.0030], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1000 Trajectories:"
      ],
      "metadata": {
        "id": "vkoraLdAJMad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# single cumprod\n",
        "# 1000 trajectories\n",
        "model11 = train_var_play(model10, 500, 0.0001, padded_state_tensors, states_first_tensor, states_last_tensor, 1, 1, testing)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7wNPtMDLjuq",
        "outputId": "7f9ffd94-4372-425f-a352-08a0eeb8e8a7"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8435369920087568e-06\n",
            "E_s_wdiff_all_sq: 9.069579199805096e-08\n",
            "E_IS_SCOPE: -1.1038198776012357e-05\n",
            "E_IS_E_SCOPE: -9.750861916403596e-06\n",
            "Total Loss: 3.032905472266013e-07\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "Var loss:  tensor(2.8471e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6681551818117882e-06\n",
            "E_s_wdiff_all_sq: 1.4820307511116906e-10\n",
            "E_IS_SCOPE: -1.013852417975717e-05\n",
            "E_IS_E_SCOPE: -8.884314617475877e-06\n",
            "Total Loss: 2.8471092060750724e-07\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "Var loss:  tensor(3.2981e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7046211317725032e-06\n",
            "E_s_wdiff_all_sq: 4.237948817006082e-08\n",
            "E_IS_SCOPE: -9.460547193621885e-06\n",
            "E_IS_E_SCOPE: -8.231770336608416e-06\n",
            "Total Loss: 3.2981099600892257e-07\n",
            "----------------------------------------\n",
            "Epoch 14\n",
            "Var loss:  tensor(3.4469e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7323293298567792e-06\n",
            "E_s_wdiff_all_sq: 6.635520273798164e-08\n",
            "E_IS_SCOPE: -9.318184677880333e-06\n",
            "E_IS_E_SCOPE: -8.09497858587953e-06\n",
            "Total Loss: 3.446850095506056e-07\n",
            "----------------------------------------\n",
            "Epoch 15\n",
            "Var loss:  tensor(3.0606e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6771839375519107e-06\n",
            "E_s_wdiff_all_sq: 2.1624156834102108e-08\n",
            "E_IS_SCOPE: -9.697189173535676e-06\n",
            "E_IS_E_SCOPE: -8.4598758712155e-06\n",
            "Total Loss: 3.0605624251087236e-07\n",
            "----------------------------------------\n",
            "Epoch 16\n",
            "Var loss:  tensor(2.7890e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6809097910442335e-06\n",
            "E_s_wdiff_all_sq: 2.7394327085961113e-09\n",
            "E_IS_SCOPE: -1.0353392876240718e-05\n",
            "E_IS_E_SCOPE: -9.091198577162251e-06\n",
            "Total Loss: 2.789048266121174e-07\n",
            "----------------------------------------\n",
            "Epoch 17\n",
            "Var loss:  tensor(2.9800e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8017804567123004e-06\n",
            "E_s_wdiff_all_sq: 5.819853221471494e-08\n",
            "E_IS_SCOPE: -1.09555982516869e-05\n",
            "E_IS_E_SCOPE: -9.670246106715022e-06\n",
            "Total Loss: 2.9800070098724416e-07\n",
            "----------------------------------------\n",
            "Epoch 18\n",
            "Var loss:  tensor(3.2048e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8969961180210046e-06\n",
            "E_s_wdiff_all_sq: 1.1019503763098044e-07\n",
            "E_IS_SCOPE: -1.1214237305682962e-05\n",
            "E_IS_E_SCOPE: -9.91851288625117e-06\n",
            "Total Loss: 3.20475307959855e-07\n",
            "----------------------------------------\n",
            "Epoch 19\n",
            "Var loss:  tensor(3.0660e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8480626340308605e-06\n",
            "E_s_wdiff_all_sq: 8.716692414689072e-08\n",
            "E_IS_SCOPE: -1.1039250381753849e-05\n",
            "E_IS_E_SCOPE: -9.749540773018597e-06\n",
            "Total Loss: 3.0659955884688105e-07\n",
            "----------------------------------------\n",
            "Epoch 20\n",
            "Var loss:  tensor(2.8092e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7263589137825757e-06\n",
            "E_s_wdiff_all_sq: 2.7093288370840447e-08\n",
            "E_IS_SCOPE: -1.0549193306570451e-05\n",
            "E_IS_E_SCOPE: -9.277456981699345e-06\n",
            "Total Loss: 2.809160421029356e-07\n",
            "----------------------------------------\n",
            "Epoch 21\n",
            "Var loss:  tensor(2.8161e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6585675003353047e-06\n",
            "E_s_wdiff_all_sq: 1.5048879050382775e-10\n",
            "E_IS_SCOPE: -9.988300349096995e-06\n",
            "E_IS_E_SCOPE: -8.73733477946256e-06\n",
            "Total Loss: 2.81608938709348e-07\n",
            "----------------------------------------\n",
            "Epoch 22\n",
            "Var loss:  tensor(2.9975e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.656183210809849e-06\n",
            "E_s_wdiff_all_sq: 7.0180357459615034e-09\n",
            "E_IS_SCOPE: -9.619636655739366e-06\n",
            "E_IS_E_SCOPE: -8.382369874497133e-06\n",
            "Total Loss: 2.9975467901283864e-07\n",
            "----------------------------------------\n",
            "Epoch 23\n",
            "Var loss:  tensor(3.0090e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6546854679117633e-06\n",
            "E_s_wdiff_all_sq: 6.07679079287042e-09\n",
            "E_IS_SCOPE: -9.597536756834598e-06\n",
            "E_IS_E_SCOPE: -8.361122973005699e-06\n",
            "Total Loss: 3.009041758945099e-07\n",
            "----------------------------------------\n",
            "Epoch 24\n",
            "Var loss:  tensor(2.8374e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6540051363120575e-06\n",
            "E_s_wdiff_all_sq: 4.834190648879977e-10\n",
            "E_IS_SCOPE: -9.897225454613175e-06\n",
            "E_IS_E_SCOPE: -8.649775199159999e-06\n",
            "Total Loss: 2.8374427277423233e-07\n",
            "----------------------------------------\n",
            "Epoch 25\n",
            "Var loss:  tensor(2.7597e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7066197763006891e-06\n",
            "E_s_wdiff_all_sq: 2.7509847190423823e-08\n",
            "E_IS_SCOPE: -1.0351394058015706e-05\n",
            "E_IS_E_SCOPE: -9.087261235238343e-06\n",
            "Total Loss: 2.759673499889514e-07\n",
            "----------------------------------------\n",
            "Epoch 26\n",
            "Var loss:  tensor(2.8587e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7992694006032959e-06\n",
            "E_s_wdiff_all_sq: 8.221050283084085e-08\n",
            "E_IS_SCOPE: -1.0736313291300548e-05\n",
            "E_IS_E_SCOPE: -9.458159443730113e-06\n",
            "Total Loss: 2.858742690650022e-07\n",
            "----------------------------------------\n",
            "Epoch 27\n",
            "Var loss:  tensor(2.9223e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8438440398062562e-06\n",
            "E_s_wdiff_all_sq: 1.1061199634434994e-07\n",
            "E_IS_SCOPE: -1.0875971347590517e-05\n",
            "E_IS_E_SCOPE: -9.592908058398854e-06\n",
            "Total Loss: 2.922285315119952e-07\n",
            "----------------------------------------\n",
            "Epoch 28\n",
            "Var loss:  tensor(2.8333e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7985129581236776e-06\n",
            "E_s_wdiff_all_sq: 8.522802025912445e-08\n",
            "E_IS_SCOPE: -1.073060654579793e-05\n",
            "E_IS_E_SCOPE: -9.453065219652134e-06\n",
            "Total Loss: 2.8332535200637716e-07\n",
            "----------------------------------------\n",
            "Epoch 29\n",
            "Var loss:  tensor(2.7433e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7183258676331013e-06\n",
            "E_s_wdiff_all_sq: 3.825185134239775e-08\n",
            "E_IS_SCOPE: -1.040134421201283e-05\n",
            "E_IS_E_SCOPE: -9.135909792211953e-06\n",
            "Total Loss: 2.7432824312236516e-07\n",
            "----------------------------------------\n",
            "Epoch 30\n",
            "Var loss:  tensor(2.7817e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6695471996792159e-06\n",
            "E_s_wdiff_all_sq: 9.579788770699002e-09\n",
            "E_IS_SCOPE: -1.0070098569364722e-05\n",
            "E_IS_E_SCOPE: -8.816638982144357e-06\n",
            "Total Loss: 2.781713029012037e-07\n",
            "----------------------------------------\n",
            "Epoch 31\n",
            "Var loss:  tensor(2.8465e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6574289329627577e-06\n",
            "E_s_wdiff_all_sq: 2.383153220342337e-09\n",
            "E_IS_SCOPE: -9.90547208542088e-06\n",
            "E_IS_E_SCOPE: -8.657711996004091e-06\n",
            "Total Loss: 2.8464866734225333e-07\n",
            "----------------------------------------\n",
            "Epoch 32\n",
            "Var loss:  tensor(2.8093e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6621009246577875e-06\n",
            "E_s_wdiff_all_sq: 4.828221179828129e-09\n",
            "E_IS_SCOPE: -9.9761540331261e-06\n",
            "E_IS_E_SCOPE: -8.72542341588035e-06\n",
            "Total Loss: 2.8093453541987614e-07\n",
            "----------------------------------------\n",
            "Epoch 33\n",
            "Var loss:  tensor(2.7343e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.688675314338477e-06\n",
            "E_s_wdiff_all_sq: 2.0101730256030135e-08\n",
            "E_IS_SCOPE: -1.02256004733299e-05\n",
            "E_IS_E_SCOPE: -8.965468562112827e-06\n",
            "Total Loss: 2.7343282808171837e-07\n",
            "----------------------------------------\n",
            "Epoch 34\n",
            "Var loss:  tensor(2.7392e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7395695851463808e-06\n",
            "E_s_wdiff_all_sq: 4.9720805790818394e-08\n",
            "E_IS_SCOPE: -1.0509647848056694e-05\n",
            "E_IS_E_SCOPE: -9.239123962011318e-06\n",
            "Total Loss: 2.7392407369822753e-07\n",
            "----------------------------------------\n",
            "Epoch 35\n",
            "Var loss:  tensor(2.7874e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7779000417897504e-06\n",
            "E_s_wdiff_all_sq: 7.144356849692458e-08\n",
            "E_IS_SCOPE: -1.0674123965770139e-05\n",
            "E_IS_E_SCOPE: -9.397703046751705e-06\n",
            "Total Loss: 2.7873770168937406e-07\n",
            "----------------------------------------\n",
            "Epoch 36\n",
            "Var loss:  tensor(2.7748e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7653944115231058e-06\n",
            "E_s_wdiff_all_sq: 6.282728384254235e-08\n",
            "E_IS_SCOPE: -1.0638127519760087e-05\n",
            "E_IS_E_SCOPE: -9.363020197556958e-06\n",
            "Total Loss: 2.774755497077237e-07\n",
            "----------------------------------------\n",
            "Epoch 37\n",
            "Var loss:  tensor(2.7209e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.71610358233623e-06\n",
            "E_s_wdiff_all_sq: 3.3356438660741866e-08\n",
            "E_IS_SCOPE: -1.043233953055605e-05\n",
            "E_IS_E_SCOPE: -9.164451798514617e-06\n",
            "Total Loss: 2.7209474602603907e-07\n",
            "----------------------------------------\n",
            "Epoch 38\n",
            "Var loss:  tensor(2.7146e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6743945915731427e-06\n",
            "E_s_wdiff_all_sq: 9.699209097463843e-09\n",
            "E_IS_SCOPE: -1.0177104032858885e-05\n",
            "E_IS_E_SCOPE: -8.91792466823561e-06\n",
            "Total Loss: 2.714597196625433e-07\n",
            "----------------------------------------\n",
            "Epoch 39\n",
            "Var loss:  tensor(2.7465e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6588719987574969e-06\n",
            "E_s_wdiff_all_sq: 1.569561423769858e-09\n",
            "E_IS_SCOPE: -1.0010334931618548e-05\n",
            "E_IS_E_SCOPE: -8.756444857804298e-06\n",
            "Total Loss: 2.746453561386403e-07\n",
            "----------------------------------------\n",
            "Epoch 40\n",
            "Var loss:  tensor(2.7412e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.659312993395853e-06\n",
            "E_s_wdiff_all_sq: 9.675658626765192e-10\n",
            "E_IS_SCOPE: -1.0014069263921202e-05\n",
            "E_IS_E_SCOPE: -8.759394030441759e-06\n",
            "Total Loss: 2.7411802700770695e-07\n",
            "----------------------------------------\n",
            "Epoch 41\n",
            "Var loss:  tensor(2.7031e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.671059484881144e-06\n",
            "E_s_wdiff_all_sq: 4.646271766222259e-09\n",
            "E_IS_SCOPE: -1.0169902172356884e-05\n",
            "E_IS_E_SCOPE: -8.909287000225669e-06\n",
            "Total Loss: 2.7030593528590487e-07\n",
            "----------------------------------------\n",
            "Epoch 42\n",
            "Var loss:  tensor(2.6953e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6955407571355302e-06\n",
            "E_s_wdiff_all_sq: 1.4921697913525555e-08\n",
            "E_IS_SCOPE: -1.0378385203481073e-05\n",
            "E_IS_E_SCOPE: -9.110281596144436e-06\n",
            "Total Loss: 2.6953491098214627e-07\n",
            "----------------------------------------\n",
            "Epoch 43\n",
            "Var loss:  tensor(2.7160e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7169536650224805e-06\n",
            "E_s_wdiff_all_sq: 2.4886194164612132e-08\n",
            "E_IS_SCOPE: -1.051738333373614e-05\n",
            "E_IS_E_SCOPE: -9.2445875011386e-06\n",
            "Total Loss: 2.715988720962057e-07\n",
            "----------------------------------------\n",
            "Epoch 44\n",
            "Var loss:  tensor(2.7114e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7144924018112085e-06\n",
            "E_s_wdiff_all_sq: 2.3781199635505362e-08\n",
            "E_IS_SCOPE: -1.0514133680660362e-05\n",
            "E_IS_E_SCOPE: -9.24178548497944e-06\n",
            "Total Loss: 2.711378772472746e-07\n",
            "----------------------------------------\n",
            "Epoch 45\n",
            "Var loss:  tensor(2.6839e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6915426963399843e-06\n",
            "E_s_wdiff_all_sq: 1.3317684808283942e-08\n",
            "E_IS_SCOPE: -1.038222583466663e-05\n",
            "E_IS_E_SCOPE: -9.114749085637569e-06\n",
            "Total Loss: 2.68394579906992e-07\n",
            "----------------------------------------\n",
            "Epoch 46\n",
            "Var loss:  tensor(2.6782e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6700411080063385e-06\n",
            "E_s_wdiff_all_sq: 4.535386397575181e-09\n",
            "E_IS_SCOPE: -1.020833430254202e-05\n",
            "E_IS_E_SCOPE: -8.946932347961355e-06\n",
            "Total Loss: 2.6782487888084654e-07\n",
            "----------------------------------------\n",
            "Epoch 47\n",
            "Var loss:  tensor(2.6908e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6610411768665737e-06\n",
            "E_s_wdiff_all_sq: 1.7326342566753764e-09\n",
            "E_IS_SCOPE: -1.00977639026607e-05\n",
            "E_IS_E_SCOPE: -8.840088954133444e-06\n",
            "Total Loss: 2.6908171198880004e-07\n",
            "----------------------------------------\n",
            "Epoch 48\n",
            "Var loss:  tensor(2.6843e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6628066778868443e-06\n",
            "E_s_wdiff_all_sq: 3.0908016453067334e-09\n",
            "E_IS_SCOPE: -1.0111004029943194e-05\n",
            "E_IS_E_SCOPE: -8.852801825385503e-06\n",
            "Total Loss: 2.684345335595736e-07\n",
            "----------------------------------------\n",
            "Epoch 49\n",
            "Var loss:  tensor(2.6645e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6764625717159275e-06\n",
            "E_s_wdiff_all_sq: 1.0667099139353596e-08\n",
            "E_IS_SCOPE: -1.0229238553510087e-05\n",
            "E_IS_E_SCOPE: -8.96700363585541e-06\n",
            "Total Loss: 2.664487037006344e-07\n",
            "----------------------------------------\n",
            "Epoch 50\n",
            "Var loss:  tensor(2.6617e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7007742196165464e-06\n",
            "E_s_wdiff_all_sq: 2.5642278851107286e-08\n",
            "E_IS_SCOPE: -1.037407816013836e-05\n",
            "E_IS_E_SCOPE: -9.107036118964874e-06\n",
            "Total Loss: 2.661709248518852e-07\n",
            "----------------------------------------\n",
            "Epoch 51\n",
            "Var loss:  tensor(2.6684e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7205066919778037e-06\n",
            "E_s_wdiff_all_sq: 3.941964509775908e-08\n",
            "E_IS_SCOPE: -1.0457372341022442e-05\n",
            "E_IS_E_SCOPE: -9.18768873797364e-06\n",
            "Total Loss: 2.6684290721585447e-07\n",
            "----------------------------------------\n",
            "Epoch 52\n",
            "Var loss:  tensor(2.6599e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7201163618590407e-06\n",
            "E_s_wdiff_all_sq: 4.1737694905049835e-08\n",
            "E_IS_SCOPE: -1.0432515549215233e-05\n",
            "E_IS_E_SCOPE: -9.163757980750616e-06\n",
            "Total Loss: 2.659865964581729e-07\n",
            "----------------------------------------\n",
            "Epoch 53\n",
            "Var loss:  tensor(2.6456e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7033898788555505e-06\n",
            "E_s_wdiff_all_sq: 3.360087996965589e-08\n",
            "E_IS_SCOPE: -1.0323273068031307e-05\n",
            "E_IS_E_SCOPE: -9.058094584576157e-06\n",
            "Total Loss: 2.645550984090112e-07\n",
            "----------------------------------------\n",
            "Epoch 54\n",
            "Var loss:  tensor(2.6451e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6866974174824644e-06\n",
            "E_s_wdiff_all_sq: 2.449915043027074e-08\n",
            "E_IS_SCOPE: -1.0204731180126292e-05\n",
            "E_IS_E_SCOPE: -8.94332793802133e-06\n",
            "Total Loss: 2.6451484927568523e-07\n",
            "----------------------------------------\n",
            "Epoch 55\n",
            "Var loss:  tensor(2.6471e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6805090730716287e-06\n",
            "E_s_wdiff_all_sq: 2.1157753439095683e-08\n",
            "E_IS_SCOPE: -1.0153382997093178e-05\n",
            "E_IS_E_SCOPE: -8.893499534188353e-06\n",
            "Total Loss: 2.6470746025629633e-07\n",
            "----------------------------------------\n",
            "Epoch 56\n",
            "Var loss:  tensor(2.6373e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6859556244337802e-06\n",
            "E_s_wdiff_all_sq: 2.4679244959016808e-08\n",
            "E_IS_SCOPE: -1.0194442276697134e-05\n",
            "E_IS_E_SCOPE: -8.933107365418894e-06\n",
            "Total Loss: 2.6372962335170036e-07\n",
            "----------------------------------------\n",
            "Epoch 57\n",
            "Var loss:  tensor(2.6277e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6999397898224377e-06\n",
            "E_s_wdiff_all_sq: 3.309090192137437e-08\n",
            "E_IS_SCOPE: -1.0293761592938672e-05\n",
            "E_IS_E_SCOPE: -9.029161518063023e-06\n",
            "Total Loss: 2.6277180458318033e-07\n",
            "----------------------------------------\n",
            "Epoch 58\n",
            "Var loss:  tensor(2.6278e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.712900179163878e-06\n",
            "E_s_wdiff_all_sq: 4.0354741865224495e-08\n",
            "E_IS_SCOPE: -1.0383789899492356e-05\n",
            "E_IS_E_SCOPE: -9.116343933255279e-06\n",
            "Total Loss: 2.6277657125791473e-07\n",
            "----------------------------------------\n",
            "Epoch 59\n",
            "Var loss:  tensor(2.6256e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7133490944394828e-06\n",
            "E_s_wdiff_all_sq: 3.976445027982784e-08\n",
            "E_IS_SCOPE: -1.040930318296914e-05\n",
            "E_IS_E_SCOPE: -9.141227590330314e-06\n",
            "Total Loss: 2.625565253154178e-07\n",
            "----------------------------------------\n",
            "Epoch 60\n",
            "Var loss:  tensor(2.6160e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7005683027948266e-06\n",
            "E_s_wdiff_all_sq: 3.1409142139555215e-08\n",
            "E_IS_SCOPE: -1.0358677924371899e-05\n",
            "E_IS_E_SCOPE: -9.092338059636917e-06\n",
            "Total Loss: 2.6160249761872307e-07\n",
            "----------------------------------------\n",
            "Epoch 61\n",
            "Var loss:  tensor(2.6102e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6846679473639299e-06\n",
            "E_s_wdiff_all_sq: 2.1525628806611662e-08\n",
            "E_IS_SCOPE: -1.0273607892391687e-05\n",
            "E_IS_E_SCOPE: -9.009984759264032e-06\n",
            "Total Loss: 2.6101911873542425e-07\n",
            "----------------------------------------\n",
            "Epoch 62\n",
            "Var loss:  tensor(2.6095e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6753804916220374e-06\n",
            "E_s_wdiff_all_sq: 1.5767248312170563e-08\n",
            "E_IS_SCOPE: -1.021932237921305e-05\n",
            "E_IS_E_SCOPE: -8.95743031263865e-06\n",
            "Total Loss: 2.609521765944829e-07\n",
            "----------------------------------------\n",
            "Epoch 63\n",
            "Var loss:  tensor(2.6043e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6754474621028189e-06\n",
            "E_s_wdiff_all_sq: 1.555849222252975e-08\n",
            "E_IS_SCOPE: -1.023144871980216e-05\n",
            "E_IS_E_SCOPE: -8.969156838861936e-06\n",
            "Total Loss: 2.6042827443325253e-07\n",
            "----------------------------------------\n",
            "Epoch 64\n",
            "Var loss:  tensor(2.5963e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6833450004286785e-06\n",
            "E_s_wdiff_all_sq: 2.00222283492076e-08\n",
            "E_IS_SCOPE: -1.0297261690842088e-05\n",
            "E_IS_E_SCOPE: -9.032854478472763e-06\n",
            "Total Loss: 2.5963141377423665e-07\n",
            "----------------------------------------\n",
            "Epoch 65\n",
            "Var loss:  tensor(2.5928e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6938466470010356e-06\n",
            "E_s_wdiff_all_sq: 2.6212260038095294e-08\n",
            "E_IS_SCOPE: -1.0368941428475684e-05\n",
            "E_IS_E_SCOPE: -9.102200319473801e-06\n",
            "Total Loss: 2.592752353925906e-07\n",
            "----------------------------------------\n",
            "Epoch 66\n",
            "Var loss:  tensor(2.5901e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6991444088206006e-06\n",
            "E_s_wdiff_all_sq: 2.968474046573108e-08\n",
            "E_IS_SCOPE: -1.040033976517296e-05\n",
            "E_IS_E_SCOPE: -9.132553826772803e-06\n",
            "Total Loss: 2.5901085798797174e-07\n",
            "----------------------------------------\n",
            "Epoch 67\n",
            "Var loss:  tensor(2.5836e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6952385391430819e-06\n",
            "E_s_wdiff_all_sq: 2.8056837322549774e-08\n",
            "E_IS_SCOPE: -1.0375143866669837e-05\n",
            "E_IS_E_SCOPE: -9.108169757822188e-06\n",
            "Total Loss: 2.583565505586515e-07\n",
            "----------------------------------------\n",
            "Epoch 68\n",
            "Var loss:  tensor(2.5774e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6861299915438776e-06\n",
            "E_s_wdiff_all_sq: 2.3616246356267666e-08\n",
            "E_IS_SCOPE: -1.0313852323114753e-05\n",
            "E_IS_E_SCOPE: -9.04890338540679e-06\n",
            "Total Loss: 2.5773893620509985e-07\n",
            "----------------------------------------\n",
            "Epoch 69\n",
            "Var loss:  tensor(2.5744e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6795925224295217e-06\n",
            "E_s_wdiff_all_sq: 2.0777977201148218e-08\n",
            "E_IS_SCOPE: -1.026252868496401e-05\n",
            "E_IS_E_SCOPE: -8.999280305833908e-06\n",
            "Total Loss: 2.5744085340158523e-07\n",
            "----------------------------------------\n",
            "Epoch 70\n",
            "Var loss:  tensor(2.5700e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6800677379171797e-06\n",
            "E_s_wdiff_all_sq: 2.178652902639422e-08\n",
            "E_IS_SCOPE: -1.0259703383982257e-05\n",
            "E_IS_E_SCOPE: -8.996499770074034e-06\n",
            "Total Loss: 2.5699704750775524e-07\n",
            "----------------------------------------\n",
            "Epoch 71\n",
            "Var loss:  tensor(2.5633e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6873302316837961e-06\n",
            "E_s_wdiff_all_sq: 2.6672399417262403e-08\n",
            "E_IS_SCOPE: -1.0302736744762634e-05\n",
            "E_IS_E_SCOPE: -9.038011193109923e-06\n",
            "Total Loss: 2.5632979539452785e-07\n",
            "----------------------------------------\n",
            "Epoch 72\n",
            "Var loss:  tensor(2.5589e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6969551657655534e-06\n",
            "E_s_wdiff_all_sq: 3.2926729684886056e-08\n",
            "E_IS_SCOPE: -1.0357699113701884e-05\n",
            "E_IS_E_SCOPE: -9.09106912618483e-06\n",
            "Total Loss: 2.558915274799738e-07\n",
            "----------------------------------------\n",
            "Epoch 73\n",
            "Var loss:  tensor(2.5553e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7018017089726907e-06\n",
            "E_s_wdiff_all_sq: 3.6382618581506375e-08\n",
            "E_IS_SCOPE: -1.0383623092620069e-05\n",
            "E_IS_E_SCOPE: -9.116117253468467e-06\n",
            "Total Loss: 2.555304785213972e-07\n",
            "----------------------------------------\n",
            "Epoch 74\n",
            "Var loss:  tensor(2.5494e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6986675579630156e-06\n",
            "E_s_wdiff_all_sq: 3.5138170036746104e-08\n",
            "E_IS_SCOPE: -1.0367479227714155e-05\n",
            "E_IS_E_SCOPE: -9.100623491040543e-06\n",
            "Total Loss: 2.5494098101245916e-07\n",
            "----------------------------------------\n",
            "Epoch 75\n",
            "Var loss:  tensor(2.5439e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.691336738703416e-06\n",
            "E_s_wdiff_all_sq: 3.1319864072879146e-08\n",
            "E_IS_SCOPE: -1.0327295495612857e-05\n",
            "E_IS_E_SCOPE: -9.061919254679542e-06\n",
            "Total Loss: 2.5438745919732187e-07\n",
            "----------------------------------------\n",
            "Epoch 76\n",
            "Var loss:  tensor(2.5399e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.68625377228405e-06\n",
            "E_s_wdiff_all_sq: 2.8847371466938995e-08\n",
            "E_IS_SCOPE: -1.0297841802881952e-05\n",
            "E_IS_E_SCOPE: -9.033572898476192e-06\n",
            "Total Loss: 2.5399165843900944e-07\n",
            "----------------------------------------\n",
            "Epoch 77\n",
            "Var loss:  tensor(2.5350e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6869615427594639e-06\n",
            "E_s_wdiff_all_sq: 2.991807328767732e-08\n",
            "E_IS_SCOPE: -1.0303328543166916e-05\n",
            "E_IS_E_SCOPE: -9.038996351620883e-06\n",
            "Total Loss: 2.53502152813134e-07\n",
            "----------------------------------------\n",
            "Epoch 78\n",
            "Var loss:  tensor(2.5291e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6926371057306124e-06\n",
            "E_s_wdiff_all_sq: 3.401659189511269e-08\n",
            "E_IS_SCOPE: -1.033884027112403e-05\n",
            "E_IS_E_SCOPE: -9.07342309635166e-06\n",
            "Total Loss: 2.5290923072417385e-07\n",
            "----------------------------------------\n",
            "Epoch 79\n",
            "Var loss:  tensor(2.5245e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6991088449331352e-06\n",
            "E_s_wdiff_all_sq: 3.856102807188364e-08\n",
            "E_IS_SCOPE: -1.0377310638533448e-05\n",
            "E_IS_E_SCOPE: -9.110698742504925e-06\n",
            "Total Loss: 2.524470912376194e-07\n",
            "----------------------------------------\n",
            "Epoch 80\n",
            "Var loss:  tensor(2.5200e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7009310612530155e-06\n",
            "E_s_wdiff_all_sq: 4.005269032608846e-08\n",
            "E_IS_SCOPE: -1.0392116091667854e-05\n",
            "E_IS_E_SCOPE: -9.125115354444773e-06\n",
            "Total Loss: 2.519999629141794e-07\n",
            "----------------------------------------\n",
            "Epoch 81\n",
            "Var loss:  tensor(2.5144e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6966764378245395e-06\n",
            "E_s_wdiff_all_sq: 3.771075791094428e-08\n",
            "E_IS_SCOPE: -1.0374844450179033e-05\n",
            "E_IS_E_SCOPE: -9.108519528487823e-06\n",
            "Total Loss: 2.5143890296459267e-07\n",
            "----------------------------------------\n",
            "Epoch 82\n",
            "Var loss:  tensor(2.5092e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6903567823540141e-06\n",
            "E_s_wdiff_all_sq: 3.3946121441320736e-08\n",
            "E_IS_SCOPE: -1.0343716826748964e-05\n",
            "E_IS_E_SCOPE: -9.078407923984629e-06\n",
            "Total Loss: 2.5091592181743857e-07\n",
            "----------------------------------------\n",
            "Epoch 83\n",
            "Var loss:  tensor(2.5046e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6868975641107207e-06\n",
            "E_s_wdiff_all_sq: 3.191221886486607e-08\n",
            "E_IS_SCOPE: -1.0326249017078746e-05\n",
            "E_IS_E_SCOPE: -9.06142505098491e-06\n",
            "Total Loss: 2.5046047949159915e-07\n",
            "----------------------------------------\n",
            "Epoch 84\n",
            "Var loss:  tensor(2.4993e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6877545976774454e-06\n",
            "E_s_wdiff_all_sq: 3.255838336680427e-08\n",
            "E_IS_SCOPE: -1.0337004492665508e-05\n",
            "E_IS_E_SCOPE: -9.071809217210522e-06\n",
            "Total Loss: 2.499287298340844e-07\n",
            "----------------------------------------\n",
            "Epoch 85\n",
            "Var loss:  tensor(2.4940e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6913967052814574e-06\n",
            "E_s_wdiff_all_sq: 3.499453223176534e-08\n",
            "E_IS_SCOPE: -1.0367684007349612e-05\n",
            "E_IS_E_SCOPE: -9.101620531403742e-06\n",
            "Total Loss: 2.4939828759136826e-07\n",
            "----------------------------------------\n",
            "Epoch 86\n",
            "Var loss:  tensor(2.4892e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6942272265366266e-06\n",
            "E_s_wdiff_all_sq: 3.718146574746891e-08\n",
            "E_IS_SCOPE: -1.0391048031284924e-05\n",
            "E_IS_E_SCOPE: -9.124421282249255e-06\n",
            "Total Loss: 2.4891532915123697e-07\n",
            "----------------------------------------\n",
            "Epoch 87\n",
            "Var loss:  tensor(2.4840e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6936831451070829e-06\n",
            "E_s_wdiff_all_sq: 3.7277709581075264e-08\n",
            "E_IS_SCOPE: -1.0391378522643025e-05\n",
            "E_IS_E_SCOPE: -9.124813721269722e-06\n",
            "Total Loss: 2.483988992128177e-07\n",
            "----------------------------------------\n",
            "Epoch 88\n",
            "Var loss:  tensor(2.4785e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6910714802243535e-06\n",
            "E_s_wdiff_all_sq: 3.5850913573887225e-08\n",
            "E_IS_SCOPE: -1.0373839366150871e-05\n",
            "E_IS_E_SCOPE: -9.107594570107407e-06\n",
            "Total Loss: 2.4785404099695315e-07\n",
            "----------------------------------------\n",
            "Epoch 89\n",
            "Var loss:  tensor(2.4735e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6885233322919809e-06\n",
            "E_s_wdiff_all_sq: 3.4403133696025766e-08\n",
            "E_IS_SCOPE: -1.0355011283800988e-05\n",
            "E_IS_E_SCOPE: -9.089064857947725e-06\n",
            "Total Loss: 2.47350413322845e-07\n",
            "----------------------------------------\n",
            "Epoch 90\n",
            "Var loss:  tensor(2.4685e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6879839029304935e-06\n",
            "E_s_wdiff_all_sq: 3.4323003697155966e-08\n",
            "E_IS_SCOPE: -1.0352187993372817e-05\n",
            "E_IS_E_SCOPE: -9.086222531448017e-06\n",
            "Total Loss: 2.4685304181715416e-07\n",
            "----------------------------------------\n",
            "Epoch 91\n",
            "Var loss:  tensor(2.4630e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.689582004464503e-06\n",
            "E_s_wdiff_all_sq: 3.584407588348409e-08\n",
            "E_IS_SCOPE: -1.0366366812968455e-05\n",
            "E_IS_E_SCOPE: -9.100088251447194e-06\n",
            "Total Loss: 2.463038719719139e-07\n",
            "----------------------------------------\n",
            "Epoch 92\n",
            "Var loss:  tensor(2.4577e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6922601381365734e-06\n",
            "E_s_wdiff_all_sq: 3.82415669918161e-08\n",
            "E_IS_SCOPE: -1.038658169615555e-05\n",
            "E_IS_E_SCOPE: -9.11989819409313e-06\n",
            "Total Loss: 2.4577463345332984e-07\n",
            "----------------------------------------\n",
            "Epoch 93\n",
            "Var loss:  tensor(2.4528e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6942455261185151e-06\n",
            "E_s_wdiff_all_sq: 4.0139691320894116e-08\n",
            "E_IS_SCOPE: -1.0398199454984302e-05\n",
            "E_IS_E_SCOPE: -9.131224824202295e-06\n",
            "Total Loss: 2.452796396670227e-07\n",
            "----------------------------------------\n",
            "Epoch 94\n",
            "Var loss:  tensor(2.4475e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6938742135876403e-06\n",
            "E_s_wdiff_all_sq: 4.037903109110672e-08\n",
            "E_IS_SCOPE: -1.0393696280311245e-05\n",
            "E_IS_E_SCOPE: -9.126760406711929e-06\n",
            "Total Loss: 2.447465017313164e-07\n",
            "----------------------------------------\n",
            "Epoch 95\n",
            "Var loss:  tensor(2.4420e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6918426142135116e-06\n",
            "E_s_wdiff_all_sq: 3.9567049451739617e-08\n",
            "E_IS_SCOPE: -1.0376156647799441e-05\n",
            "E_IS_E_SCOPE: -9.109558037984783e-06\n",
            "Total Loss: 2.442014115658689e-07\n",
            "----------------------------------------\n",
            "Epoch 96\n",
            "Var loss:  tensor(2.4368e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6903665787824395e-06\n",
            "E_s_wdiff_all_sq: 3.927720108231916e-08\n",
            "E_IS_SCOPE: -1.0361112924344464e-05\n",
            "E_IS_E_SCOPE: -9.094848024353296e-06\n",
            "Total Loss: 2.436826441511998e-07\n",
            "----------------------------------------\n",
            "Epoch 97\n",
            "Var loss:  tensor(2.4315e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6910058003735774e-06\n",
            "E_s_wdiff_all_sq: 4.005393060803126e-08\n",
            "E_IS_SCOPE: -1.0363375386530902e-05\n",
            "E_IS_E_SCOPE: -9.096913128895688e-06\n",
            "Total Loss: 2.4315042092853646e-07\n",
            "----------------------------------------\n",
            "Epoch 98\n",
            "Var loss:  tensor(2.4261e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6934241213630255e-06\n",
            "E_s_wdiff_all_sq: 4.1913488305550946e-08\n",
            "E_IS_SCOPE: -1.0377952679624788e-05\n",
            "E_IS_E_SCOPE: -9.110942065715619e-06\n",
            "Total Loss: 2.4261247167255045e-07\n",
            "----------------------------------------\n",
            "Epoch 99\n",
            "Var loss:  tensor(2.4210e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6957348936007011e-06\n",
            "E_s_wdiff_all_sq: 4.37335787672969e-08\n",
            "E_IS_SCOPE: -1.039187745577729e-05\n",
            "E_IS_E_SCOPE: -9.12436320385075e-06\n",
            "Total Loss: 2.4209587741373775e-07\n",
            "----------------------------------------\n",
            "Epoch 100\n",
            "Var loss:  tensor(2.4155e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6955513509714145e-06\n",
            "E_s_wdiff_all_sq: 4.390050913286332e-08\n",
            "E_IS_SCOPE: -1.0393149810482465e-05\n",
            "E_IS_E_SCOPE: -9.125539995224102e-06\n",
            "Total Loss: 2.4155427775523903e-07\n",
            "----------------------------------------\n",
            "Epoch 101\n",
            "Var loss:  tensor(2.4101e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.693310366680318e-06\n",
            "E_s_wdiff_all_sq: 4.2784238234586944e-08\n",
            "E_IS_SCOPE: -1.0383414445967806e-05\n",
            "E_IS_E_SCOPE: -9.11609238191256e-06\n",
            "Total Loss: 2.4100506676865403e-07\n",
            "----------------------------------------\n",
            "Epoch 102\n",
            "Var loss:  tensor(2.4047e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6910721691234906e-06\n",
            "E_s_wdiff_all_sq: 4.1670012133977186e-08\n",
            "E_IS_SCOPE: -1.0374398585770705e-05\n",
            "E_IS_E_SCOPE: -9.107370197455367e-06\n",
            "Total Loss: 2.4046844679225396e-07\n",
            "----------------------------------------\n",
            "Epoch 103\n",
            "Var loss:  tensor(2.3993e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6907452870210213e-06\n",
            "E_s_wdiff_all_sq: 4.180688744621543e-08\n",
            "E_IS_SCOPE: -1.037615061671181e-05\n",
            "E_IS_E_SCOPE: -9.109087350303633e-06\n",
            "Total Loss: 2.3993493319187044e-07\n",
            "----------------------------------------\n",
            "Epoch 104\n",
            "Var loss:  tensor(2.3939e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6921768464942244e-06\n",
            "E_s_wdiff_all_sq: 4.3324733919751014e-08\n",
            "E_IS_SCOPE: -1.0383226306463651e-05\n",
            "E_IS_E_SCOPE: -9.115933902185967e-06\n",
            "Total Loss: 2.393903704525204e-07\n",
            "----------------------------------------\n",
            "Epoch 105\n",
            "Var loss:  tensor(2.3884e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6941442222748227e-06\n",
            "E_s_wdiff_all_sq: 4.522637198548534e-08\n",
            "E_IS_SCOPE: -1.0389058919109852e-05\n",
            "E_IS_E_SCOPE: -9.12146036377818e-06\n",
            "Total Loss: 2.388438060594112e-07\n",
            "----------------------------------------\n",
            "Epoch 106\n",
            "Var loss:  tensor(2.3831e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6955026987577546e-06\n",
            "E_s_wdiff_all_sq: 4.658804669621946e-08\n",
            "E_IS_SCOPE: -1.0390998961024602e-05\n",
            "E_IS_E_SCOPE: -9.1231332967459e-06\n",
            "Total Loss: 2.3830638993754683e-07\n",
            "----------------------------------------\n",
            "Epoch 107\n",
            "Var loss:  tensor(2.3776e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6954669787093733e-06\n",
            "E_s_wdiff_all_sq: 4.6974658778947935e-08\n",
            "E_IS_SCOPE: -1.0387279545201746e-05\n",
            "E_IS_E_SCOPE: -9.119351867391869e-06\n",
            "Total Loss: 2.377600307440864e-07\n",
            "----------------------------------------\n",
            "Epoch 108\n",
            "Var loss:  tensor(2.3721e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6943973761721936e-06\n",
            "E_s_wdiff_all_sq: 4.674336415783465e-08\n",
            "E_IS_SCOPE: -1.0381463972924126e-05\n",
            "E_IS_E_SCOPE: -9.113681468071017e-06\n",
            "Total Loss: 2.3721206874155453e-07\n",
            "----------------------------------------\n",
            "Epoch 109\n",
            "Var loss:  tensor(2.3666e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6937746231358054e-06\n",
            "E_s_wdiff_all_sq: 4.698390400374258e-08\n",
            "E_IS_SCOPE: -1.0380116958032229e-05\n",
            "E_IS_E_SCOPE: -9.112490477741196e-06\n",
            "Total Loss: 2.3666082498341224e-07\n",
            "----------------------------------------\n",
            "Epoch 110\n",
            "Var loss:  tensor(2.3613e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6942466542058214e-06\n",
            "E_s_wdiff_all_sq: 4.8049587185144714e-08\n",
            "E_IS_SCOPE: -1.0386131933832583e-05\n",
            "E_IS_E_SCOPE: -9.118534410799879e-06\n",
            "Total Loss: 2.3612508738868452e-07\n",
            "----------------------------------------\n",
            "Epoch 111\n",
            "Var loss:  tensor(2.3557e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6960244447846707e-06\n",
            "E_s_wdiff_all_sq: 4.974454904358387e-08\n",
            "E_IS_SCOPE: -1.0396315503461139e-05\n",
            "E_IS_E_SCOPE: -9.128399292362523e-06\n",
            "Total Loss: 2.355705399772714e-07\n",
            "----------------------------------------\n",
            "Epoch 112\n",
            "Var loss:  tensor(2.3503e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.697802853075147e-06\n",
            "E_s_wdiff_all_sq: 5.1228372862228884e-08\n",
            "E_IS_SCOPE: -1.0403935574847117e-05\n",
            "E_IS_E_SCOPE: -9.13560020199953e-06\n",
            "Total Loss: 2.3502680095116249e-07\n",
            "----------------------------------------\n",
            "Epoch 113\n",
            "Var loss:  tensor(2.3447e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6978178911561667e-06\n",
            "E_s_wdiff_all_sq: 5.17062830162525e-08\n",
            "E_IS_SCOPE: -1.0401195667281405e-05\n",
            "E_IS_E_SCOPE: -9.132815290468971e-06\n",
            "Total Loss: 2.3447392094846063e-07\n",
            "----------------------------------------\n",
            "Epoch 114\n",
            "Var loss:  tensor(2.3391e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6963813834446498e-06\n",
            "E_s_wdiff_all_sq: 5.1389901165742885e-08\n",
            "E_IS_SCOPE: -1.0390740111433067e-05\n",
            "E_IS_E_SCOPE: -9.12263869855524e-06\n",
            "Total Loss: 2.3391172295666906e-07\n",
            "----------------------------------------\n",
            "Epoch 115\n",
            "Var loss:  tensor(2.3337e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6956038350990175e-06\n",
            "E_s_wdiff_all_sq: 5.1307639145693544e-08\n",
            "E_IS_SCOPE: -1.0385789382678743e-05\n",
            "E_IS_E_SCOPE: -9.117762276342346e-06\n",
            "Total Loss: 2.3336504971394498e-07\n",
            "----------------------------------------\n",
            "Epoch 116\n",
            "Var loss:  tensor(2.3281e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6964062628256837e-06\n",
            "E_s_wdiff_all_sq: 5.219462837219457e-08\n",
            "E_IS_SCOPE: -1.0388617328441866e-05\n",
            "E_IS_E_SCOPE: -9.120356145481202e-06\n",
            "Total Loss: 2.32812334965574e-07\n",
            "----------------------------------------\n",
            "Epoch 117\n",
            "Var loss:  tensor(2.3226e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.697969708123644e-06\n",
            "E_s_wdiff_all_sq: 5.356150422228303e-08\n",
            "E_IS_SCOPE: -1.0396512373483222e-05\n",
            "E_IS_E_SCOPE: -9.127874657124376e-06\n",
            "Total Loss: 2.322558376170834e-07\n",
            "----------------------------------------\n",
            "Epoch 118\n",
            "Var loss:  tensor(2.3170e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6985046476447504e-06\n",
            "E_s_wdiff_all_sq: 5.421227944654942e-08\n",
            "E_IS_SCOPE: -1.0403259580456e-05\n",
            "E_IS_E_SCOPE: -9.13440324291294e-06\n",
            "Total Loss: 2.3170275954549535e-07\n",
            "----------------------------------------\n",
            "Epoch 119\n",
            "Var loss:  tensor(2.3114e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.697402565253607e-06\n",
            "E_s_wdiff_all_sq: 5.366662050549304e-08\n",
            "E_IS_SCOPE: -1.0404202521657255e-05\n",
            "E_IS_E_SCOPE: -9.135342909318728e-06\n",
            "Total Loss: 2.3113978650447428e-07\n",
            "----------------------------------------\n",
            "Epoch 120\n",
            "Var loss:  tensor(2.3059e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6958400272508577e-06\n",
            "E_s_wdiff_all_sq: 5.2882884795770964e-08\n",
            "E_IS_SCOPE: -1.0403002927344853e-05\n",
            "E_IS_E_SCOPE: -9.134256792710523e-06\n",
            "Total Loss: 2.3058793961984435e-07\n",
            "----------------------------------------\n",
            "Epoch 121\n",
            "Var loss:  tensor(2.3004e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6950071719017815e-06\n",
            "E_s_wdiff_all_sq: 5.287300646841153e-08\n",
            "E_IS_SCOPE: -1.0402737494062908e-05\n",
            "E_IS_E_SCOPE: -9.134131168138253e-06\n",
            "Total Loss: 2.300445800174791e-07\n",
            "----------------------------------------\n",
            "Epoch 122\n",
            "Var loss:  tensor(2.2947e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6957747610661316e-06\n",
            "E_s_wdiff_all_sq: 5.4118831831198214e-08\n",
            "E_IS_SCOPE: -1.0403672859566108e-05\n",
            "E_IS_E_SCOPE: -9.135018404395334e-06\n",
            "Total Loss: 2.2947008532680272e-07\n",
            "----------------------------------------\n",
            "Epoch 123\n",
            "Var loss:  tensor(2.2891e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.69851863161317e-06\n",
            "E_s_wdiff_all_sq: 5.67128952213179e-08\n",
            "E_IS_SCOPE: -1.0406459704759436e-05\n",
            "E_IS_E_SCOPE: -9.137450141731153e-06\n",
            "Total Loss: 2.2890967676870108e-07\n",
            "----------------------------------------\n",
            "Epoch 124\n",
            "Var loss:  tensor(2.2835e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7010557006088108e-06\n",
            "E_s_wdiff_all_sq: 5.893392402523617e-08\n",
            "E_IS_SCOPE: -1.0409975838248118e-05\n",
            "E_IS_E_SCOPE: -9.140527125576497e-06\n",
            "Total Loss: 2.2834741767374788e-07\n",
            "----------------------------------------\n",
            "Epoch 125\n",
            "Var loss:  tensor(2.2778e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7020085298071291e-06\n",
            "E_s_wdiff_all_sq: 6.02912642130195e-08\n",
            "E_IS_SCOPE: -1.0408199075962801e-05\n",
            "E_IS_E_SCOPE: -9.138668603874811e-06\n",
            "Total Loss: 2.2777938785154696e-07\n",
            "----------------------------------------\n",
            "Epoch 126\n",
            "Var loss:  tensor(2.2723e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.701659749145655e-06\n",
            "E_s_wdiff_all_sq: 6.090723139718416e-08\n",
            "E_IS_SCOPE: -1.0403745362550728e-05\n",
            "E_IS_E_SCOPE: -9.134420515844493e-06\n",
            "Total Loss: 2.2722589076941738e-07\n",
            "----------------------------------------\n",
            "Epoch 127\n",
            "Var loss:  tensor(2.2666e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.700795388892347e-06\n",
            "E_s_wdiff_all_sq: 6.101620390606548e-08\n",
            "E_IS_SCOPE: -1.0400947318483681e-05\n",
            "E_IS_E_SCOPE: -9.131826865352494e-06\n",
            "Total Loss: 2.2666134515732097e-07\n",
            "----------------------------------------\n",
            "Epoch 128\n",
            "Var loss:  tensor(2.2609e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.700873716511624e-06\n",
            "E_s_wdiff_all_sq: 6.167522075369433e-08\n",
            "E_IS_SCOPE: -1.0402518703684154e-05\n",
            "E_IS_E_SCOPE: -9.13340402443894e-06\n",
            "Total Loss: 2.260922037009197e-07\n",
            "----------------------------------------\n",
            "Epoch 129\n",
            "Var loss:  tensor(2.2553e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7018749746582914e-06\n",
            "E_s_wdiff_all_sq: 6.264836856268655e-08\n",
            "E_IS_SCOPE: -1.040950574467023e-05\n",
            "E_IS_E_SCOPE: -9.140093721868505e-06\n",
            "Total Loss: 2.2552562692556936e-07\n",
            "----------------------------------------\n",
            "Epoch 130\n",
            "Var loss:  tensor(2.2496e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7022694267960429e-06\n",
            "E_s_wdiff_all_sq: 6.30416565482383e-08\n",
            "E_IS_SCOPE: -1.0415347616012765e-05\n",
            "E_IS_E_SCOPE: -9.14565050009191e-06\n",
            "Total Loss: 2.2495660483951133e-07\n",
            "----------------------------------------\n",
            "Epoch 131\n",
            "Var loss:  tensor(2.2439e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7013074287000594e-06\n",
            "E_s_wdiff_all_sq: 6.265066625149345e-08\n",
            "E_IS_SCOPE: -1.041671187699621e-05\n",
            "E_IS_E_SCOPE: -9.147014996766318e-06\n",
            "Total Loss: 2.243860684221955e-07\n",
            "----------------------------------------\n",
            "Epoch 132\n",
            "Var loss:  tensor(2.2382e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6994294308797075e-06\n",
            "E_s_wdiff_all_sq: 6.168922816930543e-08\n",
            "E_IS_SCOPE: -1.0414172975997192e-05\n",
            "E_IS_E_SCOPE: -9.144649020327792e-06\n",
            "Total Loss: 2.23815357805018e-07\n",
            "----------------------------------------\n",
            "Epoch 133\n",
            "Var loss:  tensor(2.2325e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.698384583052252e-06\n",
            "E_s_wdiff_all_sq: 6.120496692043343e-08\n",
            "E_IS_SCOPE: -1.0409773608868885e-05\n",
            "E_IS_E_SCOPE: -9.140246914816254e-06\n",
            "Total Loss: 2.2324929445997285e-07\n",
            "----------------------------------------\n",
            "Epoch 134\n",
            "Var loss:  tensor(2.2267e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.698706581263278e-06\n",
            "E_s_wdiff_all_sq: 6.139619114807361e-08\n",
            "E_IS_SCOPE: -1.0410608347198275e-05\n",
            "E_IS_E_SCOPE: -9.140728080671488e-06\n",
            "Total Loss: 2.2267292349504542e-07\n",
            "----------------------------------------\n",
            "Epoch 135\n",
            "Var loss:  tensor(2.2210e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6996372802864986e-06\n",
            "E_s_wdiff_all_sq: 6.231204021279156e-08\n",
            "E_IS_SCOPE: -1.0414164877965922e-05\n",
            "E_IS_E_SCOPE: -9.1439918637015e-06\n",
            "Total Loss: 2.2210227797827772e-07\n",
            "----------------------------------------\n",
            "Epoch 136\n",
            "Var loss:  tensor(2.2153e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.700150948826653e-06\n",
            "E_s_wdiff_all_sq: 6.337514200244276e-08\n",
            "E_IS_SCOPE: -1.0416964770545659e-05\n",
            "E_IS_E_SCOPE: -9.146780753096974e-06\n",
            "Total Loss: 2.2153083836025473e-07\n",
            "----------------------------------------\n",
            "Epoch 137\n",
            "Var loss:  tensor(2.2096e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7001853845114823e-06\n",
            "E_s_wdiff_all_sq: 6.40722658488198e-08\n",
            "E_IS_SCOPE: -1.0415142982660786e-05\n",
            "E_IS_E_SCOPE: -9.145002456863424e-06\n",
            "Total Loss: 2.2095513350135527e-07\n",
            "----------------------------------------\n",
            "Epoch 138\n",
            "Var loss:  tensor(2.2038e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.700336935356198e-06\n",
            "E_s_wdiff_all_sq: 6.450455268205415e-08\n",
            "E_IS_SCOPE: -1.0413839856563347e-05\n",
            "E_IS_E_SCOPE: -9.143553208250958e-06\n",
            "Total Loss: 2.2038215248278098e-07\n",
            "----------------------------------------\n",
            "Epoch 139\n",
            "Var loss:  tensor(2.1980e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.70073000796727e-06\n",
            "E_s_wdiff_all_sq: 6.51601200043887e-08\n",
            "E_IS_SCOPE: -1.0410683402799105e-05\n",
            "E_IS_E_SCOPE: -9.140239063230867e-06\n",
            "Total Loss: 2.1980427525982243e-07\n",
            "----------------------------------------\n",
            "Epoch 140\n",
            "Var loss:  tensor(2.1923e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7016242297254215e-06\n",
            "E_s_wdiff_all_sq: 6.636783752210958e-08\n",
            "E_IS_SCOPE: -1.04111836054932e-05\n",
            "E_IS_E_SCOPE: -9.140607506436531e-06\n",
            "Total Loss: 2.192272605233931e-07\n",
            "----------------------------------------\n",
            "Epoch 141\n",
            "Var loss:  tensor(2.1865e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.70209247112664e-06\n",
            "E_s_wdiff_all_sq: 6.750382769594642e-08\n",
            "E_IS_SCOPE: -1.0413373099092052e-05\n",
            "E_IS_E_SCOPE: -9.142843192822936e-06\n",
            "Total Loss: 2.1865189732588006e-07\n",
            "----------------------------------------\n",
            "Epoch 142\n",
            "Var loss:  tensor(2.1807e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7027760235211135e-06\n",
            "E_s_wdiff_all_sq: 6.864748985716881e-08\n",
            "E_IS_SCOPE: -1.0415065482949937e-05\n",
            "E_IS_E_SCOPE: -9.144473710799512e-06\n",
            "Total Loss: 2.1806805579650863e-07\n",
            "----------------------------------------\n",
            "Epoch 143\n",
            "Var loss:  tensor(2.1749e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7038463483038857e-06\n",
            "E_s_wdiff_all_sq: 6.979197028130445e-08\n",
            "E_IS_SCOPE: -1.0418568634975906e-05\n",
            "E_IS_E_SCOPE: -9.147726830880647e-06\n",
            "Total Loss: 2.174938362654792e-07\n",
            "----------------------------------------\n",
            "Epoch 144\n",
            "Var loss:  tensor(2.1691e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7046050242152406e-06\n",
            "E_s_wdiff_all_sq: 7.076870924395614e-08\n",
            "E_IS_SCOPE: -1.0420269067433244e-05\n",
            "E_IS_E_SCOPE: -9.149245575545964e-06\n",
            "Total Loss: 2.1691239763014e-07\n",
            "----------------------------------------\n",
            "Epoch 145\n",
            "Var loss:  tensor(2.1633e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.704163996941872e-06\n",
            "E_s_wdiff_all_sq: 7.115115355790393e-08\n",
            "E_IS_SCOPE: -1.0419779603439644e-05\n",
            "E_IS_E_SCOPE: -9.148876310733231e-06\n",
            "Total Loss: 2.1632932440455889e-07\n",
            "----------------------------------------\n",
            "Epoch 146\n",
            "Var loss:  tensor(2.1574e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.703743349986532e-06\n",
            "E_s_wdiff_all_sq: 7.158100394097689e-08\n",
            "E_IS_SCOPE: -1.041949753880683e-05\n",
            "E_IS_E_SCOPE: -9.148724858682339e-06\n",
            "Total Loss: 2.1574005222998985e-07\n",
            "----------------------------------------\n",
            "Epoch 147\n",
            "Var loss:  tensor(2.1517e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.704881306793064e-06\n",
            "E_s_wdiff_all_sq: 7.29761579605587e-08\n",
            "E_IS_SCOPE: -1.042334750916372e-05\n",
            "E_IS_E_SCOPE: -9.15241677644011e-06\n",
            "Total Loss: 2.1516674981870118e-07\n",
            "----------------------------------------\n",
            "Epoch 148\n",
            "Var loss:  tensor(2.1457e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.706526462966463e-06\n",
            "E_s_wdiff_all_sq: 7.468658397501789e-08\n",
            "E_IS_SCOPE: -1.0425830804693136e-05\n",
            "E_IS_E_SCOPE: -9.154636642546336e-06\n",
            "Total Loss: 2.1457462113126327e-07\n",
            "----------------------------------------\n",
            "Epoch 149\n",
            "Var loss:  tensor(2.1398e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7073353526265044e-06\n",
            "E_s_wdiff_all_sq: 7.568064679151796e-08\n",
            "E_IS_SCOPE: -1.0424545452162448e-05\n",
            "E_IS_E_SCOPE: -9.153146914022824e-06\n",
            "Total Loss: 2.1398069598915475e-07\n",
            "----------------------------------------\n",
            "Epoch 150\n",
            "Var loss:  tensor(2.1339e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7075917525626392e-06\n",
            "E_s_wdiff_all_sq: 7.643839728698429e-08\n",
            "E_IS_SCOPE: -1.0423523362632808e-05\n",
            "E_IS_E_SCOPE: -9.152080233363606e-06\n",
            "Total Loss: 2.1339016317066636e-07\n",
            "----------------------------------------\n",
            "Epoch 151\n",
            "Var loss:  tensor(2.1280e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7078299536913499e-06\n",
            "E_s_wdiff_all_sq: 7.724555179965625e-08\n",
            "E_IS_SCOPE: -1.0424512142401866e-05\n",
            "E_IS_E_SCOPE: -9.153056235838831e-06\n",
            "Total Loss: 2.1279565519904254e-07\n",
            "----------------------------------------\n",
            "Epoch 152\n",
            "Var loss:  tensor(2.1220e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7082781032454724e-06\n",
            "E_s_wdiff_all_sq: 7.806736512043233e-08\n",
            "E_IS_SCOPE: -1.0427942903354655e-05\n",
            "E_IS_E_SCOPE: -9.156377872765391e-06\n",
            "Total Loss: 2.1220374337992803e-07\n",
            "----------------------------------------\n",
            "Epoch 153\n",
            "Var loss:  tensor(2.1160e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.708568759826612e-06\n",
            "E_s_wdiff_all_sq: 7.871783454508083e-08\n",
            "E_IS_SCOPE: -1.0433217699207887e-05\n",
            "E_IS_E_SCOPE: -9.161532762380687e-06\n",
            "Total Loss: 2.11604118060549e-07\n",
            "----------------------------------------\n",
            "Epoch 154\n",
            "Var loss:  tensor(2.1101e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7084688874579642e-06\n",
            "E_s_wdiff_all_sq: 7.909059645483918e-08\n",
            "E_IS_SCOPE: -1.0438542273060671e-05\n",
            "E_IS_E_SCOPE: -9.166796163663358e-06\n",
            "Total Loss: 2.1100913864191442e-07\n",
            "----------------------------------------\n",
            "Epoch 155\n",
            "Var loss:  tensor(2.1041e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.708303795026502e-06\n",
            "E_s_wdiff_all_sq: 7.926201236738958e-08\n",
            "E_IS_SCOPE: -1.0440453771266503e-05\n",
            "E_IS_E_SCOPE: -9.168577922326337e-06\n",
            "Total Loss: 2.1041315121219585e-07\n",
            "----------------------------------------\n",
            "Epoch 156\n",
            "Var loss:  tensor(2.0981e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7080340101613432e-06\n",
            "E_s_wdiff_all_sq: 7.923693768346928e-08\n",
            "E_IS_SCOPE: -1.0439586837222441e-05\n",
            "E_IS_E_SCOPE: -9.16753270655807e-06\n",
            "Total Loss: 2.098118775825455e-07\n",
            "----------------------------------------\n",
            "Epoch 157\n",
            "Var loss:  tensor(2.0923e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7080283953366558e-06\n",
            "E_s_wdiff_all_sq: 7.955349817834871e-08\n",
            "E_IS_SCOPE: -1.0439310461240315e-05\n",
            "E_IS_E_SCOPE: -9.167124172576366e-06\n",
            "Total Loss: 2.092253862638251e-07\n",
            "----------------------------------------\n",
            "Epoch 158\n",
            "Var loss:  tensor(2.0862e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7079757548128708e-06\n",
            "E_s_wdiff_all_sq: 7.999676288417485e-08\n",
            "E_IS_SCOPE: -1.0436883870383106e-05\n",
            "E_IS_E_SCOPE: -9.164644665974267e-06\n",
            "Total Loss: 2.0862364954443146e-07\n",
            "----------------------------------------\n",
            "Epoch 159\n",
            "Var loss:  tensor(2.0803e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.708330970077691e-06\n",
            "E_s_wdiff_all_sq: 8.088002561406657e-08\n",
            "E_IS_SCOPE: -1.0433130740160609e-05\n",
            "E_IS_E_SCOPE: -9.160858207723582e-06\n",
            "Total Loss: 2.0802894602298896e-07\n",
            "----------------------------------------\n",
            "Epoch 160\n",
            "Var loss:  tensor(2.0743e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.709019016623315e-06\n",
            "E_s_wdiff_all_sq: 8.207071238494628e-08\n",
            "E_IS_SCOPE: -1.0431320276234265e-05\n",
            "E_IS_E_SCOPE: -9.159000032642425e-06\n",
            "Total Loss: 2.0743088348810276e-07\n",
            "----------------------------------------\n",
            "Epoch 161\n",
            "Var loss:  tensor(2.0683e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7103031097056667e-06\n",
            "E_s_wdiff_all_sq: 8.380759168718288e-08\n",
            "E_IS_SCOPE: -1.0431156919964509e-05\n",
            "E_IS_E_SCOPE: -9.15876051458732e-06\n",
            "Total Loss: 2.0682577369752173e-07\n",
            "----------------------------------------\n",
            "Epoch 162\n",
            "Var loss:  tensor(2.0622e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7123492956274973e-06\n",
            "E_s_wdiff_all_sq: 8.606888702136915e-08\n",
            "E_IS_SCOPE: -1.0433878608359117e-05\n",
            "E_IS_E_SCOPE: -9.161289259063609e-06\n",
            "Total Loss: 2.0622477644852845e-07\n",
            "----------------------------------------\n",
            "Epoch 163\n",
            "Var loss:  tensor(2.0562e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7141243928982958e-06\n",
            "E_s_wdiff_all_sq: 8.800319821687563e-08\n",
            "E_IS_SCOPE: -1.044067593195617e-05\n",
            "E_IS_E_SCOPE: -9.167862827271305e-06\n",
            "Total Loss: 2.0561805174510257e-07\n",
            "----------------------------------------\n",
            "Epoch 164\n",
            "Var loss:  tensor(2.0501e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.714989118281085e-06\n",
            "E_s_wdiff_all_sq: 8.940586552271192e-08\n",
            "E_IS_SCOPE: -1.04458955906296e-05\n",
            "E_IS_E_SCOPE: -9.173047560859309e-06\n",
            "Total Loss: 2.0501025965120602e-07\n",
            "----------------------------------------\n",
            "Epoch 165\n",
            "Var loss:  tensor(2.0441e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7150420385287583e-06\n",
            "E_s_wdiff_all_sq: 9.026742676778557e-08\n",
            "E_IS_SCOPE: -1.0447472080533019e-05\n",
            "E_IS_E_SCOPE: -9.174726956670623e-06\n",
            "Total Loss: 2.044074304695993e-07\n",
            "----------------------------------------\n",
            "Epoch 166\n",
            "Var loss:  tensor(2.0380e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7150233900783379e-06\n",
            "E_s_wdiff_all_sq: 9.076086845161332e-08\n",
            "E_IS_SCOPE: -1.044817350808377e-05\n",
            "E_IS_E_SCOPE: -9.175382120740345e-06\n",
            "Total Loss: 2.0380281337329128e-07\n",
            "----------------------------------------\n",
            "Epoch 167\n",
            "Var loss:  tensor(2.0319e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.714684134000113e-06\n",
            "E_s_wdiff_all_sq: 9.07823287646796e-08\n",
            "E_IS_SCOPE: -1.044470971861531e-05\n",
            "E_IS_E_SCOPE: -9.17179377110062e-06\n",
            "Total Loss: 2.0319297663946922e-07\n",
            "----------------------------------------\n",
            "Epoch 168\n",
            "Var loss:  tensor(2.0259e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7142792231291026e-06\n",
            "E_s_wdiff_all_sq: 9.088367823687257e-08\n",
            "E_IS_SCOPE: -1.0439042449084305e-05\n",
            "E_IS_E_SCOPE: -9.166076618949615e-06\n",
            "Total Loss: 2.0258695105626508e-07\n",
            "----------------------------------------\n",
            "Epoch 169\n",
            "Var loss:  tensor(2.0198e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7143008859048431e-06\n",
            "E_s_wdiff_all_sq: 9.124661605967578e-08\n",
            "E_IS_SCOPE: -1.0437127852287834e-05\n",
            "E_IS_E_SCOPE: -9.164029055795241e-06\n",
            "Total Loss: 2.0197974329339848e-07\n",
            "----------------------------------------\n",
            "Epoch 170\n",
            "Var loss:  tensor(2.0137e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7149624746731408e-06\n",
            "E_s_wdiff_all_sq: 9.199290324383039e-08\n",
            "E_IS_SCOPE: -1.043745719503757e-05\n",
            "E_IS_E_SCOPE: -9.164098110668817e-06\n",
            "Total Loss: 2.0137446912522212e-07\n",
            "----------------------------------------\n",
            "Epoch 171\n",
            "Var loss:  tensor(2.0077e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7155454576209854e-06\n",
            "E_s_wdiff_all_sq: 9.274613667832514e-08\n",
            "E_IS_SCOPE: -1.0438348513728235e-05\n",
            "E_IS_E_SCOPE: -9.164771543641058e-06\n",
            "Total Loss: 2.0076844720172417e-07\n",
            "----------------------------------------\n",
            "Epoch 172\n",
            "Var loss:  tensor(2.0016e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7148375854274172e-06\n",
            "E_s_wdiff_all_sq: 9.244574301399932e-08\n",
            "E_IS_SCOPE: -1.0440679426763994e-05\n",
            "E_IS_E_SCOPE: -9.166999917275983e-06\n",
            "Total Loss: 2.0015588987081168e-07\n",
            "----------------------------------------\n",
            "Epoch 173\n",
            "Var loss:  tensor(1.9954e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7138531755397577e-06\n",
            "E_s_wdiff_all_sq: 9.214785127596929e-08\n",
            "E_IS_SCOPE: -1.044163319320427e-05\n",
            "E_IS_E_SCOPE: -9.1679899811172e-06\n",
            "Total Loss: 1.9954196652306475e-07\n",
            "----------------------------------------\n",
            "Epoch 174\n",
            "Var loss:  tensor(1.9893e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.713380769159702e-06\n",
            "E_s_wdiff_all_sq: 9.235520111502931e-08\n",
            "E_IS_SCOPE: -1.0443403545279268e-05\n",
            "E_IS_E_SCOPE: -9.169792338344864e-06\n",
            "Total Loss: 1.989262206092816e-07\n",
            "----------------------------------------\n",
            "Epoch 175\n",
            "Var loss:  tensor(1.9831e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7133959268449226e-06\n",
            "E_s_wdiff_all_sq: 9.287441100003271e-08\n",
            "E_IS_SCOPE: -1.04463958878327e-05\n",
            "E_IS_E_SCOPE: -9.172729812795862e-06\n",
            "Total Loss: 1.9831243220463044e-07\n",
            "----------------------------------------\n",
            "Epoch 176\n",
            "Var loss:  tensor(1.9771e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7141422001143662e-06\n",
            "E_s_wdiff_all_sq: 9.37568210317337e-08\n",
            "E_IS_SCOPE: -1.0449494142420649e-05\n",
            "E_IS_E_SCOPE: -9.175595587878242e-06\n",
            "Total Loss: 1.9771133643123513e-07\n",
            "----------------------------------------\n",
            "Epoch 177\n",
            "Var loss:  tensor(1.9710e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.714938697370858e-06\n",
            "E_s_wdiff_all_sq: 9.484838885739729e-08\n",
            "E_IS_SCOPE: -1.0447289896169832e-05\n",
            "E_IS_E_SCOPE: -9.173233448721395e-06\n",
            "Total Loss: 1.9710048005000065e-07\n",
            "----------------------------------------\n",
            "Epoch 178\n",
            "Var loss:  tensor(1.9648e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7151310114866889e-06\n",
            "E_s_wdiff_all_sq: 9.591341123458748e-08\n",
            "E_IS_SCOPE: -1.0441534590894248e-05\n",
            "E_IS_E_SCOPE: -9.167603221962683e-06\n",
            "Total Loss: 1.9647792882238765e-07\n",
            "----------------------------------------\n",
            "Epoch 179\n",
            "Var loss:  tensor(1.9587e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.716399036857276e-06\n",
            "E_s_wdiff_all_sq: 9.760001273821185e-08\n",
            "E_IS_SCOPE: -1.0440011478520869e-05\n",
            "E_IS_E_SCOPE: -9.165987537125512e-06\n",
            "Total Loss: 1.9587420776176959e-07\n",
            "----------------------------------------\n",
            "Epoch 180\n",
            "Var loss:  tensor(1.9526e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7180315134008918e-06\n",
            "E_s_wdiff_all_sq: 9.934578389330224e-08\n",
            "E_IS_SCOPE: -1.0439635198325887e-05\n",
            "E_IS_E_SCOPE: -9.165360814883045e-06\n",
            "Total Loss: 1.9526002905532302e-07\n",
            "----------------------------------------\n",
            "Epoch 181\n",
            "Var loss:  tensor(1.9466e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.719278945048739e-06\n",
            "E_s_wdiff_all_sq: 1.0073459563086762e-07\n",
            "E_IS_SCOPE: -1.0441331265555423e-05\n",
            "E_IS_E_SCOPE: -9.166825373607993e-06\n",
            "Total Loss: 1.9465563195642943e-07\n",
            "----------------------------------------\n",
            "Epoch 182\n",
            "Var loss:  tensor(1.9404e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7195051868039151e-06\n",
            "E_s_wdiff_all_sq: 1.0179157921716129e-07\n",
            "E_IS_SCOPE: -1.044177470746082e-05\n",
            "E_IS_E_SCOPE: -9.167375609170886e-06\n",
            "Total Loss: 1.9403847744030355e-07\n",
            "----------------------------------------\n",
            "Epoch 183\n",
            "Var loss:  tensor(1.9342e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.71971936632737e-06\n",
            "E_s_wdiff_all_sq: 1.0277302578583528e-07\n",
            "E_IS_SCOPE: -1.0441981511066472e-05\n",
            "E_IS_E_SCOPE: -9.167659203949135e-06\n",
            "Total Loss: 1.9342479274027653e-07\n",
            "----------------------------------------\n",
            "Epoch 184\n",
            "Var loss:  tensor(1.9281e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.720767133913656e-06\n",
            "E_s_wdiff_all_sq: 1.0410892243526958e-07\n",
            "E_IS_SCOPE: -1.0444581593266387e-05\n",
            "E_IS_E_SCOPE: -9.17009570714204e-06\n",
            "Total Loss: 1.9280950566310651e-07\n",
            "----------------------------------------\n",
            "Epoch 185\n",
            "Var loss:  tensor(1.9221e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7223746467932628e-06\n",
            "E_s_wdiff_all_sq: 1.0588183463741387e-07\n",
            "E_IS_SCOPE: -1.0449157086870558e-05\n",
            "E_IS_E_SCOPE: -9.17445396007162e-06\n",
            "Total Loss: 1.922096249913897e-07\n",
            "----------------------------------------\n",
            "Epoch 186\n",
            "Var loss:  tensor(1.9160e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7226960672892019e-06\n",
            "E_s_wdiff_all_sq: 1.0692704899490493e-07\n",
            "E_IS_SCOPE: -1.0447822006216919e-05\n",
            "E_IS_E_SCOPE: -9.173175711528422e-06\n",
            "Total Loss: 1.9159949535071872e-07\n",
            "----------------------------------------\n",
            "Epoch 187\n",
            "Var loss:  tensor(1.9096e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7224130672504917e-06\n",
            "E_s_wdiff_all_sq: 1.0720692662475948e-07\n",
            "E_IS_SCOPE: -1.0443916558488135e-05\n",
            "E_IS_E_SCOPE: -9.169232855815979e-06\n",
            "Total Loss: 1.9096180171483554e-07\n",
            "----------------------------------------\n",
            "Epoch 188\n",
            "Var loss:  tensor(1.9034e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7227344015824336e-06\n",
            "E_s_wdiff_all_sq: 1.0772253661179434e-07\n",
            "E_IS_SCOPE: -1.0442362299428787e-05\n",
            "E_IS_E_SCOPE: -9.167463164315124e-06\n",
            "Total Loss: 1.9033666117672883e-07\n",
            "----------------------------------------\n",
            "Epoch 189\n",
            "Var loss:  tensor(1.8972e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7233639369202324e-06\n",
            "E_s_wdiff_all_sq: 1.0842819253161865e-07\n",
            "E_IS_SCOPE: -1.0443262325054855e-05\n",
            "E_IS_E_SCOPE: -9.168090832328354e-06\n",
            "Total Loss: 1.8971582536903026e-07\n",
            "----------------------------------------\n",
            "Epoch 190\n",
            "Var loss:  tensor(1.8908e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7230384519659143e-06\n",
            "E_s_wdiff_all_sq: 1.0866143855188347e-07\n",
            "E_IS_SCOPE: -1.0445539829426368e-05\n",
            "E_IS_E_SCOPE: -9.170327335717571e-06\n",
            "Total Loss: 1.89075092429853e-07\n",
            "----------------------------------------\n",
            "Epoch 191\n",
            "Var loss:  tensor(1.8844e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7226990171295225e-06\n",
            "E_s_wdiff_all_sq: 1.0887440998449516e-07\n",
            "E_IS_SCOPE: -1.0449000422631478e-05\n",
            "E_IS_E_SCOPE: -9.17374429138492e-06\n",
            "Total Loss: 1.8843541108532622e-07\n",
            "----------------------------------------\n",
            "Epoch 192\n",
            "Var loss:  tensor(1.8780e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7230148480187744e-06\n",
            "E_s_wdiff_all_sq: 1.0957287832379168e-07\n",
            "E_IS_SCOPE: -1.0453193396838864e-05\n",
            "E_IS_E_SCOPE: -9.17781049109356e-06\n",
            "Total Loss: 1.8779922463779116e-07\n",
            "----------------------------------------\n",
            "Epoch 193\n",
            "Var loss:  tensor(1.8716e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7230192625681622e-06\n",
            "E_s_wdiff_all_sq: 1.1020617955513921e-07\n",
            "E_IS_SCOPE: -1.045542505775823e-05\n",
            "E_IS_E_SCOPE: -9.180037327734094e-06\n",
            "Total Loss: 1.8716068939816883e-07\n",
            "----------------------------------------\n",
            "Epoch 194\n",
            "Var loss:  tensor(1.8652e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.723418170197592e-06\n",
            "E_s_wdiff_all_sq: 1.1132096869441049e-07\n",
            "E_IS_SCOPE: -1.0457086456780676e-05\n",
            "E_IS_E_SCOPE: -9.181735373253577e-06\n",
            "Total Loss: 1.8651810088239956e-07\n",
            "----------------------------------------\n",
            "Epoch 195\n",
            "Var loss:  tensor(1.8587e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.725134996679335e-06\n",
            "E_s_wdiff_all_sq: 1.1327215750803653e-07\n",
            "E_IS_SCOPE: -1.0457613485451725e-05\n",
            "E_IS_E_SCOPE: -9.182056556914457e-06\n",
            "Total Loss: 1.858720485301789e-07\n",
            "----------------------------------------\n",
            "Epoch 196\n",
            "Var loss:  tensor(1.8523e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7263861565252912e-06\n",
            "E_s_wdiff_all_sq: 1.1457308750735867e-07\n",
            "E_IS_SCOPE: -1.0454635683127434e-05\n",
            "E_IS_E_SCOPE: -9.178781067782621e-06\n",
            "Total Loss: 1.8522690476172425e-07\n",
            "----------------------------------------\n",
            "Epoch 197\n",
            "Var loss:  tensor(1.8460e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7262274636466883e-06\n",
            "E_s_wdiff_all_sq: 1.1474472310223615e-07\n",
            "E_IS_SCOPE: -1.0448940117619234e-05\n",
            "E_IS_E_SCOPE: -9.172935124474828e-06\n",
            "Total Loss: 1.845958206890553e-07\n",
            "----------------------------------------\n",
            "Epoch 198\n",
            "Var loss:  tensor(1.8396e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7252281279163673e-06\n",
            "E_s_wdiff_all_sq: 1.146281708498043e-07\n",
            "E_IS_SCOPE: -1.0442044173968287e-05\n",
            "E_IS_E_SCOPE: -9.166160327899965e-06\n",
            "Total Loss: 1.8395533136333594e-07\n",
            "----------------------------------------\n",
            "Epoch 199\n",
            "Var loss:  tensor(1.8331e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7245681465705244e-06\n",
            "E_s_wdiff_all_sq: 1.1478215948688134e-07\n",
            "E_IS_SCOPE: -1.0436700538330691e-05\n",
            "E_IS_E_SCOPE: -9.160903498556177e-06\n",
            "Total Loss: 1.833149739680298e-07\n",
            "----------------------------------------\n",
            "Epoch 200\n",
            "Var loss:  tensor(1.8267e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.726202836007298e-06\n",
            "E_s_wdiff_all_sq: 1.1636894732942425e-07\n",
            "E_IS_SCOPE: -1.0437970769880636e-05\n",
            "E_IS_E_SCOPE: -9.161827114107383e-06\n",
            "Total Loss: 1.826696435647838e-07\n",
            "----------------------------------------\n",
            "Epoch 201\n",
            "Var loss:  tensor(1.8202e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7281986799814096e-06\n",
            "E_s_wdiff_all_sq: 1.1822123678621458e-07\n",
            "E_IS_SCOPE: -1.044332322256738e-05\n",
            "E_IS_E_SCOPE: -9.166784863441305e-06\n",
            "Total Loss: 1.820237913764627e-07\n",
            "----------------------------------------\n",
            "Epoch 202\n",
            "Var loss:  tensor(1.8137e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7286511002036993e-06\n",
            "E_s_wdiff_all_sq: 1.1928660492142464e-07\n",
            "E_IS_SCOPE: -1.0447630709563186e-05\n",
            "E_IS_E_SCOPE: -9.171071307005e-06\n",
            "Total Loss: 1.8136875659931734e-07\n",
            "----------------------------------------\n",
            "Epoch 203\n",
            "Var loss:  tensor(1.8072e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7281667532991113e-06\n",
            "E_s_wdiff_all_sq: 1.199473123109744e-07\n",
            "E_IS_SCOPE: -1.0448892381943267e-05\n",
            "E_IS_E_SCOPE: -9.17257926313901e-06\n",
            "Total Loss: 1.8071626981303944e-07\n",
            "----------------------------------------\n",
            "Epoch 204\n",
            "Var loss:  tensor(1.8008e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7288458342981847e-06\n",
            "E_s_wdiff_all_sq: 1.2131666079459246e-07\n",
            "E_IS_SCOPE: -1.0449804815504884e-05\n",
            "E_IS_E_SCOPE: -9.17352014580186e-06\n",
            "Total Loss: 1.8008290053096103e-07\n",
            "----------------------------------------\n",
            "Epoch 205\n",
            "Var loss:  tensor(1.7944e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.73012698474879e-06\n",
            "E_s_wdiff_all_sq: 1.2276587322528217e-07\n",
            "E_IS_SCOPE: -1.0448439266615675e-05\n",
            "E_IS_E_SCOPE: -9.171915224447814e-06\n",
            "Total Loss: 1.7943609362120188e-07\n",
            "----------------------------------------\n",
            "Epoch 206\n",
            "Var loss:  tensor(1.7879e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7314723255312158e-06\n",
            "E_s_wdiff_all_sq: 1.2441889666259154e-07\n",
            "E_IS_SCOPE: -1.044588618773662e-05\n",
            "E_IS_E_SCOPE: -9.169192811441629e-06\n",
            "Total Loss: 1.787897427120558e-07\n",
            "----------------------------------------\n",
            "Epoch 207\n",
            "Var loss:  tensor(1.7815e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7314718123529534e-06\n",
            "E_s_wdiff_all_sq: 1.2497368843671597e-07\n",
            "E_IS_SCOPE: -1.044355001031678e-05\n",
            "E_IS_E_SCOPE: -9.166812085278547e-06\n",
            "Total Loss: 1.781453402731871e-07\n",
            "----------------------------------------\n",
            "Epoch 208\n",
            "Var loss:  tensor(1.7750e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7313581090285558e-06\n",
            "E_s_wdiff_all_sq: 1.255611359360994e-07\n",
            "E_IS_SCOPE: -1.0441436487574397e-05\n",
            "E_IS_E_SCOPE: -9.164728213518812e-06\n",
            "Total Loss: 1.7750349141470122e-07\n",
            "----------------------------------------\n",
            "Epoch 209\n",
            "Var loss:  tensor(1.7686e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.732254380250222e-06\n",
            "E_s_wdiff_all_sq: 1.2673335891493593e-07\n",
            "E_IS_SCOPE: -1.044224526833879e-05\n",
            "E_IS_E_SCOPE: -9.165354040357223e-06\n",
            "Total Loss: 1.768616318055687e-07\n",
            "----------------------------------------\n",
            "Epoch 210\n",
            "Var loss:  tensor(1.7622e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7334322496411794e-06\n",
            "E_s_wdiff_all_sq: 1.2801544705381397e-07\n",
            "E_IS_SCOPE: -1.0445846846929028e-05\n",
            "E_IS_E_SCOPE: -9.168684814141537e-06\n",
            "Total Loss: 1.762158034457966e-07\n",
            "----------------------------------------\n",
            "Epoch 211\n",
            "Var loss:  tensor(1.7557e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7342935530482898e-06\n",
            "E_s_wdiff_all_sq: 1.2933596106128676e-07\n",
            "E_IS_SCOPE: -1.0450796369171591e-05\n",
            "E_IS_E_SCOPE: -9.173539167685017e-06\n",
            "Total Loss: 1.7556625544726995e-07\n",
            "----------------------------------------\n",
            "Epoch 212\n",
            "Var loss:  tensor(1.7492e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7348823894473463e-06\n",
            "E_s_wdiff_all_sq: 1.3057577563522624e-07\n",
            "E_IS_SCOPE: -1.0455836529418268e-05\n",
            "E_IS_E_SCOPE: -9.178582595232803e-06\n",
            "Total Loss: 1.7492181187460597e-07\n",
            "----------------------------------------\n",
            "Epoch 213\n",
            "Var loss:  tensor(1.7427e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7348368761451904e-06\n",
            "E_s_wdiff_all_sq: 1.3107353068898027e-07\n",
            "E_IS_SCOPE: -1.0458450486876691e-05\n",
            "E_IS_E_SCOPE: -9.18114251407371e-06\n",
            "Total Loss: 1.7427046628366533e-07\n",
            "----------------------------------------\n",
            "Epoch 214\n",
            "Var loss:  tensor(1.7362e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7347099235538289e-06\n",
            "E_s_wdiff_all_sq: 1.312764416852881e-07\n",
            "E_IS_SCOPE: -1.0459172140731963e-05\n",
            "E_IS_E_SCOPE: -9.181704466914928e-06\n",
            "Total Loss: 1.7362120066788649e-07\n",
            "----------------------------------------\n",
            "Epoch 215\n",
            "Var loss:  tensor(1.7298e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.734987009221059e-06\n",
            "E_s_wdiff_all_sq: 1.3200271406801536e-07\n",
            "E_IS_SCOPE: -1.0456045981331547e-05\n",
            "E_IS_E_SCOPE: -9.178481639155905e-06\n",
            "Total Loss: 1.7297867723517795e-07\n",
            "----------------------------------------\n",
            "Epoch 216\n",
            "Var loss:  tensor(1.7234e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7356993957767622e-06\n",
            "E_s_wdiff_all_sq: 1.3337644820277146e-07\n",
            "E_IS_SCOPE: -1.0453085206119747e-05\n",
            "E_IS_E_SCOPE: -9.175533701182518e-06\n",
            "Total Loss: 1.7234300413294596e-07\n",
            "----------------------------------------\n",
            "Epoch 217\n",
            "Var loss:  tensor(1.7169e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.736584547819053e-06\n",
            "E_s_wdiff_all_sq: 1.3474950551539924e-07\n",
            "E_IS_SCOPE: -1.045132080476293e-05\n",
            "E_IS_E_SCOPE: -9.173687022459105e-06\n",
            "Total Loss: 1.7169054412941905e-07\n",
            "----------------------------------------\n",
            "Epoch 218\n",
            "Var loss:  tensor(1.7105e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7378456335274344e-06\n",
            "E_s_wdiff_all_sq: 1.3635409772614254e-07\n",
            "E_IS_SCOPE: -1.0451318561646616e-05\n",
            "E_IS_E_SCOPE: -9.173538168921441e-06\n",
            "Total Loss: 1.7105381678435864e-07\n",
            "----------------------------------------\n",
            "Epoch 219\n",
            "Var loss:  tensor(1.7042e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7389556440313436e-06\n",
            "E_s_wdiff_all_sq: 1.377811526933446e-07\n",
            "E_IS_SCOPE: -1.0451330095824766e-05\n",
            "E_IS_E_SCOPE: -9.17338915795263e-06\n",
            "Total Loss: 1.704156820271425e-07\n",
            "----------------------------------------\n",
            "Epoch 220\n",
            "Var loss:  tensor(1.6977e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7392665028421308e-06\n",
            "E_s_wdiff_all_sq: 1.386087277063833e-07\n",
            "E_IS_SCOPE: -1.0452244048437906e-05\n",
            "E_IS_E_SCOPE: -9.174239774450834e-06\n",
            "Total Loss: 1.697722935950181e-07\n",
            "----------------------------------------\n",
            "Epoch 221\n",
            "Var loss:  tensor(1.6912e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7385596932136388e-06\n",
            "E_s_wdiff_all_sq: 1.3858609099367413e-07\n",
            "E_IS_SCOPE: -1.0453109069422676e-05\n",
            "E_IS_E_SCOPE: -9.175123224702976e-06\n",
            "Total Loss: 1.691249792139804e-07\n",
            "----------------------------------------\n",
            "Epoch 222\n",
            "Var loss:  tensor(1.6848e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7385066676488703e-06\n",
            "E_s_wdiff_all_sq: 1.389511094917098e-07\n",
            "E_IS_SCOPE: -1.0455118799583097e-05\n",
            "E_IS_E_SCOPE: -9.177019978671165e-06\n",
            "Total Loss: 1.6848098276671291e-07\n",
            "----------------------------------------\n",
            "Epoch 223\n",
            "Var loss:  tensor(1.6783e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7393821108027646e-06\n",
            "E_s_wdiff_all_sq: 1.3989979736613458e-07\n",
            "E_IS_SCOPE: -1.0459703977310559e-05\n",
            "E_IS_E_SCOPE: -9.181315995543567e-06\n",
            "Total Loss: 1.6782941633605957e-07\n",
            "----------------------------------------\n",
            "Epoch 224\n",
            "Var loss:  tensor(1.6718e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.740273654646725e-06\n",
            "E_s_wdiff_all_sq: 1.410474862471362e-07\n",
            "E_IS_SCOPE: -1.0459643617122113e-05\n",
            "E_IS_E_SCOPE: -9.181060657244333e-06\n",
            "Total Loss: 1.6718331507744353e-07\n",
            "----------------------------------------\n",
            "Epoch 225\n",
            "Var loss:  tensor(1.6655e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7411817674774657e-06\n",
            "E_s_wdiff_all_sq: 1.424647795281127e-07\n",
            "E_IS_SCOPE: -1.0459903344764308e-05\n",
            "E_IS_E_SCOPE: -9.181257151825665e-06\n",
            "Total Loss: 1.6654766850548166e-07\n",
            "----------------------------------------\n",
            "Epoch 226\n",
            "Var loss:  tensor(1.6590e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7417042984427773e-06\n",
            "E_s_wdiff_all_sq: 1.4386432174723282e-07\n",
            "E_IS_SCOPE: -1.0456258586706909e-05\n",
            "E_IS_E_SCOPE: -9.177729233962356e-06\n",
            "Total Loss: 1.659043376398569e-07\n",
            "----------------------------------------\n",
            "Epoch 227\n",
            "Var loss:  tensor(1.6527e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7434479808515223e-06\n",
            "E_s_wdiff_all_sq: 1.4597025657158138e-07\n",
            "E_IS_SCOPE: -1.0454784482197305e-05\n",
            "E_IS_E_SCOPE: -9.176117668950777e-06\n",
            "Total Loss: 1.6526716422030155e-07\n",
            "----------------------------------------\n",
            "Epoch 228\n",
            "Var loss:  tensor(1.6463e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7454947317432827e-06\n",
            "E_s_wdiff_all_sq: 1.4812983423275126e-07\n",
            "E_IS_SCOPE: -1.0454754252648039e-05\n",
            "E_IS_E_SCOPE: -9.175824730557847e-06\n",
            "Total Loss: 1.6462891976356403e-07\n",
            "----------------------------------------\n",
            "Epoch 229\n",
            "Var loss:  tensor(1.6398e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7473079231103659e-06\n",
            "E_s_wdiff_all_sq: 1.500898268054322e-07\n",
            "E_IS_SCOPE: -1.045644023072339e-05\n",
            "E_IS_E_SCOPE: -9.17725833563972e-06\n",
            "Total Loss: 1.639773725710098e-07\n",
            "----------------------------------------\n",
            "Epoch 230\n",
            "Var loss:  tensor(1.6333e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7471696707860037e-06\n",
            "E_s_wdiff_all_sq: 1.5075674336481026e-07\n",
            "E_IS_SCOPE: -1.0455776458203247e-05\n",
            "E_IS_E_SCOPE: -9.176675251591441e-06\n",
            "Total Loss: 1.6333358063099792e-07\n",
            "----------------------------------------\n",
            "Epoch 231\n",
            "Var loss:  tensor(1.6270e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.745256333981652e-06\n",
            "E_s_wdiff_all_sq: 1.4978696654863541e-07\n",
            "E_IS_SCOPE: -1.0454565870824841e-05\n",
            "E_IS_E_SCOPE: -9.17561748314054e-06\n",
            "Total Loss: 1.6269565849782852e-07\n",
            "----------------------------------------\n",
            "Epoch 232\n",
            "Var loss:  tensor(1.6205e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7437798831952323e-06\n",
            "E_s_wdiff_all_sq: 1.487689221174582e-07\n",
            "E_IS_SCOPE: -1.0454678057638115e-05\n",
            "E_IS_E_SCOPE: -9.175637973142926e-06\n",
            "Total Loss: 1.6205385852081215e-07\n",
            "----------------------------------------\n",
            "Epoch 233\n",
            "Var loss:  tensor(1.6142e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7442396759684765e-06\n",
            "E_s_wdiff_all_sq: 1.4941162801690616e-07\n",
            "E_IS_SCOPE: -1.0458061000412243e-05\n",
            "E_IS_E_SCOPE: -9.178794473640043e-06\n",
            "Total Loss: 1.6141806084058316e-07\n",
            "----------------------------------------\n",
            "Epoch 234\n",
            "Var loss:  tensor(1.6078e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7456679839955844e-06\n",
            "E_s_wdiff_all_sq: 1.5123773315250453e-07\n",
            "E_IS_SCOPE: -1.0459716808749948e-05\n",
            "E_IS_E_SCOPE: -9.180328428986796e-06\n",
            "Total Loss: 1.6077655775019172e-07\n",
            "----------------------------------------\n",
            "Epoch 235\n",
            "Var loss:  tensor(1.6014e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7468399993177723e-06\n",
            "E_s_wdiff_all_sq: 1.530051479814524e-07\n",
            "E_IS_SCOPE: -1.045734105343696e-05\n",
            "E_IS_E_SCOPE: -9.17793062692639e-06\n",
            "Total Loss: 1.601370647485958e-07\n",
            "----------------------------------------\n",
            "Epoch 236\n",
            "Var loss:  tensor(1.5949e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7484830711520996e-06\n",
            "E_s_wdiff_all_sq: 1.54786100023696e-07\n",
            "E_IS_SCOPE: -1.0458052182294134e-05\n",
            "E_IS_E_SCOPE: -9.178388101406893e-06\n",
            "Total Loss: 1.59491875787338e-07\n",
            "----------------------------------------\n",
            "Epoch 237\n",
            "Var loss:  tensor(1.5885e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7507326501469544e-06\n",
            "E_s_wdiff_all_sq: 1.5700627626755758e-07\n",
            "E_IS_SCOPE: -1.045989639186633e-05\n",
            "E_IS_E_SCOPE: -9.179898414596901e-06\n",
            "Total Loss: 1.5885348577395397e-07\n",
            "----------------------------------------\n",
            "Epoch 238\n",
            "Var loss:  tensor(1.5821e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.751565671510783e-06\n",
            "E_s_wdiff_all_sq: 1.584821597114168e-07\n",
            "E_IS_SCOPE: -1.0460484734337986e-05\n",
            "E_IS_E_SCOPE: -9.18048751262316e-06\n",
            "Total Loss: 1.582121348031317e-07\n",
            "----------------------------------------\n",
            "Epoch 239\n",
            "Var loss:  tensor(1.5757e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7516173472166448e-06\n",
            "E_s_wdiff_all_sq: 1.594104393135381e-07\n",
            "E_IS_SCOPE: -1.0460008210153274e-05\n",
            "E_IS_E_SCOPE: -9.180126192850398e-06\n",
            "Total Loss: 1.5756593973077322e-07\n",
            "----------------------------------------\n",
            "Epoch 240\n",
            "Var loss:  tensor(1.5692e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.752702207286652e-06\n",
            "E_s_wdiff_all_sq: 1.6078765936794585e-07\n",
            "E_IS_SCOPE: -1.0461080246618529e-05\n",
            "E_IS_E_SCOPE: -9.181023103050093e-06\n",
            "Total Loss: 1.5692332721524754e-07\n",
            "----------------------------------------\n",
            "Epoch 241\n",
            "Var loss:  tensor(1.5628e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7523995269052183e-06\n",
            "E_s_wdiff_all_sq: 1.6078051001768047e-07\n",
            "E_IS_SCOPE: -1.046048271620256e-05\n",
            "E_IS_E_SCOPE: -9.180252251235532e-06\n",
            "Total Loss: 1.562811533868966e-07\n",
            "----------------------------------------\n",
            "Epoch 242\n",
            "Var loss:  tensor(1.5564e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7509988101800129e-06\n",
            "E_s_wdiff_all_sq: 1.5956252102996786e-07\n",
            "E_IS_SCOPE: -1.0460839370505924e-05\n",
            "E_IS_E_SCOPE: -9.180380992616438e-06\n",
            "Total Loss: 1.5564259980448994e-07\n",
            "----------------------------------------\n",
            "Epoch 243\n",
            "Var loss:  tensor(1.5500e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.748630436049306e-06\n",
            "E_s_wdiff_all_sq: 1.5795472743779332e-07\n",
            "E_IS_SCOPE: -1.0460836271398226e-05\n",
            "E_IS_E_SCOPE: -9.180436086459448e-06\n",
            "Total Loss: 1.549984051673694e-07\n",
            "----------------------------------------\n",
            "Epoch 244\n",
            "Var loss:  tensor(1.5436e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.747823058915892e-06\n",
            "E_s_wdiff_all_sq: 1.578094731979114e-07\n",
            "E_IS_SCOPE: -1.0457820966329391e-05\n",
            "E_IS_E_SCOPE: -9.177433532822301e-06\n",
            "Total Loss: 1.5436178513721452e-07\n",
            "----------------------------------------\n",
            "Epoch 245\n",
            "Var loss:  tensor(1.5372e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7495722502941363e-06\n",
            "E_s_wdiff_all_sq: 1.5949434645601895e-07\n",
            "E_IS_SCOPE: -1.0458696722046427e-05\n",
            "E_IS_E_SCOPE: -9.177957132727783e-06\n",
            "Total Loss: 1.5372179163424397e-07\n",
            "----------------------------------------\n",
            "Epoch 246\n",
            "Var loss:  tensor(1.5308e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7518526970942281e-06\n",
            "E_s_wdiff_all_sq: 1.621680460030213e-07\n",
            "E_IS_SCOPE: -1.0460095358712852e-05\n",
            "E_IS_E_SCOPE: -9.17923165663916e-06\n",
            "Total Loss: 1.5308031337723694e-07\n",
            "----------------------------------------\n",
            "Epoch 247\n",
            "Var loss:  tensor(1.5244e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.75447432477904e-06\n",
            "E_s_wdiff_all_sq: 1.6536910705884774e-07\n",
            "E_IS_SCOPE: -1.046280501500442e-05\n",
            "E_IS_E_SCOPE: -9.181913262289017e-06\n",
            "Total Loss: 1.524447787228019e-07\n",
            "----------------------------------------\n",
            "Epoch 248\n",
            "Var loss:  tensor(1.5180e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7567182860073056e-06\n",
            "E_s_wdiff_all_sq: 1.6840025226733468e-07\n",
            "E_IS_SCOPE: -1.0461486258712005e-05\n",
            "E_IS_E_SCOPE: -9.180666878423921e-06\n",
            "Total Loss: 1.5180233959721798e-07\n",
            "----------------------------------------\n",
            "Epoch 249\n",
            "Var loss:  tensor(1.5116e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7591926759199087e-06\n",
            "E_s_wdiff_all_sq: 1.7128499260436842e-07\n",
            "E_IS_SCOPE: -1.0460876800915892e-05\n",
            "E_IS_E_SCOPE: -9.179939976177304e-06\n",
            "Total Loss: 1.511571002717782e-07\n",
            "----------------------------------------\n",
            "Epoch 250\n",
            "Var loss:  tensor(1.5053e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7612708060504384e-06\n",
            "E_s_wdiff_all_sq: 1.735193010791507e-07\n",
            "E_IS_SCOPE: -1.0460753271206583e-05\n",
            "E_IS_E_SCOPE: -9.179580263859504e-06\n",
            "Total Loss: 1.5052855671054326e-07\n",
            "----------------------------------------\n",
            "Epoch 251\n",
            "Var loss:  tensor(1.4989e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7612159817841874e-06\n",
            "E_s_wdiff_all_sq: 1.7398767486133782e-07\n",
            "E_IS_SCOPE: -1.046046556140337e-05\n",
            "E_IS_E_SCOPE: -9.179232549581669e-06\n",
            "Total Loss: 1.4988534971286493e-07\n",
            "----------------------------------------\n",
            "Epoch 252\n",
            "Var loss:  tensor(1.4924e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7597609463033071e-06\n",
            "E_s_wdiff_all_sq: 1.732982009341844e-07\n",
            "E_IS_SCOPE: -1.0460757960355661e-05\n",
            "E_IS_E_SCOPE: -9.179586688669593e-06\n",
            "Total Loss: 1.4924326843040171e-07\n",
            "----------------------------------------\n",
            "Epoch 253\n",
            "Var loss:  tensor(1.4860e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7593921587130802e-06\n",
            "E_s_wdiff_all_sq: 1.7322126226950647e-07\n",
            "E_IS_SCOPE: -1.046192579287724e-05\n",
            "E_IS_E_SCOPE: -9.180578689378714e-06\n",
            "Total Loss: 1.4859975587993454e-07\n",
            "----------------------------------------\n",
            "Epoch 254\n",
            "Var loss:  tensor(1.4795e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7599302888829527e-06\n",
            "E_s_wdiff_all_sq: 1.7357964344731667e-07\n",
            "E_IS_SCOPE: -1.046460037451883e-05\n",
            "E_IS_E_SCOPE: -9.182839976327962e-06\n",
            "Total Loss: 1.4795291548731723e-07\n",
            "----------------------------------------\n",
            "Epoch 255\n",
            "Var loss:  tensor(1.4731e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7600955930526417e-06\n",
            "E_s_wdiff_all_sq: 1.7394179096784093e-07\n",
            "E_IS_SCOPE: -1.0464514090801401e-05\n",
            "E_IS_E_SCOPE: -9.182530029627216e-06\n",
            "Total Loss: 1.4730874616984876e-07\n",
            "----------------------------------------\n",
            "Epoch 256\n",
            "Var loss:  tensor(1.4666e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7600552270100056e-06\n",
            "E_s_wdiff_all_sq: 1.7448501591811216e-07\n",
            "E_IS_SCOPE: -1.0463452047713957e-05\n",
            "E_IS_E_SCOPE: -9.181437868345602e-06\n",
            "Total Loss: 1.466649187885999e-07\n",
            "----------------------------------------\n",
            "Epoch 257\n",
            "Var loss:  tensor(1.4602e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7599482329442396e-06\n",
            "E_s_wdiff_all_sq: 1.7489761560690423e-07\n",
            "E_IS_SCOPE: -1.0463911700489385e-05\n",
            "E_IS_E_SCOPE: -9.181832929029563e-06\n",
            "Total Loss: 1.460161408511103e-07\n",
            "----------------------------------------\n",
            "Epoch 258\n",
            "Var loss:  tensor(1.4537e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7597081048368775e-06\n",
            "E_s_wdiff_all_sq: 1.7546909543590988e-07\n",
            "E_IS_SCOPE: -1.0462726451589788e-05\n",
            "E_IS_E_SCOPE: -9.180730911284939e-06\n",
            "Total Loss: 1.4537099522468424e-07\n",
            "----------------------------------------\n",
            "Epoch 259\n",
            "Var loss:  tensor(1.4473e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.760441119439797e-06\n",
            "E_s_wdiff_all_sq: 1.7682921079583578e-07\n",
            "E_IS_SCOPE: -1.046238172181875e-05\n",
            "E_IS_E_SCOPE: -9.180380576380438e-06\n",
            "Total Loss: 1.4473268420075234e-07\n",
            "----------------------------------------\n",
            "Epoch 260\n",
            "Var loss:  tensor(1.4408e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7624567909047894e-06\n",
            "E_s_wdiff_all_sq: 1.789674116711514e-07\n",
            "E_IS_SCOPE: -1.0459599646463285e-05\n",
            "E_IS_E_SCOPE: -9.177331624509329e-06\n",
            "Total Loss: 1.4407640175914274e-07\n",
            "----------------------------------------\n",
            "Epoch 261\n",
            "Var loss:  tensor(1.4343e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7633982811940541e-06\n",
            "E_s_wdiff_all_sq: 1.8002966405584798e-07\n",
            "E_IS_SCOPE: -1.045430413598943e-05\n",
            "E_IS_E_SCOPE: -9.171771191314112e-06\n",
            "Total Loss: 1.4342579422098563e-07\n",
            "----------------------------------------\n",
            "Epoch 262\n",
            "Var loss:  tensor(1.4278e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7640436953847062e-06\n",
            "E_s_wdiff_all_sq: 1.8098976762098602e-07\n",
            "E_IS_SCOPE: -1.045028098644712e-05\n",
            "E_IS_E_SCOPE: -9.167584760592755e-06\n",
            "Total Loss: 1.4278454248840528e-07\n",
            "----------------------------------------\n",
            "Epoch 263\n",
            "Var loss:  tensor(1.4214e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7634472847825978e-06\n",
            "E_s_wdiff_all_sq: 1.8131989982456647e-07\n",
            "E_IS_SCOPE: -1.0445941598797853e-05\n",
            "E_IS_E_SCOPE: -9.163384501255257e-06\n",
            "Total Loss: 1.4213625630625622e-07\n",
            "----------------------------------------\n",
            "Epoch 264\n",
            "Var loss:  tensor(1.4149e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.764415700787053e-06\n",
            "E_s_wdiff_all_sq: 1.8280952148201338e-07\n",
            "E_IS_SCOPE: -1.0443944949440603e-05\n",
            "E_IS_E_SCOPE: -9.16132344407908e-06\n",
            "Total Loss: 1.4148623501540997e-07\n",
            "----------------------------------------\n",
            "Epoch 265\n",
            "Var loss:  tensor(1.4083e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7671742281428323e-06\n",
            "E_s_wdiff_all_sq: 1.8564507388594667e-07\n",
            "E_IS_SCOPE: -1.0445721299336475e-05\n",
            "E_IS_E_SCOPE: -9.16280967134644e-06\n",
            "Total Loss: 1.4082896471023093e-07\n",
            "----------------------------------------\n",
            "Epoch 266\n",
            "Var loss:  tensor(1.4018e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.769720434306535e-06\n",
            "E_s_wdiff_all_sq: 1.8841869647411404e-07\n",
            "E_IS_SCOPE: -1.0449456372247518e-05\n",
            "E_IS_E_SCOPE: -9.166334744924064e-06\n",
            "Total Loss: 1.401815496189308e-07\n",
            "----------------------------------------\n",
            "Epoch 267\n",
            "Var loss:  tensor(1.3952e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7698575739975834e-06\n",
            "E_s_wdiff_all_sq: 1.89644373950154e-07\n",
            "E_IS_SCOPE: -1.0448901594213123e-05\n",
            "E_IS_E_SCOPE: -9.165991806060456e-06\n",
            "Total Loss: 1.395166901755122e-07\n",
            "----------------------------------------\n",
            "Epoch 268\n",
            "Var loss:  tensor(1.3886e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7695085445879618e-06\n",
            "E_s_wdiff_all_sq: 1.9023336487219613e-07\n",
            "E_IS_SCOPE: -1.044690595751027e-05\n",
            "E_IS_E_SCOPE: -9.164135335141611e-06\n",
            "Total Loss: 1.388570014118631e-07\n",
            "----------------------------------------\n",
            "Epoch 269\n",
            "Var loss:  tensor(1.3820e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7701907405958831e-06\n",
            "E_s_wdiff_all_sq: 1.9062438202763115e-07\n",
            "E_IS_SCOPE: -1.0449437209335548e-05\n",
            "E_IS_E_SCOPE: -9.166191412145714e-06\n",
            "Total Loss: 1.3819783062200228e-07\n",
            "----------------------------------------\n",
            "Epoch 270\n",
            "Var loss:  tensor(1.3754e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.769137553642356e-06\n",
            "E_s_wdiff_all_sq: 1.8973285243082855e-07\n",
            "E_IS_SCOPE: -1.0450713624069527e-05\n",
            "E_IS_E_SCOPE: -9.16722071488748e-06\n",
            "Total Loss: 1.3754194928085e-07\n",
            "----------------------------------------\n",
            "Epoch 271\n",
            "Var loss:  tensor(1.3689e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7666987737461143e-06\n",
            "E_s_wdiff_all_sq: 1.8836787820051664e-07\n",
            "E_IS_SCOPE: -1.0449605819564161e-05\n",
            "E_IS_E_SCOPE: -9.166321918644114e-06\n",
            "Total Loss: 1.3688616013891785e-07\n",
            "----------------------------------------\n",
            "Epoch 272\n",
            "Var loss:  tensor(1.3622e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7656016011496945e-06\n",
            "E_s_wdiff_all_sq: 1.8807953362166853e-07\n",
            "E_IS_SCOPE: -1.0443620799949787e-05\n",
            "E_IS_E_SCOPE: -9.160409831614131e-06\n",
            "Total Loss: 1.3622319729013106e-07\n",
            "----------------------------------------\n",
            "Epoch 273\n",
            "Var loss:  tensor(1.3556e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7680662107946642e-06\n",
            "E_s_wdiff_all_sq: 1.9001257585059638e-07\n",
            "E_IS_SCOPE: -1.0440787953824423e-05\n",
            "E_IS_E_SCOPE: -9.156981943277473e-06\n",
            "Total Loss: 1.355646802835842e-07\n",
            "----------------------------------------\n",
            "Epoch 274\n",
            "Var loss:  tensor(1.3490e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.770323516887919e-06\n",
            "E_s_wdiff_all_sq: 1.9224045769489836e-07\n",
            "E_IS_SCOPE: -1.043931798237091e-05\n",
            "E_IS_E_SCOPE: -9.155166123176814e-06\n",
            "Total Loss: 1.3490240723824424e-07\n",
            "----------------------------------------\n",
            "Epoch 275\n",
            "Var loss:  tensor(1.3424e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7708356349537273e-06\n",
            "E_s_wdiff_all_sq: 1.940186427273107e-07\n",
            "E_IS_SCOPE: -1.0435779307134885e-05\n",
            "E_IS_E_SCOPE: -9.151931646308486e-06\n",
            "Total Loss: 1.3424473700703312e-07\n",
            "----------------------------------------\n",
            "Epoch 276\n",
            "Var loss:  tensor(1.3359e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.77196356560798e-06\n",
            "E_s_wdiff_all_sq: 1.9612187149287854e-07\n",
            "E_IS_SCOPE: -1.0430617236285214e-05\n",
            "E_IS_E_SCOPE: -9.146929711222686e-06\n",
            "Total Loss: 1.335897104234637e-07\n",
            "----------------------------------------\n",
            "Epoch 277\n",
            "Var loss:  tensor(1.3293e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.77548909727145e-06\n",
            "E_s_wdiff_all_sq: 1.995698041428827e-07\n",
            "E_IS_SCOPE: -1.0429004590830635e-05\n",
            "E_IS_E_SCOPE: -9.144947696388625e-06\n",
            "Total Loss: 1.329285706779634e-07\n",
            "----------------------------------------\n",
            "Epoch 278\n",
            "Var loss:  tensor(1.3227e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7785523855361568e-06\n",
            "E_s_wdiff_all_sq: 2.0269590318062503e-07\n",
            "E_IS_SCOPE: -1.042805965285692e-05\n",
            "E_IS_E_SCOPE: -9.14370388279196e-06\n",
            "Total Loss: 1.3226800865902796e-07\n",
            "----------------------------------------\n",
            "Epoch 279\n",
            "Var loss:  tensor(1.3162e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7796341427694831e-06\n",
            "E_s_wdiff_all_sq: 2.046307716417365e-07\n",
            "E_IS_SCOPE: -1.0425262641072191e-05\n",
            "E_IS_E_SCOPE: -9.141009510331204e-06\n",
            "Total Loss: 1.3162017607918817e-07\n",
            "----------------------------------------\n",
            "Epoch 280\n",
            "Var loss:  tensor(1.3096e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7789890088167458e-06\n",
            "E_s_wdiff_all_sq: 2.049856178529891e-07\n",
            "E_IS_SCOPE: -1.0421360817532884e-05\n",
            "E_IS_E_SCOPE: -9.13727903172707e-06\n",
            "Total Loss: 1.309628857855432e-07\n",
            "----------------------------------------\n",
            "Epoch 281\n",
            "Var loss:  tensor(1.3029e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7781198842584413e-06\n",
            "E_s_wdiff_all_sq: 2.0438164743723147e-07\n",
            "E_IS_SCOPE: -1.0419984664052013e-05\n",
            "E_IS_E_SCOPE: -9.13570107677164e-06\n",
            "Total Loss: 1.3029412869388135e-07\n",
            "----------------------------------------\n",
            "Epoch 282\n",
            "Var loss:  tensor(1.2964e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.777361957653897e-06\n",
            "E_s_wdiff_all_sq: 2.0380817626837826e-07\n",
            "E_IS_SCOPE: -1.0417414752588068e-05\n",
            "E_IS_E_SCOPE: -9.132895603981939e-06\n",
            "Total Loss: 1.2963855060667575e-07\n",
            "----------------------------------------\n",
            "Epoch 283\n",
            "Var loss:  tensor(1.2899e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7763105401164026e-06\n",
            "E_s_wdiff_all_sq: 2.0341013893713345e-07\n",
            "E_IS_SCOPE: -1.0416539458764655e-05\n",
            "E_IS_E_SCOPE: -9.132020244212534e-06\n",
            "Total Loss: 1.2898503850844248e-07\n",
            "----------------------------------------\n",
            "Epoch 284\n",
            "Var loss:  tensor(1.2832e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7751777161232545e-06\n",
            "E_s_wdiff_all_sq: 2.029930363698069e-07\n",
            "E_IS_SCOPE: -1.0415670960538858e-05\n",
            "E_IS_E_SCOPE: -9.131178060387017e-06\n",
            "Total Loss: 1.2832194588318155e-07\n",
            "----------------------------------------\n",
            "Epoch 285\n",
            "Var loss:  tensor(1.2766e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7763876577993641e-06\n",
            "E_s_wdiff_all_sq: 2.0411471294798634e-07\n",
            "E_IS_SCOPE: -1.0417525046655218e-05\n",
            "E_IS_E_SCOPE: -9.1326588564687e-06\n",
            "Total Loss: 1.2766363091175617e-07\n",
            "----------------------------------------\n",
            "Epoch 286\n",
            "Var loss:  tensor(1.2702e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7789918351959847e-06\n",
            "E_s_wdiff_all_sq: 2.0646381043275854e-07\n",
            "E_IS_SCOPE: -1.0420175725332962e-05\n",
            "E_IS_E_SCOPE: -9.13486013848053e-06\n",
            "Total Loss: 1.2701991749178068e-07\n",
            "----------------------------------------\n",
            "Epoch 287\n",
            "Var loss:  tensor(1.2635e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7796083787126626e-06\n",
            "E_s_wdiff_all_sq: 2.0810291646705268e-07\n",
            "E_IS_SCOPE: -1.041348378287602e-05\n",
            "E_IS_E_SCOPE: -9.12834679623124e-06\n",
            "Total Loss: 1.2635455538946315e-07\n",
            "----------------------------------------\n",
            "Epoch 288\n",
            "Var loss:  tensor(1.2569e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7799369660920976e-06\n",
            "E_s_wdiff_all_sq: 2.0953812730450945e-07\n",
            "E_IS_SCOPE: -1.0407141406025578e-05\n",
            "E_IS_E_SCOPE: -9.122224712898652e-06\n",
            "Total Loss: 1.2568851896715273e-07\n",
            "----------------------------------------\n",
            "Epoch 289\n",
            "Var loss:  tensor(1.2504e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7834675224954335e-06\n",
            "E_s_wdiff_all_sq: 2.130356633332161e-07\n",
            "E_IS_SCOPE: -1.040680094322707e-05\n",
            "E_IS_E_SCOPE: -9.121544642465962e-06\n",
            "Total Loss: 1.250423240734157e-07\n",
            "----------------------------------------\n",
            "Epoch 290\n",
            "Var loss:  tensor(1.2440e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7866853823331606e-06\n",
            "E_s_wdiff_all_sq: 2.1632412594151053e-07\n",
            "E_IS_SCOPE: -1.0408179001069024e-05\n",
            "E_IS_E_SCOPE: -9.122639266020722e-06\n",
            "Total Loss: 1.2440485272846273e-07\n",
            "----------------------------------------\n",
            "Epoch 291\n",
            "Var loss:  tensor(1.2376e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7868240593460986e-06\n",
            "E_s_wdiff_all_sq: 2.175604824046332e-07\n",
            "E_IS_SCOPE: -1.0403423051419139e-05\n",
            "E_IS_E_SCOPE: -9.11811180243828e-06\n",
            "Total Loss: 1.2376414541316366e-07\n",
            "----------------------------------------\n",
            "Epoch 292\n",
            "Var loss:  tensor(1.2312e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7868524714920438e-06\n",
            "E_s_wdiff_all_sq: 2.1867561328055697e-07\n",
            "E_IS_SCOPE: -1.0399227293205882e-05\n",
            "E_IS_E_SCOPE: -9.11413872178555e-06\n",
            "Total Loss: 1.2312278180424125e-07\n",
            "----------------------------------------\n",
            "Epoch 293\n",
            "Var loss:  tensor(1.2250e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7902801220221295e-06\n",
            "E_s_wdiff_all_sq: 2.2162535083602078e-07\n",
            "E_IS_SCOPE: -1.0401451241030636e-05\n",
            "E_IS_E_SCOPE: -9.11581042789991e-06\n",
            "Total Loss: 1.2249621135807247e-07\n",
            "----------------------------------------\n",
            "Epoch 294\n",
            "Var loss:  tensor(1.2186e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7920082654065135e-06\n",
            "E_s_wdiff_all_sq: 2.2299257574964347e-07\n",
            "E_IS_SCOPE: -1.0403110665061582e-05\n",
            "E_IS_E_SCOPE: -9.116969695554372e-06\n",
            "Total Loss: 1.2185681707586308e-07\n",
            "----------------------------------------\n",
            "Epoch 295\n",
            "Var loss:  tensor(1.2122e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7888360740298392e-06\n",
            "E_s_wdiff_all_sq: 2.2123878833948505e-07\n",
            "E_IS_SCOPE: -1.0396548224484091e-05\n",
            "E_IS_E_SCOPE: -9.110795849409268e-06\n",
            "Total Loss: 1.2121560197412344e-07\n",
            "----------------------------------------\n",
            "Epoch 296\n",
            "Var loss:  tensor(1.2058e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7862276753803672e-06\n",
            "E_s_wdiff_all_sq: 2.1942278040138897e-07\n",
            "E_IS_SCOPE: -1.0392967167857434e-05\n",
            "E_IS_E_SCOPE: -9.107293872774308e-06\n",
            "Total Loss: 1.2058137124614278e-07\n",
            "----------------------------------------\n",
            "Epoch 297\n",
            "Var loss:  tensor(1.1995e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7866842556344687e-06\n",
            "E_s_wdiff_all_sq: 2.196125024758515e-07\n",
            "E_IS_SCOPE: -1.0394038691874905e-05\n",
            "E_IS_E_SCOPE: -9.10791580431767e-06\n",
            "Total Loss: 1.1994904447756047e-07\n",
            "----------------------------------------\n",
            "Epoch 298\n",
            "Var loss:  tensor(1.1932e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.787005008038995e-06\n",
            "E_s_wdiff_all_sq: 2.2035834332368694e-07\n",
            "E_IS_SCOPE: -1.039511007922034e-05\n",
            "E_IS_E_SCOPE: -9.108886012504627e-06\n",
            "Total Loss: 1.1932159771729535e-07\n",
            "----------------------------------------\n",
            "Epoch 299\n",
            "Var loss:  tensor(1.1869e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7869275095264578e-06\n",
            "E_s_wdiff_all_sq: 2.2111929944694488e-07\n",
            "E_IS_SCOPE: -1.0393742402430107e-05\n",
            "E_IS_E_SCOPE: -9.107619929835728e-06\n",
            "Total Loss: 1.1868633132416935e-07\n",
            "----------------------------------------\n",
            "Epoch 300\n",
            "Var loss:  tensor(1.1805e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7878777394131112e-06\n",
            "E_s_wdiff_all_sq: 2.2242493350761248e-07\n",
            "E_IS_SCOPE: -1.0394241320850136e-05\n",
            "E_IS_E_SCOPE: -9.107979237051593e-06\n",
            "Total Loss: 1.1805170474182911e-07\n",
            "----------------------------------------\n",
            "Epoch 301\n",
            "Var loss:  tensor(1.1742e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.789271556648441e-06\n",
            "E_s_wdiff_all_sq: 2.2418822445444706e-07\n",
            "E_IS_SCOPE: -1.0393910768304846e-05\n",
            "E_IS_E_SCOPE: -9.107519044389159e-06\n",
            "Total Loss: 1.1742295079603649e-07\n",
            "----------------------------------------\n",
            "Epoch 302\n",
            "Var loss:  tensor(1.1680e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7908770319842185e-06\n",
            "E_s_wdiff_all_sq: 2.2607898292583807e-07\n",
            "E_IS_SCOPE: -1.03922041704708e-05\n",
            "E_IS_E_SCOPE: -9.105642324505715e-06\n",
            "Total Loss: 1.1679742356162505e-07\n",
            "----------------------------------------\n",
            "Epoch 303\n",
            "Var loss:  tensor(1.1617e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7919382745084536e-06\n",
            "E_s_wdiff_all_sq: 2.2750067128988802e-07\n",
            "E_IS_SCOPE: -1.0389273056368621e-05\n",
            "E_IS_E_SCOPE: -9.102578475251142e-06\n",
            "Total Loss: 1.161715074170197e-07\n",
            "----------------------------------------\n",
            "Epoch 304\n",
            "Var loss:  tensor(1.1554e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.792143657592719e-06\n",
            "E_s_wdiff_all_sq: 2.2797854203732862e-07\n",
            "E_IS_SCOPE: -1.038773721774323e-05\n",
            "E_IS_E_SCOPE: -9.100863973648154e-06\n",
            "Total Loss: 1.1554169379865563e-07\n",
            "----------------------------------------\n",
            "Epoch 305\n",
            "Var loss:  tensor(1.1493e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7907459993759377e-06\n",
            "E_s_wdiff_all_sq: 2.2719775213939785e-07\n",
            "E_IS_SCOPE: -1.0383448312964843e-05\n",
            "E_IS_E_SCOPE: -9.096575543411794e-06\n",
            "Total Loss: 1.1492577456385684e-07\n",
            "----------------------------------------\n",
            "Epoch 306\n",
            "Var loss:  tensor(1.1431e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7891368126472525e-06\n",
            "E_s_wdiff_all_sq: 2.2667283941292478e-07\n",
            "E_IS_SCOPE: -1.0377694310915142e-05\n",
            "E_IS_E_SCOPE: -9.091053504862099e-06\n",
            "Total Loss: 1.1430542756165728e-07\n",
            "----------------------------------------\n",
            "Epoch 307\n",
            "Var loss:  tensor(1.1367e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7899119733127507e-06\n",
            "E_s_wdiff_all_sq: 2.2813610952904193e-07\n",
            "E_IS_SCOPE: -1.03759071398555e-05\n",
            "E_IS_E_SCOPE: -9.089294115208419e-06\n",
            "Total Loss: 1.1367288092296075e-07\n",
            "----------------------------------------\n",
            "Epoch 308\n",
            "Var loss:  tensor(1.1304e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7936552441597232e-06\n",
            "E_s_wdiff_all_sq: 2.3202224055865683e-07\n",
            "E_IS_SCOPE: -1.0380146763917824e-05\n",
            "E_IS_E_SCOPE: -9.093290758524629e-06\n",
            "Total Loss: 1.130440592480939e-07\n",
            "----------------------------------------\n",
            "Epoch 309\n",
            "Var loss:  tensor(1.1243e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7971000373839665e-06\n",
            "E_s_wdiff_all_sq: 2.354888071559719e-07\n",
            "E_IS_SCOPE: -1.0386152808417919e-05\n",
            "E_IS_E_SCOPE: -9.098999324263099e-06\n",
            "Total Loss: 1.1242732835177043e-07\n",
            "----------------------------------------\n",
            "Epoch 310\n",
            "Var loss:  tensor(1.1180e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7969682693787913e-06\n",
            "E_s_wdiff_all_sq: 2.361542953821434e-07\n",
            "E_IS_SCOPE: -1.038216046557734e-05\n",
            "E_IS_E_SCOPE: -9.095089457404167e-06\n",
            "Total Loss: 1.1179502408371662e-07\n",
            "----------------------------------------\n",
            "Epoch 311\n",
            "Var loss:  tensor(1.1117e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7966095231007444e-06\n",
            "E_s_wdiff_all_sq: 2.365775962092629e-07\n",
            "E_IS_SCOPE: -1.0372975909110613e-05\n",
            "E_IS_E_SCOPE: -9.085985679040843e-06\n",
            "Total Loss: 1.1117453318535594e-07\n",
            "----------------------------------------\n",
            "Epoch 312\n",
            "Var loss:  tensor(1.1056e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7987056443128666e-06\n",
            "E_s_wdiff_all_sq: 2.3850206938688644e-07\n",
            "E_IS_SCOPE: -1.0368712039555494e-05\n",
            "E_IS_E_SCOPE: -9.081328937663862e-06\n",
            "Total Loss: 1.1056043757613148e-07\n",
            "----------------------------------------\n",
            "Epoch 313\n",
            "Var loss:  tensor(1.0993e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.799605218506197e-06\n",
            "E_s_wdiff_all_sq: 2.3919681381749194e-07\n",
            "E_IS_SCOPE: -1.0369280290589961e-05\n",
            "E_IS_E_SCOPE: -9.081479491550445e-06\n",
            "Total Loss: 1.0992987304308782e-07\n",
            "----------------------------------------\n",
            "Epoch 314\n",
            "Var loss:  tensor(1.0930e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.797164722089172e-06\n",
            "E_s_wdiff_all_sq: 2.374055471136057e-07\n",
            "E_IS_SCOPE: -1.0368029803934094e-05\n",
            "E_IS_E_SCOPE: -9.080239587607725e-06\n",
            "Total Loss: 1.0930180875624557e-07\n",
            "----------------------------------------\n",
            "Epoch 315\n",
            "Var loss:  tensor(1.0868e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7928762227193067e-06\n",
            "E_s_wdiff_all_sq: 2.3393090430943315e-07\n",
            "E_IS_SCOPE: -1.036439421159407e-05\n",
            "E_IS_E_SCOPE: -9.076699960883182e-06\n",
            "Total Loss: 1.0867988342151072e-07\n",
            "----------------------------------------\n",
            "Epoch 316\n",
            "Var loss:  tensor(1.0806e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.789914254803339e-06\n",
            "E_s_wdiff_all_sq: 2.316438975205221e-07\n",
            "E_IS_SCOPE: -1.0361254986746827e-05\n",
            "E_IS_E_SCOPE: -9.073588716656031e-06\n",
            "Total Loss: 1.0806088353464069e-07\n",
            "----------------------------------------\n",
            "Epoch 317\n",
            "Var loss:  tensor(1.0743e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7904555065522625e-06\n",
            "E_s_wdiff_all_sq: 2.3241589233025768e-07\n",
            "E_IS_SCOPE: -1.0361915728598315e-05\n",
            "E_IS_E_SCOPE: -9.074050448855403e-06\n",
            "Total Loss: 1.074321211695986e-07\n",
            "----------------------------------------\n",
            "Epoch 318\n",
            "Var loss:  tensor(1.0681e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.79363136683934e-06\n",
            "E_s_wdiff_all_sq: 2.3542894080123295e-07\n",
            "E_IS_SCOPE: -1.0366592564989412e-05\n",
            "E_IS_E_SCOPE: -9.078332806464287e-06\n",
            "Total Loss: 1.0680597542127319e-07\n",
            "----------------------------------------\n",
            "Epoch 319\n",
            "Var loss:  tensor(1.0618e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7954871822353848e-06\n",
            "E_s_wdiff_all_sq: 2.3772076166190373e-07\n",
            "E_IS_SCOPE: -1.0368545578542543e-05\n",
            "E_IS_E_SCOPE: -9.080191764511522e-06\n",
            "Total Loss: 1.0618185894485306e-07\n",
            "----------------------------------------\n",
            "Epoch 320\n",
            "Var loss:  tensor(1.0557e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.796094286448647e-06\n",
            "E_s_wdiff_all_sq: 2.3925479616587945e-07\n",
            "E_IS_SCOPE: -1.0367660109871508e-05\n",
            "E_IS_E_SCOPE: -9.07946382712844e-06\n",
            "Total Loss: 1.0556999123004566e-07\n",
            "----------------------------------------\n",
            "Epoch 321\n",
            "Var loss:  tensor(1.0495e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7974176418106343e-06\n",
            "E_s_wdiff_all_sq: 2.4163849454421917e-07\n",
            "E_IS_SCOPE: -1.0361000675555545e-05\n",
            "E_IS_E_SCOPE: -9.07302383794864e-06\n",
            "Total Loss: 1.0494853848601913e-07\n",
            "----------------------------------------\n",
            "Epoch 322\n",
            "Var loss:  tensor(1.0432e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8036874862586164e-06\n",
            "E_s_wdiff_all_sq: 2.4749250547790794e-07\n",
            "E_IS_SCOPE: -1.0359895685103116e-05\n",
            "E_IS_E_SCOPE: -9.071395124762296e-06\n",
            "Total Loss: 1.0431692653248355e-07\n",
            "----------------------------------------\n",
            "Epoch 323\n",
            "Var loss:  tensor(1.0370e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8106445901650156e-06\n",
            "E_s_wdiff_all_sq: 2.5391256072762406e-07\n",
            "E_IS_SCOPE: -1.0364616507943786e-05\n",
            "E_IS_E_SCOPE: -9.075538677267025e-06\n",
            "Total Loss: 1.0369943451728638e-07\n",
            "----------------------------------------\n",
            "Epoch 324\n",
            "Var loss:  tensor(1.0308e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8120113503744706e-06\n",
            "E_s_wdiff_all_sq: 2.5616298922386205e-07\n",
            "E_IS_SCOPE: -1.036250862856882e-05\n",
            "E_IS_E_SCOPE: -9.073560448369175e-06\n",
            "Total Loss: 1.0307506718473634e-07\n",
            "----------------------------------------\n",
            "Epoch 325\n",
            "Var loss:  tensor(1.0246e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.809645521938129e-06\n",
            "E_s_wdiff_all_sq: 2.552108537319324e-07\n",
            "E_IS_SCOPE: -1.0353187276728851e-05\n",
            "E_IS_E_SCOPE: -9.064636247226528e-06\n",
            "Total Loss: 1.0245567563496757e-07\n",
            "----------------------------------------\n",
            "Epoch 326\n",
            "Var loss:  tensor(1.0184e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8090177758928519e-06\n",
            "E_s_wdiff_all_sq: 2.547402845703968e-07\n",
            "E_IS_SCOPE: -1.0347670537270873e-05\n",
            "E_IS_E_SCOPE: -9.058892002823624e-06\n",
            "Total Loss: 1.0184348886137021e-07\n",
            "----------------------------------------\n",
            "Epoch 327\n",
            "Var loss:  tensor(1.0122e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8099851319002228e-06\n",
            "E_s_wdiff_all_sq: 2.551755251734757e-07\n",
            "E_IS_SCOPE: -1.0351712268160344e-05\n",
            "E_IS_E_SCOPE: -9.062357432849048e-06\n",
            "Total Loss: 1.0122300253757114e-07\n",
            "----------------------------------------\n",
            "Epoch 328\n",
            "Var loss:  tensor(1.0060e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8073908457370315e-06\n",
            "E_s_wdiff_all_sq: 2.532226102058629e-07\n",
            "E_IS_SCOPE: -1.0354904938504863e-05\n",
            "E_IS_E_SCOPE: -9.06556073912949e-06\n",
            "Total Loss: 1.0060290321383896e-07\n",
            "----------------------------------------\n",
            "Epoch 329\n",
            "Var loss:  tensor(9.9988e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8024382439765327e-06\n",
            "E_s_wdiff_all_sq: 2.4960834715332584e-07\n",
            "E_IS_SCOPE: -1.0347692701347623e-05\n",
            "E_IS_E_SCOPE: -9.05871036073377e-06\n",
            "Total Loss: 9.998828202891707e-08\n",
            "----------------------------------------\n",
            "Epoch 330\n",
            "Var loss:  tensor(9.9369e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8020365575015896e-06\n",
            "E_s_wdiff_all_sq: 2.4927179088168595e-07\n",
            "E_IS_SCOPE: -1.034288681475707e-05\n",
            "E_IS_E_SCOPE: -9.053627299224829e-06\n",
            "Total Loss: 9.936880198883544e-08\n",
            "----------------------------------------\n",
            "Epoch 331\n",
            "Var loss:  tensor(9.8755e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8059413079658765e-06\n",
            "E_s_wdiff_all_sq: 2.5271658810291076e-07\n",
            "E_IS_SCOPE: -1.0344971079032945e-05\n",
            "E_IS_E_SCOPE: -9.05517460541063e-06\n",
            "Total Loss: 9.875483905175465e-08\n",
            "----------------------------------------\n",
            "Epoch 332\n",
            "Var loss:  tensor(9.8129e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8087379248865416e-06\n",
            "E_s_wdiff_all_sq: 2.563609343439698e-07\n",
            "E_IS_SCOPE: -1.0348890346872117e-05\n",
            "E_IS_E_SCOPE: -9.059204992786168e-06\n",
            "Total Loss: 9.812934880408833e-08\n",
            "----------------------------------------\n",
            "Epoch 333\n",
            "Var loss:  tensor(9.7524e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8101969854755372e-06\n",
            "E_s_wdiff_all_sq: 2.5904382213906636e-07\n",
            "E_IS_SCOPE: -1.0351197089628065e-05\n",
            "E_IS_E_SCOPE: -9.061821140632929e-06\n",
            "Total Loss: 9.752433177961212e-08\n",
            "----------------------------------------\n",
            "Epoch 334\n",
            "Var loss:  tensor(9.6905e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8129369998475493e-06\n",
            "E_s_wdiff_all_sq: 2.6188957876502213e-07\n",
            "E_IS_SCOPE: -1.0349291910870698e-05\n",
            "E_IS_E_SCOPE: -9.059659296367752e-06\n",
            "Total Loss: 9.690525851005231e-08\n",
            "----------------------------------------\n",
            "Epoch 335\n",
            "Var loss:  tensor(9.6281e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8153851242992811e-06\n",
            "E_s_wdiff_all_sq: 2.6405561122287423e-07\n",
            "E_IS_SCOPE: -1.0347852240092736e-05\n",
            "E_IS_E_SCOPE: -9.057766547064224e-06\n",
            "Total Loss: 9.628119345280041e-08\n",
            "----------------------------------------\n",
            "Epoch 336\n",
            "Var loss:  tensor(9.5660e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8161308231553348e-06\n",
            "E_s_wdiff_all_sq: 2.653033467737564e-07\n",
            "E_IS_SCOPE: -1.0348077058037463e-05\n",
            "E_IS_E_SCOPE: -9.057931677670204e-06\n",
            "Total Loss: 9.565978208047432e-08\n",
            "----------------------------------------\n",
            "Epoch 337\n",
            "Var loss:  tensor(9.5047e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8168862539513685e-06\n",
            "E_s_wdiff_all_sq: 2.6672989349135306e-07\n",
            "E_IS_SCOPE: -1.0348822372452423e-05\n",
            "E_IS_E_SCOPE: -9.058706301059348e-06\n",
            "Total Loss: 9.50472841072792e-08\n",
            "----------------------------------------\n",
            "Epoch 338\n",
            "Var loss:  tensor(9.4435e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8178079689416856e-06\n",
            "E_s_wdiff_all_sq: 2.6747287871556757e-07\n",
            "E_IS_SCOPE: -1.0348756534917272e-05\n",
            "E_IS_E_SCOPE: -9.058244722546864e-06\n",
            "Total Loss: 9.443453191871724e-08\n",
            "----------------------------------------\n",
            "Epoch 339\n",
            "Var loss:  tensor(9.3814e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8159476781140604e-06\n",
            "E_s_wdiff_all_sq: 2.661700704995671e-07\n",
            "E_IS_SCOPE: -1.0340605077764634e-05\n",
            "E_IS_E_SCOPE: -9.050061535741709e-06\n",
            "Total Loss: 9.381359000205804e-08\n",
            "----------------------------------------\n",
            "Epoch 340\n",
            "Var loss:  tensor(9.3194e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8150493608844139e-06\n",
            "E_s_wdiff_all_sq: 2.6633188539830744e-07\n",
            "E_IS_SCOPE: -1.0335514466200388e-05\n",
            "E_IS_E_SCOPE: -9.04519113096402e-06\n",
            "Total Loss: 9.319387144678703e-08\n",
            "----------------------------------------\n",
            "Epoch 341\n",
            "Var loss:  tensor(9.2578e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8184523268055284e-06\n",
            "E_s_wdiff_all_sq: 2.6965573088217917e-07\n",
            "E_IS_SCOPE: -1.0339562369459293e-05\n",
            "E_IS_E_SCOPE: -9.048891651550014e-06\n",
            "Total Loss: 9.257822653820746e-08\n",
            "----------------------------------------\n",
            "Epoch 342\n",
            "Var loss:  tensor(9.1973e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8227743827776751e-06\n",
            "E_s_wdiff_all_sq: 2.7372057672716976e-07\n",
            "E_IS_SCOPE: -1.0343876525829274e-05\n",
            "E_IS_E_SCOPE: -9.052774495894961e-06\n",
            "Total Loss: 9.19728126152952e-08\n",
            "----------------------------------------\n",
            "Epoch 343\n",
            "Var loss:  tensor(9.1361e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8240343634623943e-06\n",
            "E_s_wdiff_all_sq: 2.7561818180105647e-07\n",
            "E_IS_SCOPE: -1.0342583762812455e-05\n",
            "E_IS_E_SCOPE: -9.051494664761084e-06\n",
            "Total Loss: 9.136105199201496e-08\n",
            "----------------------------------------\n",
            "Epoch 344\n",
            "Var loss:  tensor(9.0757e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8240842497709499e-06\n",
            "E_s_wdiff_all_sq: 2.765325262641265e-07\n",
            "E_IS_SCOPE: -1.0340055834849804e-05\n",
            "E_IS_E_SCOPE: -9.049097150987182e-06\n",
            "Total Loss: 9.075742221499456e-08\n",
            "----------------------------------------\n",
            "Epoch 345\n",
            "Var loss:  tensor(9.0147e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.824537297462487e-06\n",
            "E_s_wdiff_all_sq: 2.7771191304310383e-07\n",
            "E_IS_SCOPE: -1.0336628489948187e-05\n",
            "E_IS_E_SCOPE: -9.045727976229757e-06\n",
            "Total Loss: 9.014742341593825e-08\n",
            "----------------------------------------\n",
            "Epoch 346\n",
            "Var loss:  tensor(8.9546e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8292504105494805e-06\n",
            "E_s_wdiff_all_sq: 2.819569413978799e-07\n",
            "E_IS_SCOPE: -1.0336719875042142e-05\n",
            "E_IS_E_SCOPE: -9.045284423582013e-06\n",
            "Total Loss: 8.954563266475817e-08\n",
            "----------------------------------------\n",
            "Epoch 347\n",
            "Var loss:  tensor(8.8950e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8316428938779768e-06\n",
            "E_s_wdiff_all_sq: 2.845387036444346e-07\n",
            "E_IS_SCOPE: -1.0334778595459528e-05\n",
            "E_IS_E_SCOPE: -9.043139976395644e-06\n",
            "Total Loss: 8.89500185391897e-08\n",
            "----------------------------------------\n",
            "Epoch 348\n",
            "Var loss:  tensor(8.8347e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8302399655883206e-06\n",
            "E_s_wdiff_all_sq: 2.8384834913232284e-07\n",
            "E_IS_SCOPE: -1.033271864118667e-05\n",
            "E_IS_E_SCOPE: -9.041134579747029e-06\n",
            "Total Loss: 8.834656001013166e-08\n",
            "----------------------------------------\n",
            "Epoch 349\n",
            "Var loss:  tensor(8.7751e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8299523008747598e-06\n",
            "E_s_wdiff_all_sq: 2.8425101840628476e-07\n",
            "E_IS_SCOPE: -1.0333430923017393e-05\n",
            "E_IS_E_SCOPE: -9.04189412742951e-06\n",
            "Total Loss: 8.775075772612055e-08\n",
            "----------------------------------------\n",
            "Epoch 350\n",
            "Var loss:  tensor(8.7151e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8317749612539097e-06\n",
            "E_s_wdiff_all_sq: 2.860129220690963e-07\n",
            "E_IS_SCOPE: -1.033777496352962e-05\n",
            "E_IS_E_SCOPE: -9.045907695781059e-06\n",
            "Total Loss: 8.7150570121106e-08\n",
            "----------------------------------------\n",
            "Epoch 351\n",
            "Var loss:  tensor(8.6553e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8340378911640413e-06\n",
            "E_s_wdiff_all_sq: 2.881645550946215e-07\n",
            "E_IS_SCOPE: -1.0342370425020625e-05\n",
            "E_IS_E_SCOPE: -9.050148605802377e-06\n",
            "Total Loss: 8.655276406633746e-08\n",
            "----------------------------------------\n",
            "Epoch 352\n",
            "Var loss:  tensor(8.5947e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.833374224959294e-06\n",
            "E_s_wdiff_all_sq: 2.885023528716069e-07\n",
            "E_IS_SCOPE: -1.034095832096228e-05\n",
            "E_IS_E_SCOPE: -9.048934364541016e-06\n",
            "Total Loss: 8.594702567857271e-08\n",
            "----------------------------------------\n",
            "Epoch 353\n",
            "Var loss:  tensor(8.5363e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8345458505696458e-06\n",
            "E_s_wdiff_all_sq: 2.905258782244738e-07\n",
            "E_IS_SCOPE: -1.034068835371835e-05\n",
            "E_IS_E_SCOPE: -9.048798522546331e-06\n",
            "Total Loss: 8.536337643454943e-08\n",
            "----------------------------------------\n",
            "Epoch 354\n",
            "Var loss:  tensor(8.4763e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8382635928979762e-06\n",
            "E_s_wdiff_all_sq: 2.9377076046009085e-07\n",
            "E_IS_SCOPE: -1.0345106652618594e-05\n",
            "E_IS_E_SCOPE: -9.05268013420536e-06\n",
            "Total Loss: 8.476286204483232e-08\n",
            "----------------------------------------\n",
            "Epoch 355\n",
            "Var loss:  tensor(8.4165e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8410891513533072e-06\n",
            "E_s_wdiff_all_sq: 2.96541423453398e-07\n",
            "E_IS_SCOPE: -1.0348866636237782e-05\n",
            "E_IS_E_SCOPE: -9.05611393707684e-06\n",
            "Total Loss: 8.416539601144338e-08\n",
            "----------------------------------------\n",
            "Epoch 356\n",
            "Var loss:  tensor(8.3571e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.839962371354311e-06\n",
            "E_s_wdiff_all_sq: 2.9660907993746774e-07\n",
            "E_IS_SCOPE: -1.0343066525123418e-05\n",
            "E_IS_E_SCOPE: -9.050613678561328e-06\n",
            "Total Loss: 8.357066472607879e-08\n",
            "----------------------------------------\n",
            "Epoch 357\n",
            "Var loss:  tensor(8.2979e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8401116317700725e-06\n",
            "E_s_wdiff_all_sq: 2.9733365488619694e-07\n",
            "E_IS_SCOPE: -1.0334660170572307e-05\n",
            "E_IS_E_SCOPE: -9.042199070996025e-06\n",
            "Total Loss: 8.297884416472764e-08\n",
            "----------------------------------------\n",
            "Epoch 358\n",
            "Var loss:  tensor(8.2392e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8448962370485599e-06\n",
            "E_s_wdiff_all_sq: 3.0158148573267923e-07\n",
            "E_IS_SCOPE: -1.033480636250772e-05\n",
            "E_IS_E_SCOPE: -9.041783488554047e-06\n",
            "Total Loss: 8.239206984195125e-08\n",
            "----------------------------------------\n",
            "Epoch 359\n",
            "Var loss:  tensor(8.1802e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.848633549892066e-06\n",
            "E_s_wdiff_all_sq: 3.056729590876866e-07\n",
            "E_IS_SCOPE: -1.0335611585361874e-05\n",
            "E_IS_E_SCOPE: -9.042470579321423e-06\n",
            "Total Loss: 8.180164515689151e-08\n",
            "----------------------------------------\n",
            "Epoch 360\n",
            "Var loss:  tensor(8.1206e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8486309924552107e-06\n",
            "E_s_wdiff_all_sq: 3.066268593174746e-07\n",
            "E_IS_SCOPE: -1.0333586690667498e-05\n",
            "E_IS_E_SCOPE: -9.040626156865051e-06\n",
            "Total Loss: 8.120613196625841e-08\n",
            "----------------------------------------\n",
            "Epoch 361\n",
            "Var loss:  tensor(8.0613e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8491148360019207e-06\n",
            "E_s_wdiff_all_sq: 3.072831325904955e-07\n",
            "E_IS_SCOPE: -1.0334127471472567e-05\n",
            "E_IS_E_SCOPE: -9.040956723359244e-06\n",
            "Total Loss: 8.061327361819397e-08\n",
            "----------------------------------------\n",
            "Epoch 362\n",
            "Var loss:  tensor(8.0025e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8494941103721963e-06\n",
            "E_s_wdiff_all_sq: 3.0780308985469343e-07\n",
            "E_IS_SCOPE: -1.0335757340960319e-05\n",
            "E_IS_E_SCOPE: -9.042362846083374e-06\n",
            "Total Loss: 8.002509719702872e-08\n",
            "----------------------------------------\n",
            "Epoch 363\n",
            "Var loss:  tensor(7.9428e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8495146721495728e-06\n",
            "E_s_wdiff_all_sq: 3.0846935347571106e-07\n",
            "E_IS_SCOPE: -1.0335895365578172e-05\n",
            "E_IS_E_SCOPE: -9.042525076801941e-06\n",
            "Total Loss: 7.942780755481887e-08\n",
            "----------------------------------------\n",
            "Epoch 364\n",
            "Var loss:  tensor(7.8835e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8496907828852022e-06\n",
            "E_s_wdiff_all_sq: 3.088716849800798e-07\n",
            "E_IS_SCOPE: -1.0335584283279913e-05\n",
            "E_IS_E_SCOPE: -9.04203072540654e-06\n",
            "Total Loss: 7.883504859179393e-08\n",
            "----------------------------------------\n",
            "Epoch 365\n",
            "Var loss:  tensor(7.8245e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8497122878233997e-06\n",
            "E_s_wdiff_all_sq: 3.0880752106345143e-07\n",
            "E_IS_SCOPE: -1.0333061473182443e-05\n",
            "E_IS_E_SCOPE: -9.03917022733646e-06\n",
            "Total Loss: 7.824534150139712e-08\n",
            "----------------------------------------\n",
            "Epoch 366\n",
            "Var loss:  tensor(7.7657e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8488429888800533e-06\n",
            "E_s_wdiff_all_sq: 3.0865484641433305e-07\n",
            "E_IS_SCOPE: -1.0324552984730756e-05\n",
            "E_IS_E_SCOPE: -9.030726109337433e-06\n",
            "Total Loss: 7.765745811248985e-08\n",
            "----------------------------------------\n",
            "Epoch 367\n",
            "Var loss:  tensor(7.7074e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8492435755341458e-06\n",
            "E_s_wdiff_all_sq: 3.094937148022092e-07\n",
            "E_IS_SCOPE: -1.0317479644424225e-05\n",
            "E_IS_E_SCOPE: -9.023580106171744e-06\n",
            "Total Loss: 7.70738506603917e-08\n",
            "----------------------------------------\n",
            "Epoch 368\n",
            "Var loss:  tensor(7.6491e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.854053715743091e-06\n",
            "E_s_wdiff_all_sq: 3.13887580722104e-07\n",
            "E_IS_SCOPE: -1.0318309661867713e-05\n",
            "E_IS_E_SCOPE: -9.023910456706952e-06\n",
            "Total Loss: 7.649079113288018e-08\n",
            "----------------------------------------\n",
            "Epoch 369\n",
            "Var loss:  tensor(7.5908e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8580182006351142e-06\n",
            "E_s_wdiff_all_sq: 3.1813788184245966e-07\n",
            "E_IS_SCOPE: -1.0319279635006984e-05\n",
            "E_IS_E_SCOPE: -9.024731949275916e-06\n",
            "Total Loss: 7.590801376393387e-08\n",
            "----------------------------------------\n",
            "Epoch 370\n",
            "Var loss:  tensor(7.5324e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8590351111638258e-06\n",
            "E_s_wdiff_all_sq: 3.201984763624952e-07\n",
            "E_IS_SCOPE: -1.0318070682949e-05\n",
            "E_IS_E_SCOPE: -9.023752928199771e-06\n",
            "Total Loss: 7.532419173629035e-08\n",
            "----------------------------------------\n",
            "Epoch 371\n",
            "Var loss:  tensor(7.4740e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8599573183867416e-06\n",
            "E_s_wdiff_all_sq: 3.2143856144486204e-07\n",
            "E_IS_SCOPE: -1.032172722953697e-05\n",
            "E_IS_E_SCOPE: -9.027276323559471e-06\n",
            "Total Loss: 7.474001142029603e-08\n",
            "----------------------------------------\n",
            "Epoch 372\n",
            "Var loss:  tensor(7.4155e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8599834629728588e-06\n",
            "E_s_wdiff_all_sq: 3.2176288193937834e-07\n",
            "E_IS_SCOPE: -1.0326212261310873e-05\n",
            "E_IS_E_SCOPE: -9.031618139537151e-06\n",
            "Total Loss: 7.415540391945212e-08\n",
            "----------------------------------------\n",
            "Epoch 373\n",
            "Var loss:  tensor(7.3566e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8616804326720498e-06\n",
            "E_s_wdiff_all_sq: 3.236606325783838e-07\n",
            "E_IS_SCOPE: -1.0331318756779252e-05\n",
            "E_IS_E_SCOPE: -9.036530383617665e-06\n",
            "Total Loss: 7.356612020390772e-08\n",
            "----------------------------------------\n",
            "Epoch 374\n",
            "Var loss:  tensor(7.2992e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.862586076969805e-06\n",
            "E_s_wdiff_all_sq: 3.2486816383940227e-07\n",
            "E_IS_SCOPE: -1.0332144661005726e-05\n",
            "E_IS_E_SCOPE: -9.037220019742587e-06\n",
            "Total Loss: 7.29916970375391e-08\n",
            "----------------------------------------\n",
            "Epoch 375\n",
            "Var loss:  tensor(7.2415e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.861561522809238e-06\n",
            "E_s_wdiff_all_sq: 3.2458534001938727e-07\n",
            "E_IS_SCOPE: -1.0328223483705207e-05\n",
            "E_IS_E_SCOPE: -9.033381580126701e-06\n",
            "Total Loss: 7.24154420662548e-08\n",
            "----------------------------------------\n",
            "Epoch 376\n",
            "Var loss:  tensor(7.1830e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8634452647169618e-06\n",
            "E_s_wdiff_all_sq: 3.2650501955743144e-07\n",
            "E_IS_SCOPE: -1.0323907472611562e-05\n",
            "E_IS_E_SCOPE: -9.028790606698202e-06\n",
            "Total Loss: 7.182957976622821e-08\n",
            "----------------------------------------\n",
            "Epoch 377\n",
            "Var loss:  tensor(7.1262e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8676502331548532e-06\n",
            "E_s_wdiff_all_sq: 3.303831036841755e-07\n",
            "E_IS_SCOPE: -1.0321619274773419e-05\n",
            "E_IS_E_SCOPE: -9.026054948291937e-06\n",
            "Total Loss: 7.126154294112883e-08\n",
            "----------------------------------------\n",
            "Epoch 378\n",
            "Var loss:  tensor(7.0677e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8681204770205192e-06\n",
            "E_s_wdiff_all_sq: 3.3139491307600796e-07\n",
            "E_IS_SCOPE: -1.0316836122740247e-05\n",
            "E_IS_E_SCOPE: -9.021250347513743e-06\n",
            "Total Loss: 7.067707992491899e-08\n",
            "----------------------------------------\n",
            "Epoch 379\n",
            "Var loss:  tensor(7.0102e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8669983469061603e-06\n",
            "E_s_wdiff_all_sq: 3.307291853931478e-07\n",
            "E_IS_SCOPE: -1.031377437964768e-05\n",
            "E_IS_E_SCOPE: -9.018129460907222e-06\n",
            "Total Loss: 7.0102390465511e-08\n",
            "----------------------------------------\n",
            "Epoch 380\n",
            "Var loss:  tensor(6.9521e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8676519147512837e-06\n",
            "E_s_wdiff_all_sq: 3.316985786358116e-07\n",
            "E_IS_SCOPE: -1.0315321764380118e-05\n",
            "E_IS_E_SCOPE: -9.019544189385059e-06\n",
            "Total Loss: 6.952125255876894e-08\n",
            "----------------------------------------\n",
            "Epoch 381\n",
            "Var loss:  tensor(6.8938e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.870940628827859e-06\n",
            "E_s_wdiff_all_sq: 3.3529385816867433e-07\n",
            "E_IS_SCOPE: -1.0318959180402473e-05\n",
            "E_IS_E_SCOPE: -9.023043027015365e-06\n",
            "Total Loss: 6.893753031838255e-08\n",
            "----------------------------------------\n",
            "Epoch 382\n",
            "Var loss:  tensor(6.8360e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.874489070021739e-06\n",
            "E_s_wdiff_all_sq: 3.392391729777743e-07\n",
            "E_IS_SCOPE: -1.032022593879432e-05\n",
            "E_IS_E_SCOPE: -9.024219372773333e-06\n",
            "Total Loss: 6.835983143540615e-08\n",
            "----------------------------------------\n",
            "Epoch 383\n",
            "Var loss:  tensor(6.7776e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8795333290878558e-06\n",
            "E_s_wdiff_all_sq: 3.4417118551940225e-07\n",
            "E_IS_SCOPE: -1.032156993597268e-05\n",
            "E_IS_E_SCOPE: -9.02521539240835e-06\n",
            "Total Loss: 6.777612287321225e-08\n",
            "----------------------------------------\n",
            "Epoch 384\n",
            "Var loss:  tensor(6.7201e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8825330268905687e-06\n",
            "E_s_wdiff_all_sq: 3.475911849865068e-07\n",
            "E_IS_SCOPE: -1.0319648464937042e-05\n",
            "E_IS_E_SCOPE: -9.023216723525299e-06\n",
            "Total Loss: 6.72014255139905e-08\n",
            "----------------------------------------\n",
            "Epoch 385\n",
            "Var loss:  tensor(6.6629e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8821120359793671e-06\n",
            "E_s_wdiff_all_sq: 3.481520009204671e-07\n",
            "E_IS_SCOPE: -1.0314261774066302e-05\n",
            "E_IS_E_SCOPE: -9.018034483617153e-06\n",
            "Total Loss: 6.66285205940154e-08\n",
            "----------------------------------------\n",
            "Epoch 386\n",
            "Var loss:  tensor(6.6051e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8823419332205307e-06\n",
            "E_s_wdiff_all_sq: 3.487557818776904e-07\n",
            "E_IS_SCOPE: -1.030952085576445e-05\n",
            "E_IS_E_SCOPE: -9.01319178759603e-06\n",
            "Total Loss: 6.605108143941231e-08\n",
            "----------------------------------------\n",
            "Epoch 387\n",
            "Var loss:  tensor(6.5471e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.885504268802815e-06\n",
            "E_s_wdiff_all_sq: 3.512676843518606e-07\n",
            "E_IS_SCOPE: -1.0311361925394809e-05\n",
            "E_IS_E_SCOPE: -9.014417560974977e-06\n",
            "Total Loss: 6.547092204470775e-08\n",
            "----------------------------------------\n",
            "Epoch 388\n",
            "Var loss:  tensor(6.4906e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.887933591448443e-06\n",
            "E_s_wdiff_all_sq: 3.53466754280809e-07\n",
            "E_IS_SCOPE: -1.0315666362387826e-05\n",
            "E_IS_E_SCOPE: -9.01832423622435e-06\n",
            "Total Loss: 6.490565127409993e-08\n",
            "----------------------------------------\n",
            "Epoch 389\n",
            "Var loss:  tensor(6.4317e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8850755718474016e-06\n",
            "E_s_wdiff_all_sq: 3.516648239895659e-07\n",
            "E_IS_SCOPE: -1.0313485464848984e-05\n",
            "E_IS_E_SCOPE: -9.016377079633204e-06\n",
            "Total Loss: 6.43170438596891e-08\n",
            "----------------------------------------\n",
            "Epoch 390\n",
            "Var loss:  tensor(6.3726e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8809827221564462e-06\n",
            "E_s_wdiff_all_sq: 3.483556380783978e-07\n",
            "E_IS_SCOPE: -1.0309813220813691e-05\n",
            "E_IS_E_SCOPE: -9.012800972668712e-06\n",
            "Total Loss: 6.372565422150538e-08\n",
            "----------------------------------------\n",
            "Epoch 391\n",
            "Var loss:  tensor(6.3141e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.880338003323336e-06\n",
            "E_s_wdiff_all_sq: 3.4750566505935696e-07\n",
            "E_IS_SCOPE: -1.0312759210735495e-05\n",
            "E_IS_E_SCOPE: -9.015352134769041e-06\n",
            "Total Loss: 6.314125276448568e-08\n",
            "----------------------------------------\n",
            "Epoch 392\n",
            "Var loss:  tensor(6.2529e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8819795373454795e-06\n",
            "E_s_wdiff_all_sq: 3.494679144676805e-07\n",
            "E_IS_SCOPE: -1.0318060142803307e-05\n",
            "E_IS_E_SCOPE: -9.020507060561814e-06\n",
            "Total Loss: 6.252852482822872e-08\n",
            "----------------------------------------\n",
            "Epoch 393\n",
            "Var loss:  tensor(6.1938e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8849082075612048e-06\n",
            "E_s_wdiff_all_sq: 3.5322293056670525e-07\n",
            "E_IS_SCOPE: -1.032171481721677e-05\n",
            "E_IS_E_SCOPE: -9.024279739247746e-06\n",
            "Total Loss: 6.193818748986602e-08\n",
            "----------------------------------------\n",
            "Epoch 394\n",
            "Var loss:  tensor(6.1343e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8905244518062983e-06\n",
            "E_s_wdiff_all_sq: 3.5850958950463845e-07\n",
            "E_IS_SCOPE: -1.0320892157275671e-05\n",
            "E_IS_E_SCOPE: -9.022994571556825e-06\n",
            "Total Loss: 6.134275729738373e-08\n",
            "----------------------------------------\n",
            "Epoch 395\n",
            "Var loss:  tensor(6.0731e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8945049780451192e-06\n",
            "E_s_wdiff_all_sq: 3.6242396586569633e-07\n",
            "E_IS_SCOPE: -1.0315906718008786e-05\n",
            "E_IS_E_SCOPE: -9.017669979755636e-06\n",
            "Total Loss: 6.07306021065379e-08\n",
            "----------------------------------------\n",
            "Epoch 396\n",
            "Var loss:  tensor(6.0128e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8933896283100598e-06\n",
            "E_s_wdiff_all_sq: 3.622817607253569e-07\n",
            "E_IS_SCOPE: -1.0308766163670232e-05\n",
            "E_IS_E_SCOPE: -9.010714791335528e-06\n",
            "Total Loss: 6.012818934871049e-08\n",
            "----------------------------------------\n",
            "Epoch 397\n",
            "Var loss:  tensor(5.9533e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8921185792208823e-06\n",
            "E_s_wdiff_all_sq: 3.619872245046737e-07\n",
            "E_IS_SCOPE: -1.0303741004338369e-05\n",
            "E_IS_E_SCOPE: -9.005880202986834e-06\n",
            "Total Loss: 5.953281844655509e-08\n",
            "----------------------------------------\n",
            "Epoch 398\n",
            "Var loss:  tensor(5.8929e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8946915887260108e-06\n",
            "E_s_wdiff_all_sq: 3.641635357853031e-07\n",
            "E_IS_SCOPE: -1.0305975408668714e-05\n",
            "E_IS_E_SCOPE: -9.007614569889478e-06\n",
            "Total Loss: 5.892944181565286e-08\n",
            "----------------------------------------\n",
            "Epoch 399\n",
            "Var loss:  tensor(5.8325e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8963814821725818e-06\n",
            "E_s_wdiff_all_sq: 3.656874957201422e-07\n",
            "E_IS_SCOPE: -1.0308182679635689e-05\n",
            "E_IS_E_SCOPE: -9.009436690409244e-06\n",
            "Total Loss: 5.832507443296512e-08\n",
            "----------------------------------------\n",
            "Epoch 400\n",
            "Var loss:  tensor(5.7720e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8962954565972808e-06\n",
            "E_s_wdiff_all_sq: 3.6654028664441846e-07\n",
            "E_IS_SCOPE: -1.0308799451297773e-05\n",
            "E_IS_E_SCOPE: -9.01022041947686e-06\n",
            "Total Loss: 5.772017274445536e-08\n",
            "----------------------------------------\n",
            "Epoch 401\n",
            "Var loss:  tensor(5.7117e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8992425019596346e-06\n",
            "E_s_wdiff_all_sq: 3.698782339621514e-07\n",
            "E_IS_SCOPE: -1.0310907302631664e-05\n",
            "E_IS_E_SCOPE: -9.012222295707965e-06\n",
            "Total Loss: 5.711732058350304e-08\n",
            "----------------------------------------\n",
            "Epoch 402\n",
            "Var loss:  tensor(5.6511e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.903375168422438e-06\n",
            "E_s_wdiff_all_sq: 3.7431849631479723e-07\n",
            "E_IS_SCOPE: -1.0311693879535486e-05\n",
            "E_IS_E_SCOPE: -9.012859653331763e-06\n",
            "Total Loss: 5.6511286133611004e-08\n",
            "----------------------------------------\n",
            "Epoch 403\n",
            "Var loss:  tensor(5.5912e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9068964534486692e-06\n",
            "E_s_wdiff_all_sq: 3.7841254345400153e-07\n",
            "E_IS_SCOPE: -1.0310228319411227e-05\n",
            "E_IS_E_SCOPE: -9.01138063858352e-06\n",
            "Total Loss: 5.591161477266701e-08\n",
            "----------------------------------------\n",
            "Epoch 404\n",
            "Var loss:  tensor(5.5315e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9090275103618617e-06\n",
            "E_s_wdiff_all_sq: 3.810555537619144e-07\n",
            "E_IS_SCOPE: -1.0308605153245816e-05\n",
            "E_IS_E_SCOPE: -9.00971519963542e-06\n",
            "Total Loss: 5.531511581257126e-08\n",
            "----------------------------------------\n",
            "Epoch 405\n",
            "Var loss:  tensor(5.4695e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9097894419856842e-06\n",
            "E_s_wdiff_all_sq: 3.818784353735083e-07\n",
            "E_IS_SCOPE: -1.0308717363608888e-05\n",
            "E_IS_E_SCOPE: -9.009547759632338e-06\n",
            "Total Loss: 5.469486509249143e-08\n",
            "----------------------------------------\n",
            "Epoch 406\n",
            "Var loss:  tensor(5.4094e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9095886597959903e-06\n",
            "E_s_wdiff_all_sq: 3.8175170597980735e-07\n",
            "E_IS_SCOPE: -1.0306582002584975e-05\n",
            "E_IS_E_SCOPE: -9.007148817107538e-06\n",
            "Total Loss: 5.4093649294724934e-08\n",
            "----------------------------------------\n",
            "Epoch 407\n",
            "Var loss:  tensor(5.3500e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9106805315814025e-06\n",
            "E_s_wdiff_all_sq: 3.8295038058861307e-07\n",
            "E_IS_SCOPE: -1.0306421080388691e-05\n",
            "E_IS_E_SCOPE: -9.00674427756139e-06\n",
            "Total Loss: 5.349961177160531e-08\n",
            "----------------------------------------\n",
            "Epoch 408\n",
            "Var loss:  tensor(5.2899e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9124749859369774e-06\n",
            "E_s_wdiff_all_sq: 3.8538953250880145e-07\n",
            "E_IS_SCOPE: -1.0305837511398478e-05\n",
            "E_IS_E_SCOPE: -9.006182886934876e-06\n",
            "Total Loss: 5.2899270934386346e-08\n",
            "----------------------------------------\n",
            "Epoch 409\n",
            "Var loss:  tensor(5.2288e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.916742737206139e-06\n",
            "E_s_wdiff_all_sq: 3.899225905310482e-07\n",
            "E_IS_SCOPE: -1.0308637794441105e-05\n",
            "E_IS_E_SCOPE: -9.008810123198848e-06\n",
            "Total Loss: 5.228787062399303e-08\n",
            "----------------------------------------\n",
            "Epoch 410\n",
            "Var loss:  tensor(5.1689e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.921960955053436e-06\n",
            "E_s_wdiff_all_sq: 3.953565836214308e-07\n",
            "E_IS_SCOPE: -1.0312402731527401e-05\n",
            "E_IS_E_SCOPE: -9.01238374838736e-06\n",
            "Total Loss: 5.168947158534095e-08\n",
            "----------------------------------------\n",
            "Epoch 411\n",
            "Var loss:  tensor(5.1088e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9263836476506966e-06\n",
            "E_s_wdiff_all_sq: 4.001696409414085e-07\n",
            "E_IS_SCOPE: -1.0315468640460884e-05\n",
            "E_IS_E_SCOPE: -9.015343983908966e-06\n",
            "Total Loss: 5.108776003886853e-08\n",
            "----------------------------------------\n",
            "Epoch 412\n",
            "Var loss:  tensor(5.0496e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.928243872312046e-06\n",
            "E_s_wdiff_all_sq: 4.026839433969053e-07\n",
            "E_IS_SCOPE: -1.0315367066493988e-05\n",
            "E_IS_E_SCOPE: -9.015273516281268e-06\n",
            "Total Loss: 5.0495894923119075e-08\n",
            "----------------------------------------\n",
            "Epoch 413\n",
            "Var loss:  tensor(4.9893e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.928279119808373e-06\n",
            "E_s_wdiff_all_sq: 4.0316330998112404e-07\n",
            "E_IS_SCOPE: -1.031276202353378e-05\n",
            "E_IS_E_SCOPE: -9.012589329517008e-06\n",
            "Total Loss: 4.9893488227120005e-08\n",
            "----------------------------------------\n",
            "Epoch 414\n",
            "Var loss:  tensor(4.9287e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9286787303341227e-06\n",
            "E_s_wdiff_all_sq: 4.035944525186352e-07\n",
            "E_IS_SCOPE: -1.0312871556318868e-05\n",
            "E_IS_E_SCOPE: -9.012411584664777e-06\n",
            "Total Loss: 4.928740094072229e-08\n",
            "----------------------------------------\n",
            "Epoch 415\n",
            "Var loss:  tensor(4.8683e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9277680282338125e-06\n",
            "E_s_wdiff_all_sq: 4.029852566040519e-07\n",
            "E_IS_SCOPE: -1.0311963799916697e-05\n",
            "E_IS_E_SCOPE: -9.01135224469221e-06\n",
            "Total Loss: 4.868272761420326e-08\n",
            "----------------------------------------\n",
            "Epoch 416\n",
            "Var loss:  tensor(4.8088e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.925455778907526e-06\n",
            "E_s_wdiff_all_sq: 4.011546046490546e-07\n",
            "E_IS_SCOPE: -1.030914507920772e-05\n",
            "E_IS_E_SCOPE: -9.008477149483244e-06\n",
            "Total Loss: 4.808838124293403e-08\n",
            "----------------------------------------\n",
            "Epoch 417\n",
            "Var loss:  tensor(4.7484e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9259531111147583e-06\n",
            "E_s_wdiff_all_sq: 4.0177157110714343e-07\n",
            "E_IS_SCOPE: -1.0302810841748247e-05\n",
            "E_IS_E_SCOPE: -9.001900469608946e-06\n",
            "Total Loss: 4.748386216242956e-08\n",
            "----------------------------------------\n",
            "Epoch 418\n",
            "Var loss:  tensor(4.6893e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.930656330309447e-06\n",
            "E_s_wdiff_all_sq: 4.0642532623652443e-07\n",
            "E_IS_SCOPE: -1.0296972168748347e-05\n",
            "E_IS_E_SCOPE: -8.995741575516742e-06\n",
            "Total Loss: 4.6892884043128745e-08\n",
            "----------------------------------------\n",
            "Epoch 419\n",
            "Var loss:  tensor(4.6310e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9371871025886784e-06\n",
            "E_s_wdiff_all_sq: 4.133183968838577e-07\n",
            "E_IS_SCOPE: -1.0294429272677638e-05\n",
            "E_IS_E_SCOPE: -8.993088372611993e-06\n",
            "Total Loss: 4.6309972006947576e-08\n",
            "----------------------------------------\n",
            "Epoch 420\n",
            "Var loss:  tensor(4.5700e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9423607590056343e-06\n",
            "E_s_wdiff_all_sq: 4.1892784958815415e-07\n",
            "E_IS_SCOPE: -1.0290417381247346e-05\n",
            "E_IS_E_SCOPE: -8.988989385913393e-06\n",
            "Total Loss: 4.569998518298775e-08\n",
            "----------------------------------------\n",
            "Epoch 421\n",
            "Var loss:  tensor(4.5103e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9452350853392965e-06\n",
            "E_s_wdiff_all_sq: 4.22396313785321e-07\n",
            "E_IS_SCOPE: -1.0285999651299317e-05\n",
            "E_IS_E_SCOPE: -8.984570377647036e-06\n",
            "Total Loss: 4.510329068283076e-08\n",
            "----------------------------------------\n",
            "Epoch 422\n",
            "Var loss:  tensor(4.4529e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9471939934897836e-06\n",
            "E_s_wdiff_all_sq: 4.247724661096949e-07\n",
            "E_IS_SCOPE: -1.0289086262470626e-05\n",
            "E_IS_E_SCOPE: -8.987578519233446e-06\n",
            "Total Loss: 4.452910733914403e-08\n",
            "----------------------------------------\n",
            "Epoch 423\n",
            "Var loss:  tensor(4.3930e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.947574658466445e-06\n",
            "E_s_wdiff_all_sq: 4.2558459641404884e-07\n",
            "E_IS_SCOPE: -1.0294991997778182e-05\n",
            "E_IS_E_SCOPE: -8.99340032609152e-06\n",
            "Total Loss: 4.392978511248535e-08\n",
            "----------------------------------------\n",
            "Epoch 424\n",
            "Var loss:  tensor(4.3359e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9479600237661343e-06\n",
            "E_s_wdiff_all_sq: 4.2597404088463045e-07\n",
            "E_IS_SCOPE: -1.0300030910587423e-05\n",
            "E_IS_E_SCOPE: -8.998156013432985e-06\n",
            "Total Loss: 4.335925500604425e-08\n",
            "----------------------------------------\n",
            "Epoch 425\n",
            "Var loss:  tensor(4.2790e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.947921239678948e-06\n",
            "E_s_wdiff_all_sq: 4.254612447949879e-07\n",
            "E_IS_SCOPE: -1.0302317154034801e-05\n",
            "E_IS_E_SCOPE: -8.999920495019092e-06\n",
            "Total Loss: 4.2789743285956995e-08\n",
            "----------------------------------------\n",
            "Epoch 426\n",
            "Var loss:  tensor(4.2206e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.94530247543964e-06\n",
            "E_s_wdiff_all_sq: 4.229146323097299e-07\n",
            "E_IS_SCOPE: -1.030173416437278e-05\n",
            "E_IS_E_SCOPE: -8.999081864077862e-06\n",
            "Total Loss: 4.220630897348957e-08\n",
            "----------------------------------------\n",
            "Epoch 427\n",
            "Var loss:  tensor(4.1624e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9401216619518816e-06\n",
            "E_s_wdiff_all_sq: 4.1866445602970125e-07\n",
            "E_IS_SCOPE: -1.0297414168841731e-05\n",
            "E_IS_E_SCOPE: -8.994936224371753e-06\n",
            "Total Loss: 4.162438341564022e-08\n",
            "----------------------------------------\n",
            "Epoch 428\n",
            "Var loss:  tensor(4.1048e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9388431987567555e-06\n",
            "E_s_wdiff_all_sq: 4.175990908218464e-07\n",
            "E_IS_SCOPE: -1.0295132022411679e-05\n",
            "E_IS_E_SCOPE: -8.992472580103146e-06\n",
            "Total Loss: 4.104828975125745e-08\n",
            "----------------------------------------\n",
            "Epoch 429\n",
            "Var loss:  tensor(4.0468e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.941982110452639e-06\n",
            "E_s_wdiff_all_sq: 4.2051051540512925e-07\n",
            "E_IS_SCOPE: -1.029263201829579e-05\n",
            "E_IS_E_SCOPE: -8.98956871717617e-06\n",
            "Total Loss: 4.0468059241684484e-08\n",
            "----------------------------------------\n",
            "Epoch 430\n",
            "Var loss:  tensor(3.9898e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9471119902807254e-06\n",
            "E_s_wdiff_all_sq: 4.2625371780903963e-07\n",
            "E_IS_SCOPE: -1.0288374890701507e-05\n",
            "E_IS_E_SCOPE: -8.985333177324015e-06\n",
            "Total Loss: 3.989791215011724e-08\n",
            "----------------------------------------\n",
            "Epoch 431\n",
            "Var loss:  tensor(3.9337e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.954560415571042e-06\n",
            "E_s_wdiff_all_sq: 4.339844567023788e-07\n",
            "E_IS_SCOPE: -1.0287451916620904e-05\n",
            "E_IS_E_SCOPE: -8.984270753892916e-06\n",
            "Total Loss: 3.9336699846103246e-08\n",
            "----------------------------------------\n",
            "Epoch 432\n",
            "Var loss:  tensor(3.8773e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9622411521689833e-06\n",
            "E_s_wdiff_all_sq: 4.4200240313091826e-07\n",
            "E_IS_SCOPE: -1.0285787726604281e-05\n",
            "E_IS_E_SCOPE: -8.982493069529045e-06\n",
            "Total Loss: 3.877250132100615e-08\n",
            "----------------------------------------\n",
            "Epoch 433\n",
            "Var loss:  tensor(3.8202e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9685726572620084e-06\n",
            "E_s_wdiff_all_sq: 4.490687293141164e-07\n",
            "E_IS_SCOPE: -1.028333315974993e-05\n",
            "E_IS_E_SCOPE: -8.980120613142e-06\n",
            "Total Loss: 3.820190116544822e-08\n",
            "----------------------------------------\n",
            "Epoch 434\n",
            "Var loss:  tensor(3.7642e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9726499148576263e-06\n",
            "E_s_wdiff_all_sq: 4.539485898120544e-07\n",
            "E_IS_SCOPE: -1.0282220308088313e-05\n",
            "E_IS_E_SCOPE: -8.979129358468066e-06\n",
            "Total Loss: 3.76424922384916e-08\n",
            "----------------------------------------\n",
            "Epoch 435\n",
            "Var loss:  tensor(3.7086e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.975743583839813e-06\n",
            "E_s_wdiff_all_sq: 4.5713783269794133e-07\n",
            "E_IS_SCOPE: -1.0285969785079868e-05\n",
            "E_IS_E_SCOPE: -8.98264828801081e-06\n",
            "Total Loss: 3.7085823437170286e-08\n",
            "----------------------------------------\n",
            "Epoch 436\n",
            "Var loss:  tensor(3.6525e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9757471303206706e-06\n",
            "E_s_wdiff_all_sq: 4.5706293198430473e-07\n",
            "E_IS_SCOPE: -1.029230595366593e-05\n",
            "E_IS_E_SCOPE: -8.988664774185958e-06\n",
            "Total Loss: 3.652490580983657e-08\n",
            "----------------------------------------\n",
            "Epoch 437\n",
            "Var loss:  tensor(3.5968e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9716167161454974e-06\n",
            "E_s_wdiff_all_sq: 4.533516761518446e-07\n",
            "E_IS_SCOPE: -1.0297272931334995e-05\n",
            "E_IS_E_SCOPE: -8.993562889114314e-06\n",
            "Total Loss: 3.596802198570827e-08\n",
            "----------------------------------------\n",
            "Epoch 438\n",
            "Var loss:  tensor(3.5410e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9667405396391795e-06\n",
            "E_s_wdiff_all_sq: 4.490371122098463e-07\n",
            "E_IS_SCOPE: -1.029872891911679e-05\n",
            "E_IS_E_SCOPE: -8.9950207235799e-06\n",
            "Total Loss: 3.541010278896939e-08\n",
            "----------------------------------------\n",
            "Epoch 439\n",
            "Var loss:  tensor(3.4848e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9658863268248642e-06\n",
            "E_s_wdiff_all_sq: 4.4828732170732727e-07\n",
            "E_IS_SCOPE: -1.0300728832402589e-05\n",
            "E_IS_E_SCOPE: -8.996791687024787e-06\n",
            "Total Loss: 3.484778079534966e-08\n",
            "----------------------------------------\n",
            "Epoch 440\n",
            "Var loss:  tensor(3.4293e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9685372005665407e-06\n",
            "E_s_wdiff_all_sq: 4.506852260804692e-07\n",
            "E_IS_SCOPE: -1.030413098421614e-05\n",
            "E_IS_E_SCOPE: -8.999789796555668e-06\n",
            "Total Loss: 3.429266559854117e-08\n",
            "----------------------------------------\n",
            "Epoch 441\n",
            "Var loss:  tensor(3.3741e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.967275125692619e-06\n",
            "E_s_wdiff_all_sq: 4.504043240216321e-07\n",
            "E_IS_SCOPE: -1.0299167883881777e-05\n",
            "E_IS_E_SCOPE: -8.995041237554212e-06\n",
            "Total Loss: 3.3740575449273e-08\n",
            "----------------------------------------\n",
            "Epoch 442\n",
            "Var loss:  tensor(3.3191e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9673300299335046e-06\n",
            "E_s_wdiff_all_sq: 4.50968007791106e-07\n",
            "E_IS_SCOPE: -1.0296486394932122e-05\n",
            "E_IS_E_SCOPE: -8.992339345408752e-06\n",
            "Total Loss: 3.3190989529073914e-08\n",
            "----------------------------------------\n",
            "Epoch 443\n",
            "Var loss:  tensor(3.2646e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.971708487182637e-06\n",
            "E_s_wdiff_all_sq: 4.5504771166667184e-07\n",
            "E_IS_SCOPE: -1.0299287893714963e-05\n",
            "E_IS_E_SCOPE: -8.994718758509122e-06\n",
            "Total Loss: 3.264557153769931e-08\n",
            "----------------------------------------\n",
            "Epoch 444\n",
            "Var loss:  tensor(3.2085e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.975958718338566e-06\n",
            "E_s_wdiff_all_sq: 4.592709909401639e-07\n",
            "E_IS_SCOPE: -1.0303370209107688e-05\n",
            "E_IS_E_SCOPE: -8.998507479317703e-06\n",
            "Total Loss: 3.2085334251847386e-08\n",
            "----------------------------------------\n",
            "Epoch 445\n",
            "Var loss:  tensor(3.1549e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9783750632307583e-06\n",
            "E_s_wdiff_all_sq: 4.6228985319246573e-07\n",
            "E_IS_SCOPE: -1.0301947276556897e-05\n",
            "E_IS_E_SCOPE: -8.997117435776314e-06\n",
            "Total Loss: 3.1548594910541065e-08\n",
            "----------------------------------------\n",
            "Epoch 446\n",
            "Var loss:  tensor(3.1004e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.979640589823085e-06\n",
            "E_s_wdiff_all_sq: 4.6378258893867996e-07\n",
            "E_IS_SCOPE: -1.0299063776970112e-05\n",
            "E_IS_E_SCOPE: -8.994075409726573e-06\n",
            "Total Loss: 3.1004332830741265e-08\n",
            "----------------------------------------\n",
            "Epoch 447\n",
            "Var loss:  tensor(3.0451e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9789138135608665e-06\n",
            "E_s_wdiff_all_sq: 4.632855400394444e-07\n",
            "E_IS_SCOPE: -1.0295340625861947e-05\n",
            "E_IS_E_SCOPE: -8.990190232283805e-06\n",
            "Total Loss: 3.045055279855164e-08\n",
            "----------------------------------------\n",
            "Epoch 448\n",
            "Var loss:  tensor(2.9913e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9750544455106806e-06\n",
            "E_s_wdiff_all_sq: 4.6057671334858063e-07\n",
            "E_IS_SCOPE: -1.0290084810830747e-05\n",
            "E_IS_E_SCOPE: -8.985240843047508e-06\n",
            "Total Loss: 2.9912863029036915e-08\n",
            "----------------------------------------\n",
            "Epoch 449\n",
            "Var loss:  tensor(2.9367e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.974880816956654e-06\n",
            "E_s_wdiff_all_sq: 4.608332820575906e-07\n",
            "E_IS_SCOPE: -1.0290867242869428e-05\n",
            "E_IS_E_SCOPE: -8.985965647594675e-06\n",
            "Total Loss: 2.9367410782973942e-08\n",
            "----------------------------------------\n",
            "Epoch 450\n",
            "Var loss:  tensor(2.8822e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9801333808803957e-06\n",
            "E_s_wdiff_all_sq: 4.655344720903491e-07\n",
            "E_IS_SCOPE: -1.0294914512798929e-05\n",
            "E_IS_E_SCOPE: -8.989464480203053e-06\n",
            "Total Loss: 2.882191003171197e-08\n",
            "----------------------------------------\n",
            "Epoch 451\n",
            "Var loss:  tensor(2.8284e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.982815472153122e-06\n",
            "E_s_wdiff_all_sq: 4.683797620209274e-07\n",
            "E_IS_SCOPE: -1.0295163194026595e-05\n",
            "E_IS_E_SCOPE: -8.989526020200222e-06\n",
            "Total Loss: 2.8284428912865203e-08\n",
            "----------------------------------------\n",
            "Epoch 452\n",
            "Var loss:  tensor(2.7740e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9823941336797825e-06\n",
            "E_s_wdiff_all_sq: 4.6915035507205683e-07\n",
            "E_IS_SCOPE: -1.0290395715213404e-05\n",
            "E_IS_E_SCOPE: -8.985082200798287e-06\n",
            "Total Loss: 2.7739816210904987e-08\n",
            "----------------------------------------\n",
            "Epoch 453\n",
            "Var loss:  tensor(2.7204e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9836686399468414e-06\n",
            "E_s_wdiff_all_sq: 4.7096921868742543e-07\n",
            "E_IS_SCOPE: -1.0288014591082486e-05\n",
            "E_IS_E_SCOPE: -8.9827054548465e-06\n",
            "Total Loss: 2.720421522085587e-08\n",
            "----------------------------------------\n",
            "Epoch 454\n",
            "Var loss:  tensor(2.6660e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.98827204289551e-06\n",
            "E_s_wdiff_all_sq: 4.7502999380114606e-07\n",
            "E_IS_SCOPE: -1.028764712693516e-05\n",
            "E_IS_E_SCOPE: -8.981794516470897e-06\n",
            "Total Loss: 2.6659894599252716e-08\n",
            "----------------------------------------\n",
            "Epoch 455\n",
            "Var loss:  tensor(2.6126e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9904602106515353e-06\n",
            "E_s_wdiff_all_sq: 4.771517346678013e-07\n",
            "E_IS_SCOPE: -1.028731356273192e-05\n",
            "E_IS_E_SCOPE: -8.981160915145488e-06\n",
            "Total Loss: 2.6126247244283324e-08\n",
            "----------------------------------------\n",
            "Epoch 456\n",
            "Var loss:  tensor(2.5589e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9876724712908743e-06\n",
            "E_s_wdiff_all_sq: 4.753837819776823e-07\n",
            "E_IS_SCOPE: -1.0284261785265774e-05\n",
            "E_IS_E_SCOPE: -8.978350454765674e-06\n",
            "Total Loss: 2.55890947464066e-08\n",
            "----------------------------------------\n",
            "Epoch 457\n",
            "Var loss:  tensor(2.5052e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.987519936935822e-06\n",
            "E_s_wdiff_all_sq: 4.753993171853836e-07\n",
            "E_IS_SCOPE: -1.028616789807712e-05\n",
            "E_IS_E_SCOPE: -8.980072237445806e-06\n",
            "Total Loss: 2.5052364921225227e-08\n",
            "----------------------------------------\n",
            "Epoch 458\n",
            "Var loss:  tensor(2.4525e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9890061147548036e-06\n",
            "E_s_wdiff_all_sq: 4.761384972290951e-07\n",
            "E_IS_SCOPE: -1.0292939354488937e-05\n",
            "E_IS_E_SCOPE: -8.986206490108061e-06\n",
            "Total Loss: 2.4524955197370838e-08\n",
            "----------------------------------------\n",
            "Epoch 459\n",
            "Var loss:  tensor(2.3984e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9859373187723843e-06\n",
            "E_s_wdiff_all_sq: 4.7415411311995065e-07\n",
            "E_IS_SCOPE: -1.028793910740668e-05\n",
            "E_IS_E_SCOPE: -8.98147812894845e-06\n",
            "Total Loss: 2.398431516939284e-08\n",
            "----------------------------------------\n",
            "Epoch 460\n",
            "Var loss:  tensor(2.3457e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.984895474743378e-06\n",
            "E_s_wdiff_all_sq: 4.7395057700158714e-07\n",
            "E_IS_SCOPE: -1.0284254263461434e-05\n",
            "E_IS_E_SCOPE: -8.977948825960277e-06\n",
            "Total Loss: 2.3457089172890808e-08\n",
            "----------------------------------------\n",
            "Epoch 461\n",
            "Var loss:  tensor(2.2930e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.989949091633991e-06\n",
            "E_s_wdiff_all_sq: 4.782974582663617e-07\n",
            "E_IS_SCOPE: -1.0284117899632877e-05\n",
            "E_IS_E_SCOPE: -8.977195746053177e-06\n",
            "Total Loss: 2.293039264164445e-08\n",
            "----------------------------------------\n",
            "Epoch 462\n",
            "Var loss:  tensor(2.2394e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9938142547301895e-06\n",
            "E_s_wdiff_all_sq: 4.830442677321873e-07\n",
            "E_IS_SCOPE: -1.0281112612798635e-05\n",
            "E_IS_E_SCOPE: -8.974362879895768e-06\n",
            "Total Loss: 2.2393587625682505e-08\n",
            "----------------------------------------\n",
            "Epoch 463\n",
            "Var loss:  tensor(2.1870e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9953250693956728e-06\n",
            "E_s_wdiff_all_sq: 4.859716830305691e-07\n",
            "E_IS_SCOPE: -1.0278185299983794e-05\n",
            "E_IS_E_SCOPE: -8.971881965660985e-06\n",
            "Total Loss: 2.1869784152900174e-08\n",
            "----------------------------------------\n",
            "Epoch 464\n",
            "Var loss:  tensor(2.1344e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.003164335266507e-06\n",
            "E_s_wdiff_all_sq: 4.931387667050078e-07\n",
            "E_IS_SCOPE: -1.0283250412551368e-05\n",
            "E_IS_E_SCOPE: -8.976348075778355e-06\n",
            "Total Loss: 2.1343961448888737e-08\n",
            "----------------------------------------\n",
            "Epoch 465\n",
            "Var loss:  tensor(2.0814e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.00596918495258e-06\n",
            "E_s_wdiff_all_sq: 4.952635587804395e-07\n",
            "E_IS_SCOPE: -1.0286195390715075e-05\n",
            "E_IS_E_SCOPE: -8.978688053113097e-06\n",
            "Total Loss: 2.0814017401600554e-08\n",
            "----------------------------------------\n",
            "Epoch 466\n",
            "Var loss:  tensor(2.0284e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9995584575920467e-06\n",
            "E_s_wdiff_all_sq: 4.903411498157026e-07\n",
            "E_IS_SCOPE: -1.0275274070393226e-05\n",
            "E_IS_E_SCOPE: -8.968245836771698e-06\n",
            "Total Loss: 2.0283906966706e-08\n",
            "----------------------------------------\n",
            "Epoch 467\n",
            "Var loss:  tensor(1.9758e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9959596161206824e-06\n",
            "E_s_wdiff_all_sq: 4.873287085325954e-07\n",
            "E_IS_SCOPE: -1.0270748177989506e-05\n",
            "E_IS_E_SCOPE: -8.963750194366115e-06\n",
            "Total Loss: 1.9758006774719977e-08\n",
            "----------------------------------------\n",
            "Epoch 468\n",
            "Var loss:  tensor(1.9230e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9985455291651874e-06\n",
            "E_s_wdiff_all_sq: 4.888012164532013e-07\n",
            "E_IS_SCOPE: -1.0275088649430562e-05\n",
            "E_IS_E_SCOPE: -8.967270113601776e-06\n",
            "Total Loss: 1.9230307487831258e-08\n",
            "----------------------------------------\n",
            "Epoch 469\n",
            "Var loss:  tensor(1.8714e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9984234763651494e-06\n",
            "E_s_wdiff_all_sq: 4.890398871504153e-07\n",
            "E_IS_SCOPE: -1.0274631358936603e-05\n",
            "E_IS_E_SCOPE: -8.966734901051235e-06\n",
            "Total Loss: 1.8713739877413158e-08\n",
            "----------------------------------------\n",
            "Epoch 470\n",
            "Var loss:  tensor(1.8188e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.995669330630659e-06\n",
            "E_s_wdiff_all_sq: 4.884849641922127e-07\n",
            "E_IS_SCOPE: -1.0268853852534552e-05\n",
            "E_IS_E_SCOPE: -8.961794348471656e-06\n",
            "Total Loss: 1.8188424746071312e-08\n",
            "----------------------------------------\n",
            "Epoch 471\n",
            "Var loss:  tensor(1.7654e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0009154834961565e-06\n",
            "E_s_wdiff_all_sq: 4.935294380987902e-07\n",
            "E_IS_SCOPE: -1.0270804474898572e-05\n",
            "E_IS_E_SCOPE: -8.96337667772767e-06\n",
            "Total Loss: 1.7653517488978252e-08\n",
            "----------------------------------------\n",
            "Epoch 472\n",
            "Var loss:  tensor(1.7130e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0106833652765395e-06\n",
            "E_s_wdiff_all_sq: 5.017487333839017e-07\n",
            "E_IS_SCOPE: -1.0281921310143514e-05\n",
            "E_IS_E_SCOPE: -8.973457569561061e-06\n",
            "Total Loss: 1.7130217161146577e-08\n",
            "----------------------------------------\n",
            "Epoch 473\n",
            "Var loss:  tensor(1.6605e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0089824588572434e-06\n",
            "E_s_wdiff_all_sq: 5.016492865707103e-07\n",
            "E_IS_SCOPE: -1.0278737323103787e-05\n",
            "E_IS_E_SCOPE: -8.970811548136593e-06\n",
            "Total Loss: 1.6604688785559573e-08\n",
            "----------------------------------------\n",
            "Epoch 474\n",
            "Var loss:  tensor(1.6084e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0070264155972893e-06\n",
            "E_s_wdiff_all_sq: 5.007549154991957e-07\n",
            "E_IS_SCOPE: -1.0272246898742075e-05\n",
            "E_IS_E_SCOPE: -8.964591637726033e-06\n",
            "Total Loss: 1.6084044499427647e-08\n",
            "----------------------------------------\n",
            "Epoch 475\n",
            "Var loss:  tensor(1.5556e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.012614379042489e-06\n",
            "E_s_wdiff_all_sq: 5.052714628275577e-07\n",
            "E_IS_SCOPE: -1.027195239757e-05\n",
            "E_IS_E_SCOPE: -8.96349746351898e-06\n",
            "Total Loss: 1.5556114546305388e-08\n",
            "----------------------------------------\n",
            "Epoch 476\n",
            "Var loss:  tensor(1.5031e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.013095232489268e-06\n",
            "E_s_wdiff_all_sq: 5.063400791984594e-07\n",
            "E_IS_SCOPE: -1.0270091308184446e-05\n",
            "E_IS_E_SCOPE: -8.961667628328162e-06\n",
            "Total Loss: 1.503086001165506e-08\n",
            "----------------------------------------\n",
            "Epoch 477\n",
            "Var loss:  tensor(1.4512e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0101912815628833e-06\n",
            "E_s_wdiff_all_sq: 5.042761565991641e-07\n",
            "E_IS_SCOPE: -1.026830339652073e-05\n",
            "E_IS_E_SCOPE: -8.960040412371295e-06\n",
            "Total Loss: 1.4512223098265357e-08\n",
            "----------------------------------------\n",
            "Epoch 478\n",
            "Var loss:  tensor(1.3997e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0084034273743267e-06\n",
            "E_s_wdiff_all_sq: 5.021976627636277e-07\n",
            "E_IS_SCOPE: -1.0267541684777306e-05\n",
            "E_IS_E_SCOPE: -8.958875817994713e-06\n",
            "Total Loss: 1.399709747892942e-08\n",
            "----------------------------------------\n",
            "Epoch 479\n",
            "Var loss:  tensor(1.3472e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.00511133658807e-06\n",
            "E_s_wdiff_all_sq: 4.990444905324619e-07\n",
            "E_IS_SCOPE: -1.0264668437748381e-05\n",
            "E_IS_E_SCOPE: -8.955809287950449e-06\n",
            "Total Loss: 1.347161289316056e-08\n",
            "----------------------------------------\n",
            "Epoch 480\n",
            "Var loss:  tensor(1.2957e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9995328352099963e-06\n",
            "E_s_wdiff_all_sq: 4.94920380580167e-07\n",
            "E_IS_SCOPE: -1.0259141565745345e-05\n",
            "E_IS_E_SCOPE: -8.950752446623513e-06\n",
            "Total Loss: 1.2957282819580681e-08\n",
            "----------------------------------------\n",
            "Epoch 481\n",
            "Var loss:  tensor(1.2438e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0043148972001274e-06\n",
            "E_s_wdiff_all_sq: 4.998115661188598e-07\n",
            "E_IS_SCOPE: -1.0260549988734314e-05\n",
            "E_IS_E_SCOPE: -8.951955932629254e-06\n",
            "Total Loss: 1.2438285304563134e-08\n",
            "----------------------------------------\n",
            "Epoch 482\n",
            "Var loss:  tensor(1.1928e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.017045923761808e-06\n",
            "E_s_wdiff_all_sq: 5.117629193993071e-07\n",
            "E_IS_SCOPE: -1.0264801530970467e-05\n",
            "E_IS_E_SCOPE: -8.95556260317696e-06\n",
            "Total Loss: 1.1928215208904065e-08\n",
            "----------------------------------------\n",
            "Epoch 483\n",
            "Var loss:  tensor(1.1407e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.022310496883602e-06\n",
            "E_s_wdiff_all_sq: 5.1807453639443e-07\n",
            "E_IS_SCOPE: -1.0263127367008421e-05\n",
            "E_IS_E_SCOPE: -8.954151553771795e-06\n",
            "Total Loss: 1.1407400449336221e-08\n",
            "----------------------------------------\n",
            "Epoch 484\n",
            "Var loss:  tensor(1.0893e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.022981893181914e-06\n",
            "E_s_wdiff_all_sq: 5.200435764492271e-07\n",
            "E_IS_SCOPE: -1.0261679164788244e-05\n",
            "E_IS_E_SCOPE: -8.95309509235394e-06\n",
            "Total Loss: 1.0893238297497883e-08\n",
            "----------------------------------------\n",
            "Epoch 485\n",
            "Var loss:  tensor(1.0363e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0252071081959425e-06\n",
            "E_s_wdiff_all_sq: 5.22072554799289e-07\n",
            "E_IS_SCOPE: -1.0264293230275965e-05\n",
            "E_IS_E_SCOPE: -8.955346017061737e-06\n",
            "Total Loss: 1.0363193401614356e-08\n",
            "----------------------------------------\n",
            "Epoch 486\n",
            "Var loss:  tensor(9.8518e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.024914653712312e-06\n",
            "E_s_wdiff_all_sq: 5.216232890060248e-07\n",
            "E_IS_SCOPE: -1.0265907213115858e-05\n",
            "E_IS_E_SCOPE: -8.956625919005472e-06\n",
            "Total Loss: 9.851842918931338e-09\n",
            "----------------------------------------\n",
            "Epoch 487\n",
            "Var loss:  tensor(9.3458e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.022858531667642e-06\n",
            "E_s_wdiff_all_sq: 5.203457590253743e-07\n",
            "E_IS_SCOPE: -1.0265113927732144e-05\n",
            "E_IS_E_SCOPE: -8.955968912106792e-06\n",
            "Total Loss: 9.34580782497589e-09\n",
            "----------------------------------------\n",
            "Epoch 488\n",
            "Var loss:  tensor(8.8433e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0267006036201575e-06\n",
            "E_s_wdiff_all_sq: 5.240024881718483e-07\n",
            "E_IS_SCOPE: -1.0265307938302357e-05\n",
            "E_IS_E_SCOPE: -8.955818984906495e-06\n",
            "Total Loss: 8.843275090000414e-09\n",
            "----------------------------------------\n",
            "Epoch 489\n",
            "Var loss:  tensor(8.3281e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0309187340696747e-06\n",
            "E_s_wdiff_all_sq: 5.27899398606759e-07\n",
            "E_IS_SCOPE: -1.0263623009476016e-05\n",
            "E_IS_E_SCOPE: -8.953715860084739e-06\n",
            "Total Loss: 8.32810311377693e-09\n",
            "----------------------------------------\n",
            "Epoch 490\n",
            "Var loss:  tensor(7.8280e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0281283746860327e-06\n",
            "E_s_wdiff_all_sq: 5.260273939485552e-07\n",
            "E_IS_SCOPE: -1.026008809391416e-05\n",
            "E_IS_E_SCOPE: -8.950390061989873e-06\n",
            "Total Loss: 7.82798332232031e-09\n",
            "----------------------------------------\n",
            "Epoch 491\n",
            "Var loss:  tensor(7.3177e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0227103279590094e-06\n",
            "E_s_wdiff_all_sq: 5.218185022823556e-07\n",
            "E_IS_SCOPE: -1.0256673059719374e-05\n",
            "E_IS_E_SCOPE: -8.947324450068174e-06\n",
            "Total Loss: 7.317672807668958e-09\n",
            "----------------------------------------\n",
            "Epoch 492\n",
            "Var loss:  tensor(6.8026e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.019462041337302e-06\n",
            "E_s_wdiff_all_sq: 5.181756571681855e-07\n",
            "E_IS_SCOPE: -1.0257478020974765e-05\n",
            "E_IS_E_SCOPE: -8.947674594732654e-06\n",
            "Total Loss: 6.802598118311215e-09\n",
            "----------------------------------------\n",
            "Epoch 493\n",
            "Var loss:  tensor(6.2937e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.017559307781662e-06\n",
            "E_s_wdiff_all_sq: 5.15767650089832e-07\n",
            "E_IS_SCOPE: -1.0259784859273294e-05\n",
            "E_IS_E_SCOPE: -8.949474326275213e-06\n",
            "Total Loss: 6.2936581290822296e-09\n",
            "----------------------------------------\n",
            "Epoch 494\n",
            "Var loss:  tensor(5.7918e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.015137596547622e-06\n",
            "E_s_wdiff_all_sq: 5.142496071136681e-07\n",
            "E_IS_SCOPE: -1.025826412532849e-05\n",
            "E_IS_E_SCOPE: -8.948154477142417e-06\n",
            "Total Loss: 5.791759495222871e-09\n",
            "----------------------------------------\n",
            "Epoch 495\n",
            "Var loss:  tensor(5.2869e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.018153880339629e-06\n",
            "E_s_wdiff_all_sq: 5.18282217484924e-07\n",
            "E_IS_SCOPE: -1.0253491659292948e-05\n",
            "E_IS_E_SCOPE: -8.943637756711987e-06\n",
            "Total Loss: 5.286924126199414e-09\n",
            "----------------------------------------\n",
            "Epoch 496\n",
            "Var loss:  tensor(4.7711e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0276998155701463e-06\n",
            "E_s_wdiff_all_sq: 5.273901922229109e-07\n",
            "E_IS_SCOPE: -1.0251325775400617e-05\n",
            "E_IS_E_SCOPE: -8.94099496396742e-06\n",
            "Total Loss: 4.7710669142541285e-09\n",
            "----------------------------------------\n",
            "Epoch 497\n",
            "Var loss:  tensor(4.2629e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0401389272714813e-06\n",
            "E_s_wdiff_all_sq: 5.397492775917084e-07\n",
            "E_IS_SCOPE: -1.0251847532007956e-05\n",
            "E_IS_E_SCOPE: -8.941222628017317e-06\n",
            "Total Loss: 4.26290813190995e-09\n",
            "----------------------------------------\n",
            "Epoch 498\n",
            "Var loss:  tensor(3.7534e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.046950732785681e-06\n",
            "E_s_wdiff_all_sq: 5.480995169849807e-07\n",
            "E_IS_SCOPE: -1.0251311878486663e-05\n",
            "E_IS_E_SCOPE: -8.941201447996694e-06\n",
            "Total Loss: 3.753421254179856e-09\n",
            "----------------------------------------\n",
            "Epoch 499\n",
            "Var loss:  tensor(3.2414e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.051876139884322e-06\n",
            "E_s_wdiff_all_sq: 5.528963214159742e-07\n",
            "E_IS_SCOPE: -1.0254595066316716e-05\n",
            "E_IS_E_SCOPE: -8.944164340235894e-06\n",
            "Total Loss: 3.2414327401195762e-09\n",
            "----------------------------------------\n",
            "Epoch 500\n",
            "Var loss:  tensor(2.7303e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0530651413587383e-06\n",
            "E_s_wdiff_all_sq: 5.533114186064268e-07\n",
            "E_IS_SCOPE: -1.0257403787613617e-05\n",
            "E_IS_E_SCOPE: -8.946330523549091e-06\n",
            "Total Loss: 2.7302610566741994e-09\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[-0.2101,  0.3801],\n",
            "        [ 0.7356, -0.4928],\n",
            "        [-0.0438, -0.4692],\n",
            "        [ 0.1624, -0.1203],\n",
            "        [-0.2191, -0.1823],\n",
            "        [-0.6192, -0.4586],\n",
            "        [ 0.4871,  0.4499],\n",
            "        [ 0.0730,  0.3805],\n",
            "        [-0.0262, -0.6044],\n",
            "        [-0.2140, -0.1630],\n",
            "        [-0.5518,  0.5047],\n",
            "        [ 0.6495, -0.4965],\n",
            "        [-0.6236, -0.0745],\n",
            "        [-0.0356,  0.3041],\n",
            "        [ 0.0052,  0.5972],\n",
            "        [-0.0604, -0.1989]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([-0.0844, -0.5681,  0.6441,  0.6516, -0.5922, -0.1688, -0.1012,  0.3523,\n",
            "        -0.0529,  0.7032,  0.4311,  0.7167,  0.5218, -0.4728,  0.1729,  0.0767],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[-0.0723,  0.0443, -0.2342,  0.2346,  0.2472, -0.1674, -0.2108,  0.2270,\n",
            "          0.2062, -0.2065, -0.0532,  0.0441, -0.1241,  0.0217,  0.0297,  0.2058],\n",
            "        [ 0.1407, -0.0838, -0.0309, -0.0524,  0.0307, -0.0390, -0.1469,  0.0782,\n",
            "         -0.1361,  0.3170, -0.2752, -0.2110, -0.1958, -0.0817, -0.2421,  0.2182],\n",
            "        [ 0.1490, -0.1923,  0.2114,  0.0494, -0.1272, -0.0874, -0.1222,  0.1429,\n",
            "          0.1397,  0.1364, -0.1316, -0.2463, -0.1448,  0.0281, -0.1215, -0.1329],\n",
            "        [ 0.1357, -0.1700, -0.1376, -0.0408, -0.2021, -0.0557,  0.0013, -0.0773,\n",
            "          0.2358,  0.1358, -0.1219,  0.0374,  0.0765,  0.2062,  0.0384, -0.2461],\n",
            "        [-0.1683,  0.2549, -0.0666, -0.2172, -0.2492,  0.2069,  0.2020, -0.0604,\n",
            "         -0.0837, -0.1553,  0.1239,  0.0097, -0.1396,  0.1377, -0.1685, -0.0125],\n",
            "        [-0.0887, -0.1167, -0.2472,  0.2480,  0.1460, -0.1333,  0.0869, -0.0297,\n",
            "          0.1020,  0.2673,  0.0181, -0.1046, -0.1542, -0.1216, -0.0773, -0.0919],\n",
            "        [ 0.0961, -0.1260,  0.2149,  0.0128, -0.0109, -0.1642,  0.0273,  0.1218,\n",
            "          0.0393,  0.1113, -0.1200, -0.2115,  0.0602,  0.0367, -0.0153, -0.1823],\n",
            "        [ 0.0389, -0.0843,  0.0426,  0.0417, -0.1042, -0.0314,  0.0859,  0.0507,\n",
            "          0.0765, -0.1602, -0.1115,  0.1037,  0.1218, -0.0143, -0.0750, -0.0884],\n",
            "        [ 0.0089,  0.4062,  0.1052, -0.0295,  0.1986, -0.1902,  0.2464, -0.0310,\n",
            "          0.1342,  0.0531, -0.2306,  0.0636, -0.1858, -0.2073, -0.1100, -0.2053],\n",
            "        [-0.0116, -0.2301, -0.0819, -0.0763,  0.1273, -0.1310,  0.1043,  0.1762,\n",
            "          0.1718,  0.0573, -0.1396, -0.1208,  0.1038,  0.1016, -0.1340,  0.2209],\n",
            "        [ 0.1314, -0.3478, -0.1507,  0.0981,  0.0243,  0.2286,  0.1045, -0.0915,\n",
            "         -0.0558,  0.0997, -0.1871,  0.1925,  0.0995,  0.0429, -0.0423, -0.1166],\n",
            "        [ 0.0751, -0.0163,  0.1346,  0.0925, -0.2416,  0.0813, -0.2958, -0.0724,\n",
            "          0.0433,  0.2542,  0.1256, -0.2655,  0.0154,  0.0138, -0.0757, -0.1927],\n",
            "        [ 0.2209, -0.0048,  0.0346, -0.2223,  0.0038,  0.0669, -0.1826,  0.1822,\n",
            "          0.2285,  0.0287, -0.1796, -0.0091,  0.0505, -0.1555, -0.0848,  0.1192],\n",
            "        [-0.0816,  0.0704,  0.0109, -0.1508, -0.0177,  0.2430,  0.1335, -0.2067,\n",
            "          0.0896, -0.2968,  0.2249, -0.1285, -0.0861, -0.0375,  0.1871,  0.0676],\n",
            "        [-0.1169, -0.1662,  0.0133,  0.1843, -0.2427, -0.2037, -0.1257, -0.0658,\n",
            "         -0.0482,  0.1870, -0.1433,  0.1704,  0.2412,  0.2343, -0.1149,  0.2100],\n",
            "        [-0.0814, -0.0236, -0.1137, -0.1326, -0.1443,  0.1173,  0.1302, -0.0051,\n",
            "          0.1721, -0.1738,  0.0825, -0.0336,  0.0855, -0.0797,  0.0132,  0.1194],\n",
            "        [-0.2904,  0.1067, -0.2938, -0.1049, -0.1551,  0.0998,  0.1479,  0.1157,\n",
            "         -0.1763, -0.1254,  0.0138,  0.2312, -0.1980,  0.1132, -0.2773, -0.2279],\n",
            "        [-0.1073, -0.1993,  0.1531,  0.0594,  0.0292,  0.0082,  0.0678, -0.0263,\n",
            "         -0.2444, -0.0980,  0.0504, -0.1207,  0.2453, -0.2473,  0.2290, -0.1811],\n",
            "        [ 0.0217,  0.1852, -0.0128,  0.0377, -0.0341,  0.1431, -0.2219,  0.0861,\n",
            "         -0.0946,  0.0917,  0.0913,  0.1392,  0.1109, -0.3874, -0.0792, -0.0132],\n",
            "        [ 0.1445, -0.0582, -0.2403, -0.0522,  0.1757,  0.0614,  0.1480, -0.0291,\n",
            "         -0.1732, -0.2209,  0.1266, -0.1022, -0.1371, -0.2013,  0.0909, -0.0258],\n",
            "        [-0.1988, -0.2591, -0.1653, -0.2291,  0.0325,  0.1640, -0.2165, -0.1013,\n",
            "          0.0831, -0.0624, -0.1373,  0.0671, -0.2039,  0.0062,  0.0244,  0.2164],\n",
            "        [ 0.0578,  0.1973, -0.0365,  0.2350, -0.1320, -0.0176, -0.2484,  0.0699,\n",
            "          0.1687, -0.1458,  0.0152,  0.1684, -0.2164, -0.1875,  0.2008,  0.1275],\n",
            "        [-0.2907,  0.1481,  0.2162,  0.1830, -0.0871, -0.1800,  0.0038,  0.1564,\n",
            "         -0.2033,  0.2414,  0.0755,  0.0118,  0.1514, -0.2136, -0.1369,  0.0037],\n",
            "        [ 0.0123,  0.1065,  0.1411,  0.1744,  0.0520,  0.0412, -0.2828, -0.1565,\n",
            "          0.2441,  0.0524,  0.2814, -0.1340,  0.0186, -0.1726, -0.1644,  0.1237],\n",
            "        [ 0.0383,  0.3420,  0.2942,  0.1720, -0.0857,  0.2014, -0.1948, -0.1641,\n",
            "         -0.0152,  0.1601,  0.1854, -0.0968,  0.3323, -0.0686, -0.0844,  0.1973],\n",
            "        [-0.2468, -0.1675, -0.1414,  0.1380,  0.2404, -0.1686, -0.0242,  0.0605,\n",
            "         -0.2336, -0.0629,  0.0349, -0.3694, -0.0238, -0.1747, -0.0088,  0.1758],\n",
            "        [-0.0784,  0.0665, -0.2722,  0.0654, -0.0289, -0.1542,  0.1631,  0.0431,\n",
            "         -0.2163,  0.1303,  0.1347, -0.1966, -0.1760, -0.0225, -0.2000,  0.1045],\n",
            "        [-0.0615,  0.3851,  0.2880, -0.1568, -0.1623, -0.1406, -0.2765,  0.0808,\n",
            "          0.0429,  0.0209, -0.1395,  0.0537,  0.1785,  0.1555,  0.1116, -0.2451],\n",
            "        [-0.0438, -0.0040, -0.2408, -0.1435, -0.0551,  0.1013, -0.0878,  0.0008,\n",
            "          0.2385, -0.1580,  0.1218, -0.1817, -0.0245,  0.0712, -0.0395,  0.0799],\n",
            "        [-0.0294, -0.1168, -0.1768, -0.4298, -0.0596, -0.1157, -0.0414, -0.1549,\n",
            "          0.0198,  0.2689,  0.0352, -0.1089,  0.0212, -0.1252,  0.1863,  0.1202],\n",
            "        [-0.0183, -0.0076, -0.0205,  0.2282, -0.0270, -0.0412, -0.0038, -0.0265,\n",
            "         -0.0269, -0.1750, -0.0062,  0.1763,  0.0688,  0.1550, -0.0042,  0.1926],\n",
            "        [-0.1474, -0.0022, -0.0472,  0.1161,  0.0839, -0.0988, -0.0731, -0.1240,\n",
            "          0.1890,  0.1056, -0.0994, -0.6337, -0.0903, -0.0600,  0.0467,  0.2175]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([ 0.0023, -0.1293,  0.1437, -0.2342, -0.0009,  0.0433,  0.0330, -0.2351,\n",
            "         0.1822, -0.1495, -0.0861, -0.2659,  0.2627, -0.0961,  0.1377, -0.0565,\n",
            "         0.1741, -0.2573,  0.1343,  0.0675, -0.1959,  0.0510, -0.1727,  0.1640,\n",
            "         0.0957, -0.1765,  0.2066, -0.0127, -0.1928,  0.0063, -0.1169,  0.3009],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[-9.1361e-03, -8.1587e-03, -8.1484e-02,  8.3674e-03, -1.3339e-02,\n",
            "         -5.7281e-02, -1.1561e-02,  7.4972e-02, -5.4146e-03,  1.7219e-02,\n",
            "         -2.5101e-02, -7.5459e-02,  7.2642e-02, -2.3989e-03, -1.5589e-01,\n",
            "         -8.0905e-03, -1.3245e-02,  9.6031e-05, -5.5253e-02,  3.6214e-03,\n",
            "         -2.3125e-01,  6.9517e-04, -1.6196e-02,  8.6999e-02, -6.9840e-02,\n",
            "          1.2434e-01,  1.4296e-02, -7.9747e-03,  5.2897e-02, -8.6052e-03,\n",
            "          7.8192e-02, -2.6261e-01]], dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([0.0026], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model12 = train_var_play(model11, 500, 0.0001, padded_state_tensors, states_first_tensor, states_last_tensor, 1, 1, testing)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TpygwFvCGOLV",
        "outputId": "2a9bcaca-aaaf-4e96-94e9-9f10930c3f3e"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Var loss:  tensor(2.2263e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0454397267940005e-06\n",
            "E_s_wdiff_all_sq: 5.467628114465457e-07\n",
            "E_IS_SCOPE: -1.0254970373924974e-05\n",
            "E_IS_E_SCOPE: -8.944183529765734e-06\n",
            "Total Loss: 2.2262934623888673e-09\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "Var loss:  tensor(6.5306e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.65793187982493e-06\n",
            "E_s_wdiff_all_sq: 1.2877612576471057e-07\n",
            "E_IS_SCOPE: -9.075641433495659e-06\n",
            "E_IS_E_SCOPE: -7.781154824562122e-06\n",
            "Total Loss: 6.530560262656123e-08\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "Var loss:  tensor(1.9184e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 3.6306633195734738e-06\n",
            "E_s_wdiff_all_sq: 1.7726246188113302e-06\n",
            "E_IS_SCOPE: -1.1890450153615224e-05\n",
            "E_IS_E_SCOPE: -1.0494788465396067e-05\n",
            "Total Loss: 1.9183839075724527e-07\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "Var loss:  tensor(3.7999e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.4990283990365634e-06\n",
            "E_s_wdiff_all_sq: 9.370953803085665e-07\n",
            "E_IS_SCOPE: -1.079701560358715e-05\n",
            "E_IS_E_SCOPE: -9.472486973329307e-06\n",
            "Total Loss: 3.799882464572611e-08\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "Var loss:  tensor(4.2666e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6728484945990395e-06\n",
            "E_s_wdiff_all_sq: 2.4253645884522285e-07\n",
            "E_IS_SCOPE: -9.249256192303062e-06\n",
            "E_IS_E_SCOPE: -7.992871776672937e-06\n",
            "Total Loss: 4.2666270926984354e-08\n",
            "----------------------------------------\n",
            "Epoch 6\n",
            "Var loss:  tensor(1.0662e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.608193151590466e-06\n",
            "E_s_wdiff_all_sq: 1.2806360816480075e-07\n",
            "E_IS_SCOPE: -8.765931068606625e-06\n",
            "E_IS_E_SCOPE: -7.51661677239007e-06\n",
            "Total Loss: 1.066240174259725e-07\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "Var loss:  tensor(4.5669e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8056038189969946e-06\n",
            "E_s_wdiff_all_sq: 3.2133003772692877e-07\n",
            "E_IS_SCOPE: -9.370670709967898e-06\n",
            "E_IS_E_SCOPE: -8.088806824909606e-06\n",
            "Total Loss: 4.566907758689896e-08\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "Var loss:  tensor(8.1549e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.3477212622009084e-06\n",
            "E_s_wdiff_all_sq: 8.180333063325221e-07\n",
            "E_IS_SCOPE: -1.0408065671711388e-05\n",
            "E_IS_E_SCOPE: -9.084737627037868e-06\n",
            "Total Loss: 8.154932954762701e-09\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "Var loss:  tensor(4.8483e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.9482423854384237e-06\n",
            "E_s_wdiff_all_sq: 1.328140216626351e-06\n",
            "E_IS_SCOPE: -1.1202955715851152e-05\n",
            "E_IS_E_SCOPE: -9.854584417812217e-06\n",
            "Total Loss: 4.8482639167617086e-08\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "Var loss:  tensor(5.7106e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.99805086697032e-06\n",
            "E_s_wdiff_all_sq: 1.3731808895837784e-06\n",
            "E_IS_SCOPE: -1.1319287672495042e-05\n",
            "E_IS_E_SCOPE: -9.972843998552723e-06\n",
            "Total Loss: 5.710569593531947e-08\n",
            "----------------------------------------\n",
            "Epoch 11\n",
            "Var loss:  tensor(1.5587e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.532865144912458e-06\n",
            "E_s_wdiff_all_sq: 9.922791607161005e-07\n",
            "E_IS_SCOPE: -1.0836657340886324e-05\n",
            "E_IS_E_SCOPE: -9.511596541181188e-06\n",
            "Total Loss: 1.5587451219502673e-08\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "Var loss:  tensor(2.8988e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0223316178676115e-06\n",
            "E_s_wdiff_all_sq: 5.476404855329914e-07\n",
            "E_IS_SCOPE: -1.0103498458886906e-05\n",
            "E_IS_E_SCOPE: -8.805040765470641e-06\n",
            "Total Loss: 2.8988119355073726e-09\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "Var loss:  tensor(3.1376e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7574157726583948e-06\n",
            "E_s_wdiff_all_sq: 2.883126171883475e-07\n",
            "E_IS_SCOPE: -9.535296196954057e-06\n",
            "E_IS_E_SCOPE: -8.25387102207524e-06\n",
            "Total Loss: 3.1375872145828754e-08\n",
            "----------------------------------------\n",
            "Epoch 14\n",
            "Var loss:  tensor(3.8228e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7052472153957135e-06\n",
            "E_s_wdiff_all_sq: 2.2872666677047923e-07\n",
            "E_IS_SCOPE: -9.418262156012151e-06\n",
            "E_IS_E_SCOPE: -8.136554509896575e-06\n",
            "Total Loss: 3.822832282749832e-08\n",
            "----------------------------------------\n",
            "Epoch 15\n",
            "Var loss:  tensor(1.1918e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7913785855639713e-06\n",
            "E_s_wdiff_all_sq: 3.1137623828872424e-07\n",
            "E_IS_SCOPE: -9.73522999509544e-06\n",
            "E_IS_E_SCOPE: -8.43862629482213e-06\n",
            "Total Loss: 1.191801316204334e-08\n",
            "----------------------------------------\n",
            "Epoch 16\n",
            "Var loss:  tensor(-4.8566e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0036845900537093e-06\n",
            "E_s_wdiff_all_sq: 4.94979475248252e-07\n",
            "E_IS_SCOPE: -1.0256996658681559e-05\n",
            "E_IS_E_SCOPE: -8.939839736762956e-06\n",
            "Total Loss: -4.85662598332864e-10\n",
            "----------------------------------------\n",
            "Epoch 17\n",
            "Var loss:  tensor(1.5389e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.2290155307542045e-06\n",
            "E_s_wdiff_all_sq: 6.732558133721486e-07\n",
            "E_IS_SCOPE: -1.0683645186787486e-05\n",
            "E_IS_E_SCOPE: -9.350898132367572e-06\n",
            "Total Loss: 1.5388674975643242e-08\n",
            "----------------------------------------\n",
            "Epoch 18\n",
            "Var loss:  tensor(2.3111e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.274936542776133e-06\n",
            "E_s_wdiff_all_sq: 7.047807549844749e-07\n",
            "E_IS_SCOPE: -1.079232018614846e-05\n",
            "E_IS_E_SCOPE: -9.456236285494397e-06\n",
            "Total Loss: 2.3111052916951816e-08\n",
            "----------------------------------------\n",
            "Epoch 19\n",
            "Var loss:  tensor(7.9511e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.1049937209070637e-06\n",
            "E_s_wdiff_all_sq: 5.683517889969924e-07\n",
            "E_IS_SCOPE: -1.055909797818024e-05\n",
            "E_IS_E_SCOPE: -9.23219100822281e-06\n",
            "Total Loss: 7.951058428624494e-09\n",
            "----------------------------------------\n",
            "Epoch 20\n",
            "Var loss:  tensor(-2.4889e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8704765994039856e-06\n",
            "E_s_wdiff_all_sq: 3.761509426158727e-07\n",
            "E_IS_SCOPE: -1.0139025399839854e-05\n",
            "E_IS_E_SCOPE: -8.828056573225597e-06\n",
            "Total Loss: -2.4889300069854286e-09\n",
            "----------------------------------------\n",
            "Epoch 21\n",
            "Var loss:  tensor(6.7332e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7188875842519047e-06\n",
            "E_s_wdiff_all_sq: 2.43736449977665e-07\n",
            "E_IS_SCOPE: -9.770997087798155e-06\n",
            "E_IS_E_SCOPE: -8.47422661181701e-06\n",
            "Total Loss: 6.733248745365261e-09\n",
            "----------------------------------------\n",
            "Epoch 22\n",
            "Var loss:  tensor(1.4259e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6828102960631392e-06\n",
            "E_s_wdiff_all_sq: 2.107352975635334e-07\n",
            "E_IS_SCOPE: -9.654894028161382e-06\n",
            "E_IS_E_SCOPE: -8.363424427472517e-06\n",
            "Total Loss: 1.4258863555291614e-08\n",
            "----------------------------------------\n",
            "Epoch 23\n",
            "Var loss:  tensor(5.5985e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7499156544064517e-06\n",
            "E_s_wdiff_all_sq: 2.753077209570467e-07\n",
            "E_IS_SCOPE: -9.836817859364206e-06\n",
            "E_IS_E_SCOPE: -8.539751623021573e-06\n",
            "Total Loss: 5.598527197554554e-09\n",
            "----------------------------------------\n",
            "Epoch 24\n",
            "Var loss:  tensor(-3.0188e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9199213315060747e-06\n",
            "E_s_wdiff_all_sq: 4.282633078187896e-07\n",
            "E_IS_SCOPE: -1.0199640373845419e-05\n",
            "E_IS_E_SCOPE: -8.889740407281066e-06\n",
            "Total Loss: -3.01884300800533e-09\n",
            "----------------------------------------\n",
            "Epoch 25\n",
            "Var loss:  tensor(1.6337e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.1379403932650914e-06\n",
            "E_s_wdiff_all_sq: 6.151188678561323e-07\n",
            "E_IS_SCOPE: -1.054162539355591e-05\n",
            "E_IS_E_SCOPE: -9.21846992273857e-06\n",
            "Total Loss: 1.633650207696397e-09\n",
            "----------------------------------------\n",
            "Epoch 26\n",
            "Var loss:  tensor(7.2470e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.272737573357248e-06\n",
            "E_s_wdiff_all_sq: 7.305798163246795e-07\n",
            "E_IS_SCOPE: -1.0679218140984182e-05\n",
            "E_IS_E_SCOPE: -9.349201205240987e-06\n",
            "Total Loss: 7.246951979593888e-09\n",
            "----------------------------------------\n",
            "Epoch 27\n",
            "Var loss:  tensor(2.0994e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.244149197724913e-06\n",
            "E_s_wdiff_all_sq: 7.125754440284311e-07\n",
            "E_IS_SCOPE: -1.0552396077269611e-05\n",
            "E_IS_E_SCOPE: -9.225097376676322e-06\n",
            "Total Loss: 2.0994189433187347e-09\n",
            "----------------------------------------\n",
            "Epoch 28\n",
            "Var loss:  tensor(-4.1642e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.1072409416105232e-06\n",
            "E_s_wdiff_all_sq: 6.025610774163309e-07\n",
            "E_IS_SCOPE: -1.0245847636005125e-05\n",
            "E_IS_E_SCOPE: -8.928864093977677e-06\n",
            "Total Loss: -4.1641534272860706e-09\n",
            "----------------------------------------\n",
            "Epoch 29\n",
            "Var loss:  tensor(-1.4225e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.977730430989686e-06\n",
            "E_s_wdiff_all_sq: 4.947392966653689e-07\n",
            "E_IS_SCOPE: -9.933041141213564e-06\n",
            "E_IS_E_SCOPE: -8.628272815129899e-06\n",
            "Total Loss: -1.4224514095970944e-09\n",
            "----------------------------------------\n",
            "Epoch 30\n",
            "Var loss:  tensor(2.7102e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9293878724989144e-06\n",
            "E_s_wdiff_all_sq: 4.577848917958676e-07\n",
            "E_IS_SCOPE: -9.779328763147705e-06\n",
            "E_IS_E_SCOPE: -8.482320857905994e-06\n",
            "Total Loss: 2.7102366530397027e-09\n",
            "----------------------------------------\n",
            "Epoch 31\n",
            "Var loss:  tensor(-4.5556e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9831465700422948e-06\n",
            "E_s_wdiff_all_sq: 5.13713300620971e-07\n",
            "E_IS_SCOPE: -9.851801228994431e-06\n",
            "E_IS_E_SCOPE: -8.554295278679982e-06\n",
            "Total Loss: -4.555647741596266e-10\n",
            "----------------------------------------\n",
            "Epoch 32\n",
            "Var loss:  tensor(-4.7566e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.1268637121412923e-06\n",
            "E_s_wdiff_all_sq: 6.461666938826711e-07\n",
            "E_IS_SCOPE: -1.00877837794804e-05\n",
            "E_IS_E_SCOPE: -8.782495414164582e-06\n",
            "Total Loss: -4.756645939598935e-09\n",
            "----------------------------------------\n",
            "Epoch 33\n",
            "Var loss:  tensor(-3.1391e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.296936988863881e-06\n",
            "E_s_wdiff_all_sq: 7.94248319390156e-07\n",
            "E_IS_SCOPE: -1.0341415715436838e-05\n",
            "E_IS_E_SCOPE: -9.025940283370465e-06\n",
            "Total Loss: -3.139128225602964e-09\n",
            "----------------------------------------\n",
            "Epoch 34\n",
            "Var loss:  tensor(-7.9965e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.388167147307035e-06\n",
            "E_s_wdiff_all_sq: 8.697817398213587e-07\n",
            "E_IS_SCOPE: -1.0471372414918928e-05\n",
            "E_IS_E_SCOPE: -9.149218353156198e-06\n",
            "Total Loss: -7.996496063676509e-10\n",
            "----------------------------------------\n",
            "Epoch 35\n",
            "Var loss:  tensor(-3.2679e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.3424686913632853e-06\n",
            "E_s_wdiff_all_sq: 8.272612205428611e-07\n",
            "E_IS_SCOPE: -1.0422966314532416e-05\n",
            "E_IS_E_SCOPE: -9.10116710545891e-06\n",
            "Total Loss: -3.2678808931710317e-09\n",
            "----------------------------------------\n",
            "Epoch 36\n",
            "Var loss:  tensor(-5.8994e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.2035525446867224e-06\n",
            "E_s_wdiff_all_sq: 7.041061742223488e-07\n",
            "E_IS_SCOPE: -1.0251540354566407e-05\n",
            "E_IS_E_SCOPE: -8.936305940591546e-06\n",
            "Total Loss: -5.899391051932471e-09\n",
            "----------------------------------------\n",
            "Epoch 37\n",
            "Var loss:  tensor(-4.3999e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.065288766853955e-06\n",
            "E_s_wdiff_all_sq: 5.809361454438431e-07\n",
            "E_IS_SCOPE: -1.0080679131466384e-05\n",
            "E_IS_E_SCOPE: -8.773741318620893e-06\n",
            "Total Loss: -4.399937847453072e-09\n",
            "----------------------------------------\n",
            "Epoch 38\n",
            "Var loss:  tensor(-3.0209e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.991715851293202e-06\n",
            "E_s_wdiff_all_sq: 5.15309182209182e-07\n",
            "E_IS_SCOPE: -1.002294481857319e-05\n",
            "E_IS_E_SCOPE: -8.720669496919584e-06\n",
            "Total Loss: -3.020907789773035e-09\n",
            "----------------------------------------\n",
            "Epoch 39\n",
            "Var loss:  tensor(-5.0437e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9970586119530063e-06\n",
            "E_s_wdiff_all_sq: 5.188513016666733e-07\n",
            "E_IS_SCOPE: -1.0110620654553642e-05\n",
            "E_IS_E_SCOPE: -8.806433618906716e-06\n",
            "Total Loss: -5.043694574100036e-09\n",
            "----------------------------------------\n",
            "Epoch 40\n",
            "Var loss:  tensor(-6.6662e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0569913583397095e-06\n",
            "E_s_wdiff_all_sq: 5.659813749117779e-07\n",
            "E_IS_SCOPE: -1.0279330213865076e-05\n",
            "E_IS_E_SCOPE: -8.967930591941114e-06\n",
            "Total Loss: -6.666193986576173e-09\n",
            "----------------------------------------\n",
            "Epoch 41\n",
            "Var loss:  tensor(-5.6267e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.1153510287362964e-06\n",
            "E_s_wdiff_all_sq: 6.073533886343014e-07\n",
            "E_IS_SCOPE: -1.0414883075742426e-05\n",
            "E_IS_E_SCOPE: -9.095509383179949e-06\n",
            "Total Loss: -5.626678589540541e-09\n",
            "----------------------------------------\n",
            "Epoch 42\n",
            "Var loss:  tensor(-5.2464e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.112886907952283e-06\n",
            "E_s_wdiff_all_sq: 5.969161359064466e-07\n",
            "E_IS_SCOPE: -1.042978523463228e-05\n",
            "E_IS_E_SCOPE: -9.106615110591327e-06\n",
            "Total Loss: -5.246409602655439e-09\n",
            "----------------------------------------\n",
            "Epoch 43\n",
            "Var loss:  tensor(-6.8132e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.039923866230653e-06\n",
            "E_s_wdiff_all_sq: 5.30574700159961e-07\n",
            "E_IS_SCOPE: -1.031689196804094e-05\n",
            "E_IS_E_SCOPE: -8.99624923568608e-06\n",
            "Total Loss: -6.813232205611442e-09\n",
            "----------------------------------------\n",
            "Epoch 44\n",
            "Var loss:  tensor(-7.3928e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9441578551521687e-06\n",
            "E_s_wdiff_all_sq: 4.4916410118914387e-07\n",
            "E_IS_SCOPE: -1.0151281513607879e-05\n",
            "E_IS_E_SCOPE: -8.837526703431912e-06\n",
            "Total Loss: -7.392799955492662e-09\n",
            "----------------------------------------\n",
            "Epoch 45\n",
            "Var loss:  tensor(-6.5178e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8821676349355666e-06\n",
            "E_s_wdiff_all_sq: 3.9936381639448614e-07\n",
            "E_IS_SCOPE: -1.0037807575901622e-05\n",
            "E_IS_E_SCOPE: -8.7305852292044e-06\n",
            "Total Loss: -6.517808419948901e-09\n",
            "----------------------------------------\n",
            "Epoch 46\n",
            "Var loss:  tensor(-6.7853e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.883060704527282e-06\n",
            "E_s_wdiff_all_sq: 4.0428624088720274e-07\n",
            "E_IS_SCOPE: -1.0041732370649016e-05\n",
            "E_IS_E_SCOPE: -8.736390935578567e-06\n",
            "Total Loss: -6.785340067401595e-09\n",
            "----------------------------------------\n",
            "Epoch 47\n",
            "Var loss:  tensor(-8.0597e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.94533537712362e-06\n",
            "E_s_wdiff_all_sq: 4.603580130029238e-07\n",
            "E_IS_SCOPE: -1.0149056124069345e-05\n",
            "E_IS_E_SCOPE: -8.83997607268987e-06\n",
            "Total Loss: -8.059672204838145e-09\n",
            "----------------------------------------\n",
            "Epoch 48\n",
            "Var loss:  tensor(-8.1724e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.036555760763813e-06\n",
            "E_s_wdiff_all_sq: 5.386882930020705e-07\n",
            "E_IS_SCOPE: -1.0281581526552437e-05\n",
            "E_IS_E_SCOPE: -8.966000075588007e-06\n",
            "Total Loss: -8.172367733702172e-09\n",
            "----------------------------------------\n",
            "Epoch 49\n",
            "Var loss:  tensor(-7.7063e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.1039205169944664e-06\n",
            "E_s_wdiff_all_sq: 5.96166041379565e-07\n",
            "E_IS_SCOPE: -1.0353639049823191e-05\n",
            "E_IS_E_SCOPE: -9.033347149177912e-06\n",
            "Total Loss: -7.70625924224273e-09\n",
            "----------------------------------------\n",
            "Epoch 50\n",
            "Var loss:  tensor(-8.2901e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.1115693399332563e-06\n",
            "E_s_wdiff_all_sq: 6.047857123156647e-07\n",
            "E_IS_SCOPE: -1.0327009954743108e-05\n",
            "E_IS_E_SCOPE: -9.006911578708541e-06\n",
            "Total Loss: -8.290058018125898e-09\n",
            "----------------------------------------\n",
            "Epoch 51\n",
            "Var loss:  tensor(-9.0166e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0730990201433454e-06\n",
            "E_s_wdiff_all_sq: 5.76369688901628e-07\n",
            "E_IS_SCOPE: -1.0234164964291299e-05\n",
            "E_IS_E_SCOPE: -8.918730486870515e-06\n",
            "Total Loss: -9.016557166433678e-09\n",
            "----------------------------------------\n",
            "Epoch 52\n",
            "Var loss:  tensor(-8.8202e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0333898849087516e-06\n",
            "E_s_wdiff_all_sq: 5.476780900266462e-07\n",
            "E_IS_SCOPE: -1.0148520386632672e-05\n",
            "E_IS_E_SCOPE: -8.83869284565458e-06\n",
            "Total Loss: -8.820220640663851e-09\n",
            "----------------------------------------\n",
            "Epoch 53\n",
            "Var loss:  tensor(-8.8394e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0303466839366845e-06\n",
            "E_s_wdiff_all_sq: 5.496380813985817e-07\n",
            "E_IS_SCOPE: -1.0131618277069346e-05\n",
            "E_IS_E_SCOPE: -8.824282723437756e-06\n",
            "Total Loss: -8.839438291661334e-09\n",
            "----------------------------------------\n",
            "Epoch 54\n",
            "Var loss:  tensor(-9.5629e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.071353188420848e-06\n",
            "E_s_wdiff_all_sq: 5.870432309364803e-07\n",
            "E_IS_SCOPE: -1.0189145134420258e-05\n",
            "E_IS_E_SCOPE: -8.879647174873827e-06\n",
            "Total Loss: -9.5628951750787e-09\n",
            "----------------------------------------\n",
            "Epoch 55\n",
            "Var loss:  tensor(-9.8628e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.1319225434191327e-06\n",
            "E_s_wdiff_all_sq: 6.380365940098327e-07\n",
            "E_IS_SCOPE: -1.0273122960965279e-05\n",
            "E_IS_E_SCOPE: -8.958687054734043e-06\n",
            "Total Loss: -9.862796619757214e-09\n",
            "----------------------------------------\n",
            "Epoch 56\n",
            "Var loss:  tensor(-9.6851e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.1696649498068823e-06\n",
            "E_s_wdiff_all_sq: 6.677167580673232e-07\n",
            "E_IS_SCOPE: -1.0319913981473181e-05\n",
            "E_IS_E_SCOPE: -9.001535783660428e-06\n",
            "Total Loss: -9.68513745252954e-09\n",
            "----------------------------------------\n",
            "Epoch 57\n",
            "Var loss:  tensor(-1.0012e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.157701761166814e-06\n",
            "E_s_wdiff_all_sq: 6.557746591509468e-07\n",
            "E_IS_SCOPE: -1.0298095446149528e-05\n",
            "E_IS_E_SCOPE: -8.979564532562231e-06\n",
            "Total Loss: -1.0011658725310767e-08\n",
            "----------------------------------------\n",
            "Epoch 58\n",
            "Var loss:  tensor(-1.0537e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.1083444142817814e-06\n",
            "E_s_wdiff_all_sq: 6.137402800020223e-07\n",
            "E_IS_SCOPE: -1.0229141090254144e-05\n",
            "E_IS_E_SCOPE: -8.914008818664182e-06\n",
            "Total Loss: -1.0537342466748804e-08\n",
            "----------------------------------------\n",
            "Epoch 59\n",
            "Var loss:  tensor(-1.0580e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0588787535783285e-06\n",
            "E_s_wdiff_all_sq: 5.723536189983016e-07\n",
            "E_IS_SCOPE: -1.0168141237396644e-05\n",
            "E_IS_E_SCOPE: -8.857026995763894e-06\n",
            "Total Loss: -1.0580282252057838e-08\n",
            "----------------------------------------\n",
            "Epoch 60\n",
            "Var loss:  tensor(-1.0683e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0404932774222043e-06\n",
            "E_s_wdiff_all_sq: 5.568538343567911e-07\n",
            "E_IS_SCOPE: -1.0160223961351329e-05\n",
            "E_IS_E_SCOPE: -8.85050113647764e-06\n",
            "Total Loss: -1.0683140248548155e-08\n",
            "----------------------------------------\n",
            "Epoch 61\n",
            "Var loss:  tensor(-1.1170e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.058299025902971e-06\n",
            "E_s_wdiff_all_sq: 5.705509876058819e-07\n",
            "E_IS_SCOPE: -1.0209825847674995e-05\n",
            "E_IS_E_SCOPE: -8.897805118531843e-06\n",
            "Total Loss: -1.1170353555799432e-08\n",
            "----------------------------------------\n",
            "Epoch 62\n",
            "Var loss:  tensor(-1.1406e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0901270627097105e-06\n",
            "E_s_wdiff_all_sq: 5.946714261195164e-07\n",
            "E_IS_SCOPE: -1.0275634508564324e-05\n",
            "E_IS_E_SCOPE: -8.959642263040774e-06\n",
            "Total Loss: -1.1405788023489006e-08\n",
            "----------------------------------------\n",
            "Epoch 63\n",
            "Var loss:  tensor(-1.1426e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.1044643209911997e-06\n",
            "E_s_wdiff_all_sq: 6.038609792329203e-07\n",
            "E_IS_SCOPE: -1.030907090466257e-05\n",
            "E_IS_E_SCOPE: -8.990494736880702e-06\n",
            "Total Loss: -1.142592737204359e-08\n",
            "----------------------------------------\n",
            "Epoch 64\n",
            "Var loss:  tensor(-1.1745e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.085697139219106e-06\n",
            "E_s_wdiff_all_sq: 5.868093456695682e-07\n",
            "E_IS_SCOPE: -1.0288330525939115e-05\n",
            "E_IS_E_SCOPE: -8.970452580051253e-06\n",
            "Total Loss: -1.1745031792772768e-08\n",
            "----------------------------------------\n",
            "Epoch 65\n",
            "Var loss:  tensor(-1.2092e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.047154380205936e-06\n",
            "E_s_wdiff_all_sq: 5.549632068238898e-07\n",
            "E_IS_SCOPE: -1.0234604895454022e-05\n",
            "E_IS_E_SCOPE: -8.919902012283507e-06\n",
            "Total Loss: -1.209152652556809e-08\n",
            "----------------------------------------\n",
            "Epoch 66\n",
            "Var loss:  tensor(-1.2192e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.017162186569903e-06\n",
            "E_s_wdiff_all_sq: 5.310615526495849e-07\n",
            "E_IS_SCOPE: -1.019084382793026e-05\n",
            "E_IS_E_SCOPE: -8.87913575983426e-06\n",
            "Total Loss: -1.2192435838268324e-08\n",
            "----------------------------------------\n",
            "Epoch 67\n",
            "Var loss:  tensor(-1.2409e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0161724200981404e-06\n",
            "E_s_wdiff_all_sq: 5.312603184207926e-07\n",
            "E_IS_SCOPE: -1.018788869146272e-05\n",
            "E_IS_E_SCOPE: -8.87666664007372e-06\n",
            "Total Loss: -1.240893466723844e-08\n",
            "----------------------------------------\n",
            "Epoch 68\n",
            "Var loss:  tensor(-1.2773e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0428988421615277e-06\n",
            "E_s_wdiff_all_sq: 5.539229937661871e-07\n",
            "E_IS_SCOPE: -1.0222739984150881e-05\n",
            "E_IS_E_SCOPE: -8.909303854742165e-06\n",
            "Total Loss: -1.2773343988675469e-08\n",
            "----------------------------------------\n",
            "Epoch 69\n",
            "Var loss:  tensor(-1.2941e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.076200481918031e-06\n",
            "E_s_wdiff_all_sq: 5.815902528574173e-07\n",
            "E_IS_SCOPE: -1.0263462195842254e-05\n",
            "E_IS_E_SCOPE: -8.947125245419527e-06\n",
            "Total Loss: -1.2940605351425109e-08\n",
            "----------------------------------------\n",
            "Epoch 70\n",
            "Var loss:  tensor(-1.3090e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0915139289719753e-06\n",
            "E_s_wdiff_all_sq: 5.947428316835495e-07\n",
            "E_IS_SCOPE: -1.0274280079701651e-05\n",
            "E_IS_E_SCOPE: -8.956788238687128e-06\n",
            "Total Loss: -1.3089518307204045e-08\n",
            "----------------------------------------\n",
            "Epoch 71\n",
            "Var loss:  tensor(-1.3410e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.081608196225933e-06\n",
            "E_s_wdiff_all_sq: 5.878709593076894e-07\n",
            "E_IS_SCOPE: -1.0249122306728301e-05\n",
            "E_IS_E_SCOPE: -8.93298711846665e-06\n",
            "Total Loss: -1.3410073171642398e-08\n",
            "----------------------------------------\n",
            "Epoch 72\n",
            "Var loss:  tensor(-1.3650e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0618559211137135e-06\n",
            "E_s_wdiff_all_sq: 5.733219881087013e-07\n",
            "E_IS_SCOPE: -1.021148406058251e-05\n",
            "E_IS_E_SCOPE: -8.897830473701985e-06\n",
            "Total Loss: -1.365017432262253e-08\n",
            "----------------------------------------\n",
            "Epoch 73\n",
            "Var loss:  tensor(-1.3805e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0535637637923985e-06\n",
            "E_s_wdiff_all_sq: 5.679519160408657e-07\n",
            "E_IS_SCOPE: -1.0192157862549516e-05\n",
            "E_IS_E_SCOPE: -8.879887826466524e-06\n",
            "Total Loss: -1.3805157981037316e-08\n",
            "----------------------------------------\n",
            "Epoch 74\n",
            "Var loss:  tensor(-1.4072e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0663840449086025e-06\n",
            "E_s_wdiff_all_sq: 5.793946264130268e-07\n",
            "E_IS_SCOPE: -1.0204611607333337e-05\n",
            "E_IS_E_SCOPE: -8.891519487590294e-06\n",
            "Total Loss: -1.4071754557094975e-08\n",
            "----------------------------------------\n",
            "Epoch 75\n",
            "Var loss:  tensor(-1.4331e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0909028504966113e-06\n",
            "E_s_wdiff_all_sq: 5.998950380494457e-07\n",
            "E_IS_SCOPE: -1.0233972282377307e-05\n",
            "E_IS_E_SCOPE: -8.918741358588417e-06\n",
            "Total Loss: -1.4330968697198656e-08\n",
            "----------------------------------------\n",
            "Epoch 76\n",
            "Var loss:  tensor(-1.4510e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.109465215007962e-06\n",
            "E_s_wdiff_all_sq: 6.154703433585179e-07\n",
            "E_IS_SCOPE: -1.0253579130586587e-05\n",
            "E_IS_E_SCOPE: -8.936765289734745e-06\n",
            "Total Loss: -1.4509743620823597e-08\n",
            "----------------------------------------\n",
            "Epoch 77\n",
            "Var loss:  tensor(-1.4764e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.1087995336194855e-06\n",
            "E_s_wdiff_all_sq: 6.155301512283624e-07\n",
            "E_IS_SCOPE: -1.0246530105306173e-05\n",
            "E_IS_E_SCOPE: -8.929951883834188e-06\n",
            "Total Loss: -1.4763994119431213e-08\n",
            "----------------------------------------\n",
            "Epoch 78\n",
            "Var loss:  tensor(-1.5028e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.093237095393229e-06\n",
            "E_s_wdiff_all_sq: 6.034111063565782e-07\n",
            "E_IS_SCOPE: -1.0219937106723515e-05\n",
            "E_IS_E_SCOPE: -8.904948493532769e-06\n",
            "Total Loss: -1.5028170911426167e-08\n",
            "----------------------------------------\n",
            "Epoch 79\n",
            "Var loss:  tensor(-1.5221e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.078180154434319e-06\n",
            "E_s_wdiff_all_sq: 5.91307000361544e-07\n",
            "E_IS_SCOPE: -1.019520344627778e-05\n",
            "E_IS_E_SCOPE: -8.88159497871888e-06\n",
            "Total Loss: -1.5220714611610247e-08\n",
            "----------------------------------------\n",
            "Epoch 80\n",
            "Var loss:  tensor(-1.5450e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.076155542762418e-06\n",
            "E_s_wdiff_all_sq: 5.893733451721251e-07\n",
            "E_IS_SCOPE: -1.0190543106159438e-05\n",
            "E_IS_E_SCOPE: -8.87686543224567e-06\n",
            "Total Loss: -1.545008380382493e-08\n",
            "----------------------------------------\n",
            "Epoch 81\n",
            "Var loss:  tensor(-1.5716e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0864177772724906e-06\n",
            "E_s_wdiff_all_sq: 5.971980885534593e-07\n",
            "E_IS_SCOPE: -1.0205015559041124e-05\n",
            "E_IS_E_SCOPE: -8.88998623011595e-06\n",
            "Total Loss: -1.5715902697901463e-08\n",
            "----------------------------------------\n",
            "Epoch 82\n",
            "Var loss:  tensor(-1.5931e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0969009367687504e-06\n",
            "E_s_wdiff_all_sq: 6.052145464012129e-07\n",
            "E_IS_SCOPE: -1.0222006612789805e-05\n",
            "E_IS_E_SCOPE: -8.905636546449801e-06\n",
            "Total Loss: -1.593067587905463e-08\n",
            "----------------------------------------\n",
            "Epoch 83\n",
            "Var loss:  tensor(-1.6155e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0955619619847117e-06\n",
            "E_s_wdiff_all_sq: 6.03834491251812e-07\n",
            "E_IS_SCOPE: -1.0222915566011725e-05\n",
            "E_IS_E_SCOPE: -8.906412696594876e-06\n",
            "Total Loss: -1.6155201667381245e-08\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-a8a140889831>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel12\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_var_play\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded_state_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates_first_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates_last_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-34-4dcebd0cbd6f>\u001b[0m in \u001b[0;36mtrain_var_play\u001b[0;34m(model, num_epochs, learning_rate, padded_state_tensors, states_first_tensor, states_last_tensor, samples_all_shaping, samples_IS_SCOPE, test1)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, samples_all_shaping, samples_IS_SCOPE = test1.bootstrap_shaping_terms(sums_states_weight_diff, gamma_weights_states_last_sub_states_first, IS_tensor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0msamples_IS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_sums_states_weight_diff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_gamma_weight_states_last_sub_states_first\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_all_shaping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_IS_SCOPE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbootstrap_all_terms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msums_states_weight_diff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma_weights_states_last_sub_states_first\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIS_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-314ae88ec427>\u001b[0m in \u001b[0;36mbootstrap_all_terms\u001b[0;34m(self, sums_states_weight_diff, gamma_weights_states_last_sub_states_first, IS_tensor)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;31m# Sample indices with replacement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0msampled_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msums_states_weight_diff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_bootstraps_lin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mreshaped_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msums_states_weight_diff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Greater policy randomness in pi_b"
      ],
      "metadata": {
        "id": "mw24KxKZ4l8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b = action_probs_top_n_epsilon(q_table, 2, 0.4)\n",
        "pi_b = experiment_actions(200, env, P_pi_b)\n",
        "P_pi_e = action_probs_top_n_epsilon(q_table, 1, 0.05)\n",
        "pi_e = experiment_actions(200, env, P_pi_e)\n",
        "model_200_2_p4 = CustomizableFeatureNet(input_dim=2, hidden_dims=[16, 32], output_dim=1, dtype = torch.float64)\n",
        "testing = SCOPE_variance_play(model_200_2_p4, 0.9, 10000, pi_b, P_pi_b, P_pi_e, dtype = torch.float64)\n",
        "IS_tensor, padded_state_tensors, padded_weight_diff_tensors, gamma_weights_last_tensor, states_first_tensor, states_last_tensor, weight_first_tensor = testing.prepare()\n"
      ],
      "metadata": {
        "id": "Qsp5-eqR4owZ"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "timesteps, states, states_first, states_last, actions, rewards, gamma_last, weights_last, weights, weights_difference, weights_first = testing.prep_policies()"
      ],
      "metadata": {
        "id": "8ysYBr-r-AFW"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that the variance within trajectories is quite low, which keeps the variance quite low, might need to consider normalizing in some manner, found this function of PDIS that does this based on maximum and minimum possible discounted reward\n",
        "\n",
        "https://github.com/hari-sikchi/safeRL/blob/master/importance_sampling/importance_sampling.py\n",
        "\n"
      ],
      "metadata": {
        "id": "SNvSFJCaOD_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# '''\n",
        "# Per Decision Importance Sampling\n",
        "# reward: list of reward obtained per time step\n",
        "\n",
        "# gamma: discount factor\n",
        "# trajectory_reward_high: Maximum value of sum of discounted rewards in a trajectory\n",
        "# trajectory_reward_low: Minimum value of sum of discounted rewards in a trajectory\n",
        "\n",
        "# returns normalized estimate of reward under evaluation policy\n",
        "# '''\n",
        "\n",
        "# def per_decision_is(pi_b,pi_e,gamma,reward,trajectory_reward_high,trajectory_reward_low):\n",
        "#     horizon = len(reward)\n",
        "#     expected_reward = 0\n",
        "#     gamma_t = 1\n",
        "#     importance_weight = 1\n",
        "#     for t in range(1,horizon+1):\n",
        "#         importance_weight *= pi_e[t-1]/pi_b[t-1]\n",
        "#         expected_reward+= gamma_t * reward[t-1] *importance_weight\n",
        "#         gamma_t *= gamma\n",
        "\n",
        "#     return (expected_reward - trajectory_reward_low)/(trajectory_reward_high-trajectory_reward_low)"
      ],
      "metadata": {
        "id": "DYBdIiUKOP0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trajectory_reward_high = 0.9**16 * 1\n",
        "trajectory_reward_low = 0.9**7 * -1"
      ],
      "metadata": {
        "id": "jd8aOsLxVciK"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "0.9**80"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBzJV2LgXRRC",
        "outputId": "fb3ecaab-6753-4e24-be15-a207f564c369"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.00021847450052839255"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trajectory_reward_high"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZdhy9nIXAx-",
        "outputId": "c6ff4c60-09dd-4e07-fece-c372bb48a974"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.18530201888518416"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trajectory_reward_low"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKjqsz0hXD-s",
        "outputId": "48e2a73c-d7e8-4071-e919-3d6d09947e07"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.4782969000000001"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(trajectory_reward_high-trajectory_reward_low)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CLW6JGnW-Xc",
        "outputId": "3f557d92-d255-4a04-9f3a-84a5b61c9249"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6635989188851843"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cum_ratio = 1\n",
        "cumul_weights = []\n",
        "P_pi_e_probs = []\n",
        "P_pi_b_probs = []\n",
        "\n",
        "for step in pi_b[0]:\n",
        "    P_pi_b_prob = P_pi_b[tuple(np.append(step[0].astype(int), (step[1],)))]\n",
        "    P_pi_e_prob = P_pi_e[tuple(np.append(step[0].astype(int), (step[1],)))]\n",
        "\n",
        "    P_pi_b_probs.append(P_pi_b_prob)\n",
        "    P_pi_e_probs.append(P_pi_e_prob)\n",
        "\n",
        "    ratio = P_pi_e_prob / P_pi_b_prob\n",
        "    cum_ratio *= ratio\n",
        "    cumul_weights.append(cum_ratio)\n"
      ],
      "metadata": {
        "id": "aJX3KvmBZzvy"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b_probs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8eE5sZAani4",
        "outputId": "59e0dfba-52dc-4ab6-e06f-8df805397465"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.38,\n",
              " 0.08,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.08,\n",
              " 0.38,\n",
              " 0.08,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.08,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.08,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.08,\n",
              " 0.08,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.08,\n",
              " 0.38,\n",
              " 0.38]"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_e[2,8,0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HHyVC2nbugu",
        "outputId": "9078bda2-0225-44bc-af77-6a1bc4bc47fb"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.01"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pi_b[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eb9-8ChfbIP9",
        "outputId": "17463c14-6ac0-471a-f9b5-c613ebd1c11e"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([([2., 9.], 1, 0., [2., 8.],  0, 3.),\n",
              "       ([2., 8.], 0, 0., [2., 8.],  1, 3.),\n",
              "       ([2., 8.], 1, 0., [2., 7.],  2, 3.),\n",
              "       ([2., 7.], 1, 0., [2., 6.],  3, 3.),\n",
              "       ([2., 6.], 3, 0., [1., 6.],  4, 3.),\n",
              "       ([1., 6.], 2, 0., [1., 7.],  5, 4.),\n",
              "       ([1., 7.], 3, 0., [0., 7.],  6, 4.),\n",
              "       ([0., 7.], 0, 0., [0., 7.],  7, 5.),\n",
              "       ([0., 7.], 1, 0., [0., 6.],  8, 5.),\n",
              "       ([0., 6.], 3, 0., [0., 6.],  9, 5.),\n",
              "       ([0., 6.], 1, 0., [0., 5.], 10, 5.),\n",
              "       ([0., 5.], 1, 0., [0., 4.], 11, 5.),\n",
              "       ([0., 4.], 1, 0., [0., 3.], 12, 6.),\n",
              "       ([0., 3.], 2, 0., [0., 4.], 13, 7.),\n",
              "       ([0., 4.], 1, 0., [0., 3.], 14, 6.),\n",
              "       ([0., 3.], 4, 0., [1., 3.], 15, 7.),\n",
              "       ([1., 3.], 0, 0., [1., 3.], 16, 6.),\n",
              "       ([1., 3.], 2, 0., [1., 4.], 17, 6.),\n",
              "       ([1., 4.], 0, 0., [1., 4.], 18, 5.),\n",
              "       ([1., 4.], 0, 0., [1., 4.], 19, 5.),\n",
              "       ([1., 4.], 0, 0., [1., 4.], 20, 5.),\n",
              "       ([1., 4.], 0, 0., [1., 4.], 21, 5.),\n",
              "       ([1., 4.], 1, 0., [1., 3.], 22, 5.),\n",
              "       ([1., 3.], 0, 0., [1., 3.], 23, 6.),\n",
              "       ([1., 3.], 0, 0., [1., 3.], 24, 6.),\n",
              "       ([1., 3.], 2, 0., [1., 4.], 25, 6.),\n",
              "       ([1., 4.], 0, 0., [1., 4.], 26, 5.),\n",
              "       ([1., 4.], 1, 0., [1., 3.], 27, 5.),\n",
              "       ([1., 3.], 4, 0., [2., 3.], 28, 6.),\n",
              "       ([2., 3.], 1, 0., [2., 2.], 29, 5.),\n",
              "       ([2., 2.], 4, 0., [3., 2.], 30, 6.),\n",
              "       ([3., 2.], 4, 0., [4., 2.], 31, 5.),\n",
              "       ([4., 2.], 4, 0., [5., 2.], 32, 4.),\n",
              "       ([5., 2.], 3, 0., [4., 2.], 33, 3.),\n",
              "       ([4., 2.], 1, 0., [4., 1.], 34, 4.),\n",
              "       ([4., 1.], 0, 0., [4., 1.], 35, 5.),\n",
              "       ([4., 1.], 0, 0., [4., 1.], 36, 5.),\n",
              "       ([4., 1.], 0, 0., [4., 1.], 37, 5.),\n",
              "       ([4., 1.], 4, 0., [5., 1.], 38, 5.),\n",
              "       ([5., 1.], 0, 0., [5., 1.], 39, 4.),\n",
              "       ([5., 1.], 4, 0., [6., 1.], 40, 4.),\n",
              "       ([6., 1.], 3, 0., [5., 1.], 41, 4.),\n",
              "       ([5., 1.], 1, 1., [5., 0.], 42, 4.)],\n",
              "      dtype=[('state', '<f8', (2,)), ('action', '<i8'), ('reward', '<f8'), ('state_next', '<f8', (2,)), ('timestep', '<i8'), ('psi', '<f8')])"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_e_probs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFZBF-V1av1q",
        "outputId": "029d57c9-0f53-4a66-f73d-a0b74b29ffd9"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.01,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.96,\n",
              " 0.01,\n",
              " 0.96,\n",
              " 0.01,\n",
              " 0.96,\n",
              " 0.01,\n",
              " 0.96,\n",
              " 0.96,\n",
              " 0.01,\n",
              " 0.96,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.96,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.96,\n",
              " 0.96,\n",
              " 0.96,\n",
              " 0.96,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.96,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.96,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.96]"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pi_b[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHWedeeOZhg2",
        "outputId": "1d5f68a3-3695-475f-f14b-d7dda7f91c44"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([([2., 9.], 1, 0., [2., 8.],  0, 3.),\n",
              "       ([2., 8.], 0, 0., [2., 8.],  1, 3.),\n",
              "       ([2., 8.], 1, 0., [2., 7.],  2, 3.),\n",
              "       ([2., 7.], 1, 0., [2., 6.],  3, 3.),\n",
              "       ([2., 6.], 3, 0., [1., 6.],  4, 3.),\n",
              "       ([1., 6.], 2, 0., [1., 7.],  5, 4.),\n",
              "       ([1., 7.], 3, 0., [0., 7.],  6, 4.),\n",
              "       ([0., 7.], 0, 0., [0., 7.],  7, 5.),\n",
              "       ([0., 7.], 1, 0., [0., 6.],  8, 5.),\n",
              "       ([0., 6.], 3, 0., [0., 6.],  9, 5.),\n",
              "       ([0., 6.], 1, 0., [0., 5.], 10, 5.),\n",
              "       ([0., 5.], 1, 0., [0., 4.], 11, 5.),\n",
              "       ([0., 4.], 1, 0., [0., 3.], 12, 6.),\n",
              "       ([0., 3.], 2, 0., [0., 4.], 13, 7.),\n",
              "       ([0., 4.], 1, 0., [0., 3.], 14, 6.),\n",
              "       ([0., 3.], 4, 0., [1., 3.], 15, 7.),\n",
              "       ([1., 3.], 0, 0., [1., 3.], 16, 6.),\n",
              "       ([1., 3.], 2, 0., [1., 4.], 17, 6.),\n",
              "       ([1., 4.], 0, 0., [1., 4.], 18, 5.),\n",
              "       ([1., 4.], 0, 0., [1., 4.], 19, 5.),\n",
              "       ([1., 4.], 0, 0., [1., 4.], 20, 5.),\n",
              "       ([1., 4.], 0, 0., [1., 4.], 21, 5.),\n",
              "       ([1., 4.], 1, 0., [1., 3.], 22, 5.),\n",
              "       ([1., 3.], 0, 0., [1., 3.], 23, 6.),\n",
              "       ([1., 3.], 0, 0., [1., 3.], 24, 6.),\n",
              "       ([1., 3.], 2, 0., [1., 4.], 25, 6.),\n",
              "       ([1., 4.], 0, 0., [1., 4.], 26, 5.),\n",
              "       ([1., 4.], 1, 0., [1., 3.], 27, 5.),\n",
              "       ([1., 3.], 4, 0., [2., 3.], 28, 6.),\n",
              "       ([2., 3.], 1, 0., [2., 2.], 29, 5.),\n",
              "       ([2., 2.], 4, 0., [3., 2.], 30, 6.),\n",
              "       ([3., 2.], 4, 0., [4., 2.], 31, 5.),\n",
              "       ([4., 2.], 4, 0., [5., 2.], 32, 4.),\n",
              "       ([5., 2.], 3, 0., [4., 2.], 33, 3.),\n",
              "       ([4., 2.], 1, 0., [4., 1.], 34, 4.),\n",
              "       ([4., 1.], 0, 0., [4., 1.], 35, 5.),\n",
              "       ([4., 1.], 0, 0., [4., 1.], 36, 5.),\n",
              "       ([4., 1.], 0, 0., [4., 1.], 37, 5.),\n",
              "       ([4., 1.], 4, 0., [5., 1.], 38, 5.),\n",
              "       ([5., 1.], 0, 0., [5., 1.], 39, 4.),\n",
              "       ([5., 1.], 4, 0., [6., 1.], 40, 4.),\n",
              "       ([6., 1.], 3, 0., [5., 1.], 41, 4.),\n",
              "       ([5., 1.], 1, 1., [5., 0.], 42, 4.)],\n",
              "      dtype=[('state', '<f8', (2,)), ('action', '<i8'), ('reward', '<f8'), ('state_next', '<f8', (2,)), ('timestep', '<i8'), ('psi', '<f8')])"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aWPsckKYhao",
        "outputId": "10ac346c-55c2-4009-ccdc-57572fd970ca"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.02631578947368421,\n",
              " 0.003289473684210526,\n",
              " 8.656509695290857e-05,\n",
              " 2.2780288671818044e-06,\n",
              " 5.755020296038243e-06,\n",
              " 7.193775370047803e-07,\n",
              " 1.817374830327866e-06,\n",
              " 2.2717185379098326e-07,\n",
              " 5.739078411561682e-07,\n",
              " 1.510283792516232e-08,\n",
              " 3.815453791619955e-08,\n",
              " 9.639041157776727e-08,\n",
              " 2.5365897783622966e-09,\n",
              " 6.408226808494222e-09,\n",
              " 1.686375475919532e-10,\n",
              " 4.437830199788242e-12,\n",
              " 1.167850052575853e-13,\n",
              " 1.4598125657198164e-14,\n",
              " 3.841612015052148e-16,\n",
              " 1.010950530276881e-17,\n",
              " 2.6603961323075813e-19,\n",
              " 7.001042453441003e-21,\n",
              " 1.7686844092903583e-20,\n",
              " 4.654432656027258e-22,\n",
              " 1.2248506989545416e-23,\n",
              " 1.531063373693177e-24,\n",
              " 4.029114141297834e-26,\n",
              " 1.0178814672752422e-25,\n",
              " 2.571490022590085e-25,\n",
              " 6.496395846543372e-25,\n",
              " 1.6411947401793782e-24,\n",
              " 2.0514934252242227e-25,\n",
              " 2.5643667815302784e-26,\n",
              " 6.748333635605995e-28,\n",
              " 1.7048421816267776e-27,\n",
              " 4.4864267937546775e-29,\n",
              " 1.1806386299354413e-30,\n",
              " 3.1069437629880036e-32,\n",
              " 7.849121085443377e-32,\n",
              " 2.065558180379836e-33,\n",
              " 2.581947725474795e-34,\n",
              " 6.79459927756525e-36,\n",
              " 1.7165303438059576e-35]"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IS_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gW62FfxyPmXv",
        "outputId": "0bd68c05-652b-4bf9-9b2b-7f685da4acf6"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2.0551e-37],\n",
              "        [-4.8452e-12],\n",
              "        [ 3.4739e-26],\n",
              "        [ 1.9805e-52],\n",
              "        [ 5.6599e-30],\n",
              "        [ 3.6186e-28],\n",
              "        [ 1.2260e-37],\n",
              "        [ 3.3817e-61],\n",
              "        [ 4.8221e-73],\n",
              "        [ 8.0587e-33],\n",
              "        [ 2.3787e-34],\n",
              "        [ 2.5989e-18],\n",
              "        [ 1.1778e-45],\n",
              "        [ 1.5114e-51],\n",
              "        [ 1.0731e-23],\n",
              "        [ 3.1264e-31],\n",
              "        [ 4.8743e-37],\n",
              "        [ 6.9782e-22],\n",
              "        [ 7.5361e-54],\n",
              "        [ 6.3329e-16],\n",
              "        [ 2.5512e-42],\n",
              "        [ 2.8200e-22],\n",
              "        [ 1.0058e-30],\n",
              "        [ 3.5798e-20],\n",
              "        [ 4.5442e-51],\n",
              "        [ 2.2281e-20],\n",
              "        [ 1.8043e-30],\n",
              "        [ 1.2700e-46],\n",
              "        [ 1.1456e-37],\n",
              "        [ 6.1262e-48],\n",
              "        [ 2.1988e-26],\n",
              "        [ 9.2430e-31],\n",
              "        [ 7.5947e-22],\n",
              "        [ 1.7820e-57],\n",
              "        [ 5.8006e-42],\n",
              "        [ 1.3517e-53],\n",
              "        [ 3.3349e-24],\n",
              "        [ 2.6211e-40],\n",
              "        [ 3.5798e-20],\n",
              "        [ 4.9731e-44],\n",
              "        [ 1.4578e-21],\n",
              "        [ 1.0805e-47],\n",
              "        [ 4.2534e-27],\n",
              "        [ 5.4923e-36],\n",
              "        [ 6.1497e-65],\n",
              "        [ 4.9654e-13],\n",
              "        [ 5.3505e-26],\n",
              "        [ 8.9888e-45],\n",
              "        [ 5.7611e-29],\n",
              "        [ 7.7836e-34],\n",
              "        [ 1.5779e-72],\n",
              "        [ 1.0404e-41],\n",
              "        [ 2.3371e-46],\n",
              "        [ 9.4352e-81],\n",
              "        [ 3.2290e-11],\n",
              "        [ 4.4306e-29],\n",
              "        [ 3.4365e-51],\n",
              "        [ 1.2925e-56],\n",
              "        [ 2.5025e-12],\n",
              "        [ 4.0775e-27],\n",
              "        [ 2.8678e-22],\n",
              "        [ 1.2222e-30],\n",
              "        [ 1.4578e-21],\n",
              "        [ 2.2871e-63],\n",
              "        [ 5.4835e-38],\n",
              "        [ 3.2514e-35],\n",
              "        [ 1.7018e-40],\n",
              "        [ 2.5809e-27],\n",
              "        [ 2.1988e-26],\n",
              "        [ 4.2534e-27],\n",
              "        [ 2.5513e-09],\n",
              "        [ 7.7239e-33],\n",
              "        [ 1.1193e-56],\n",
              "        [ 1.7781e-38],\n",
              "        [ 1.2334e-29],\n",
              "        [ 4.0584e-22],\n",
              "        [ 3.5443e-33],\n",
              "        [ 8.8318e-24],\n",
              "        [ 9.1998e-26],\n",
              "        [ 2.5722e-86],\n",
              "        [ 6.8861e-61],\n",
              "        [ 1.8365e-18],\n",
              "        [ 7.6832e-51],\n",
              "        [ 2.4021e-76],\n",
              "        [ 1.3793e-38],\n",
              "        [ 2.0899e-37],\n",
              "        [ 7.6941e-49],\n",
              "        [ 1.6463e-39],\n",
              "        [ 2.2380e-14],\n",
              "        [ 3.2414e-28],\n",
              "        [ 7.0866e-68],\n",
              "        [ 5.7293e-36],\n",
              "        [ 5.2929e-51],\n",
              "        [ 5.2887e-74],\n",
              "        [ 2.3062e-41],\n",
              "        [ 1.6414e-43],\n",
              "        [-3.4057e-30],\n",
              "        [ 8.8247e-03],\n",
              "        [ 1.7765e-50],\n",
              "        [ 4.9887e-18],\n",
              "        [ 4.0674e-41],\n",
              "        [ 1.0160e-17],\n",
              "        [ 1.5528e-49],\n",
              "        [ 2.1922e-30],\n",
              "        [ 3.8162e-69],\n",
              "        [ 7.2350e-19],\n",
              "        [ 2.5045e-33],\n",
              "        [ 3.4055e-19],\n",
              "        [ 2.3513e-05],\n",
              "        [ 5.0422e-48],\n",
              "        [ 6.8240e-29],\n",
              "        [ 9.3633e-47],\n",
              "        [ 8.3418e-32],\n",
              "        [ 2.2923e-49],\n",
              "        [ 2.1254e-37],\n",
              "        [ 3.5520e-41],\n",
              "        [ 8.3229e-46],\n",
              "        [ 1.3941e-35],\n",
              "        [ 4.6152e-31],\n",
              "        [ 2.9757e-40],\n",
              "        [ 3.0548e-17],\n",
              "        [ 3.3840e-49],\n",
              "        [ 5.2120e-49],\n",
              "        [ 5.1606e-29],\n",
              "        [ 4.2992e-68],\n",
              "        [ 5.9680e-38],\n",
              "        [ 1.3750e-31],\n",
              "        [ 1.4399e-15],\n",
              "        [ 1.3528e-41],\n",
              "        [ 2.8285e-18],\n",
              "        [ 7.7903e-22],\n",
              "        [ 3.3477e-41],\n",
              "        [ 3.0735e-20],\n",
              "        [ 1.8867e-49],\n",
              "        [ 8.1149e-24],\n",
              "        [ 1.3770e-29],\n",
              "        [ 7.7060e-80],\n",
              "        [ 4.4817e-80],\n",
              "        [ 4.5307e-22],\n",
              "        [ 3.2290e-11],\n",
              "        [ 1.6822e-11],\n",
              "        [ 7.6477e-13],\n",
              "        [ 1.4522e-37],\n",
              "        [ 2.5868e-13],\n",
              "        [ 2.8458e-21],\n",
              "        [ 2.2885e-40],\n",
              "        [ 5.8138e-28],\n",
              "        [ 5.9731e-26],\n",
              "        [ 2.7447e-57],\n",
              "        [ 2.6010e-39],\n",
              "        [ 9.6121e-24],\n",
              "        [ 4.9462e-29],\n",
              "        [ 3.8070e-50],\n",
              "        [ 9.5384e-23],\n",
              "        [ 2.5220e-24],\n",
              "        [ 2.1554e-52],\n",
              "        [ 3.4233e-34],\n",
              "        [ 6.8237e-62],\n",
              "        [ 3.6295e-24],\n",
              "        [ 1.6450e-18],\n",
              "        [ 5.3580e-24],\n",
              "        [ 1.2908e-69],\n",
              "        [ 3.2891e-53],\n",
              "        [ 5.0490e-79],\n",
              "        [ 7.1123e-41],\n",
              "        [ 2.7154e-16],\n",
              "        [ 2.3602e-55],\n",
              "        [ 1.0796e-26],\n",
              "        [ 1.3395e-21],\n",
              "        [ 2.1420e-16],\n",
              "        [ 1.7903e-51],\n",
              "        [ 8.2912e-29],\n",
              "        [ 1.9561e-46],\n",
              "        [ 1.9367e-59],\n",
              "        [ 1.1474e-35],\n",
              "        [ 2.1940e-51],\n",
              "        [ 4.6369e-36],\n",
              "        [ 7.4787e-20],\n",
              "        [ 5.2844e-53],\n",
              "        [ 9.0940e-41],\n",
              "        [ 9.3196e-42],\n",
              "        [ 8.4854e-43],\n",
              "        [ 1.3373e-12],\n",
              "        [ 8.2775e-64],\n",
              "        [ 9.8046e-64],\n",
              "        [ 5.5902e-24],\n",
              "        [ 1.0955e-51],\n",
              "        [ 7.9969e-32],\n",
              "        [ 5.8862e-34],\n",
              "        [ 9.6572e-29],\n",
              "        [ 9.2704e-60],\n",
              "        [ 8.7830e-31],\n",
              "        [ 5.6165e-29],\n",
              "        [ 3.2864e-32],\n",
              "        [ 1.0880e-27],\n",
              "        [ 7.0969e-33],\n",
              "        [ 4.6944e-75],\n",
              "        [ 3.7112e-83],\n",
              "        [ 1.0191e-46],\n",
              "        [ 6.0707e-49]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.var(IS_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MENIklmqKgq6",
        "outputId": "dadbf702-f264-4417-c359-13f26c689133"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.8937e-07, dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mean(IS_tensor**2) - torch.mean(IS_tensor)**2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjd3r5nCMFWG",
        "outputId": "7411b265-8782-41bf-f250-2a3fd7dda739"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.8742e-07, dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mean(IS_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSBBkdn5LpI0",
        "outputId": "a988c264-2707-486b-956e-c5ba6a45e43a"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.4241e-05, dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(weights[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmC6YFqmHzcL",
        "outputId": "f0ed6cf3-a94f-42da-8a1e-e075b2db1b24"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(weights_difference[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DI1Hfg1JWRu",
        "outputId": "9a4045e7-e683-4fb0-bb34-38db58f495d9"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(pi_b[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FflnxUpHpPC",
        "outputId": "b530f2e9-b988-4d9c-e85e-2e5180146932"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# single cumprod\n",
        "# 200 trajectories\n",
        "model_200_2_p4 = train_var_play(model_200_2_p4, 200, 0.001, padded_state_tensors, states_first_tensor, states_last_tensor, 1, 1, testing)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_WriHen4pWo",
        "outputId": "3662f880-4886-4038-eeb8-608e6f25a4d2"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Var loss:  tensor(1.1985, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 2.297909386211681\n",
            "E_s_wdiff_all_sq: 1.0994508765271211\n",
            "E_IS_SCOPE: 3.878983758204295e-05\n",
            "E_IS_E_SCOPE: 3.843762575160876e-05\n",
            "Total Loss: 1.1984592160084957\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "Var loss:  tensor(0.0416, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.04392587686827187\n",
            "E_s_wdiff_all_sq: 0.0023080316182087575\n",
            "E_IS_SCOPE: -8.007193464295585e-06\n",
            "E_IS_E_SCOPE: -7.634354580536492e-06\n",
            "Total Loss: 0.04161710147257035\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "Var loss:  tensor(0.0388, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.03925886301233597\n",
            "E_s_wdiff_all_sq: 0.0004488434884700709\n",
            "E_IS_SCOPE: -7.451422098909373e-06\n",
            "E_IS_E_SCOPE: -7.078667767300758e-06\n",
            "Total Loss: 0.03880927591547743\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "Var loss:  tensor(0.0362, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.03618221541199196\n",
            "E_s_wdiff_all_sq: 1.5627195795477096e-05\n",
            "E_IS_SCOPE: -6.73635978293311e-06\n",
            "E_IS_E_SCOPE: -6.363300668902292e-06\n",
            "Total Loss: 0.03616584399824317\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "Var loss:  tensor(0.0341, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.03483415076299158\n",
            "E_s_wdiff_all_sq: 0.0007483471171284855\n",
            "E_IS_SCOPE: -5.954896256454207e-06\n",
            "E_IS_E_SCOPE: -5.581613167763779e-06\n",
            "Total Loss: 0.03408505897996047\n",
            "----------------------------------------\n",
            "Epoch 6\n",
            "Var loss:  tensor(0.0327, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.03500008997453642\n",
            "E_s_wdiff_all_sq: 0.002299828566122942\n",
            "E_IS_SCOPE: -5.201083616526263e-06\n",
            "E_IS_E_SCOPE: -4.8279615663606775e-06\n",
            "Total Loss: 0.032699517064587895\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "Var loss:  tensor(0.0319, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.03627056723217435\n",
            "E_s_wdiff_all_sq: 0.004386374656823539\n",
            "E_IS_SCOPE: -4.4822491843661086e-06\n",
            "E_IS_E_SCOPE: -4.109621191323106e-06\n",
            "Total Loss: 0.03188344921963948\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "Var loss:  tensor(0.0315, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.03824929035390946\n",
            "E_s_wdiff_all_sq: 0.006738201877200653\n",
            "E_IS_SCOPE: -3.82324042087388e-06\n",
            "E_IS_E_SCOPE: -3.4514823381124335e-06\n",
            "Total Loss: 0.031510346860818036\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "Var loss:  tensor(0.0314, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.040508941581502686\n",
            "E_s_wdiff_all_sq: 0.009076811804137457\n",
            "E_IS_SCOPE: -3.245941847961306e-06\n",
            "E_IS_E_SCOPE: -2.8754542389428553e-06\n",
            "Total Loss: 0.03143139070242195\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "Var loss:  tensor(0.0315, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.042621271923216415\n",
            "E_s_wdiff_all_sq: 0.011158634778542032\n",
            "E_IS_SCOPE: -2.765903893180527e-06\n",
            "E_IS_E_SCOPE: -2.3967410027452646e-06\n",
            "Total Loss: 0.03146190071916826\n",
            "----------------------------------------\n",
            "Epoch 11\n",
            "Var loss:  tensor(0.0314, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.044266651997166125\n",
            "E_s_wdiff_all_sq: 0.01281841741840197\n",
            "E_IS_SCOPE: -2.389031988940191e-06\n",
            "E_IS_E_SCOPE: -2.0209475150507352e-06\n",
            "Total Loss: 0.03144750031009113\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "Var loss:  tensor(0.0313, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.045239818172975184\n",
            "E_s_wdiff_all_sq: 0.013948519258881251\n",
            "E_IS_SCOPE: -2.1186112441408252e-06\n",
            "E_IS_E_SCOPE: -1.7521169803677011e-06\n",
            "Total Loss: 0.03129056782584114\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "Var loss:  tensor(0.0309, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.0454763667053736\n",
            "E_s_wdiff_all_sq: 0.014534955972714323\n",
            "E_IS_SCOPE: -1.946147086723511e-06\n",
            "E_IS_E_SCOPE: -1.581752904500871e-06\n",
            "Total Loss: 0.030940683844569578\n",
            "----------------------------------------\n",
            "Epoch 14\n",
            "Var loss:  tensor(0.0304, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.044982254200287265\n",
            "E_s_wdiff_all_sq: 0.014590674951117004\n",
            "E_IS_SCOPE: -1.8653044406692305e-06\n",
            "E_IS_E_SCOPE: -1.5035736953486128e-06\n",
            "Total Loss: 0.030390857687954374\n",
            "----------------------------------------\n",
            "Epoch 15\n",
            "Var loss:  tensor(0.0297, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.04385896261366019\n",
            "E_s_wdiff_all_sq: 0.014184396941775479\n",
            "E_IS_SCOPE: -1.8642884714399405e-06\n",
            "E_IS_E_SCOPE: -1.5055700636623406e-06\n",
            "Total Loss: 0.02967385013534391\n",
            "----------------------------------------\n",
            "Epoch 16\n",
            "Var loss:  tensor(0.0288, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.04223117382857745\n",
            "E_s_wdiff_all_sq: 0.013393948540381943\n",
            "E_IS_SCOPE: -1.9327902088660277e-06\n",
            "E_IS_E_SCOPE: -1.5773754704137532e-06\n",
            "Total Loss: 0.02883651635899335\n",
            "----------------------------------------\n",
            "Epoch 17\n",
            "Var loss:  tensor(0.0279, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.040272442555752234\n",
            "E_s_wdiff_all_sq: 0.012329139230491027\n",
            "E_IS_SCOPE: -2.0548381139786605e-06\n",
            "E_IS_E_SCOPE: -1.7029494763619422e-06\n",
            "Total Loss: 0.027942601448260725\n",
            "----------------------------------------\n",
            "Epoch 18\n",
            "Var loss:  tensor(0.0271, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.03815787516764467\n",
            "E_s_wdiff_all_sq: 0.011103359885243462\n",
            "E_IS_SCOPE: -2.214917342017269e-06\n",
            "E_IS_E_SCOPE: -1.8667013467230403e-06\n",
            "Total Loss: 0.027053820750685374\n",
            "----------------------------------------\n",
            "Epoch 19\n",
            "Var loss:  tensor(0.0262, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.036045122030530674\n",
            "E_s_wdiff_all_sq: 0.009819596471660913\n",
            "E_IS_SCOPE: -2.394384643898371e-06\n",
            "E_IS_E_SCOPE: -2.049887566771903e-06\n",
            "Total Loss: 0.026224838464990262\n",
            "----------------------------------------\n",
            "Epoch 20\n",
            "Var loss:  tensor(0.0255, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.034048284507499645\n",
            "E_s_wdiff_all_sq: 0.00856380955915508\n",
            "E_IS_SCOPE: -2.578006777514063e-06\n",
            "E_IS_E_SCOPE: -2.2373787193848528e-06\n",
            "Total Loss: 0.025483795592503057\n",
            "----------------------------------------\n",
            "Epoch 21\n",
            "Var loss:  tensor(0.0248, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.03210011705996097\n",
            "E_s_wdiff_all_sq: 0.007265569052274326\n",
            "E_IS_SCOPE: -2.7869321418720623e-06\n",
            "E_IS_E_SCOPE: -2.4503620409244804e-06\n",
            "Total Loss: 0.024833876767759503\n",
            "----------------------------------------\n",
            "Epoch 22\n",
            "Var loss:  tensor(0.0243, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.03035880143875993\n",
            "E_s_wdiff_all_sq: 0.0060609501289704635\n",
            "E_IS_SCOPE: -2.9886672191389325e-06\n",
            "E_IS_E_SCOPE: -2.656169330458181e-06\n",
            "Total Loss: 0.024297188214286856\n",
            "----------------------------------------\n",
            "Epoch 23\n",
            "Var loss:  tensor(0.0239, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.028893437377904292\n",
            "E_s_wdiff_all_sq: 0.005036224433765073\n",
            "E_IS_SCOPE: -3.1565300334446345e-06\n",
            "E_IS_E_SCOPE: -2.8279737328275426e-06\n",
            "Total Loss: 0.023856557731812736\n",
            "----------------------------------------\n",
            "Epoch 24\n",
            "Var loss:  tensor(0.0235, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.027683324209120598\n",
            "E_s_wdiff_all_sq: 0.00420977443350421\n",
            "E_IS_SCOPE: -3.2748137328653198e-06\n",
            "E_IS_E_SCOPE: -2.9499748416950865e-06\n",
            "Total Loss: 0.023472901998108798\n",
            "----------------------------------------\n",
            "Epoch 25\n",
            "Var loss:  tensor(0.0231, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.026686837610308146\n",
            "E_s_wdiff_all_sq: 0.0035836433560412716\n",
            "E_IS_SCOPE: -3.331727970206348e-06\n",
            "E_IS_E_SCOPE: -3.0105376470245005e-06\n",
            "Total Loss: 0.023102553773895265\n",
            "----------------------------------------\n",
            "Epoch 26\n",
            "Var loss:  tensor(0.0227, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.025847027049085376\n",
            "E_s_wdiff_all_sq: 0.003139009703658511\n",
            "E_IS_SCOPE: -3.321684196379081e-06\n",
            "E_IS_E_SCOPE: -3.0038344210674964e-06\n",
            "Total Loss: 0.02270738354615099\n",
            "----------------------------------------\n",
            "Epoch 27\n",
            "Var loss:  tensor(0.0223, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.025110536788134106\n",
            "E_s_wdiff_all_sq: 0.0028530780417820333\n",
            "E_IS_SCOPE: -3.2439638220504366e-06\n",
            "E_IS_E_SCOPE: -2.9291155523118645e-06\n",
            "Total Loss: 0.022256830950087344\n",
            "----------------------------------------\n",
            "Epoch 28\n",
            "Var loss:  tensor(0.0217, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.02445254827845828\n",
            "E_s_wdiff_all_sq: 0.0027121430335832987\n",
            "E_IS_SCOPE: -3.0950811895847455e-06\n",
            "E_IS_E_SCOPE: -2.7828293869470027e-06\n",
            "Total Loss: 0.021739782641544456\n",
            "----------------------------------------\n",
            "Epoch 29\n",
            "Var loss:  tensor(0.0212, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.023862469079324513\n",
            "E_s_wdiff_all_sq: 0.002687277465738614\n",
            "E_IS_SCOPE: -2.8846996881920006e-06\n",
            "E_IS_E_SCOPE: -2.5747940778952074e-06\n",
            "Total Loss: 0.02117457370264006\n",
            "----------------------------------------\n",
            "Epoch 30\n",
            "Var loss:  tensor(0.0206, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.02334199743582177\n",
            "E_s_wdiff_all_sq: 0.00275876791942823\n",
            "E_IS_SCOPE: -2.6212076654539654e-06\n",
            "E_IS_E_SCOPE: -2.3133736047279843e-06\n",
            "Total Loss: 0.020582615748546838\n",
            "----------------------------------------\n",
            "Epoch 31\n",
            "Var loss:  tensor(0.0200, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.0228877954925864\n",
            "E_s_wdiff_all_sq: 0.00290140251193011\n",
            "E_IS_SCOPE: -2.3180876457147406e-06\n",
            "E_IS_E_SCOPE: -2.0120692325446993e-06\n",
            "Total Loss: 0.019985782844104703\n",
            "----------------------------------------\n",
            "Epoch 32\n",
            "Var loss:  tensor(0.0194, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.022499263463222115\n",
            "E_s_wdiff_all_sq: 0.0030931384249713507\n",
            "E_IS_SCOPE: -1.9912770986092742e-06\n",
            "E_IS_E_SCOPE: -1.686844240184114e-06\n",
            "Total Loss: 0.019405518072808665\n",
            "----------------------------------------\n",
            "Epoch 33\n",
            "Var loss:  tensor(0.0189, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.02218138527822573\n",
            "E_s_wdiff_all_sq: 0.003315533238852356\n",
            "E_IS_SCOPE: -1.6519068431043025e-06\n",
            "E_IS_E_SCOPE: -1.3489632049508678e-06\n",
            "Total Loss: 0.018865248052371816\n",
            "----------------------------------------\n",
            "Epoch 34\n",
            "Var loss:  tensor(0.0184, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.021939676598509893\n",
            "E_s_wdiff_all_sq: 0.00357011099691371\n",
            "E_IS_SCOPE: -1.3011227865717189e-06\n",
            "E_IS_E_SCOPE: -1.0006736465147596e-06\n",
            "Total Loss: 0.01836896660359082\n",
            "----------------------------------------\n",
            "Epoch 35\n",
            "Var loss:  tensor(0.0179, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.02169695958143122\n",
            "E_s_wdiff_all_sq: 0.003766596027349277\n",
            "E_IS_SCOPE: -9.76442423531455e-07\n",
            "E_IS_E_SCOPE: -6.791607499717546e-07\n",
            "Total Loss: 0.01792977089100958\n",
            "----------------------------------------\n",
            "Epoch 36\n",
            "Var loss:  tensor(0.0175, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.021367123602767508\n",
            "E_s_wdiff_all_sq: 0.00384817055518921\n",
            "E_IS_SCOPE: -6.995754675542332e-07\n",
            "E_IS_E_SCOPE: -4.0584075933746697e-07\n",
            "Total Loss: 0.017518367478436617\n",
            "----------------------------------------\n",
            "Epoch 37\n",
            "Var loss:  tensor(0.0171, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.02084119261402764\n",
            "E_s_wdiff_all_sq: 0.003728740153148207\n",
            "E_IS_SCOPE: -4.962908312687996e-07\n",
            "E_IS_E_SCOPE: -2.0787027719281508e-07\n",
            "Total Loss: 0.01711187752004603\n",
            "----------------------------------------\n",
            "Epoch 38\n",
            "Var loss:  tensor(0.0167, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.02015661990200089\n",
            "E_s_wdiff_all_sq: 0.003452574263615173\n",
            "E_IS_SCOPE: -3.5428511539102974e-07\n",
            "E_IS_E_SCOPE: -7.174935513163259e-08\n",
            "Total Loss: 0.01670348246713995\n",
            "----------------------------------------\n",
            "Epoch 39\n",
            "Var loss:  tensor(0.0163, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.019171650322192545\n",
            "E_s_wdiff_all_sq: 0.002899953543942618\n",
            "E_IS_SCOPE: -3.236982939354758e-07\n",
            "E_IS_E_SCOPE: -4.786063992429541e-08\n",
            "Total Loss: 0.016271147003216656\n",
            "----------------------------------------\n",
            "Epoch 40\n",
            "Var loss:  tensor(0.0158, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.01816520961836425\n",
            "E_s_wdiff_all_sq: 0.0023204547289400346\n",
            "E_IS_SCOPE: -3.259520373806938e-07\n",
            "E_IS_E_SCOPE: -5.7348620134436905e-08\n",
            "Total Loss: 0.01584421958286447\n",
            "----------------------------------------\n",
            "Epoch 41\n",
            "Var loss:  tensor(0.0155, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.017220117575009262\n",
            "E_s_wdiff_all_sq: 0.0017643030091933796\n",
            "E_IS_SCOPE: -3.5217191558103625e-07\n",
            "E_IS_E_SCOPE: -9.12109017177355e-08\n",
            "Total Loss: 0.015455294544062907\n",
            "----------------------------------------\n",
            "Epoch 42\n",
            "Var loss:  tensor(0.0151, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.016420745982184005\n",
            "E_s_wdiff_all_sq: 0.001303225480171744\n",
            "E_IS_SCOPE: -3.719972859653301e-07\n",
            "E_IS_E_SCOPE: -1.2056273848951452e-07\n",
            "Total Loss: 0.015117019533192059\n",
            "----------------------------------------\n",
            "Epoch 43\n",
            "Var loss:  tensor(0.0148, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.01576500741449024\n",
            "E_s_wdiff_all_sq: 0.0009415106538215532\n",
            "E_IS_SCOPE: -3.5853933490358923e-07\n",
            "E_IS_E_SCOPE: -1.1643066324927331e-07\n",
            "Total Loss: 0.01482301444360013\n",
            "----------------------------------------\n",
            "Epoch 44\n",
            "Var loss:  tensor(0.0145, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.015234540157521206\n",
            "E_s_wdiff_all_sq: 0.0006907269713655656\n",
            "E_IS_SCOPE: -3.0736108187771806e-07\n",
            "E_IS_E_SCOPE: -7.377243254886983e-08\n",
            "Total Loss: 0.014543347909131737\n",
            "----------------------------------------\n",
            "Epoch 45\n",
            "Var loss:  tensor(0.0143, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.014775702376684519\n",
            "E_s_wdiff_all_sq: 0.000515355339383985\n",
            "E_IS_SCOPE: -2.3301816794342082e-07\n",
            "E_IS_E_SCOPE: -7.519761420032742e-09\n",
            "Total Loss: 0.014259897940762241\n",
            "----------------------------------------\n",
            "Epoch 46\n",
            "Var loss:  tensor(0.0140, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.014392534465630536\n",
            "E_s_wdiff_all_sq: 0.00042761431519573815\n",
            "E_IS_SCOPE: -1.049192526817825e-07\n",
            "E_IS_E_SCOPE: 1.1335665116636626e-07\n",
            "Total Loss: 0.013964485498901856\n",
            "----------------------------------------\n",
            "Epoch 47\n",
            "Var loss:  tensor(0.0137, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.014067031877123798\n",
            "E_s_wdiff_all_sq: 0.00040057910337717485\n",
            "E_IS_SCOPE: 6.670478460470299e-08\n",
            "E_IS_E_SCOPE: 2.78495260210021e-07\n",
            "Total Loss: 0.013666031093070167\n",
            "----------------------------------------\n",
            "Epoch 48\n",
            "Var loss:  tensor(0.0134, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.013789714953882109\n",
            "E_s_wdiff_all_sq: 0.00041245234746356015\n",
            "E_IS_SCOPE: 2.673981181367783e-07\n",
            "E_IS_E_SCOPE: 4.7321575210973444e-07\n",
            "Total Loss: 0.013376852871425355\n",
            "----------------------------------------\n",
            "Epoch 49\n",
            "Var loss:  tensor(0.0131, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.013556134420975323\n",
            "E_s_wdiff_all_sq: 0.00044693663210773057\n",
            "E_IS_SCOPE: 4.837544551306583e-07\n",
            "E_IS_E_SCOPE: 6.838840547672098e-07\n",
            "Total Loss: 0.013108799429943073\n",
            "----------------------------------------\n",
            "Epoch 50\n",
            "Var loss:  tensor(0.0129, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.013344168280251149\n",
            "E_s_wdiff_all_sq: 0.00048146223359412635\n",
            "E_IS_SCOPE: 6.958703707207129e-07\n",
            "E_IS_E_SCOPE: 8.902933590755734e-07\n",
            "Total Loss: 0.012862319100955066\n",
            "----------------------------------------\n",
            "Epoch 51\n",
            "Var loss:  tensor(0.0126, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.013128497113832781\n",
            "E_s_wdiff_all_sq: 0.0004947913318387111\n",
            "E_IS_SCOPE: 8.819550360020273e-07\n",
            "E_IS_E_SCOPE: 1.07036226466189e-06\n",
            "Total Loss: 0.012633330867811505\n",
            "----------------------------------------\n",
            "Epoch 52\n",
            "Var loss:  tensor(0.0124, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.012888148026360948\n",
            "E_s_wdiff_all_sq: 0.00047671112836318146\n",
            "E_IS_SCOPE: 1.0334036262810518e-06\n",
            "E_IS_E_SCOPE: 1.2153569936101924e-06\n",
            "Total Loss: 0.012411074891537862\n",
            "----------------------------------------\n",
            "Epoch 53\n",
            "Var loss:  tensor(0.0122, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.012611285251020059\n",
            "E_s_wdiff_all_sq: 0.0004208746598268171\n",
            "E_IS_SCOPE: 1.1424879654273389e-06\n",
            "E_IS_E_SCOPE: 1.3173864995723452e-06\n",
            "Total Loss: 0.012190062694399706\n",
            "----------------------------------------\n",
            "Epoch 54\n",
            "Var loss:  tensor(0.0120, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.012293206601517117\n",
            "E_s_wdiff_all_sq: 0.00032659131231060353\n",
            "E_IS_SCOPE: 1.200809310645725e-06\n",
            "E_IS_E_SCOPE: 1.3680133678632635e-06\n",
            "Total Loss: 0.011966282781366832\n",
            "----------------------------------------\n",
            "Epoch 55\n",
            "Var loss:  tensor(0.0117, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.011953148298318882\n",
            "E_s_wdiff_all_sq: 0.00020929931751925048\n",
            "E_IS_SCOPE: 1.2111480021756202e-06\n",
            "E_IS_E_SCOPE: 1.370250048353744e-06\n",
            "Total Loss: 0.011743532676982029\n",
            "----------------------------------------\n",
            "Epoch 56\n",
            "Var loss:  tensor(0.0115, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.011645708295181655\n",
            "E_s_wdiff_all_sq: 0.00010824049892926428\n",
            "E_IS_SCOPE: 1.2012511809202424e-06\n",
            "E_IS_E_SCOPE: 1.3520291652705321e-06\n",
            "Total Loss: 0.011537168140558442\n",
            "----------------------------------------\n",
            "Epoch 57\n",
            "Var loss:  tensor(0.0113, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.011390184585635009\n",
            "E_s_wdiff_all_sq: 4.2006434280738924e-05\n",
            "E_IS_SCOPE: 1.1931914026906156e-06\n",
            "E_IS_E_SCOPE: 1.3357072338403815e-06\n",
            "Total Loss: 0.011347895019966723\n",
            "----------------------------------------\n",
            "Epoch 58\n",
            "Var loss:  tensor(0.0112, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.011182751502713443\n",
            "E_s_wdiff_all_sq: 1.0410333692265589e-05\n",
            "E_IS_SCOPE: 1.207172404805416e-06\n",
            "E_IS_E_SCOPE: 1.3418427795148682e-06\n",
            "Total Loss: 0.011172073728546512\n",
            "----------------------------------------\n",
            "Epoch 59\n",
            "Var loss:  tensor(0.0110, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.01100348079444672\n",
            "E_s_wdiff_all_sq: 9.079580379452349e-07\n",
            "E_IS_SCOPE: 1.2548485067268862e-06\n",
            "E_IS_E_SCOPE: 1.3822636411868356e-06\n",
            "Total Loss: 0.011002319906414608\n",
            "----------------------------------------\n",
            "Epoch 60\n",
            "Var loss:  tensor(0.0108, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.010836025698227928\n",
            "E_s_wdiff_all_sq: 1.3815001815035173e-07\n",
            "E_IS_SCOPE: 1.3363864376115195e-06\n",
            "E_IS_E_SCOPE: 1.4571433487103514e-06\n",
            "Total Loss: 0.010835647934662332\n",
            "----------------------------------------\n",
            "Epoch 61\n",
            "Var loss:  tensor(0.0107, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.010668746086285097\n",
            "E_s_wdiff_all_sq: 5.618208118544752e-07\n",
            "E_IS_SCOPE: 1.452084320592511e-06\n",
            "E_IS_E_SCOPE: 1.5668181991774236e-06\n",
            "Total Loss: 0.010667956697990828\n",
            "----------------------------------------\n",
            "Epoch 62\n",
            "Var loss:  tensor(0.0105, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.0105050270238876\n",
            "E_s_wdiff_all_sq: 2.0560060934047763e-07\n",
            "E_IS_SCOPE: 1.5908895916688176e-06\n",
            "E_IS_E_SCOPE: 1.7000739559691682e-06\n",
            "Total Loss: 0.010504604954824413\n",
            "----------------------------------------\n",
            "Epoch 63\n",
            "Var loss:  tensor(0.0104, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.010351152255609296\n",
            "E_s_wdiff_all_sq: 1.9453383284759797e-09\n",
            "E_IS_SCOPE: 1.73403924650792e-06\n",
            "E_IS_E_SCOPE: 1.8378746227886796e-06\n",
            "Total Loss: 0.01035094453979316\n",
            "----------------------------------------\n",
            "Epoch 64\n",
            "Var loss:  tensor(0.0102, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.010207433070852897\n",
            "E_s_wdiff_all_sq: 3.8801967234060255e-08\n",
            "E_IS_SCOPE: 1.8596894964328984e-06\n",
            "E_IS_E_SCOPE: 1.958050106032603e-06\n",
            "Total Loss: 0.010207199447941216\n",
            "----------------------------------------\n",
            "Epoch 65\n",
            "Var loss:  tensor(0.0101, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.010069114085118094\n",
            "E_s_wdiff_all_sq: 1.202498069755943e-07\n",
            "E_IS_SCOPE: 1.95333524059022e-06\n",
            "E_IS_E_SCOPE: 2.0459116797379765e-06\n",
            "Total Loss: 0.010068810582707578\n",
            "----------------------------------------\n",
            "Epoch 66\n",
            "Var loss:  tensor(0.0099, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.00993492218837907\n",
            "E_s_wdiff_all_sq: 3.1880861893030127e-06\n",
            "E_IS_SCOPE: 2.0069427726803724e-06\n",
            "E_IS_E_SCOPE: 2.093326725353096e-06\n",
            "Total Loss: 0.009931563234559175\n",
            "----------------------------------------\n",
            "Epoch 67\n",
            "Var loss:  tensor(0.0098, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.009812929052107218\n",
            "E_s_wdiff_all_sq: 1.6722923492097697e-05\n",
            "E_IS_SCOPE: 2.023164420470091e-06\n",
            "E_IS_E_SCOPE: 2.1029772945105716e-06\n",
            "Total Loss: 0.009796048403141792\n",
            "----------------------------------------\n",
            "Epoch 68\n",
            "Var loss:  tensor(0.0097, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.009718403173824651\n",
            "E_s_wdiff_all_sq: 4.805244770819048e-05\n",
            "E_IS_SCOPE: 2.010905888881555e-06\n",
            "E_IS_E_SCOPE: 2.0839336144940737e-06\n",
            "Total Loss: 0.00967020657093999\n",
            "----------------------------------------\n",
            "Epoch 69\n",
            "Var loss:  tensor(0.0096, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.009646690656586228\n",
            "E_s_wdiff_all_sq: 9.592515433326874e-05\n",
            "E_IS_SCOPE: 1.991218020249977e-06\n",
            "E_IS_E_SCOPE: 2.057533762100899e-06\n",
            "Total Loss: 0.00955063477104401\n",
            "----------------------------------------\n",
            "Epoch 70\n",
            "Var loss:  tensor(0.0094, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.00958774507183524\n",
            "E_s_wdiff_all_sq: 0.00015066772413066895\n",
            "E_IS_SCOPE: 1.98067809308604e-06\n",
            "E_IS_E_SCOPE: 2.040582687637834e-06\n",
            "Total Loss: 0.009436959438790223\n",
            "----------------------------------------\n",
            "Epoch 71\n",
            "Var loss:  tensor(0.0093, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.009517022312448793\n",
            "E_s_wdiff_all_sq: 0.00019145463698150625\n",
            "E_IS_SCOPE: 1.997583556408386e-06\n",
            "E_IS_E_SCOPE: 2.0515918204922955e-06\n",
            "Total Loss: 0.009325461559213872\n",
            "----------------------------------------\n",
            "Epoch 72\n",
            "Var loss:  tensor(0.0092, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.009418213695419123\n",
            "E_s_wdiff_all_sq: 0.00020742827477355716\n",
            "E_IS_SCOPE: 2.0459906089688907e-06\n",
            "E_IS_E_SCOPE: 2.0946950829359754e-06\n",
            "Total Loss: 0.009210689911972386\n",
            "----------------------------------------\n",
            "Epoch 73\n",
            "Var loss:  tensor(0.0091, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.00930921134127681\n",
            "E_s_wdiff_all_sq: 0.00020976405315419923\n",
            "E_IS_SCOPE: 2.1087619122286057e-06\n",
            "E_IS_E_SCOPE: 2.1525672249549158e-06\n",
            "Total Loss: 0.009099361577771912\n",
            "----------------------------------------\n",
            "Epoch 74\n",
            "Var loss:  tensor(0.0090, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.0091995964762784\n",
            "E_s_wdiff_all_sq: 0.00020638041314544842\n",
            "E_IS_SCOPE: 2.174446446355403e-06\n",
            "E_IS_E_SCOPE: 2.213590572456769e-06\n",
            "Total Loss: 0.008993139675155502\n",
            "----------------------------------------\n",
            "Epoch 75\n",
            "Var loss:  tensor(0.0089, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.009099993714022\n",
            "E_s_wdiff_all_sq: 0.00020799981881966122\n",
            "E_IS_SCOPE: 2.229414726698709e-06\n",
            "E_IS_E_SCOPE: 2.2638977190429157e-06\n",
            "Total Loss: 0.008891926829492403\n",
            "----------------------------------------\n",
            "Epoch 76\n",
            "Var loss:  tensor(0.0088, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.00901508851990273\n",
            "E_s_wdiff_all_sq: 0.00022232141393947887\n",
            "E_IS_SCOPE: 2.263489411115759e-06\n",
            "E_IS_E_SCOPE: 2.2931601150703357e-06\n",
            "Total Loss: 0.008792709664830095\n",
            "----------------------------------------\n",
            "Epoch 77\n",
            "Var loss:  tensor(0.0087, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008948379686704047\n",
            "E_s_wdiff_all_sq: 0.0002544096968894246\n",
            "E_IS_SCOPE: 2.27176921013607e-06\n",
            "E_IS_E_SCOPE: 2.296363760415371e-06\n",
            "Total Loss: 0.008693922700988817\n",
            "----------------------------------------\n",
            "Epoch 78\n",
            "Var loss:  tensor(0.0086, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008903714796784342\n",
            "E_s_wdiff_all_sq: 0.00030649060883905483\n",
            "E_IS_SCOPE: 2.255168584142636e-06\n",
            "E_IS_E_SCOPE: 2.2744780981584286e-06\n",
            "Total Loss: 0.008597187469192009\n",
            "----------------------------------------\n",
            "Epoch 79\n",
            "Var loss:  tensor(0.0085, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008873805120559361\n",
            "E_s_wdiff_all_sq: 0.00037051924468563816\n",
            "E_IS_SCOPE: 2.2279324486813705e-06\n",
            "E_IS_E_SCOPE: 2.2419142898709893e-06\n",
            "Total Loss: 0.008503259812466097\n",
            "----------------------------------------\n",
            "Epoch 80\n",
            "Var loss:  tensor(0.0084, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008848989949106278\n",
            "E_s_wdiff_all_sq: 0.0004372885365886362\n",
            "E_IS_SCOPE: 2.199943390433275e-06\n",
            "E_IS_E_SCOPE: 2.2087120864441973e-06\n",
            "Total Loss: 0.008411685775400373\n",
            "----------------------------------------\n",
            "Epoch 81\n",
            "Var loss:  tensor(0.0083, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008819390982655982\n",
            "E_s_wdiff_all_sq: 0.0004971544392122861\n",
            "E_IS_SCOPE: 2.179381013885778e-06\n",
            "E_IS_E_SCOPE: 2.1832001489248226e-06\n",
            "Total Loss: 0.008322230805448373\n",
            "----------------------------------------\n",
            "Epoch 82\n",
            "Var loss:  tensor(0.0082, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.00877775243334565\n",
            "E_s_wdiff_all_sq: 0.0005436831752453883\n",
            "E_IS_SCOPE: 2.1706706433754043e-06\n",
            "E_IS_E_SCOPE: 2.169872214253779e-06\n",
            "Total Loss: 0.008234072755233258\n",
            "----------------------------------------\n",
            "Epoch 83\n",
            "Var loss:  tensor(0.0081, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008722117012827362\n",
            "E_s_wdiff_all_sq: 0.0005755438795128182\n",
            "E_IS_SCOPE: 2.173043277642234e-06\n",
            "E_IS_E_SCOPE: 2.1679445469076365e-06\n",
            "Total Loss: 0.008146585231050767\n",
            "----------------------------------------\n",
            "Epoch 84\n",
            "Var loss:  tensor(0.0081, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.00865713397376764\n",
            "E_s_wdiff_all_sq: 0.0005968876700513027\n",
            "E_IS_SCOPE: 2.1812827323806136e-06\n",
            "E_IS_E_SCOPE: 2.1721280726982123e-06\n",
            "Total Loss: 0.008060266513310455\n",
            "----------------------------------------\n",
            "Epoch 85\n",
            "Var loss:  tensor(0.0080, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008591523021600633\n",
            "E_s_wdiff_all_sq: 0.0006160458063093296\n",
            "E_IS_SCOPE: 2.188087841227219e-06\n",
            "E_IS_E_SCOPE: 2.1750132367066322e-06\n",
            "Total Loss: 0.007975505264775098\n",
            "----------------------------------------\n",
            "Epoch 86\n",
            "Var loss:  tensor(0.0079, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008534388989960964\n",
            "E_s_wdiff_all_sq: 0.0006421742388989396\n",
            "E_IS_SCOPE: 2.1860096005905963e-06\n",
            "E_IS_E_SCOPE: 2.169041484994533e-06\n",
            "Total Loss: 0.00789225058756797\n",
            "----------------------------------------\n",
            "Epoch 87\n",
            "Var loss:  tensor(0.0078, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008495956476267847\n",
            "E_s_wdiff_all_sq: 0.0006836606500257036\n",
            "E_IS_SCOPE: 2.1685216007829194e-06\n",
            "E_IS_E_SCOPE: 2.147613013266405e-06\n",
            "Total Loss: 0.007812339543691931\n",
            "----------------------------------------\n",
            "Epoch 88\n",
            "Var loss:  tensor(0.0077, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008438616504133668\n",
            "E_s_wdiff_all_sq: 0.0007051137022769351\n",
            "E_IS_SCOPE: 2.162775627442828e-06\n",
            "E_IS_E_SCOPE: 2.138088171608812e-06\n",
            "Total Loss: 0.007733554077043155\n",
            "----------------------------------------\n",
            "Epoch 89\n",
            "Var loss:  tensor(0.0077, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008382767285299476\n",
            "E_s_wdiff_all_sq: 0.0007277951754567229\n",
            "E_IS_SCOPE: 2.1515679659045613e-06\n",
            "E_IS_E_SCOPE: 2.123148081443343e-06\n",
            "Total Loss: 0.00765503084988643\n",
            "----------------------------------------\n",
            "Epoch 90\n",
            "Var loss:  tensor(0.0076, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008350625449189129\n",
            "E_s_wdiff_all_sq: 0.0007734205879803565\n",
            "E_IS_SCOPE: 2.1242675411020434e-06\n",
            "E_IS_E_SCOPE: 2.0920589961909506e-06\n",
            "Total Loss: 0.007577271178573348\n",
            "----------------------------------------\n",
            "Epoch 91\n",
            "Var loss:  tensor(0.0075, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008338909341958117\n",
            "E_s_wdiff_all_sq: 0.0008377826568160024\n",
            "E_IS_SCOPE: 2.083992684941488e-06\n",
            "E_IS_E_SCOPE: 2.047999580028704e-06\n",
            "Total Loss: 0.0075012005716266926\n",
            "----------------------------------------\n",
            "Epoch 92\n",
            "Var loss:  tensor(0.0074, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008340456621861845\n",
            "E_s_wdiff_all_sq: 0.0009135643477882987\n",
            "E_IS_SCOPE: 2.037985537153975e-06\n",
            "E_IS_E_SCOPE: 1.9982779815977825e-06\n",
            "Total Loss: 0.0074269735894594135\n",
            "----------------------------------------\n",
            "Epoch 93\n",
            "Var loss:  tensor(0.0074, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008322226772457341\n",
            "E_s_wdiff_all_sq: 0.0009688195844378601\n",
            "E_IS_SCOPE: 2.003250075498307e-06\n",
            "E_IS_E_SCOPE: 1.960055877607679e-06\n",
            "Total Loss: 0.007353495476690015\n",
            "----------------------------------------\n",
            "Epoch 94\n",
            "Var loss:  tensor(0.0073, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.00829933268020982\n",
            "E_s_wdiff_all_sq: 0.0010186131999866516\n",
            "E_IS_SCOPE: 1.9726130296331335e-06\n",
            "E_IS_E_SCOPE: 1.9261336703498657e-06\n",
            "Total Loss: 0.007280814339216488\n",
            "----------------------------------------\n",
            "Epoch 95\n",
            "Var loss:  tensor(0.0072, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008268338222415501\n",
            "E_s_wdiff_all_sq: 0.0010597202431958793\n",
            "E_IS_SCOPE: 1.9476434350998863e-06\n",
            "E_IS_E_SCOPE: 1.8980991362425127e-06\n",
            "Total Loss: 0.007208718968092089\n",
            "----------------------------------------\n",
            "Epoch 96\n",
            "Var loss:  tensor(0.0071, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008228019505571805\n",
            "E_s_wdiff_all_sq: 0.0010901304783836638\n",
            "E_IS_SCOPE: 1.9285687496650107e-06\n",
            "E_IS_E_SCOPE: 1.8761760300814585e-06\n",
            "Total Loss: 0.0071379957129020614\n",
            "----------------------------------------\n",
            "Epoch 97\n",
            "Var loss:  tensor(0.0071, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008188059319690483\n",
            "E_s_wdiff_all_sq: 0.001119838593450259\n",
            "E_IS_SCOPE: 1.9086996121029974e-06\n",
            "E_IS_E_SCOPE: 1.8536047458625981e-06\n",
            "Total Loss: 0.007068332816247459\n",
            "----------------------------------------\n",
            "Epoch 98\n",
            "Var loss:  tensor(0.0070, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008131621464777009\n",
            "E_s_wdiff_all_sq: 0.001131341432804316\n",
            "E_IS_SCOPE: 1.8948996149661494e-06\n",
            "E_IS_E_SCOPE: 1.837261599497312e-06\n",
            "Total Loss: 0.007000397208278384\n",
            "----------------------------------------\n",
            "Epoch 99\n",
            "Var loss:  tensor(0.0069, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008091475457291983\n",
            "E_s_wdiff_all_sq: 0.001158503447014413\n",
            "E_IS_SCOPE: 1.8711429744163476e-06\n",
            "E_IS_E_SCOPE: 1.8109872176100253e-06\n",
            "Total Loss: 0.006933094222065936\n",
            "----------------------------------------\n",
            "Epoch 100\n",
            "Var loss:  tensor(0.0069, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008072609172742242\n",
            "E_s_wdiff_all_sq: 0.001206256147582139\n",
            "E_IS_SCOPE: 1.8349806167476927e-06\n",
            "E_IS_E_SCOPE: 1.7722987515428524e-06\n",
            "Total Loss: 0.006866480289165266\n",
            "----------------------------------------\n",
            "Epoch 101\n",
            "Var loss:  tensor(0.0068, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008046360764405952\n",
            "E_s_wdiff_all_sq: 0.0012457914777252535\n",
            "E_IS_SCOPE: 1.8007419374267148e-06\n",
            "E_IS_E_SCOPE: 1.7356187210704045e-06\n",
            "Total Loss: 0.006800701433388167\n",
            "----------------------------------------\n",
            "Epoch 102\n",
            "Var loss:  tensor(0.0067, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008010073504638674\n",
            "E_s_wdiff_all_sq: 0.0012735504894248878\n",
            "E_IS_SCOPE: 1.7701676130225247e-06\n",
            "E_IS_E_SCOPE: 1.7027008319874566e-06\n",
            "Total Loss: 0.00673665984905061\n",
            "----------------------------------------\n",
            "Epoch 103\n",
            "Var loss:  tensor(0.0067, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.007982981601109865\n",
            "E_s_wdiff_all_sq: 0.0013100400272689976\n",
            "E_IS_SCOPE: 1.7361428319988846e-06\n",
            "E_IS_E_SCOPE: 1.6663933662575958e-06\n",
            "Total Loss: 0.006673082973047103\n",
            "----------------------------------------\n",
            "Epoch 104\n",
            "Var loss:  tensor(0.0066, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.007960983096211528\n",
            "E_s_wdiff_all_sq: 0.0013510410062976422\n",
            "E_IS_SCOPE: 1.7009924837652738e-06\n",
            "E_IS_E_SCOPE: 1.6290515038665392e-06\n",
            "Total Loss: 0.006610087872148437\n",
            "----------------------------------------\n",
            "Epoch 105\n",
            "Var loss:  tensor(0.0065, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.007941187348380688\n",
            "E_s_wdiff_all_sq: 0.0013928527068352817\n",
            "E_IS_SCOPE: 1.6666344370623034e-06\n",
            "E_IS_E_SCOPE: 1.5926054372174672e-06\n",
            "Total Loss: 0.0065484845998198486\n",
            "----------------------------------------\n",
            "Epoch 106\n",
            "Var loss:  tensor(0.0065, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.007929160114803062\n",
            "E_s_wdiff_all_sq: 0.0014414044496099986\n",
            "E_IS_SCOPE: 1.6310413009012685e-06\n",
            "E_IS_E_SCOPE: 1.5549824447389268e-06\n",
            "Total Loss: 0.006487909683180141\n",
            "----------------------------------------\n",
            "Epoch 107\n",
            "Var loss:  tensor(0.0064, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.007882529541872995\n",
            "E_s_wdiff_all_sq: 0.0014541886221567746\n",
            "E_IS_SCOPE: 1.6103684643082914e-06\n",
            "E_IS_E_SCOPE: 1.5324918873259775e-06\n",
            "Total Loss: 0.006428498573144939\n",
            "----------------------------------------\n",
            "Epoch 108\n",
            "Var loss:  tensor(0.0064, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.007828247810569958\n",
            "E_s_wdiff_all_sq: 0.001458003663583914\n",
            "E_IS_SCOPE: 1.5922409160034266e-06\n",
            "E_IS_E_SCOPE: 1.5126207297610886e-06\n",
            "Total Loss: 0.006370405287633282\n",
            "----------------------------------------\n",
            "Epoch 109\n",
            "Var loss:  tensor(0.0063, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.007774522355229317\n",
            "E_s_wdiff_all_sq: 0.001461459370749036\n",
            "E_IS_SCOPE: 1.573984608401368e-06\n",
            "E_IS_E_SCOPE: 1.492636922030676e-06\n",
            "Total Loss: 0.006313227580127775\n",
            "----------------------------------------\n",
            "Epoch 110\n",
            "Var loss:  tensor(0.0063, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.007729801544134302\n",
            "E_s_wdiff_all_sq: 0.0014730817657564001\n",
            "E_IS_SCOPE: 1.5511099301739699e-06\n",
            "E_IS_E_SCOPE: 1.4680061995190064e-06\n",
            "Total Loss: 0.006256887886113965\n",
            "----------------------------------------\n",
            "Epoch 111\n",
            "Var loss:  tensor(0.0062, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.007689218330536046\n",
            "E_s_wdiff_all_sq: 0.001488256669386754\n",
            "E_IS_SCOPE: 1.5268100435176147e-06\n",
            "E_IS_E_SCOPE: 1.4419294316260533e-06\n",
            "Total Loss: 0.006201133322647828\n",
            "----------------------------------------\n",
            "Epoch 112\n",
            "Var loss:  tensor(0.0061, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.00764986162838397\n",
            "E_s_wdiff_all_sq: 0.0015040386920734993\n",
            "E_IS_SCOPE: 1.5025672888491617e-06\n",
            "E_IS_E_SCOPE: 1.415909799266442e-06\n",
            "Total Loss: 0.006145998151564388\n",
            "----------------------------------------\n",
            "Epoch 113\n",
            "Var loss:  tensor(0.0061, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.007608384174394664\n",
            "E_s_wdiff_all_sq: 0.0015169963680661982\n",
            "E_IS_SCOPE: 1.4800542433381779e-06\n",
            "E_IS_E_SCOPE: 1.391650719518582e-06\n",
            "Total Loss: 0.006091566513650858\n",
            "----------------------------------------\n",
            "Epoch 114\n",
            "Var loss:  tensor(0.0060, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.007547147064110846\n",
            "E_s_wdiff_all_sq: 0.0015093571606669895\n",
            "E_IS_SCOPE: 1.4657493679299505e-06\n",
            "E_IS_E_SCOPE: 1.375752170910689e-06\n",
            "Total Loss: 0.006037971798112648\n",
            "----------------------------------------\n",
            "Epoch 115\n",
            "Var loss:  tensor(0.0060, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.00748462639294576\n",
            "E_s_wdiff_all_sq: 0.0014993438389927026\n",
            "E_IS_SCOPE: 1.452981223145976e-06\n",
            "E_IS_E_SCOPE: 1.361413219865486e-06\n",
            "Total Loss: 0.005985467590234371\n",
            "----------------------------------------\n",
            "Epoch 116\n",
            "Var loss:  tensor(0.0059, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.007415313631006333\n",
            "E_s_wdiff_all_sq: 0.0014812321668752466\n",
            "E_IS_SCOPE: 1.4441175696071432e-06\n",
            "E_IS_E_SCOPE: 1.3509423470563495e-06\n",
            "Total Loss: 0.0059342697148509396\n",
            "----------------------------------------\n",
            "Epoch 117\n",
            "Var loss:  tensor(0.0059, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.007356485457028489\n",
            "E_s_wdiff_all_sq: 0.001472739044274259\n",
            "E_IS_SCOPE: 1.4278485096937465e-06\n",
            "E_IS_E_SCOPE: 1.3329679244867772e-06\n",
            "Total Loss: 0.005883938074199397\n",
            "----------------------------------------\n",
            "Epoch 118\n",
            "Var loss:  tensor(0.0058, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.0073268216578304705\n",
            "E_s_wdiff_all_sq: 0.0014936613589037365\n",
            "E_IS_SCOPE: 1.3974716596526374e-06\n",
            "E_IS_E_SCOPE: 1.3007555661750458e-06\n",
            "Total Loss: 0.005833355631388442\n",
            "----------------------------------------\n",
            "Epoch 119\n",
            "Var loss:  tensor(0.0058, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.007294701334065443\n",
            "E_s_wdiff_all_sq: 0.0015098690749145154\n",
            "E_IS_SCOPE: 1.3686414240181257e-06\n",
            "E_IS_E_SCOPE: 1.2701327172619556e-06\n",
            "Total Loss: 0.005785031176839193\n",
            "----------------------------------------\n",
            "Epoch 120\n",
            "Var loss:  tensor(0.0057, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.007225942935946969\n",
            "E_s_wdiff_all_sq: 0.0014892553321432405\n",
            "E_IS_SCOPE: 1.3556778278444911e-06\n",
            "E_IS_E_SCOPE: 1.2556353493752482e-06\n",
            "Total Loss: 0.00573688958903542\n",
            "----------------------------------------\n",
            "Epoch 121\n",
            "Var loss:  tensor(0.0057, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.007152278539623219\n",
            "E_s_wdiff_all_sq: 0.0014628651594356874\n",
            "E_IS_SCOPE: 1.3461843768804664e-06\n",
            "E_IS_E_SCOPE: 1.2447528269742843e-06\n",
            "Total Loss: 0.005689618143562097\n",
            "----------------------------------------\n",
            "Epoch 122\n",
            "Var loss:  tensor(0.0056, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.007074413319081597\n",
            "E_s_wdiff_all_sq: 0.0014316689383678577\n",
            "E_IS_SCOPE: 1.3403322511287078e-06\n",
            "E_IS_E_SCOPE: 1.2376358346618868e-06\n",
            "Total Loss: 0.005642951673821426\n",
            "----------------------------------------\n",
            "Epoch 123\n",
            "Var loss:  tensor(0.0056, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.007000544982317966\n",
            "E_s_wdiff_all_sq: 0.0014038677994502034\n",
            "E_IS_SCOPE: 1.3335626127466436e-06\n",
            "E_IS_E_SCOPE: 1.2296538005665591e-06\n",
            "Total Loss: 0.005596886900766876\n",
            "----------------------------------------\n",
            "Epoch 124\n",
            "Var loss:  tensor(0.0056, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.006951674911733834\n",
            "E_s_wdiff_all_sq: 0.0014007879258936772\n",
            "E_IS_SCOPE: 1.3165956700811214e-06\n",
            "E_IS_E_SCOPE: 1.2113745842074228e-06\n",
            "Total Loss: 0.005551099328286657\n",
            "----------------------------------------\n",
            "Epoch 125\n",
            "Var loss:  tensor(0.0055, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.006910616518839402\n",
            "E_s_wdiff_all_sq: 0.001404698638286044\n",
            "E_IS_SCOPE: 1.2960562156893523e-06\n",
            "E_IS_E_SCOPE: 1.1895223380392421e-06\n",
            "Total Loss: 0.0055061328485834105\n",
            "----------------------------------------\n",
            "Epoch 126\n",
            "Var loss:  tensor(0.0055, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.0068463596398622316\n",
            "E_s_wdiff_all_sq: 0.0013858323463310847\n",
            "E_IS_SCOPE: 1.284891444488107e-06\n",
            "E_IS_E_SCOPE: 1.1771498437661987e-06\n",
            "Total Loss: 0.005460744677007343\n",
            "----------------------------------------\n",
            "Epoch 127\n",
            "Var loss:  tensor(0.0054, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.006770904359962036\n",
            "E_s_wdiff_all_sq: 0.0013540954745472522\n",
            "E_IS_SCOPE: 1.2781708719986338e-06\n",
            "E_IS_E_SCOPE: 1.1692739404065535e-06\n",
            "Total Loss: 0.005417028579552721\n",
            "----------------------------------------\n",
            "Epoch 128\n",
            "Var loss:  tensor(0.0054, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.006720479414765168\n",
            "E_s_wdiff_all_sq: 0.0013476359590089938\n",
            "E_IS_SCOPE: 1.2596155827891558e-06\n",
            "E_IS_E_SCOPE: 1.1494572489196661e-06\n",
            "Total Loss: 0.0053730656726986665\n",
            "----------------------------------------\n",
            "Epoch 129\n",
            "Var loss:  tensor(0.0053, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.0066869499611581845\n",
            "E_s_wdiff_all_sq: 0.001357977841158285\n",
            "E_IS_SCOPE: 1.2337182991687376e-06\n",
            "E_IS_E_SCOPE: 1.122249166794644e-06\n",
            "Total Loss: 0.0053291969585394\n",
            "----------------------------------------\n",
            "Epoch 130\n",
            "Var loss:  tensor(0.0053, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.0066629114468284316\n",
            "E_s_wdiff_all_sq: 0.0013770921206919784\n",
            "E_IS_SCOPE: 1.2058350823056723e-06\n",
            "E_IS_E_SCOPE: 1.0930828888053644e-06\n",
            "Total Loss: 0.005286046730798206\n",
            "----------------------------------------\n",
            "Epoch 131\n",
            "Var loss:  tensor(0.0052, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.006609913975435086\n",
            "E_s_wdiff_all_sq: 0.0013663212871194293\n",
            "E_IS_SCOPE: 1.194634791959628e-06\n",
            "E_IS_E_SCOPE: 1.0808221491119755e-06\n",
            "Total Loss: 0.005243822213876106\n",
            "----------------------------------------\n",
            "Epoch 132\n",
            "Var loss:  tensor(0.0052, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.0065137915671138955\n",
            "E_s_wdiff_all_sq: 0.001312693205911151\n",
            "E_IS_SCOPE: 1.2048009314342784e-06\n",
            "E_IS_E_SCOPE: 1.0902539980780411e-06\n",
            "Total Loss: 0.005201329355344209\n",
            "----------------------------------------\n",
            "Epoch 133\n",
            "Var loss:  tensor(0.0052, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.006441660412753178\n",
            "E_s_wdiff_all_sq: 0.0012820780833259875\n",
            "E_IS_SCOPE: 1.2050802100283971e-06\n",
            "E_IS_E_SCOPE: 1.0897147696042058e-06\n",
            "Total Loss: 0.005159814960582792\n",
            "----------------------------------------\n",
            "Epoch 134\n",
            "Var loss:  tensor(0.0051, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.006399931183514836\n",
            "E_s_wdiff_all_sq: 0.0012814043527221858\n",
            "E_IS_SCOPE: 1.191291880673237e-06\n",
            "E_IS_E_SCOPE: 1.0749311780345552e-06\n",
            "Total Loss: 0.00511876145247268\n",
            "----------------------------------------\n",
            "Epoch 135\n",
            "Var loss:  tensor(0.0051, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.006366413808944962\n",
            "E_s_wdiff_all_sq: 0.0012885176488628446\n",
            "E_IS_SCOPE: 1.1723458822767625e-06\n",
            "E_IS_E_SCOPE: 1.0548939970827308e-06\n",
            "Total Loss: 0.005078132964127257\n",
            "----------------------------------------\n",
            "Epoch 136\n",
            "Var loss:  tensor(0.0050, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.006312099861591627\n",
            "E_s_wdiff_all_sq: 0.0012743497244230239\n",
            "E_IS_SCOPE: 1.1625331872437664e-06\n",
            "E_IS_E_SCOPE: 1.0440762996815318e-06\n",
            "Total Loss: 0.005037988951218481\n",
            "----------------------------------------\n",
            "Epoch 137\n",
            "Var loss:  tensor(0.0050, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.006272489538555492\n",
            "E_s_wdiff_all_sq: 0.001274334701018714\n",
            "E_IS_SCOPE: 1.1463993019073197e-06\n",
            "E_IS_E_SCOPE: 1.0268739411575622e-06\n",
            "Total Loss: 0.004998395788533031\n",
            "----------------------------------------\n",
            "Epoch 138\n",
            "Var loss:  tensor(0.0050, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.006250096713026883\n",
            "E_s_wdiff_all_sq: 0.0012913969959237332\n",
            "E_IS_SCOPE: 1.123464539059661e-06\n",
            "E_IS_E_SCOPE: 1.0028174076336424e-06\n",
            "Total Loss: 0.004958942911640754\n",
            "----------------------------------------\n",
            "Epoch 139\n",
            "Var loss:  tensor(0.0049, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.0062359845645877056\n",
            "E_s_wdiff_all_sq: 0.0013154454564992138\n",
            "E_IS_SCOPE: 1.0995180758221853e-06\n",
            "E_IS_E_SCOPE: 9.777372472925195e-07\n",
            "Total Loss: 0.0049207845700203045\n",
            "----------------------------------------\n",
            "Epoch 140\n",
            "Var loss:  tensor(0.0049, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.006178405807424129\n",
            "E_s_wdiff_all_sq: 0.0012969492441318147\n",
            "E_IS_SCOPE: 1.0968729176095886e-06\n",
            "E_IS_E_SCOPE: 9.743265119429493e-07\n",
            "Total Loss: 0.0048817035563784\n",
            "----------------------------------------\n",
            "Epoch 141\n",
            "Var loss:  tensor(0.0048, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.006100416668453988\n",
            "E_s_wdiff_all_sq: 0.0012561137516923717\n",
            "E_IS_SCOPE: 1.1040868061173614e-06\n",
            "E_IS_E_SCOPE: 9.809455442584906e-07\n",
            "Total Loss: 0.004844551099560087\n",
            "----------------------------------------\n",
            "Epoch 142\n",
            "Var loss:  tensor(0.0048, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.006045040778288479\n",
            "E_s_wdiff_all_sq: 0.0012373447039182677\n",
            "E_IS_SCOPE: 1.1001374816064936e-06\n",
            "E_IS_E_SCOPE: 9.762659299457236e-07\n",
            "Total Loss: 0.0048079457177482845\n",
            "----------------------------------------\n",
            "Epoch 143\n",
            "Var loss:  tensor(0.0048, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.006029664292706384\n",
            "E_s_wdiff_all_sq: 0.0012589130266997526\n",
            "E_IS_SCOPE: 1.0756739584144667e-06\n",
            "E_IS_E_SCOPE: 9.508580890478709e-07\n",
            "Total Loss: 0.004771002798020117\n",
            "----------------------------------------\n",
            "Epoch 144\n",
            "Var loss:  tensor(0.0047, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.006030931833783016\n",
            "E_s_wdiff_all_sq: 0.0012969954327172988\n",
            "E_IS_SCOPE: 1.0460167265358186e-06\n",
            "E_IS_E_SCOPE: 9.202104105541383e-07\n",
            "Total Loss: 0.004734189913972433\n",
            "----------------------------------------\n",
            "Epoch 145\n",
            "Var loss:  tensor(0.0047, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.006024382087127848\n",
            "E_s_wdiff_all_sq: 0.0013268896348691112\n",
            "E_IS_SCOPE: 1.0253406143075266e-06\n",
            "E_IS_E_SCOPE: 8.986220157935793e-07\n",
            "Total Loss: 0.0046977477897305175\n",
            "----------------------------------------\n",
            "Epoch 146\n",
            "Var loss:  tensor(0.0047, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.006003590182129443\n",
            "E_s_wdiff_all_sq: 0.0013411004233950558\n",
            "E_IS_SCOPE: 1.0172971018529609e-06\n",
            "E_IS_E_SCOPE: 8.898543808519225e-07\n",
            "Total Loss: 0.004662746544451142\n",
            "----------------------------------------\n",
            "Epoch 147\n",
            "Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005932188363824686\n",
            "E_s_wdiff_all_sq: 0.001304873581964718\n",
            "E_IS_SCOPE: 1.0351949278007678e-06\n",
            "E_IS_E_SCOPE: 9.074548383172794e-07\n",
            "Total Loss: 0.0046275721623136885\n",
            "----------------------------------------\n",
            "Epoch 148\n",
            "Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005847017980544554\n",
            "E_s_wdiff_all_sq: 0.0012545165979354071\n",
            "E_IS_SCOPE: 1.058325729658441e-06\n",
            "E_IS_E_SCOPE: 9.304037679667907e-07\n",
            "Total Loss: 0.0045927591268072835\n",
            "----------------------------------------\n",
            "Epoch 149\n",
            "Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.0057864792047962665\n",
            "E_s_wdiff_all_sq: 0.0012280846619330378\n",
            "E_IS_SCOPE: 1.0638555298258055e-06\n",
            "E_IS_E_SCOPE: 9.355511779591883e-07\n",
            "Total Loss: 0.004558653051841714\n",
            "----------------------------------------\n",
            "Epoch 150\n",
            "Var loss:  tensor(0.0045, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005775198157417325\n",
            "E_s_wdiff_all_sq: 0.0012511988495153249\n",
            "E_IS_SCOPE: 1.0392389072007122e-06\n",
            "E_IS_E_SCOPE: 9.100855669703931e-07\n",
            "Total Loss: 0.004524259514857214\n",
            "----------------------------------------\n",
            "Epoch 151\n",
            "Var loss:  tensor(0.0045, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005806709020051685\n",
            "E_s_wdiff_all_sq: 0.001316670237545853\n",
            "E_IS_SCOPE: 9.928177515809362e-07\n",
            "E_IS_E_SCOPE: 8.624680672708002e-07\n",
            "Total Loss: 0.004490301382149205\n",
            "----------------------------------------\n",
            "Epoch 152\n",
            "Var loss:  tensor(0.0045, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005835706223027883\n",
            "E_s_wdiff_all_sq: 0.0013779019380111789\n",
            "E_IS_SCOPE: 9.526219224088915e-07\n",
            "E_IS_E_SCOPE: 8.212133337724664e-07\n",
            "Total Loss: 0.0044580690024687295\n",
            "----------------------------------------\n",
            "Epoch 153\n",
            "Var loss:  tensor(0.0044, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.00580564321532073\n",
            "E_s_wdiff_all_sq: 0.001380680863311377\n",
            "E_IS_SCOPE: 9.450948906026216e-07\n",
            "E_IS_E_SCOPE: 8.131769960039123e-07\n",
            "Total Loss: 0.004425228088073304\n",
            "----------------------------------------\n",
            "Epoch 154\n",
            "Var loss:  tensor(0.0044, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.00571764488842596\n",
            "E_s_wdiff_all_sq: 0.001326188853642343\n",
            "E_IS_SCOPE: 9.703379517381517e-07\n",
            "E_IS_E_SCOPE: 8.384405073264432e-07\n",
            "Total Loss: 0.004391721729947193\n",
            "----------------------------------------\n",
            "Epoch 155\n",
            "Var loss:  tensor(0.0044, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005616803859623317\n",
            "E_s_wdiff_all_sq: 0.001257354041170326\n",
            "E_IS_SCOPE: 1.004380804212145e-06\n",
            "E_IS_E_SCOPE: 8.726444675556512e-07\n",
            "Total Loss: 0.004359715191401057\n",
            "----------------------------------------\n",
            "Epoch 156\n",
            "Var loss:  tensor(0.0043, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005562133315554134\n",
            "E_s_wdiff_all_sq: 0.0012343110226743735\n",
            "E_IS_SCOPE: 1.0140942655088695e-06\n",
            "E_IS_E_SCOPE: 8.821420197532515e-07\n",
            "Total Loss: 0.004328088097646024\n",
            "----------------------------------------\n",
            "Epoch 157\n",
            "Var loss:  tensor(0.0043, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005548745523510721\n",
            "E_s_wdiff_all_sq: 0.0012529292381400921\n",
            "E_IS_SCOPE: 9.978248504623217e-07\n",
            "E_IS_E_SCOPE: 8.652371128870706e-07\n",
            "Total Loss: 0.004296083361120532\n",
            "----------------------------------------\n",
            "Epoch 158\n",
            "Var loss:  tensor(0.0043, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005559204012189817\n",
            "E_s_wdiff_all_sq: 0.001294855830239539\n",
            "E_IS_SCOPE: 9.67086012070673e-07\n",
            "E_IS_E_SCOPE: 8.336320146194316e-07\n",
            "Total Loss: 0.0042646169902199335\n",
            "----------------------------------------\n",
            "Epoch 159\n",
            "Var loss:  tensor(0.0042, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005557752326399675\n",
            "E_s_wdiff_all_sq: 0.0013233540527439747\n",
            "E_IS_SCOPE: 9.442048266983648e-07\n",
            "E_IS_E_SCOPE: 8.100140388094933e-07\n",
            "Total Loss: 0.00423466855550623\n",
            "----------------------------------------\n",
            "Epoch 160\n",
            "Var loss:  tensor(0.0042, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005518625580161883\n",
            "E_s_wdiff_all_sq: 0.0013142774805072405\n",
            "E_IS_SCOPE: 9.431347576064318e-07\n",
            "E_IS_E_SCOPE: 8.085636947515616e-07\n",
            "Total Loss: 0.004204619142055104\n",
            "----------------------------------------\n",
            "Epoch 161\n",
            "Var loss:  tensor(0.0042, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005446060910532108\n",
            "E_s_wdiff_all_sq: 0.0012717598974359254\n",
            "E_IS_SCOPE: 9.607231528934881e-07\n",
            "E_IS_E_SCOPE: 8.260958306385952e-07\n",
            "Total Loss: 0.004174572168015445\n",
            "----------------------------------------\n",
            "Epoch 162\n",
            "Var loss:  tensor(0.0041, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005368492280207882\n",
            "E_s_wdiff_all_sq: 0.001223253442569503\n",
            "E_IS_SCOPE: 9.773930772689486e-07\n",
            "E_IS_E_SCOPE: 8.42734566980901e-07\n",
            "Total Loss: 0.004145510054933708\n",
            "----------------------------------------\n",
            "Epoch 163\n",
            "Var loss:  tensor(0.0041, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005326084894938203\n",
            "E_s_wdiff_all_sq: 0.0012090980387912406\n",
            "E_IS_SCOPE: 9.760191229215644e-07\n",
            "E_IS_E_SCOPE: 8.410903289034203e-07\n",
            "Total Loss: 0.004117258614009752\n",
            "----------------------------------------\n",
            "Epoch 164\n",
            "Var loss:  tensor(0.0041, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005321481684160546\n",
            "E_s_wdiff_all_sq: 0.001232679512619521\n",
            "E_IS_SCOPE: 9.531446000280616e-07\n",
            "E_IS_E_SCOPE: 8.175631466880593e-07\n",
            "Total Loss: 0.004089075234722459\n",
            "----------------------------------------\n",
            "Epoch 165\n",
            "Var loss:  tensor(0.0041, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005334680552508796\n",
            "E_s_wdiff_all_sq: 0.0012729881376299537\n",
            "E_IS_SCOPE: 9.213696238139901e-07\n",
            "E_IS_E_SCOPE: 7.849510235024732e-07\n",
            "Total Loss: 0.004061967152354218\n",
            "----------------------------------------\n",
            "Epoch 166\n",
            "Var loss:  tensor(0.0040, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005318466179485129\n",
            "E_s_wdiff_all_sq: 0.0012836492597140473\n",
            "E_IS_SCOPE: 9.052685418127412e-07\n",
            "E_IS_E_SCOPE: 7.682247034172523e-07\n",
            "Total Loss: 0.004035092907722625\n",
            "----------------------------------------\n",
            "Epoch 167\n",
            "Var loss:  tensor(0.0040, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005264425101702584\n",
            "E_s_wdiff_all_sq: 0.0012566894794211387\n",
            "E_IS_SCOPE: 9.094188369113313e-07\n",
            "E_IS_E_SCOPE: 7.720420052833662e-07\n",
            "Total Loss: 0.004008012276219454\n",
            "----------------------------------------\n",
            "Epoch 168\n",
            "Var loss:  tensor(0.0040, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005193052441715927\n",
            "E_s_wdiff_all_sq: 0.0012119403957072095\n",
            "E_IS_SCOPE: 9.228597256264463e-07\n",
            "E_IS_E_SCOPE: 7.852754751720164e-07\n",
            "Total Loss: 0.00398138911478438\n",
            "----------------------------------------\n",
            "Epoch 169\n",
            "Var loss:  tensor(0.0040, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005134882069096538\n",
            "E_s_wdiff_all_sq: 0.0011801184221524466\n",
            "E_IS_SCOPE: 9.268569701980983e-07\n",
            "E_IS_E_SCOPE: 7.889318019898651e-07\n",
            "Total Loss: 0.00395504139755526\n",
            "----------------------------------------\n",
            "Epoch 170\n",
            "Var loss:  tensor(0.0039, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005098758882083571\n",
            "E_s_wdiff_all_sq: 0.0011703966543161178\n",
            "E_IS_SCOPE: 9.166515621243388e-07\n",
            "E_IS_E_SCOPE: 7.781152696345467e-07\n",
            "Total Loss: 0.003928641200627186\n",
            "----------------------------------------\n",
            "Epoch 171\n",
            "Var loss:  tensor(0.0039, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005078734428481101\n",
            "E_s_wdiff_all_sq: 0.0011764447434115851\n",
            "E_IS_SCOPE: 8.959611941256223e-07\n",
            "E_IS_E_SCOPE: 7.566057236142552e-07\n",
            "Total Loss: 0.0039025702962852907\n",
            "----------------------------------------\n",
            "Epoch 172\n",
            "Var loss:  tensor(0.0039, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005067777516373937\n",
            "E_s_wdiff_all_sq: 0.0011910896128824598\n",
            "E_IS_SCOPE: 8.715901871625362e-07\n",
            "E_IS_E_SCOPE: 7.313480148413162e-07\n",
            "Total Loss: 0.003876970288110873\n",
            "----------------------------------------\n",
            "Epoch 173\n",
            "Var loss:  tensor(0.0039, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005041734322092077\n",
            "E_s_wdiff_all_sq: 0.0011904918142149462\n",
            "E_IS_SCOPE: 8.580975759760437e-07\n",
            "E_IS_E_SCOPE: 7.17141540871298e-07\n",
            "Total Loss: 0.003851526320222093\n",
            "----------------------------------------\n",
            "Epoch 174\n",
            "Var loss:  tensor(0.0038, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004995700770393556\n",
            "E_s_wdiff_all_sq: 0.0011699683128826666\n",
            "E_IS_SCOPE: 8.575884887187991e-07\n",
            "E_IS_E_SCOPE: 7.161439977385609e-07\n",
            "Total Loss: 0.003826017246767602\n",
            "----------------------------------------\n",
            "Epoch 175\n",
            "Var loss:  tensor(0.0038, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004942487627150221\n",
            "E_s_wdiff_all_sq: 0.001141972813686249\n",
            "E_IS_SCOPE: 8.626024070203891e-07\n",
            "E_IS_E_SCOPE: 7.207700224896264e-07\n",
            "Total Loss: 0.003800800378507786\n",
            "----------------------------------------\n",
            "Epoch 176\n",
            "Var loss:  tensor(0.0038, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004889388032648047\n",
            "E_s_wdiff_all_sq: 0.0011137203007227888\n",
            "E_IS_SCOPE: 8.668604604543136e-07\n",
            "E_IS_E_SCOPE: 7.246127747364586e-07\n",
            "Total Loss: 0.0037759541275714462\n",
            "----------------------------------------\n",
            "Epoch 177\n",
            "Var loss:  tensor(0.0038, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004851455578606807\n",
            "E_s_wdiff_all_sq: 0.0011006254558783525\n",
            "E_IS_SCOPE: 8.608900150070084e-07\n",
            "E_IS_E_SCOPE: 7.18033795434341e-07\n",
            "Total Loss: 0.003751117735442353\n",
            "----------------------------------------\n",
            "Epoch 178\n",
            "Var loss:  tensor(0.0037, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004831378697673755\n",
            "E_s_wdiff_all_sq: 0.0011051875617490872\n",
            "E_IS_SCOPE: 8.426187659234638e-07\n",
            "E_IS_E_SCOPE: 6.989407859613245e-07\n",
            "Total Loss: 0.003726480392159345\n",
            "----------------------------------------\n",
            "Epoch 179\n",
            "Var loss:  tensor(0.0037, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.0048249035947001894\n",
            "E_s_wdiff_all_sq: 0.0011231388540928254\n",
            "E_IS_SCOPE: 8.172766048711727e-07\n",
            "E_IS_E_SCOPE: 6.726684801074345e-07\n",
            "Total Loss: 0.0037020558571316444\n",
            "----------------------------------------\n",
            "Epoch 180\n",
            "Var loss:  tensor(0.0037, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004810112711160102\n",
            "E_s_wdiff_all_sq: 0.0011325047064383992\n",
            "E_IS_SCOPE: 7.984570469702854e-07\n",
            "E_IS_E_SCOPE: 6.530426608695024e-07\n",
            "Total Loss: 0.0036779007337686574\n",
            "----------------------------------------\n",
            "Epoch 181\n",
            "Var loss:  tensor(0.0037, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004764548128711829\n",
            "E_s_wdiff_all_sq: 0.0011112316521693622\n",
            "E_IS_SCOPE: 7.97640404429613e-07\n",
            "E_IS_E_SCOPE: 6.517311229947027e-07\n",
            "Total Loss: 0.003653610195380089\n",
            "----------------------------------------\n",
            "Epoch 182\n",
            "Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004712310194641897\n",
            "E_s_wdiff_all_sq: 0.0010828972227594448\n",
            "E_IS_SCOPE: 8.024652665894328e-07\n",
            "E_IS_E_SCOPE: 6.561677301145933e-07\n",
            "Total Loss: 0.003629707467230155\n",
            "----------------------------------------\n",
            "Epoch 183\n",
            "Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.0046709069476284885\n",
            "E_s_wdiff_all_sq: 0.0010651705965772271\n",
            "E_IS_SCOPE: 8.01668018823555e-07\n",
            "E_IS_E_SCOPE: 6.548995988544426e-07\n",
            "Total Loss: 0.003606031788165953\n",
            "----------------------------------------\n",
            "Epoch 184\n",
            "Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.0046494355893586135\n",
            "E_s_wdiff_all_sq: 0.0010672905028057899\n",
            "E_IS_SCOPE: 7.889046296089398e-07\n",
            "E_IS_E_SCOPE: 6.41476588797913e-07\n",
            "Total Loss: 0.003582441842909198\n",
            "----------------------------------------\n",
            "Epoch 185\n",
            "Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.0046349041007615515\n",
            "E_s_wdiff_all_sq: 0.0010762206752812865\n",
            "E_IS_SCOPE: 7.697467985990959e-07\n",
            "E_IS_E_SCOPE: 6.2156329711649e-07\n",
            "Total Loss: 0.003558981692757982\n",
            "----------------------------------------\n",
            "Epoch 186\n",
            "Var loss:  tensor(0.0035, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004609581304227192\n",
            "E_s_wdiff_all_sq: 0.0010741162147654528\n",
            "E_IS_SCOPE: 7.566114774605808e-07\n",
            "E_IS_E_SCOPE: 6.07784845230346e-07\n",
            "Total Loss: 0.0035357646430009522\n",
            "----------------------------------------\n",
            "Epoch 187\n",
            "Var loss:  tensor(0.0035, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004576704808092104\n",
            "E_s_wdiff_all_sq: 0.0010642753377744089\n",
            "E_IS_SCOPE: 7.485972758357742e-07\n",
            "E_IS_E_SCOPE: 5.992416780840037e-07\n",
            "Total Loss: 0.003512730081787951\n",
            "----------------------------------------\n",
            "Epoch 188\n",
            "Var loss:  tensor(0.0035, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004536206148322164\n",
            "E_s_wdiff_all_sq: 0.0010466724343208987\n",
            "E_IS_SCOPE: 7.467388651630075e-07\n",
            "E_IS_E_SCOPE: 5.969592894551453e-07\n",
            "Total Loss: 0.003489835173427433\n",
            "----------------------------------------\n",
            "Epoch 189\n",
            "Var loss:  tensor(0.0035, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004498236491801987\n",
            "E_s_wdiff_all_sq: 0.0010314592779661997\n",
            "E_IS_SCOPE: 7.441602339296764e-07\n",
            "E_IS_E_SCOPE: 5.939615051099517e-07\n",
            "Total Loss: 0.00346707951156818\n",
            "----------------------------------------\n",
            "Epoch 190\n",
            "Var loss:  tensor(0.0034, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004468924180444248\n",
            "E_s_wdiff_all_sq: 0.001024723811763508\n",
            "E_IS_SCOPE: 7.368173174951087e-07\n",
            "E_IS_E_SCOPE: 5.861297242028363e-07\n",
            "Total Loss: 0.003444503644142078\n",
            "----------------------------------------\n",
            "Epoch 191\n",
            "Var loss:  tensor(0.0034, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004448983925283799\n",
            "E_s_wdiff_all_sq: 0.0010271130909300162\n",
            "E_IS_SCOPE: 7.242571222734109e-07\n",
            "E_IS_E_SCOPE: 5.729302937282573e-07\n",
            "Total Loss: 0.003422175388285626\n",
            "----------------------------------------\n",
            "Epoch 192\n",
            "Var loss:  tensor(0.0034, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004423233194831453\n",
            "E_s_wdiff_all_sq: 0.0010232874800201837\n",
            "E_IS_SCOPE: 7.149746002165773e-07\n",
            "E_IS_E_SCOPE: 5.628919936941227e-07\n",
            "Total Loss: 0.0034002517802990675\n",
            "----------------------------------------\n",
            "Epoch 193\n",
            "Var loss:  tensor(0.0034, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004389443386687223\n",
            "E_s_wdiff_all_sq: 0.001011307603792663\n",
            "E_IS_SCOPE: 7.101616689289592e-07\n",
            "E_IS_E_SCOPE: 5.573902690416607e-07\n",
            "Total Loss: 0.0033784432259690873\n",
            "----------------------------------------\n",
            "Epoch 194\n",
            "Var loss:  tensor(0.0034, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004359353417463506\n",
            "E_s_wdiff_all_sq: 0.0010028278609429215\n",
            "E_IS_SCOPE: 7.039567721772232e-07\n",
            "E_IS_E_SCOPE: 5.504752838751707e-07\n",
            "Total Loss: 0.0033568344197719424\n",
            "----------------------------------------\n",
            "Epoch 195\n",
            "Var loss:  tensor(0.0033, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.00433250644488849\n",
            "E_s_wdiff_all_sq: 0.0009974266834676922\n",
            "E_IS_SCOPE: 6.961567879279808e-07\n",
            "E_IS_E_SCOPE: 5.419506713140584e-07\n",
            "Total Loss: 0.0033353900739287777\n",
            "----------------------------------------\n",
            "Epoch 196\n",
            "Var loss:  tensor(0.0033, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004307191150940204\n",
            "E_s_wdiff_all_sq: 0.0009934225166424882\n",
            "E_IS_SCOPE: 6.88138711898242e-07\n",
            "E_IS_E_SCOPE: 5.3321454970314e-07\n",
            "Total Loss: 0.003314080382896859\n",
            "----------------------------------------\n",
            "Epoch 197\n",
            "Var loss:  tensor(0.0033, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004281452467245057\n",
            "E_s_wdiff_all_sq: 0.0009888347871489878\n",
            "E_IS_SCOPE: 6.811485412985601e-07\n",
            "E_IS_E_SCOPE: 5.255322502037095e-07\n",
            "Total Loss: 0.003292930812953011\n",
            "----------------------------------------\n",
            "Epoch 198\n",
            "Var loss:  tensor(0.0033, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004254658478690678\n",
            "E_s_wdiff_all_sq: 0.0009830391035873592\n",
            "E_IS_SCOPE: 6.754693697462542e-07\n",
            "E_IS_E_SCOPE: 5.191929017375946e-07\n",
            "Total Loss: 0.0032719338283140886\n",
            "----------------------------------------\n",
            "Epoch 199\n",
            "Var loss:  tensor(0.0033, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004227576518762368\n",
            "E_s_wdiff_all_sq: 0.0009768376099179945\n",
            "E_IS_SCOPE: 6.705222658861819e-07\n",
            "E_IS_E_SCOPE: 5.136074783411824e-07\n",
            "Total Loss: 0.0032510546386942166\n",
            "----------------------------------------\n",
            "Epoch 200\n",
            "Var loss:  tensor(0.0032, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004201757957507674\n",
            "E_s_wdiff_all_sq: 0.00097174064474578\n",
            "E_IS_SCOPE: 6.652389060076409e-07\n",
            "E_IS_E_SCOPE: 5.077035404547203e-07\n",
            "Total Loss: 0.003230334283767753\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[-0.1982, -0.5572],\n",
            "        [-0.1966,  0.6373],\n",
            "        [-0.1872,  0.6034],\n",
            "        [ 0.2048,  0.2073],\n",
            "        [ 0.0360,  0.0917],\n",
            "        [-0.5381, -0.2891],\n",
            "        [ 0.4075,  0.6089],\n",
            "        [-0.0640,  0.5867],\n",
            "        [-0.4904,  0.6757],\n",
            "        [ 0.4426, -0.2146],\n",
            "        [-0.0742, -0.5438],\n",
            "        [ 0.5966, -0.7549],\n",
            "        [ 0.5963, -0.2325],\n",
            "        [-0.2952,  0.0108],\n",
            "        [ 0.1167, -0.6869],\n",
            "        [ 0.1609, -0.6295]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([ 0.6531, -0.2189, -0.6595, -0.4758,  0.1414, -0.0896, -0.4736, -0.6275,\n",
            "        -0.2590, -0.2865, -0.0873,  0.2530, -0.1865,  0.3412, -0.6498, -0.2523],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[-0.1546, -0.0545, -0.0697, -0.0867, -0.0794, -0.2138, -0.2200,  0.0882,\n",
            "         -0.0215,  0.0129,  0.0420,  0.1505,  0.1874,  0.1642, -0.2323, -0.0318],\n",
            "        [ 0.0802,  0.0086, -0.0644, -0.1551,  0.1024, -0.0680, -0.0411, -0.1347,\n",
            "         -0.1220,  0.1177, -0.0411, -0.1531,  0.0137,  0.0704,  0.0098,  0.0463],\n",
            "        [-0.1535, -0.2394,  0.1020,  0.1508,  0.2561,  0.0950,  0.1881, -0.0211,\n",
            "         -0.1755,  0.2078, -0.1304,  0.1400,  0.0854, -0.1028, -0.0756,  0.0118],\n",
            "        [ 0.1521,  0.1843,  0.1161, -0.1471, -0.2114, -0.0303,  0.2202,  0.0156,\n",
            "          0.2065,  0.0229, -0.0116, -0.1288, -0.1105, -0.1625,  0.2154,  0.2138],\n",
            "        [ 0.0022,  0.0768, -0.0332,  0.2388,  0.2647,  0.0675,  0.1308,  0.1305,\n",
            "         -0.2184, -0.0698, -0.1668, -0.1146, -0.0992,  0.0173,  0.0410,  0.0983],\n",
            "        [ 0.0632, -0.1089, -0.0067, -0.2158, -0.2066,  0.1576,  0.0614,  0.1457,\n",
            "         -0.2282,  0.0700, -0.1871, -0.1209,  0.1555,  0.0320, -0.0318,  0.2479],\n",
            "        [-0.2332, -0.1246,  0.2135,  0.1455,  0.1984, -0.1430,  0.2140,  0.1744,\n",
            "         -0.1596, -0.0706,  0.2149,  0.1696, -0.1465,  0.0323, -0.1672,  0.0926],\n",
            "        [ 0.1089,  0.1670, -0.2249, -0.2189,  0.1179, -0.0113, -0.0678,  0.2028,\n",
            "         -0.1757,  0.0023, -0.0385,  0.1358, -0.1601, -0.0097,  0.1769, -0.2432],\n",
            "        [-0.0463,  0.1378, -0.0290,  0.0715,  0.1556, -0.0367,  0.1482, -0.1757,\n",
            "         -0.1539, -0.1673, -0.0841,  0.0339,  0.2838,  0.1859,  0.2242,  0.2398],\n",
            "        [ 0.1387,  0.1727,  0.2009,  0.0136, -0.1266,  0.1731, -0.2164,  0.1936,\n",
            "         -0.0926,  0.1236, -0.0625, -0.2264, -0.4129, -0.1619, -0.1795, -0.0079],\n",
            "        [-0.0399,  0.1163,  0.1206, -0.1231,  0.1247, -0.0755, -0.2203,  0.1003,\n",
            "          0.0034, -0.0572,  0.1353, -0.0008, -0.2254, -0.2079, -0.1988, -0.1142],\n",
            "        [ 0.0976,  0.0315,  0.0430, -0.0254, -0.1001,  0.2371, -0.1523, -0.2132,\n",
            "          0.1539, -0.0044,  0.0943,  0.0544,  0.1760, -0.1598, -0.0526, -0.2768],\n",
            "        [ 0.0351,  0.0720, -0.0836,  0.1628, -0.0845, -0.0819,  0.1836, -0.2252,\n",
            "         -0.1398, -0.0636, -0.1314,  0.1209, -0.2052,  0.1925,  0.1158, -0.1535],\n",
            "        [ 0.0212,  0.1279, -0.1914,  0.1408,  0.0490,  0.0389,  0.0423, -0.0826,\n",
            "          0.2231,  0.0557,  0.0821,  0.2298,  0.2168, -0.2212,  0.0398,  0.2307],\n",
            "        [-0.0565, -0.0334, -0.0393,  0.1867,  0.0327,  0.0709, -0.1260, -0.0740,\n",
            "         -0.0886, -0.2016,  0.2351,  0.2023, -0.0943,  0.0312,  0.2274, -0.0230],\n",
            "        [-0.1809,  0.1610, -0.1408, -0.1244,  0.1742,  0.0923, -0.2062,  0.2557,\n",
            "         -0.2121, -0.0775,  0.2405,  0.2165,  0.1261,  0.2476,  0.1001, -0.1018],\n",
            "        [-0.0192,  0.0173,  0.1256, -0.0156, -0.0270,  0.0490, -0.0512,  0.0649,\n",
            "         -0.1934, -0.1255,  0.0803, -0.1295, -0.1560,  0.0079,  0.0418,  0.2188],\n",
            "        [-0.2111,  0.1921,  0.2242,  0.0515, -0.0755,  0.1394,  0.1820, -0.1806,\n",
            "         -0.0030, -0.1068,  0.2356,  0.0478, -0.1334, -0.1540, -0.0214, -0.0463],\n",
            "        [ 0.0334, -0.1430, -0.0417, -0.2481, -0.1653,  0.2342,  0.0070,  0.0118,\n",
            "         -0.2491, -0.0443, -0.0636, -0.0087,  0.0592,  0.1518,  0.2170, -0.0180],\n",
            "        [ 0.1481,  0.1155,  0.2205,  0.0945,  0.0494,  0.1236, -0.0701, -0.0263,\n",
            "         -0.3350, -0.0497, -0.1500, -0.3071,  0.1145,  0.1081,  0.1766,  0.1611],\n",
            "        [-0.2410, -0.1346,  0.1229,  0.1418, -0.0822, -0.0168, -0.1592, -0.1896,\n",
            "          0.1664,  0.0893, -0.0971,  0.1895,  0.2506,  0.1666, -0.0472,  0.0458],\n",
            "        [ 0.0842,  0.2755, -0.2420,  0.0596,  0.0655,  0.0495,  0.1064, -0.0195,\n",
            "          0.2155, -0.1148,  0.0489, -0.2266,  0.1923, -0.0160,  0.1085, -0.2453],\n",
            "        [-0.1452,  0.2444, -0.1142, -0.1677, -0.1545, -0.0282, -0.0396,  0.1553,\n",
            "         -0.1745,  0.1249,  0.0963, -0.0875, -0.0083,  0.1906, -0.2387, -0.1926],\n",
            "        [-0.1340,  0.1325, -0.1715, -0.0767, -0.3052,  0.0273, -0.0505,  0.0942,\n",
            "         -0.2032, -0.1079, -0.1551,  0.1173,  0.1880, -0.1975, -0.1104,  0.1976],\n",
            "        [-0.0623,  0.1707,  0.2052,  0.1002,  0.0170, -0.2230,  0.2580,  0.0406,\n",
            "         -0.1152, -0.0750, -0.1574,  0.0559, -0.1226,  0.2420, -0.1214,  0.0797],\n",
            "        [ 0.0108,  0.1957,  0.0510, -0.2114, -0.0662, -0.2477,  0.0530,  0.1546,\n",
            "          0.1367, -0.2128, -0.1689, -0.0409,  0.1100, -0.1452,  0.1201,  0.0693],\n",
            "        [ 0.0493, -0.1933, -0.1683, -0.1329,  0.2132,  0.1135, -0.0402, -0.1131,\n",
            "         -0.0138, -0.1450,  0.0649,  0.1615, -0.2229,  0.2334,  0.0560, -0.1925],\n",
            "        [ 0.0568, -0.1142, -0.0405, -0.2190,  0.3011, -0.1397, -0.0906,  0.1108,\n",
            "          0.1830,  0.1712, -0.2286, -0.0654,  0.0701, -0.2764, -0.2392,  0.1708],\n",
            "        [-0.0850, -0.1332,  0.0961, -0.0646, -0.1389,  0.2093, -0.1233, -0.2249,\n",
            "         -0.0603, -0.0842,  0.0493, -0.1323, -0.2014, -0.0563, -0.2218, -0.1645],\n",
            "        [-0.2214,  0.1204,  0.1781, -0.1904,  0.0810, -0.2487, -0.0085, -0.1260,\n",
            "          0.0559, -0.1381, -0.0150, -0.2701,  0.0648,  0.2134,  0.2258, -0.1195],\n",
            "        [-0.0683, -0.0635, -0.0428, -0.2306, -0.0144,  0.0132, -0.1317,  0.1891,\n",
            "         -0.1345,  0.1695, -0.1253,  0.0689,  0.1748, -0.0326,  0.0112,  0.0301],\n",
            "        [ 0.0842,  0.1448, -0.1303,  0.0008, -0.1123, -0.0491, -0.1082,  0.1981,\n",
            "          0.0015,  0.1279,  0.2473,  0.1515, -0.0186, -0.2113,  0.0246,  0.1176]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([ 0.0172, -0.1504, -0.0874, -0.2893,  0.2289, -0.1769,  0.1101,  0.0386,\n",
            "         0.1417,  0.0211, -0.0096,  0.0535,  0.1977,  0.0695,  0.2758,  0.2096,\n",
            "        -0.1818, -0.0889, -0.1757, -0.0723, -0.2244,  0.2384,  0.2637,  0.1348,\n",
            "        -0.1132,  0.0609,  0.1632, -0.1413, -0.1888,  0.1368,  0.0030, -0.1752],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[-0.0866,  0.0072,  0.1330,  0.0939,  0.0215, -0.2428, -0.0581,  0.1353,\n",
            "         -0.0059,  0.0968, -0.0737,  0.0536,  0.1304, -0.1576, -0.1444, -0.1279,\n",
            "          0.0682, -0.0187, -0.1720, -0.0956,  0.0347, -0.0174, -0.1482,  0.0554,\n",
            "          0.0281, -0.0432,  0.0036, -0.1145, -0.0082, -0.0987,  0.1181,  0.1102]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([0.1307], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# doubly cumprod, not sure which is right for stepIS\n",
        "model5 = train_var_play(model4, 50, 0.00001, padded_state_tensors, states_first_tensor, states_last_tensor, samples_all_shaping, samples_IS_SCOPE, testing)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymZsAiRhT_Y7",
        "outputId": "0e2605cb-8f98-4742-ed50-1a64d5f7046a"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Var loss:  tensor(3.8975e+86, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 7.837653119776905e+86\n",
            "E_s_wdiff_all_sq: 3.936778943589322e+86\n",
            "E_IS_SCOPE: -4.922151070341052e+83\n",
            "E_IS_E_SCOPE: -3.229592269140938e+83\n",
            "Total Loss: 3.897490314804813e+86\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "Var loss:  tensor(6.8576e+88, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 1.3783057143777487e+89\n",
            "E_s_wdiff_all_sq: 6.925931966846359e+88\n",
            "E_IS_SCOPE: 6.527757697009708e+84\n",
            "E_IS_E_SCOPE: 4.283174687928771e+84\n",
            "Total Loss: 6.857574106095142e+88\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "Var loss:  tensor(4.5003e+87, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 9.044137064483694e+87\n",
            "E_s_wdiff_all_sq: 4.545021682025533e+87\n",
            "E_IS_SCOPE: 1.672171354213606e+84\n",
            "E_IS_E_SCOPE: 1.0971964008089646e+84\n",
            "Total Loss: 4.500265457986933e+87\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "Var loss:  tensor(1.5214e+88, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 3.0583029353013085e+88\n",
            "E_s_wdiff_all_sq: 1.5366475625865213e+88\n",
            "E_IS_SCOPE: -3.074858116302592e+84\n",
            "E_IS_E_SCOPE: -2.017552623022135e+84\n",
            "Total Loss: 1.5214439241783276e+88\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "Var loss:  tensor(3.8990e+88, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 7.837268553336831e+88\n",
            "E_s_wdiff_all_sq: 3.9379339053594285e+88\n",
            "E_IS_SCOPE: -4.922308531912808e+84\n",
            "E_IS_E_SCOPE: -3.2297516233039736e+84\n",
            "Total Loss: 3.898996149157877e+88\n",
            "----------------------------------------\n",
            "Epoch 6\n",
            "Var loss:  tensor(2.7116e+88, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 5.4506295872945704e+88\n",
            "E_s_wdiff_all_sq: 2.7387164761149973e+88\n",
            "E_IS_SCOPE: -4.104963120562134e+84\n",
            "E_IS_E_SCOPE: -2.693452904678721e+84\n",
            "Total Loss: 2.711630821698593e+88\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "Var loss:  tensor(5.9902e+87, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 1.2041596706721822e+88\n",
            "E_s_wdiff_all_sq: 6.050094371557648e+87\n",
            "E_IS_SCOPE: -1.9294089061961931e+84\n",
            "E_IS_E_SCOPE: -1.2659695895298638e+84\n",
            "Total Loss: 5.990175582152803e+87\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "Var loss:  tensor(6.2260e+86, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 1.2509352348714792e+87\n",
            "E_s_wdiff_all_sq: 6.287611866075718e+86\n",
            "E_IS_SCOPE: 6.219108809846561e+83\n",
            "E_IS_E_SCOPE: 4.080711692570723e+83\n",
            "Total Loss: 6.226018533093256e+86\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "Var loss:  tensor(1.1302e+88, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 2.2715648269907793e+88\n",
            "E_s_wdiff_all_sq: 1.1415002787395577e+88\n",
            "E_IS_SCOPE: 2.6500667929330647e+84\n",
            "E_IS_E_SCOPE: 1.7388395342654813e+84\n",
            "Total Loss: 1.1302468062651514e+88\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "Var loss:  tensor(1.9833e+88, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 3.986042073292496e+88\n",
            "E_s_wdiff_all_sq: 2.0030198205023387e+88\n",
            "E_IS_SCOPE: 3.510459375607212e+84\n",
            "E_IS_E_SCOPE: 2.303383524109326e+84\n",
            "Total Loss: 1.9832636805226533e+88\n",
            "----------------------------------------\n",
            "Epoch 11\n",
            "Var loss:  tensor(1.5900e+88, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 3.195653088273935e+88\n",
            "E_s_wdiff_all_sq: 1.6058526817015858e+88\n",
            "E_IS_SCOPE: 3.143209092939606e+84\n",
            "E_IS_E_SCOPE: 2.062413362375359e+84\n",
            "Total Loss: 1.5900165782806578e+88\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "Var loss:  tensor(5.7458e+87, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 1.1547485063429879e+88\n",
            "E_s_wdiff_all_sq: 5.802974245104604e+87\n",
            "E_IS_SCOPE: 1.8894699655776472e+84\n",
            "E_IS_E_SCOPE: 1.239776227470915e+84\n",
            "Total Loss: 5.74581033142345e+87\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "Var loss:  tensor(7.9471e+85, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 1.5956256908839205e+86\n",
            "E_s_wdiff_all_sq: 8.024481018307015e+85\n",
            "E_IS_SCOPE: 2.2213395875670698e+83\n",
            "E_IS_E_SCOPE: 1.45758751542778e+83\n",
            "Total Loss: 7.947063494171279e+85\n",
            "----------------------------------------\n",
            "Epoch 14\n",
            "Var loss:  tensor(2.9157e+87, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 5.861457695178025e+87\n",
            "E_s_wdiff_all_sq: 2.9448653606518576e+87\n",
            "E_IS_SCOPE: -1.3461146328497164e+84\n",
            "E_IS_E_SCOPE: -8.83242816702203e+83\n",
            "Total Loss: 2.9156667165158357e+87\n",
            "----------------------------------------\n",
            "Epoch 15\n",
            "Var loss:  tensor(8.9492e+87, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 1.798943371559614e+88\n",
            "E_s_wdiff_all_sq: 9.038642868581803e+87\n",
            "E_IS_SCOPE: -2.3582630793778606e+84\n",
            "E_IS_E_SCOPE: -1.5473609573610972e+84\n",
            "Total Loss: 8.949169168392268e+87\n",
            "----------------------------------------\n",
            "Epoch 16\n",
            "Var loss:  tensor(1.0661e+88, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 2.1429836072185233e+88\n",
            "E_s_wdiff_all_sq: 1.0767316325215912e+88\n",
            "E_IS_SCOPE: -2.573910293310698e+84\n",
            "E_IS_E_SCOPE: -1.6888572242494243e+84\n",
            "Total Loss: 1.0660749766453165e+88\n",
            "----------------------------------------\n",
            "Epoch 17\n",
            "Var loss:  tensor(6.6488e+87, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 1.3365460659669224e+88\n",
            "E_s_wdiff_all_sq: 6.7152802868889205e+87\n",
            "E_IS_SCOPE: -2.032705961192708e+84\n",
            "E_IS_E_SCOPE: -1.333747639224853e+84\n",
            "Total Loss: 6.64878258175833e+87\n",
            "----------------------------------------\n",
            "Epoch 18\n",
            "Var loss:  tensor(1.5255e+87, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 3.067038500759716e+87\n",
            "E_s_wdiff_all_sq: 1.5408342807567995e+87\n",
            "E_IS_SCOPE: -9.737221076570453e+83\n",
            "E_IS_E_SCOPE: -6.388985878829503e+83\n",
            "Total Loss: 1.5255346985853312e+87\n",
            "----------------------------------------\n",
            "Epoch 19\n",
            "Var loss:  tensor(1.1045e+86, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 2.217950638602012e+86\n",
            "E_s_wdiff_all_sq: 1.1152759314217639e+86\n",
            "E_IS_SCOPE: 2.6188838977173844e+83\n",
            "E_IS_E_SCOPE: 1.7184350142558822e+83\n",
            "Total Loss: 1.1044768611668018e+86\n",
            "----------------------------------------\n",
            "Epoch 20\n",
            "Var loss:  tensor(2.7594e+87, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 5.54534866802881e+87\n",
            "E_s_wdiff_all_sq: 2.7868343232000967e+87\n",
            "E_IS_SCOPE: 1.309374437032462e+84\n",
            "E_IS_E_SCOPE: 8.591483019713049e+83\n",
            "Total Loss: 2.7594149227207985e+87\n",
            "----------------------------------------\n",
            "Epoch 21\n",
            "Var loss:  tensor(5.6809e+87, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 1.1417080144477217e+88\n",
            "E_s_wdiff_all_sq: 5.737444915957507e+87\n",
            "E_IS_SCOPE: 1.8787710174160626e+84\n",
            "E_IS_E_SCOPE: 1.2327561453964254e+84\n",
            "Total Loss: 5.680927383885712e+87\n",
            "----------------------------------------\n",
            "Epoch 22\n",
            "Var loss:  tensor(5.5033e+87, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 1.1060027672678821e+88\n",
            "E_s_wdiff_all_sq: 5.558023590427719e+87\n",
            "E_IS_SCOPE: 1.849160244884443e+84\n",
            "E_IS_E_SCOPE: 1.2133271266416297e+84\n",
            "Total Loss: 5.50327587410955e+87\n",
            "----------------------------------------\n",
            "Epoch 23\n",
            "Var loss:  tensor(2.6745e+87, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 5.3745910497876315e+87\n",
            "E_s_wdiff_all_sq: 2.701025572434766e+87\n",
            "E_IS_SCOPE: 1.2890575346034187e+84\n",
            "E_IS_E_SCOPE: 8.458174280586367e+83\n",
            "Total Loss: 2.6744520831879185e+87\n",
            "----------------------------------------\n",
            "Epoch 24\n",
            "Var loss:  tensor(2.6730e+86, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 5.369605364434185e+86\n",
            "E_s_wdiff_all_sq: 2.699367556334373e+86\n",
            "E_IS_SCOPE: 4.074677525458872e+83\n",
            "E_IS_E_SCOPE: 2.673649600634012e+83\n",
            "Total Loss: 2.6730411201690913e+86\n",
            "----------------------------------------\n",
            "Epoch 25\n",
            "Var loss:  tensor(4.2614e+86, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 8.56936141220449e+86\n",
            "E_s_wdiff_all_sq: 4.3043805516183637e+86\n",
            "E_IS_SCOPE: -5.146800735968692e+83\n",
            "E_IS_E_SCOPE: -3.376995458396228e+83\n",
            "Total Loss: 4.261442506250611e+86\n",
            "----------------------------------------\n",
            "Epoch 26\n",
            "Var loss:  tensor(2.3215e+87, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 4.667121919114039e+87\n",
            "E_s_wdiff_all_sq: 2.3447776402080183e+87\n",
            "E_IS_SCOPE: -1.2011648130209186e+84\n",
            "E_IS_E_SCOPE: -7.881344304440632e+83\n",
            "Total Loss: 2.32151834376283e+87\n",
            "----------------------------------------\n",
            "Epoch 27\n",
            "Var loss:  tensor(3.4505e+87, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 6.9364773411371185e+87\n",
            "E_s_wdiff_all_sq: 3.4850070260869156e+87\n",
            "E_IS_SCOPE: -1.4643656124980096e+84\n",
            "E_IS_E_SCOPE: -9.608328385946076e+83\n",
            "Total Loss: 3.4504633751243594e+87\n",
            "----------------------------------------\n",
            "Epoch 28\n",
            "Var loss:  tensor(2.5625e+87, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 5.151474009308681e+87\n",
            "E_s_wdiff_all_sq: 2.5881371826118765e+87\n",
            "E_IS_SCOPE: -1.2619563216603506e+84\n",
            "E_IS_E_SCOPE: -8.280225947952616e+83\n",
            "Total Loss: 2.5624690848650376e+87\n",
            "----------------------------------------\n",
            "Epoch 29\n",
            "Var loss:  tensor(7.7909e+86, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 1.5664877086556264e+87\n",
            "E_s_wdiff_all_sq: 7.869195685604381e+86\n",
            "E_IS_SCOPE: -6.958784933936726e+83\n",
            "E_IS_E_SCOPE: -4.5659234052440576e+83\n",
            "Total Loss: 7.790896934114128e+86\n",
            "----------------------------------------\n",
            "Epoch 30\n",
            "Var loss:  tensor(1.6952e+84, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 3.3820384868950102e+84\n",
            "E_s_wdiff_all_sq: 1.7092209991157447e+84\n",
            "E_IS_SCOPE: 3.2365863302345985e+82\n",
            "E_IS_E_SCOPE: 2.1242990703737244e+82\n",
            "Total Loss: 1.6951888549395312e+84\n",
            "----------------------------------------\n",
            "Epoch 31\n",
            "Var loss:  tensor(7.5709e+86, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 1.5211939901987585e+87\n",
            "E_s_wdiff_all_sq: 7.645806988566776e+86\n",
            "E_IS_SCOPE: 6.858055967814821e+83\n",
            "E_IS_E_SCOPE: 4.49995494747505e+83\n",
            "Total Loss: 7.57085037168112e+86\n",
            "----------------------------------------\n",
            "Epoch 32\n",
            "Var loss:  tensor(1.8262e+87, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 3.6698412575815546e+87\n",
            "E_s_wdiff_all_sq: 1.8443519647089066e+87\n",
            "E_IS_SCOPE: 1.06518590189668e+84\n",
            "E_IS_E_SCOPE: 6.989247341010318e+83\n",
            "Total Loss: 1.8262219408302022e+87\n",
            "----------------------------------------\n",
            "Epoch 33\n",
            "Var loss:  tensor(1.8518e+87, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 3.7211967054981814e+87\n",
            "E_s_wdiff_all_sq: 1.870159395351237e+87\n",
            "E_IS_SCOPE: 1.0726128530914907e+84\n",
            "E_IS_E_SCOPE: 7.037979057110123e+83\n",
            "Total Loss: 1.851775065663668e+87\n",
            "----------------------------------------\n",
            "Epoch 34\n",
            "Var loss:  tensor(8.7443e+86, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 1.7570158690357867e+87\n",
            "E_s_wdiff_all_sq: 8.830924585106656e+86\n",
            "E_IS_SCOPE: 7.370470422235385e+83\n",
            "E_IS_E_SCOPE: 4.8361741429783514e+83\n",
            "Total Loss: 8.744303954029355e+86\n",
            "----------------------------------------\n",
            "Epoch 35\n",
            "Var loss:  tensor(6.0753e+85, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 1.2196174581559286e+86\n",
            "E_s_wdiff_all_sq: 6.134259163521959e+85\n",
            "E_IS_SCOPE: 1.9420922956911794e+83\n",
            "E_IS_E_SCOPE: 1.2743602606239946e+83\n",
            "Total Loss: 6.0752826209349756e+85\n",
            "----------------------------------------\n",
            "Epoch 36\n",
            "Var loss:  tensor(2.1256e+86, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 4.275253337170368e+86\n",
            "E_s_wdiff_all_sq: 2.1471299098150054e+86\n",
            "E_IS_SCOPE: -3.635241037565288e+83\n",
            "E_IS_E_SCOPE: -2.385190129908618e+83\n",
            "Total Loss: 2.1256245817596795e+86\n",
            "----------------------------------------\n",
            "Epoch 37\n",
            "Var loss:  tensor(9.0814e+86, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 1.8259214394910263e+87\n",
            "E_s_wdiff_all_sq: 9.172633943479747e+86\n",
            "E_IS_SCOPE: -7.512982716219675e+83\n",
            "E_IS_E_SCOPE: -4.929558598773401e+83\n",
            "Total Loss: 9.081414859415255e+86\n",
            "----------------------------------------\n",
            "Epoch 38\n",
            "Var loss:  tensor(1.1718e+87, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 2.355984214996604e+87\n",
            "E_s_wdiff_all_sq: 1.1835791444580413e+87\n",
            "E_IS_SCOPE: -8.534138190174724e+83\n",
            "E_IS_E_SCOPE: -5.599586672679444e+83\n",
            "Total Loss: 1.1718182858570266e+87\n",
            "----------------------------------------\n",
            "Epoch 39\n",
            "Var loss:  tensor(6.9890e+86, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 1.4052720717014727e+87\n",
            "E_s_wdiff_all_sq: 7.059228570094e+86\n",
            "E_IS_SCOPE: -6.590965774498347e+83\n",
            "E_IS_E_SCOPE: -4.3245799710571113e+83\n",
            "Total Loss: 6.988960631533475e+86\n",
            "----------------------------------------\n",
            "Epoch 40\n",
            "Var loss:  tensor(1.0744e+86, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 2.1615783609290368e+86\n",
            "E_s_wdiff_all_sq: 1.0853666241201738e+86\n",
            "E_IS_SCOPE: -2.584775092475388e+83\n",
            "E_IS_E_SCOPE: -1.695930076104556e+83\n",
            "Total Loss: 1.0744353029957517e+86\n",
            "----------------------------------------\n",
            "Epoch 41\n",
            "Var loss:  tensor(6.1167e+85, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 1.2279312067750127e+86\n",
            "E_s_wdiff_all_sq: 6.176054380017834e+85\n",
            "E_IS_SCOPE: 1.9486992637973178e+83\n",
            "E_IS_E_SCOPE: 1.278695406294073e+83\n",
            "Total Loss: 6.116670327078663e+85\n",
            "----------------------------------------\n",
            "Epoch 42\n",
            "Var loss:  tensor(4.6883e+86, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 9.419116464001514e+86\n",
            "E_s_wdiff_all_sq: 4.734574838098272e+86\n",
            "E_IS_SCOPE: 5.396585778275006e+83\n",
            "E_IS_E_SCOPE: 3.541015711001669e+83\n",
            "Total Loss: 4.6882540222574187e+86\n",
            "----------------------------------------\n",
            "Epoch 43\n",
            "Var loss:  tensor(7.0907e+86, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 1.4247039376532172e+87\n",
            "E_s_wdiff_all_sq: 7.160894951414018e+86\n",
            "E_IS_SCOPE: 6.636997883289355e+83\n",
            "E_IS_E_SCOPE: 4.3549083611694844e+83\n",
            "Total Loss: 7.090709860382026e+86\n",
            "----------------------------------------\n",
            "Epoch 44\n",
            "Var loss:  tensor(4.7157e+86, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 9.474196544894399e+86\n",
            "E_s_wdiff_all_sq: 4.762256367036719e+86\n",
            "E_IS_SCOPE: 5.41234064027121e+83\n",
            "E_IS_E_SCOPE: 3.551353217268139e+83\n",
            "Total Loss: 4.715663408923316e+86\n",
            "----------------------------------------\n",
            "Epoch 45\n",
            "Var loss:  tensor(8.9897e+85, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 1.80508205151314e+86\n",
            "E_s_wdiff_all_sq: 9.07739096634913e+85\n",
            "E_IS_SCOPE: 2.3626221442221024e+83\n",
            "E_IS_E_SCOPE: 1.5502896543407176e+83\n",
            "Total Loss: 8.989688760776205e+85\n",
            "----------------------------------------\n",
            "Epoch 46\n",
            "Var loss:  tensor(2.5718e+85, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 5.179049186358142e+85\n",
            "E_s_wdiff_all_sq: 2.5985241595554088e+85\n",
            "E_IS_SCOPE: -1.2650507802836305e+83\n",
            "E_IS_E_SCOPE: -8.299969580777913e+82\n",
            "Total Loss: 2.5718365125549215e+85\n",
            "----------------------------------------\n",
            "Epoch 47\n",
            "Var loss:  tensor(2.7068e+86, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 5.443731186792979e+86\n",
            "E_s_wdiff_all_sq: 2.734126528315301e+86\n",
            "E_IS_SCOPE: -4.1020867225103166e+83\n",
            "E_IS_E_SCOPE: -2.691509506822782e+83\n",
            "Total Loss: 2.706784760265933e+86\n",
            "----------------------------------------\n",
            "Epoch 48\n",
            "Var loss:  tensor(4.2963e+86, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 8.639441264088649e+86\n",
            "E_s_wdiff_all_sq: 4.339587949052286e+86\n",
            "E_IS_SCOPE: -5.167804526906915e+83\n",
            "E_IS_E_SCOPE: -3.390777018957542e+83\n",
            "Total Loss: 4.296300516240094e+86\n",
            "----------------------------------------\n",
            "Epoch 49\n",
            "Var loss:  tensor(2.8546e+86, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 5.740822526524662e+86\n",
            "E_s_wdiff_all_sq: 2.88337586359815e+86\n",
            "E_IS_SCOPE: -4.212543734590628e+83\n",
            "E_IS_E_SCOPE: -2.7639855397922327e+83\n",
            "Total Loss: 2.854550802756545e+86\n",
            "----------------------------------------\n",
            "Epoch 50\n",
            "Var loss:  tensor(4.9920e+85, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 1.0047394444118317e+86\n",
            "E_s_wdiff_all_sq: 5.043265829926229e+85\n",
            "E_IS_SCOPE: -1.7621372108929036e+83\n",
            "E_IS_E_SCOPE: -1.156158712885409e+83\n",
            "Total Loss: 4.992021606428242e+85\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[ 0.0057, -0.6100],\n",
            "        [ 0.3443,  0.3599],\n",
            "        [ 0.0603, -0.6894],\n",
            "        [ 0.0467,  0.0746],\n",
            "        [-0.2990, -0.5145],\n",
            "        [ 0.5804, -0.5688],\n",
            "        [ 0.2525,  0.6377],\n",
            "        [-0.0274, -0.5872],\n",
            "        [ 0.3506,  0.6663],\n",
            "        [-0.2037,  0.2161],\n",
            "        [ 0.1259, -0.1210],\n",
            "        [ 0.5856,  0.6529],\n",
            "        [-0.5431, -0.4579],\n",
            "        [-0.3938, -0.1607],\n",
            "        [ 0.5919, -0.2230],\n",
            "        [ 0.2164,  0.1424]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([-0.2603,  0.3900, -0.1267,  0.3600, -0.3407, -0.4320, -0.4568,  0.0077,\n",
            "         0.1181, -0.0323,  0.3781, -0.2170, -0.1138,  0.3433,  0.5592, -0.6726],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[ 0.0385,  0.1607,  0.0537,  0.1362,  0.1027, -0.1052, -0.0967,  0.1405,\n",
            "         -0.2242,  0.1343,  0.2250,  0.1195,  0.0101, -0.0537,  0.0888, -0.0150],\n",
            "        [-0.2443, -0.2089,  0.1078, -0.2029,  0.2421,  0.0321, -0.2072,  0.1845,\n",
            "         -0.1160, -0.2427, -0.1520, -0.2045,  0.1968,  0.1299, -0.0931,  0.0351],\n",
            "        [-0.1388, -0.0849, -0.1800, -0.0828,  0.0163,  0.2144,  0.0428, -0.1220,\n",
            "          0.1630, -0.0051,  0.2334,  0.1353,  0.0479, -0.2065,  0.0663,  0.0205],\n",
            "        [-0.0223, -0.0925,  0.0553,  0.1817,  0.1728,  0.0358,  0.1021,  0.0723,\n",
            "         -0.2108,  0.1436,  0.1223,  0.0515, -0.2234, -0.2380,  0.2588, -0.1484],\n",
            "        [ 0.2326, -0.2058,  0.0210,  0.0105,  0.2428, -0.1296,  0.0172, -0.2466,\n",
            "         -0.0725,  0.2136, -0.1839,  0.1385,  0.2397,  0.1813,  0.0985, -0.0114],\n",
            "        [-0.0598,  0.1158, -0.0868, -0.0648,  0.0944,  0.1485,  0.1504,  0.2069,\n",
            "         -0.1268,  0.1903, -0.0059, -0.1603, -0.1928,  0.2256,  0.0258, -0.0301],\n",
            "        [ 0.0028, -0.1960, -0.1355,  0.2132,  0.1930, -0.1458,  0.1829, -0.2268,\n",
            "         -0.2057,  0.1018, -0.2002, -0.0316,  0.0088, -0.1407, -0.2071, -0.2563],\n",
            "        [ 0.1226, -0.2321, -0.2095,  0.1210,  0.2011, -0.0797, -0.2472, -0.1447,\n",
            "         -0.1118, -0.1112, -0.0644, -0.0462,  0.2324,  0.0267, -0.0405,  0.0270],\n",
            "        [ 0.0356,  0.0735,  0.1655, -0.1377,  0.2421, -0.0151, -0.2196, -0.2296,\n",
            "          0.1087,  0.1373, -0.1671, -0.1895, -0.1617,  0.0957, -0.1707, -0.0964],\n",
            "        [ 0.0864,  0.1653,  0.1580,  0.2232,  0.2087,  0.2240, -0.0733,  0.1772,\n",
            "          0.2404, -0.0513,  0.1970, -0.0834,  0.0132, -0.1743, -0.0942,  0.0490],\n",
            "        [ 0.1404,  0.1331,  0.1049, -0.1975, -0.1276, -0.1781, -0.0294,  0.0525,\n",
            "         -0.0680,  0.0958,  0.0937,  0.0449, -0.2339, -0.1146,  0.0658, -0.2119],\n",
            "        [-0.1854,  0.1002, -0.0539,  0.2179,  0.2327, -0.0351, -0.1866,  0.0155,\n",
            "          0.1941,  0.1905, -0.1512,  0.0818, -0.0459,  0.2223,  0.1095,  0.1137],\n",
            "        [ 0.1301, -0.0741,  0.0088, -0.2102, -0.0019,  0.1090,  0.2121,  0.0169,\n",
            "          0.1982,  0.1137, -0.0476, -0.1419, -0.0138,  0.0242,  0.1944, -0.0159],\n",
            "        [-0.1140,  0.1794,  0.0216, -0.2030, -0.0781, -0.1073, -0.0901,  0.2027,\n",
            "          0.0276, -0.1373, -0.1219, -0.0507,  0.0966, -0.1865,  0.2059,  0.1724],\n",
            "        [-0.0525, -0.2466,  0.0758,  0.2112, -0.2105, -0.0317,  0.0676,  0.0982,\n",
            "          0.0120, -0.1962,  0.1114,  0.0919,  0.0579, -0.1252, -0.2141,  0.1544],\n",
            "        [-0.0700,  0.1529, -0.0512,  0.0674, -0.1620,  0.2611, -0.1782,  0.2083,\n",
            "         -0.1981, -0.1330, -0.1570,  0.2139, -0.2148,  0.1181, -0.0496, -0.1860],\n",
            "        [ 0.2095, -0.1590, -0.0726,  0.0835,  0.0676,  0.0158,  0.1621,  0.2150,\n",
            "          0.0275, -0.0673, -0.0519, -0.0873, -0.1941,  0.1961, -0.0169,  0.2167],\n",
            "        [-0.1702,  0.0076,  0.0832,  0.1387, -0.0534, -0.1946, -0.0532,  0.1080,\n",
            "          0.2263,  0.2426, -0.1710,  0.0973, -0.0738, -0.0918, -0.0796,  0.1665],\n",
            "        [ 0.0752,  0.2095, -0.1088, -0.1003, -0.1436, -0.0289, -0.1112, -0.0959,\n",
            "          0.2292,  0.2397,  0.0689, -0.1798, -0.0281,  0.0557, -0.0527, -0.0226],\n",
            "        [ 0.1749, -0.0238,  0.0266, -0.0917,  0.2317,  0.1405,  0.0147,  0.0478,\n",
            "          0.0114, -0.0634, -0.1340, -0.2402, -0.1246,  0.1135,  0.2237, -0.1618],\n",
            "        [ 0.1508, -0.1032,  0.0307,  0.1573,  0.1597, -0.2207, -0.0863,  0.0799,\n",
            "         -0.0957, -0.1142,  0.1997, -0.0183,  0.0878, -0.1367,  0.1528, -0.1219],\n",
            "        [-0.1164,  0.1273, -0.1732, -0.1619,  0.1850, -0.0230,  0.0280,  0.1014,\n",
            "          0.0235,  0.1276,  0.1700, -0.2250, -0.2457, -0.2397,  0.2155,  0.0816],\n",
            "        [ 0.0717,  0.1566, -0.2082, -0.1406,  0.1578,  0.2227,  0.1878, -0.1951,\n",
            "         -0.0506,  0.0416, -0.1165, -0.0838, -0.2011, -0.0309,  0.0655,  0.1953],\n",
            "        [ 0.1506, -0.0581,  0.0545, -0.1305,  0.0410, -0.0670, -0.1568, -0.2053,\n",
            "         -0.2224, -0.1154,  0.0073,  0.0638, -0.0847, -0.2224, -0.2494,  0.0066],\n",
            "        [ 0.2441, -0.2159,  0.1701,  0.1729,  0.0498, -0.2286, -0.2306,  0.0044,\n",
            "         -0.2085,  0.2553,  0.1823,  0.0364,  0.0049,  0.0330,  0.1710,  0.1530],\n",
            "        [-0.1691,  0.0183,  0.0151,  0.1456, -0.1523,  0.0140,  0.1107,  0.1649,\n",
            "         -0.0961,  0.0369,  0.1660,  0.0854,  0.0902,  0.2101, -0.2266,  0.0532],\n",
            "        [-0.0305,  0.0595, -0.0412, -0.1722, -0.1480,  0.1776,  0.1730, -0.0601,\n",
            "          0.0148, -0.1616,  0.1800,  0.0327,  0.0449, -0.1433, -0.1982,  0.1902],\n",
            "        [-0.2281,  0.1787,  0.2350,  0.1225,  0.1040, -0.2257,  0.1944, -0.1659,\n",
            "         -0.1148,  0.1082, -0.1264,  0.2329, -0.0157,  0.0391, -0.0187,  0.1562],\n",
            "        [ 0.1872, -0.0049, -0.1972, -0.2247,  0.1307,  0.0958, -0.2034,  0.0847,\n",
            "         -0.0691, -0.2042,  0.0478,  0.0534, -0.2466,  0.1539,  0.0483,  0.1013],\n",
            "        [ 0.0984, -0.0091, -0.0703, -0.1365, -0.0303,  0.2239,  0.0346,  0.1965,\n",
            "         -0.0163, -0.1643,  0.1658, -0.0299, -0.2271, -0.0389, -0.2230,  0.1360],\n",
            "        [ 0.0846, -0.1789,  0.1758, -0.0041, -0.0720,  0.1870,  0.1668,  0.0533,\n",
            "          0.1085, -0.2203, -0.0854, -0.1453, -0.0079,  0.1412, -0.1511,  0.2060],\n",
            "        [ 0.1633,  0.1194,  0.2112, -0.2535,  0.2361, -0.1522, -0.1092, -0.1170,\n",
            "         -0.1035, -0.2434, -0.0377,  0.2140,  0.1338,  0.0197, -0.0060, -0.0218]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([-0.0844,  0.2144,  0.2339,  0.1293, -0.2160,  0.1337, -0.1717,  0.0917,\n",
            "        -0.0122,  0.2378, -0.1503,  0.1356,  0.0690, -0.1095, -0.1798,  0.1041,\n",
            "         0.0093,  0.0048, -0.0405, -0.1691,  0.0958,  0.1319,  0.1541,  0.0802,\n",
            "         0.0656,  0.2310, -0.2521,  0.0452,  0.1527,  0.0092,  0.1901, -0.0566],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[-0.1005,  0.1250, -0.1375, -0.0578,  0.0231, -0.1704, -0.0235,  0.0314,\n",
            "         -0.1519,  0.1800, -0.1501,  0.0119, -0.0097, -0.1317,  0.0177, -0.0431,\n",
            "          0.1433,  0.1614,  0.0847,  0.0759,  0.1391, -0.0207,  0.1146,  0.0106,\n",
            "         -0.1546, -0.1361, -0.0071, -0.0994,  0.1144, -0.1813, -0.0998, -0.1650]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([0.0674], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IS Play"
      ],
      "metadata": {
        "id": "hlu2XrJwhJFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_importance_weights(eval_policy, behav_policy, behavior_policies):\n",
        "    \"\"\"\n",
        "    Calculate importance weights for behavior policies.\n",
        "\n",
        "    Parameters:\n",
        "    - eval_policy: Evaluation policy\n",
        "    - behav_policy: Behavior policy\n",
        "    - behavior_policies: List of behavior policies\n",
        "\n",
        "    Returns:\n",
        "    - all_weights: List of importance weights\n",
        "    \"\"\"\n",
        "    all_weights_temp = []\n",
        "    for trajectory in behavior_policies:\n",
        "        cum_ratio = 1\n",
        "        cumul_weights = []\n",
        "        for step in trajectory:\n",
        "            # eval_action_probs = get_quadrant_policy(step[0], eval_policy)\n",
        "            # behav_action_probs = get_quadrant_policy(step[0], behav_policy)\n",
        "\n",
        "            P_pi_b = behav_policy[tuple(np.append(step[0].astype(int) , (step[1],)))]\n",
        "            P_pi_e = eval_policy[tuple(np.append(step[0].astype(int) , (step[1],)))]\n",
        "\n",
        "            # ratio = (0.8*eval_action_probs[step[1]] +0.2*0.25)/ (0.8*behav_action_probs[step[1]]+0.2*0.25)\n",
        "            ratio = P_pi_e/P_pi_b\n",
        "            cum_ratio *= ratio\n",
        "            cumul_weights.append(cum_ratio)\n",
        "        all_weights_temp.append(cumul_weights)\n",
        "\n",
        "        all_weights = [list(np.cumprod(i)) for i in all_weights_temp]\n",
        "\n",
        "    return all_weights_temp, all_weights"
      ],
      "metadata": {
        "id": "3NvlDTygDhon"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_weights_temp, all_weights = calculate_importance_weights(P_pi_e, P_pi_b, pi_b)"
      ],
      "metadata": {
        "id": "eWX9DHMDDl-W"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_weights_temp[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqKsg2xDDtgF",
        "outputId": "b1ba3c6a-026d-4de6-8605-95a8381f831e"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7132352941176471,\n",
              " 0.5087045847750865,\n",
              " 0.36282606414105434,\n",
              " 0.2587803545711932,\n",
              " 0.18457128230445397,\n",
              " 0.1316427528200885,\n",
              " 0.09389225752609254,\n",
              " 0.06696727191199248,\n",
              " 0.0477634218784064,\n",
              " 0.03406655825151045,\n",
              " 0.004258319781438806,\n",
              " 0.0005322899726798508,\n",
              " 0.00037964799522018767,\n",
              " 0.0002707783495320456,\n",
              " 3.38472936915057e-05,\n",
              " 2.4141084471147448e-05,\n",
              " 1.721827348309781e-05,\n",
              " 2.1522841853872264e-06,\n",
              " 1.304822287391006e-05,\n",
              " 9.306453079185852e-06,\n",
              " 1.1633066348982315e-06,\n",
              " 8.297113498906504e-07,\n",
              " 5.917794186720081e-07]"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_weights[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uEATYCyLNex",
        "outputId": "0a34724c-c9d0-4457-d76f-59ff5617b6f6"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7132352941176471,\n",
              " 0.36282606414105434,\n",
              " 0.13164275282008847,\n",
              " 0.034066558251510434,\n",
              " 0.006287708340180658,\n",
              " 0.0008277312348312113,\n",
              " 7.771755426316267e-05,\n",
              " 5.204532588676245e-06,\n",
              " 2.48586285712858e-07,\n",
              " 8.468479182763697e-09,\n",
              " 3.6061492422665387e-11,\n",
              " 1.9195170816455204e-14,\n",
              " 7.287408118376271e-18,\n",
              " 1.973272342660357e-21,\n",
              " 6.678992851535058e-26,\n",
              " 1.612381306110978e-30,\n",
              " 2.776242228765327e-35,\n",
              " 5.9752622437758e-41,\n",
              " 7.796655348684653e-46,\n",
              " 7.255920717711713e-51,\n",
              " 8.440860713209574e-57,\n",
              " 7.003477936596074e-63,\n",
              " 4.1445141020010597e-69]"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract probability for each state-action pair\n",
        "num_steps, num_states, num_actions = P_pi_b.shape\n",
        "num_samples = states_test.shape[0]\n",
        "\n",
        "# Convert states_test to integers for indexing\n",
        "states_int = states_test.astype(int)\n",
        "\n",
        "# Extract probabilities using array indexing\n",
        "probs_pi_b = P_pi_b[states_int[:, 0], states_int[:, 1], actions_test]\n",
        "probs_pi_e = P_pi_e[states_int[:, 0], states_int[:, 1], actions_test]"
      ],
      "metadata": {
        "id": "psMIyTu1j0PS"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs_pi_b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrGoFbE3kx-K",
        "outputId": "f80b0739-0035-4628-a24b-a610ef62764d"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.08,\n",
              "       0.08, 0.68, 0.68, 0.08, 0.68, 0.68, 0.08, 0.08, 0.68, 0.08, 0.68,\n",
              "       0.68])"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "probs_pi_e"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_d9hkR7wk_mf",
        "outputId": "3edb3fdf-94bb-4a27-f7f0-3079dca07bec"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.485, 0.485, 0.485, 0.485, 0.485, 0.485, 0.485, 0.485, 0.485,\n",
              "       0.485, 0.01 , 0.01 , 0.485, 0.485, 0.01 , 0.485, 0.485, 0.01 ,\n",
              "       0.485, 0.485, 0.01 , 0.485, 0.485])"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(probs_pi_e/probs_pi_b).cumprod(axis=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iVhb2RVlCI8",
        "outputId": "6af4e661-1c4e-4398-ff9b-170e9bc7e28e"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7.13235294e-01, 5.08704585e-01, 3.62826064e-01, 2.58780355e-01,\n",
              "       1.84571282e-01, 1.31642753e-01, 9.38922575e-02, 6.69672719e-02,\n",
              "       4.77634219e-02, 3.40665583e-02, 4.25831978e-03, 5.32289973e-04,\n",
              "       3.79647995e-04, 2.70778350e-04, 3.38472937e-05, 2.41410845e-05,\n",
              "       1.72182735e-05, 2.15228419e-06, 1.30482229e-05, 9.30645308e-06,\n",
              "       1.16330663e-06, 8.29711350e-07, 5.91779419e-07])"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(probs_pi_e/probs_pi_b).prod(axis=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haf3CzhmnP-g",
        "outputId": "8a4cc96b-b454-43f3-d94c-e4546858ecd8"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.917794186720081e-07"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFeC8cDJlRqF",
        "outputId": "04d5b1ae-ed42-465b-eccd-b87ee7f98e05"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7132352941176471,\n",
              " 0.36282606414105434,\n",
              " 0.13164275282008847,\n",
              " 0.034066558251510434,\n",
              " 0.006287708340180658,\n",
              " 0.0008277312348312113,\n",
              " 7.771755426316267e-05,\n",
              " 5.204532588676245e-06,\n",
              " 2.48586285712858e-07,\n",
              " 8.468479182763697e-09,\n",
              " 3.6061492422665387e-11,\n",
              " 1.9195170816455204e-14,\n",
              " 7.287408118376271e-18,\n",
              " 1.973272342660357e-21,\n",
              " 6.678992851535058e-26,\n",
              " 1.612381306110978e-30,\n",
              " 2.776242228765327e-35,\n",
              " 5.9752622437758e-41,\n",
              " 7.796655348684653e-46,\n",
              " 7.255920717711713e-51,\n",
              " 8.440860713209574e-57,\n",
              " 7.003477936596074e-63,\n",
              " 4.1445141020010597e-69]"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSZax_wTBuz2",
        "outputId": "10644bfa-fb7d-4b7d-ca1a-ecb9f63bd4c2"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.7132352941176471,\n",
              "  0.36282606414105434,\n",
              "  0.13164275282008847,\n",
              "  0.034066558251510434,\n",
              "  0.006287708340180658,\n",
              "  0.0008277312348312113,\n",
              "  7.771755426316267e-05,\n",
              "  5.204532588676245e-06,\n",
              "  2.48586285712858e-07,\n",
              "  8.468479182763697e-09,\n",
              "  3.6061492422665387e-11,\n",
              "  1.9195170816455204e-14,\n",
              "  7.287408118376271e-18,\n",
              "  1.973272342660357e-21,\n",
              "  6.678992851535058e-26,\n",
              "  1.612381306110978e-30,\n",
              "  2.776242228765327e-35,\n",
              "  5.9752622437758e-41,\n",
              "  7.796655348684653e-46,\n",
              "  7.255920717711713e-51,\n",
              "  8.440860713209574e-57,\n",
              "  7.003477936596074e-63,\n",
              "  4.1445141020010597e-69],\n",
              " [6.0625,\n",
              "  26.214183134191178,\n",
              "  80.84510557563685,\n",
              "  177.82956323277526,\n",
              "  278.98895939887166,\n",
              "  2653.5166914163347,\n",
              "  18000.702591032885,\n",
              "  87094.33652773884,\n",
              "  300554.4756778875,\n",
              "  739757.3859855295,\n",
              "  227596.42361250217,\n",
              "  49942.971995499654,\n",
              "  1369.9141292252755,\n",
              "  26.80063802941003,\n",
              "  0.37396395766511065,\n",
              "  0.03163487428795419,\n",
              "  0.001908689588734961,\n",
              "  8.213671358375234e-05,\n",
              "  2.1428466437824626e-05,\n",
              "  3.9872887390228824e-06,\n",
              "  5.291723054894178e-07],\n",
              " [0.7132352941176471,\n",
              "  0.06358807309688581,\n",
              "  0.004043443040174894,\n",
              "  0.00018338331548064946,\n",
              "  1.0396288528903333e-06,\n",
              "  4.203680049584427e-09,\n",
              "  1.2123103392960128e-11,\n",
              "  2.493622974018479e-14,\n",
              "  3.658310788273809e-17,\n",
              "  3.827923332764183e-20,\n",
              "  2.8567924540782985e-23,\n",
              "  1.5206419773333412e-26,\n",
              "  1.011778095713248e-30,\n",
              "  8.41498960820744e-36,\n",
              "  4.991771772741668e-41,\n",
              "  3.7013987228869067e-47,\n",
              "  1.957536400670582e-53,\n",
              "  1.2940880754943391e-60,\n",
              "  6.1016971764870074e-68,\n",
              "  3.596230150266961e-76,\n",
              "  1.2849790795932546e-83,\n",
              "  3.274744808368086e-91,\n",
              "  5.95239431745802e-99,\n",
              "  7.716826756593017e-107,\n",
              "  7.135405081264397e-115,\n",
              "  4.7057769931646824e-123,\n",
              "  1.881463521646853e-130,\n",
              "  5.365288613487482e-138,\n",
              "  1.0912473473433638e-145],\n",
              " [0.125,\n",
              "  0.011144301470588236,\n",
              "  0.0007086446565254968,\n",
              "  3.213934395021691e-05,\n",
              "  1.039628852890333e-06,\n",
              "  2.3985703812334665e-08,\n",
              "  6.917300171277249e-11,\n",
              "  2.4936229740184782e-14,\n",
              "  6.411472515531416e-18,\n",
              "  1.175757087011211e-21,\n",
              "  2.6951779101998296e-26,\n",
              "  4.40646269442255e-31,\n",
              "  4.367616605600319e-35,\n",
              "  3.087676164250621e-39,\n",
              "  1.5568680559372986e-43,\n",
              "  5.598925597374785e-48,\n",
              "  1.2207011013886082e-51,\n",
              "  1.6134879567799814e-54,\n",
              "  1.521090121055426e-57,\n",
              "  1.022767664998916e-60,\n",
              "  4.904919212915387e-64,\n",
              "  1.426062237134181e-66,\n",
              "  2.9571811322967266e-69,\n",
              "  4.3737121729807376e-72,\n",
              "  4.613763172345368e-75,\n",
              "  3.4713085877923017e-78,\n",
              "  1.8627903232948804e-81,\n",
              "  7.129639150096391e-85,\n",
              "  1.946273869590634e-88,\n",
              "  3.789423814439231e-92,\n",
              "  5.262295527618552e-96,\n",
              "  5.212068491909747e-100],\n",
              " [0.7132352941176471,\n",
              "  3.0840215451989623,\n",
              "  9.511188891251395,\n",
              "  177.82956323277526,\n",
              "  2371.406154890409,\n",
              "  22554.891877038845,\n",
              "  153005.9720237795,\n",
              "  740301.8604857799,\n",
              "  447733.2137675746,\n",
              "  193135.72310271577,\n",
              "  10413.960365070396,\n",
              "  400.49957250084367,\n",
              "  10.985530119573722,\n",
              "  0.21491800837354608,\n",
              "  0.0029988684932305667,\n",
              "  2.9845225280935253e-05,\n",
              "  2.1184837024610783e-07,\n",
              "  1.0725269631729829e-09,\n",
              "  3.291872929075463e-11,\n",
              "  7.206273348629824e-13,\n",
              "  1.9719160146074268e-15,\n",
              "  3.848565853595951e-18,\n",
              "  5.357254229013603e-21]]"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights_first = [trajectory[0] for trajectory in weights]\n"
      ],
      "metadata": {
        "id": "fsu9StgFC5UA"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights_first"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmEx-WpwC-FU",
        "outputId": "eeed1cc6-afbf-4cf0-a28e-24aa8de7c279"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7132352941176471, 6.0625, 0.7132352941176471, 0.125, 0.7132352941176471]"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "states[0].astype(int)[:,0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6k1h2M-j_ur",
        "outputId": "98f2d6a9-cc37-4828-9d0b-7abf66df9714"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 0, 0, 0, 0, 1, 1, 2, 3, 4, 4, 5, 6, 6, 7, 8, 8, 7, 8, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    }
  ]
}