{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
<<<<<<< HEAD
      "machine_shape": "hm",
      "collapsed_sections": [
        "0fwQz6Zfke5i",
        "O36PGywGna2d"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPGp94ucYy5ezY3YmljrYBJ",
=======
      "toc_visible": true,
      "machine_shape": "hm",
      "collapsed_sections": [
        "O36PGywGna2d",
        "72Fy4L1cuitK"
      ],
      "authorship_tag": "ABX9TyNXR0if9Ks8iQ/jqLnnO5tV",
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
<<<<<<< HEAD
        "<a href=\"https://colab.research.google.com/github/ajagota7/Shaping/blob/main/Lifegate_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
=======
        "<a href=\"https://colab.research.google.com/github/ai4ai-lab/Reward-Shaping/blob/main/Lifegate_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "zZ2S2CI8K_jT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jsHzrhmfpiTr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from google.colab import drive\n",
        "import pickle\n",
        "# np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)\n",
        "from scipy.optimize import minimize\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.lines import Line2D\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# deadend dependencies"
      ],
      "metadata": {
        "id": "UMj8NNrGfwu8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/microsoft/med-deadend.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KStXBTWK3f64",
<<<<<<< HEAD
        "outputId": "05e77258-eee6-4957-b27e-fcc15f7a8929"
=======
        "outputId": "f2af2ca9-9ac1-492c-9ff5-a350c37264a2"
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'med-deadend'...\n",
            "remote: Enumerating objects: 130, done.\u001b[K\n",
            "remote: Counting objects: 100% (130/130), done.\u001b[K\n",
            "remote: Compressing objects: 100% (105/105), done.\u001b[K\n",
            "remote: Total 130 (delta 52), reused 77 (delta 22), pack-reused 0\u001b[K\n",
<<<<<<< HEAD
            "Receiving objects: 100% (130/130), 395.48 KiB | 19.77 MiB/s, done.\n",
=======
            "Receiving objects: 100% (130/130), 395.48 KiB | 24.72 MiB/s, done.\n",
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
            "Resolving deltas: 100% (52/52), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# shaping dependencies"
      ],
      "metadata": {
        "id": "AsZMw4C0f2K-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ajagota7/Shaping.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wu7X59dK3hqk",
<<<<<<< HEAD
        "outputId": "9be788f3-078c-432c-84f6-d2caadcba371"
=======
        "outputId": "b7d216a7-5260-4292-e7be-c14178a7a643"
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Shaping'...\n",
<<<<<<< HEAD
            "remote: Enumerating objects: 87, done.\u001b[K\n",
            "remote: Counting objects: 100% (87/87), done.\u001b[K\n",
            "remote: Compressing objects: 100% (63/63), done.\u001b[K\n",
            "remote: Total 87 (delta 40), reused 65 (delta 23), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (87/87), 11.61 MiB | 31.69 MiB/s, done.\n",
            "Resolving deltas: 100% (40/40), done.\n"
=======
            "remote: Enumerating objects: 63, done.\u001b[K\n",
            "remote: Counting objects:   1% (1/63)\u001b[K\rremote: Counting objects:   3% (2/63)\u001b[K\rremote: Counting objects:   4% (3/63)\u001b[K\rremote: Counting objects:   6% (4/63)\u001b[K\rremote: Counting objects:   7% (5/63)\u001b[K\rremote: Counting objects:   9% (6/63)\u001b[K\rremote: Counting objects:  11% (7/63)\u001b[K\rremote: Counting objects:  12% (8/63)\u001b[K\rremote: Counting objects:  14% (9/63)\u001b[K\rremote: Counting objects:  15% (10/63)\u001b[K\rremote: Counting objects:  17% (11/63)\u001b[K\rremote: Counting objects:  19% (12/63)\u001b[K\rremote: Counting objects:  20% (13/63)\u001b[K\rremote: Counting objects:  22% (14/63)\u001b[K\rremote: Counting objects:  23% (15/63)\u001b[K\rremote: Counting objects:  25% (16/63)\u001b[K\rremote: Counting objects:  26% (17/63)\u001b[K\rremote: Counting objects:  28% (18/63)\u001b[K\rremote: Counting objects:  30% (19/63)\u001b[K\rremote: Counting objects:  31% (20/63)\u001b[K\rremote: Counting objects:  33% (21/63)\u001b[K\rremote: Counting objects:  34% (22/63)\u001b[K\rremote: Counting objects:  36% (23/63)\u001b[K\rremote: Counting objects:  38% (24/63)\u001b[K\rremote: Counting objects:  39% (25/63)\u001b[K\rremote: Counting objects:  41% (26/63)\u001b[K\rremote: Counting objects:  42% (27/63)\u001b[K\rremote: Counting objects:  44% (28/63)\u001b[K\rremote: Counting objects:  46% (29/63)\u001b[K\rremote: Counting objects:  47% (30/63)\u001b[K\rremote: Counting objects:  49% (31/63)\u001b[K\rremote: Counting objects:  50% (32/63)\u001b[K\rremote: Counting objects:  52% (33/63)\u001b[K\rremote: Counting objects:  53% (34/63)\u001b[K\rremote: Counting objects:  55% (35/63)\u001b[K\rremote: Counting objects:  57% (36/63)\u001b[K\rremote: Counting objects:  58% (37/63)\u001b[K\rremote: Counting objects:  60% (38/63)\u001b[K\rremote: Counting objects:  61% (39/63)\u001b[K\rremote: Counting objects:  63% (40/63)\u001b[K\rremote: Counting objects:  65% (41/63)\u001b[K\rremote: Counting objects:  66% (42/63)\u001b[K\rremote: Counting objects:  68% (43/63)\u001b[K\rremote: Counting objects:  69% (44/63)\u001b[K\rremote: Counting objects:  71% (45/63)\u001b[K\rremote: Counting objects:  73% (46/63)\u001b[K\rremote: Counting objects:  74% (47/63)\u001b[K\rremote: Counting objects:  76% (48/63)\u001b[K\rremote: Counting objects:  77% (49/63)\u001b[K\rremote: Counting objects:  79% (50/63)\u001b[K\rremote: Counting objects:  80% (51/63)\u001b[K\rremote: Counting objects:  82% (52/63)\u001b[K\rremote: Counting objects:  84% (53/63)\u001b[K\rremote: Counting objects:  85% (54/63)\u001b[K\rremote: Counting objects:  87% (55/63)\u001b[K\rremote: Counting objects:  88% (56/63)\u001b[K\rremote: Counting objects:  90% (57/63)\u001b[K\rremote: Counting objects:  92% (58/63)\u001b[K\rremote: Counting objects:  93% (59/63)\u001b[K\rremote: Counting objects:  95% (60/63)\u001b[K\rremote: Counting objects:  96% (61/63)\u001b[K\rremote: Counting objects:  98% (62/63)\u001b[K\rremote: Counting objects: 100% (63/63)\u001b[K\rremote: Counting objects: 100% (63/63), done.\u001b[K\n",
            "remote: Compressing objects: 100% (44/44), done.\u001b[K\n",
            "remote: Total 63 (delta 24), reused 55 (delta 18), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (63/63), 11.54 MiB | 34.24 MiB/s, done.\n",
            "Resolving deltas: 100% (24/24), done.\n"
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
<<<<<<< HEAD
        "# %cd /content/Shaping"
      ],
      "metadata": {
        "id": "5SkpvWFqz631"
      },
      "execution_count": 5,
=======
        "# cd /content/"
      ],
      "metadata": {
        "id": "hZ8dnFnidxL_"
      },
      "execution_count": 4,
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
<<<<<<< HEAD
        "# !git pull origin main"
      ],
      "metadata": {
        "id": "8QRHhC-G0AiH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cd /content/"
      ],
      "metadata": {
        "id": "hZ8dnFnidxL_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
=======
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
        "# %cd /content/Shaping\n",
        "\n",
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile('/content/Shaping/lifegate_1.zip', 'r') as zip_ref:\n",
        "    # zip_ref.extractall('/content/med-deadend/lifegate/results/lifegate_1')\n",
        "    zip_ref.extractall('/content/Shaping/')"
      ],
      "metadata": {
        "id": "2noY6FOTdsmY"
      },
<<<<<<< HEAD
      "execution_count": 4,
=======
      "execution_count": 5,
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/med-deadend/lifegate\n",
        "\n",
        "\n",
        "# results_dir = 'results/lifegate_1/'\n",
        "results_dir = '/content/Shaping/'\n",
        "# Load the Q tables from the primary learning agent, Q_D and Q_R value functions\n",
        "with open(results_dir+'tabular_qnet.pkl', 'rb') as fq:\n",
        "    ai = pickle.load(fq)\n",
        "\n",
        "with open(results_dir+'tabular_qd.pkl', 'rb') as fd:\n",
        "    ai_d = pickle.load(fd)\n",
        "\n",
        "with open(results_dir+'tabular_qr.pkl', 'rb') as fr:\n",
        "    ai_r = pickle.load(fr)"
      ],
      "metadata": {
        "id": "7lv4ZIBkeLW3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
<<<<<<< HEAD
        "outputId": "ada31bb5-ea3a-42b4-885d-512872ca9052"
      },
      "execution_count": 5,
=======
        "outputId": "5d58a8c4-93c5-459b-ebe3-ccc75bd5918f"
      },
      "execution_count": 6,
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/med-deadend/lifegate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q_table = np.zeros((10, 10, 5))\n",
        "q_d = np.zeros_like(q_table)\n",
        "q_r = np.zeros_like(q_table)\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    for j in range(10):\n",
        "        for a in range(5):\n",
        "            key = tuple([j, i, a])\n",
        "            try:\n",
        "                q_table[i,j,a] = ai.q[key]\n",
        "                q_d[i,j,a] = ai_d.q[key]\n",
        "                q_r[i,j,a] = ai_r.q[key]\n",
        "            except:\n",
        "                pass"
      ],
      "metadata": {
        "id": "Rk0Z42sNebl4"
      },
<<<<<<< HEAD
      "execution_count": 6,
=======
      "execution_count": 7,
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "import random"
      ],
      "metadata": {
        "id": "4uTTjsWNfK21"
      },
<<<<<<< HEAD
      "execution_count": 7,
=======
      "execution_count": 8,
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from lifegate import LifeGate"
      ],
      "metadata": {
        "id": "WZDw5-YMfMSM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
<<<<<<< HEAD
        "outputId": "bf9f9aa2-5a92-4a6c-9938-dc0883bf8598"
      },
      "execution_count": 8,
=======
        "id": "WZDw5-YMfMSM",
        "outputId": "44d7aaac-cbf2-4fc6-9271-73b72e624bc9"
      },
      "execution_count": 9,
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pygame 2.5.2 (SDL 2.28.2, Python 3.10.12)\n",
            "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params = yaml.safe_load(open('config.yaml', 'r'))"
      ],
      "metadata": {
        "id": "pzii8SOefSCm"
      },
<<<<<<< HEAD
      "execution_count": 9,
=======
      "execution_count": 10,
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(seed=params['random_seed'])\n",
        "random.seed(params['random_seed'])\n",
        "random_state = np.random.RandomState(params['random_seed'])"
      ],
      "metadata": {
        "id": "ircWaFyzfVZr"
      },
<<<<<<< HEAD
      "execution_count": 10,
=======
      "execution_count": 11,
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = LifeGate(max_steps=params['episode_max_len'], state_mode='tabular',\n",
        "                        rendering=True, image_saving=False, render_dir=None, rng=random_state, death_drag = 0.1)"
      ],
      "metadata": {
        "id": "XUoJuLN0fabn"
      },
<<<<<<< HEAD
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env_30 = LifeGate(max_steps=30, state_mode='tabular',\n",
        "                        rendering=True, image_saving=False, render_dir=None, rng=random_state, death_drag = 0.1)"
      ],
      "metadata": {
        "id": "7wG_zU6SM3xY"
      },
=======
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KZp-8-f7far2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import Shaping"
      ],
      "metadata": {
        "id": "hS65UmL5Yu_K"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from Shaping import *"
      ],
      "metadata": {
        "id": "FwGOFhh0ZeGx"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Shaping\n",
        "\n",
        "from choose_actions import action_probs_top_n_epsilon\n",
        "from shaping_features import *\n",
        "from gen_policies import *\n",
        "from IS import *\n",
        "from subset_policies import *\n",
        "from v_pi_e import *\n",
        "from optimization import *\n",
        "from neural_net import *\n",
        "from prep_variance import *\n",
        "from SCOPE_variance import SCOPE_variance"
      ],
      "metadata": {
        "id": "NYtD9mJOadhF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
<<<<<<< HEAD
        "outputId": "c91e19b7-c0e1-435f-e7b1-a4b7113626c3"
=======
        "outputId": "3f42684f-7bcd-4bce-84c8-d7baf889f375"
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Shaping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating policies"
      ],
<<<<<<< HEAD
      "metadata": {
        "id": "0fwQz6Zfke5i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## interm updates"
      ],
      "metadata": {
        "id": "d4uOoMlDEv-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def experiment_actions(nb_episodes, env, action_probs):\n",
        "    \"\"\"\n",
        "    Run the experiment for a specified number of episodes.\n",
        "\n",
        "    Parameters:\n",
        "    - nb_episodes: Number of episodes\n",
        "    - env: Experiment environment\n",
        "    - action_probs: Action probabilities\n",
        "\n",
        "    Returns:\n",
        "    - policies: List of policies (pi_b or pi_e)\n",
        "    \"\"\"\n",
        "    # Define the dtype for the structured array\n",
        "    dtype = [\n",
        "        ('state_last', np.float64, (2,)),\n",
        "        ('action', np.int64),\n",
        "        ('reward', np.float64),\n",
        "        ('state', np.float64, (2,)),\n",
        "        ('timestep', np.int64),\n",
        "        ('psi', np.float64)\n",
        "    ]\n",
        "\n",
        "    policies = []\n",
        "    for i in range(nb_episodes):\n",
        "        trajectory = np.empty(0, dtype=dtype)\n",
        "        s = env.reset()\n",
        "        env.render()\n",
        "        term = False\n",
        "        timestep = 0\n",
        "        while not term:\n",
        "            state_last = s\n",
        "            print(s)\n",
        "            action = choose_action(tuple(s), action_probs)\n",
        "            s, r, term, _ = env.step(action)\n",
        "\n",
        "            psi = smallest_distance_to_deadend(state_last, env)\n",
        "            data_point = np.array([(state_last, action, r, s, timestep, psi)], dtype=dtype)\n",
        "            trajectory = np.append(trajectory, data_point)\n",
        "            timestep += 1\n",
        "\n",
        "        policies.append(trajectory)\n",
        "\n",
        "    with open('policies.pkl', 'wb') as f:\n",
        "        pickle.dump(policies, f)\n",
        "\n",
        "    return policies"
      ],
      "metadata": {
        "id": "Xh2UezkqHisR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b_good = np.zeros((10, 10, 5))\n",
        "\n",
        "P_pi_b_good[2,9,3] = 1\n",
        "P_pi_b_good[1,9,3] = 1\n",
        "P_pi_b_good[0,9,1] = 1\n",
        "P_pi_b_good[0,8,1] = 1\n",
        "P_pi_b_good[0,7,1] = 1\n",
        "P_pi_b_good[0,6,1] = 1\n",
        "P_pi_b_good[0,5,1] = 1\n",
        "P_pi_b_good[0,4,4] = 1\n",
        "P_pi_b_good[1,4,4] = 1\n",
        "P_pi_b_good[2,4,4] = 1\n",
        "P_pi_b_good[3,4,4] = 1\n",
        "P_pi_b_good[4,4,4] = 1\n",
        "P_pi_b_good[5,4,1] = 1\n",
        "P_pi_b_good[5,5,1] = 1\n",
        "P_pi_b_good[5,4,1] = 1\n",
        "P_pi_b_good[5,3,1] = 1\n",
        "P_pi_b_good[5,2,1] = 1\n",
        "P_pi_b_good[5,1,1] = 1"
      ],
      "metadata": {
        "id": "PYLauaUbIq6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b_good_stoch = np.zeros((10, 10, 5))\n",
        "\n",
        "P_pi_b_good_stoch[2,9,3] = 0.5\n",
        "P_pi_b_good_stoch[2,9,1] = 0.5\n",
        "\n",
        "P_pi_b_good_stoch[2,8,3] = 0.5\n",
        "P_pi_b_good_stoch[2,8,1] = 0.5\n",
        "\n",
        "P_pi_b_good_stoch[2,7,3] = 0.5\n",
        "P_pi_b_good_stoch[2,7,1] = 0.5\n",
        "\n",
        "P_pi_b_good_stoch[1,9,3] = 0.5\n",
        "P_pi_b_good_stoch[1,9,1] = 0.5\n",
        "\n",
        "P_pi_b_good_stoch[1,8,3] = 0.5\n",
        "P_pi_b_good_stoch[1,8,1] = 0.5\n",
        "\n",
        "P_pi_b_good_stoch[1,7,3] = 0.5\n",
        "P_pi_b_good_stoch[1,7,1] = 0.5\n",
        "\n",
        "P_pi_b_good_stoch[2,6,3] = 1\n",
        "P_pi_b_good_stoch[1,6,3] = 1\n",
        "P_pi_b_good_stoch[1,5,3] = 1\n",
        "\n",
        "\n",
        "P_pi_b_good_stoch[0,9,1] = 1\n",
        "P_pi_b_good_stoch[0,8,1] = 1\n",
        "P_pi_b_good_stoch[0,7,1] = 1\n",
        "P_pi_b_good_stoch[0,6,1] = 1\n",
        "P_pi_b_good_stoch[0,5,1] = 1\n",
        "\n",
        "P_pi_b_good_stoch[0,4,1] = 0.5\n",
        "P_pi_b_good_stoch[0,4,4] = 0.5\n",
        "P_pi_b_good_stoch[0,4,1] = 0.5\n",
        "P_pi_b_good_stoch[0,4,4] = 0.5\n",
        "P_pi_b_good_stoch[0,3,1] = 0.5\n",
        "P_pi_b_good_stoch[0,3,4] = 0.5\n",
        "P_pi_b_good_stoch[0,2,1] = 0.5\n",
        "P_pi_b_good_stoch[0,2,4] = 0.5\n",
        "\n",
        "P_pi_b_good_stoch[1,4,1] = 0.5\n",
        "P_pi_b_good_stoch[1,4,4] = 0.5\n",
        "P_pi_b_good_stoch[1,4,1] = 0.5\n",
        "P_pi_b_good_stoch[1,4,4] = 0.5\n",
        "P_pi_b_good_stoch[1,3,1] = 0.5\n",
        "P_pi_b_good_stoch[1,3,4] = 0.5\n",
        "P_pi_b_good_stoch[1,2,1] = 0.5\n",
        "P_pi_b_good_stoch[1,2,4] = 0.5\n",
        "\n",
        "P_pi_b_good_stoch[2,4,1] = 0.5\n",
        "P_pi_b_good_stoch[2,4,4] = 0.5\n",
        "P_pi_b_good_stoch[2,4,1] = 0.5\n",
        "P_pi_b_good_stoch[2,4,4] = 0.5\n",
        "P_pi_b_good_stoch[2,3,1] = 0.5\n",
        "P_pi_b_good_stoch[2,3,4] = 0.5\n",
        "P_pi_b_good_stoch[2,2,1] = 0.5\n",
        "P_pi_b_good_stoch[2,2,4] = 0.5\n",
        "\n",
        "P_pi_b_good_stoch[3,4,1] = 0.5\n",
        "P_pi_b_good_stoch[3,4,4] = 0.5\n",
        "P_pi_b_good_stoch[3,4,1] = 0.5\n",
        "P_pi_b_good_stoch[3,4,4] = 0.5\n",
        "P_pi_b_good_stoch[3,3,1] = 0.5\n",
        "P_pi_b_good_stoch[3,3,4] = 0.5\n",
        "P_pi_b_good_stoch[3,2,1] = 0.5\n",
        "P_pi_b_good_stoch[3,2,4] = 0.5\n",
        "\n",
        "P_pi_b_good_stoch[4,4,1] = 0.5\n",
        "P_pi_b_good_stoch[4,4,4] = 0.5\n",
        "P_pi_b_good_stoch[4,4,1] = 0.5\n",
        "P_pi_b_good_stoch[4,4,4] = 0.5\n",
        "P_pi_b_good_stoch[4,3,1] = 0.5\n",
        "P_pi_b_good_stoch[4,3,4] = 0.5\n",
        "P_pi_b_good_stoch[4,2,1] = 0.5\n",
        "P_pi_b_good_stoch[4,2,4] = 0.5\n",
        "\n",
        "P_pi_b_good_stoch[0,1,4] = 1\n",
        "P_pi_b_good_stoch[1,1,4] = 1\n",
        "P_pi_b_good_stoch[2,1,4] = 1\n",
        "P_pi_b_good_stoch[3,1,4] = 1\n",
        "P_pi_b_good_stoch[4,1,4] = 1\n",
        "\n",
        "P_pi_b_good_stoch[5,4,1] = 1\n",
        "P_pi_b_good_stoch[5,3,1] = 1\n",
        "P_pi_b_good_stoch[5,2,1] = 1\n",
        "P_pi_b_good_stoch[5,1,1] = 1\n",
        "\n"
      ],
      "metadata": {
        "id": "t5GNtT3tPttg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b_bad = np.zeros((10, 10, 5))\n",
        "\n",
        "P_pi_b_bad[2,9,4] = 1\n",
        "\n",
        "P_pi_b_bad[3,9,1] = 1\n",
        "P_pi_b_bad[3,8,1] = 1\n",
        "P_pi_b_bad[3,7,1] = 1\n",
        "P_pi_b_bad[3,6,4] = 1\n",
        "\n",
        "P_pi_b_bad[4,6,2] = 1\n",
        "P_pi_b_bad[4,7,2] = 1\n",
        "P_pi_b_bad[4,8,2] = 1\n",
        "P_pi_b_bad[4,9,4] = 1\n",
        "\n",
        "P_pi_b_bad[5,9,1] = 1\n",
        "P_pi_b_bad[5,8,1] = 1\n",
        "P_pi_b_bad[5,7,1] = 1\n",
        "P_pi_b_bad[5,6,4] = 1\n",
        "\n",
        "P_pi_b_bad[6,6,4] = 1\n",
        "P_pi_b_bad[7,6,4] = 1\n",
        "P_pi_b_bad[8,6,4] = 1\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kuKtHy7UgHwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env.main_deaths"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1B0ogRtNlRu6",
        "outputId": "01841628-6c3d-4127-e489-96b0ebdb6cb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[9, 0],\n",
              " [9, 1],\n",
              " [9, 2],\n",
              " [9, 3],\n",
              " [9, 4],\n",
              " [9, 5],\n",
              " [9, 6],\n",
              " [9, 7],\n",
              " [9, 8],\n",
              " [9, 9],\n",
              " [8, 0]]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gen Policies"
      ],
      "metadata": {
        "id": "RBlY1w9aJppv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b = action_probs_top_n_epsilon(q_table, 1, 0.4)\n",
        "pi_b = experiment_actions(1000, env, P_pi_b)\n",
        "P_pi_e = action_probs_top_n_epsilon(q_table, 2, 0.05)\n",
        "pi_e = experiment_actions(1000, env, P_pi_e)"
      ],
      "metadata": {
        "id": "wW1SGejBZZlb"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b = action_probs_top_n_epsilon(q_table, 1, 0.4)\n",
        "pi_b = experiment_actions(1000, env_30, P_pi_b)\n",
        "\n",
        "P_pi_e = action_probs_top_n_epsilon(q_table, 2, 0.05)\n",
        "pi_e = experiment_actions(1000, env_30, P_pi_e)"
      ],
      "metadata": {
        "id": "1KqavLn-NERh"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prep"
      ],
      "metadata": {
        "id": "03SCZEAMnGeY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = CustomizableFeatureNet(input_dim=2, hidden_dims=[16, 32], output_dim=1, dtype = torch.float64)"
      ],
      "metadata": {
        "id": "LRcpZ6zAowqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test1 = SCOPE_variance(model, 0.9, 10000, pi_b, P_pi_b, P_pi_e, dtype = torch.float64)"
      ],
      "metadata": {
        "id": "jqKcMhNSnRTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# IS_tensor, samples_IS, padded_state_tensors, padded_weight_diff_tensors, gamma_weights_last_tensor, states_first_tensor, states_last_tensor = test1.prepare()\n",
        "\n",
        "# Modified class with bootstrap_all_terms\n",
        "IS_tensor, padded_state_tensors, padded_weight_diff_tensors, gamma_weights_last_tensor, states_first_tensor, states_last_tensor = test1.prepare()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uftstgp1nRTP",
        "outputId": "2d127529-334e-4e7d-a5ca-71688f5d883f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-827856c56c37>:89: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  padded_weight_diff_tensors = torch.tensor(padded_weights_difference, dtype = self.dtype)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "timesteps, states, states_first, states_last, actions, rewards, gamma_last, weights_last, weights, weights_difference = test1.prep_policies()"
      ],
      "metadata": {
        "id": "IG7OqI1kuQ7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "states_output, states_first_output, states_last_output = test1.pass_states(model, padded_state_tensors, states_first_tensor, states_last_tensor)\n",
        "sums_states_weight_diff = test1.states_weight_diff_sums(states_output, padded_weight_diff_tensors)\n",
        "gamma_weights_states_last_sub_states_first = test1.last_first_terms_operations(gamma_weights_last_tensor, states_last_output, states_first_output)\n",
        "\n",
        "\n",
        "# sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, samples_all_shaping, samples_IS_SCOPE = test1.bootstrap_shaping_terms(sums_states_weight_diff, gamma_weights_states_last_sub_states_first, IS_tensor)\n",
        "samples_IS, sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, samples_all_shaping, samples_IS_SCOPE = test1.bootstrap_all_terms(sums_states_weight_diff, gamma_weights_states_last_sub_states_first, IS_tensor)\n"
      ],
=======
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
      "metadata": {
        "id": "0fwQz6Zfke5i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sum_terms = sums_states_weight_diff + gamma_weights_states_last_sub_states_first\n",
        "IS_SCOPE_1 = IS_tensor*sum_terms"
      ],
      "metadata": {
        "id": "Gspo0QLFDzTJ"
      },
<<<<<<< HEAD
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CdImElYSD_rx"
      },
      "execution_count": null,
=======
      "execution_count": 16,
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SCOPE = sample_sums_states_weight_diff+samples_gamma_weight_states_last_sub_states_first\n",
        "E_IS_SCOPE = torch.mean(torch.mean(samples_IS, dim =1) * torch.mean(SCOPE, dim =1))\n",
        "E_IS_E_SCOPE = torch.mean(torch.mean(samples_IS,dim = 1 ))*torch.mean(torch.mean(SCOPE, dim =1))\n",
        "\n",
        "E_IS_SCOPE_2 = torch.mean(torch.mean(samples_IS_SCOPE, dim =1))\n",
        "E_IS_E_SCOPE_2 = torch.mean(torch.mean(samples_IS,dim = 1 )) * torch.mean(torch.mean(samples_all_shaping, dim =1))"
      ],
      "metadata": {
        "id": "mZ_xYyhiCxe9"
      },
<<<<<<< HEAD
      "execution_count": null,
=======
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prep"
      ],
      "metadata": {
        "id": "03SCZEAMnGeY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = CustomizableFeatureNet(input_dim=2, hidden_dims=[16, 32], output_dim=1, dtype = torch.float64)"
      ],
      "metadata": {
        "id": "LRcpZ6zAowqJ"
      },
      "execution_count": 18,
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
<<<<<<< HEAD
        "E_IS_SCOPE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGY9Jt3FDHKZ",
        "outputId": "4806bfd5-cc2a-40dc-9cf1-f9e471dfaf85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-1.1470e+24, dtype=torch.float64, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "E_IS_SCOPE_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbttxO_jDJGy",
        "outputId": "a0767c9a-54f3-4b4a-878c-f97fde383d23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-1.5943e+26, dtype=torch.float64, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "samples_IS_SCOPE[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtJJjUv-Ctv9",
        "outputId": "30a2eb29-85cd-42f7-913a-422b80b5c82d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ -2.5405e-85,  -0.0000e+00,   7.9024e-62,  -2.9790e-61,  -3.1831e-75,\n",
              "         -1.5365e-64,  -0.0000e+00,  -8.3521e-71,   9.1314e-24,  -6.9648e-66,\n",
              "        -2.0605e-135,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -1.5136e-54,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "          0.0000e+00,   7.9024e-62,   0.0000e+00,  -0.0000e+00,  2.1164e-111,\n",
              "        -9.5684e-135,  -0.0000e+00, -1.4140e-116,  -3.3219e-82,  -0.0000e+00,\n",
              "         -1.5197e-87,  -2.5695e-67,   5.3077e-82,  -0.0000e+00,   2.3741e-47,\n",
              "         -0.0000e+00,  -1.8253e-71,  -3.4879e+11,  -0.0000e+00,  -0.0000e+00,\n",
              "         3.8146e-114,  -0.0000e+00,  -7.5975e-31,  1.2321e-124,  -0.0000e+00,\n",
              "         -0.0000e+00, -2.0958e-170,   0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00, -1.0845e-110,  -1.8398e-69,  -1.8253e-71,   0.0000e+00,\n",
              "         -1.0142e-82,  -3.8087e-71, -4.7846e-116,  -0.0000e+00,  -1.1575e+14,\n",
              "         -8.3983e-61,  -0.0000e+00,  -3.5652e-20,  -4.5806e-83,  -4.3459e-47,\n",
              "         -8.4544e-60,  -0.0000e+00,  -8.8170e-22,  -0.0000e+00,  -0.0000e+00,\n",
              "          1.2354e-36,  -1.5363e-35,  -0.0000e+00, -4.9603e-128,  -0.0000e+00,\n",
              "         -6.3533e-43,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -1.5943e-87,\n",
              "         -3.5388e-13,  -0.0000e+00,  -4.5280e-49,  -1.8006e-40,  -1.9589e-72,\n",
              "         -0.0000e+00,  -1.6958e-50,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "        -6.2039e-105,  -0.0000e+00, -2.1867e-103, -5.2111e-109,  -9.0234e-81,\n",
              "        -7.3637e-125,  -0.0000e+00, -4.3031e-114,  -0.0000e+00,  -0.0000e+00,\n",
              "         -9.0569e-20, -4.9603e-128,  -0.0000e+00,  -0.0000e+00,  -1.2844e-50,\n",
              "          6.8821e-47,  -0.0000e+00,  -0.0000e+00,  -3.6297e-43,  -1.2560e-81,\n",
              "         -0.0000e+00,  -9.6121e-75,  -0.0000e+00,  -0.0000e+00,  -4.7752e-22,\n",
              "         -0.0000e+00,  -8.8170e-22,  -0.0000e+00,  -0.0000e+00,  -3.1837e-84,\n",
              "         -1.1765e-76,  -0.0000e+00,  -1.2844e-50, -7.3798e-163,  -2.0995e-92,\n",
              "         -0.0000e+00, -2.1867e-103,  -0.0000e+00,  -5.9858e-99,  -0.0000e+00,\n",
              "        -3.8876e-136,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -5.4505e-63,\n",
              "         -1.7515e-70,  -0.0000e+00,  -4.5557e-54,  -0.0000e+00,   1.7970e-29,\n",
              "         -4.4059e-35,  -1.8068e-87,  -4.7919e-84,  -1.2284e-23,  -1.5365e-64,\n",
              "          7.8287e-64,  -0.0000e+00,   0.0000e+00,  -2.5680e-16,  1.0151e-134,\n",
              "          5.4627e-50,  -2.1715e-71,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,   2.3966e-44, -4.9603e-128,  -8.2095e-86,  -2.6167e-27,\n",
              "         -6.9755e-72,  -2.5695e-67,  -1.7051e-55, -3.8876e-136,  -1.0863e-21,\n",
              "         9.3247e-114,  -4.4059e-35, -5.3088e-177,  -1.7168e-40,  -0.0000e+00,\n",
              "         -9.1651e-07,  -0.0000e+00,  -0.0000e+00,  -5.1282e-98,  -2.1147e-36,\n",
              "         -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,   3.2571e-55,\n",
              "          0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -2.5695e-67,\n",
              "         -3.3292e-89,  -0.0000e+00,  -0.0000e+00,   0.0000e+00, -5.9574e-107,\n",
              "         -6.7180e-81,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00, -2.2899e-120,\n",
              "         -1.2131e-90,  -1.1847e-05,  -0.0000e+00,  -0.0000e+00,   5.6168e-64,\n",
              "         -0.0000e+00,  -0.0000e+00,  -7.5275e-79,  -3.9772e-98, -1.4124e-115,\n",
              "          6.7779e-24,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -3.4915e-62,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -4.7835e-21,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00, -7.4818e-121,  -1.4379e-56,  -5.9858e-99,   6.5353e-19,\n",
              "         -0.0000e+00, -1.0845e-110,  -1.6331e-73,  -0.0000e+00,  -3.3794e-44,\n",
              "         -0.0000e+00,  -0.0000e+00,  -1.4403e-82,  -0.0000e+00,  -8.2958e-38,\n",
              "         -0.0000e+00,  -2.1267e-31,  -2.0919e-39,  -6.2543e-89,  -7.2344e-89,\n",
              "         -0.0000e+00, -7.4410e-122,  -0.0000e+00,  -9.2244e-29,  -7.6267e-28,\n",
              "         -0.0000e+00,  -1.4441e-84,  -3.4686e-46,  -0.0000e+00,   1.5539e-32,\n",
              "         -0.0000e+00,   2.8584e-70,  -0.0000e+00, -6.7465e-145,   2.3744e-38,\n",
              "         -1.0969e-41,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -2.6507e-76,  -0.0000e+00, -6.5637e-111,  -0.0000e+00,  -1.0553e-59,\n",
              "         -6.3674e-30,  -0.0000e+00,  -1.1992e-76, -8.8087e-109,  -0.0000e+00,\n",
              "         -0.0000e+00,  -2.0183e-60,   2.3741e-47,  -0.0000e+00,   6.4848e-87,\n",
              "         -5.4107e-35,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -9.3262e-46,  -0.0000e+00,  -1.0841e-42,  -0.0000e+00,  -3.2018e-02,\n",
              "         -0.0000e+00,  -1.1614e-91,  -0.0000e+00,  -7.3072e-92,  -0.0000e+00,\n",
              "          1.7396e-15, -8.8087e-109,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -3.3292e-89,  -0.0000e+00,  -1.8096e-45,   1.6171e-12,   2.3741e-47,\n",
              "         -2.1147e-36, -7.3798e-163,  -0.0000e+00,   2.4396e-88,  -0.0000e+00,\n",
              "         -0.0000e+00, -1.7320e-101,   3.5779e-27,  -0.0000e+00,  -3.9346e-91,\n",
              "         -1.4120e-71,  -0.0000e+00,  -0.0000e+00,  -1.1299e-90,  -0.0000e+00,\n",
              "         -0.0000e+00,  -5.2727e-61,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -1.0228e-11,  2.1164e-111,  -0.0000e+00,  -0.0000e+00,\n",
              "         -3.3794e-44, -2.3564e-152,  -0.0000e+00,  -2.5200e-98,  -1.4403e-82,\n",
              "         -0.0000e+00, -1.6503e-110,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -2.5405e-85,  -0.0000e+00,  -0.0000e+00,  -1.7051e-55,  -1.1579e-96,\n",
              "        -1.6503e-110,  -0.0000e+00, -7.9975e-114,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -2.5266e-42,  -3.2963e-38,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00, -1.3348e-146,  -7.9739e-71,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -1.6331e-73,  -1.2096e-60,  -4.9155e-49,  -0.0000e+00,\n",
              "         -8.5756e-93,  -0.0000e+00, -2.3319e-135,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,   2.0816e+09,  -3.3419e-33,  -0.0000e+00,\n",
              "         -9.5822e-03,  -0.0000e+00, -3.0795e-106,  -0.0000e+00,  -0.0000e+00,\n",
              "         -1.1765e-76,  -0.0000e+00,  -0.0000e+00,  -1.0841e-42,  -0.0000e+00,\n",
              "         -4.1517e-59,  -1.0295e-65,  -0.0000e+00,  -1.8006e-40,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -8.4740e-76,   0.0000e+00,\n",
              "        -2.9514e-101,  -2.5200e-98, -2.0605e-135,   2.3977e-39,  -0.0000e+00,\n",
              "         -0.0000e+00,  -1.6331e-73, -5.5873e-109,  -0.0000e+00,  -1.1992e-76,\n",
              "         -3.1831e-75,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -1.8398e-69,\n",
              "        -1.0896e-137,  -0.0000e+00,  -1.1847e-05,  -0.0000e+00,  -0.0000e+00,\n",
              "         -2.8369e-95,  -6.2692e-86,  -0.0000e+00,  -0.0000e+00,   1.9911e-59,\n",
              "         -2.3919e-79, -5.9400e-117,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -1.3256e-29,  -0.0000e+00,  -0.0000e+00,  -2.9009e-36,\n",
              "        -5.9194e-108,  -1.7051e-55,  -4.4059e-35,  -0.0000e+00, -2.0605e-135,\n",
              "         -1.5469e-21,  -4.4059e-35,  -4.5557e-54,  -0.0000e+00,  -8.7108e-62,\n",
              "         -1.1976e-94,  -1.8848e-48,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "        -5.2070e-107,  -0.0000e+00,  -2.0882e-86,  -0.0000e+00,  -5.1132e-04,\n",
              "          0.0000e+00,   9.1906e-19,  -3.1091e-65,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "        -3.7267e-107,  -0.0000e+00,  -4.9777e-77,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,  -4.1925e-25, -3.0795e-106,  -0.0000e+00,\n",
              "         -0.0000e+00,   0.0000e+00,  -0.0000e+00,  -4.5806e-83,  2.1164e-111,\n",
              "         -2.5200e-98, -4.3088e-113,  -0.0000e+00,  -3.6404e-32,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -9.1264e-43,  -0.0000e+00,\n",
              "         -2.4591e-89,  -0.0000e+00,  -0.0000e+00,   1.9275e-45,  -1.1543e-33,\n",
              "         -1.2560e-81,  -0.0000e+00,  -0.0000e+00,   2.3977e-39, -3.3028e-112,\n",
              "          7.8287e-64,  -0.0000e+00,  -0.0000e+00, -7.7889e-104, -6.3394e-172,\n",
              "         -8.8170e-22, -5.5873e-109,  3.8146e-114,  -0.0000e+00,  3.4576e-143,\n",
              "        -1.3164e-160,  -0.0000e+00,  -1.1579e-96,  -0.0000e+00,  -1.1299e-90,\n",
              "         -0.0000e+00,  -0.0000e+00,  -1.1997e-38,  -2.4591e-89,   9.1690e-44,\n",
              "         -2.2622e-69,  -1.2560e-81,  -3.2067e-77,  -3.5388e-13,   2.4880e-25,\n",
              "         -3.5370e-23,   5.4627e-50,  -0.0000e+00, -2.4613e-126,  -0.0000e+00,\n",
              "        -7.9975e-114,  -4.0313e-39,  -0.0000e+00,  -5.2680e-78, -6.3760e-128,\n",
              "         -5.0730e-73,  -9.1651e-07,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "        -2.2899e-120,   6.4848e-87,  -0.0000e+00,  -0.0000e+00,   1.7396e-15,\n",
              "         -2.4878e-79,  -0.0000e+00, -6.7220e-124,  3.4576e-143,  -5.4505e-63,\n",
              "          0.0000e+00,  -0.0000e+00,  -9.2244e-29,  -0.0000e+00,  -0.0000e+00,\n",
              "         -1.8006e-40,  -0.0000e+00,  -0.0000e+00, -3.9715e-111, -7.8048e-109,\n",
              "         -0.0000e+00,  -0.0000e+00,  -6.0378e-78,  -6.9027e-64,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,  -0.0000e+00,   0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,  -4.6446e+26,  -2.8369e-95, -3.7267e-107,\n",
              "         -0.0000e+00,   5.9283e-29,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "        -5.2111e-109,  -4.9777e-77,  -2.5057e-97,  -0.0000e+00,  -0.0000e+00,\n",
              "         -4.3459e-47,  -0.0000e+00,  -9.6952e-11,  -0.0000e+00,  -0.0000e+00,\n",
              "         -1.0423e-88,  -0.0000e+00,  -9.7803e-64,  -0.0000e+00,  -2.6108e-10,\n",
              "         -1.1245e-32,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -1.1614e-91,\n",
              "          5.9283e-29,  -1.8006e-40,  -0.0000e+00,  -1.4581e-42,  -1.9457e-84,\n",
              "          0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,  -1.2597e-64,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -7.6267e-28,  -1.1340e-54,  -0.0000e+00,   5.6168e-64,\n",
              "         2.1164e-111,  -1.6117e-70, -1.6001e-142, -7.4188e-119,  -1.6297e-40,\n",
              "         -0.0000e+00, -9.6814e-148,   0.0000e+00,  -4.9886e-56,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,  -3.5652e-20, -5.6374e-108,  -0.0000e+00,\n",
              "          6.4848e-87,  -0.0000e+00, -1.2228e-108,   9.1690e-44,  -2.4591e-89,\n",
              "        -5.2111e-109, -1.0845e-110,  -0.0000e+00,  -0.0000e+00,  -1.2284e-23,\n",
              "        -1.3276e-126,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,  -2.5405e-85,  -1.1543e-33,  -6.5620e-73,\n",
              "          9.6998e-75,   2.3966e-44,  -0.0000e+00,  -1.5943e-87,   6.8821e-47,\n",
              "         -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -2.5695e-67,  -3.9346e-91, -9.5684e-135,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00, -1.6503e-110,  -2.4878e-79,  -0.0000e+00,  -1.2096e-60,\n",
              "         -4.9154e-65,  -0.0000e+00,  -0.0000e+00,  -1.6205e-31, -5.9400e-117,\n",
              "         -3.6297e-43, -3.8447e-105,  -2.1245e-84,  -0.0000e+00,  -0.0000e+00,\n",
              "         -5.9911e-37,  -0.0000e+00,  -0.0000e+00,  -2.5057e-97, -2.6928e-118,\n",
              "         -0.0000e+00, -3.7267e-107,  -2.7470e-44, -2.1867e-103,  -5.0835e-67,\n",
              "        -7.4188e-119, -2.9514e-101,  -8.8828e-84, -3.9715e-111,  -5.5407e-09,\n",
              "         -8.3866e-92,  -0.0000e+00,  -3.7204e-20,   1.1578e-36,  -0.0000e+00,\n",
              "         -4.2977e-22,  -4.1575e-21,  -1.8068e-87,  -0.0000e+00,  -0.0000e+00,\n",
              "        -7.7889e-104,  -5.8622e-39,  -1.5944e+29,  -0.0000e+00,  -2.6167e-27,\n",
              "         -0.0000e+00,  -0.0000e+00,  -2.6167e-27,  -8.2095e-86,  -0.0000e+00,\n",
              "         -1.8470e-62,  -0.0000e+00,  -1.0278e-42,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -1.0553e-59,  -0.0000e+00, -6.5637e-111,  -0.0000e+00,\n",
              "         -4.6573e-78,  -1.3726e-66,  -1.7515e-70,  -2.3103e-40,  -0.0000e+00,\n",
              "         -4.9064e-04,   1.9275e-45,  -0.0000e+00,  -0.0000e+00,  -6.7637e-94,\n",
              "         -1.1299e-90,  -0.0000e+00, -1.2228e-108,  -0.0000e+00,  -1.5363e-35,\n",
              "        -2.6557e-114,  -7.6029e-46,  -2.7147e-61,  -1.9612e-45,  -1.2844e-50,\n",
              "         -1.6958e-50,  -2.7470e-44,  -0.0000e+00, -8.3040e-105,   0.0000e+00,\n",
              "        -7.4818e-121,  -0.0000e+00,   0.0000e+00,   6.8821e-47,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "          5.9283e-29,  -0.0000e+00, -8.8087e-109,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -8.2095e-86,  -0.0000e+00,  -0.0000e+00,  3.8146e-114,\n",
              "         -0.0000e+00,  -0.0000e+00, -5.7092e-133,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -3.1256e-52,  -0.0000e+00,\n",
              "          0.0000e+00,  -2.1977e-38,  -9.2244e-29,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,  -6.3676e+00,  -3.4200e-45,  -0.0000e+00,\n",
              "         -9.1264e-43, -9.5684e-135,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,   0.0000e+00,  -1.4581e-42,  -0.0000e+00,\n",
              "         -0.0000e+00,   2.0581e-29,   1.7970e-29,  -4.6949e-62, -4.3031e-114,\n",
              "         -0.0000e+00,  -0.0000e+00,  -4.1925e-25,  -0.0000e+00,  -0.0000e+00,\n",
              "        -1.6001e-142,  -0.0000e+00, -5.9574e-107, -1.6001e-142,  -3.7204e-20,\n",
              "        -8.0555e-127,  -0.0000e+00,  -0.0000e+00,  -1.4441e-84,  -0.0000e+00,\n",
              "         -5.1132e-04,   5.9283e-29,  -0.0000e+00,  -8.4817e-65,  -0.0000e+00,\n",
              "         -1.0142e-82,  -0.0000e+00,   0.0000e+00,  -0.0000e+00,  -1.6297e-40,\n",
              "         -1.1806e-76,  -0.0000e+00,   8.8334e-65,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,  -1.2844e-50,  -6.9755e-72,  -0.0000e+00,\n",
              "        -1.6001e-142,  -0.0000e+00,  -2.7082e-39, -2.3923e-123,  -1.2560e-81,\n",
              "         -5.5725e-99,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -6.2249e-32,\n",
              "         -0.0000e+00,  -3.4879e+11,  -1.2096e-60,  -1.2131e-90, -6.7220e-124,\n",
              "          7.6016e-81,  -5.5407e-09,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -2.0995e-92, -5.7092e-133,  -4.1575e-21,  -9.1264e-43, -1.8313e-144,\n",
              "         -0.0000e+00,  -1.5363e-35,  -0.0000e+00,  -3.4915e-62,  -0.0000e+00,\n",
              "         -0.0000e+00,  -3.2067e-77,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -1.5469e-21,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,  9.3247e-114,  -0.0000e+00, -1.4124e-115,\n",
              "         -0.0000e+00,  -6.5620e-73, -1.6503e-110,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00, -3.0795e-106,  -1.1997e-38, -5.3088e-177,  -0.0000e+00,\n",
              "         -7.8034e-88,  -0.0000e+00,   2.0581e-29,  -2.5405e-85,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -3.9346e-91,  -4.1575e-21,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00, -7.4410e-122,  -0.0000e+00,  -0.0000e+00,\n",
              "          0.0000e+00,  -2.0389e-21,  -1.3726e-66, -7.3637e-125,  -0.0000e+00,\n",
              "         -7.5275e-79,  -0.0000e+00,  -7.9739e-71,  -0.0000e+00,  -0.0000e+00,\n",
              "        -4.7846e-116,  -0.0000e+00, -5.7104e-117,   0.0000e+00,  -0.0000e+00,\n",
              "        -7.4818e-121,  -1.5197e-87,  -0.0000e+00,  -0.0000e+00, -1.4183e-111,\n",
              "         -4.3459e-47,  -0.0000e+00, -3.6588e-102,  -0.0000e+00,  -0.0000e+00,\n",
              "         -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -4.7835e-21,\n",
              "         -4.7835e-21,  -0.0000e+00,  -1.0228e-11,  -0.0000e+00,  -0.0000e+00,\n",
              "         -3.9772e-98,  -0.0000e+00,  -4.2977e-22,  -0.0000e+00,  -0.0000e+00,\n",
              "         -2.5680e-16, -1.4183e-111,  -0.0000e+00,  -4.2977e-22,  -1.2793e-97,\n",
              "         -6.8366e-36,  -0.0000e+00,   2.3977e-39,  -9.6952e-11,  -0.0000e+00,\n",
              "         -0.0000e+00,   1.9911e-59,  -1.4120e-71,  -0.0000e+00, -9.5684e-135,\n",
              "        -3.1407e-107,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,  -0.0000e+00,\n",
              "         -2.5266e-42,  -2.6108e-10,  -0.0000e+00,  -0.0000e+00,  -5.3309e-32,\n",
              "         -0.0000e+00, -3.4482e-108,  -0.0000e+00, -3.3028e-112,  -1.8253e-71,\n",
              "         -1.5197e-87,  -0.0000e+00,  -1.2319e-33,  -0.0000e+00,   0.0000e+00],\n",
              "       dtype=torch.float64, grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_sums_states_weight_diff[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Orvqs0-IwoN4",
        "outputId": "82af141d-6b75-47cc-f39e-77dccf6c0612"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 5.1683e-01,  5.2720e-01,  2.3982e+00,  5.2951e-01,  5.1357e-01,\n",
              "         5.1364e-01, -1.1535e+00,  5.1631e-01,  5.1753e-01,  5.1325e-01,\n",
              "         9.0952e-02,  3.6275e-01,  5.2720e-01,  7.6119e-02,  7.6752e-02,\n",
              "         5.3759e-01,  9.0952e-02,  7.6337e-02,  9.0952e-02,  9.0657e-02,\n",
              "         5.7605e+00,  2.3982e+00,  3.6205e+00,  9.0436e-02,  3.9866e+00,\n",
              "         7.6361e-02,  5.1632e-01,  7.7653e-02,  1.2674e-01,  9.0436e-02,\n",
              "         7.6119e-02,  5.1709e-01,  3.6920e+00,  5.1663e-01,  9.0973e-02,\n",
              "         5.3759e-01,  5.3762e-01, -2.9977e+06,  5.1357e-01,  5.3602e-01,\n",
              "         4.1946e+00,  5.2720e-01, -6.4696e+01,  5.2645e-01,  5.1683e-01,\n",
              "         5.2907e-01,  5.2645e-01,  3.6920e+00,  5.3771e-01,  4.8009e-01,\n",
              "         4.2201e-01,  9.0952e-02,  8.3283e-02,  5.3762e-01,  4.2676e+00,\n",
              "         5.1366e-01,  7.7653e-02,  5.3583e-01,  5.3728e-01, -5.6362e+07,\n",
              "         2.5242e-01, -1.5415e+10, -1.8276e-02,  8.9459e-02,  9.0952e-02,\n",
              "         5.1665e-01, -2.1687e+00, -4.6237e+01,  5.2644e-01,  5.3773e-01,\n",
              "         9.0433e-02, -3.7703e-01,  5.1365e-01,  7.7653e-02,  5.3583e-01,\n",
              "         5.1357e-01,  9.0955e-02,  9.0431e-02,  7.7654e-02,  5.1709e-01,\n",
              "         4.2142e-01,  5.3759e-01,  5.3759e-01,  5.1357e-01, -2.4942e+01,\n",
              "         8.9367e-02,  5.3773e-01,  5.2656e-01,  9.0952e-02,  5.3583e-01,\n",
              "         5.1364e-01,  5.2901e-01,  5.2644e-01,  7.7619e-02,  9.0952e-02,\n",
              "         9.0952e-02,  4.7722e-01,  5.2653e-01,  5.3771e-01,  5.3759e-01,\n",
              "        -2.7596e-01,  7.7653e-02,  9.0952e-02,  7.6361e-02,  9.0952e-02,\n",
              "         5.1728e-01,  9.0952e-02,  9.0431e-02,  4.7655e-01,  5.3759e-01,\n",
              "         5.2644e-01,  9.0657e-02,  7.6361e-02,  1.3149e-01,  5.1357e-01,\n",
              "         7.7556e-02, -4.6237e+01,  5.2653e-01,  9.0436e-02,  4.3616e-01,\n",
              "         7.7633e-02,  9.0433e-02,  9.0952e-02,  9.0952e-02,  5.1665e-01,\n",
              "         5.3547e-01,  5.2644e-01,  7.6105e-02,  9.0952e-02, -1.3443e+00,\n",
              "         5.0960e-01,  5.3761e-01,  9.0952e-02,  5.3591e-01,  5.1357e-01,\n",
              "         5.2714e-01,  4.7650e-01,  8.2442e-02,  5.2920e-01,  7.4989e-02,\n",
              "         5.1428e-01, -9.2283e-01,  5.3759e-01,  5.2900e-01,  5.1364e-01,\n",
              "         1.3196e+00,  5.3602e-01,  3.5049e+00, -1.3996e+03,  1.0444e+01,\n",
              "         7.6121e-02,  9.0949e-02,  7.7556e-02,  9.0952e-02,  5.1711e-01,\n",
              "         9.0955e-02,  4.2595e+00,  7.7653e-02,  5.1357e-01,  5.2900e-01,\n",
              "         5.1782e-01,  5.1709e-01, -2.5074e+01,  5.0960e-01, -1.8205e+00,\n",
              "         5.2652e-01,  5.1428e-01,  5.3773e-01,  5.3771e-01,  5.2720e-01,\n",
              "        -6.8967e+05,  5.3583e-01, -5.6433e-01,  5.3761e-01,  5.2720e-01,\n",
              "         7.7653e-02,  8.9262e-02, -4.4482e+00,  9.0956e-02,  9.0436e-02,\n",
              "         5.4839e+00,  5.2644e-01,  2.3645e-01,  5.1589e-01,  5.1709e-01,\n",
              "         5.3759e-01,  5.1916e-01,  9.0657e-02,  3.6926e+00,  5.2720e-01,\n",
              "         3.5348e-01,  7.6119e-02,  9.0433e-02,  5.2481e-01,  9.0952e-02,\n",
              "         3.9951e-01,  5.1318e-01,  9.0976e-02,  7.6361e-02,  7.4962e-02,\n",
              "         9.0436e-02,  9.0955e-02,  5.2644e-01,  5.1364e-01,  5.2656e-01,\n",
              "         7.6119e-02,  9.0954e-02,  5.3771e-01,  5.1724e-01,  4.3459e-01,\n",
              "         4.7453e-01,  5.2481e-01,  5.3093e-01,  5.2720e-01,  4.7947e-01,\n",
              "         5.1357e-01,  9.0654e-02,  4.0053e-01,  9.0954e-02,  5.3761e-01,\n",
              "         9.0974e-02,  2.5289e-01,  5.3583e-01,  5.1370e-01,  4.7938e-01,\n",
              "         8.3403e-02,  5.3602e-01,  2.3645e-01,  9.0973e-02,  5.2973e-01,\n",
              "         8.9367e-02,  7.7653e-02,  5.1366e-01,  9.0952e-02,  7.4973e-02,\n",
              "         4.7722e-01,  9.0952e-02,  9.0952e-02,  5.3583e-01,  4.8604e-02,\n",
              "         7.7653e-02,  5.1711e-01,  4.1136e-01,  4.7650e-01,  5.2264e-01,\n",
              "         5.3544e-01,  7.7653e-02,  5.2720e-01,  5.2720e-01,  5.1683e-01,\n",
              "         5.2643e-01,  9.0954e-02,  9.0952e-02,  5.1562e-01, -3.3918e-01,\n",
              "         7.7633e-02,  5.1665e-01,  5.3759e-01,  5.1364e-01,  2.8980e+00,\n",
              "        -1.2457e+01,  1.3655e+06,  5.1364e-01,  9.0952e-02,  7.7619e-02,\n",
              "         7.7653e-02,  5.2907e-01,  5.2481e-01,  8.4154e-02,  7.7633e-02,\n",
              "         5.3602e-01,  5.2644e-01,  5.3773e-01,  4.7939e-01,  7.7246e-02,\n",
              "        -4.3690e+00, -1.0027e+00, -8.2078e+00,  9.0973e-02,  5.2723e-01,\n",
              "         5.3330e-01,  5.1357e-01,  9.0973e-02,  4.2201e-01,  3.9321e+00,\n",
              "         4.7938e-01,  4.4394e-01,  5.1665e-01,  9.0436e-02, -7.3013e+01,\n",
              "         8.3361e-02,  5.1414e-01,  4.2142e-01,  5.1504e-01, -1.6895e+10,\n",
              "         9.0952e-02,  4.7722e-01,  7.7633e-02,  5.1357e-01,  9.0952e-02,\n",
              "         5.1815e+00,  9.0973e-02,  5.2644e-01,  4.8009e-01, -2.7487e+10,\n",
              "         5.3759e-01,  4.7722e-01,  7.5000e-02,  6.7563e-02,  9.0973e-02,\n",
              "         5.2720e-01,  9.0952e-02,  5.3058e-01,  5.1724e-01,  5.1364e-01,\n",
              "         9.0973e-02,  7.7627e-02,  5.3583e-01, -9.8881e+02,  5.2714e-01,\n",
              "         5.1683e-01,  5.3340e-01,  9.0952e-02,  5.2644e-01,  7.7653e-02,\n",
              "         5.1724e-01,  5.3759e-01,  5.3602e-01,  9.0418e-02,  5.3602e-01,\n",
              "         7.7556e-02, -4.9233e+04,  3.9866e+00, -4.4482e+00,  5.3602e-01,\n",
              "         4.8604e-02,  5.3761e-01,  5.3728e-01,  9.0952e-02,  4.1136e-01,\n",
              "         5.3759e-01,  9.0973e-02,  5.3591e-01,  4.7938e-01,  4.8097e-01,\n",
              "         5.1683e-01,  7.6119e-02,  5.2644e-01, -2.5074e+01,  5.3602e-01,\n",
              "         9.0973e-02,  9.0956e-02,  5.2652e-01,  5.2481e-01, -1.1318e+06,\n",
              "         5.1666e-01,  5.2720e-01,  5.1665e-01,  9.0952e-02,  7.6119e-02,\n",
              "         7.7653e-02,  7.6121e-02, -3.0503e+00,  4.7722e-01,  5.2901e-01,\n",
              "         5.2907e-01,  9.0952e-02,  5.1893e-01,  5.3058e-01,  5.2901e-01,\n",
              "         5.2900e-01, -1.1318e+06,  5.1728e-01,  5.1365e-01,  4.7708e-01,\n",
              "         7.7243e-02,  9.0976e-02, -2.0596e+05,  3.9834e-01, -1.1694e+00,\n",
              "        -7.6578e+01,  5.1632e-01,  5.3444e-01,  7.7627e-02,  5.2653e-01,\n",
              "         7.7633e-02, -1.2990e-01,  5.2481e-01,  4.2142e-01,  4.7708e-01,\n",
              "         5.1298e-01,  9.0948e-02,  3.3077e-01,  5.1357e-01,  7.6361e-02,\n",
              "         5.3771e-01,  5.3602e-01,  8.5267e-02,  5.1411e-01,  3.3376e+00,\n",
              "         5.3602e-01,  9.0952e-02,  9.0952e-02,  5.3761e-01,  5.3761e-01,\n",
              "         5.2720e-01,  9.0952e-02,  5.1364e-01,  5.1665e-01, -8.2078e+00,\n",
              "         5.1357e-01,  9.0656e-02,  5.1631e-01,  9.0433e-02,  8.3283e-02,\n",
              "         7.6361e-02,  5.3773e-01,  5.1318e-01,  9.0657e-02,  7.7619e-02,\n",
              "         5.1709e-01,  4.9870e-01,  8.1049e-02,  5.3602e-01,  5.3583e-01,\n",
              "         5.1414e-01,  5.1366e-01,  9.0436e-02,  4.3569e-01,  5.3408e-01,\n",
              "        -1.1694e+00,  5.1357e-01,  5.3005e-01, -1.1318e+06,  5.3771e-01,\n",
              "         5.3602e-01, -2.5074e+01,  5.1428e-01,  9.0952e-02,  9.0952e-02,\n",
              "         1.3058e+01,  5.1428e-01,  8.2442e-02,  5.1364e-01,  7.7574e-02,\n",
              "         4.7995e-01,  5.3602e-01,  6.9435e-02,  9.0657e-02,  9.0973e-02,\n",
              "         5.1709e-01,  5.3404e-01,  7.7653e-02,  5.1357e-01, -1.1658e+06,\n",
              "         3.5049e+00,  4.5514e-01,  5.1665e-01,  5.1047e-01, -7.2190e+10,\n",
              "         5.2653e-01, -2.0584e-01,  5.3602e-01,  5.3544e-01, -2.1687e+00,\n",
              "         5.3773e-01,  7.6361e-02,  5.2644e-01,  5.1770e-01,  4.3616e-01,\n",
              "        -3.4605e+02,  3.8834e-01, -5.7075e-01,  5.3444e-01,  4.3616e-01,\n",
              "         5.2724e-01,  5.4799e+00,  5.2993e-01,  8.9459e-02,  3.9866e+00,\n",
              "         9.0952e-02,  5.3761e-01, -2.2314e+00,  5.1792e-01,  4.7939e-01,\n",
              "         4.3616e-01,  8.9367e-02,  5.1683e-01, -5.4331e+00,  5.2973e-01,\n",
              "         5.1367e-01,  5.3602e-01,  9.0954e-02,  7.6118e-02,  5.1357e-01,\n",
              "         5.3759e-01,  4.3616e-01,  5.3408e-01,  5.3761e-01,  5.1414e-01,\n",
              "         1.3196e+00,  5.3591e-01, -7.5061e-02,  4.8096e-01,  7.6361e-02,\n",
              "        -4.6237e+01,  5.1364e-01,  4.1946e+00,  5.2481e-01,  5.1357e-01,\n",
              "         9.0976e-02,  5.1419e-01,  5.3602e-01,  5.2638e-01,  5.2644e-01,\n",
              "         5.2720e-01, -1.3566e+07, -2.2910e+00,  5.1367e-01,  4.2555e+00,\n",
              "         5.3759e-01,  5.3759e-01,  7.7653e-02,  4.2142e-01,  7.4973e-02,\n",
              "         2.5229e-01,  7.6121e-02,  4.3569e-01,  9.0657e-02,  5.3058e-01,\n",
              "         5.2652e-01,  4.7938e-01,  5.3762e-01,  5.2951e-01,  5.1709e-01,\n",
              "        -4.4662e-01, -6.8967e+05,  5.1605e-01,  5.2973e-01, -2.7469e+03,\n",
              "         9.0952e-02,  3.9321e+00,  5.2907e-01,  5.1297e-01,  5.1815e+00,\n",
              "         5.1411e-01, -2.0584e-01,  7.7633e-02,  5.1357e-01,  5.1357e-01,\n",
              "         4.4238e+00, -2.6895e+01,  5.1562e-01,  7.6361e-02,  5.3544e-01,\n",
              "         5.1357e-01,  5.2993e-01,  5.2653e-01,  5.1665e-01,  5.1711e-01,\n",
              "         5.3771e-01,  5.1364e-01,  5.1365e-01,  5.3583e-01,  9.0431e-02,\n",
              "         5.3759e-01,  9.0657e-02, -4.7566e-02,  3.6920e+00,  5.2652e-01,\n",
              "         5.2799e-01,  5.3728e-01, -5.2253e+15,  5.1709e-01,  5.3773e-01,\n",
              "         5.3544e-01,  7.6356e-02,  5.1631e-01,  5.1685e-01, -2.7487e+10,\n",
              "         7.7619e-02,  5.2644e-01,  5.1366e-01,  5.3759e-01,  5.2720e-01,\n",
              "         9.0952e-02,  8.6001e-02, -6.6563e+03, -3.5506e+00,  5.2973e-01,\n",
              "         5.3602e-01,  5.3759e-01,  5.3759e-01,  7.5080e-02,  3.0557e+00,\n",
              "        -2.5344e-01,  5.3762e-01,  9.0952e-02,  5.2901e-01,  4.7722e-01,\n",
              "         7.6356e-02,  5.1357e-01,  7.7653e-02,  5.1325e-01,  7.7556e-02,\n",
              "         1.3330e+00,  7.6104e-02,  5.2644e-01,  5.2901e-01,  7.6752e-02,\n",
              "         5.1711e-01,  9.0952e-02, -1.1708e+00,  5.2900e-01, -3.2846e+01,\n",
              "         5.2600e-01, -3.3918e-01,  5.1357e-01,  7.7653e-02,  7.4962e-02,\n",
              "         3.9866e+00,  9.0948e-02,  5.3773e-01,  5.3771e-01,  4.7939e-01,\n",
              "         5.1419e-01,  5.3761e-01,  5.7605e+00,  3.8131e-01,  5.2644e-01,\n",
              "         9.0973e-02,  9.0952e-02, -1.8276e-02,  7.6361e-02,  5.1297e-01,\n",
              "         3.9321e+00,  5.2653e-01,  9.0952e-02,  4.2555e+00,  5.1367e-01,\n",
              "         7.7619e-02,  9.0952e-02,  5.2481e-01,  5.1444e-01,  5.2900e-01,\n",
              "         4.3569e-01, -1.0532e+07,  5.1419e-01,  9.0955e-02,  7.7246e-02,\n",
              "         5.2920e-01, -1.1318e+06,  5.1683e-01,  5.1357e-01,  5.1357e-01,\n",
              "         7.4989e-02,  4.2595e+00,  7.6361e-02,  5.1709e-01,  5.1728e-01,\n",
              "         5.3761e-01,  9.0952e-02,  4.0053e-01,  8.1049e-02,  4.7650e-01,\n",
              "         4.2840e-01,  9.0952e-02,  5.2644e-01,  5.3588e-01,  5.1411e-01,\n",
              "         5.1709e-01,  5.2714e-01,  7.6361e-02,  5.3771e-01,  9.0431e-02,\n",
              "         5.1364e-01,  9.0973e-02,  5.1411e-01, -8.0030e+06,  5.1893e-01,\n",
              "         9.0952e-02,  5.1357e-01,  5.1711e-01,  5.3005e-01,  5.1366e-01,\n",
              "         4.7655e-01,  5.3759e-01,  8.4499e-02,  5.2720e-01,  9.0955e-02,\n",
              "         5.1357e-01, -1.8447e-01,  9.0433e-02,  5.1366e-01,  5.2721e-01,\n",
              "         9.0656e-02,  5.3773e-01,  5.1364e-01,  5.2644e-01,  5.3055e-01,\n",
              "         5.3771e-01,  5.3602e-01,  5.2631e-01,  5.1665e-01, -8.5441e+00,\n",
              "         4.7468e-01,  9.0973e-02, -6.4931e+01,  1.9185e+00,  9.0952e-02,\n",
              "         8.3283e-02,  5.1357e-01, -9.2283e-01,  5.2720e-01,  5.2720e-01,\n",
              "         4.8096e-01,  5.1357e-01, -9.3440e+14, -7.3013e+01,  5.2900e-01,\n",
              "         9.0952e-02,  7.7654e-02,  5.2900e-01,  5.1357e-01,  5.3547e-01,\n",
              "         5.0987e-01,  4.3616e-01,  9.0657e-02,  5.3583e-01,  5.1770e-01,\n",
              "         5.3591e-01,  7.7246e-02, -3.6693e+06,  5.3773e-01,  4.3569e-01,\n",
              "         4.8324e-01,  4.7938e-01,  5.2714e-01,  7.6345e-02,  7.7243e-02,\n",
              "        -2.4566e+05,  7.6118e-02,  5.3771e-01,  5.2907e-01,  9.0952e-02,\n",
              "         5.2644e-01,  9.0976e-02,  9.0952e-02,  9.0954e-02, -3.7703e-01,\n",
              "         5.1357e-01,  5.1411e-01,  7.7653e-02,  5.1665e-01,  9.0952e-02,\n",
              "         5.3773e-01,  5.1364e-01,  5.2644e-01,  5.1364e-01,  1.0034e+00,\n",
              "         7.7653e-02,  5.1297e-01,  5.4839e+00,  5.1728e-01,  5.3759e-01,\n",
              "        -2.6111e+01,  4.7939e-01,  5.2644e-01,  2.7664e-01,  5.1477e-01,\n",
              "         7.6356e-02,  5.3588e-01,  9.0973e-02,  9.0952e-02,  5.3583e-01,\n",
              "         5.3340e-01,  5.1357e-01,  5.3761e-01,  9.0957e-02,  4.1946e+00,\n",
              "         5.1365e-01,  5.3602e-01,  5.1683e-01,  4.3616e-01, -8.0030e+06,\n",
              "         4.3569e-01,  7.7556e-02,  9.0952e-02,  5.1665e-01,  5.1782e-01,\n",
              "         3.3888e+00,  5.1357e-01,  5.1562e-01,  5.1683e-01,  5.3602e-01,\n",
              "         5.1666e-01,  5.3759e-01, -1.5824e+02,  5.1357e-01,  5.2644e-01,\n",
              "        -5.4331e+00,  7.6361e-02,  5.3591e-01,  9.0433e-02,  5.2653e-01,\n",
              "         5.2720e-01,  7.7618e-02,  5.6180e+00,  5.1325e-01,  5.1711e-01,\n",
              "         3.6519e-01,  4.3561e-01,  7.4989e-02,  9.0952e-02,  5.2653e-01,\n",
              "         7.7637e-02,  5.3773e-01, -5.7075e-01,  9.0973e-02,  5.1365e-01,\n",
              "         5.3773e-01,  9.0431e-02,  5.2720e-01,  5.3773e-01, -6.4931e+01,\n",
              "         7.7633e-02,  5.3728e-01,  7.7653e-02,  5.1665e-01,  5.2481e-01,\n",
              "        -1.1658e+06,  7.6356e-02, -5.6433e-01,  4.3616e-01,  5.1444e-01,\n",
              "         5.1366e-01,  5.3759e-01,  5.4839e+00,  5.3602e-01,  4.7939e-01,\n",
              "         5.2644e-01,  5.2720e-01,  3.6919e+00,  9.0952e-02,  5.3762e-01,\n",
              "         5.1414e-01,  4.2835e-01,  9.0952e-02,  5.1782e-01,  7.7653e-02,\n",
              "         5.3773e-01,  5.3759e-01, -7.8570e-01,  9.0952e-02,  5.3759e-01,\n",
              "         7.5382e-02,  8.9367e-02, -4.4482e+00,  4.7938e-01,  5.1357e-01,\n",
              "         9.0656e-02, -2.9977e+06,  5.1893e-01,  3.9951e-01,  7.7633e-02,\n",
              "         7.7619e-02, -8.5441e+00,  5.3773e-01,  4.7453e-01,  5.1724e-01,\n",
              "         5.1665e-01,  5.1683e-01,  5.1357e-01, -5.4331e+00,  5.3420e-01,\n",
              "         5.3773e-01, -3.7703e-01,  5.2952e-01,  5.1357e-01,  1.9632e-01,\n",
              "         9.0952e-02,  7.7653e-02,  8.9262e-02,  5.2953e-01,  9.0973e-02,\n",
              "         5.3583e-01,  1.3058e+01,  5.2952e-01,  5.1370e-01,  5.3547e-01,\n",
              "         5.2644e-01,  9.0952e-02,  5.2652e-01,  5.1364e-01,  5.2656e-01,\n",
              "         5.2724e-01,  5.1357e-01,  9.0973e-02,  9.0952e-02,  7.6119e-02,\n",
              "         5.3602e-01,  5.3444e-01, -2.2910e+00,  5.3773e-01,  7.7654e-02,\n",
              "        -2.2579e-01,  4.6518e-01,  4.3561e-01,  5.1683e-01,  4.1597e-01,\n",
              "         9.0657e-02,  9.0436e-02,  7.7246e-02,  9.0436e-02,  7.7556e-02,\n",
              "         5.2714e-01,  5.1357e-01,  5.1367e-01,  5.2720e-01, -3.8281e+02,\n",
              "         5.2973e-01,  5.2644e-01,  9.0954e-02,  5.3537e-01,  4.7708e-01,\n",
              "         1.3330e+00,  5.1356e-01,  4.7938e-01,  9.0952e-02,  9.0657e-02,\n",
              "         5.2644e-01,  9.0952e-02, -3.0503e+00,  4.4394e-01,  9.0973e-02,\n",
              "         5.3583e-01,  5.1357e-01,  5.2951e-01,  3.3888e+00,  4.2835e-01,\n",
              "         7.7653e-02,  7.6119e-02,  9.0973e-02,  5.3761e-01,  5.2959e-01,\n",
              "         9.0952e-02,  5.3583e-01,  5.1724e-01,  5.3404e-01,  5.1357e-01,\n",
              "         7.7633e-02,  7.5080e-02,  5.3340e-01,  9.0955e-02,  9.0974e-02,\n",
              "         9.0974e-02,  5.1683e-01, -4.9233e+04,  5.3771e-01,  5.3110e-01,\n",
              "         5.1364e-01, -3.6693e+06,  8.3283e-02,  5.2481e-01, -3.4611e+00,\n",
              "        -1.3996e+03,  5.2959e-01,  5.2720e-01,  8.3283e-02,  7.7653e-02,\n",
              "         5.1355e-01,  5.1412e-01,  5.3761e-01, -6.6563e+03,  5.3759e-01,\n",
              "         4.7938e-01,  5.3583e-01,  5.1683e-01,  9.0957e-02,  7.6361e-02,\n",
              "         5.1357e-01,  9.0973e-02, -1.3134e+06,  4.2840e-01,  9.0436e-02,\n",
              "         5.2720e-01,  3.0557e+00,  5.2901e-01,  5.3602e-01,  5.1297e-01,\n",
              "         5.1504e-01,  5.1411e-01,  5.1419e-01,  5.1414e-01,  5.3762e-01,\n",
              "         7.6119e-02,  9.0955e-02, -3.0039e+04,  5.1365e-01,  3.5049e+00],\n",
              "       dtype=torch.float64, grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sums_shaping = sums_states_weight_diff + gamma_weights_states_last_sub_states_first"
      ],
      "metadata": {
        "id": "cQwdg78It-sd"
      },
      "execution_count": null,
=======
        "test1 = SCOPE_variance(model, 0.9, 10000, pi_b, P_pi_b, P_pi_e, dtype = torch.float64)"
      ],
      "metadata": {
        "id": "jqKcMhNSnRTC"
      },
      "execution_count": 19,
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
<<<<<<< HEAD
        "torch.mean(sums_shaping)"
=======
        "samples_IS, padded_state_tensors, padded_weight_diff_tensors, gamma_weights_last_tensor, states_first_tensor, states_last_tensor = test1.prepare()"
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
<<<<<<< HEAD
        "id": "jpNY7q-guFCA",
        "outputId": "21738905-c107-4f20-9480-a0e1cead242f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-9.7904e+39, dtype=torch.float64, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 58
=======
        "id": "uftstgp1nRTP",
        "outputId": "f2c3d69a-7ed8-42c3-d815-289323c15faa"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/Shaping/SCOPE_variance.py:89: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  padded_weight_diff_tensors = torch.tensor(padded_weights_difference, dtype = self.dtype)\n"
          ]
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
<<<<<<< HEAD
=======
        "def clamp_large_terms(tensor):\n",
        "  clamped_tensor = torch.clamp(tensor, min = -1e38, max = 1e38)\n",
        "  return clamped_tensor"
      ],
      "metadata": {
        "id": "pHvWigy5tCVY"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "states_output, states_first_output, states_last_output = test1.pass_states(model, padded_state_tensors, states_first_tensor, states_last_tensor)\n",
        "sums_states_weight_diff = test1.states_weight_diff_sums(states_output, padded_weight_diff_tensors)\n",
        "gamma_weights_states_last_sub_states_first = test1.last_first_terms_operations(gamma_weights_last_tensor, states_last_output, states_first_output)\n",
        "sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first = test1.bootstrap_shaping_terms(sums_states_weight_diff, gamma_weights_states_last_sub_states_first)"
      ],
      "metadata": {
        "id": "-AlHoAZwi9Dr"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
        "# Print the min and max values of tensors\n",
        "print(\"padded_weight_diff_tensors - Min:\", padded_weight_diff_tensors.min().item(), \" Max:\", padded_weight_diff_tensors.max().item())\n",
        "print(\"sums_states_weight_diff - Min:\", sums_states_weight_diff.min().item(), \" Max:\", sums_states_weight_diff.max().item())\n",
        "print(\"gamma_weights_last_tensor - Min:\", gamma_weights_last_tensor.min().item(), \" Max:\", gamma_weights_last_tensor.max().item())\n",
        "print(\"samples_IS - Min:\", samples_IS.min().item(), \" Max:\", samples_IS.max().item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RZCBfD9vwRx",
<<<<<<< HEAD
        "outputId": "ebaecd5c-ec6a-430d-f578-ee4fc5fe8ddd"
      },
      "execution_count": null,
=======
        "outputId": "a59034bf-9d51-4363-9e2a-07829ff78330"
      },
      "execution_count": 38,
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
<<<<<<< HEAD
            "padded_weight_diff_tensors - Min: -6979572071212940.0  Max: 1.839130399958296e+16\n",
            "sums_states_weight_diff - Min: -5225342891061462.0  Max: 1365487.6953395614\n",
            "gamma_weights_last_tensor - Min: 1.846463839642936e-238  Max: 143894458319084.28\n",
            "samples_IS - Min: -10076.89890923087  Max: 159882731465649.2\n"
=======
            "padded_weight_diff_tensors - Min: -7.550129734505424e+42  Max: 6.991006254054227e+42\n",
            "sums_states_weight_diff - Min: -1.4941302238414574e+31  Max: 2.3861580455071615e+41\n",
            "gamma_weights_last_tensor - Min: 0.0  Max: 9.232375374691587e+41\n",
            "samples_IS - Min: -1.025819486076843e+42  Max: 1.0028234611748854e+17\n"
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
          ]
        }
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "source": [
        "torch.mean(sample_sums_states_weight_diff,dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lj6mSyUmUqqp",
        "outputId": "21a53d42-836a-4dc8-d67f-ba381264b891"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-9.9641e+39, -2.6692e+27, -9.9641e+39,  ..., -1.9928e+40,\n",
              "        -2.9892e+40, -1.3346e+27], dtype=torch.float64,\n",
              "       grad_fn=<MeanBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mean(samples_gamma_weight_states_last_sub_states_first, dim =1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYJ0CkAeUxYJ",
        "outputId": "9c9fe1d0-8246-427a-e25a-4704db91823d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.7368e+38, 5.5852e+13, 1.7368e+38,  ..., 3.4735e+38, 5.2103e+38,\n",
              "        2.7925e+13], dtype=torch.float64, grad_fn=<MeanBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fpf1bgqIRAzx"
=======
      "source": [],
      "metadata": {
        "id": "wY_5o9lNM7m0"
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
      },
      "execution_count": null,
      "outputs": []
    },
    {
<<<<<<< HEAD
      "cell_type": "markdown",
      "source": [
        "# Calc Variance"
      ],
      "metadata": {
        "id": "wwmn8QMhO5QN"
      }
=======
      "cell_type": "code",
      "source": [
        "sample_sums_states_weight_diff"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lj6mSyUmUqqp",
        "outputId": "268a89c8-d6ca-4ecc-9dbe-372e23425e10"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 4.3824e-01,  8.1490e-01,  9.2492e-01,  ...,  1.0635e+00,\n",
              "          1.3945e+00,  6.3964e-01],\n",
              "        [ 8.2159e-01,  5.7726e-01,  2.1574e-01,  ...,  3.8854e-01,\n",
              "          3.9796e-01,  5.7957e-01],\n",
              "        [ 2.1822e-01,  3.3109e-01,  3.8186e-01,  ...,  4.7009e+00,\n",
              "          1.0229e+00,  9.5873e-02],\n",
              "        ...,\n",
              "        [ 7.5091e-01,  3.8642e-01,  1.6987e-01,  ...,  4.2620e-01,\n",
              "          4.3590e-01,  8.2233e-01],\n",
              "        [ 2.2644e-01, -3.0499e+03,  4.8253e-01,  ...,  1.3384e+00,\n",
              "          4.2620e-01,  2.6050e-01],\n",
              "        [ 3.9880e+01,  1.1781e+00,  1.0513e+00,  ...,  7.5233e-01,\n",
              "          7.8159e-01, -2.7768e+00]], dtype=torch.float64,\n",
              "       grad_fn=<ViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
    },
    {
      "cell_type": "code",
      "source": [
<<<<<<< HEAD
        "def calculate_shaped_variance(samples_IS, sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, samples_all_shaping, samples_IS_SCOPE):\n",
=======
        "samples_gamma_weight_states_last_sub_states_first"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYJ0CkAeUxYJ",
        "outputId": "044b3ccc-17f0-4043-a1d0-2517451e8944"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-8.6231e-01, -1.4442e+00, -1.2610e-01,  ..., -2.1841e-01,\n",
              "         -6.6780e-01, -5.2401e-01],\n",
              "        [-1.4953e+00, -1.0242e+00, -9.4766e-01,  ..., -1.8190e+00,\n",
              "         -4.9152e-01, -3.7517e-01],\n",
              "        [-3.7047e-01, -6.6903e-01, -1.1389e+00,  ..., -1.2655e+00,\n",
              "         -5.4174e-01, -1.4010e+00],\n",
              "        ...,\n",
              "        [-3.9031e-01, -8.3449e-02, -1.0242e+00,  ..., -2.0116e+00,\n",
              "         -1.7070e+00, -1.7322e+00],\n",
              "        [-1.2640e+00,  6.1336e+01, -7.4077e-01,  ..., -7.5364e-01,\n",
              "         -2.0116e+00, -9.2058e-01],\n",
              "        [-7.7774e-01, -1.2001e-01, -4.1986e-03,  ..., -1.0285e+00,\n",
              "         -5.7615e-01, -3.1064e-01]], dtype=torch.float64,\n",
              "       grad_fn=<ViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_shaped_variance(samples_IS, sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first):\n",
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
        "\n",
        "  # states_output, states_first_output, states_last_output = pass_states(model, padded_state_tensors, states_first_tensor, states_last_tensor)\n",
        "\n",
        "  # Begin calcs without clamping\n",
        "\n",
        "  # IS\n",
        "  E_IS_sq = torch.mean(torch.mean(samples_IS, dim = 1)**2)\n",
        "  E_IS_all_sq = torch.mean(torch.mean(samples_IS, dim = 1))**2\n",
        "\n",
        "  # states_weight_diff\n",
        "  E_s_wdiff_sq = torch.mean(torch.mean(sample_sums_states_weight_diff, dim =1)**2)\n",
        "  E_s_wdiff_all_sq = torch.mean(torch.mean(sample_sums_states_weight_diff, dim = 1))**2\n",
        "\n",
        "  # all terms\n",
<<<<<<< HEAD
        "  # SCOPE = sample_sums_states_weight_diff+samples_gamma_weight_states_last_sub_states_first\n",
        "  # E_IS_SCOPE = torch.mean(torch.mean(samples_IS, dim =1) * torch.mean(SCOPE, dim =1))\n",
        "  # E_IS_E_SCOPE = torch.mean(torch.mean(samples_IS,dim = 1 ))*torch.mean(torch.mean(SCOPE, dim =1))\n",
        "\n",
        "  E_IS_SCOPE = torch.mean(torch.mean(samples_IS_SCOPE, dim =1))\n",
        "  E_IS_E_SCOPE = torch.mean(torch.mean(samples_IS,dim = 1 )) * torch.mean(torch.mean(samples_all_shaping, dim =1))\n",
        "\n",
        "\n",
        "\n",
        "  # SCOPE_variance = E_IS_sq + 2*E_IS_SCOPE + E_s_wdiff_sq - E_IS_all_sq - 2*E_IS_E_SCOPE - E_IS_E_SCOPE\n",
        "  SCOPE_variance = E_IS_sq + 2*E_IS_SCOPE + E_s_wdiff_sq - E_IS_all_sq - 2*E_IS_E_SCOPE - E_s_wdiff_all_sq\n",
=======
        "  SCOPE = sample_sums_states_weight_diff-samples_gamma_weight_states_last_sub_states_first\n",
        "  E_IS_SCOPE = torch.mean(torch.mean(samples_IS, dim =1) * torch.mean(SCOPE, dim =1))\n",
        "  E_IS_E_SCOPE = torch.mean(torch.mean(samples_IS,dim = 1 ))*torch.mean(torch.mean(SCOPE, dim =1))\n",
        "\n",
        "  SCOPE_variance = E_IS_sq + 2*E_IS_SCOPE + E_s_wdiff_sq - E_IS_all_sq - 2*E_IS_E_SCOPE - E_IS_E_SCOPE\n",
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
        "\n",
        "  IS_variance = E_IS_sq - E_IS_all_sq\n",
        "\n",
        "  return E_IS_sq, E_IS_all_sq, E_s_wdiff_sq, E_s_wdiff_all_sq, E_IS_SCOPE, E_IS_E_SCOPE, IS_variance, SCOPE_variance\n"
      ],
      "metadata": {
        "id": "WlDazbYPvvrg"
      },
<<<<<<< HEAD
      "execution_count": null,
=======
      "execution_count": 52,
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
<<<<<<< HEAD
        "SCOPE = sample_sums_states_weight_diff-samples_gamma_weight_states_last_sub_states_first\n"
      ],
      "metadata": {
        "id": "ut3fyQ4s1l-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_,_,_,_,_,_,IS_variance, SCOPE_variance = calculate_shaped_variance(samples_IS, sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, samples_all_shaping, samples_IS_SCOPE)"
=======
        "IS_variance, SCOPE_variance = calculate_shaped_variance(samples_IS, sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first)"
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
      ],
      "metadata": {
        "id": "yWcJ_iSFvvru"
      },
<<<<<<< HEAD
      "execution_count": null,
=======
      "execution_count": 40,
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
<<<<<<< HEAD
        "print(f'IS Variance: {IS_variance.item()} SCOPE Variance: {SCOPE_variance.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ecraXkwWRcI",
        "outputId": "0b7a14e9-64a6-4c20-98a0-f958228fad62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IS Variance: 2.514807940970177e+22 SCOPE Variance: 5.892057226414652e+25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
=======
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
        "SCOPE_variance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
<<<<<<< HEAD
        "id": "iJtda6na7iFY",
        "outputId": "ce79b72f-e4fc-4ab7-c2b7-6e09fb2db4ed"
      },
      "execution_count": null,
=======
        "outputId": "cea9b01a-1ec1-4bde-8b20-afebdf00663f",
        "id": "aGXswiRNvvrv"
      },
      "execution_count": 41,
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
<<<<<<< HEAD
              "tensor([2.0262e+82, 1.7582e+80, 2.0262e+82,  ..., 4.0349e+82, 6.0435e+82,\n",
              "        1.7582e+80], dtype=torch.float64, grad_fn=<SubBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 32
=======
              "tensor(-5.4124e+77, dtype=torch.float64, grad_fn=<SubBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 41
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
        }
      ]
    },
    {
<<<<<<< HEAD
=======
      "cell_type": "code",
      "source": [
        "IS_variance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8003fb8a-aaf4-4f39-889d-5deabb9a4745",
        "id": "7Id4_3YPvvrv"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.0786e+78, dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1V2lMOPkxpDN"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
      "cell_type": "markdown",
      "source": [
        "# Optimizing"
      ],
      "metadata": {
        "id": "InzaU1hEzXaK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "wEeNxHjkz9Gx"
      },
<<<<<<< HEAD
      "execution_count": null,
=======
      "execution_count": 28,
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
<<<<<<< HEAD
        "def train_var(model, num_epochs, learning_rate, samples_IS, padded_state_tensors, states_first_tensor, states_last_tensor, samples_all_shaping, samples_IS_SCOPE, test1):\n",
=======
        "def train_var(model, num_epochs, learning_rate, samples_IS, padded_state_tensors, states_first_tensor, states_last_tensor, test1):\n",
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
        "    model.train()\n",
        "\n",
        "    # Enable anomaly detection\n",
        "    torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "\n",
        "        # Forward pass\n",
        "        states_output, states_first_output, states_last_output = test1.pass_states(model, padded_state_tensors, states_first_tensor, states_last_tensor)\n",
        "        sums_states_weight_diff = test1.states_weight_diff_sums(states_output, padded_weight_diff_tensors)\n",
        "        gamma_weights_states_last_sub_states_first = test1.last_first_terms_operations(gamma_weights_last_tensor, states_last_output, states_first_output)\n",
<<<<<<< HEAD
        "        # sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, samples_all_shaping, samples_IS_SCOPE = test1.bootstrap_shaping_terms(sums_states_weight_diff, gamma_weights_states_last_sub_states_first, IS_tensor)\n",
        "\n",
        "        samples_IS, sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, samples_all_shaping, samples_IS_SCOPE = test1.bootstrap_all_terms(sums_states_weight_diff, gamma_weights_states_last_sub_states_first, IS_tensor)\n",
        "\n",
        "\n",
        "        E_IS_sq, E_IS_all_sq, E_s_wdiff_sq, E_s_wdiff_all_sq, E_IS_SCOPE, E_IS_E_SCOPE, _, variance_loss = calculate_shaped_variance(samples_IS, sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, samples_all_shaping, samples_IS_SCOPE)\n",
=======
        "        sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first = test1.bootstrap_shaping_terms(sums_states_weight_diff, gamma_weights_states_last_sub_states_first)\n",
        "\n",
        "        E_IS_sq, E_IS_all_sq, E_s_wdiff_sq, E_s_wdiff_all_sq, E_IS_SCOPE, E_IS_E_SCOPE, _, variance_loss = calculate_shaped_variance(samples_IS, sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first)\n",
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
        "\n",
        "        print(f\"Epoch {epoch+1}\")\n",
        "        print(\"Var loss: \", variance_loss)\n",
        "\n",
        "        # Print each term\n",
        "        print(f\"E_IS_sq: {E_IS_sq}\")\n",
        "        print(f\"E_IS_all_sq: {E_IS_all_sq}\")\n",
        "        print(f\"E_s_wdiff_sq: {E_s_wdiff_sq}\")\n",
        "        print(f\"E_s_wdiff_all_sq: {E_s_wdiff_all_sq}\")\n",
        "        print(f\"E_IS_SCOPE: {E_IS_SCOPE}\")\n",
        "        print(f\"E_IS_E_SCOPE: {E_IS_E_SCOPE}\")\n",
        "\n",
        "        tot = variance_loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Retain the graph to avoid clearing it before backward pass\n",
        "        tot.backward(retain_graph=True)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += tot.item()\n",
        "\n",
        "        print(f\"Total Loss: {total_loss}\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "    # Disable anomaly detection after running the code\n",
        "    torch.autograd.set_detect_anomaly(False)\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            print(f\"Parameter name: {name}\")\n",
        "            print(f\"Weights: {param.data}\")\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "lEfGUHfGNwiJ"
      },
<<<<<<< HEAD
      "execution_count": null,
=======
      "execution_count": 46,
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
<<<<<<< HEAD
        "model2 = train_var(model, 20, 0.0001, samples_IS, padded_state_tensors, states_first_tensor, states_last_tensor, samples_all_shaping, samples_IS_SCOPE, test1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0zmGSWkVyC_",
        "outputId": "18597fc2-7ea7-4000-98c0-75ccad13417b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Var loss:  tensor(-3.0838e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 5.210967549166126e+22\n",
            "E_s_wdiff_all_sq: 2.5172984363039316e+22\n",
            "E_IS_SCOPE: -1.5459488896936224e+25\n",
            "E_IS_E_SCOPE: -1.4417566494849713e+22\n",
            "Total Loss: -3.0838057890344423e+25\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "Var loss:  tensor(-3.3585e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 6.546944000346388e+22\n",
            "E_s_wdiff_all_sq: 3.517525168586692e+22\n",
            "E_IS_SCOPE: -1.6839284068856547e+25\n",
            "E_IS_E_SCOPE: -1.8983210591791954e+22\n",
            "Total Loss: -3.358515944880221e+25\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "Var loss:  tensor(-3.6329e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 8.127328468140865e+22\n",
            "E_s_wdiff_all_sq: 4.669789629828819e+22\n",
            "E_IS_SCOPE: -1.8217910544502339e+25\n",
            "E_IS_E_SCOPE: -2.3493888489215494e+22\n",
            "Total Loss: -3.632910984423342e+25\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "Var loss:  tensor(-3.9072e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 9.956227907220597e+22\n",
            "E_s_wdiff_all_sq: 5.9793486972912325e+22\n",
            "E_IS_SCOPE: -1.959656202176037e+25\n",
            "E_IS_E_SCOPE: -2.7986036228854552e+22\n",
            "Total Loss: -3.907223509955403e+25\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "Var loss:  tensor(-4.1814e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2030804144930232e+23\n",
            "E_s_wdiff_all_sq: 7.444645256087994e+22\n",
            "E_IS_SCOPE: -2.0974953048619344e+25\n",
            "E_IS_E_SCOPE: -3.2460902003401042e+22\n",
            "Total Loss: -4.1813974624933755e+25\n",
            "----------------------------------------\n",
            "Epoch 6\n",
            "Var loss:  tensor(-4.4554e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.4346387559415976e+23\n",
            "E_s_wdiff_all_sq: 9.062655780558345e+22\n",
            "E_IS_SCOPE: -2.235296219189662e+25\n",
            "E_IS_E_SCOPE: -3.6915356807178387e+22\n",
            "Total Loss: -4.4554108272980605e+25\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "Var loss:  tensor(-4.7293e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.6896450448835388e+23\n",
            "E_s_wdiff_all_sq: 1.08290772380101e+23\n",
            "E_IS_SCOPE: -2.3730518621395594e+25\n",
            "E_IS_E_SCOPE: -4.134422009246762e+22\n",
            "Total Loss: -4.72925269910883e+25\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "Var loss:  tensor(-5.0029e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.9673881915757514e+23\n",
            "E_s_wdiff_all_sq: 1.2739332729182658e+23\n",
            "E_IS_SCOPE: -2.5107576940337e+25\n",
            "E_IS_E_SCOPE: -4.574329549359406e+22\n",
            "Total Loss: -5.0029173718411355e+25\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "Var loss:  tensor(-5.2764e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 2.267249722521212e+23\n",
            "E_s_wdiff_all_sq: 1.4789613654870718e+23\n",
            "E_IS_SCOPE: -2.6484105436396702e+25\n",
            "E_IS_E_SCOPE: -5.011115472982626e+22\n",
            "Total Loss: -5.276401164822063e+25\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "Var loss:  tensor(-5.5497e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 2.5887526111029046e+23\n",
            "E_s_wdiff_all_sq: 1.6977134979120384e+23\n",
            "E_IS_SCOPE: -2.786008235633142e+25\n",
            "E_IS_E_SCOPE: -5.444868998604533e+22\n",
            "Total Loss: -5.549701534196196e+25\n",
            "----------------------------------------\n",
            "Epoch 11\n",
            "Var loss:  tensor(-5.8228e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 2.93150580846501e+23\n",
            "E_s_wdiff_all_sq: 1.9299681728485064e+23\n",
            "E_IS_SCOPE: -2.9235491360209344e+25\n",
            "E_IS_E_SCOPE: -5.875756424517042e+22\n",
            "Total Loss: -5.822816574895699e+25\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "Var loss:  tensor(-6.0957e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 3.2951384287536245e+23\n",
            "E_s_wdiff_all_sq: 2.1755135214562837e+23\n",
            "E_IS_SCOPE: -3.061031877917925e+25\n",
            "E_IS_E_SCOPE: -6.303918086962085e+22\n",
            "Total Loss: -6.095744862647982e+25\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "Var loss:  tensor(-6.3685e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 3.67926590345648e+23\n",
            "E_s_wdiff_all_sq: 2.434124883277089e+23\n",
            "E_IS_SCOPE: -3.1984552495154813e+25\n",
            "E_IS_E_SCOPE: -6.729439799700456e+22\n",
            "Total Loss: -6.368485401288798e+25\n",
            "----------------------------------------\n",
            "Epoch 14\n",
            "Var loss:  tensor(-6.6411e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 4.083511343418876e+23\n",
            "E_s_wdiff_all_sq: 2.7055798170633747e+23\n",
            "E_IS_SCOPE: -3.3358493269605055e+25\n",
            "E_IS_E_SCOPE: -7.152390355712248e+22\n",
            "Total Loss: -6.641099750005061e+25\n",
            "----------------------------------------\n",
            "Epoch 15\n",
            "Var loss:  tensor(-6.9135e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 4.507797613123608e+23\n",
            "E_s_wdiff_all_sq: 2.9898588786408246e+23\n",
            "E_IS_SCOPE: -3.47318020008451e+25\n",
            "E_IS_E_SCOPE: -7.573118707256295e+22\n",
            "Total Loss: -6.91351996746871e+25\n",
            "----------------------------------------\n",
            "Epoch 16\n",
            "Var loss:  tensor(-7.1858e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 4.9525968530722806e+23\n",
            "E_s_wdiff_all_sq: 3.287304205334282e+23\n",
            "E_IS_SCOPE: -3.6104516466931023e+25\n",
            "E_IS_E_SCOPE: -7.992410040288414e+22\n",
            "Total Loss: -7.185750738887278e+25\n",
            "----------------------------------------\n",
            "Epoch 17\n",
            "Var loss:  tensor(-7.4578e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 5.422597581911685e+23\n",
            "E_s_wdiff_all_sq: 3.6010637596031907e+23\n",
            "E_IS_SCOPE: -3.7476645794703584e+25\n",
            "E_IS_E_SCOPE: -8.414638867962763e+22\n",
            "Total Loss: -7.457769735040736e+25\n",
            "----------------------------------------\n",
            "Epoch 18\n",
            "Var loss:  tensor(-7.7296e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 5.912088932901162e+23\n",
            "E_s_wdiff_all_sq: 3.9273065020191513e+23\n",
            "E_IS_SCOPE: -3.884814950188801e+25\n",
            "E_IS_E_SCOPE: -8.834554946761315e+22\n",
            "Total Loss: -7.7295981582342884e+25\n",
            "----------------------------------------\n",
            "Epoch 19\n",
            "Var loss:  tensor(-8.0012e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 6.420042041666823e+23\n",
            "E_s_wdiff_all_sq: 4.2653734809269504e+23\n",
            "E_IS_SCOPE: -4.021901783374139e+25\n",
            "E_IS_E_SCOPE: -9.251635569965136e+22\n",
            "Total Loss: -8.001238802059979e+25\n",
            "----------------------------------------\n",
            "Epoch 20\n",
            "Var loss:  tensor(-8.2727e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 6.945934268931316e+23\n",
            "E_s_wdiff_all_sq: 4.614945900147421e+23\n",
            "E_IS_SCOPE: -4.158924544997166e+25\n",
            "E_IS_E_SCOPE: -9.665836613397322e+22\n",
            "Total Loss: -8.272692725138728e+25\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[-0.4510,  0.0021],\n",
            "        [ 0.3396,  0.6556],\n",
            "        [-0.0427,  0.1722],\n",
            "        [-0.1050, -0.3208],\n",
            "        [ 0.6667,  0.6256],\n",
            "        [ 0.0633, -0.0869],\n",
            "        [-0.5012,  0.5401],\n",
            "        [-0.2295, -0.6730],\n",
            "        [-0.2369, -0.6463],\n",
            "        [-0.3752, -0.3359],\n",
            "        [-0.6697,  0.5156],\n",
            "        [-0.2812,  0.2000],\n",
            "        [-0.1604,  0.5577],\n",
            "        [-0.5985, -0.1328],\n",
            "        [-0.4052, -0.3473],\n",
            "        [-0.2117,  0.0203]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([-0.5800,  0.0521,  0.6555,  0.4989, -0.2725,  0.2633, -0.4585,  0.6680,\n",
            "         0.4422,  0.6497,  0.6227,  0.4099, -0.5805,  0.7856,  0.5691,  0.2211],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[ 1.7559e-01,  1.6233e-01,  2.3772e-01,  2.2629e-01,  1.8467e-01,\n",
            "          3.0120e-01, -2.3406e-01, -1.8666e-01,  7.2061e-02,  2.3042e-01,\n",
            "         -3.1664e-02, -1.7317e-01, -5.9300e-02,  2.1983e-01, -2.3025e-01,\n",
            "         -2.5168e-01],\n",
            "        [ 7.1529e-03,  2.4635e-01, -1.0106e-01, -1.2429e-01, -1.5923e-01,\n",
            "         -1.8235e-02,  1.4430e-02, -1.5267e-01,  1.9970e-01, -2.2146e-02,\n",
            "         -2.2856e-01, -1.7931e-01,  1.9001e-01,  2.4006e-02,  2.1272e-01,\n",
            "          9.1185e-02],\n",
            "        [-6.1545e-02, -1.6846e-01, -1.9149e-01,  9.8640e-02, -2.1220e-01,\n",
            "          1.1819e-01,  9.9572e-02, -1.0969e-01,  1.8555e-01,  2.3056e-01,\n",
            "         -7.3723e-02, -6.4354e-02,  1.8917e-01,  1.4870e-01, -1.2193e-01,\n",
            "          1.9635e-01],\n",
            "        [ 1.9140e-01,  5.9702e-02,  2.0254e-01, -5.3336e-02, -1.2643e-01,\n",
            "          1.1372e-01, -2.2702e-01, -1.5411e-01,  1.7170e-01, -1.0972e-01,\n",
            "         -6.0289e-02,  1.4019e-01, -1.7271e-01,  3.9220e-01, -8.3202e-02,\n",
            "         -1.3331e-01],\n",
            "        [-2.2063e-01, -2.3476e-01, -2.0329e-01,  1.1068e-02,  2.1729e-01,\n",
            "         -2.8234e-01,  8.6570e-02, -9.5660e-02, -1.9528e-01,  8.0604e-02,\n",
            "          7.2492e-02, -1.7119e-01, -1.3159e-01,  9.6841e-02,  1.2702e-01,\n",
            "         -2.1615e-01],\n",
            "        [-1.5366e-01,  1.9952e-01, -3.9314e-02, -1.4778e-01, -1.5110e-01,\n",
            "          8.4972e-02, -2.8361e-01,  6.8140e-02, -1.6945e-01,  2.4092e-02,\n",
            "         -1.8115e-01, -2.7334e-02, -3.8245e-02,  7.6595e-02, -6.4935e-02,\n",
            "          2.7648e-01],\n",
            "        [ 7.1929e-03, -8.6183e-02,  1.9110e-01,  1.1232e-01,  1.7308e-01,\n",
            "         -5.8804e-02, -2.2953e-01, -2.3573e-02, -2.7324e-02,  1.1141e-01,\n",
            "         -2.1644e-01,  2.0180e-01,  1.1418e-02, -1.7533e-01,  1.6569e-01,\n",
            "          1.9179e-01],\n",
            "        [ 3.6563e-02,  2.7998e-02,  2.6304e-01, -1.8567e-01,  1.8540e-01,\n",
            "         -1.3270e-01,  7.6032e-02, -2.9636e-02, -2.1079e-04, -1.0609e-01,\n",
            "          2.2287e-01, -2.2479e-01,  1.1056e-01, -2.3385e-01, -1.6760e-01,\n",
            "          9.9343e-02],\n",
            "        [ 1.7877e-01, -1.1848e-01,  2.7068e-02,  9.9388e-02,  2.4131e-01,\n",
            "         -1.5313e-01,  2.0315e-01, -1.8985e-01, -1.1247e-01, -1.1768e-02,\n",
            "         -2.8191e-02, -7.7164e-02,  1.1229e-01, -2.7218e-01, -9.0932e-02,\n",
            "         -1.9059e-01],\n",
            "        [ 1.5427e-01, -1.1397e-01,  2.4423e-01,  6.1690e-02, -2.4008e-03,\n",
            "          5.1089e-02,  1.0899e-01,  1.0263e-01, -1.7723e-02,  7.6825e-02,\n",
            "          4.6833e-02,  1.8567e-01,  6.8519e-03, -5.1221e-02,  7.3215e-02,\n",
            "          2.1663e-02],\n",
            "        [ 3.0704e-02,  1.6847e-01,  1.9887e-01, -1.9659e-01,  1.6256e-03,\n",
            "          2.7731e-01, -4.4841e-02, -1.0408e-01, -2.2601e-01, -1.8564e-01,\n",
            "          1.8752e-01, -1.7683e-01, -1.8726e-01,  1.9871e-01, -3.5240e-02,\n",
            "         -1.3091e-01],\n",
            "        [ 3.1929e-02,  3.2215e-02,  1.5373e-01, -2.2811e-01, -5.2812e-02,\n",
            "          1.1565e-01, -1.0283e-01,  1.9907e-01,  3.4308e-02, -1.2375e-01,\n",
            "          1.0030e-01,  7.0572e-02, -7.3479e-02, -5.4203e-02, -4.8761e-02,\n",
            "         -1.7009e-01],\n",
            "        [ 1.8268e-01, -3.1818e-02, -2.7465e-01,  2.0304e-01, -2.5103e-01,\n",
            "          1.3380e-01,  5.7078e-02, -1.6024e-01,  2.3616e-01,  1.3602e-01,\n",
            "          1.8643e-01, -1.7847e-01, -1.6410e-01,  2.1505e-01, -1.4369e-01,\n",
            "         -4.8390e-02],\n",
            "        [-1.3087e-01,  1.1866e-01,  3.6743e-02, -1.4394e-01, -1.1981e-01,\n",
            "         -7.0510e-02,  8.3873e-03,  1.4202e-01,  5.7004e-02,  2.4725e-01,\n",
            "          1.7666e-02, -2.3482e-01, -2.2211e-01,  2.0162e-01,  8.6532e-02,\n",
            "          7.8177e-02],\n",
            "        [-1.4544e-01, -3.7057e-01,  3.0520e-01, -7.4018e-02, -3.4248e-02,\n",
            "         -3.6749e-02, -5.1584e-02, -1.4300e-01,  7.9773e-02, -1.7701e-01,\n",
            "          2.3044e-01, -4.2904e-01, -1.0584e-01, -1.3126e-01,  1.9303e-02,\n",
            "          2.8921e-01],\n",
            "        [-2.4521e-01,  2.4946e-01, -3.0612e-01,  4.3380e-02, -1.0360e-02,\n",
            "          4.2349e-02,  7.6393e-02, -1.4996e-01,  2.6837e-02, -1.2947e-01,\n",
            "         -6.0119e-02, -1.2891e-01, -2.9666e-01,  7.5903e-03,  1.1003e-01,\n",
            "         -1.3607e-01],\n",
            "        [-2.3086e-01,  1.2024e-01, -1.7377e-01,  1.9102e-01, -1.4026e-01,\n",
            "         -2.1704e-01,  2.3345e-01,  1.8437e-01, -3.6461e-02, -2.4583e-01,\n",
            "         -4.0944e-01, -3.2514e-01, -3.4505e-01,  2.2425e-01,  2.4350e-03,\n",
            "          2.9624e-01],\n",
            "        [ 1.7996e-01,  6.2290e-03,  4.7523e-02,  1.1118e-02,  1.6657e-01,\n",
            "         -9.6748e-03,  1.1051e-01, -2.2243e-01,  7.2220e-02, -1.1556e-01,\n",
            "          3.8988e-02, -2.0665e-01,  5.8580e-02,  1.9515e-01, -1.9692e-01,\n",
            "         -1.6146e-01],\n",
            "        [-2.4386e-01, -1.9133e-01,  3.3801e-02, -2.1412e-01,  1.1644e-01,\n",
            "         -3.6942e-01, -1.6242e-01, -1.4523e-01,  1.8902e-01,  8.2447e-02,\n",
            "         -4.7722e-01,  5.2936e-02, -9.7944e-02,  9.3941e-02,  5.6936e-02,\n",
            "         -2.5046e-01],\n",
            "        [-2.1121e-02, -3.0001e-01, -4.9378e-02,  1.1902e-01,  7.8042e-02,\n",
            "          3.1770e-01,  3.9925e-02,  2.2312e-01,  5.2246e-02,  9.3138e-02,\n",
            "          1.1217e-01,  5.3098e-02,  2.2271e-01,  3.9138e-01,  5.3523e-02,\n",
            "         -1.2653e-01],\n",
            "        [ 1.9650e-01, -1.4172e-01,  2.8714e-02, -2.9400e-02,  2.3476e-01,\n",
            "          2.9832e-01,  1.4017e-01,  2.4546e-01,  9.2309e-03,  1.0585e-01,\n",
            "         -1.4108e-01, -1.6467e-01, -2.5441e-01,  1.3023e-01,  5.3941e-02,\n",
            "          3.4543e-02],\n",
            "        [ 6.2436e-02, -8.1427e-02,  6.8004e-03, -2.4202e-01, -6.0287e-02,\n",
            "         -1.4947e-01,  1.9532e-01, -2.4530e-01, -2.7072e-02,  1.3022e-01,\n",
            "          3.4743e-01,  1.9774e-01,  5.8964e-02, -4.1659e-02,  1.8627e-01,\n",
            "         -1.6851e-01],\n",
            "        [-2.3660e-01,  1.4217e-01, -2.7298e-01, -2.3568e-01,  1.8135e-01,\n",
            "         -9.9376e-02, -2.1404e-01, -7.8582e-02, -7.0298e-02, -1.0721e-02,\n",
            "          1.1153e-01,  1.2434e-01,  1.4717e-01,  1.4747e-01,  1.7566e-01,\n",
            "          1.6961e-01],\n",
            "        [-2.1504e-01, -5.6804e-02,  1.2303e-01, -1.2970e-01, -9.0758e-04,\n",
            "          9.0054e-02, -1.4854e-01, -5.5772e-03, -3.3620e-02, -1.3572e-01,\n",
            "         -1.2283e-01, -3.5842e-02,  2.0300e-01,  1.7445e-01,  1.9926e-01,\n",
            "          1.4480e-02],\n",
            "        [-1.8815e-02, -8.8772e-02,  1.6216e-01,  3.7306e-02,  1.0765e-01,\n",
            "         -2.1936e-02,  1.8456e-01,  1.4760e-01, -7.9331e-02,  1.5561e-01,\n",
            "          2.0303e-01, -1.4509e-01, -8.1366e-02, -3.1612e-01,  5.6964e-02,\n",
            "         -1.7146e-01],\n",
            "        [ 2.7233e-04,  2.0508e-01,  2.3661e-01,  3.0674e-02,  1.2631e-01,\n",
            "          7.2449e-02, -2.0767e-01,  6.0481e-02,  5.9943e-02,  1.2595e-01,\n",
            "         -1.5610e-01, -1.2661e-01,  2.0987e-01, -2.9389e-01, -2.3863e-01,\n",
            "          1.8265e-01],\n",
            "        [-2.3910e-01,  2.7046e-01,  1.7394e-01,  1.4304e-01,  2.2724e-01,\n",
            "          1.5284e-01,  6.0089e-02, -2.4203e-02,  1.4016e-01,  1.2150e-01,\n",
            "          1.1739e-01,  4.5788e-02, -2.4074e-01,  7.2400e-02, -1.8276e-01,\n",
            "         -1.9739e-01],\n",
            "        [ 3.0014e-02,  8.0140e-03, -3.5501e-02,  1.3929e-01, -2.8273e-01,\n",
            "         -8.2736e-02, -2.0914e-01, -1.9566e-01,  1.4068e-01, -2.0598e-01,\n",
            "          1.6162e-01,  1.1231e-01,  1.1277e-01, -6.3876e-02, -5.7794e-02,\n",
            "         -4.4601e-02],\n",
            "        [-6.8022e-02,  1.2553e-01, -7.4896e-02,  5.8154e-02,  1.5711e-01,\n",
            "         -2.2227e-01,  1.3049e-01, -1.2746e-01, -2.7043e-02, -7.6503e-03,\n",
            "          2.5763e-02,  7.0767e-02, -5.9477e-03, -4.2300e-01, -9.2563e-02,\n",
            "          1.0574e-01],\n",
            "        [ 2.4462e-01, -4.4803e-02,  6.5335e-02,  2.1805e-01,  2.5980e-01,\n",
            "          1.4863e-02,  1.3684e-01,  1.9241e-01, -1.3083e-01,  1.8042e-01,\n",
            "         -9.6065e-02,  1.9216e-01,  1.2768e-01, -3.9125e-02,  8.0967e-02,\n",
            "          6.9863e-02],\n",
            "        [-2.0339e-01, -1.3332e-01,  1.2844e-02, -2.4017e-01,  1.1610e-01,\n",
            "         -1.6190e-01, -5.8829e-02,  1.3671e-01, -6.2188e-02,  1.3888e-01,\n",
            "          1.7607e-01,  1.4970e-01,  6.7824e-02,  7.6705e-02,  7.5816e-02,\n",
            "         -1.3883e-01],\n",
            "        [-8.8667e-02, -9.7587e-02,  7.9214e-02, -1.6263e-01, -3.5249e-02,\n",
            "          5.5645e-02, -2.3595e-02,  7.8961e-02, -1.2570e-01,  2.1665e-01,\n",
            "          2.7871e-02,  1.2805e-01,  4.8840e-02,  7.5699e-02, -1.5474e-01,\n",
            "         -1.3606e-01]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([ 0.0152, -0.0980,  0.0864,  0.0689,  0.2498, -0.0135,  0.1991,  0.1723,\n",
            "         0.1992, -0.0625,  0.1075, -0.0684,  0.2318, -0.0104, -0.2247, -0.0120,\n",
            "        -0.1201,  0.2344,  0.0327,  0.0824,  0.2338,  0.0025, -0.0555, -0.2357,\n",
            "         0.0321, -0.2639,  0.1652,  0.0119,  0.0660,  0.0135, -0.1878, -0.2406],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[ 0.0168,  0.1780,  0.1248,  0.0681, -0.1202, -0.0241,  0.1450, -0.0256,\n",
            "         -0.0325, -0.1131,  0.1277, -0.0804,  0.0521,  0.0330,  0.1509,  0.0562,\n",
            "         -0.1326,  0.0699, -0.1098,  0.1518,  0.1084, -0.3186,  0.1366, -0.1010,\n",
            "         -0.0525, -0.0417,  0.0804, -0.0123, -0.1114, -0.0858, -0.1678,  0.1389]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([-0.0005], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model5 = train_var(model4, 500, 0.0001, samples_IS, padded_state_tensors, states_first_tensor, states_last_tensor, samples_all_shaping, samples_IS_SCOPE, test1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "K7RunrrFPEy7",
        "outputId": "fa9e6784-1b9a-4a4f-be7b-e7e99b2b6a1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Var loss:  tensor(1.6838e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2080531216272573e+22\n",
            "E_s_wdiff_all_sq: 7.854446300022197e+18\n",
            "E_IS_SCOPE: -3.2924307594909997e+22\n",
            "E_IS_E_SCOPE: -1.0101281026055919e+22\n",
            "Total Loss: 1.683838514322106e+21\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "Var loss:  tensor(2.4018e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.5681370975049804e+22\n",
            "E_s_wdiff_all_sq: 5.3651102132735515e+20\n",
            "E_IS_SCOPE: -2.958920317364135e+22\n",
            "E_IS_E_SCOPE: -6.916923741107582e+21\n",
            "Total Loss: 2.401815260791626e+21\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "Var loss:  tensor(2.3126e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.060980670643068e+22\n",
            "E_s_wdiff_all_sq: 2.9444178650483524e+20\n",
            "E_IS_SCOPE: -3.670629845441955e+22\n",
            "E_IS_E_SCOPE: -1.3322424158069409e+22\n",
            "Total Loss: 2.3125616815015744e+21\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "Var loss:  tensor(2.2341e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.0633852358230838e+22\n",
            "E_s_wdiff_all_sq: 2.5690002961311597e+20\n",
            "E_IS_SCOPE: -3.649677342924772e+22\n",
            "E_IS_E_SCOPE: -1.3148560016495734e+22\n",
            "Total Loss: 2.2340649589243705e+21\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "Var loss:  tensor(1.6178e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2198354392569919e+22\n",
            "E_s_wdiff_all_sq: 3.652535509560464e+18\n",
            "E_IS_SCOPE: -3.332237717470749e+22\n",
            "E_IS_E_SCOPE: -1.0305375073970072e+22\n",
            "Total Loss: 1.6178046747669262e+21\n",
            "----------------------------------------\n",
            "Epoch 6\n",
            "Var loss:  tensor(2.0155e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.4497548452943698e+22\n",
            "E_s_wdiff_all_sq: 3.101753381008754e+20\n",
            "E_IS_SCOPE: -3.054246607770964e+22\n",
            "E_IS_E_SCOPE: -7.818279936741865e+21\n",
            "Total Loss: 2.0155355174517866e+21\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "Var loss:  tensor(2.0581e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.4616360950367095e+22\n",
            "E_s_wdiff_all_sq: 3.4398198073409634e+20\n",
            "E_IS_SCOPE: -3.036719256598841e+22\n",
            "E_IS_E_SCOPE: -7.676013074519667e+21\n",
            "Total Loss: 2.0580944516510541e+21\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "Var loss:  tensor(1.6603e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2939949932413746e+22\n",
            "E_s_wdiff_all_sq: 7.213751316865191e+19\n",
            "E_IS_SCOPE: -3.213132082516763e+22\n",
            "E_IS_E_SCOPE: -9.278309953212547e+21\n",
            "Total Loss: 1.6603175514178983e+21\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "Var loss:  tensor(1.6789e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.1369778160525388e+22\n",
            "E_s_wdiff_all_sq: 1.6735233495303238e+19\n",
            "E_IS_SCOPE: -3.4343132217582195e+22\n",
            "E_IS_E_SCOPE: -1.1282428200323708e+22\n",
            "Total Loss: 1.6788777360338956e+21\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "Var loss:  tensor(1.9160e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.0759040073523123e+22\n",
            "E_s_wdiff_all_sq: 1.146480960753118e+20\n",
            "E_IS_SCOPE: -3.550444204464186e+22\n",
            "E_IS_E_SCOPE: -1.2339266693254665e+22\n",
            "Total Loss: 1.9160354737051664e+21\n",
            "----------------------------------------\n",
            "Epoch 11\n",
            "Var loss:  tensor(1.7996e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.0934688991814363e+22\n",
            "E_s_wdiff_all_sq: 6.6358570149114085e+19\n",
            "E_IS_SCOPE: -3.5050020881405305e+22\n",
            "E_IS_E_SCOPE: -1.1938953376668441e+22\n",
            "Total Loss: 1.7995867687108477e+21\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "Var loss:  tensor(1.5873e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.177134347775273e+22\n",
            "E_s_wdiff_all_sq: 2.4829363686499043e+17\n",
            "E_IS_SCOPE: -3.352526279960078e+22\n",
            "E_IS_E_SCOPE: -1.057280545146834e+22\n",
            "Total Loss: 1.5873136426579615e+21\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "Var loss:  tensor(1.6518e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2952111814378758e+22\n",
            "E_s_wdiff_all_sq: 9.31244535538539e+19\n",
            "E_IS_SCOPE: -3.191352877889636e+22\n",
            "E_IS_E_SCOPE: -9.126238020662737e+21\n",
            "Total Loss: 1.6518477282760217e+21\n",
            "----------------------------------------\n",
            "Epoch 14\n",
            "Var loss:  tensor(1.7801e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.359938149685174e+22\n",
            "E_s_wdiff_all_sq: 1.9379745607524398e+20\n",
            "E_IS_SCOPE: -3.1165569678760726e+22\n",
            "E_IS_E_SCOPE: -8.454597465652572e+21\n",
            "Total Loss: 1.780113945989774e+21\n",
            "----------------------------------------\n",
            "Epoch 15\n",
            "Var loss:  tensor(1.6882e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.3203151331044018e+22\n",
            "E_s_wdiff_all_sq: 1.319710181949291e+20\n",
            "E_IS_SCOPE: -3.1602686497240834e+22\n",
            "E_IS_E_SCOPE: -8.847446901451736e+21\n",
            "Total Loss: 1.688198450619331e+21\n",
            "----------------------------------------\n",
            "Epoch 16\n",
            "Var loss:  tensor(1.5562e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2215919712213322e+22\n",
            "E_s_wdiff_all_sq: 2.0899687616620753e+19\n",
            "E_IS_SCOPE: -3.283190220996491e+22\n",
            "E_IS_E_SCOPE: -9.951990093450058e+21\n",
            "Total Loss: 1.5561649823354454e+21\n",
            "----------------------------------------\n",
            "Epoch 17\n",
            "Var loss:  tensor(1.6003e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.1377950739780977e+22\n",
            "E_s_wdiff_all_sq: 6.728656834605102e+18\n",
            "E_IS_SCOPE: -3.4107211151752986e+22\n",
            "E_IS_E_SCOPE: -1.1096232306045503e+22\n",
            "Total Loss: 1.6003047641132869e+21\n",
            "----------------------------------------\n",
            "Epoch 18\n",
            "Var loss:  tensor(1.6798e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.1052807949431192e+22\n",
            "E_s_wdiff_all_sq: 3.5202491836908536e+19\n",
            "E_IS_SCOPE: -3.471015741715299e+22\n",
            "E_IS_E_SCOPE: -1.163307656577775e+22\n",
            "Total Loss: 1.6798022221602352e+21\n",
            "----------------------------------------\n",
            "Epoch 19\n",
            "Var loss:  tensor(1.6168e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.1245231656492002e+22\n",
            "E_s_wdiff_all_sq: 1.5721640040077249e+19\n",
            "E_IS_SCOPE: -3.43792134152922e+22\n",
            "E_IS_E_SCOPE: -1.1327314441601773e+22\n",
            "Total Loss: 1.6168275604146917e+21\n",
            "----------------------------------------\n",
            "Epoch 20\n",
            "Var loss:  tensor(1.5268e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.186523423103466e+22\n",
            "E_s_wdiff_all_sq: 2.7415667138166825e+18\n",
            "E_IS_SCOPE: -3.3405647924408474e+22\n",
            "E_IS_E_SCOPE: -1.0441599899703955e+22\n",
            "Total Loss: 1.5268174910313474e+21\n",
            "----------------------------------------\n",
            "Epoch 21\n",
            "Var loss:  tensor(1.5536e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.263193783444266e+22\n",
            "E_s_wdiff_all_sq: 5.60570436459224e+19\n",
            "E_IS_SCOPE: -3.2396879704542404e+22\n",
            "E_IS_E_SCOPE: -9.522452985415874e+21\n",
            "Total Loss: 1.5536167913072424e+21\n",
            "----------------------------------------\n",
            "Epoch 22\n",
            "Var loss:  tensor(1.6038e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.3038238778747116e+22\n",
            "E_s_wdiff_all_sq: 1.038464977379727e+20\n",
            "E_IS_SCOPE: -3.1941390037369942e+22\n",
            "E_IS_E_SCOPE: -9.100087115917017e+21\n",
            "Total Loss: 1.603799461460053e+21\n",
            "----------------------------------------\n",
            "Epoch 23\n",
            "Var loss:  tensor(1.5579e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.280744616265086e+22\n",
            "E_s_wdiff_all_sq: 7.232327063685525e+19\n",
            "E_IS_SCOPE: -3.226097241733373e+22\n",
            "E_IS_E_SCOPE: -9.374780287438828e+21\n",
            "Total Loss: 1.5579216000016533e+21\n",
            "----------------------------------------\n",
            "Epoch 24\n",
            "Var loss:  tensor(1.4955e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2186054363945735e+22\n",
            "E_s_wdiff_all_sq: 1.4320783436180496e+19\n",
            "E_IS_SCOPE: -3.311621804425452e+22\n",
            "E_IS_E_SCOPE: -1.0131275611539864e+22\n",
            "Total Loss: 1.4955245197580546e+21\n",
            "----------------------------------------\n",
            "Epoch 25\n",
            "Var loss:  tensor(1.5135e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.1632689759298687e+22\n",
            "E_s_wdiff_all_sq: 1.084200194891547e+18\n",
            "E_IS_SCOPE: -3.399041051449923e+22\n",
            "E_IS_E_SCOPE: -1.0904521428491936e+22\n",
            "Total Loss: 1.5135124254778102e+21\n",
            "----------------------------------------\n",
            "Epoch 26\n",
            "Var loss:  tensor(1.5428e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.1424102425190768e+22\n",
            "E_s_wdiff_all_sq: 9.995917013511735e+18\n",
            "E_IS_SCOPE: -3.438730299143147e+22\n",
            "E_IS_E_SCOPE: -1.1248423262188292e+22\n",
            "Total Loss: 1.5428456385944727e+21\n",
            "----------------------------------------\n",
            "Epoch 27\n",
            "Var loss:  tensor(1.5052e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.1604771700615028e+22\n",
            "E_s_wdiff_all_sq: 2.497813187449078e+18\n",
            "E_IS_SCOPE: -3.41309817677249e+22\n",
            "E_IS_E_SCOPE: -1.10047754887802e+22\n",
            "Total Loss: 1.5052140412075927e+21\n",
            "----------------------------------------\n",
            "Epoch 28\n",
            "Var loss:  tensor(1.4629e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2080736777878213e+22\n",
            "E_s_wdiff_all_sq: 5.962303699342489e+18\n",
            "E_IS_SCOPE: -3.344352078594305e+22\n",
            "E_IS_E_SCOPE: -1.0373720528271083e+22\n",
            "Total Loss: 1.4629362005071322e+21\n",
            "----------------------------------------\n",
            "Epoch 29\n",
            "Var loss:  tensor(1.4770e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2592625258055936e+22\n",
            "E_s_wdiff_all_sq: 3.991967222209619e+19\n",
            "E_IS_SCOPE: -3.2780876560970264e+22\n",
            "E_IS_E_SCOPE: -9.766007546533942e+21\n",
            "Total Loss: 1.4769741854190055e+21\n",
            "----------------------------------------\n",
            "Epoch 30\n",
            "Var loss:  tensor(1.4901e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2793876705606977e+22\n",
            "E_s_wdiff_all_sq: 5.9502027677624975e+19\n",
            "E_IS_SCOPE: -3.2554403762262136e+22\n",
            "E_IS_E_SCOPE: -9.552317118832756e+21\n",
            "Total Loss: 1.490099947282744e+21\n",
            "----------------------------------------\n",
            "Epoch 31\n",
            "Var loss:  tensor(1.4566e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.255984103315449e+22\n",
            "E_s_wdiff_all_sq: 3.5746662274154856e+19\n",
            "E_IS_SCOPE: -3.2879345052357864e+22\n",
            "E_IS_E_SCOPE: -9.83578305695054e+21\n",
            "Total Loss: 1.4565795089921522e+21\n",
            "----------------------------------------\n",
            "Epoch 32\n",
            "Var loss:  tensor(1.4298e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.21067556028737e+22\n",
            "E_s_wdiff_all_sq: 5.902081057804411e+18\n",
            "E_IS_SCOPE: -3.3523765883237877e+22\n",
            "E_IS_E_SCOPE: -1.0407510391118763e+22\n",
            "Total Loss: 1.4298344194560062e+21\n",
            "----------------------------------------\n",
            "Epoch 33\n",
            "Var loss:  tensor(1.4413e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.175482671195341e+22\n",
            "E_s_wdiff_all_sq: 3.608061351989825e+17\n",
            "E_IS_SCOPE: -3.4076115135540777e+22\n",
            "E_IS_E_SCOPE: -1.0896870497663756e+22\n",
            "Total Loss: 1.4412873435648958e+21\n",
            "----------------------------------------\n",
            "Epoch 34\n",
            "Var loss:  tensor(1.4412e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.1683486231838048e+22\n",
            "E_s_wdiff_all_sq: 1.556677069839308e+18\n",
            "E_IS_SCOPE: -3.420723472477327e+22\n",
            "E_IS_E_SCOPE: -1.100803445272771e+22\n",
            "Total Loss: 1.4411995501764154e+21\n",
            "----------------------------------------\n",
            "Epoch 35\n",
            "Var loss:  tensor(1.4114e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.1899953007459526e+22\n",
            "E_s_wdiff_all_sq: 5.0133590337038566e+17\n",
            "E_IS_SCOPE: -3.3877475235530344e+22\n",
            "E_IS_E_SCOPE: -1.0706104847560193e+22\n",
            "Total Loss: 1.411396488781185e+21\n",
            "----------------------------------------\n",
            "Epoch 36\n",
            "Var loss:  tensor(1.3971e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2270487781157556e+22\n",
            "E_s_wdiff_all_sq: 1.452261542540968e+19\n",
            "E_IS_SCOPE: -3.334386714471336e+22\n",
            "E_IS_E_SCOPE: -1.0222092984288681e+22\n",
            "Total Loss: 1.3971118542986527e+21\n",
            "----------------------------------------\n",
            "Epoch 37\n",
            "Var loss:  tensor(1.4043e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.25455514272645e+22\n",
            "E_s_wdiff_all_sq: 3.5443729775789773e+19\n",
            "E_IS_SCOPE: -3.2980659698734673e+22\n",
            "E_IS_E_SCOPE: -9.890679039300559e+21\n",
            "Total Loss: 1.4043485573986008e+21\n",
            "----------------------------------------\n",
            "Epoch 38\n",
            "Var loss:  tensor(1.3937e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2523128111479212e+22\n",
            "E_s_wdiff_all_sq: 3.3737923484991574e+19\n",
            "E_IS_SCOPE: -3.302263786840805e+22\n",
            "E_IS_E_SCOPE: -9.92258909122313e+21\n",
            "Total Loss: 1.393699058034271e+21\n",
            "----------------------------------------\n",
            "Epoch 39\n",
            "Var loss:  tensor(1.3697e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2241589554837774e+22\n",
            "E_s_wdiff_all_sq: 1.3463824661238282e+19\n",
            "E_IS_SCOPE: -3.341677226186248e+22\n",
            "E_IS_E_SCOPE: -1.0271178566861467e+22\n",
            "Total Loss: 1.3696601413989884e+21\n",
            "----------------------------------------\n",
            "Epoch 40\n",
            "Var loss:  tensor(1.3640e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.1928459720067207e+22\n",
            "E_s_wdiff_all_sq: 1.2785224077778248e+18\n",
            "E_IS_SCOPE: -3.3881247263236477e+22\n",
            "E_IS_E_SCOPE: -1.0683328741037868e+22\n",
            "Total Loss: 1.3640308264096256e+21\n",
            "----------------------------------------\n",
            "Epoch 41\n",
            "Var loss:  tensor(1.3643e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.1786838981563338e+22\n",
            "E_s_wdiff_all_sq: 2550734243817073.0\n",
            "E_IS_SCOPE: -3.410544001229776e+22\n",
            "E_IS_E_SCOPE: -1.0880103563929582e+22\n",
            "Total Loss: 1.3643490584583356e+21\n",
            "----------------------------------------\n",
            "Epoch 42\n",
            "Var loss:  tensor(1.3475e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.1880218899585343e+22\n",
            "E_s_wdiff_all_sq: 6.887443066764826e+17\n",
            "E_IS_SCOPE: -3.3964912908349544e+22\n",
            "E_IS_E_SCOPE: -1.0749667745270736e+22\n",
            "Total Loss: 1.347475728400235e+21\n",
            "----------------------------------------\n",
            "Epoch 43\n",
            "Var loss:  tensor(1.3311e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2132323808601113e+22\n",
            "E_s_wdiff_all_sq: 9.0125476743935e+18\n",
            "E_IS_SCOPE: -3.3596038639327665e+22\n",
            "E_IS_E_SCOPE: -1.04142431226007e+22\n",
            "Total Loss: 1.3310553074496543e+21\n",
            "----------------------------------------\n",
            "Epoch 44\n",
            "Var loss:  tensor(1.3288e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2359518219820369e+22\n",
            "E_s_wdiff_all_sq: 2.355155912170939e+19\n",
            "E_IS_SCOPE: -3.3284183456581075e+22\n",
            "E_IS_E_SCOPE: -1.0129853799297874e+22\n",
            "Total Loss: 1.3287921142536088e+21\n",
            "----------------------------------------\n",
            "Epoch 45\n",
            "Var loss:  tensor(1.3210e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.238773829114204e+22\n",
            "E_s_wdiff_all_sq: 2.6027424365793227e+19\n",
            "E_IS_SCOPE: -3.325724543577118e+22\n",
            "E_IS_E_SCOPE: -1.0099905093363302e+22\n",
            "Total Loss: 1.3210421093913623e+21\n",
            "----------------------------------------\n",
            "Epoch 46\n",
            "Var loss:  tensor(1.3036e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2205940343263744e+22\n",
            "E_s_wdiff_all_sq: 1.3827445038710628e+19\n",
            "E_IS_SCOPE: -3.351893605020439e+22\n",
            "E_IS_E_SCOPE: -1.0329141024401517e+22\n",
            "Total Loss: 1.3035707257612906e+21\n",
            "----------------------------------------\n",
            "Epoch 47\n",
            "Var loss:  tensor(1.2943e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.1971769088341126e+22\n",
            "E_s_wdiff_all_sq: 3.3808223308120694e+18\n",
            "E_IS_SCOPE: -3.3868683983787127e+22\n",
            "E_IS_E_SCOPE: -1.0637275207129033e+22\n",
            "Total Loss: 1.2943061518557412e+21\n",
            "----------------------------------------\n",
            "Epoch 48\n",
            "Var loss:  tensor(1.2897e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.1854936498453332e+22\n",
            "E_s_wdiff_all_sq: 7.516945630442011e+17\n",
            "E_IS_SCOPE: -3.405854906542557e+22\n",
            "E_IS_E_SCOPE: -1.080127225483636e+22\n",
            "Total Loss: 1.289734541813041e+21\n",
            "----------------------------------------\n",
            "Epoch 49\n",
            "Var loss:  tensor(1.2763e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.1921079734718163e+22\n",
            "E_s_wdiff_all_sq: 2.076841512173565e+18\n",
            "E_IS_SCOPE: -3.397632371078965e+22\n",
            "E_IS_E_SCOPE: -1.071993393085295e+22\n",
            "Total Loss: 1.2763135153994832e+21\n",
            "----------------------------------------\n",
            "Epoch 50\n",
            "Var loss:  tensor(1.2627e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2110884012131495e+22\n",
            "E_s_wdiff_all_sq: 9.069685530858882e+18\n",
            "E_IS_SCOPE: -3.3718835790941866e+22\n",
            "E_IS_E_SCOPE: -1.0480477852306265e+22\n",
            "Total Loss: 1.2627253968683265e+21\n",
            "----------------------------------------\n",
            "Epoch 51\n",
            "Var loss:  tensor(1.2564e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2278191404034225e+22\n",
            "E_s_wdiff_all_sq: 1.8685241388524634e+19\n",
            "E_IS_SCOPE: -3.350828240418175e+22\n",
            "E_IS_E_SCOPE: -1.0282236121184601e+22\n",
            "Total Loss: 1.256414368926305e+21\n",
            "----------------------------------------\n",
            "Epoch 52\n",
            "Var loss:  tensor(1.2467e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2292507139117263e+22\n",
            "E_s_wdiff_all_sq: 1.943348264484393e+19\n",
            "E_IS_SCOPE: -3.351490470015154e+22\n",
            "E_IS_E_SCOPE: -1.0278635985077858e+22\n",
            "Total Loss: 1.246685103749526e+21\n",
            "----------------------------------------\n",
            "Epoch 53\n",
            "Var loss:  tensor(1.2325e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2156577494832555e+22\n",
            "E_s_wdiff_all_sq: 1.0911978081941123e+19\n",
            "E_IS_SCOPE: -3.3732205758776047e+22\n",
            "E_IS_E_SCOPE: -1.0464088822638019e+22\n",
            "Total Loss: 1.2325118548962894e+21\n",
            "----------------------------------------\n",
            "Epoch 54\n",
            "Var loss:  tensor(1.2232e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.199476757834252e+22\n",
            "E_s_wdiff_all_sq: 3.8209152072431867e+18\n",
            "E_IS_SCOPE: -3.399230348502566e+22\n",
            "E_IS_E_SCOPE: -1.0688333226491356e+22\n",
            "Total Loss: 1.2232396974670364e+21\n",
            "----------------------------------------\n",
            "Epoch 55\n",
            "Var loss:  tensor(1.2150e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.1934386231559609e+22\n",
            "E_s_wdiff_all_sq: 2.0219336569202732e+18\n",
            "E_IS_SCOPE: -3.4108479363212556e+22\n",
            "E_IS_E_SCOPE: -1.0783161025489789e+22\n",
            "Total Loss: 1.2149899913056339e+21\n",
            "----------------------------------------\n",
            "Epoch 56\n",
            "Var loss:  tensor(1.2020e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2012212744656058e+22\n",
            "E_s_wdiff_all_sq: 4.200909866380894e+18\n",
            "E_IS_SCOPE: -3.4019954462078697e+22\n",
            "E_IS_E_SCOPE: -1.0693855981469404e+22\n",
            "Total Loss: 1.2019511746086463e+21\n",
            "----------------------------------------\n",
            "Epoch 57\n",
            "Var loss:  tensor(1.1903e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.214390478637759e+22\n",
            "E_s_wdiff_all_sq: 9.84692014117684e+18\n",
            "E_IS_SCOPE: -3.3848198683308272e+22\n",
            "E_IS_E_SCOPE: -1.0531587344468344e+22\n",
            "Total Loss: 1.1903488628678501e+21\n",
            "----------------------------------------\n",
            "Epoch 58\n",
            "Var loss:  tensor(1.1801e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.216407197502897e+22\n",
            "E_s_wdiff_all_sq: 1.1790627644726143e+19\n",
            "E_IS_SCOPE: -3.3809238666236645e+22\n",
            "E_IS_E_SCOPE: -1.049547874794727e+22\n",
            "Total Loss: 1.1801102960992631e+21\n",
            "----------------------------------------\n",
            "Epoch 59\n",
            "Var loss:  tensor(1.1689e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2084167305902185e+22\n",
            "E_s_wdiff_all_sq: 8.847664656674314e+18\n",
            "E_IS_SCOPE: -3.3900875979975534e+22\n",
            "E_IS_E_SCOPE: -1.0579472643091774e+22\n",
            "Total Loss: 1.1689126849282069e+21\n",
            "----------------------------------------\n",
            "Epoch 60\n",
            "Var loss:  tensor(1.1585e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2001962823171067e+22\n",
            "E_s_wdiff_all_sq: 6.025374071502084e+18\n",
            "E_IS_SCOPE: -3.4005369668284935e+22\n",
            "E_IS_E_SCOPE: -1.0673082323603003e+22\n",
            "Total Loss: 1.1585498671119744e+21\n",
            "----------------------------------------\n",
            "Epoch 61\n",
            "Var loss:  tensor(1.1473e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2064932943767403e+22\n",
            "E_s_wdiff_all_sq: 8.533814493309938e+18\n",
            "E_IS_SCOPE: -3.3947366417133333e+22\n",
            "E_IS_E_SCOPE: -1.0609657567980491e+22\n",
            "Total Loss: 1.1472522231439824e+21\n",
            "----------------------------------------\n",
            "Epoch 62\n",
            "Var loss:  tensor(1.1367e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.212830196089783e+22\n",
            "E_s_wdiff_all_sq: 1.1377345801781285e+19\n",
            "E_IS_SCOPE: -3.3892766133473864e+22\n",
            "E_IS_E_SCOPE: -1.0548613427595294e+22\n",
            "Total Loss: 1.1366893864377574e+21\n",
            "----------------------------------------\n",
            "Epoch 63\n",
            "Var loss:  tensor(1.1254e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2092257992794534e+22\n",
            "E_s_wdiff_all_sq: 9.581448977066113e+18\n",
            "E_IS_SCOPE: -3.3962956285604794e+22\n",
            "E_IS_E_SCOPE: -1.0603645791052633e+22\n",
            "Total Loss: 1.1253622044446163e+21\n",
            "----------------------------------------\n",
            "Epoch 64\n",
            "Var loss:  tensor(1.1144e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2028444769477068e+22\n",
            "E_s_wdiff_all_sq: 6.633882610849539e+18\n",
            "E_IS_SCOPE: -3.407678218877208e+22\n",
            "E_IS_E_SCOPE: -1.0697158144042446e+22\n",
            "Total Loss: 1.1144342337620206e+21\n",
            "----------------------------------------\n",
            "Epoch 65\n",
            "Var loss:  tensor(1.1031e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2051917330869666e+22\n",
            "E_s_wdiff_all_sq: 7.10035377010985e+18\n",
            "E_IS_SCOPE: -3.4089221360463743e+22\n",
            "E_IS_E_SCOPE: -1.0693856547036306e+22\n",
            "Total Loss: 1.1031236607528665e+21\n",
            "----------------------------------------\n",
            "Epoch 66\n",
            "Var loss:  tensor(1.0918e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2127351467841742e+22\n",
            "E_s_wdiff_all_sq: 9.71706088519e+18\n",
            "E_IS_SCOPE: -3.404097726408538e+22\n",
            "E_IS_E_SCOPE: -1.0632784592245564e+22\n",
            "Total Loss: 1.0918301261094464e+21\n",
            "----------------------------------------\n",
            "Epoch 67\n",
            "Var loss:  tensor(1.0806e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2146223448982945e+22\n",
            "E_s_wdiff_all_sq: 1.0052183228978827e+19\n",
            "E_IS_SCOPE: -3.4059757960315407e+22\n",
            "E_IS_E_SCOPE: -1.0635270460826664e+22\n",
            "Total Loss: 1.0805983205338907e+21\n",
            "----------------------------------------\n",
            "Epoch 68\n",
            "Var loss:  tensor(1.0691e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2101062659164732e+22\n",
            "E_s_wdiff_all_sq: 7.609704325882423e+18\n",
            "E_IS_SCOPE: -3.4157812232006274e+22\n",
            "E_IS_E_SCOPE: -1.0711846053681341e+22\n",
            "Total Loss: 1.0690557658979799e+21\n",
            "----------------------------------------\n",
            "Epoch 69\n",
            "Var loss:  tensor(1.0577e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2082168099871543e+22\n",
            "E_s_wdiff_all_sq: 6.393003270357774e+18\n",
            "E_IS_SCOPE: -3.422562451272381e+22\n",
            "E_IS_E_SCOPE: -1.075957872307528e+22\n",
            "Total Loss: 1.0577346533515382e+21\n",
            "----------------------------------------\n",
            "Epoch 70\n",
            "Var loss:  tensor(1.0460e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.213020326599022e+22\n",
            "E_s_wdiff_all_sq: 7.831166897434421e+18\n",
            "E_IS_SCOPE: -3.4207913238684225e+22\n",
            "E_IS_E_SCOPE: -1.0727856352283935e+22\n",
            "Total Loss: 1.0460252551753446e+21\n",
            "----------------------------------------\n",
            "Epoch 71\n",
            "Var loss:  tensor(1.0346e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2177250193971446e+22\n",
            "E_s_wdiff_all_sq: 9.487218270428697e+18\n",
            "E_IS_SCOPE: -3.418695069608659e+22\n",
            "E_IS_E_SCOPE: -1.0694381326064123e+22\n",
            "Total Loss: 1.0345721896924076e+21\n",
            "----------------------------------------\n",
            "Epoch 72\n",
            "Var loss:  tensor(1.0228e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2161087009954743e+22\n",
            "E_s_wdiff_all_sq: 8.49785090682553e+18\n",
            "E_IS_SCOPE: -3.4241322838926444e+22\n",
            "E_IS_E_SCOPE: -1.0732085248959202e+22\n",
            "Total Loss: 1.0227764886812314e+21\n",
            "----------------------------------------\n",
            "Epoch 73\n",
            "Var loss:  tensor(1.0111e+21, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2121070845041656e+22\n",
            "E_s_wdiff_all_sq: 6.68449501634125e+18\n",
            "E_IS_SCOPE: -3.432317794684397e+22\n",
            "E_IS_E_SCOPE: -1.0796089635684118e+22\n",
            "Total Loss: 1.0110632681078386e+21\n",
            "----------------------------------------\n",
            "Epoch 74\n",
            "Var loss:  tensor(9.9918e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2127058158385526e+22\n",
            "E_s_wdiff_all_sq: 6.826442545100489e+18\n",
            "E_IS_SCOPE: -3.434318336583652e+22\n",
            "E_IS_E_SCOPE: -1.0803469958265608e+22\n",
            "Total Loss: 9.991807112110827e+20\n",
            "----------------------------------------\n",
            "Epoch 75\n",
            "Var loss:  tensor(9.8722e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2168073481343449e+22\n",
            "E_s_wdiff_all_sq: 8.508589829581772e+18\n",
            "E_IS_SCOPE: -3.4314882434000207e+22\n",
            "E_IS_E_SCOPE: -1.0766942331751084e+22\n",
            "Total Loss: 9.872150182980559e+20\n",
            "----------------------------------------\n",
            "Epoch 76\n",
            "Var loss:  tensor(9.7525e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2176684387901119e+22\n",
            "E_s_wdiff_all_sq: 8.980974322210485e+18\n",
            "E_IS_SCOPE: -3.43240522518299e+22\n",
            "E_IS_E_SCOPE: -1.0766197186037736e+22\n",
            "Total Loss: 9.752508520563013e+20\n",
            "----------------------------------------\n",
            "Epoch 77\n",
            "Var loss:  tensor(9.6309e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2139674910767213e+22\n",
            "E_s_wdiff_all_sq: 7.545514491885366e+18\n",
            "E_IS_SCOPE: -3.438931357036018e+22\n",
            "E_IS_E_SCOPE: -1.0817988395033115e+22\n",
            "Total Loss: 9.630923648479758e+20\n",
            "----------------------------------------\n",
            "Epoch 78\n",
            "Var loss:  tensor(9.5101e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2115370444249251e+22\n",
            "E_s_wdiff_all_sq: 6.778270906114173e+18\n",
            "E_IS_SCOPE: -3.4435642213529958e+22\n",
            "E_IS_E_SCOPE: -1.0852947379384148e+22\n",
            "Total Loss: 9.510075650435543e+20\n",
            "----------------------------------------\n",
            "Epoch 79\n",
            "Var loss:  tensor(9.3868e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.21355216942951e+22\n",
            "E_s_wdiff_all_sq: 7.81528263127965e+18\n",
            "E_IS_SCOPE: -3.442446713968044e+22\n",
            "E_IS_E_SCOPE: -1.0834671522602918e+22\n",
            "Total Loss: 9.38681392444746e+20\n",
            "----------------------------------------\n",
            "Epoch 80\n",
            "Var loss:  tensor(9.2643e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2156487501320747e+22\n",
            "E_s_wdiff_all_sq: 9.02246369271829e+18\n",
            "E_IS_SCOPE: -3.440994847517194e+22\n",
            "E_IS_E_SCOPE: -1.081392153187406e+22\n",
            "Total Loss: 9.26434556300822e+20\n",
            "----------------------------------------\n",
            "Epoch 81\n",
            "Var loss:  tensor(9.1402e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2136907593662983e+22\n",
            "E_s_wdiff_all_sq: 8.473657060423804e+18\n",
            "E_IS_SCOPE: -3.444711980633373e+22\n",
            "E_IS_E_SCOPE: -1.0841089739270146e+22\n",
            "Total Loss: 9.140166085077337e+20\n",
            "----------------------------------------\n",
            "Epoch 82\n",
            "Var loss:  tensor(9.0160e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2104044271443062e+22\n",
            "E_s_wdiff_all_sq: 7.335639167722385e+18\n",
            "E_IS_SCOPE: -3.450389617466081e+22\n",
            "E_IS_E_SCOPE: -1.088575519237585e+22\n",
            "Total Loss: 9.015969089507662e+20\n",
            "----------------------------------------\n",
            "Epoch 83\n",
            "Var loss:  tensor(8.8908e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.210462980474097e+22\n",
            "E_s_wdiff_all_sq: 7.573405599137854e+18\n",
            "E_IS_SCOPE: -3.451885488122717e+22\n",
            "E_IS_E_SCOPE: -1.0891360132994127e+22\n",
            "Total Loss: 8.890798509707808e+20\n",
            "----------------------------------------\n",
            "Epoch 84\n",
            "Var loss:  tensor(8.7648e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2128173657756937e+22\n",
            "E_s_wdiff_all_sq: 8.77376816568012e+18\n",
            "E_IS_SCOPE: -3.450570525847417e+22\n",
            "E_IS_E_SCOPE: -1.0870547232488094e+22\n",
            "Total Loss: 8.764842479746516e+20\n",
            "----------------------------------------\n",
            "Epoch 85\n",
            "Var loss:  tensor(8.6383e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.212906469517107e+22\n",
            "E_s_wdiff_all_sq: 8.930388870312846e+18\n",
            "E_IS_SCOPE: -3.4525139627025638e+22\n",
            "E_IS_E_SCOPE: -1.0878989833763344e+22\n",
            "Total Loss: 8.638343521115979e+20\n",
            "----------------------------------------\n",
            "Epoch 86\n",
            "Var loss:  tensor(8.5112e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2104141925470454e+22\n",
            "E_s_wdiff_all_sq: 7.879041544775077e+18\n",
            "E_IS_SCOPE: -3.458123738420071e+22\n",
            "E_IS_E_SCOPE: -1.0920456986651288e+22\n",
            "Total Loss: 8.511175267246743e+20\n",
            "----------------------------------------\n",
            "Epoch 87\n",
            "Var loss:  tensor(8.3837e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2095989539369612e+22\n",
            "E_s_wdiff_all_sq: 7.551307781983021e+18\n",
            "E_IS_SCOPE: -3.4616653838467564e+22\n",
            "E_IS_E_SCOPE: -1.0942534790485513e+22\n",
            "Total Loss: 8.383656435927986e+20\n",
            "----------------------------------------\n",
            "Epoch 88\n",
            "Var loss:  tensor(8.2549e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2116214096607895e+22\n",
            "E_s_wdiff_all_sq: 8.415079779994917e+18\n",
            "E_IS_SCOPE: -3.4615901098296012e+22\n",
            "E_IS_E_SCOPE: -1.0930998201774231e+22\n",
            "Total Loss: 8.254859150403358e+20\n",
            "----------------------------------------\n",
            "Epoch 89\n",
            "Var loss:  tensor(8.1257e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2127881795100419e+22\n",
            "E_s_wdiff_all_sq: 8.926240639637699e+18\n",
            "E_IS_SCOPE: -3.4626769304095033e+22\n",
            "E_IS_E_SCOPE: -1.0930050732786012e+22\n",
            "Total Loss: 8.125747949701599e+20\n",
            "----------------------------------------\n",
            "Epoch 90\n",
            "Var loss:  tensor(7.9961e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2112026495103854e+22\n",
            "E_s_wdiff_all_sq: 8.237318787873422e+18\n",
            "E_IS_SCOPE: -3.4672668280155697e+22\n",
            "E_IS_E_SCOPE: -1.0961612287202992e+22\n",
            "Total Loss: 7.996062061032081e+20\n",
            "----------------------------------------\n",
            "Epoch 91\n",
            "Var loss:  tensor(7.8658e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2099940651323695e+22\n",
            "E_s_wdiff_all_sq: 7.605545050523092e+18\n",
            "E_IS_SCOPE: -3.4719271398748027e+22\n",
            "E_IS_E_SCOPE: -1.0992368307587204e+22\n",
            "Total Loss: 7.865821862910241e+20\n",
            "----------------------------------------\n",
            "Epoch 92\n",
            "Var loss:  tensor(7.7343e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2116220275722086e+22\n",
            "E_s_wdiff_all_sq: 8.067148890868569e+18\n",
            "E_IS_SCOPE: -3.473374738855318e+22\n",
            "E_IS_E_SCOPE: -1.099220797935788e+22\n",
            "Total Loss: 7.734288463911348e+20\n",
            "----------------------------------------\n",
            "Epoch 93\n",
            "Var loss:  tensor(7.6028e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2137587735952986e+22\n",
            "E_s_wdiff_all_sq: 8.68580370972083e+18\n",
            "E_IS_SCOPE: -3.474494150470191e+22\n",
            "E_IS_E_SCOPE: -1.0988164678149632e+22\n",
            "Total Loss: 7.602781706998356e+20\n",
            "----------------------------------------\n",
            "Epoch 94\n",
            "Var loss:  tensor(7.4706e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2134175266144829e+22\n",
            "E_s_wdiff_all_sq: 8.33367465602258e+18\n",
            "E_IS_SCOPE: -3.4783819423621598e+22\n",
            "E_IS_E_SCOPE: -1.1010813608694362e+22\n",
            "Total Loss: 7.470566546864897e+20\n",
            "----------------------------------------\n",
            "Epoch 95\n",
            "Var loss:  tensor(7.3375e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2120698413984216e+22\n",
            "E_s_wdiff_all_sq: 7.654825889031122e+18\n",
            "E_IS_SCOPE: -3.4832144012901597e+22\n",
            "E_IS_E_SCOPE: -1.1043087591814073e+22\n",
            "Total Loss: 7.337525733250145e+20\n",
            "----------------------------------------\n",
            "Epoch 96\n",
            "Var loss:  tensor(7.2035e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2125549607379469e+22\n",
            "E_s_wdiff_all_sq: 7.800669340819894e+18\n",
            "E_IS_SCOPE: -3.4854958292456954e+22\n",
            "E_IS_E_SCOPE: -1.1052213694925352e+22\n",
            "Total Loss: 7.203535169433905e+20\n",
            "----------------------------------------\n",
            "Epoch 97\n",
            "Var loss:  tensor(7.0694e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.214051485679126e+22\n",
            "E_s_wdiff_all_sq: 8.436832673704211e+18\n",
            "E_IS_SCOPE: -3.4862528911040294e+22\n",
            "E_IS_E_SCOPE: -1.1047802340738316e+22\n",
            "Total Loss: 7.069434666273871e+20\n",
            "----------------------------------------\n",
            "Epoch 98\n",
            "Var loss:  tensor(6.9349e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2138996324570675e+22\n",
            "E_s_wdiff_all_sq: 8.40636883391521e+18\n",
            "E_IS_SCOPE: -3.488983493688199e+22\n",
            "E_IS_E_SCOPE: -1.1062028830543643e+22\n",
            "Total Loss: 6.93492352139393e+20\n",
            "----------------------------------------\n",
            "Epoch 99\n",
            "Var loss:  tensor(6.7992e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.212507933697997e+22\n",
            "E_s_wdiff_all_sq: 7.759711596577149e+18\n",
            "E_IS_SCOPE: -3.493699909694722e+22\n",
            "E_IS_E_SCOPE: -1.1093587469670529e+22\n",
            "Total Loss: 6.799229617988908e+20\n",
            "----------------------------------------\n",
            "Epoch 100\n",
            "Var loss:  tensor(6.6627e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2126933425903955e+22\n",
            "E_s_wdiff_all_sq: 7.675937753143454e+18\n",
            "E_IS_SCOPE: -3.4968613877174485e+22\n",
            "E_IS_E_SCOPE: -1.110949578580027e+22\n",
            "Total Loss: 6.662724386575708e+20\n",
            "----------------------------------------\n",
            "Epoch 101\n",
            "Var loss:  tensor(6.5265e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2118295601655837e+22\n",
            "E_s_wdiff_all_sq: 7.393457080459871e+18\n",
            "E_IS_SCOPE: -3.5003825086458283e+22\n",
            "E_IS_E_SCOPE: -1.1131307214810055e+22\n",
            "Total Loss: 6.526464828712073e+20\n",
            "----------------------------------------\n",
            "Epoch 102\n",
            "Var loss:  tensor(6.3911e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2185973985349649e+22\n",
            "E_s_wdiff_all_sq: 1.01791643920203e+19\n",
            "E_IS_SCOPE: -3.495239374762885e+22\n",
            "E_IS_E_SCOPE: -1.106994767943105e+22\n",
            "Total Loss: 6.391089380868657e+20\n",
            "----------------------------------------\n",
            "Epoch 103\n",
            "Var loss:  tensor(6.2507e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2136319738575835e+22\n",
            "E_s_wdiff_all_sq: 8.142100704686345e+18\n",
            "E_IS_SCOPE: -3.503571868745321e+22\n",
            "E_IS_E_SCOPE: -1.113736891045439e+22\n",
            "Total Loss: 6.250685047343541e+20\n",
            "----------------------------------------\n",
            "Epoch 104\n",
            "Var loss:  tensor(6.1144e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2087617619006325e+22\n",
            "E_s_wdiff_all_sq: 6.422063779349371e+18\n",
            "E_IS_SCOPE: -3.511513274938363e+22\n",
            "E_IS_E_SCOPE: -1.120200239658005e+22\n",
            "Total Loss: 6.11438719680987e+20\n",
            "----------------------------------------\n",
            "Epoch 105\n",
            "Var loss:  tensor(5.9739e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2120737570239967e+22\n",
            "E_s_wdiff_all_sq: 7.808324648228662e+18\n",
            "E_IS_SCOPE: -3.509748065004141e+22\n",
            "E_IS_E_SCOPE: -1.1174510754122558e+22\n",
            "Total Loss: 5.973879422265946e+20\n",
            "----------------------------------------\n",
            "Epoch 106\n",
            "Var loss:  tensor(5.8353e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2162968083986043e+22\n",
            "E_s_wdiff_all_sq: 9.638060411956275e+18\n",
            "E_IS_SCOPE: -3.5072453658775975e+22\n",
            "E_IS_E_SCOPE: -1.1139129005088728e+22\n",
            "Total Loss: 5.835271914020489e+20\n",
            "----------------------------------------\n",
            "Epoch 107\n",
            "Var loss:  tensor(5.6940e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2137580062259297e+22\n",
            "E_s_wdiff_all_sq: 8.512270176500157e+18\n",
            "E_IS_SCOPE: -3.513236770320805e+22\n",
            "E_IS_E_SCOPE: -1.1182825869870771e+22\n",
            "Total Loss: 5.6940167515728354e+20\n",
            "----------------------------------------\n",
            "Epoch 108\n",
            "Var loss:  tensor(5.5543e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2095684426043654e+22\n",
            "E_s_wdiff_all_sq: 6.873550518731116e+18\n",
            "E_IS_SCOPE: -3.521004777742553e+22\n",
            "E_IS_E_SCOPE: -1.1243921260508644e+22\n",
            "Total Loss: 5.5543206242029666e+20\n",
            "----------------------------------------\n",
            "Epoch 109\n",
            "Var loss:  tensor(5.4122e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.211184758891624e+22\n",
            "E_s_wdiff_all_sq: 7.617602314669122e+18\n",
            "E_IS_SCOPE: -3.5213492215301592e+22\n",
            "E_IS_E_SCOPE: -1.1236091168822407e+22\n",
            "Total Loss: 5.412160744820467e+20\n",
            "----------------------------------------\n",
            "Epoch 110\n",
            "Var loss:  tensor(5.2705e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.214812585238545e+22\n",
            "E_s_wdiff_all_sq: 9.313738670386946e+18\n",
            "E_IS_SCOPE: -3.5190487640541667e+22\n",
            "E_IS_E_SCOPE: -1.120393945465897e+22\n",
            "Total Loss: 5.2704834498079595e+20\n",
            "----------------------------------------\n",
            "Epoch 111\n",
            "Var loss:  tensor(5.1279e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2131420756020654e+22\n",
            "E_s_wdiff_all_sq: 8.851903681805893e+18\n",
            "E_IS_SCOPE: -3.522899041069885e+22\n",
            "E_IS_E_SCOPE: -1.1230423947615305e+22\n",
            "Total Loss: 5.1279118717063633e+20\n",
            "----------------------------------------\n",
            "Epoch 112\n",
            "Var loss:  tensor(4.9853e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2091093760979184e+22\n",
            "E_s_wdiff_all_sq: 7.273800898953008e+18\n",
            "E_IS_SCOPE: -3.530378582897494e+22\n",
            "E_IS_E_SCOPE: -1.128897779932501e+22\n",
            "Total Loss: 4.9853491070610964e+20\n",
            "----------------------------------------\n",
            "Epoch 113\n",
            "Var loss:  tensor(4.8414e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2098322663072957e+22\n",
            "E_s_wdiff_all_sq: 7.567748981419239e+18\n",
            "E_IS_SCOPE: -3.532324057333828e+22\n",
            "E_IS_E_SCOPE: -1.1294739428627817e+22\n",
            "Total Loss: 4.841392119816158e+20\n",
            "----------------------------------------\n",
            "Epoch 114\n",
            "Var loss:  tensor(4.6980e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2135996318699995e+22\n",
            "E_s_wdiff_all_sq: 9.036747450801875e+18\n",
            "E_IS_SCOPE: -3.530978938996114e+22\n",
            "E_IS_E_SCOPE: -1.126843288614729e+22\n",
            "Total Loss: 4.697956069213607e+20\n",
            "----------------------------------------\n",
            "Epoch 115\n",
            "Var loss:  tensor(4.5539e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2134749561741143e+22\n",
            "E_s_wdiff_all_sq: 8.947076666151327e+18\n",
            "E_IS_SCOPE: -3.534148910052979e+22\n",
            "E_IS_E_SCOPE: -1.128517897897711e+22\n",
            "Total Loss: 4.553877073146602e+20\n",
            "----------------------------------------\n",
            "Epoch 116\n",
            "Var loss:  tensor(4.4090e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2102280523613894e+22\n",
            "E_s_wdiff_all_sq: 7.58825348756846e+18\n",
            "E_IS_SCOPE: -3.541062934509949e+22\n",
            "E_IS_E_SCOPE: -1.1337265590590505e+22\n",
            "Total Loss: 4.408980148882034e+20\n",
            "----------------------------------------\n",
            "Epoch 117\n",
            "Var loss:  tensor(4.2635e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2101040142819569e+22\n",
            "E_s_wdiff_all_sq: 7.573095252815326e+18\n",
            "E_IS_SCOPE: -3.543980535359371e+22\n",
            "E_IS_E_SCOPE: -1.135227882976325e+22\n",
            "Total Loss: 4.263453346236759e+20\n",
            "----------------------------------------\n",
            "Epoch 118\n",
            "Var loss:  tensor(4.1168e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2129312227831413e+22\n",
            "E_s_wdiff_all_sq: 8.815906185424067e+18\n",
            "E_IS_SCOPE: -3.543145657752981e+22\n",
            "E_IS_E_SCOPE: -1.1332399964825884e+22\n",
            "Total Loss: 4.116783769512145e+20\n",
            "----------------------------------------\n",
            "Epoch 119\n",
            "Var loss:  tensor(3.9707e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2129276424265883e+22\n",
            "E_s_wdiff_all_sq: 8.973023490845377e+18\n",
            "E_IS_SCOPE: -3.5454495983748543e+22\n",
            "E_IS_E_SCOPE: -1.134290140752373e+22\n",
            "Total Loss: 3.970680890417595e+20\n",
            "----------------------------------------\n",
            "Epoch 120\n",
            "Var loss:  tensor(3.8237e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2101396448771196e+22\n",
            "E_s_wdiff_all_sq: 7.757830553102307e+18\n",
            "E_IS_SCOPE: -3.5520072943078486e+22\n",
            "E_IS_E_SCOPE: -1.1391013150754131e+22\n",
            "Total Loss: 3.823694245783887e+20\n",
            "----------------------------------------\n",
            "Epoch 121\n",
            "Var loss:  tensor(3.6757e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2101589800352104e+22\n",
            "E_s_wdiff_all_sq: 7.568626379815266e+18\n",
            "E_IS_SCOPE: -3.555780874143794e+22\n",
            "E_IS_E_SCOPE: -1.141117389001589e+22\n",
            "Total Loss: 3.675733972256639e+20\n",
            "----------------------------------------\n",
            "Epoch 122\n",
            "Var loss:  tensor(3.5272e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2133500199739933e+22\n",
            "E_s_wdiff_all_sq: 8.599337443984928e+18\n",
            "E_IS_SCOPE: -3.5560002140252473e+22\n",
            "E_IS_E_SCOPE: -1.1397047848270029e+22\n",
            "Total Loss: 3.5271887374684206e+20\n",
            "----------------------------------------\n",
            "Epoch 123\n",
            "Var loss:  tensor(3.3789e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2142785055565522e+22\n",
            "E_s_wdiff_all_sq: 8.817136149464127e+18\n",
            "E_IS_SCOPE: -3.5585433688957807e+22\n",
            "E_IS_E_SCOPE: -1.1405964049542711e+22\n",
            "Total Loss: 3.3788923597981064e+20\n",
            "----------------------------------------\n",
            "Epoch 124\n",
            "Var loss:  tensor(3.2294e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2120776852312835e+22\n",
            "E_s_wdiff_all_sq: 7.797444480348061e+18\n",
            "E_IS_SCOPE: -3.5646489801883994e+22\n",
            "E_IS_E_SCOPE: -1.1449021931728665e+22\n",
            "Total Loss: 3.2294245343261046e+20\n",
            "----------------------------------------\n",
            "Epoch 125\n",
            "Var loss:  tensor(3.0794e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2115403123188319e+22\n",
            "E_s_wdiff_all_sq: 7.568939925811033e+18\n",
            "E_IS_SCOPE: -3.5683686433781696e+22\n",
            "E_IS_E_SCOPE: -1.1470610342222066e+22\n",
            "Total Loss: 3.079406919928932e+20\n",
            "----------------------------------------\n",
            "Epoch 126\n",
            "Var loss:  tensor(2.9286e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2135820367177324e+22\n",
            "E_s_wdiff_all_sq: 8.478356919777422e+18\n",
            "E_IS_SCOPE: -3.5685792951848042e+22\n",
            "E_IS_E_SCOPE: -1.1460183369630207e+22\n",
            "Total Loss: 2.928639820736307e+20\n",
            "----------------------------------------\n",
            "Epoch 127\n",
            "Var loss:  tensor(2.7779e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2140165405517856e+22\n",
            "E_s_wdiff_all_sq: 8.69040690733726e+18\n",
            "E_IS_SCOPE: -3.5709542682080307e+22\n",
            "E_IS_E_SCOPE: -1.1469543959836764e+22\n",
            "Total Loss: 2.777913305693044e+20\n",
            "----------------------------------------\n",
            "Epoch 128\n",
            "Var loss:  tensor(2.6258e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2121119769083255e+22\n",
            "E_s_wdiff_all_sq: 7.798521990456603e+18\n",
            "E_IS_SCOPE: -3.5767462779568483e+22\n",
            "E_IS_E_SCOPE: -1.150943692666e+22\n",
            "Total Loss: 2.6258439962805823e+20\n",
            "----------------------------------------\n",
            "Epoch 129\n",
            "Var loss:  tensor(2.4743e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2120516103250008e+22\n",
            "E_s_wdiff_all_sq: 7.614902570840139e+18\n",
            "E_IS_SCOPE: -3.5805307264536462e+22\n",
            "E_IS_E_SCOPE: -1.15298148631276e+22\n",
            "Total Loss: 2.4742557326165148e+20\n",
            "----------------------------------------\n",
            "Epoch 130\n",
            "Var loss:  tensor(2.3217e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2142033045783449e+22\n",
            "E_s_wdiff_all_sq: 8.463252554697501e+18\n",
            "E_IS_SCOPE: -3.58108669594462e+22\n",
            "E_IS_E_SCOPE: -1.152126423133578e+22\n",
            "Total Loss: 2.321712306001606e+20\n",
            "----------------------------------------\n",
            "Epoch 131\n",
            "Var loss:  tensor(2.1685e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2143886463254502e+22\n",
            "E_s_wdiff_all_sq: 8.594348642653532e+18\n",
            "E_IS_SCOPE: -3.5837171162239233e+22\n",
            "E_IS_E_SCOPE: -1.1533074111513965e+22\n",
            "Total Loss: 2.1684588301970204e+20\n",
            "----------------------------------------\n",
            "Epoch 132\n",
            "Var loss:  tensor(2.0145e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2122656214780607e+22\n",
            "E_s_wdiff_all_sq: 7.835351096493454e+18\n",
            "E_IS_SCOPE: -3.588909749357273e+22\n",
            "E_IS_E_SCOPE: -1.156963725164919e+22\n",
            "Total Loss: 2.0145239228449345e+20\n",
            "----------------------------------------\n",
            "Epoch 133\n",
            "Var loss:  tensor(1.8598e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2116587504463832e+22\n",
            "E_s_wdiff_all_sq: 7.842054687835633e+18\n",
            "E_IS_SCOPE: -3.591691991489834e+22\n",
            "E_IS_E_SCOPE: -1.1585051820466264e+22\n",
            "Total Loss: 1.859825457677174e+20\n",
            "----------------------------------------\n",
            "Epoch 134\n",
            "Var loss:  tensor(1.7054e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2127241736386242e+22\n",
            "E_s_wdiff_all_sq: 8.555112100219276e+18\n",
            "E_IS_SCOPE: -3.5923674091904486e+22\n",
            "E_IS_E_SCOPE: -1.15808567177009e+22\n",
            "Total Loss: 1.7054311538174093e+20\n",
            "----------------------------------------\n",
            "Epoch 135\n",
            "Var loss:  tensor(1.5501e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2125134238247589e+22\n",
            "E_s_wdiff_all_sq: 8.533636510262068e+18\n",
            "E_IS_SCOPE: -3.5954667843890572e+22\n",
            "E_IS_E_SCOPE: -1.159704359178439e+22\n",
            "Total Loss: 1.5500873552138705e+20\n",
            "----------------------------------------\n",
            "Epoch 136\n",
            "Var loss:  tensor(1.3934e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2113305957379978e+22\n",
            "E_s_wdiff_all_sq: 7.918880979269823e+18\n",
            "E_IS_SCOPE: -3.6005627774352402e+22\n",
            "E_IS_E_SCOPE: -1.1629738387696611e+22\n",
            "Total Loss: 1.3934498146678106e+20\n",
            "----------------------------------------\n",
            "Epoch 137\n",
            "Var loss:  tensor(1.2372e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2119076915685639e+22\n",
            "E_s_wdiff_all_sq: 8.005162939135414e+18\n",
            "E_IS_SCOPE: -3.6036068511186265e+22\n",
            "E_IS_E_SCOPE: -1.1642901561206362e+22\n",
            "Total Loss: 1.2372398663396858e+20\n",
            "----------------------------------------\n",
            "Epoch 138\n",
            "Var loss:  tensor(1.0809e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.213297720219529e+22\n",
            "E_s_wdiff_all_sq: 8.55781666713699e+18\n",
            "E_IS_SCOPE: -3.6051434308650897e+22\n",
            "E_IS_E_SCOPE: -1.164329958974709e+22\n",
            "Total Loss: 1.0808676383653993e+20\n",
            "----------------------------------------\n",
            "Epoch 139\n",
            "Var loss:  tensor(9.2405e+19, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2128708857438969e+22\n",
            "E_s_wdiff_all_sq: 8.48763461236741e+18\n",
            "E_IS_SCOPE: -3.608367032371898e+22\n",
            "E_IS_E_SCOPE: -1.1660985745921e+22\n",
            "Total Loss: 9.240485746577926e+19\n",
            "----------------------------------------\n",
            "Epoch 140\n",
            "Var loss:  tensor(7.6648e+19, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2117665998150513e+22\n",
            "E_s_wdiff_all_sq: 8.14955694662722e+18\n",
            "E_IS_SCOPE: -3.6123798920388103e+22\n",
            "E_IS_E_SCOPE: -1.1686166742476337e+22\n",
            "Total Loss: 7.664779450509165e+19\n",
            "----------------------------------------\n",
            "Epoch 141\n",
            "Var loss:  tensor(6.0822e+19, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2111003667703475e+22\n",
            "E_s_wdiff_all_sq: 8.045203847492336e+18\n",
            "E_IS_SCOPE: -3.6156687509448928e+22\n",
            "E_IS_E_SCOPE: -1.1705037969994805e+22\n",
            "Total Loss: 6.0821968491808555e+19\n",
            "----------------------------------------\n",
            "Epoch 142\n",
            "Var loss:  tensor(4.5004e+19, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2112585362610982e+22\n",
            "E_s_wdiff_all_sq: 8.33121977073828e+18\n",
            "E_IS_SCOPE: -3.617740301194891e+22\n",
            "E_IS_E_SCOPE: -1.171304828703877e+22\n",
            "Total Loss: 4.500360953124094e+19\n",
            "----------------------------------------\n",
            "Epoch 143\n",
            "Var loss:  tensor(2.9147e+19, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2117110253448205e+22\n",
            "E_s_wdiff_all_sq: 8.591672382237137e+18\n",
            "E_IS_SCOPE: -3.6200836211480593e+22\n",
            "E_IS_E_SCOPE: -1.172187660925064e+22\n",
            "Total Loss: 2.9147067940710908e+19\n",
            "----------------------------------------\n",
            "Epoch 144\n",
            "Var loss:  tensor(1.3173e+19, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2117068352872522e+22\n",
            "E_s_wdiff_all_sq: 8.493027115927862e+18\n",
            "E_IS_SCOPE: -3.6236785327513887e+22\n",
            "E_IS_E_SCOPE: -1.1740531847299932e+22\n",
            "Total Loss: 1.3172649446315393e+19\n",
            "----------------------------------------\n",
            "Epoch 145\n",
            "Var loss:  tensor(-2.8655e+18, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2115045973815909e+22\n",
            "E_s_wdiff_all_sq: 8.204898352980747e+18\n",
            "E_IS_SCOPE: -3.6279690314680703e+22\n",
            "E_IS_E_SCOPE: -1.1764463259738832e+22\n",
            "Total Loss: -2.865466627227386e+18\n",
            "----------------------------------------\n",
            "Epoch 146\n",
            "Var loss:  tensor(-1.8837e+19, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.21182928109298e+22\n",
            "E_s_wdiff_all_sq: 8.016914411021243e+18\n",
            "E_IS_SCOPE: -3.63209903236539e+22\n",
            "E_IS_E_SCOPE: -1.1785590517616624e+22\n",
            "Total Loss: -1.8836873826359312e+19\n",
            "----------------------------------------\n",
            "Epoch 147\n",
            "Var loss:  tensor(-3.4878e+19, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2127278674333649e+22\n",
            "E_s_wdiff_all_sq: 8.165706400204357e+18\n",
            "E_IS_SCOPE: -3.635125478450819e+22\n",
            "E_IS_E_SCOPE: -1.1797424419202824e+22\n",
            "Total Loss: -3.487822737248669e+19\n",
            "----------------------------------------\n",
            "Epoch 148\n",
            "Var loss:  tensor(-5.0993e+19, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2135913387610308e+22\n",
            "E_s_wdiff_all_sq: 8.430319069066772e+18\n",
            "E_IS_SCOPE: -3.637685334953238e+22\n",
            "E_IS_E_SCOPE: -1.180624032837817e+22\n",
            "Total Loss: -5.09929166181761e+19\n",
            "----------------------------------------\n",
            "Epoch 149\n",
            "Var loss:  tensor(-6.7169e+19, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2135347018513852e+22\n",
            "E_s_wdiff_all_sq: 8.367625721076847e+18\n",
            "E_IS_SCOPE: -3.641155817954212e+22\n",
            "E_IS_E_SCOPE: -1.182417368615821e+22\n",
            "Total Loss: -6.71688723939889e+19\n",
            "----------------------------------------\n",
            "Epoch 150\n",
            "Var loss:  tensor(-8.3421e+19, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2128855530491697e+22\n",
            "E_s_wdiff_all_sq: 8.131162501062754e+18\n",
            "E_IS_SCOPE: -3.6450744394082956e+22\n",
            "E_IS_E_SCOPE: -1.1847044150901915e+22\n",
            "Total Loss: -8.342139526669612e+19\n",
            "----------------------------------------\n",
            "Epoch 151\n",
            "Var loss:  tensor(-9.9733e+19, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2123977943652638e+22\n",
            "E_s_wdiff_all_sq: 8.085648236205699e+18\n",
            "E_IS_SCOPE: -3.648302565185138e+22\n",
            "E_IS_E_SCOPE: -1.1864753728287364e+22\n",
            "Total Loss: -9.973276548626016e+19\n",
            "----------------------------------------\n",
            "Epoch 152\n",
            "Var loss:  tensor(-1.1610e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2122836464148526e+22\n",
            "E_s_wdiff_all_sq: 8.255304982092833e+18\n",
            "E_IS_SCOPE: -3.6508355153682198e+22\n",
            "E_IS_E_SCOPE: -1.1876563661881833e+22\n",
            "Total Loss: -1.1610344786860232e+20\n",
            "----------------------------------------\n",
            "Epoch 153\n",
            "Var loss:  tensor(-1.3250e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.21218220693654e+22\n",
            "E_s_wdiff_all_sq: 8.437896556983168e+18\n",
            "E_IS_SCOPE: -3.653336550031556e+22\n",
            "E_IS_E_SCOPE: -1.1888109242496026e+22\n",
            "Total Loss: -1.3250179407587102e+20\n",
            "----------------------------------------\n",
            "Epoch 154\n",
            "Var loss:  tensor(-1.4892e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2119185830499483e+22\n",
            "E_s_wdiff_all_sq: 8.382579473740544e+18\n",
            "E_IS_SCOPE: -3.656727125519529e+22\n",
            "E_IS_E_SCOPE: -1.1906118321752961e+22\n",
            "Total Loss: -1.489223049304395e+20\n",
            "----------------------------------------\n",
            "Epoch 155\n",
            "Var loss:  tensor(-1.6541e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2117650689385132e+22\n",
            "E_s_wdiff_all_sq: 8.26333388347596e+18\n",
            "E_IS_SCOPE: -3.6604477559866455e+22\n",
            "E_IS_E_SCOPE: -1.1925937647230688e+22\n",
            "Total Loss: -1.6541207895394065e+20\n",
            "----------------------------------------\n",
            "Epoch 156\n",
            "Var loss:  tensor(-1.8192e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2120739593354765e+22\n",
            "E_s_wdiff_all_sq: 8.229488802725618e+18\n",
            "E_IS_SCOPE: -3.664043847529751e+22\n",
            "E_IS_E_SCOPE: -1.194337817449285e+22\n",
            "Total Loss: -1.819234240599341e+20\n",
            "----------------------------------------\n",
            "Epoch 157\n",
            "Var loss:  tensor(-1.9848e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2125690287053961e+22\n",
            "E_s_wdiff_all_sq: 8.348566220547242e+18\n",
            "E_IS_SCOPE: -3.6671138775860448e+22\n",
            "E_IS_E_SCOPE: -1.1956674411768094e+22\n",
            "Total Loss: -1.9848461966088182e+20\n",
            "----------------------------------------\n",
            "Epoch 158\n",
            "Var loss:  tensor(-2.1512e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2128147442954976e+22\n",
            "E_s_wdiff_all_sq: 8.420738146647486e+18\n",
            "E_IS_SCOPE: -3.670274869727986e+22\n",
            "E_IS_E_SCOPE: -1.1971382361353921e+22\n",
            "Total Loss: -2.151234578412051e+20\n",
            "----------------------------------------\n",
            "Epoch 159\n",
            "Var loss:  tensor(-2.3184e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2126009066524512e+22\n",
            "E_s_wdiff_all_sq: 8.344881417173497e+18\n",
            "E_IS_SCOPE: -3.673834145068559e+22\n",
            "E_IS_E_SCOPE: -1.199025233810653e+22\n",
            "Total Loss: -2.3183741082530533e+20\n",
            "----------------------------------------\n",
            "Epoch 160\n",
            "Var loss:  tensor(-2.4857e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.212222862724474e+22\n",
            "E_s_wdiff_all_sq: 8.248367842994133e+18\n",
            "E_IS_SCOPE: -3.677405529269655e+22\n",
            "E_IS_E_SCOPE: -1.2009744608298323e+22\n",
            "Total Loss: -2.485687235516249e+20\n",
            "----------------------------------------\n",
            "Epoch 161\n",
            "Var loss:  tensor(-2.6531e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2121951517397496e+22\n",
            "E_s_wdiff_all_sq: 8.258280085326128e+18\n",
            "E_IS_SCOPE: -3.6807117129377695e+22\n",
            "E_IS_E_SCOPE: -1.202629835048986e+22\n",
            "Total Loss: -2.653082801865375e+20\n",
            "----------------------------------------\n",
            "Epoch 162\n",
            "Var loss:  tensor(-2.8219e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2125247681776715e+22\n",
            "E_s_wdiff_all_sq: 8.264314752660881e+18\n",
            "E_IS_SCOPE: -3.6842280926602175e+22\n",
            "E_IS_E_SCOPE: -1.204301443460597e+22\n",
            "Total Loss: -2.8219145790795284e+20\n",
            "----------------------------------------\n",
            "Epoch 163\n",
            "Var loss:  tensor(-2.9902e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2130926858498822e+22\n",
            "E_s_wdiff_all_sq: 8.219817826283616e+18\n",
            "E_IS_SCOPE: -3.688056087900254e+22\n",
            "E_IS_E_SCOPE: -1.2061030600384847e+22\n",
            "Total Loss: -2.990236886499391e+20\n",
            "----------------------------------------\n",
            "Epoch 164\n",
            "Var loss:  tensor(-3.1591e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.213479631084819e+22\n",
            "E_s_wdiff_all_sq: 8.23389938709003e+18\n",
            "E_IS_SCOPE: -3.6915697644503143e+22\n",
            "E_IS_E_SCOPE: -1.207753652447686e+22\n",
            "Total Loss: -3.1590999502574374e+20\n",
            "----------------------------------------\n",
            "Epoch 165\n",
            "Var loss:  tensor(-3.3286e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2136468634913175e+22\n",
            "E_s_wdiff_all_sq: 8.289467987627777e+18\n",
            "E_IS_SCOPE: -3.694824043785155e+22\n",
            "E_IS_E_SCOPE: -1.2093024621805932e+22\n",
            "Total Loss: -3.328589656703579e+20\n",
            "----------------------------------------\n",
            "Epoch 166\n",
            "Var loss:  tensor(-3.4989e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2134705751119041e+22\n",
            "E_s_wdiff_all_sq: 8.291764886023741e+18\n",
            "E_IS_SCOPE: -3.698149670076634e+22\n",
            "E_IS_E_SCOPE: -1.2110106369742548e+22\n",
            "Total Loss: -3.4988913148421997e+20\n",
            "----------------------------------------\n",
            "Epoch 167\n",
            "Var loss:  tensor(-3.6700e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.213039316564978e+22\n",
            "E_s_wdiff_all_sq: 8.264366484504631e+18\n",
            "E_IS_SCOPE: -3.701491381174132e+22\n",
            "E_IS_E_SCOPE: -1.2128119695772934e+22\n",
            "Total Loss: -3.6699596081228415e+20\n",
            "----------------------------------------\n",
            "Epoch 168\n",
            "Var loss:  tensor(-3.8416e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2123261165467863e+22\n",
            "E_s_wdiff_all_sq: 8.239663391580307e+18\n",
            "E_IS_SCOPE: -3.704699648541147e+22\n",
            "E_IS_E_SCOPE: -1.214616576249274e+22\n",
            "Total Loss: -3.8415510817507954e+20\n",
            "----------------------------------------\n",
            "Epoch 169\n",
            "Var loss:  tensor(-4.0132e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2116852350069638e+22\n",
            "E_s_wdiff_all_sq: 8.291866007374452e+18\n",
            "E_IS_SCOPE: -3.7076294944289123e+22\n",
            "E_IS_E_SCOPE: -1.2162111886370726e+22\n",
            "Total Loss: -4.013224696946591e+20\n",
            "----------------------------------------\n",
            "Epoch 170\n",
            "Var loss:  tensor(-4.1853e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.210642780049374e+22\n",
            "E_s_wdiff_all_sq: 8.01366323478059e+18\n",
            "E_IS_SCOPE: -3.711735197027742e+22\n",
            "E_IS_E_SCOPE: -1.2187223125450188e+22\n",
            "Total Loss: -4.1852735400876546e+20\n",
            "----------------------------------------\n",
            "Epoch 171\n",
            "Var loss:  tensor(-4.3586e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2109008702331886e+22\n",
            "E_s_wdiff_all_sq: 8.16398986667352e+18\n",
            "E_IS_SCOPE: -3.714713199838404e+22\n",
            "E_IS_E_SCOPE: -1.2200439302998408e+22\n",
            "Total Loss: -4.3585797573920267e+20\n",
            "----------------------------------------\n",
            "Epoch 172\n",
            "Var loss:  tensor(-4.5314e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.212087637752977e+22\n",
            "E_s_wdiff_all_sq: 8.638088036883652e+18\n",
            "E_IS_SCOPE: -3.71681940797954e+22\n",
            "E_IS_E_SCOPE: -1.2204764859696138e+22\n",
            "Total Loss: -4.531377932708474e+20\n",
            "----------------------------------------\n",
            "Epoch 173\n",
            "Var loss:  tensor(-4.7048e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2123902708499142e+22\n",
            "E_s_wdiff_all_sq: 8.733292606359138e+18\n",
            "E_IS_SCOPE: -3.7200627660297574e+22\n",
            "E_IS_E_SCOPE: -1.2219597293820418e+22\n",
            "Total Loss: -4.704813209329766e+20\n",
            "----------------------------------------\n",
            "Epoch 174\n",
            "Var loss:  tensor(-4.8790e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2115666260143678e+22\n",
            "E_s_wdiff_all_sq: 8.331541217390411e+18\n",
            "E_IS_SCOPE: -3.724784002286469e+22\n",
            "E_IS_E_SCOPE: -1.2248011196940373e+22\n",
            "Total Loss: -4.8790078506281625e+20\n",
            "----------------------------------------\n",
            "Epoch 175\n",
            "Var loss:  tensor(-5.0527e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2106786529175245e+22\n",
            "E_s_wdiff_all_sq: 8.213216407732219e+18\n",
            "E_IS_SCOPE: -3.728333488111103e+22\n",
            "E_IS_E_SCOPE: -1.2268844606422237e+22\n",
            "Total Loss: -5.0527000407833156e+20\n",
            "----------------------------------------\n",
            "Epoch 176\n",
            "Var loss:  tensor(-5.2267e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2104740401032292e+22\n",
            "E_s_wdiff_all_sq: 8.510874854617543e+18\n",
            "E_IS_SCOPE: -3.7305213053481672e+22\n",
            "E_IS_E_SCOPE: -1.2278310889669188e+22\n",
            "Total Loss: -5.226736272217169e+20\n",
            "----------------------------------------\n",
            "Epoch 177\n",
            "Var loss:  tensor(-5.4007e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2100940052908405e+22\n",
            "E_s_wdiff_all_sq: 8.792421467982654e+18\n",
            "E_IS_SCOPE: -3.7327119683469124e+22\n",
            "E_IS_E_SCOPE: -1.2288382970208966e+22\n",
            "Total Loss: -5.400709937011706e+20\n",
            "----------------------------------------\n",
            "Epoch 178\n",
            "Var loss:  tensor(-5.5752e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2093763765539095e+22\n",
            "E_s_wdiff_all_sq: 8.614067751322986e+18\n",
            "E_IS_SCOPE: -3.7365843230369256e+22\n",
            "E_IS_E_SCOPE: -1.2310774985500672e+22\n",
            "Total Loss: -5.5751832899562766e+20\n",
            "----------------------------------------\n",
            "Epoch 179\n",
            "Var loss:  tensor(-5.7494e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.208933879273105e+22\n",
            "E_s_wdiff_all_sq: 8.377411254038716e+18\n",
            "E_IS_SCOPE: -3.7408247779311686e+22\n",
            "E_IS_E_SCOPE: -1.2334712859416265e+22\n",
            "Total Loss: -5.7493877794175504e+20\n",
            "----------------------------------------\n",
            "Epoch 180\n",
            "Var loss:  tensor(-5.9243e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2093801035991972e+22\n",
            "E_s_wdiff_all_sq: 8.56574149282789e+18\n",
            "E_IS_SCOPE: -3.7437849953760174e+22\n",
            "E_IS_E_SCOPE: -1.2347130385251166e+22\n",
            "Total Loss: -5.924283060731039e+20\n",
            "----------------------------------------\n",
            "Epoch 181\n",
            "Var loss:  tensor(-6.0998e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2100305099436887e+22\n",
            "E_s_wdiff_all_sq: 8.85042078515889e+18\n",
            "E_IS_SCOPE: -3.746482005382111e+22\n",
            "E_IS_E_SCOPE: -1.2357091174867993e+22\n",
            "Total Loss: -6.099820738995814e+20\n",
            "----------------------------------------\n",
            "Epoch 182\n",
            "Var loss:  tensor(-6.2760e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2099466959183845e+22\n",
            "E_s_wdiff_all_sq: 8.780537904300356e+18\n",
            "E_IS_SCOPE: -3.7502545657424113e+22\n",
            "E_IS_E_SCOPE: -1.2376647901713424e+22\n",
            "Total Loss: -6.276012408223386e+20\n",
            "----------------------------------------\n",
            "Epoch 183\n",
            "Var loss:  tensor(-6.4528e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2093927200575749e+22\n",
            "E_s_wdiff_all_sq: 8.502721682101603e+18\n",
            "E_IS_SCOPE: -3.7546498660110006e+22\n",
            "E_IS_E_SCOPE: -1.2401904736392521e+22\n",
            "Total Loss: -6.452765007649303e+20\n",
            "----------------------------------------\n",
            "Epoch 184\n",
            "Var loss:  tensor(-6.6288e+20, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2091641687126665e+22\n",
            "E_s_wdiff_all_sq: 8.421209012866424e+18\n",
            "E_IS_SCOPE: -3.758405071735987e+22\n",
            "E_IS_E_SCOPE: -1.2421832478324517e+22\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-01d57a9c684f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_IS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded_state_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates_first_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates_last_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_all_shaping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_IS_SCOPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-30-5d294114b799>\u001b[0m in \u001b[0;36mtrain_var\u001b[0;34m(model, num_epochs, learning_rate, samples_IS, padded_state_tensors, states_first_tensor, states_last_tensor, samples_all_shaping, samples_IS_SCOPE, test1)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# Retain the graph to avoid clearing it before backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mtot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = train_var(model, 200, 0.0001, samples_IS, padded_state_tensors, states_first_tensor, states_last_tensor, samples_all_shaping, samples_IS_SCOPE, test1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "V5HankiakEiu",
        "outputId": "6616ce3c-94b2-4fdf-9833-cd1af30ac8fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Var loss:  tensor(-5.0872e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2091641687126665e+22\n",
            "E_s_wdiff_all_sq: 8.421209012866424e+18\n",
            "E_IS_SCOPE: -2.547315218031649e+25\n",
            "E_IS_E_SCOPE: -1.2421832478324517e+22\n",
            "Total Loss: -5.087179914210118e+25\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "Var loss:  tensor(-5.3797e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.1588018418409055e+22\n",
            "E_s_wdiff_all_sq: 8.04536804186359e+20\n",
            "E_IS_SCOPE: -2.694291367756086e+25\n",
            "E_IS_E_SCOPE: -1.7349946687008094e+22\n",
            "Total Loss: -5.379704141723259e+25\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "Var loss:  tensor(-5.6711e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.4111873352395464e+22\n",
            "E_s_wdiff_all_sq: 3.463374565893483e+21\n",
            "E_IS_SCOPE: -2.8408122806833696e+25\n",
            "E_IS_E_SCOPE: -2.215367046350286e+22\n",
            "Total Loss: -5.671052464951478e+25\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "Var loss:  tensor(-5.9621e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.9427952560721845e+22\n",
            "E_s_wdiff_all_sq: 7.837952653226776e+21\n",
            "E_IS_SCOPE: -2.987325832672755e+25\n",
            "E_IS_E_SCOPE: -2.682911211818654e+22\n",
            "Total Loss: -5.962145328513011e+25\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "Var loss:  tensor(-6.2530e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 2.7263608969798527e+22\n",
            "E_s_wdiff_all_sq: 1.375398874050293e+22\n",
            "E_IS_SCOPE: -3.1338148723437466e+25\n",
            "E_IS_E_SCOPE: -3.1355187507019592e+22\n",
            "Total Loss: -6.252982019597437e+25\n",
            "----------------------------------------\n",
            "Epoch 6\n",
            "Var loss:  tensor(-6.5435e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 3.748339183415563e+22\n",
            "E_s_wdiff_all_sq: 2.116529777547345e+22\n",
            "E_IS_SCOPE: -3.280275788491791e+25\n",
            "E_IS_E_SCOPE: -3.5795217994547766e+22\n",
            "Total Loss: -6.543549864460832e+25\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "Var loss:  tensor(-6.8338e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 5.004461314920678e+22\n",
            "E_s_wdiff_all_sq: 3.0068462342649105e+22\n",
            "E_IS_SCOPE: -3.4266963700336215e+25\n",
            "E_IS_E_SCOPE: -4.018966356332541e+22\n",
            "Total Loss: -6.833816571742354e+25\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "Var loss:  tensor(-7.1238e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 6.481053799005235e+22\n",
            "E_s_wdiff_all_sq: 4.037113835105185e+22\n",
            "E_IS_SCOPE: -3.57308221505971e+25\n",
            "E_IS_E_SCOPE: -4.452089429979757e+22\n",
            "Total Loss: -7.1238123000895045e+25\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "Var loss:  tensor(-7.4135e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 8.170428479059414e+22\n",
            "E_s_wdiff_all_sq: 5.203125263787489e+22\n",
            "E_IS_SCOPE: -3.7194150366745127e+25\n",
            "E_IS_E_SCOPE: -4.879709737567206e+22\n",
            "Total Loss: -7.413505707716294e+25\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "Var loss:  tensor(-7.7029e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.006562379984491e+23\n",
            "E_s_wdiff_all_sq: 6.5009257231549674e+22\n",
            "E_IS_SCOPE: -3.8656945868055057e+25\n",
            "E_IS_E_SCOPE: -5.302351238455299e+22\n",
            "Total Loss: -7.702901688154831e+25\n",
            "----------------------------------------\n",
            "Epoch 11\n",
            "Var loss:  tensor(-7.9920e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.215950259010862e+23\n",
            "E_s_wdiff_all_sq: 7.926284934170995e+22\n",
            "E_IS_SCOPE: -4.0119165595627445e+25\n",
            "E_IS_E_SCOPE: -5.720242133076124e+22\n",
            "Total Loss: -7.991998082195182e+25\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "Var loss:  tensor(-8.2808e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.4444713311004935e+23\n",
            "E_s_wdiff_all_sq: 9.47475141144426e+22\n",
            "E_IS_SCOPE: -4.158076958043214e+25\n",
            "E_IS_E_SCOPE: -6.133460319520498e+22\n",
            "Total Loss: -8.280794013875891e+25\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "Var loss:  tensor(-8.5693e+25, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.691368025139844e+23\n",
            "E_s_wdiff_all_sq: 1.1141678394072568e+23\n",
            "E_IS_SCOPE: -4.3041720954261145e+25\n",
            "E_IS_E_SCOPE: -6.5420000998008646e+22\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-5d2902af0be1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_IS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded_state_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates_first_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates_last_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_all_shaping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_IS_SCOPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-38-5d294114b799>\u001b[0m in \u001b[0;36mtrain_var\u001b[0;34m(model, num_epochs, learning_rate, samples_IS, padded_state_tensors, states_first_tensor, states_last_tensor, samples_all_shaping, samples_IS_SCOPE, test1)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# Retain the graph to avoid clearing it before backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mtot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = train_var(model, 20, 0.001, samples_IS, padded_state_tensors, states_first_tensor, states_last_tensor, samples_all_shaping, samples_IS_SCOPE, test1)"
=======
        "model2 = train_var(model, 20, 0.001, samples_IS, padded_state_tensors, states_first_tensor, states_last_tensor, test1)"
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHLpALXBN40b",
<<<<<<< HEAD
        "outputId": "8cffe722-37df-4139-8ebf-3479a805cb23"
      },
      "execution_count": null,
=======
        "outputId": "d20ddce3-e6d9-4046-8528-ecca97e60873"
      },
      "execution_count": 53,
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
<<<<<<< HEAD
            "Var loss:  tensor(-1.3998e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 2.7000520983736854e+26\n",
            "E_s_wdiff_all_sq: 1.1991158006418987e+26\n",
            "E_IS_SCOPE: -2.0238984353616566e+26\n",
            "E_IS_E_SCOPE: 1.7432066784634587e+24\n",
            "Total Loss: -1.3997894919094345e+26\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "Var loss:  tensor(-1.8930e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 2.4851380256092592e+26\n",
            "E_s_wdiff_all_sq: 1.0868796875981285e+26\n",
            "E_IS_SCOPE: -2.1642866384407017e+26\n",
            "E_IS_E_SCOPE: 1.6592145943890643e+24\n",
            "Total Loss: -1.892960208309719e+26\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "Var loss:  tensor(-2.3750e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 2.2864222596610805e+26\n",
            "E_s_wdiff_all_sq: 9.831123864853387e+25\n",
            "E_IS_SCOPE: -2.3071556879644427e+26\n",
            "E_IS_E_SCOPE: 1.5775847477927258e+24\n",
            "Total Loss: -2.3749651779074894e+26\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "Var loss:  tensor(-2.8423e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 2.1107685666169942e+26\n",
            "E_s_wdiff_all_sq: 8.908178298603343e+25\n",
            "E_IS_SCOPE: -2.454130057488368e+26\n",
            "E_IS_E_SCOPE: 1.5012467817496386e+24\n",
            "Total Loss: -2.842277471018134e+26\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "Var loss:  tensor(-3.2993e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.95377408787041e+26\n",
            "E_s_wdiff_all_sq: 8.078126017319421e+25\n",
            "E_IS_SCOPE: -2.6052506542281885e+26\n",
            "E_IS_E_SCOPE: 1.4291329785199847e+24\n",
            "Total Loss: -3.299349729147468e+26\n",
            "----------------------------------------\n",
            "Epoch 6\n",
            "Var loss:  tensor(-3.7487e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.8132467079007727e+26\n",
            "E_s_wdiff_all_sq: 7.329651482777037e+25\n",
            "E_IS_SCOPE: -2.7606843344170066e+26\n",
            "E_IS_E_SCOPE: 1.360869471486018e+24\n",
            "Total Loss: -3.748696564283724e+26\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "Var loss:  tensor(-4.1896e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.688620283159106e+26\n",
            "E_s_wdiff_all_sq: 6.659493094301345e+25\n",
            "E_IS_SCOPE: -2.9198032751618074e+26\n",
            "E_IS_E_SCOPE: 1.2967482268817199e+24\n",
            "Total Loss: -4.189637233176863e+26\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "Var loss:  tensor(-4.6262e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.576707664912865e+26\n",
            "E_s_wdiff_all_sq: 6.052083489607422e+25\n",
            "E_IS_SCOPE: -3.08305451841946e+26\n",
            "E_IS_E_SCOPE: 1.2357861039386222e+24\n",
            "Total Loss: -4.626223474250116e+26\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "Var loss:  tensor(-5.0587e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.4763612808585628e+26\n",
            "E_s_wdiff_all_sq: 5.50174234409973e+25\n",
            "E_IS_SCOPE: -3.2499784261118546e+26\n",
            "E_IS_E_SCOPE: 1.1778527193751983e+24\n",
            "Total Loss: -5.058679672152305e+26\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "Var loss:  tensor(-5.4889e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.3848700547605917e+26\n",
            "E_s_wdiff_all_sq: 4.995988928518009e+25\n",
            "E_IS_SCOPE: -3.420172749344094e+26\n",
            "E_IS_E_SCOPE: 1.1220005061754078e+24\n",
            "Total Loss: -5.488883978318761e+26\n",
            "----------------------------------------\n",
            "Epoch 11\n",
            "Var loss:  tensor(-5.9179e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.3006442730443957e+26\n",
            "E_s_wdiff_all_sq: 4.527488207429612e+25\n",
            "E_IS_SCOPE: -3.593391101377815e+26\n",
            "E_IS_E_SCOPE: 1.067680399123898e+24\n",
            "Total Loss: -5.917916860890854e+26\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "Var loss:  tensor(-6.3462e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.2229417912969604e+26\n",
            "E_s_wdiff_all_sq: 4.092707164503446e+25\n",
            "E_IS_SCOPE: -3.769466846843736e+26\n",
            "E_IS_E_SCOPE: 1.0146928561134615e+24\n",
            "Total Loss: -6.346181207279818e+26\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "Var loss:  tensor(-6.7612e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.1518335335596193e+26\n",
            "E_s_wdiff_all_sq: 3.6950381982478167e+25\n",
            "E_IS_SCOPE: -3.9421864533730626e+26\n",
            "E_IS_E_SCOPE: 9.636992190084379e+23\n",
            "Total Loss: -6.761198868962662e+26\n",
            "----------------------------------------\n",
            "Epoch 14\n",
            "Var loss:  tensor(-7.1583e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.0875381753628806e+26\n",
            "E_s_wdiff_all_sq: 3.3357822679325225e+25\n",
            "E_IS_SCOPE: -4.10933498575679e+26\n",
            "E_IS_E_SCOPE: 9.152111976069571e+23\n",
            "Total Loss: -7.158336651284811e+26\n",
            "----------------------------------------\n",
            "Epoch 15\n",
            "Var loss:  tensor(-7.5579e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 1.0300003666921198e+26\n",
            "E_s_wdiff_all_sq: 3.008197928388507e+25\n",
            "E_IS_SCOPE: -4.281029201156582e+26\n",
            "E_IS_E_SCOPE: 8.686640466504931e+23\n",
            "Total Loss: -7.557866476226461e+26\n",
            "----------------------------------------\n",
            "Epoch 16\n",
            "Var loss:  tensor(-7.9625e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 9.780866290057678e+25\n",
            "E_s_wdiff_all_sq: 2.706676561722053e+25\n",
            "E_IS_SCOPE: -4.458086666377223e+26\n",
            "E_IS_E_SCOPE: 8.235217772818606e+23\n",
            "Total Loss: -7.962540876273037e+26\n",
            "----------------------------------------\n",
            "Epoch 17\n",
            "Var loss:  tensor(-8.3770e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 9.25864062540654e+25\n",
            "E_s_wdiff_all_sq: 2.408043092938196e+25\n",
            "E_IS_SCOPE: -4.639890551795465e+26\n",
            "E_IS_E_SCOPE: 7.762667967592406e+23\n",
            "Total Loss: -8.376953564158955e+26\n",
            "----------------------------------------\n",
            "Epoch 18\n",
            "Var loss:  tensor(-8.7964e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 8.772145597482964e+25\n",
            "E_s_wdiff_all_sq: 2.128158973430442e+25\n",
            "E_IS_SCOPE: -4.826000005768793e+26\n",
            "E_IS_E_SCOPE: 7.292373507211456e+23\n",
            "Total Loss: -8.796411091516826e+26\n",
            "----------------------------------------\n",
            "Epoch 19\n",
            "Var loss:  tensor(-9.2201e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 8.332681175269682e+25\n",
            "E_s_wdiff_all_sq: 1.8710506668717508e+25\n",
            "E_IS_SCOPE: -5.016565446564469e+26\n",
            "E_IS_E_SCOPE: 6.832218590962401e+23\n",
            "Total Loss: -9.220107950580761e+26\n",
            "----------------------------------------\n",
            "Epoch 20\n",
            "Var loss:  tensor(-9.6468e+26, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 5.058576277992128e+22\n",
            "E_IS_all_sq: 2.543768337021951e+22\n",
            "E_s_wdiff_sq: 7.938632829251062e+25\n",
            "E_s_wdiff_all_sq: 1.636020374096819e+25\n",
            "E_IS_SCOPE: -5.210907454597642e+26\n",
            "E_IS_E_SCOPE: 6.382979689732807e+23\n",
            "Total Loss: -9.64684908454528e+26\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[ 0.6824,  0.3805],\n",
            "        [ 0.6172,  0.3862],\n",
            "        [-0.0410, -0.2904],\n",
            "        [ 0.3265, -0.6162],\n",
            "        [-0.4672,  0.3825],\n",
            "        [-0.4019,  0.5381],\n",
            "        [-0.0941, -0.5162],\n",
            "        [-0.5809,  0.0319],\n",
            "        [-0.1979,  0.2670],\n",
            "        [-0.4053, -0.3357],\n",
            "        [ 0.0179,  0.6101],\n",
            "        [ 0.3949,  0.0047],\n",
            "        [ 0.7054,  0.4417],\n",
            "        [-0.3734, -0.1384],\n",
            "        [ 0.1148,  0.4802],\n",
            "        [ 0.3828, -0.3846]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([-0.2569,  0.1246,  0.6364, -0.6841, -0.2801, -0.0636, -0.0846, -0.5966,\n",
            "         0.2269, -0.0934,  0.5676, -0.6006,  0.3885, -0.4913, -0.3735,  0.0440],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[ 4.8119e-02, -4.0558e-02,  2.2185e-01,  1.7136e-01,  2.0620e-01,\n",
            "         -7.6490e-02, -4.9387e-03,  1.0780e-01, -9.7940e-02, -5.2611e-02,\n",
            "          8.6816e-02,  2.0431e-01, -1.1189e-01, -2.3857e-01,  4.5704e-02,\n",
            "         -2.4755e-02],\n",
            "        [-1.1661e-01,  1.6673e-01, -1.2172e-01, -1.7377e-02, -1.9116e-01,\n",
            "          2.1572e-01,  1.8230e-01, -3.6067e-02, -4.8273e-02,  2.0668e-01,\n",
            "          1.8825e-01, -2.2010e-01,  3.0955e-02, -2.3602e-01,  1.6450e-01,\n",
            "         -1.9474e-01],\n",
            "        [-2.3669e-01, -8.8660e-02,  1.5782e-01,  5.4865e-02, -3.7314e-02,\n",
            "         -2.2701e-01, -1.7717e-01,  1.0917e-01, -1.3188e-01, -2.3322e-01,\n",
            "         -2.0656e-01, -6.6348e-02,  2.9485e-03, -1.5408e-01,  4.4631e-02,\n",
            "          5.9431e-03],\n",
            "        [-3.1699e-02,  2.1269e-01,  6.5254e-02,  1.6674e-01,  1.0271e-01,\n",
            "         -1.5640e-01, -1.1433e-01,  9.1803e-02,  4.8161e-02,  6.3060e-02,\n",
            "         -1.2206e-01,  1.8972e-01, -1.1215e-01, -6.9293e-02, -1.9905e-01,\n",
            "         -8.7023e-05],\n",
            "        [-5.5292e-02, -2.1445e-01,  1.0447e-01,  1.9652e-01, -2.0886e-01,\n",
            "          8.6149e-02, -6.7564e-02,  1.6284e-01,  1.8813e-01,  1.2977e-01,\n",
            "         -1.8909e-03,  1.5335e-01,  2.2191e-01, -2.0367e-01, -1.9575e-01,\n",
            "         -1.1563e-02],\n",
            "        [-1.5999e-01,  3.4475e-02,  1.4412e-01, -2.0440e-01, -2.4086e-01,\n",
            "          4.3020e-03,  7.6393e-02,  2.0897e-01,  6.2470e-02, -1.5482e-01,\n",
            "          1.8559e-01,  1.2675e-01, -3.5940e-02,  1.3949e-01, -2.4669e-01,\n",
            "         -1.6998e-01],\n",
            "        [-1.4121e-03,  9.2029e-02,  1.6774e-02,  2.4159e-01, -1.8972e-01,\n",
            "          2.2045e-01,  2.4686e-01, -1.0914e-02, -1.4103e-01,  9.1213e-02,\n",
            "         -4.3784e-02, -1.6879e-01,  4.5783e-02,  1.8536e-01,  6.9759e-02,\n",
            "          2.2215e-01],\n",
            "        [-1.2859e-01, -9.0884e-02,  5.4626e-02, -3.8355e-02,  1.1648e-01,\n",
            "          7.5265e-02,  2.2921e-01,  2.3633e-01,  1.0943e-01,  9.5796e-02,\n",
            "          9.7141e-02,  1.2300e-01, -2.5879e-01, -1.2350e-01, -1.5009e-02,\n",
            "          1.3043e-02],\n",
            "        [-1.6694e-02,  1.5965e-01, -4.7113e-02, -2.1283e-01,  7.2415e-02,\n",
            "         -1.0634e-01,  7.0834e-02,  1.0853e-01, -1.9885e-01, -2.0899e-01,\n",
            "         -8.6902e-02,  6.2196e-02,  4.3863e-02,  2.2491e-01,  6.7579e-02,\n",
            "         -2.4318e-01],\n",
            "        [ 1.6246e-02, -1.8128e-01, -1.9994e-01,  7.6150e-02, -2.1505e-01,\n",
            "         -2.4253e-01, -7.8125e-02, -2.0187e-01,  7.0338e-03,  5.8107e-02,\n",
            "         -2.5847e-03, -1.5630e-01, -6.0726e-02, -1.1809e-01, -1.6551e-01,\n",
            "         -5.4297e-02],\n",
            "        [ 2.4383e-01,  4.2616e-02,  5.6662e-02,  1.3916e-01,  2.2539e-01,\n",
            "          1.9607e-01, -1.7537e-01, -1.8012e-01, -1.2684e-01, -1.7179e-01,\n",
            "         -3.5418e-02,  1.2716e-01,  1.2756e-01, -5.8339e-02,  9.8414e-02,\n",
            "          2.5362e-02],\n",
            "        [ 1.6507e-01,  1.7497e-01,  6.1446e-02, -9.7664e-02,  1.8058e-01,\n",
            "         -2.5965e-01, -3.1194e-02, -1.4002e-01,  1.0309e-01,  4.9587e-02,\n",
            "          1.3151e-01,  6.2520e-02, -1.0080e-01,  1.8290e-01, -2.2798e-03,\n",
            "          2.0217e-03],\n",
            "        [-1.5221e-01,  1.4097e-01, -7.1615e-04, -6.8548e-02,  2.2222e-01,\n",
            "          1.2362e-01,  1.8278e-01, -2.1061e-01, -7.6397e-02,  1.7362e-01,\n",
            "          4.3270e-02, -2.1091e-01,  4.2701e-02,  1.2101e-01, -4.7703e-02,\n",
            "         -2.0536e-01],\n",
            "        [-6.6673e-02, -4.6614e-02, -2.1227e-01,  2.9418e-02, -2.1981e-01,\n",
            "          1.3636e-01,  1.7628e-01, -1.8667e-02, -1.4600e-01,  1.7796e-01,\n",
            "         -8.2919e-02, -2.2852e-01, -1.9402e-02, -1.0765e-01,  1.1574e-01,\n",
            "         -1.5714e-01],\n",
            "        [-1.0918e-01, -1.9517e-01,  9.8679e-02,  1.5596e-01, -4.4319e-02,\n",
            "         -1.7486e-01, -1.5448e-01,  2.9712e-02, -3.3289e-03,  1.5767e-01,\n",
            "          1.1929e-01, -2.6514e-01, -1.0920e-03,  8.7649e-02,  7.2158e-02,\n",
            "          6.2090e-02],\n",
            "        [-8.3881e-03,  6.5977e-02,  2.1695e-01,  1.9215e-01, -2.9525e-02,\n",
            "          1.7588e-01, -5.8884e-02,  8.2231e-03,  5.6097e-02, -1.6881e-01,\n",
            "         -1.4676e-01, -1.2744e-01, -1.5995e-01, -1.6587e-02, -2.8196e-02,\n",
            "          2.3959e-01],\n",
            "        [ 9.9272e-02, -8.2990e-02, -1.1069e-01,  1.9435e-01,  2.0021e-01,\n",
            "          1.6971e-01,  5.8639e-02, -1.3337e-01, -1.8521e-02,  2.2435e-01,\n",
            "          6.4262e-02,  5.9340e-02, -5.0475e-02, -5.0460e-03,  1.2239e-01,\n",
            "          1.1172e-01],\n",
            "        [ 8.1245e-02,  1.7842e-01, -1.4347e-01, -1.9353e-01, -9.7532e-02,\n",
            "          3.3191e-02,  9.2401e-02,  3.2447e-02, -7.3296e-02,  4.2897e-02,\n",
            "         -5.4902e-03, -1.7552e-01,  2.3623e-01,  1.8997e-01,  1.3470e-01,\n",
            "         -2.2129e-01],\n",
            "        [-1.9724e-01, -8.5698e-02,  4.3844e-02,  1.9982e-01,  2.4789e-01,\n",
            "         -2.3965e-01, -1.8726e-01,  2.2428e-01, -1.4151e-01,  1.6169e-02,\n",
            "          1.3268e-01,  1.4430e-01, -5.2540e-02, -2.0882e-01, -1.0297e-01,\n",
            "          7.5755e-02],\n",
            "        [-1.3038e-01, -2.1669e-01, -5.8820e-02, -9.0053e-02,  2.5145e-01,\n",
            "         -2.2259e-01,  2.0062e-01, -6.5883e-02,  2.1339e-01,  6.7655e-02,\n",
            "         -1.5339e-01,  1.2299e-01, -6.6090e-02, -9.7631e-02,  2.4591e-01,\n",
            "          1.6375e-02],\n",
            "        [ 2.0833e-01,  2.2925e-01, -8.1671e-02, -7.4458e-02,  2.4689e-01,\n",
            "         -1.7912e-01, -3.0479e-02,  2.2088e-01,  4.1135e-02, -1.4143e-01,\n",
            "          1.4276e-02, -4.4181e-02,  2.1406e-02, -8.7408e-02, -2.6004e-02,\n",
            "         -3.1061e-02],\n",
            "        [ 2.7277e-02, -9.2468e-02, -1.8294e-01, -2.0342e-01,  1.7406e-01,\n",
            "          6.5903e-02,  8.9643e-02, -5.2062e-02,  2.6414e-01, -1.2718e-01,\n",
            "         -2.3894e-01,  1.6539e-01,  1.8297e-02,  6.2260e-02, -9.3196e-02,\n",
            "          4.3673e-03],\n",
            "        [-5.9226e-02, -1.7806e-01, -1.5932e-01,  2.5755e-02,  1.8840e-01,\n",
            "         -2.3118e-01,  4.6522e-02, -1.5184e-01,  5.4040e-03, -6.1534e-03,\n",
            "         -7.5576e-02,  1.5076e-01,  1.9803e-01, -5.7331e-02,  1.2015e-03,\n",
            "         -2.8805e-02],\n",
            "        [ 9.5230e-02, -5.9195e-02,  5.9797e-02, -1.4853e-01,  2.2916e-01,\n",
            "          6.8206e-03, -1.0452e-02, -6.4086e-02,  1.3535e-01,  2.1016e-01,\n",
            "         -1.2791e-01,  1.3874e-01,  2.4114e-01,  1.8081e-01,  1.3184e-01,\n",
            "         -2.1979e-01],\n",
            "        [ 1.9239e-01,  3.5063e-02, -1.7934e-01,  1.7502e-01,  8.2594e-02,\n",
            "          1.0295e-01,  2.3758e-01,  1.2021e-01, -5.1508e-02,  1.5860e-01,\n",
            "          1.1935e-01, -7.2050e-02, -1.4643e-01,  2.2494e-01, -1.6159e-01,\n",
            "         -1.2161e-02],\n",
            "        [-1.1569e-01,  2.4863e-01,  8.7303e-02, -4.0421e-02,  1.6243e-01,\n",
            "          1.6153e-02,  2.2084e-01, -1.5133e-01, -3.1824e-02,  1.2209e-01,\n",
            "          2.3849e-01,  3.1212e-02, -4.0532e-02,  1.5685e-01, -1.0802e-02,\n",
            "         -7.3412e-02],\n",
            "        [ 2.5694e-01, -3.9981e-02, -5.8586e-03,  2.5751e-01, -9.3908e-02,\n",
            "         -2.6468e-01, -6.8448e-02,  5.6993e-02, -8.4784e-02,  1.0977e-01,\n",
            "         -9.5266e-03, -4.4528e-02,  5.6235e-02, -3.2194e-02, -1.3303e-01,\n",
            "          7.7084e-02],\n",
            "        [-1.2107e-01, -4.9455e-02, -1.0928e-01, -1.4182e-01, -2.1752e-01,\n",
            "         -1.3493e-01, -2.4229e-01,  6.4488e-02, -6.0827e-02, -9.6155e-02,\n",
            "          4.3416e-02, -1.0943e-01, -8.7071e-02,  1.0680e-01, -1.9074e-01,\n",
            "          1.8180e-01],\n",
            "        [ 1.1885e-01, -1.3959e-01,  1.3637e-01, -1.7812e-01,  1.7236e-01,\n",
            "          1.7322e-01,  1.5212e-01, -4.9635e-02,  1.2627e-02, -1.7094e-01,\n",
            "          5.6883e-02,  1.1782e-01,  2.6690e-01,  1.5117e-01, -1.3883e-01,\n",
            "         -7.5040e-02],\n",
            "        [ 1.7444e-02, -3.5884e-02, -1.8073e-01, -4.8182e-02,  5.1672e-02,\n",
            "         -2.1597e-01,  1.5905e-02, -2.4473e-01,  2.2163e-01,  6.5373e-02,\n",
            "          1.5828e-01,  4.6021e-02,  2.7998e-02,  1.6024e-01,  2.1393e-01,\n",
            "          1.7622e-02],\n",
            "        [-2.4343e-02,  1.6148e-02,  1.8917e-02,  4.6976e-02,  8.1570e-02,\n",
            "         -7.2976e-02, -8.2241e-02,  9.8812e-02,  1.2289e-01,  1.7245e-01,\n",
            "         -1.7320e-01, -2.4167e-01,  1.7690e-01, -7.3494e-02,  1.4066e-01,\n",
            "         -2.3803e-01],\n",
            "        [-1.9888e-01, -1.8503e-01,  8.4259e-02,  2.4136e-01,  5.5319e-02,\n",
            "         -1.5181e-01,  8.2156e-02, -1.8184e-01, -7.5127e-02, -2.1625e-01,\n",
            "          1.1747e-01, -4.3509e-02, -2.2899e-01,  9.2018e-02,  1.9127e-01,\n",
            "         -1.1790e-01]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([-0.0860, -0.2362, -0.2142,  0.1716,  0.1689,  0.2149, -0.0474, -0.1591,\n",
            "        -0.1497, -0.0224, -0.1051, -0.1015,  0.1446,  0.1406,  0.2544, -0.1735,\n",
            "        -0.1481, -0.1807,  0.0241, -0.2079,  0.2115,  0.0250,  0.1389,  0.2335,\n",
            "         0.2197,  0.1802,  0.2623, -0.1372,  0.0478,  0.2256,  0.0486, -0.0534],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[ 0.1721,  0.0623, -0.0768,  0.1644,  0.0325, -0.0332, -0.0931,  0.0436,\n",
            "          0.0268, -0.0838, -0.1538, -0.0204,  0.0539, -0.0472,  0.1059, -0.0720,\n",
            "          0.1543, -0.0265,  0.0777,  0.1012,  0.1266,  0.0518, -0.1264, -0.1316,\n",
            "         -0.0902, -0.0639, -0.1390,  0.0065,  0.1957, -0.0794,  0.0822,  0.1624]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([0.1091], dtype=torch.float64)\n"
=======
            "Var loss:  tensor(3.5878e+78, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 2.189111377156518e+78\n",
            "E_IS_all_sq: 1.1105457776126258e+78\n",
            "E_s_wdiff_sq: 3.980768876646654e+76\n",
            "E_s_wdiff_all_sq: 2.0194614640538768e+76\n",
            "E_IS_SCOPE: 5.16524725816184e+78\n",
            "E_IS_E_SCOPE: 2.6203525287790254e+78\n",
            "Total Loss: 3.5878102182969632e+78\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "Var loss:  tensor(4.4556e+78, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 2.189111377156518e+78\n",
            "E_IS_all_sq: 1.1105457776126258e+78\n",
            "E_s_wdiff_sq: 1.7025264038264168e+78\n",
            "E_s_wdiff_all_sq: 8.636990921136386e+77\n",
            "E_IS_SCOPE: 3.5025410517081507e+78\n",
            "E_IS_E_SCOPE: 1.7768543969537756e+78\n",
            "Total Loss: 4.455610915925283e+78\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "Var loss:  tensor(3.5681e+78, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 2.189111377156518e+78\n",
            "E_IS_all_sq: 1.1105457776126258e+78\n",
            "E_s_wdiff_sq: 3.102455394931125e+77\n",
            "E_s_wdiff_all_sq: 1.5738891930193287e+77\n",
            "E_IS_SCOPE: 4.558334717935871e+78\n",
            "E_IS_E_SCOPE: 2.312463142262486e+78\n",
            "Total Loss: 3.5680911481212876e+78\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "Var loss:  tensor(3.7732e+78, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 2.189111377156518e+78\n",
            "E_IS_all_sq: 1.1105457776126258e+78\n",
            "E_s_wdiff_sq: 2.8087493207150034e+76\n",
            "E_s_wdiff_all_sq: 1.4248908172534639e+76\n",
            "E_IS_SCOPE: 5.577591511209017e+78\n",
            "E_IS_E_SCOPE: 2.8295365720955755e+78\n",
            "Total Loss: 3.773226398882349e+78\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "Var loss:  tensor(4.0227e+78, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 2.189111377156518e+78\n",
            "E_IS_all_sq: 1.1105457776126258e+78\n",
            "E_s_wdiff_sq: 1.4526467952446066e+77\n",
            "E_s_wdiff_all_sq: 7.369340737202615e+76\n",
            "E_IS_SCOPE: 5.854227525888195e+78\n",
            "E_IS_E_SCOPE: 2.9698752324503868e+78\n",
            "Total Loss: 4.022659633493584e+78\n",
            "----------------------------------------\n",
            "Epoch 6\n",
            "Var loss:  tensor(3.7606e+78, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 2.189111377156518e+78\n",
            "E_IS_all_sq: 1.1105457776126258e+78\n",
            "E_s_wdiff_sq: 3.3426759544793736e+76\n",
            "E_s_wdiff_all_sq: 1.6957541341843097e+76\n",
            "E_IS_SCOPE: 5.539951134066399e+78\n",
            "E_IS_E_SCOPE: 2.8104414441181565e+78\n",
            "Total Loss: 3.760570294867015e+78\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "Var loss:  tensor(3.4919e+78, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 2.189111377156518e+78\n",
            "E_IS_all_sq: 1.1105457776126258e+78\n",
            "E_s_wdiff_sq: 3.816599982613929e+76\n",
            "E_s_wdiff_all_sq: 1.9361778659960546e+76\n",
            "E_IS_SCOPE: 4.968118083831195e+78\n",
            "E_IS_E_SCOPE: 2.5203480363248868e+78\n",
            "Total Loss: 3.491923658057761e+78\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "Var loss:  tensor(3.5125e+78, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 2.189111377156518e+78\n",
            "E_IS_all_sq: 1.1105457776126258e+78\n",
            "E_s_wdiff_sq: 3.388041749815248e+77\n",
            "E_s_wdiff_all_sq: 1.718768400108009e+77\n",
            "E_IS_SCOPE: 4.382420179036226e+78\n",
            "E_IS_E_SCOPE: 2.2232209271634515e+78\n",
            "Total Loss: 3.5125473511075155e+78\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "Var loss:  tensor(3.6692e+78, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 2.189111377156518e+78\n",
            "E_IS_all_sq: 1.1105457776126258e+78\n",
            "E_s_wdiff_sq: 6.75956175934316e+77\n",
            "E_s_wdiff_all_sq: 3.4291552491667434e+77\n",
            "E_IS_SCOPE: 4.00488545331366e+78\n",
            "E_IS_E_SCOPE: 2.031695909328058e+78\n",
            "Total Loss: 3.6692049541213538e+78\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "Var loss:  tensor(3.6803e+78, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 2.189111377156518e+78\n",
            "E_IS_all_sq: 1.1105457776126258e+78\n",
            "E_s_wdiff_sq: 7.220706934909294e+77\n",
            "E_s_wdiff_all_sq: 3.663096213945515e+77\n",
            "E_IS_SCOPE: 3.931677882629627e+78\n",
            "E_IS_E_SCOPE: 1.9945573884830764e+78\n",
            "Total Loss: 3.6803198928448453e+78\n",
            "----------------------------------------\n",
            "Epoch 11\n",
            "Var loss:  tensor(3.5336e+78, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 2.189111377156518e+78\n",
            "E_IS_all_sq: 1.1105457776126258e+78\n",
            "E_s_wdiff_sq: 4.868817479437429e+77\n",
            "E_s_wdiff_all_sq: 2.469972405182581e+77\n",
            "E_IS_SCOPE: 4.1166676133237e+78\n",
            "E_IS_E_SCOPE: 2.088403488077554e+78\n",
            "Total Loss: 3.533572109902373e+78\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "Var loss:  tensor(3.4017e+78, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 2.189111377156518e+78\n",
            "E_IS_all_sq: 1.1105457776126258e+78\n",
            "E_s_wdiff_sq: 1.987284468083128e+77\n",
            "E_s_wdiff_all_sq: 1.0081581036841473e+77\n",
            "E_IS_SCOPE: 4.443494595961775e+78\n",
            "E_IS_E_SCOPE: 2.2542042460317447e+78\n",
            "Total Loss: 3.401670500180521e+78\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "Var loss:  tensor(3.3985e+78, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 2.189111377156518e+78\n",
            "E_IS_all_sq: 1.1105457776126258e+78\n",
            "E_s_wdiff_sq: 3.458999645442689e+76\n",
            "E_s_wdiff_all_sq: 1.754765650696777e+76\n",
            "E_IS_SCOPE: 4.780224041599195e+78\n",
            "E_IS_E_SCOPE: 2.4250285667825334e+78\n",
            "Total Loss: 3.398517978849109e+78\n",
            "----------------------------------------\n",
            "Epoch 14\n",
            "Var loss:  tensor(3.4694e+78, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 2.189111377156518e+78\n",
            "E_IS_all_sq: 1.1105457776126258e+78\n",
            "E_s_wdiff_sq: 3.5518534860491134e+73\n",
            "E_s_wdiff_all_sq: 1.8018707984767296e+73\n",
            "E_IS_SCOPE: 5.000820518186337e+78\n",
            "E_IS_E_SCOPE: 2.5369381243256224e+78\n",
            "Total Loss: 3.4694277814745597e+78\n",
            "----------------------------------------\n",
            "Epoch 15\n",
            "Var loss:  tensor(3.4859e+78, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 2.189111377156518e+78\n",
            "E_IS_all_sq: 1.1105457776126258e+78\n",
            "E_s_wdiff_sq: 1.817512926761716e+75\n",
            "E_s_wdiff_all_sq: 9.220322590841967e+74\n",
            "E_IS_SCOPE: 5.0314513204822355e+78\n",
            "E_IS_E_SCOPE: 2.5524772643207502e+78\n",
            "Total Loss: 3.4858539604728743e+78\n",
            "----------------------------------------\n",
            "Epoch 16\n",
            "Var loss:  tensor(3.4109e+78, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 2.189111377156518e+78\n",
            "E_IS_all_sq: 1.1105457776126258e+78\n",
            "E_s_wdiff_sq: 1.4570203678674671e+75\n",
            "E_s_wdiff_all_sq: 7.391528053919173e+74\n",
            "E_IS_SCOPE: 4.875517081271722e+78\n",
            "E_IS_E_SCOPE: 2.473371142655284e+78\n",
            "Total Loss: 3.4109433544893506e+78\n",
            "----------------------------------------\n",
            "Epoch 17\n",
            "Var loss:  tensor(3.3171e+78, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 2.189111377156518e+78\n",
            "E_IS_all_sq: 1.1105457776126258e+78\n",
            "E_s_wdiff_sq: 4.278964464883676e+76\n",
            "E_s_wdiff_all_sq: 2.1707373903893155e+76\n",
            "E_IS_SCOPE: 4.5926980439193454e+78\n",
            "E_IS_E_SCOPE: 2.3298958078514863e+78\n",
            "Total Loss: 3.3170639084769608e+78\n",
            "----------------------------------------\n",
            "Epoch 18\n",
            "Var loss:  tensor(3.2821e+78, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 2.189111377156518e+78\n",
            "E_IS_all_sq: 1.1105457776126258e+78\n",
            "E_s_wdiff_sq: 1.619811547258961e+77\n",
            "E_s_wdiff_all_sq: 8.217374834975841e+76\n",
            "E_IS_SCOPE: 4.270314000634233e+78\n",
            "E_IS_E_SCOPE: 2.1663489724660645e+78\n",
            "Total Loss: 3.2821278381400607e+78\n",
            "----------------------------------------\n",
            "Epoch 19\n",
            "Var loss:  tensor(3.3056e+78, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 2.189111377156518e+78\n",
            "E_IS_all_sq: 1.1105457776126258e+78\n",
            "E_s_wdiff_sq: 3.1442128569409736e+77\n",
            "E_s_wdiff_all_sq: 1.5950729361622226e+77\n",
            "E_IS_SCOPE: 4.000625227609234e+78\n",
            "E_IS_E_SCOPE: 2.0295346781921684e+78\n",
            "Total Loss: 3.305633305879953e+78\n",
            "----------------------------------------\n",
            "Epoch 20\n",
            "Var loss:  tensor(3.3222e+78, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 2.189111377156518e+78\n",
            "E_IS_all_sq: 1.1105457776126258e+78\n",
            "E_s_wdiff_sq: 4.016609677529607e+77\n",
            "E_s_wdiff_all_sq: 2.037643659418479e+77\n",
            "E_IS_SCOPE: 3.85272008825822e+78\n",
            "E_IS_E_SCOPE: 1.954501754007675e+78\n",
            "Total Loss: 3.3221614817902695e+78\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[ 0.1494,  0.3235],\n",
            "        [-0.4772, -0.2132],\n",
            "        [-0.2447, -0.3008],\n",
            "        [-0.0972,  0.2482],\n",
            "        [-0.6291, -0.3313],\n",
            "        [ 0.6678,  0.4458],\n",
            "        [-0.0978, -0.0088],\n",
            "        [-0.6612, -0.0090],\n",
            "        [ 0.5813, -0.2481],\n",
            "        [ 0.4297,  0.1741],\n",
            "        [-0.1446,  0.3074],\n",
            "        [ 0.4882,  0.4010],\n",
            "        [ 0.3449,  0.0306],\n",
            "        [-0.0714, -0.3128],\n",
            "        [-0.5226, -0.0293],\n",
            "        [ 0.3826,  0.3302]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([-0.2143, -0.1456,  0.2308, -0.3326, -0.1936,  0.5699, -0.0265, -0.2574,\n",
            "         0.1725,  0.4097, -0.5397, -0.1018, -0.0712,  0.4128,  0.6681,  0.5178],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[-1.7493e-01,  2.4497e-01,  7.9690e-02, -1.3599e-01, -1.5304e-01,\n",
            "          2.1388e-01, -1.5173e-01, -1.3753e-01,  1.7014e-01, -4.9458e-02,\n",
            "          1.1134e-01, -1.0593e-01,  3.9395e-01,  1.0046e-02, -2.7846e-01,\n",
            "         -1.4099e-01],\n",
            "        [ 1.8055e-01,  4.6963e-02,  7.4367e-02, -2.7511e-02, -4.6318e-02,\n",
            "          5.3624e-02,  2.2984e-02,  1.5579e-01,  2.3899e-02, -1.5721e-01,\n",
            "          2.4873e-01, -2.2942e-01, -2.1055e-01, -2.2316e-02, -1.1666e-01,\n",
            "          1.0100e-01],\n",
            "        [-2.8891e-02,  9.3791e-02,  2.5044e-03, -6.7609e-02,  2.4764e-01,\n",
            "         -4.7847e-02, -1.1119e-01, -4.8219e-02,  1.9453e-01, -1.1918e-01,\n",
            "          1.6467e-01, -1.1054e-01,  2.1823e-01, -9.8533e-02, -1.9726e-01,\n",
            "         -5.6995e-02],\n",
            "        [-1.8868e-01,  2.2140e-01, -4.9561e-02,  9.4256e-03, -2.1267e-01,\n",
            "          1.3736e-01,  7.3755e-03,  2.3710e-02,  1.6666e-01, -3.4240e-05,\n",
            "          1.9518e-01,  2.4554e-02, -2.6986e-01,  1.9466e-01, -2.4637e-01,\n",
            "         -2.0253e-01],\n",
            "        [ 1.2436e-01, -1.2100e-01,  7.6264e-02, -1.7594e-01,  2.1008e-01,\n",
            "         -9.6830e-02,  1.8012e-01,  7.5463e-02,  1.7006e-01, -1.4880e-02,\n",
            "          1.8911e-01,  1.6330e-01, -3.7995e-02,  1.1680e-01,  9.1897e-02,\n",
            "          1.3103e-01],\n",
            "        [-8.8471e-02, -7.0448e-03,  1.1167e-01,  7.5007e-02,  2.0969e-01,\n",
            "         -7.2922e-02, -5.2013e-02, -5.3915e-02, -2.0506e-01,  9.9985e-02,\n",
            "          1.0600e-02,  1.1971e-01, -1.3356e-01, -8.9629e-02,  3.7689e-01,\n",
            "         -1.2952e-02],\n",
            "        [-1.0050e-01, -6.3672e-02,  2.0884e-01,  8.2197e-02, -2.1761e-01,\n",
            "         -1.3108e-01,  3.2806e-02, -1.9561e-01, -1.4036e-01,  1.9051e-01,\n",
            "          8.7938e-02,  2.0692e-01,  7.6207e-02,  1.8118e-01,  6.5414e-03,\n",
            "          3.0283e-02],\n",
            "        [ 2.6131e-01, -2.0211e-01, -2.0206e-03,  1.6582e-01,  1.8593e-01,\n",
            "          2.7924e-02,  4.9513e-02, -2.7487e-02,  1.4616e-01, -7.1783e-02,\n",
            "         -1.0726e-01, -1.9574e-01,  5.7174e-02,  9.6236e-02, -2.9006e-01,\n",
            "         -2.9770e-01],\n",
            "        [-1.9382e-01,  1.1349e-01, -1.3734e-01,  1.7534e-01,  1.2164e-01,\n",
            "         -7.3879e-02,  1.0755e-01, -1.5085e-01, -1.6948e-01,  2.0657e-02,\n",
            "          2.7259e-01, -2.5322e-01,  8.3883e-02, -1.7711e-01,  2.7465e-01,\n",
            "         -8.1249e-02],\n",
            "        [-1.6789e-01, -8.3078e-02, -1.5958e-01,  1.4855e-01, -3.4678e-02,\n",
            "         -2.0794e-01, -1.4185e-01, -6.2943e-02, -2.1014e-01, -2.2462e-01,\n",
            "         -2.5808e-01, -1.6418e-02,  2.1944e-01,  2.4399e-01, -2.5703e-01,\n",
            "          1.2234e-01],\n",
            "        [-1.2067e-01, -1.8831e-02,  7.6804e-02, -1.3005e-01,  1.6436e-01,\n",
            "         -1.6100e-01, -2.3486e-01,  2.8156e-02, -1.1161e-01, -1.2722e-02,\n",
            "          1.6655e-02, -1.7436e-01, -2.2360e-01, -1.0990e-01, -2.1919e-01,\n",
            "         -1.6364e-01],\n",
            "        [ 1.1022e-01,  1.8837e-01,  2.1493e-02, -1.8416e-01, -3.1379e-02,\n",
            "         -1.3146e-01, -1.7114e-01,  1.7575e-02, -2.0458e-01,  1.2273e-01,\n",
            "          1.9864e-01,  1.4539e-01, -2.8215e-02, -2.4538e-01,  3.0965e-01,\n",
            "          1.9255e-01],\n",
            "        [ 1.7856e-01,  1.4603e-01,  2.3590e-01, -1.2325e-01, -6.5662e-03,\n",
            "          1.4069e-01, -9.6993e-02,  2.1491e-01,  1.6861e-01,  1.0808e-01,\n",
            "          1.5395e-01,  2.2570e-01,  6.1711e-02,  1.4988e-01, -6.5206e-02,\n",
            "          2.9402e-01],\n",
            "        [-1.7453e-01,  1.9261e-01, -2.0682e-01, -1.1618e-02, -1.1209e-01,\n",
            "          1.3718e-01,  1.7208e-01, -5.5587e-02,  1.6460e-01,  2.3912e-01,\n",
            "          9.7144e-02,  1.9965e-01,  1.5052e-02, -1.0464e-01,  3.8533e-01,\n",
            "          2.3401e-01],\n",
            "        [ 2.0283e-01, -2.1112e-01, -1.6540e-01,  1.9445e-01, -3.2534e-02,\n",
            "          1.7492e-01, -1.1893e-01,  3.9980e-02,  7.1071e-02, -9.4498e-02,\n",
            "          2.1906e-01, -3.1927e-02, -1.9965e-01, -2.1334e-01, -1.7636e-01,\n",
            "          1.7358e-01],\n",
            "        [-1.4954e-01,  2.1518e-01, -4.7475e-02, -1.7053e-01, -1.7777e-01,\n",
            "          4.9989e-02, -1.0984e-01, -5.2646e-02,  2.3072e-02,  1.9431e-01,\n",
            "          3.5533e-02,  4.4179e-02, -2.3469e-01,  1.0713e-01,  1.3766e-01,\n",
            "          1.3763e-01],\n",
            "        [ 2.5018e-01, -6.4112e-02, -2.4942e-01,  3.3737e-02, -1.3001e-01,\n",
            "         -2.2515e-01,  1.4501e-03,  2.2288e-01, -3.1270e-02, -7.0728e-02,\n",
            "         -1.6216e-01,  1.7884e-01, -1.7303e-01, -7.4084e-02,  3.2593e-01,\n",
            "         -2.1508e-01],\n",
            "        [ 1.1584e-01,  2.0980e-02, -4.1659e-02,  5.3515e-02,  1.7407e-01,\n",
            "         -4.1308e-02,  1.6735e-02, -1.9070e-01, -1.1419e-02, -2.0429e-02,\n",
            "          1.5776e-01,  2.1641e-01, -1.0512e-01,  1.5398e-01, -3.5251e-02,\n",
            "          2.1929e-01],\n",
            "        [-7.5010e-02,  2.6068e-02, -1.9934e-01,  1.5249e-02,  8.9669e-02,\n",
            "         -7.8493e-02, -1.7770e-01,  1.7042e-01,  7.1670e-02, -6.3168e-02,\n",
            "          1.2933e-01,  2.7374e-02, -2.3743e-01, -1.2070e-01, -8.0870e-02,\n",
            "          2.3913e-01],\n",
            "        [-2.1135e-03,  1.4448e-01,  1.3029e-02, -1.5678e-01,  2.1886e-01,\n",
            "         -1.9954e-02,  1.3096e-01,  4.9577e-03, -3.4040e-01, -1.6206e-01,\n",
            "         -1.5033e-01,  1.2966e-01,  1.7468e-01,  2.7925e-03, -2.4112e-01,\n",
            "          1.0162e-02],\n",
            "        [-2.4484e-01, -1.9311e-01,  1.8789e-01,  2.0393e-01, -2.3468e-01,\n",
            "         -1.2510e-01,  2.0174e-01,  6.2812e-03, -3.5653e-01, -1.3851e-02,\n",
            "         -3.3112e-01,  1.3665e-02, -4.7856e-02,  1.9215e-01, -9.8527e-02,\n",
            "         -1.2637e-01],\n",
            "        [-6.3456e-02, -1.5999e-01,  2.2066e-01,  4.3840e-02, -9.8037e-02,\n",
            "         -1.8578e-01, -1.2493e-01, -1.9014e-01, -8.4465e-02, -2.0922e-01,\n",
            "         -1.5823e-03, -1.5930e-01,  2.7573e-01, -2.0319e-01, -1.5342e-01,\n",
            "          5.4162e-02],\n",
            "        [ 1.5812e-01,  3.0146e-02, -1.3203e-01, -1.9513e-01, -2.3398e-02,\n",
            "         -1.1185e-01,  8.0136e-02, -6.9907e-02,  3.0372e-02, -1.6118e-01,\n",
            "          1.1515e-01,  2.1040e-01, -1.0613e-02,  2.3637e-01, -2.5356e-01,\n",
            "          1.1124e-01],\n",
            "        [-2.3585e-01,  1.9899e-01,  8.1676e-04,  9.4500e-02, -1.5707e-01,\n",
            "          1.4368e-01,  1.9287e-03,  7.7264e-02, -9.0661e-02, -7.5695e-02,\n",
            "          4.7436e-02, -1.8603e-01, -3.0229e-02,  2.0812e-01, -5.6777e-02,\n",
            "          5.1993e-02],\n",
            "        [-9.3987e-02,  9.2772e-02, -8.4065e-02, -1.8552e-01,  7.1155e-02,\n",
            "          9.2420e-02, -1.8668e-01,  1.2938e-01, -2.2547e-01, -1.6376e-01,\n",
            "          2.4216e-01,  9.6841e-02, -2.5713e-01, -1.5210e-01,  2.7194e-01,\n",
            "          7.2975e-03],\n",
            "        [-1.5141e-01,  1.3956e-01,  1.7355e-01, -1.5433e-01, -1.3408e-02,\n",
            "          9.6488e-02,  1.2266e-01, -1.6204e-02, -2.3391e-01, -1.8115e-01,\n",
            "          7.4827e-02,  1.1485e-01,  1.1492e-01,  2.2648e-01,  1.6150e-01,\n",
            "          2.3990e-01],\n",
            "        [-6.5113e-02,  2.0003e-01, -1.7170e-01,  9.3744e-02,  2.7409e-02,\n",
            "         -1.5627e-01, -6.4196e-02, -1.7263e-01,  7.3803e-02,  1.4941e-01,\n",
            "         -2.3925e-01, -1.5477e-01, -2.9391e-01, -2.2497e-01,  2.3228e-01,\n",
            "         -5.3550e-02],\n",
            "        [-3.6098e-02, -2.0078e-01, -1.5989e-01,  1.1906e-01, -1.6843e-01,\n",
            "          2.1627e-01, -1.4943e-01, -1.6188e-01,  1.6535e-01,  2.2528e-01,\n",
            "          2.5231e-01, -1.7606e-01,  1.5234e-01,  1.4328e-01,  2.5229e-01,\n",
            "         -8.6871e-02],\n",
            "        [ 8.4516e-02,  1.2684e-01,  5.1654e-02,  1.5533e-01, -3.1614e-02,\n",
            "          5.0763e-02, -1.6944e-01, -4.7434e-02, -1.5313e-01,  2.4590e-02,\n",
            "          1.9616e-01, -1.5684e-02,  2.2196e-01,  2.2278e-01, -2.0419e-01,\n",
            "         -6.7439e-02],\n",
            "        [-1.5808e-01, -2.2222e-01,  2.1659e-01,  8.8525e-02, -1.9841e-02,\n",
            "          7.4530e-02, -1.2119e-01,  1.2869e-02, -4.6774e-03, -3.4407e-01,\n",
            "         -2.5325e-01, -7.3243e-02,  3.3671e-03, -2.3881e-02,  2.6434e-01,\n",
            "          1.1801e-01],\n",
            "        [-1.1314e-01, -5.2173e-02, -1.0223e-01,  8.4181e-02, -7.0907e-02,\n",
            "          1.9636e-01,  2.9293e-02, -6.8984e-02,  1.3013e-01,  8.2903e-03,\n",
            "          1.7520e-01, -2.0122e-01,  1.1931e-02, -1.4239e-01,  2.9343e-01,\n",
            "          2.8269e-01],\n",
            "        [-1.7643e-01, -9.0866e-02, -6.1464e-02,  2.7443e-02,  2.1739e-01,\n",
            "          8.5679e-02,  2.0109e-01,  1.7199e-01,  2.5223e-01, -2.4822e-01,\n",
            "         -2.0023e-01,  2.9576e-02, -1.0572e-01, -8.5924e-02,  2.1456e-01,\n",
            "         -1.3494e-01]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([-0.1841,  0.1109, -0.2156,  0.0433,  0.1517, -0.0382, -0.1418,  0.0457,\n",
            "         0.1472,  0.0659, -0.0399, -0.1983, -0.0019,  0.1809, -0.0839,  0.2237,\n",
            "         0.2276, -0.0731, -0.1763,  0.1248,  0.1379,  0.0462,  0.0472,  0.0135,\n",
            "        -0.0607,  0.1144,  0.0952,  0.1295, -0.2452, -0.0999,  0.1983,  0.1670],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[ 0.1378, -0.0146, -0.0600, -0.0653,  0.1354,  0.0506,  0.0458,  0.1855,\n",
            "         -0.0196,  0.0415, -0.1237,  0.0366,  0.1875,  0.1184, -0.0775, -0.1298,\n",
            "          0.0445,  0.0703, -0.0966,  0.0326,  0.0641,  0.0591, -0.1482,  0.0063,\n",
            "          0.0598, -0.0508,  0.0154,  0.0272, -0.0243, -0.0707,  0.1977, -0.0599]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([-0.1026], dtype=torch.float64)\n"
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Working on prep"
      ],
      "metadata": {
        "id": "O36PGywGna2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Working on padding trajectories to allow for easier optimization\n",
        "\n",
        "# def pad_trajectories(pi_b):\n",
        "#     # Find the maximum length among all trajectories\n",
        "#     max_length = max(len(traj) for traj in pi_b)\n",
        "\n",
        "#     # Define the padding value\n",
        "#     padding_value = np.array([np.array([0, 0]), 0, 0, np.array([0, 0]), 0, 0], dtype=object)\n",
        "\n",
        "#     # Pad each trajectory to match the maximum length\n",
        "#     padded_pi_b = [traj + [padding_value] * (max_length - len(traj)) for traj in pi_b]\n",
        "\n",
        "#     return padded_pi_b"
      ],
      "metadata": {
        "id": "ErjhWCq3czmx"
      },
<<<<<<< HEAD
      "execution_count": null,
=======
      "execution_count": 22,
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pi_b_padded = pad_trajectories(pi_b)"
      ],
      "metadata": {
        "id": "31TWTP7Eb1sC"
      },
<<<<<<< HEAD
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def variance_terms_tens(eval_policy, behav_policy, behavior_policies):\n",
        "  # Initialize lists to store axis data for each policy\n",
        "  timesteps = []\n",
        "  states = []\n",
        "  state_first = []\n",
        "  state_last = []\n",
        "  actions = []\n",
        "  rewards = []\n",
        "  gamma_last = []\n",
        "  weight_last = []\n",
        "  weights = calculate_importance_weights(eval_policy, behav_policy, behavior_policies)\n",
        "  psi = []\n",
        "\n",
        "  for index, policy in enumerate(behavior_policies):\n",
        "      policy_array = np.array(policy)\n",
        "      timesteps.append(policy_array[:, 4].astype(int))\n",
        "      # s.append(policy_array[:, 0])\n",
        "\n",
        "      # last timestep for gamma\n",
        "      gamma_last.append(len(policy))\n",
        "      # last importance weight\n",
        "      weight_last.append(weights[index][-1])\n",
        "\n",
        "\n",
        "      states.append(policy_array[:, 0][1:])\n",
        "      psi.append(policy_array[:,5][1:])\n",
        "      state_first.append(policy_array[:,0][0])\n",
        "      state_last.append(policy_array[:,0][-1])\n",
        "      actions.append(policy_array[:, 1])\n",
        "      rewards.append(policy_array[:, 2].astype(float))\n",
        "\n",
        "  weights_difference = []\n",
        "  for index, weight in enumerate(weights):\n",
        "    # diff = np.array(w[index][:-1]) - np.array(w[index][1:])\n",
        "    diff = np.array(weight[:-1]) - np.array(weight[1:])\n",
        "    weights_difference.append(diff)\n",
        "\n",
        "  return timesteps, states, state_first, state_last, actions, rewards, gamma_last, weight_last, weights, weights_difference"
      ],
      "metadata": {
        "id": "Kcx483JVfDWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# t, s, s_f, s_l, a, r, g_l, w_l, w, w_diff = variance_terms_tens(P_pi_e, P_pi_b, pi_b)"
      ],
      "metadata": {
        "id": "q8d3KfusfsZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "timesteps, states, states_first, states_last, actions, rewards, gamma_last, weights_last, weights, weights_difference = variance_terms_tens(P_pi_e, P_pi_b, pi_b)"
      ],
      "metadata": {
        "id": "BAqNV3alEAjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def padding_IS_terms(timesteps, actions, rewards, weights):\n",
        "    # Find the maximum length among all lists\n",
        "    max_length = max(len(traj) for traj in timesteps)\n",
        "\n",
        "    # Define the padding values\n",
        "    zero_padding = 0\n",
        "\n",
        "    # Pad each list to match the maximum length\n",
        "    padded_timesteps = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in timesteps]\n",
        "    padded_rewards = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in rewards]\n",
        "    padded_actions = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in actions]\n",
        "    padded_weights = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in weights]\n",
        "\n",
        "    return padded_timesteps, padded_rewards, padded_actions, padded_weights"
      ],
      "metadata": {
        "id": "AuuBKl0joAEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_timesteps, padded_rewards, padded_actions, padded_weights = padding_IS_terms(timesteps, actions, rewards, weights)"
      ],
      "metadata": {
        "id": "xD675spBnrP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def padding_states_weights_difference(states, weights_difference):\n",
        "    # Find the maximum length of trajectories\n",
        "    max_length = max(len(trajectory) for trajectory in states)\n",
        "\n",
        "    zero_padding = 0\n",
        "\n",
        "    # Pad each trajectory to make them all the same length\n",
        "    padded_states = [\n",
        "        [list(item) for item in trajectory] + [[0, 0]] * (max_length - len(trajectory))\n",
        "        for trajectory in states\n",
        "    ]\n",
        "\n",
        "    padded_weights_difference = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in weights_difference]\n",
        "\n",
        "    return padded_states, padded_weights_difference"
      ],
      "metadata": {
        "id": "4DekSrOTzLAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_states, padded_weights_difference = padding_states_weights_difference(states, weights_difference)"
      ],
      "metadata": {
        "id": "aX6DIhEQTCVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tensorize_padded_terms(padded_states, padded_weights_difference):\n",
        "  padded_state_tensors = torch.tensor(padded_states, dtype = torch.float64)\n",
        "  padded_weight_diff_tensors = torch.tensor(padded_weights_difference, dtype = torch.float64)\n",
        "  padded_weight_diff_tensors = padded_weight_diff_tensors.unsqueeze(-1)\n",
        "\n",
        "  return padded_state_tensors, padded_weight_diff_tensors\n"
      ],
      "metadata": {
        "id": "hHZhHnuUzHFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_state_tensors, padded_weight_diff_tensors = tensorize_padded_terms(padded_states, padded_weights_difference)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5kb1vOxTZSu",
        "outputId": "6b5b983d-35ca-4d5f-9ff4-1cba9d74450b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-3c22136e8020>:3: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  padded_weight_diff_tensors = torch.tensor(padded_weights_difference, dtype = torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tensorize_last_and_first_terms(states_first, states_last, gamma_last, weights_last):\n",
        "  states_first_tensor = torch.tensor(states_first, dtype = torch.float64)\n",
        "  states_last_tensor = torch.tensor(states_last, dtype = torch.float64)\n",
        "  gamma_last_tensor = torch.tensor(gamma_last, dtype = torch.float64)\n",
        "  weights_last_tensor = torch.tensor(weights_last, dtype = torch.float64)\n",
        "\n",
        "  return states_first_tensor, states_last_tensor, gamma_last_tensor, weights_last_tensor"
      ],
      "metadata": {
        "id": "AqtoK6MEmPWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "states_first_tensor, states_last_tensor, gamma_last_tensor, weights_last_tensor = tensorize_last_and_first_terms(states_first, states_last, gamma_last, weights_last)"
      ],
      "metadata": {
        "id": "gvE-AddhDTkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_IS_terms(gamma, timesteps, rewards, weights):\n",
        "  gtrw = np.power(gamma, timesteps)*rewards*weights\n",
        "\n",
        "  IS_tensor = torch.sum(torch.tensor(gtrw, dtype = torch.float32), dim = 1, keepdim = True)\n",
        "\n",
        "  return IS_tensor\n"
      ],
      "metadata": {
        "id": "YVpa0bTwd3HX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IS_tensor = calc_IS_terms(0.9, padded_timesteps, padded_rewards, padded_weights)"
      ],
      "metadata": {
        "id": "xjRU7xlj89PY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.finfo(torch.float64).max"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGtcFc-YY9SK",
        "outputId": "ce82a7a6-848c-4034-f260-6a3bf7702324"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.7976931348623157e+308"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# samples_IS[0]"
      ],
      "metadata": {
        "id": "s_JAi7apXuJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_gamma_weight_last(gamma, gamma_last, weights_last):\n",
        "  gamma_weight_last = np.power(gamma, gamma_last)*weights_last\n",
        "\n",
        "  gamma_weight_last_tensor = torch.tensor(gamma_weight_last, dtype = torch.float64).unsqueeze(-1)\n",
        "\n",
        "  return gamma_weight_last_tensor"
      ],
      "metadata": {
        "id": "8I3qisEpsYzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gamma_weights_last_tensor = calc_gamma_weight_last(0.9, gamma_last, weights_last)"
      ],
      "metadata": {
        "id": "XHDztxg4C3So"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bootstrap_IS_terms(IS_tensor, num_samples):\n",
        "  seed = 42\n",
        "  torch.manual_seed(seed)\n",
        "\n",
        "  num_bootstraps = num_samples*len(IS_tensor)\n",
        "\n",
        "  # Sample indices with replacement\n",
        "  sampled_indices = torch.randint(0, len(IS_tensor), size=(num_bootstraps,), dtype=torch.long)\n",
        "\n",
        "  # new_size = (num_samples, IS_tensor.shape[0], IS_tensor.shape[1])\n",
        "  new_size = (num_samples, IS_tensor.shape[0])\n",
        "\n",
        "  IS_bootstraps = IS_tensor[sampled_indices].view(new_size)\n",
        "\n",
        "  # sampled_tensor = IS_bootstraps.view(new_size)\n",
        "\n",
        "  return IS_bootstraps"
      ],
      "metadata": {
        "id": "rdqtMRAT35lW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples_IS = bootstrap_IS_terms(IS_tensor, 10000)"
      ],
      "metadata": {
        "id": "MHOyNeJ-UdcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clamp_large_terms(input_term):\n",
        "  max_float64 = torch.finfo(torch.float64).max\n",
        "  return torch.clamp(input_term, min=-max_float64, max=max_float64)\n"
      ],
      "metadata": {
        "id": "ng9lLOfsGvdb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clamp_large_terms(input_term):\n",
        "    max_float64 = torch.tensor(torch.finfo(torch.float64).max, dtype=torch.float64)\n",
        "    min_value = torch.tensor(-1e50, dtype=torch.float64)\n",
        "    return torch.clamp(input_term, min=min_value, max=max_float64)\n",
        "\n",
        "    # return torch.clamp(input_term, min=-max_float64, max=max_float64)\n"
      ],
      "metadata": {
        "id": "C1Su5BQ0cfUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CustomizableFeatureNet_d(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dims, output_dim, dropout_prob=0.2, dtype=torch.float32):\n",
        "        super(CustomizableFeatureNet_d, self).__init__()\n",
        "        self.hidden_layers = nn.ModuleList()\n",
        "\n",
        "        # Create the hidden layers based on the provided sizes\n",
        "        for in_dim, out_dim in zip([input_dim] + hidden_dims, hidden_dims):\n",
        "            self.hidden_layers.append(nn.Linear(in_dim, out_dim).to(dtype))\n",
        "\n",
        "        self.output_layer = nn.Linear(hidden_dims[-1], output_dim).to(dtype)\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.hidden_layers:\n",
        "            x = F.relu(layer(x))\n",
        "            x = self.dropout(x)\n",
        "        x = self.output_layer(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "YFqvRa0LS7OF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CustomizableFeatureNet_d(input_dim=2, hidden_dims=[16, 32], output_dim=1, dtype = torch.float64)"
      ],
      "metadata": {
        "id": "udif1c2cTBzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = CustomizableFeatureNet(input_dim=2, hidden_dims=[16, 32], output_dim=1)"
      ],
      "metadata": {
        "id": "ct8DQIU6rUvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pass_states(model, padded_state_tensors, states_first_tensor, states_last_tensor):\n",
        "  # Get model outputs for states\n",
        "  states_output = model(padded_state_tensors)\n",
        "  states_first_output = model(states_first_tensor)\n",
        "  states_last_output = model(states_last_tensor)\n",
        "  return states_output, states_first_output, states_last_output"
      ],
      "metadata": {
        "id": "0JNHRYkBmZ5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "states_output, states_first_output, states_last_output = pass_states(model, padded_state_tensors, states_first_tensor, states_last_tensor)"
      ],
      "metadata": {
        "id": "duNRe00YE34A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def states_weight_diff_sums(states_output, padded_weight_diff_tensors):\n",
        "  states_weight_diff = states_output * padded_weight_diff_tensors\n",
        "  sums_states_weight_diff = torch.sum(states_weight_diff, dim =1)\n",
        "\n",
        "  return sums_states_weight_diff"
      ],
      "metadata": {
        "id": "8nZkrdWPW5AQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sums_states_weight_diff = states_weight_diff_sums(states_output, padded_weight_diff_tensors)"
      ],
      "metadata": {
        "id": "nlxvS4QpYW0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def last_first_terms_operations(gamma_weights_last_tensor, states_last_output, states_first_output):\n",
        "  gamma_weights_states_last_sub_states_first = gamma_weights_last_tensor*states_last_output -  states_first_output\n",
        "\n",
        "  return gamma_weights_states_last_sub_states_first"
      ],
      "metadata": {
        "id": "fDDD0NcUaxpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gamma_weights_states_last_sub_states_first = last_first_terms_operations(gamma_weights_last_tensor, states_last_output, states_first_output)"
      ],
      "metadata": {
        "id": "ScpV8dhaCqHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gamma_weights_states_last_sub_states_first.shape"
      ],
      "metadata": {
        "id": "oC-P2rDqFIwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bootstrap_shaping_terms(sums_states_weight_diff, gamma_weights_states_last_sub_states_first, num_samples):\n",
        "\n",
        "  seed = 42\n",
        "  torch.manual_seed(seed)\n",
        "\n",
        "  num_bootstraps = num_samples*sums_states_weight_diff.shape[0]\n",
        "\n",
        "  # Sample indices with replacement\n",
        "  sampled_indices = torch.randint(0, len(sums_states_weight_diff), size=(num_bootstraps,), dtype=torch.long)\n",
        "\n",
        "  # sizes\n",
        "  # size_states_weights_diff = (num_samples, states_output.shape[0], states_output.shape[1])\n",
        "  reshaped_size = (num_samples, sums_states_weight_diff.shape[0])\n",
        "\n",
        "  # Resize samples to shape num_samples x num_trajectories x length_padded_trajectories\n",
        "  # samples_states_output = states_output[sampled_indices].view(size_states_weights_diff)\n",
        "  # samples_weight_diff = padded_weight_diff_tensors[sampled_indices].view(size_states_weights_diff)\n",
        "\n",
        "  # Resize samples to shape num_samples x num_trajectories\n",
        "  sample_sums_states_weight_diff = sums_states_weight_diff[sampled_indices].view(reshaped_size)\n",
        "  # samples_states_first_output = sums_states_weight_diff[sampled_indices].view(reshaped_size)\n",
        "  # samples_states_last_output = states_last_output[sampled_indices].view(reshaped_size)\n",
        "  samples_gamma_weight_states_last_sub_states_first = gamma_weights_states_last_sub_states_first[sampled_indices].view(reshaped_size)\n",
        "\n",
        "\n",
        "  return sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first\n"
      ],
      "metadata": {
        "id": "d3UM9eUGeQdq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first = bootstrap_shaping_terms(sums_states_weight_diff, gamma_weights_states_last_sub_states_first, 10000)"
      ],
      "metadata": {
        "id": "whCU0iyDCi8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def gtrw_plus_states_weight_diff_min_last_firsts_terms(gtrw_tensor, sums_states_weight_diff, gamma_weights_states_last_sub_states_first):\n",
        "#   sum_IS_and_shaping = gtrw_tensor + sums_states_weight_diff + gamma_weights_states_last_sub_states_first\n",
        "\n",
        "#   return sum_IS_and_shaping"
      ],
      "metadata": {
        "id": "sIw1SreEnUpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def bootstrap_IS_shaping_terms(gtrw_tensor, sums_states_weight_diff, gamma_weights_states_last_sub_states_first):\n",
        "#   seed = 42\n",
        "#   torch.manual_seed(seed)\n",
        "\n",
        "#   num_bootstraps = num_samples*sums_states_weight_diff.shape[0]\n",
        "\n",
        "#   # Sample indices with replacement\n",
        "#   sampled_indices = torch.randint(0, len(sums_states_weight_diff), size=(num_bootstraps,), dtype=torch.long)\n",
        "\n"
      ],
      "metadata": {
        "id": "OZHZzE6d58xQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wTVuyCVBB4-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clamp_large_terms(torch.mean(clamp_large_terms(torch.mean(samples_IS, dim = 1))))"
      ],
      "metadata": {
        "id": "tdFIzbNUgx94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clamp_large_terms(torch.mean(clamp_large_terms(torch.mean(samples_IS, dim =1)**2)))"
      ],
      "metadata": {
        "id": "4dLA0DBLh-pV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clamp_large_terms(torch.mean(clamp_large_terms(torch.mean(samples_IS, dim =1))**2) - torch.mean(clamp_large_terms(torch.mean(samples_IS, dim = 1))))"
      ],
      "metadata": {
        "id": "7pfgg5rZlakd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SCOPE = sample_sums_states_weight_diff+samples_gamma_weight_states_last_sub_states_first"
      ],
      "metadata": {
        "id": "MWwuJS4En1ll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.mean(SCOPE,dim =1).shape"
      ],
      "metadata": {
        "id": "ECEj-Lhooh8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mean(clamp_large_terms(samples_IS), dim = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6YXvZmXYUKd",
        "outputId": "d5a030e2-5c73-48bd-b58f-8e4970fbe046"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([      -inf, 2.0056e+14,       -inf,  ...,       -inf,       -inf,\n",
              "        1.0028e+14])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_shaped_variance(samples_IS, sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first):\n",
        "\n",
        "\n",
        "  # states_output, states_first_output, states_last_output = pass_states(model, padded_state_tensors, states_first_tensor, states_last_tensor)\n",
        "\n",
        "\n",
        "\n",
        "  # Begin calcs without clamping\n",
        "\n",
        "  # IS\n",
        "  E_IS_sq = torch.mean(torch.mean(clamp_large_terms(samples_IS), dim = 1)**2)\n",
        "  E_IS_all_sq = torch.mean(torch.mean(clamp_large_terms(samples_IS), dim = 1))**2\n",
        "\n",
        "  # states_weight_diff\n",
        "  E_s_wdiff_sq = torch.mean(torch.mean(clamp_large_terms(sample_sums_states_weight_diff), dim =1)**2)\n",
        "  E_s_wdiff_all_sq = torch.mean(torch.mean(clamp_large_terms(sample_sums_states_weight_diff), dim = 1))**2\n",
        "\n",
        "  # all terms\n",
        "  SCOPE = clamp_large_terms(sample_sums_states_weight_diff)+clamp_large_terms(samples_gamma_weight_states_last_sub_states_first)\n",
        "  E_IS_SCOPE = torch.mean(torch.mean(clamp_large_terms(samples_IS), dim =1) * torch.mean(SCOPE, dim =1))\n",
        "  E_IS_E_SCOPE = torch.mean(torch.mean(clamp_large_terms(samples_IS),dim = 1 ))*torch.mean(torch.mean(SCOPE, dim =1))\n",
        "\n",
        "  SCOPE_variance = E_IS_sq + 2*E_IS_SCOPE + E_s_wdiff_sq - E_IS_all_sq - 2*E_IS_E_SCOPE - E_IS_E_SCOPE\n",
        "\n",
        "  IS_variance = E_IS_sq - E_IS_all_sq\n",
        "\n",
        "  return IS_variance, SCOPE_variance\n"
      ],
      "metadata": {
        "id": "LLuzewmQ3DR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IS_variance, SCOPE_variance = calculate_shaped_variance(samples_IS, sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first)"
      ],
      "metadata": {
        "id": "Nz9ApTk-qnx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mean(torch.mean(clamp_large_terms(samples_IS), dim = 1)**2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qN1zDrJWo4wZ",
        "outputId": "548dc965-3831-4791-9077-d8d8de7062d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(inf)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SCOPE_variance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBjjOVEggKhd",
        "outputId": "fdeba7f8-0ed2-498d-f842-25fe37e45dcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(nan, dtype=torch.float64, grad_fn=<SubBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IS_variance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyMAdyWjgb4b",
        "outputId": "fcadf31c-726b-4846-b87e-576e2d0c1d59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(nan)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def clamp_large_terms(input_term):\n",
        "    max_float64 = torch.tensor(torch.finfo(torch.float64).max, dtype=torch.float64)\n",
        "    # min_value = torch.tensor(-1e38, dtype=torch.float64)\n",
        "    min_value = torch.tensor(-9e-38, dtype=torch.float64)\n",
        "\n",
        "    # min_value = torch.tensor(-1.7e+308, dtype = torch.float64)\n",
        "    # min_value = torch.tensor(torch.finfo(torch.float64).min, dtype=torch.float64)\n",
        "\n",
        "\n",
        "    # Using torch.where to explicitly set values outside the desired range\n",
        "    clamped_result = torch.where(input_term < min_value, min_value, input_term)\n",
        "    clamped_result = torch.where(clamped_result > max_float64, max_float64, clamped_result)\n",
        "\n",
        "    return clamped_result\n",
        "clamp_large_terms(samples_IS)[0].min()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDs0epOwdjjK",
        "outputId": "70d2de61-11b2-465f-a114-7527e815ead9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-9.0000e-38)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "samples_IS[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGlLqnsIhLAr",
        "outputId": "dbacfd91-4d5b-48ae-8d2b-c36b24042d6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.0000e+00, -9.5567e-34, -1.1020e-12, -5.7703e-20,  0.0000e+00,\n",
              "        -6.6609e-06,  0.0000e+00,  0.0000e+00,  0.0000e+00, -7.4562e-17,\n",
              "        -1.3518e-33, -6.3068e-29, -1.1566e-08,  0.0000e+00, -3.2522e-24,\n",
              "         0.0000e+00,  0.0000e+00, -4.0924e-02,  0.0000e+00,  0.0000e+00,\n",
              "        -6.0833e-21, -1.1020e-12,  0.0000e+00, -3.5032e-43, -3.4013e-37,\n",
              "        -7.9832e-23,  0.0000e+00, -2.2156e-12,  0.0000e+00, -7.3671e-27,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -3.0953e-12,  0.0000e+00, -7.1745e-11,  0.0000e+00,\n",
              "        -1.2184e+02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -4.8370e-19,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -1.7865e-25, -3.0953e-12, -3.1972e-14,\n",
              "         0.0000e+00, -3.9939e-21,  0.0000e+00, -4.2383e-17,  0.0000e+00,\n",
              "         0.0000e+00, -9.5567e-34,  0.0000e+00,  0.0000e+00, -5.4262e-07,\n",
              "        -3.7487e-37, -2.6165e-41,  0.0000e+00, -1.0701e-07,  0.0000e+00,\n",
              "         0.0000e+00, -6.6945e-22,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -1.3046e-34, -1.7190e-19,  0.0000e+00,\n",
              "         9.6867e-18, -4.6108e-20,  1.3313e-32, -4.5634e-22,  0.0000e+00,\n",
              "         0.0000e+00, -1.9068e-20, -3.2430e-22, -8.2104e-17,  0.0000e+00,\n",
              "        -1.0108e-29,  0.0000e+00, -8.4772e-20,  0.0000e+00, -2.0319e-39,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -6.3362e-38,  0.0000e+00,\n",
              "         4.7220e-16,  0.0000e+00, -1.5748e-17,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -1.3046e-34,  3.4275e-23,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.2642e-11,\n",
              "        -2.0774e-08,  0.0000e+00, -2.4060e-40, -3.5032e-43,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "        -9.3884e-01, -8.4772e-20, -2.5036e-39,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -1.3247e-35,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -3.8730e-15, -1.0150e-03, -2.0038e-36,  0.0000e+00,\n",
              "         0.0000e+00, -8.4655e-19,  0.0000e+00, -7.3035e-20, -6.6609e-06,\n",
              "         0.0000e+00,  0.0000e+00, -1.6692e-14, -2.6013e-38,  0.0000e+00,\n",
              "         0.0000e+00, -5.6024e-35, -4.5634e-22,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -2.8727e-10, -2.2156e-12,\n",
              "         0.0000e+00,  0.0000e+00,  5.1149e-40,  0.0000e+00,  0.0000e+00,\n",
              "        -1.3400e-08,  0.0000e+00, -2.6687e-08,  0.0000e+00, -4.5020e-30,\n",
              "        -1.0701e-07, -1.0052e-13,  0.0000e+00,  0.0000e+00, -4.5720e-36,\n",
              "        -2.7511e-36,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -9.6992e-23,  0.0000e+00,  0.0000e+00,  1.1169e-32,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -1.2418e-12,  3.4265e-14,\n",
              "         0.0000e+00,  0.0000e+00, -1.6255e-43, -1.1568e-11,  0.0000e+00,\n",
              "        -2.5918e-04, -4.2958e-02, -1.4635e-26,  0.0000e+00, -8.7134e-11,\n",
              "         3.6282e-29,  0.0000e+00,  0.0000e+00, -1.2983e-17,  0.0000e+00,\n",
              "         0.0000e+00, -1.2418e-12, -1.6759e-21,  0.0000e+00,  0.0000e+00,\n",
              "        -1.9035e-38, -2.1801e-26,  0.0000e+00, -1.2909e-23, -4.1059e-16,\n",
              "        -2.4789e-27, -1.0616e-20,  0.0000e+00, -2.5688e-29, -5.9457e-04,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -1.4309e-17,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "        -3.0097e+06,  0.0000e+00, -3.9645e-25, -8.8058e-20,  1.9898e-43,\n",
              "        -2.2156e-12,  0.0000e+00,  0.0000e+00, -3.8730e-15,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -2.4202e-34,  0.0000e+00,  0.0000e+00, -3.2028e-23,\n",
              "         0.0000e+00,  0.0000e+00, -3.9735e-34,  0.0000e+00, -3.8966e-08,\n",
              "         0.0000e+00, -2.2030e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -3.5367e-40,  0.0000e+00,  0.0000e+00,\n",
              "        -7.4222e-38,  0.0000e+00,  0.0000e+00, -9.4159e-16,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -2.1972e-42, -8.4772e-20,  0.0000e+00,\n",
              "         0.0000e+00, -2.0903e-15,  0.0000e+00,  0.0000e+00, -2.5223e-44,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -1.4013e-45,  0.0000e+00,\n",
              "        -1.7457e-24,  0.0000e+00, -1.0543e-37, -1.6182e-33, -3.5188e-28,\n",
              "        -8.2104e-17,  0.0000e+00, -3.8662e-06,  0.0000e+00,  0.0000e+00,\n",
              "        -2.4441e-09, -8.4772e-20,  0.0000e+00,  0.0000e+00, -9.1102e-12,\n",
              "         0.0000e+00, -3.0097e+06,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "        -4.5720e-36,  0.0000e+00, -3.6430e-12,  0.0000e+00,  0.0000e+00,\n",
              "        -1.6816e-44,  1.9004e-41, -4.8050e-26, -2.8832e-06, -1.4013e-45,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -4.4110e-04,\n",
              "         0.0000e+00,  0.0000e+00, -5.9390e-13,  0.0000e+00,  0.0000e+00,\n",
              "        -4.5634e-22,  0.0000e+00, -3.4013e-37,  0.0000e+00,  0.0000e+00,\n",
              "         1.9898e-43,  0.0000e+00, -4.2383e-17,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -1.2412e-14, -5.9457e-04,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -1.0701e-07,  5.1149e-40,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.5719e-17,\n",
              "         0.0000e+00,  0.0000e+00, -6.4470e-14, -1.3247e-35,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "        -9.8613e-27, -3.9645e-25, -1.5112e-30, -1.1566e-08,  0.0000e+00,\n",
              "         0.0000e+00, -1.5719e-17,  0.0000e+00, -1.3828e-31,  0.0000e+00,\n",
              "        -4.5551e-22, -1.6255e-43, -1.9179e-27,  4.6289e-17, -6.6137e-04,\n",
              "        -8.4772e-20,  0.0000e+00,  0.0000e+00, -8.2205e-14, -1.2163e-08,\n",
              "         0.0000e+00,  0.0000e+00, -1.2418e-12, -1.0543e-37,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  2.8294e-34, -4.5634e-22,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -7.7118e-30,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -1.3518e-33,  0.0000e+00,  0.0000e+00,\n",
              "        -1.8627e-28, -3.9645e-25,  0.0000e+00,  0.0000e+00, -2.1972e-42,\n",
              "         0.0000e+00, -2.4485e-09, -1.0150e-03,  0.0000e+00, -1.7865e-25,\n",
              "         0.0000e+00,        -inf,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -6.7035e-32,  0.0000e+00,  0.0000e+00, -6.3710e-32,\n",
              "        -6.6137e-04, -6.5706e-01,  0.0000e+00, -1.5719e-17,  0.0000e+00,\n",
              "         0.0000e+00,  5.1149e-40,  0.0000e+00, -7.1308e-38, -1.3518e-33,\n",
              "         0.0000e+00,  0.0000e+00, -1.0150e-03,  0.0000e+00, -5.4345e-13,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -9.3034e-30,\n",
              "        -8.1634e-13,  0.0000e+00,  1.7343e-39,  0.0000e+00, -3.7737e+01,\n",
              "        -1.6692e-14,  0.0000e+00,  0.0000e+00, -1.1301e-18,  0.0000e+00,\n",
              "        -1.0095e-10, -8.0009e-07,  0.0000e+00, -2.4070e-08, -2.6165e-41,\n",
              "        -3.0533e-07,  0.0000e+00, -2.6325e-14,  0.0000e+00,  0.0000e+00,\n",
              "        -6.7686e-14,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -1.3188e+01,  0.0000e+00, -3.4013e-37,\n",
              "         0.0000e+00,  7.1993e-41, -2.2864e-35, -6.5861e-44, -4.9438e-23,\n",
              "        -2.0903e-15,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "        -4.6133e-21,  0.0000e+00,  0.0000e+00,  0.0000e+00, -5.8006e-24,\n",
              "         0.0000e+00,  0.0000e+00, -6.3710e-32,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -6.0236e-15,  0.0000e+00, -2.5559e-05, -3.8831e-13,\n",
              "         0.0000e+00,  0.0000e+00, -1.2184e+02,  0.0000e+00, -1.0090e+01,\n",
              "        -5.2582e-35, -1.3873e-42,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         1.6419e-27, -8.8237e-12, -1.2808e-33, -4.6133e-21,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  9.6867e-18,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -2.4571e-31,  0.0000e+00,  1.3201e-38,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -4.1568e-11,  0.0000e+00,\n",
              "        -1.4013e-45, -1.0701e-07,  3.2638e-35,  0.0000e+00,  0.0000e+00,\n",
              "         3.4265e-14, -2.5223e-44,  0.0000e+00, -1.7958e-41, -2.4441e-09,\n",
              "         0.0000e+00, -8.0009e-07, -1.4125e-01, -1.0090e+01,  0.0000e+00,\n",
              "        -2.2156e-12,  0.0000e+00,  0.0000e+00,  0.0000e+00, -2.4070e-08,\n",
              "        -4.5634e-22, -1.3188e+01,  0.0000e+00,  0.0000e+00, -5.0588e-29,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.3046e-34,\n",
              "        -2.3189e-15,  0.0000e+00, -2.9159e+00, -4.8370e-19, -1.0197e-32,\n",
              "         0.0000e+00, -4.2383e-17,  1.0241e-28,  0.0000e+00, -3.0533e-07,\n",
              "         0.0000e+00,  0.0000e+00, -1.0150e-03,  0.0000e+00, -9.1102e-12,\n",
              "         0.0000e+00, -2.6325e-14, -1.4617e-36, -3.8065e-38,  0.0000e+00,\n",
              "        -5.4262e-07, -1.0095e-10,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -6.6729e-06,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -4.5634e-22,  0.0000e+00, -9.8748e-13,  0.0000e+00,\n",
              "        -1.8556e-23,  0.0000e+00, -5.4529e-33,  0.0000e+00, -3.2522e-24,\n",
              "         1.1032e-38, -1.5748e-17,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "        -7.9976e-23, -3.2028e-23, -9.3884e-01,  0.0000e+00,  0.0000e+00,\n",
              "        -3.4013e-37,  2.8026e-45,  0.0000e+00, -6.8054e-14,  0.0000e+00,\n",
              "        -1.0145e-30, -4.4114e-29, -6.0833e-21,  0.0000e+00, -1.2272e+09,\n",
              "         0.0000e+00, -8.2104e-17,  0.0000e+00, -6.1665e+15, -1.7958e-41,\n",
              "        -2.5223e-44, -6.8813e-12, -3.8615e-09,  0.0000e+00, -4.6133e-21,\n",
              "         0.0000e+00,  0.0000e+00, -3.5367e-40, -5.1789e+02, -7.3035e-20,\n",
              "         0.0000e+00, -2.3485e-09, -1.0284e-27, -4.5693e-33,  0.0000e+00,\n",
              "        -2.0038e-36, -1.5719e-17,  0.0000e+00, -5.8006e-24, -1.7944e-15,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.8730e-15,\n",
              "         0.0000e+00,  0.0000e+00, -1.0701e-07,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -1.4013e-45, -7.9832e-23,  0.0000e+00, -1.3046e-34,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.5112e-30,\n",
              "        -5.8855e-44,  0.0000e+00,  0.0000e+00,  0.0000e+00, -6.7035e-32,\n",
              "         3.4275e-23,  0.0000e+00, -3.5486e-18,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -1.4617e-36,  0.0000e+00,\n",
              "         0.0000e+00, -3.0533e-07, -1.4830e-20, -8.4772e-20,  0.0000e+00,\n",
              "        -6.8054e-14,  0.0000e+00, -2.0976e-10,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -1.0095e-10, -8.4655e-19, -9.5567e-34,  0.0000e+00,\n",
              "        -2.5559e-05, -1.4857e-20,  0.0000e+00,  0.0000e+00, -2.2156e-12,\n",
              "        -1.5748e-17,  0.0000e+00, -2.2156e-12, -2.8727e-10,  0.0000e+00,\n",
              "        -6.2816e-41,  0.0000e+00,  0.0000e+00,  0.0000e+00, -4.6129e-11,\n",
              "        -1.2412e-14,  0.0000e+00, -4.7570e-17,  0.0000e+00, -2.4571e-31,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -4.5551e-22,\n",
              "        -1.0701e-07,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -5.6052e-45, -3.8615e-09,  0.0000e+00, -6.6945e-22,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -1.4857e-20,  0.0000e+00,\n",
              "        -1.9068e-20, -1.4830e-20,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "        -1.4309e-17, -1.7958e-41,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -4.9438e-23, -5.4529e-33,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -8.4772e-20,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -2.8727e-10,  0.0000e+00, -9.0216e-24, -1.2184e+02,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "        -4.2036e-30, -2.2960e-18,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -2.3133e-27,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -7.9832e-23,  0.0000e+00, -1.3400e-08, -2.4060e-40,\n",
              "        -9.5567e-34, -2.6038e-21,  0.0000e+00, -9.8748e-13,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -9.8091e-45,  0.0000e+00,\n",
              "         0.0000e+00, -1.3046e-34,  1.1169e-32,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -4.2383e-17, -2.2156e-12,  0.0000e+00,  0.0000e+00,\n",
              "        -3.7737e+01,  0.0000e+00,  0.0000e+00,  0.0000e+00, -5.1789e+02,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -2.2141e-04, -7.1308e-38,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -2.7511e-36,\n",
              "         0.0000e+00, -2.3189e-15,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -5.9457e-04,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -1.5112e-30,  0.0000e+00, -1.4125e-01,\n",
              "        -3.2425e-18,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -1.0095e-10,  0.0000e+00, -7.4033e-39,\n",
              "        -1.7015e-18, -6.6945e-22,  0.0000e+00, -1.9035e-38, -4.2974e-25,\n",
              "        -1.1244e-36,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.6816e-44,\n",
              "        -1.0052e-13,  0.0000e+00,  0.0000e+00, -2.5688e-29,  0.0000e+00,\n",
              "         0.0000e+00, -7.1308e-38, -1.3400e-08,  0.0000e+00, -8.7134e-11,\n",
              "         0.0000e+00, -1.7944e-15,  0.0000e+00, -2.5462e-42,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -1.2808e-33, -2.6687e-08,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -3.5322e-01, -2.0774e-08,\n",
              "        -1.4013e-45, -1.0095e-10,  0.0000e+00, -9.5567e-34,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -2.4202e-34, -3.3704e-28,  0.0000e+00,\n",
              "        -1.8556e-23, -3.0591e-21,  0.0000e+00,  0.0000e+00,  2.1787e-40,\n",
              "        -1.4635e-26,  0.0000e+00,  0.0000e+00,  0.0000e+00, -2.4565e-24,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -4.2036e-30,  0.0000e+00,\n",
              "        -1.4309e-17,  0.0000e+00, -2.4565e-24,  0.0000e+00,  0.0000e+00,\n",
              "        -5.4262e-07,  0.0000e+00, -2.8903e-30,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -2.4789e-27,\n",
              "        -2.4789e-27,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.4645e-07,\n",
              "         0.0000e+00, -4.7570e-17,  0.0000e+00, -1.2418e-12,  0.0000e+00,\n",
              "        -2.6013e-38,  0.0000e+00, -4.5020e-30,  0.0000e+00,  0.0000e+00,\n",
              "        -1.1129e-17,  0.0000e+00,  0.0000e+00,  0.0000e+00, -4.6108e-20,\n",
              "        -1.6266e-28,  0.0000e+00,  0.0000e+00, -9.0216e-24, -7.9832e-23,\n",
              "         0.0000e+00, -1.6816e-44,  0.0000e+00,  0.0000e+00, -3.5032e-43,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -2.8558e-42, -4.0543e-28,\n",
              "        -1.6182e-33,  0.0000e+00, -1.3873e-42,  0.0000e+00, -3.0953e-12,\n",
              "         0.0000e+00,  0.0000e+00,  1.8187e-35, -1.3828e-31, -1.6692e-14])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clamp_large_terms(samples_IS)[0].min()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xg4Fy5iQcqnl",
        "outputId": "534b197d-a951-470c-d848-9b9d74a2121f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-9.0000e-38)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clamp_large_terms(tensor):\n",
        "    max_float64 = torch.finfo(torch.float64).max\n",
        "    min_float64 = torch.finfo(torch.float64).min\n",
        "\n",
        "    tensor[tensor == float('inf')] = 1e38  # Choose a large finite value\n",
        "    tensor[tensor == float('-inf')] = -1e38  # Choose a small finite value\n",
        "\n",
        "    return tensor\n",
        "\n",
        "# Example usage:\n",
        "# samples_IS_clamped = clamp_tensor(samples_IS)"
      ],
      "metadata": {
        "id": "5I1eVRAvlZK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# samples_IS_clamped[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "fMWanHX9l-kL",
        "outputId": "d8453853-77ac-49e1-fca3-d1760b015b58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'samples_IS_clamped' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-5babce667c95>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msamples_IS_clamped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'samples_IS_clamped' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tensor(torch.finfo(torch.float64).min, dtype=torch.float64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZvLUFyNeJBo",
        "outputId": "c35697a7-262f-427d-d331-dfc87a2c111b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-1.7977e+308, dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "MHWCgv3e3fSs",
        "outputId": "f1041452-2c44-40ad-fd87-8a903fee57eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomizableFeatureNet_d(\n",
              "  (hidden_layers): ModuleList(\n",
              "    (0): Linear(in_features=2, out_features=16, bias=True)\n",
              "    (1): Linear(in_features=16, out_features=32, bias=True)\n",
              "  )\n",
              "  (output_layer): Linear(in_features=32, out_features=1, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = model(state_tensors)"
      ],
      "metadata": {
        "id": "HkIlYqmg25KD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "651d0a8b-af25-4e2f-a721-0b694511e29f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 must have the same dtype, but got Float and Double",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-602b7502521b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-45-0c890199681a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 must have the same dtype, but got Float and Double"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output.shape"
      ],
      "metadata": {
        "id": "Tukv3iQZ3ekc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FltSKPtH8TAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CustomizableFeatureNet(input_dim=2, hidden_dims=[16, 32], output_dim=1)"
      ],
      "metadata": {
        "id": "pG06s2t_0gZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3PZWZk4GqndI"
      },
      "execution_count": null,
=======
      "execution_count": 23,
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def variance_terms_tens(eval_policy, behav_policy, behavior_policies):\n",
        "  # Initialize lists to store axis data for each policy\n",
        "  timesteps = []\n",
        "  states = []\n",
        "  state_first = []\n",
        "  state_last = []\n",
        "  actions = []\n",
        "  rewards = []\n",
        "  gamma_last = []\n",
        "  weight_last = []\n",
        "  weights = calculate_importance_weights(eval_policy, behav_policy, behavior_policies)\n",
        "  psi = []\n",
        "\n",
        "  for index, policy in enumerate(behavior_policies):\n",
        "      policy_array = np.array(policy)\n",
        "      timesteps.append(policy_array[:, 4].astype(int))\n",
        "      # s.append(policy_array[:, 0])\n",
        "\n",
        "      # last timestep for gamma\n",
        "      gamma_last.append(len(policy))\n",
        "      # last importance weight\n",
        "      weight_last.append(weights[index][-1])\n",
        "\n",
        "\n",
        "      states.append(policy_array[:, 0][1:])\n",
        "      psi.append(policy_array[:,5][1:])\n",
        "      state_first.append(policy_array[:,0][0])\n",
        "      state_last.append(policy_array[:,0][-1])\n",
        "      actions.append(policy_array[:, 1])\n",
        "      rewards.append(policy_array[:, 2].astype(float))\n",
        "\n",
        "  weights_difference = []\n",
        "  for index, weight in enumerate(weights):\n",
        "    # diff = np.array(w[index][:-1]) - np.array(w[index][1:])\n",
        "    diff = np.array(weight[:-1]) - np.array(weight[1:])\n",
        "    weights_difference.append(diff)\n",
        "\n",
        "  return timesteps, states, state_first, state_last, actions, rewards, gamma_last, weight_last, weights, weights_difference"
      ],
      "metadata": {
        "id": "Kcx483JVfDWA"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# t, s, s_f, s_l, a, r, g_l, w_l, w, w_diff = variance_terms_tens(P_pi_e, P_pi_b, pi_b)"
      ],
      "metadata": {
        "id": "q8d3KfusfsZ4"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "timesteps, states, states_first, states_last, actions, rewards, gamma_last, weights_last, weights, weights_difference = variance_terms_tens(P_pi_e, P_pi_b, pi_b)"
      ],
      "metadata": {
        "id": "BAqNV3alEAjQ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def padding_IS_terms(timesteps, actions, rewards, weights):\n",
        "    # Find the maximum length among all lists\n",
        "    max_length = max(len(traj) for traj in timesteps)\n",
        "\n",
        "    # Define the padding values\n",
        "    zero_padding = 0\n",
        "\n",
        "    # Pad each list to match the maximum length\n",
        "    padded_timesteps = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in timesteps]\n",
        "    padded_rewards = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in rewards]\n",
        "    padded_actions = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in actions]\n",
        "    padded_weights = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in weights]\n",
        "\n",
        "    return padded_timesteps, padded_rewards, padded_actions, padded_weights"
      ],
      "metadata": {
        "id": "AuuBKl0joAEk"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_timesteps, padded_rewards, padded_actions, padded_weights = padding_IS_terms(timesteps, actions, rewards, weights)"
      ],
      "metadata": {
        "id": "xD675spBnrP9"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def padding_states_weights_difference(states, weights_difference):\n",
        "    # Find the maximum length of trajectories\n",
        "    max_length = max(len(trajectory) for trajectory in states)\n",
        "\n",
        "    zero_padding = 0\n",
        "\n",
        "    # Pad each trajectory to make them all the same length\n",
        "    padded_states = [\n",
        "        [list(item) for item in trajectory] + [[0, 0]] * (max_length - len(trajectory))\n",
        "        for trajectory in states\n",
        "    ]\n",
        "\n",
        "    padded_weights_difference = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in weights_difference]\n",
        "\n",
        "    return padded_states, padded_weights_difference"
      ],
      "metadata": {
        "id": "4DekSrOTzLAn"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_states, padded_weights_difference = padding_states_weights_difference(states, weights_difference)"
      ],
      "metadata": {
        "id": "aX6DIhEQTCVR"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tensorize_padded_terms(padded_states, padded_weights_difference):\n",
        "  padded_state_tensors = torch.tensor(padded_states, dtype = torch.float64)\n",
        "  padded_weight_diff_tensors = torch.tensor(padded_weights_difference, dtype = torch.float64)\n",
        "  padded_weight_diff_tensors = padded_weight_diff_tensors.unsqueeze(-1)\n",
        "\n",
        "  return padded_state_tensors, padded_weight_diff_tensors\n"
      ],
      "metadata": {
        "id": "hHZhHnuUzHFr"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_state_tensors, padded_weight_diff_tensors = tensorize_padded_terms(padded_states, padded_weights_difference)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5kb1vOxTZSu",
        "outputId": "6b5b983d-35ca-4d5f-9ff4-1cba9d74450b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-3c22136e8020>:3: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  padded_weight_diff_tensors = torch.tensor(padded_weights_difference, dtype = torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tensorize_last_and_first_terms(states_first, states_last, gamma_last, weights_last):\n",
        "  states_first_tensor = torch.tensor(states_first, dtype = torch.float64)\n",
        "  states_last_tensor = torch.tensor(states_last, dtype = torch.float64)\n",
        "  gamma_last_tensor = torch.tensor(gamma_last, dtype = torch.float64)\n",
        "  weights_last_tensor = torch.tensor(weights_last, dtype = torch.float64)\n",
        "\n",
        "  return states_first_tensor, states_last_tensor, gamma_last_tensor, weights_last_tensor"
      ],
      "metadata": {
        "id": "AqtoK6MEmPWJ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "states_first_tensor, states_last_tensor, gamma_last_tensor, weights_last_tensor = tensorize_last_and_first_terms(states_first, states_last, gamma_last, weights_last)"
      ],
      "metadata": {
        "id": "gvE-AddhDTkx"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_IS_terms(gamma, timesteps, rewards, weights):\n",
        "  gtrw = np.power(gamma, timesteps)*rewards*weights\n",
        "\n",
        "  IS_tensor = torch.sum(torch.tensor(gtrw, dtype = torch.float32), dim = 1, keepdim = True)\n",
        "\n",
        "  return IS_tensor\n"
      ],
      "metadata": {
        "id": "YVpa0bTwd3HX"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IS_tensor = calc_IS_terms(0.9, padded_timesteps, padded_rewards, padded_weights)"
      ],
      "metadata": {
        "id": "xjRU7xlj89PY"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.finfo(torch.float64).max"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGtcFc-YY9SK",
        "outputId": "ce82a7a6-848c-4034-f260-6a3bf7702324"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.7976931348623157e+308"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# samples_IS[0]"
      ],
      "metadata": {
        "id": "s_JAi7apXuJ2"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_gamma_weight_last(gamma, gamma_last, weights_last):\n",
        "  gamma_weight_last = np.power(gamma, gamma_last)*weights_last\n",
        "\n",
        "  gamma_weight_last_tensor = torch.tensor(gamma_weight_last, dtype = torch.float64).unsqueeze(-1)\n",
        "\n",
        "  return gamma_weight_last_tensor"
      ],
      "metadata": {
        "id": "8I3qisEpsYzB"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gamma_weights_last_tensor = calc_gamma_weight_last(0.9, gamma_last, weights_last)"
      ],
      "metadata": {
        "id": "XHDztxg4C3So"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bootstrap_IS_terms(IS_tensor, num_samples):\n",
        "  seed = 42\n",
        "  torch.manual_seed(seed)\n",
        "\n",
        "  num_bootstraps = num_samples*len(IS_tensor)\n",
        "\n",
        "  # Sample indices with replacement\n",
        "  sampled_indices = torch.randint(0, len(IS_tensor), size=(num_bootstraps,), dtype=torch.long)\n",
        "\n",
        "  # new_size = (num_samples, IS_tensor.shape[0], IS_tensor.shape[1])\n",
        "  new_size = (num_samples, IS_tensor.shape[0])\n",
        "\n",
        "  IS_bootstraps = IS_tensor[sampled_indices].view(new_size)\n",
        "\n",
        "  # sampled_tensor = IS_bootstraps.view(new_size)\n",
        "\n",
        "  return IS_bootstraps"
      ],
      "metadata": {
        "id": "rdqtMRAT35lW"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples_IS = bootstrap_IS_terms(IS_tensor, 10000)"
      ],
      "metadata": {
        "id": "MHOyNeJ-UdcS"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clamp_large_terms(input_term):\n",
        "  max_float64 = torch.finfo(torch.float64).max\n",
        "  return torch.clamp(input_term, min=-max_float64, max=max_float64)\n"
      ],
      "metadata": {
        "id": "ng9lLOfsGvdb"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clamp_large_terms(input_term):\n",
        "    max_float64 = torch.tensor(torch.finfo(torch.float64).max, dtype=torch.float64)\n",
        "    min_value = torch.tensor(-1e50, dtype=torch.float64)\n",
        "    return torch.clamp(input_term, min=min_value, max=max_float64)\n",
        "\n",
        "    # return torch.clamp(input_term, min=-max_float64, max=max_float64)\n"
      ],
      "metadata": {
        "id": "C1Su5BQ0cfUV"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CustomizableFeatureNet_d(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dims, output_dim, dropout_prob=0.2, dtype=torch.float32):\n",
        "        super(CustomizableFeatureNet_d, self).__init__()\n",
        "        self.hidden_layers = nn.ModuleList()\n",
        "\n",
        "        # Create the hidden layers based on the provided sizes\n",
        "        for in_dim, out_dim in zip([input_dim] + hidden_dims, hidden_dims):\n",
        "            self.hidden_layers.append(nn.Linear(in_dim, out_dim).to(dtype))\n",
        "\n",
        "        self.output_layer = nn.Linear(hidden_dims[-1], output_dim).to(dtype)\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.hidden_layers:\n",
        "            x = F.relu(layer(x))\n",
        "            x = self.dropout(x)\n",
        "        x = self.output_layer(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "YFqvRa0LS7OF"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CustomizableFeatureNet_d(input_dim=2, hidden_dims=[16, 32], output_dim=1, dtype = torch.float64)"
      ],
      "metadata": {
        "id": "udif1c2cTBzV"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = CustomizableFeatureNet(input_dim=2, hidden_dims=[16, 32], output_dim=1)"
      ],
      "metadata": {
        "id": "ct8DQIU6rUvw"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pass_states(model, padded_state_tensors, states_first_tensor, states_last_tensor):\n",
        "  # Get model outputs for states\n",
        "  states_output = model(padded_state_tensors)\n",
        "  states_first_output = model(states_first_tensor)\n",
        "  states_last_output = model(states_last_tensor)\n",
        "  return states_output, states_first_output, states_last_output"
      ],
      "metadata": {
        "id": "0JNHRYkBmZ5Q"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "states_output, states_first_output, states_last_output = pass_states(model, padded_state_tensors, states_first_tensor, states_last_tensor)"
      ],
      "metadata": {
        "id": "duNRe00YE34A"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def states_weight_diff_sums(states_output, padded_weight_diff_tensors):\n",
        "  states_weight_diff = states_output * padded_weight_diff_tensors\n",
        "  sums_states_weight_diff = torch.sum(states_weight_diff, dim =1)\n",
        "\n",
        "  return sums_states_weight_diff"
      ],
      "metadata": {
        "id": "8nZkrdWPW5AQ"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sums_states_weight_diff = states_weight_diff_sums(states_output, padded_weight_diff_tensors)"
      ],
      "metadata": {
        "id": "nlxvS4QpYW0s"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def last_first_terms_operations(gamma_weights_last_tensor, states_last_output, states_first_output):\n",
        "  gamma_weights_states_last_sub_states_first = gamma_weights_last_tensor*states_last_output -  states_first_output\n",
        "\n",
        "  return gamma_weights_states_last_sub_states_first"
      ],
      "metadata": {
        "id": "fDDD0NcUaxpk"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gamma_weights_states_last_sub_states_first = last_first_terms_operations(gamma_weights_last_tensor, states_last_output, states_first_output)"
      ],
      "metadata": {
        "id": "ScpV8dhaCqHc"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gamma_weights_states_last_sub_states_first.shape"
      ],
      "metadata": {
        "id": "oC-P2rDqFIwP"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bootstrap_shaping_terms(sums_states_weight_diff, gamma_weights_states_last_sub_states_first, num_samples):\n",
        "\n",
        "  seed = 42\n",
        "  torch.manual_seed(seed)\n",
        "\n",
        "  num_bootstraps = num_samples*sums_states_weight_diff.shape[0]\n",
        "\n",
        "  # Sample indices with replacement\n",
        "  sampled_indices = torch.randint(0, len(sums_states_weight_diff), size=(num_bootstraps,), dtype=torch.long)\n",
        "\n",
        "  # sizes\n",
        "  # size_states_weights_diff = (num_samples, states_output.shape[0], states_output.shape[1])\n",
        "  reshaped_size = (num_samples, sums_states_weight_diff.shape[0])\n",
        "\n",
        "  # Resize samples to shape num_samples x num_trajectories x length_padded_trajectories\n",
        "  # samples_states_output = states_output[sampled_indices].view(size_states_weights_diff)\n",
        "  # samples_weight_diff = padded_weight_diff_tensors[sampled_indices].view(size_states_weights_diff)\n",
        "\n",
        "  # Resize samples to shape num_samples x num_trajectories\n",
        "  sample_sums_states_weight_diff = sums_states_weight_diff[sampled_indices].view(reshaped_size)\n",
        "  # samples_states_first_output = sums_states_weight_diff[sampled_indices].view(reshaped_size)\n",
        "  # samples_states_last_output = states_last_output[sampled_indices].view(reshaped_size)\n",
        "  samples_gamma_weight_states_last_sub_states_first = gamma_weights_states_last_sub_states_first[sampled_indices].view(reshaped_size)\n",
        "\n",
        "\n",
        "  return sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first\n"
      ],
      "metadata": {
        "id": "d3UM9eUGeQdq"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first = bootstrap_shaping_terms(sums_states_weight_diff, gamma_weights_states_last_sub_states_first, 10000)"
      ],
      "metadata": {
        "id": "whCU0iyDCi8U"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def gtrw_plus_states_weight_diff_min_last_firsts_terms(gtrw_tensor, sums_states_weight_diff, gamma_weights_states_last_sub_states_first):\n",
        "#   sum_IS_and_shaping = gtrw_tensor + sums_states_weight_diff + gamma_weights_states_last_sub_states_first\n",
        "\n",
        "#   return sum_IS_and_shaping"
      ],
      "metadata": {
        "id": "sIw1SreEnUpM"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def bootstrap_IS_shaping_terms(gtrw_tensor, sums_states_weight_diff, gamma_weights_states_last_sub_states_first):\n",
        "#   seed = 42\n",
        "#   torch.manual_seed(seed)\n",
        "\n",
        "#   num_bootstraps = num_samples*sums_states_weight_diff.shape[0]\n",
        "\n",
        "#   # Sample indices with replacement\n",
        "#   sampled_indices = torch.randint(0, len(sums_states_weight_diff), size=(num_bootstraps,), dtype=torch.long)\n",
        "\n"
      ],
      "metadata": {
        "id": "OZHZzE6d58xQ"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wTVuyCVBB4-8"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clamp_large_terms(torch.mean(clamp_large_terms(torch.mean(samples_IS, dim = 1))))"
      ],
      "metadata": {
        "id": "tdFIzbNUgx94"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clamp_large_terms(torch.mean(clamp_large_terms(torch.mean(samples_IS, dim =1)**2)))"
      ],
      "metadata": {
        "id": "4dLA0DBLh-pV"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clamp_large_terms(torch.mean(clamp_large_terms(torch.mean(samples_IS, dim =1))**2) - torch.mean(clamp_large_terms(torch.mean(samples_IS, dim = 1))))"
      ],
      "metadata": {
        "id": "7pfgg5rZlakd"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SCOPE = sample_sums_states_weight_diff+samples_gamma_weight_states_last_sub_states_first"
      ],
      "metadata": {
        "id": "MWwuJS4En1ll"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.mean(SCOPE,dim =1).shape"
      ],
      "metadata": {
        "id": "ECEj-Lhooh8M"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mean(clamp_large_terms(samples_IS), dim = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6YXvZmXYUKd",
        "outputId": "d5a030e2-5c73-48bd-b58f-8e4970fbe046"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([      -inf, 2.0056e+14,       -inf,  ...,       -inf,       -inf,\n",
              "        1.0028e+14])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_shaped_variance(samples_IS, sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first):\n",
        "\n",
        "\n",
        "  # states_output, states_first_output, states_last_output = pass_states(model, padded_state_tensors, states_first_tensor, states_last_tensor)\n",
        "\n",
        "\n",
        "\n",
        "  # Begin calcs without clamping\n",
        "\n",
        "  # IS\n",
        "  E_IS_sq = torch.mean(torch.mean(clamp_large_terms(samples_IS), dim = 1)**2)\n",
        "  E_IS_all_sq = torch.mean(torch.mean(clamp_large_terms(samples_IS), dim = 1))**2\n",
        "\n",
        "  # states_weight_diff\n",
        "  E_s_wdiff_sq = torch.mean(torch.mean(clamp_large_terms(sample_sums_states_weight_diff), dim =1)**2)\n",
        "  E_s_wdiff_all_sq = torch.mean(torch.mean(clamp_large_terms(sample_sums_states_weight_diff), dim = 1))**2\n",
        "\n",
        "  # all terms\n",
        "  SCOPE = clamp_large_terms(sample_sums_states_weight_diff)+clamp_large_terms(samples_gamma_weight_states_last_sub_states_first)\n",
        "  E_IS_SCOPE = torch.mean(torch.mean(clamp_large_terms(samples_IS), dim =1) * torch.mean(SCOPE, dim =1))\n",
        "  E_IS_E_SCOPE = torch.mean(torch.mean(clamp_large_terms(samples_IS),dim = 1 ))*torch.mean(torch.mean(SCOPE, dim =1))\n",
        "\n",
        "  SCOPE_variance = E_IS_sq + 2*E_IS_SCOPE + E_s_wdiff_sq - E_IS_all_sq - 2*E_IS_E_SCOPE - E_IS_E_SCOPE\n",
        "\n",
        "  IS_variance = E_IS_sq - E_IS_all_sq\n",
        "\n",
        "  return IS_variance, SCOPE_variance\n"
      ],
      "metadata": {
        "id": "LLuzewmQ3DR6"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IS_variance, SCOPE_variance = calculate_shaped_variance(samples_IS, sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first)"
      ],
      "metadata": {
        "id": "Nz9ApTk-qnx9"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mean(torch.mean(clamp_large_terms(samples_IS), dim = 1)**2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qN1zDrJWo4wZ",
        "outputId": "548dc965-3831-4791-9077-d8d8de7062d5"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(inf)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SCOPE_variance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBjjOVEggKhd",
        "outputId": "fdeba7f8-0ed2-498d-f842-25fe37e45dcd"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(nan, dtype=torch.float64, grad_fn=<SubBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IS_variance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyMAdyWjgb4b",
        "outputId": "fcadf31c-726b-4846-b87e-576e2d0c1d59"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(nan)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def clamp_large_terms(input_term):\n",
        "    max_float64 = torch.tensor(torch.finfo(torch.float64).max, dtype=torch.float64)\n",
        "    # min_value = torch.tensor(-1e38, dtype=torch.float64)\n",
        "    min_value = torch.tensor(-9e-38, dtype=torch.float64)\n",
        "\n",
        "    # min_value = torch.tensor(-1.7e+308, dtype = torch.float64)\n",
        "    # min_value = torch.tensor(torch.finfo(torch.float64).min, dtype=torch.float64)\n",
        "\n",
        "\n",
        "    # Using torch.where to explicitly set values outside the desired range\n",
        "    clamped_result = torch.where(input_term < min_value, min_value, input_term)\n",
        "    clamped_result = torch.where(clamped_result > max_float64, max_float64, clamped_result)\n",
        "\n",
        "    return clamped_result\n",
        "clamp_large_terms(samples_IS)[0].min()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDs0epOwdjjK",
        "outputId": "70d2de61-11b2-465f-a114-7527e815ead9"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-9.0000e-38)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "samples_IS[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGlLqnsIhLAr",
        "outputId": "dbacfd91-4d5b-48ae-8d2b-c36b24042d6d"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.0000e+00, -9.5567e-34, -1.1020e-12, -5.7703e-20,  0.0000e+00,\n",
              "        -6.6609e-06,  0.0000e+00,  0.0000e+00,  0.0000e+00, -7.4562e-17,\n",
              "        -1.3518e-33, -6.3068e-29, -1.1566e-08,  0.0000e+00, -3.2522e-24,\n",
              "         0.0000e+00,  0.0000e+00, -4.0924e-02,  0.0000e+00,  0.0000e+00,\n",
              "        -6.0833e-21, -1.1020e-12,  0.0000e+00, -3.5032e-43, -3.4013e-37,\n",
              "        -7.9832e-23,  0.0000e+00, -2.2156e-12,  0.0000e+00, -7.3671e-27,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -3.0953e-12,  0.0000e+00, -7.1745e-11,  0.0000e+00,\n",
              "        -1.2184e+02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -4.8370e-19,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -1.7865e-25, -3.0953e-12, -3.1972e-14,\n",
              "         0.0000e+00, -3.9939e-21,  0.0000e+00, -4.2383e-17,  0.0000e+00,\n",
              "         0.0000e+00, -9.5567e-34,  0.0000e+00,  0.0000e+00, -5.4262e-07,\n",
              "        -3.7487e-37, -2.6165e-41,  0.0000e+00, -1.0701e-07,  0.0000e+00,\n",
              "         0.0000e+00, -6.6945e-22,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -1.3046e-34, -1.7190e-19,  0.0000e+00,\n",
              "         9.6867e-18, -4.6108e-20,  1.3313e-32, -4.5634e-22,  0.0000e+00,\n",
              "         0.0000e+00, -1.9068e-20, -3.2430e-22, -8.2104e-17,  0.0000e+00,\n",
              "        -1.0108e-29,  0.0000e+00, -8.4772e-20,  0.0000e+00, -2.0319e-39,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -6.3362e-38,  0.0000e+00,\n",
              "         4.7220e-16,  0.0000e+00, -1.5748e-17,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -1.3046e-34,  3.4275e-23,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.2642e-11,\n",
              "        -2.0774e-08,  0.0000e+00, -2.4060e-40, -3.5032e-43,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "        -9.3884e-01, -8.4772e-20, -2.5036e-39,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -1.3247e-35,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -3.8730e-15, -1.0150e-03, -2.0038e-36,  0.0000e+00,\n",
              "         0.0000e+00, -8.4655e-19,  0.0000e+00, -7.3035e-20, -6.6609e-06,\n",
              "         0.0000e+00,  0.0000e+00, -1.6692e-14, -2.6013e-38,  0.0000e+00,\n",
              "         0.0000e+00, -5.6024e-35, -4.5634e-22,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -2.8727e-10, -2.2156e-12,\n",
              "         0.0000e+00,  0.0000e+00,  5.1149e-40,  0.0000e+00,  0.0000e+00,\n",
              "        -1.3400e-08,  0.0000e+00, -2.6687e-08,  0.0000e+00, -4.5020e-30,\n",
              "        -1.0701e-07, -1.0052e-13,  0.0000e+00,  0.0000e+00, -4.5720e-36,\n",
              "        -2.7511e-36,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -9.6992e-23,  0.0000e+00,  0.0000e+00,  1.1169e-32,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -1.2418e-12,  3.4265e-14,\n",
              "         0.0000e+00,  0.0000e+00, -1.6255e-43, -1.1568e-11,  0.0000e+00,\n",
              "        -2.5918e-04, -4.2958e-02, -1.4635e-26,  0.0000e+00, -8.7134e-11,\n",
              "         3.6282e-29,  0.0000e+00,  0.0000e+00, -1.2983e-17,  0.0000e+00,\n",
              "         0.0000e+00, -1.2418e-12, -1.6759e-21,  0.0000e+00,  0.0000e+00,\n",
              "        -1.9035e-38, -2.1801e-26,  0.0000e+00, -1.2909e-23, -4.1059e-16,\n",
              "        -2.4789e-27, -1.0616e-20,  0.0000e+00, -2.5688e-29, -5.9457e-04,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -1.4309e-17,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "        -3.0097e+06,  0.0000e+00, -3.9645e-25, -8.8058e-20,  1.9898e-43,\n",
              "        -2.2156e-12,  0.0000e+00,  0.0000e+00, -3.8730e-15,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -2.4202e-34,  0.0000e+00,  0.0000e+00, -3.2028e-23,\n",
              "         0.0000e+00,  0.0000e+00, -3.9735e-34,  0.0000e+00, -3.8966e-08,\n",
              "         0.0000e+00, -2.2030e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -3.5367e-40,  0.0000e+00,  0.0000e+00,\n",
              "        -7.4222e-38,  0.0000e+00,  0.0000e+00, -9.4159e-16,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -2.1972e-42, -8.4772e-20,  0.0000e+00,\n",
              "         0.0000e+00, -2.0903e-15,  0.0000e+00,  0.0000e+00, -2.5223e-44,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -1.4013e-45,  0.0000e+00,\n",
              "        -1.7457e-24,  0.0000e+00, -1.0543e-37, -1.6182e-33, -3.5188e-28,\n",
              "        -8.2104e-17,  0.0000e+00, -3.8662e-06,  0.0000e+00,  0.0000e+00,\n",
              "        -2.4441e-09, -8.4772e-20,  0.0000e+00,  0.0000e+00, -9.1102e-12,\n",
              "         0.0000e+00, -3.0097e+06,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "        -4.5720e-36,  0.0000e+00, -3.6430e-12,  0.0000e+00,  0.0000e+00,\n",
              "        -1.6816e-44,  1.9004e-41, -4.8050e-26, -2.8832e-06, -1.4013e-45,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -4.4110e-04,\n",
              "         0.0000e+00,  0.0000e+00, -5.9390e-13,  0.0000e+00,  0.0000e+00,\n",
              "        -4.5634e-22,  0.0000e+00, -3.4013e-37,  0.0000e+00,  0.0000e+00,\n",
              "         1.9898e-43,  0.0000e+00, -4.2383e-17,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -1.2412e-14, -5.9457e-04,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -1.0701e-07,  5.1149e-40,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.5719e-17,\n",
              "         0.0000e+00,  0.0000e+00, -6.4470e-14, -1.3247e-35,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "        -9.8613e-27, -3.9645e-25, -1.5112e-30, -1.1566e-08,  0.0000e+00,\n",
              "         0.0000e+00, -1.5719e-17,  0.0000e+00, -1.3828e-31,  0.0000e+00,\n",
              "        -4.5551e-22, -1.6255e-43, -1.9179e-27,  4.6289e-17, -6.6137e-04,\n",
              "        -8.4772e-20,  0.0000e+00,  0.0000e+00, -8.2205e-14, -1.2163e-08,\n",
              "         0.0000e+00,  0.0000e+00, -1.2418e-12, -1.0543e-37,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  2.8294e-34, -4.5634e-22,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -7.7118e-30,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -1.3518e-33,  0.0000e+00,  0.0000e+00,\n",
              "        -1.8627e-28, -3.9645e-25,  0.0000e+00,  0.0000e+00, -2.1972e-42,\n",
              "         0.0000e+00, -2.4485e-09, -1.0150e-03,  0.0000e+00, -1.7865e-25,\n",
              "         0.0000e+00,        -inf,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -6.7035e-32,  0.0000e+00,  0.0000e+00, -6.3710e-32,\n",
              "        -6.6137e-04, -6.5706e-01,  0.0000e+00, -1.5719e-17,  0.0000e+00,\n",
              "         0.0000e+00,  5.1149e-40,  0.0000e+00, -7.1308e-38, -1.3518e-33,\n",
              "         0.0000e+00,  0.0000e+00, -1.0150e-03,  0.0000e+00, -5.4345e-13,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -9.3034e-30,\n",
              "        -8.1634e-13,  0.0000e+00,  1.7343e-39,  0.0000e+00, -3.7737e+01,\n",
              "        -1.6692e-14,  0.0000e+00,  0.0000e+00, -1.1301e-18,  0.0000e+00,\n",
              "        -1.0095e-10, -8.0009e-07,  0.0000e+00, -2.4070e-08, -2.6165e-41,\n",
              "        -3.0533e-07,  0.0000e+00, -2.6325e-14,  0.0000e+00,  0.0000e+00,\n",
              "        -6.7686e-14,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -1.3188e+01,  0.0000e+00, -3.4013e-37,\n",
              "         0.0000e+00,  7.1993e-41, -2.2864e-35, -6.5861e-44, -4.9438e-23,\n",
              "        -2.0903e-15,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "        -4.6133e-21,  0.0000e+00,  0.0000e+00,  0.0000e+00, -5.8006e-24,\n",
              "         0.0000e+00,  0.0000e+00, -6.3710e-32,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -6.0236e-15,  0.0000e+00, -2.5559e-05, -3.8831e-13,\n",
              "         0.0000e+00,  0.0000e+00, -1.2184e+02,  0.0000e+00, -1.0090e+01,\n",
              "        -5.2582e-35, -1.3873e-42,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         1.6419e-27, -8.8237e-12, -1.2808e-33, -4.6133e-21,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  9.6867e-18,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -2.4571e-31,  0.0000e+00,  1.3201e-38,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -4.1568e-11,  0.0000e+00,\n",
              "        -1.4013e-45, -1.0701e-07,  3.2638e-35,  0.0000e+00,  0.0000e+00,\n",
              "         3.4265e-14, -2.5223e-44,  0.0000e+00, -1.7958e-41, -2.4441e-09,\n",
              "         0.0000e+00, -8.0009e-07, -1.4125e-01, -1.0090e+01,  0.0000e+00,\n",
              "        -2.2156e-12,  0.0000e+00,  0.0000e+00,  0.0000e+00, -2.4070e-08,\n",
              "        -4.5634e-22, -1.3188e+01,  0.0000e+00,  0.0000e+00, -5.0588e-29,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.3046e-34,\n",
              "        -2.3189e-15,  0.0000e+00, -2.9159e+00, -4.8370e-19, -1.0197e-32,\n",
              "         0.0000e+00, -4.2383e-17,  1.0241e-28,  0.0000e+00, -3.0533e-07,\n",
              "         0.0000e+00,  0.0000e+00, -1.0150e-03,  0.0000e+00, -9.1102e-12,\n",
              "         0.0000e+00, -2.6325e-14, -1.4617e-36, -3.8065e-38,  0.0000e+00,\n",
              "        -5.4262e-07, -1.0095e-10,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -6.6729e-06,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -4.5634e-22,  0.0000e+00, -9.8748e-13,  0.0000e+00,\n",
              "        -1.8556e-23,  0.0000e+00, -5.4529e-33,  0.0000e+00, -3.2522e-24,\n",
              "         1.1032e-38, -1.5748e-17,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "        -7.9976e-23, -3.2028e-23, -9.3884e-01,  0.0000e+00,  0.0000e+00,\n",
              "        -3.4013e-37,  2.8026e-45,  0.0000e+00, -6.8054e-14,  0.0000e+00,\n",
              "        -1.0145e-30, -4.4114e-29, -6.0833e-21,  0.0000e+00, -1.2272e+09,\n",
              "         0.0000e+00, -8.2104e-17,  0.0000e+00, -6.1665e+15, -1.7958e-41,\n",
              "        -2.5223e-44, -6.8813e-12, -3.8615e-09,  0.0000e+00, -4.6133e-21,\n",
              "         0.0000e+00,  0.0000e+00, -3.5367e-40, -5.1789e+02, -7.3035e-20,\n",
              "         0.0000e+00, -2.3485e-09, -1.0284e-27, -4.5693e-33,  0.0000e+00,\n",
              "        -2.0038e-36, -1.5719e-17,  0.0000e+00, -5.8006e-24, -1.7944e-15,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.8730e-15,\n",
              "         0.0000e+00,  0.0000e+00, -1.0701e-07,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -1.4013e-45, -7.9832e-23,  0.0000e+00, -1.3046e-34,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.5112e-30,\n",
              "        -5.8855e-44,  0.0000e+00,  0.0000e+00,  0.0000e+00, -6.7035e-32,\n",
              "         3.4275e-23,  0.0000e+00, -3.5486e-18,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -1.4617e-36,  0.0000e+00,\n",
              "         0.0000e+00, -3.0533e-07, -1.4830e-20, -8.4772e-20,  0.0000e+00,\n",
              "        -6.8054e-14,  0.0000e+00, -2.0976e-10,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -1.0095e-10, -8.4655e-19, -9.5567e-34,  0.0000e+00,\n",
              "        -2.5559e-05, -1.4857e-20,  0.0000e+00,  0.0000e+00, -2.2156e-12,\n",
              "        -1.5748e-17,  0.0000e+00, -2.2156e-12, -2.8727e-10,  0.0000e+00,\n",
              "        -6.2816e-41,  0.0000e+00,  0.0000e+00,  0.0000e+00, -4.6129e-11,\n",
              "        -1.2412e-14,  0.0000e+00, -4.7570e-17,  0.0000e+00, -2.4571e-31,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -4.5551e-22,\n",
              "        -1.0701e-07,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -5.6052e-45, -3.8615e-09,  0.0000e+00, -6.6945e-22,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -1.4857e-20,  0.0000e+00,\n",
              "        -1.9068e-20, -1.4830e-20,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "        -1.4309e-17, -1.7958e-41,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -4.9438e-23, -5.4529e-33,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -8.4772e-20,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -2.8727e-10,  0.0000e+00, -9.0216e-24, -1.2184e+02,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "        -4.2036e-30, -2.2960e-18,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -2.3133e-27,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -7.9832e-23,  0.0000e+00, -1.3400e-08, -2.4060e-40,\n",
              "        -9.5567e-34, -2.6038e-21,  0.0000e+00, -9.8748e-13,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -9.8091e-45,  0.0000e+00,\n",
              "         0.0000e+00, -1.3046e-34,  1.1169e-32,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00, -4.2383e-17, -2.2156e-12,  0.0000e+00,  0.0000e+00,\n",
              "        -3.7737e+01,  0.0000e+00,  0.0000e+00,  0.0000e+00, -5.1789e+02,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -2.2141e-04, -7.1308e-38,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -2.7511e-36,\n",
              "         0.0000e+00, -2.3189e-15,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -5.9457e-04,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -1.5112e-30,  0.0000e+00, -1.4125e-01,\n",
              "        -3.2425e-18,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -1.0095e-10,  0.0000e+00, -7.4033e-39,\n",
              "        -1.7015e-18, -6.6945e-22,  0.0000e+00, -1.9035e-38, -4.2974e-25,\n",
              "        -1.1244e-36,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.6816e-44,\n",
              "        -1.0052e-13,  0.0000e+00,  0.0000e+00, -2.5688e-29,  0.0000e+00,\n",
              "         0.0000e+00, -7.1308e-38, -1.3400e-08,  0.0000e+00, -8.7134e-11,\n",
              "         0.0000e+00, -1.7944e-15,  0.0000e+00, -2.5462e-42,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -1.2808e-33, -2.6687e-08,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -3.5322e-01, -2.0774e-08,\n",
              "        -1.4013e-45, -1.0095e-10,  0.0000e+00, -9.5567e-34,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00, -2.4202e-34, -3.3704e-28,  0.0000e+00,\n",
              "        -1.8556e-23, -3.0591e-21,  0.0000e+00,  0.0000e+00,  2.1787e-40,\n",
              "        -1.4635e-26,  0.0000e+00,  0.0000e+00,  0.0000e+00, -2.4565e-24,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -4.2036e-30,  0.0000e+00,\n",
              "        -1.4309e-17,  0.0000e+00, -2.4565e-24,  0.0000e+00,  0.0000e+00,\n",
              "        -5.4262e-07,  0.0000e+00, -2.8903e-30,  0.0000e+00,  0.0000e+00,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -2.4789e-27,\n",
              "        -2.4789e-27,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.4645e-07,\n",
              "         0.0000e+00, -4.7570e-17,  0.0000e+00, -1.2418e-12,  0.0000e+00,\n",
              "        -2.6013e-38,  0.0000e+00, -4.5020e-30,  0.0000e+00,  0.0000e+00,\n",
              "        -1.1129e-17,  0.0000e+00,  0.0000e+00,  0.0000e+00, -4.6108e-20,\n",
              "        -1.6266e-28,  0.0000e+00,  0.0000e+00, -9.0216e-24, -7.9832e-23,\n",
              "         0.0000e+00, -1.6816e-44,  0.0000e+00,  0.0000e+00, -3.5032e-43,\n",
              "         0.0000e+00,  0.0000e+00,  0.0000e+00, -2.8558e-42, -4.0543e-28,\n",
              "        -1.6182e-33,  0.0000e+00, -1.3873e-42,  0.0000e+00, -3.0953e-12,\n",
              "         0.0000e+00,  0.0000e+00,  1.8187e-35, -1.3828e-31, -1.6692e-14])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clamp_large_terms(samples_IS)[0].min()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xg4Fy5iQcqnl",
        "outputId": "534b197d-a951-470c-d848-9b9d74a2121f"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-9.0000e-38)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clamp_large_terms(tensor):\n",
        "    max_float64 = torch.finfo(torch.float64).max\n",
        "    min_float64 = torch.finfo(torch.float64).min\n",
        "\n",
        "    tensor[tensor == float('inf')] = 1e38  # Choose a large finite value\n",
        "    tensor[tensor == float('-inf')] = -1e38  # Choose a small finite value\n",
        "\n",
        "    return tensor\n",
        "\n",
        "# Example usage:\n",
        "# samples_IS_clamped = clamp_tensor(samples_IS)"
      ],
      "metadata": {
        "id": "5I1eVRAvlZK5"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# samples_IS_clamped[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "fMWanHX9l-kL",
        "outputId": "d8453853-77ac-49e1-fca3-d1760b015b58"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'samples_IS_clamped' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-5babce667c95>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msamples_IS_clamped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'samples_IS_clamped' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tensor(torch.finfo(torch.float64).min, dtype=torch.float64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZvLUFyNeJBo",
        "outputId": "c35697a7-262f-427d-d331-dfc87a2c111b"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-1.7977e+308, dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "MHWCgv3e3fSs",
        "outputId": "f1041452-2c44-40ad-fd87-8a903fee57eb"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomizableFeatureNet_d(\n",
              "  (hidden_layers): ModuleList(\n",
              "    (0): Linear(in_features=2, out_features=16, bias=True)\n",
              "    (1): Linear(in_features=16, out_features=32, bias=True)\n",
              "  )\n",
              "  (output_layer): Linear(in_features=32, out_features=1, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = model(state_tensors)"
      ],
      "metadata": {
        "id": "HkIlYqmg25KD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "651d0a8b-af25-4e2f-a721-0b694511e29f"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 must have the same dtype, but got Float and Double",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-602b7502521b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-45-0c890199681a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 must have the same dtype, but got Float and Double"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output.shape"
      ],
      "metadata": {
        "id": "Tukv3iQZ3ekc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FltSKPtH8TAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CustomizableFeatureNet(input_dim=2, hidden_dims=[16, 32], output_dim=1)"
      ],
      "metadata": {
        "id": "pG06s2t_0gZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3PZWZk4GqndI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scope_set, phi_set = subset_policies(pi_b, 0.3)"
      ],
      "metadata": {
        "id": "OFF9HKErgm34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IS, state_tensors, w_diff, f, st_og, psi_res, sample_last_tensors = variance_terms_tens(P_pi_e, P_pi_b, phi_set)"
      ],
      "metadata": {
        "id": "inVdxVMRjT4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CustomizableFeatureNet(input_dim=2, hidden_dims=[16, 32], output_dim=1)"
      ],
      "metadata": {
        "id": "qq1dLzLCjUp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = train_mse_var(model, 40, 0.001, 1, 1, IS, state_tensors, w_diff, f, sample_last_tensors, phi_set, st_og, psi_res)"
      ],
      "metadata": {
        "id": "TYKlf1urD34t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test class"
      ],
      "metadata": {
        "id": "72Fy4L1cuitK"
      }
    },
    {
      "cell_type": "code",
      "source": [
<<<<<<< HEAD
        "# import numpy as np\n",
        "# from IS import calculate_importance_weights\n",
        "\n",
        "# import torch\n",
        "\n",
        "class SCOPE_variance_play(object):\n",
        "    def __init__(self, model, gamma, num_bootstraps, pi_b, P_pi_b, P_pi_e, dtype):\n",
=======
        "class SCOPE_variance(object):\n",
        "    def __init__(self, model, gamma, num_bootstraps, pi_b, P_pi_b, P_pi_e):\n",
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
        "        self.model = model\n",
        "        self.gamma = gamma\n",
        "        self.num_bootstraps = num_bootstraps\n",
        "        self.pi_b = pi_b\n",
        "        self.P_pi_b = P_pi_b\n",
        "        self.P_pi_e = P_pi_e\n",
<<<<<<< HEAD
        "        self.dtype = dtype\n",
=======
        "\n",
        "\n",
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
        "\n",
        "\n",
        "    def prep_policies(self):\n",
        "        # Initialize lists to store axis data for each policy\n",
        "        timesteps = []\n",
        "        states = []\n",
        "        state_first = []\n",
        "        state_last = []\n",
        "        actions = []\n",
        "        rewards = []\n",
        "        gamma_last = []\n",
        "        weight_last = []\n",
<<<<<<< HEAD
        "        weight_first = []\n",
        "        # all_weights_temp, weights = calculate_importance_weights(self.P_pi_e, self.P_pi_b, self.pi_b)\n",
        "        weights, all_weights_temp = calculate_importance_weights(self.P_pi_e, self.P_pi_b, self.pi_b)\n",
        "        psi = []\n",
        "\n",
        "        for index, policy in enumerate(self.pi_b):\n",
        "            policy_array = np.array(policy)\n",
        "            timesteps.append(policy_array['timestep'].astype(int))\n",
=======
        "        weights = calculate_importance_weights(self.P_pi_e, self.P_pi_b, self.pi_b)\n",
        "        psi = []\n",
        "\n",
        "        for index, policy in enumerate(pi_b):\n",
        "            policy_array = np.array(policy)\n",
        "            timesteps.append(policy_array[:, 4].astype(int))\n",
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
        "            # s.append(policy_array[:, 0])\n",
        "\n",
        "            # last timestep for gamma\n",
        "            gamma_last.append(len(policy))\n",
        "            # last importance weight\n",
        "            weight_last.append(weights[index][-1])\n",
<<<<<<< HEAD
        "            weight_first.append(weights[index][0])\n",
        "\n",
        "\n",
        "            states.append(policy_array['state'][1:])\n",
        "            psi.append(policy_array['psi'][1:])\n",
        "            state_first.append(policy_array['state'][0])\n",
        "            state_last.append(policy_array['state'][-1])\n",
        "            actions.append(policy_array['action'])\n",
        "            rewards.append(policy_array['reward'].astype(float))\n",
=======
        "\n",
        "\n",
        "            states.append(policy_array[:, 0][1:])\n",
        "            psi.append(policy_array[:,5][1:])\n",
        "            state_first.append(policy_array[:,0][0])\n",
        "            state_last.append(policy_array[:,0][-1])\n",
        "            actions.append(policy_array[:, 1])\n",
        "            rewards.append(policy_array[:, 2].astype(float))\n",
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
        "\n",
        "        weights_difference = []\n",
        "        for index, weight in enumerate(weights):\n",
        "            # diff = np.array(w[index][:-1]) - np.array(w[index][1:])\n",
        "            diff = np.array(weight[:-1]) - np.array(weight[1:])\n",
        "            weights_difference.append(diff)\n",
        "\n",
<<<<<<< HEAD
        "        return timesteps, states, state_first, state_last, actions, rewards, gamma_last, weight_last, weights, weights_difference, weight_first\n",
=======
        "        return timesteps, states, state_first, state_last, actions, rewards, gamma_last, weight_last, weights, weights_difference\n",
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
        "\n",
        "    def padding_IS_terms(self,timesteps, actions, rewards, weights):\n",
        "        # Find the maximum length among all lists\n",
        "        max_length = max(len(traj) for traj in timesteps)\n",
        "\n",
        "        # Define the padding values\n",
        "        zero_padding = 0\n",
        "\n",
        "        # Pad each list to match the maximum length\n",
        "        padded_timesteps = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in timesteps]\n",
        "        padded_rewards = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in rewards]\n",
        "        padded_actions = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in actions]\n",
        "        padded_weights = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in weights]\n",
        "\n",
        "        return padded_timesteps, padded_rewards, padded_actions, padded_weights\n",
        "\n",
        "    def padding_states_weights_difference(self, states, weights_difference):\n",
        "        # Find the maximum length of trajectories\n",
        "        max_length = max(len(trajectory) for trajectory in states)\n",
        "\n",
        "        zero_padding = 0\n",
        "\n",
        "        # Pad each trajectory to make them all the same length\n",
        "        padded_states = [\n",
        "            [list(item) for item in trajectory] + [[0, 0]] * (max_length - len(trajectory))\n",
        "            for trajectory in states\n",
        "        ]\n",
        "\n",
        "        padded_weights_difference = [np.concatenate([traj, [zero_padding] * (max_length - len(traj))]) for traj in weights_difference]\n",
        "\n",
        "        return padded_states, padded_weights_difference\n",
        "\n",
        "    def tensorize_padded_terms(self, padded_states, padded_weights_difference):\n",
<<<<<<< HEAD
        "        padded_state_tensors = torch.tensor(padded_states, dtype = self.dtype)\n",
        "        padded_weight_diff_tensors = torch.tensor(padded_weights_difference, dtype = self.dtype)\n",
=======
        "        padded_state_tensors = torch.tensor(padded_states, dtype = torch.float32)\n",
        "        padded_weight_diff_tensors = torch.tensor(padded_weights_difference, dtype = torch.float32)\n",
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
        "        padded_weight_diff_tensors = padded_weight_diff_tensors.unsqueeze(-1)\n",
        "\n",
        "        return padded_state_tensors, padded_weight_diff_tensors\n",
        "\n",
        "    def tensorize_last_and_first_terms(self, states_first, states_last, gamma_last, weights_last):\n",
<<<<<<< HEAD
        "        states_first_tensor = torch.tensor(states_first, dtype = self.dtype)\n",
        "        states_last_tensor = torch.tensor(states_last, dtype = self.dtype)\n",
        "        gamma_last_tensor = torch.tensor(gamma_last, dtype = self.dtype)\n",
        "        weights_last_tensor = torch.tensor(weights_last, dtype = self.dtype)\n",
=======
        "        states_first_tensor = torch.tensor(states_first, dtype = torch.float32)\n",
        "        states_last_tensor = torch.tensor(states_last, dtype = torch.float32)\n",
        "        gamma_last_tensor = torch.tensor(gamma_last, dtype = torch.float32)\n",
        "        weights_last_tensor = torch.tensor(weights_last, dtype = torch.float32)\n",
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
        "\n",
        "        return states_first_tensor, states_last_tensor, gamma_last_tensor, weights_last_tensor\n",
        "\n",
        "    def calc_IS_terms(self, gamma, timesteps, rewards, weights):\n",
        "        gtrw = np.power(gamma, timesteps)*rewards*weights\n",
        "\n",
<<<<<<< HEAD
        "        IS_tensor = torch.sum(torch.tensor(gtrw, dtype = self.dtype), dim = 1, keepdim = True)\n",
=======
        "        IS_tensor = torch.sum(torch.tensor(gtrw, dtype = torch.float32), dim = 1, keepdim = True)\n",
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
        "\n",
        "        return IS_tensor\n",
        "\n",
        "    def calc_gamma_weight_last(self, gamma, gamma_last, weights_last):\n",
        "        gamma_weight_last = np.power(gamma, gamma_last)*weights_last\n",
        "\n",
<<<<<<< HEAD
        "        gamma_weight_last_tensor = torch.tensor(gamma_weight_last, dtype = self.dtype).unsqueeze(-1)\n",
        "\n",
        "        return gamma_weight_last_tensor\n",
        "\n",
        "    def tensorize_weight_first(self, weights_first):\n",
        "\n",
        "      weight_first_tensor = torch.tensor(weights_first, dtype = torch.float64).unsqueeze(-1)\n",
        "\n",
        "      return weight_first_tensor\n",
=======
        "        gamma_weight_last_tensor = torch.tensor(gamma_weight_last, dtype = torch.float32).unsqueeze(-1)\n",
        "\n",
        "        return gamma_weight_last_tensor\n",
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
        "    def bootstrap_IS_terms(self, IS_tensor, num_samples):\n",
        "        seed = 42\n",
        "        torch.manual_seed(seed)\n",
        "\n",
        "        num_bootstraps = num_samples*len(IS_tensor)\n",
        "\n",
        "        # Sample indices with replacement\n",
        "        sampled_indices = torch.randint(0, len(IS_tensor), size=(num_bootstraps,), dtype=torch.long)\n",
        "\n",
        "        # new_size = (num_samples, IS_tensor.shape[0], IS_tensor.shape[1])\n",
        "        new_size = (num_samples, IS_tensor.shape[0])\n",
        "\n",
        "        IS_bootstraps = IS_tensor[sampled_indices].view(new_size)\n",
        "\n",
        "        # sampled_tensor = IS_bootstraps.view(new_size)\n",
        "\n",
        "        return IS_bootstraps\n",
        "\n",
        "    def states_weight_diff_sums(self, states_output, padded_weight_diff_tensors):\n",
        "        states_weight_diff = states_output * padded_weight_diff_tensors\n",
        "        sums_states_weight_diff = torch.sum(states_weight_diff, dim =1)\n",
        "\n",
        "        return sums_states_weight_diff\n",
        "\n",
<<<<<<< HEAD
        "    def last_first_terms_operations(self, gamma_weights_last_tensor, states_last_output, states_first_output, temp = 1):\n",
        "        gamma_weights_states_last_sub_states_first = gamma_weights_last_tensor*states_last_output -  temp*states_first_output\n",
        "\n",
        "        return gamma_weights_states_last_sub_states_first\n",
        "\n",
        "    # def last_first_terms_operations(self, gamma_weights_last_tensor, states_last_output, states_first_output):\n",
        "    #     gamma_weights_states_last_sub_states_first = gamma_weights_last_tensor*states_last_output - states_first_output\n",
        "\n",
        "    #     return gamma_weights_states_last_sub_states_first\n",
        "\n",
        "    def bootstrap_shaping_terms(self, sums_states_weight_diff, gamma_weights_states_last_sub_states_first, IS_tensor):\n",
=======
        "    def bootstrap_shaping_terms(self, sums_states_weight_diff, gamma_weights_states_last_sub_states_first, num_samples):\n",
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
        "\n",
        "        seed = 42\n",
        "        torch.manual_seed(seed)\n",
        "\n",
<<<<<<< HEAD
        "        num_samples = self.num_bootstraps\n",
        "\n",
        "        num_bootstraps_lin = num_samples*sums_states_weight_diff.shape[0]\n",
        "\n",
        "        # Sample indices with replacement\n",
        "        sampled_indices = torch.randint(0, len(sums_states_weight_diff), size=(num_bootstraps_lin,), dtype=torch.long)\n",
=======
        "        num_bootstraps = num_samples*sums_states_weight_diff.shape[0]\n",
        "\n",
        "        # Sample indices with replacement\n",
        "        sampled_indices = torch.randint(0, len(sums_states_weight_diff), size=(num_bootstraps,), dtype=torch.long)\n",
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
        "\n",
        "        reshaped_size = (num_samples, sums_states_weight_diff.shape[0])\n",
        "\n",
        "        # Resize samples to shape num_samples x num_trajectories\n",
        "        sample_sums_states_weight_diff = sums_states_weight_diff[sampled_indices].view(reshaped_size)\n",
        "        samples_gamma_weight_states_last_sub_states_first = gamma_weights_states_last_sub_states_first[sampled_indices].view(reshaped_size)\n",
        "\n",
<<<<<<< HEAD
        "        # Sum states_weight_diff and gamma_weights-states_last_sub_states_first\n",
        "        sum_terms = sums_states_weight_diff + gamma_weights_states_last_sub_states_first\n",
        "\n",
        "        # sample IS terms\n",
        "\n",
        "        IS_SCOPE = IS_tensor * sum_terms\n",
        "\n",
        "        samples_IS_SCOPE = IS_SCOPE[sampled_indices].view(reshaped_size)\n",
        "\n",
        "\n",
        "        sample_all_shaping = sum_terms[sampled_indices].view(reshaped_size)\n",
        "\n",
        "        return sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, sample_all_shaping, samples_IS_SCOPE\n",
        "\n",
        "    def bootstrap_all_terms(self, sums_states_weight_diff, gamma_weights_states_last_sub_states_first, IS_tensor):\n",
        "        seed = 42\n",
        "        torch.manual_seed(seed)\n",
        "\n",
        "        # num_bootstraps = num_samples*len(IS_tensor)\n",
        "\n",
        "        # Sample indices with replacement\n",
        "        # sampled_indices = torch.randint(0, len(IS_tensor), size=(num_bootstraps,), dtype=torch.long)\n",
        "\n",
        "        # new_size = (num_samples, IS_tensor.shape[0], IS_tensor.shape[1])\n",
        "        # new_size = (num_samples, IS_tensor.shape[0])\n",
        "\n",
        "        # IS_bootstraps = IS_tensor[sampled_indices].view(new_size)\n",
        "\n",
        "        num_samples = self.num_bootstraps\n",
        "        num_bootstraps_lin = num_samples*sums_states_weight_diff.shape[0]\n",
        "\n",
        "\n",
        "        # Sample indices with replacement\n",
        "        sampled_indices = torch.randint(0, len(sums_states_weight_diff), size=(num_bootstraps_lin,), dtype=torch.long)\n",
        "\n",
        "        reshaped_size = (num_samples, sums_states_weight_diff.shape[0])\n",
        "\n",
        "        IS_bootstraps = IS_tensor[sampled_indices].view(reshaped_size)\n",
        "\n",
        "        # Resize samples to shape num_samples x num_trajectories\n",
        "        sample_sums_states_weight_diff = sums_states_weight_diff[sampled_indices].view(reshaped_size)\n",
        "        samples_gamma_weight_states_last_sub_states_first = gamma_weights_states_last_sub_states_first[sampled_indices].view(reshaped_size)\n",
        "\n",
        "        # Sum states_weight_diff and gamma_weights-states_last_sub_states_first\n",
        "        sum_terms = sums_states_weight_diff + gamma_weights_states_last_sub_states_first\n",
        "\n",
        "        # sample IS terms\n",
        "\n",
        "        IS_SCOPE = IS_tensor * sum_terms\n",
        "\n",
        "        samples_IS_SCOPE = IS_SCOPE[sampled_indices].view(reshaped_size)\n",
        "\n",
        "        sample_all_shaping = sum_terms[sampled_indices].view(reshaped_size)\n",
        "\n",
        "        return IS_bootstraps, sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, sample_all_shaping, samples_IS_SCOPE\n",
        "\n",
        "\n",
=======
        "\n",
        "        return sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first\n",
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
        "\n",
        "    def pass_states(self,model, padded_state_tensors, states_first_tensor, states_last_tensor):\n",
        "        # Get model outputs for states\n",
        "        states_output = model(padded_state_tensors)\n",
        "        states_first_output = model(states_first_tensor)\n",
        "        states_last_output = model(states_last_tensor)\n",
        "        return states_output, states_first_output, states_last_output\n",
        "\n",
        "\n",
<<<<<<< HEAD
        "    # def prepare(self):\n",
        "    #     timesteps, states, states_first, states_last, actions, rewards, gamma_last, weights_last, weights, weights_difference = self.prep_policies()\n",
        "    #     padded_timesteps, padded_rewards, padded_actions, padded_weights = self.padding_IS_terms(timesteps, actions, rewards, weights)\n",
        "    #     padded_states, padded_weights_difference = self.padding_states_weights_difference(states, weights_difference)\n",
        "    #     padded_state_tensors, padded_weight_diff_tensors = self.tensorize_padded_terms(padded_states, padded_weights_difference)\n",
        "    #     states_first_tensor, states_last_tensor, gamma_last_tensor, weights_last_tensor = self.tensorize_last_and_first_terms(states_first, states_last, gamma_last, weights_last)\n",
        "    #     IS_tensor = self.calc_IS_terms(self.gamma, padded_timesteps, padded_rewards, padded_weights)\n",
        "    #     gamma_weights_last_tensor = self.calc_gamma_weight_last(self.gamma, gamma_last, weights_last)\n",
        "    #     samples_IS = self.bootstrap_IS_terms(IS_tensor, self.num_bootstraps)\n",
        "\n",
        "    #     return IS_tensor, samples_IS, padded_state_tensors, padded_weight_diff_tensors, gamma_weights_last_tensor, states_first_tensor, states_last_tensor\n",
        "\n",
        "\n",
        "    def prepare(self):\n",
        "        timesteps, states, states_first, states_last, actions, rewards, gamma_last, weights_last, weights, weights_difference, weight_first = self.prep_policies()\n",
=======
        "    def prepare(self):\n",
        "        timesteps, states, states_first, states_last, actions, rewards, gamma_last, weights_last, weights, weights_difference = self.prep_policies()\n",
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
        "        padded_timesteps, padded_rewards, padded_actions, padded_weights = self.padding_IS_terms(timesteps, actions, rewards, weights)\n",
        "        padded_states, padded_weights_difference = self.padding_states_weights_difference(states, weights_difference)\n",
        "        padded_state_tensors, padded_weight_diff_tensors = self.tensorize_padded_terms(padded_states, padded_weights_difference)\n",
        "        states_first_tensor, states_last_tensor, gamma_last_tensor, weights_last_tensor = self.tensorize_last_and_first_terms(states_first, states_last, gamma_last, weights_last)\n",
        "        IS_tensor = self.calc_IS_terms(self.gamma, padded_timesteps, padded_rewards, padded_weights)\n",
        "        gamma_weights_last_tensor = self.calc_gamma_weight_last(self.gamma, gamma_last, weights_last)\n",
<<<<<<< HEAD
        "        weight_first_tensor = self.tensorize_weight_first(weight_first)\n",
        "        # samples_IS = self.bootstrap_IS_terms(IS_tensor, self.num_bootstraps)\n",
        "\n",
        "        return IS_tensor, padded_state_tensors, padded_weight_diff_tensors, gamma_weights_last_tensor, states_first_tensor, states_last_tensor, weight_first_tensor"
=======
        "        samples_IS = self.bootstrap_IS_terms(IS_tensor, self.num_bootstraps)\n",
        "\n",
        "        return samples_IS, padded_state_tensors, padded_weight_diff_tensors, gamma_weights_last_tensor, states_first_tensor, states_last_tensor\n"
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
      ],
      "metadata": {
        "id": "1vZCWSiPum0K"
      },
<<<<<<< HEAD
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_importance_weights(eval_policy, behav_policy, behavior_policies):\n",
        "    \"\"\"\n",
        "    Calculate importance weights for behavior policies.\n",
        "\n",
        "    Parameters:\n",
        "    - eval_policy: Evaluation policy\n",
        "    - behav_policy: Behavior policy\n",
        "    - behavior_policies: List of behavior policies\n",
        "\n",
        "    Returns:\n",
        "    - all_weights: List of importance weights\n",
        "    \"\"\"\n",
        "    all_weights_temp = []\n",
        "    for trajectory in behavior_policies:\n",
        "        cum_ratio = 1\n",
        "        cumul_weights = []\n",
        "        for step in trajectory:\n",
        "            # eval_action_probs = get_quadrant_policy(step[0], eval_policy)\n",
        "            # behav_action_probs = get_quadrant_policy(step[0], behav_policy)\n",
        "\n",
        "            P_pi_b = behav_policy[tuple(np.append(step[0].astype(int) , (step[1],)))]\n",
        "            P_pi_e = eval_policy[tuple(np.append(step[0].astype(int) , (step[1],)))]\n",
        "\n",
        "            # ratio = (0.8*eval_action_probs[step[1]] +0.2*0.25)/ (0.8*behav_action_probs[step[1]]+0.2*0.25)\n",
        "            ratio = P_pi_e/P_pi_b\n",
        "            cum_ratio *= ratio\n",
        "            cumul_weights.append(cum_ratio)\n",
        "        all_weights_temp.append(cumul_weights)\n",
        "\n",
        "        all_weights = [list(np.cumprod(i)) for i in all_weights_temp]\n",
        "\n",
        "    return all_weights_temp, all_weights"
      ],
      "metadata": {
        "id": "qRsjTJiS5cYe"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test variance"
      ],
      "metadata": {
        "id": "x6L6-NZfHdt_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_shaped_variance_play(samples_IS, sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, samples_all_shaping, samples_IS_SCOPE):\n",
        "\n",
        "  # states_output, states_first_output, states_last_output = pass_states(model, padded_state_tensors, states_first_tensor, states_last_tensor)\n",
        "\n",
        "  # Begin calcs without clamping\n",
        "\n",
        "  # IS\n",
        "  E_IS_sq = torch.mean(torch.mean(samples_IS, dim = 1)**2)\n",
        "  E_IS_all_sq = torch.mean(torch.mean(samples_IS, dim = 1))**2\n",
        "\n",
        "  # states_weight_diff\n",
        "  E_s_wdiff_sq = torch.mean(torch.mean(sample_sums_states_weight_diff, dim =1)**2)\n",
        "  E_s_wdiff_all_sq = torch.mean(torch.mean(sample_sums_states_weight_diff, dim = 1))**2\n",
        "\n",
        "  # all terms\n",
        "  SCOPE = sample_sums_states_weight_diff+samples_gamma_weight_states_last_sub_states_first\n",
        "  E_IS_SCOPE = torch.mean(torch.mean(samples_IS, dim =1) * torch.mean(SCOPE, dim =1))\n",
        "  E_IS_E_SCOPE = torch.mean(torch.mean(samples_IS,dim = 1 ))*torch.mean(torch.mean(SCOPE, dim =1))\n",
        "\n",
        "  # E_IS_SCOPE = torch.mean(torch.mean(samples_IS_SCOPE, dim =1))\n",
        "  # E_IS_E_SCOPE = torch.mean(torch.mean(samples_IS,dim = 1 )) * torch.mean(torch.mean(samples_all_shaping, dim =1))\n",
        "\n",
        "\n",
        "\n",
        "  # SCOPE_variance = E_IS_sq + 2*E_IS_SCOPE + E_s_wdiff_sq - E_IS_all_sq - 2*E_IS_E_SCOPE - E_IS_E_SCOPE\n",
        "  SCOPE_variance = E_IS_sq + 2*E_IS_SCOPE + E_s_wdiff_sq - E_IS_all_sq - 2*E_IS_E_SCOPE - E_s_wdiff_all_sq\n",
        "\n",
        "  IS_variance = E_IS_sq - E_IS_all_sq\n",
        "\n",
        "  return E_IS_sq, E_IS_all_sq, E_s_wdiff_sq, E_s_wdiff_all_sq, E_IS_SCOPE, E_IS_E_SCOPE, IS_variance, SCOPE_variance\n"
      ],
      "metadata": {
        "id": "2c4zRUmqHfz2"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimizing play"
      ],
      "metadata": {
        "id": "ScU_mVSALakh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "def train_var_play(model, num_epochs, learning_rate, padded_state_tensors, states_first_tensor, states_last_tensor, test1):\n",
        "    model.train()\n",
        "\n",
        "    # Enable anomaly detection\n",
        "    torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "\n",
        "        # Forward pass\n",
        "        states_output, states_first_output, states_last_output = test1.pass_states(model, padded_state_tensors, states_first_tensor, states_last_tensor)\n",
        "        sums_states_weight_diff = test1.states_weight_diff_sums(states_output, padded_weight_diff_tensors)\n",
        "        gamma_weights_states_last_sub_states_first = test1.last_first_terms_operations(gamma_weights_last_tensor, states_last_output, states_first_output, weight_first_tensor)\n",
        "        # sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, samples_all_shaping, samples_IS_SCOPE = test1.bootstrap_shaping_terms(sums_states_weight_diff, gamma_weights_states_last_sub_states_first, IS_tensor)\n",
        "\n",
        "        samples_IS, sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, samples_all_shaping, samples_IS_SCOPE = test1.bootstrap_all_terms(sums_states_weight_diff, gamma_weights_states_last_sub_states_first, IS_tensor)\n",
        "\n",
        "\n",
        "        E_IS_sq, E_IS_all_sq, E_s_wdiff_sq, E_s_wdiff_all_sq, E_IS_SCOPE, E_IS_E_SCOPE, _, variance_loss = calculate_shaped_variance_play(samples_IS, sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, samples_all_shaping, samples_IS_SCOPE)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}\")\n",
        "        print(\"Var loss: \", variance_loss)\n",
        "\n",
        "        # Print each term\n",
        "        print(f\"E_IS_sq: {E_IS_sq}\")\n",
        "        print(f\"E_IS_all_sq: {E_IS_all_sq}\")\n",
        "        print(f\"E_s_wdiff_sq: {E_s_wdiff_sq}\")\n",
        "        print(f\"E_s_wdiff_all_sq: {E_s_wdiff_all_sq}\")\n",
        "        print(f\"E_IS_SCOPE: {E_IS_SCOPE}\")\n",
        "        print(f\"E_IS_E_SCOPE: {E_IS_E_SCOPE}\")\n",
        "\n",
        "        tot = variance_loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Retain the graph to avoid clearing it before backward pass\n",
        "        tot.backward(retain_graph=True)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += tot.item()\n",
        "\n",
        "        print(f\"Total Loss: {total_loss}\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "    # Disable anomaly detection after running the code\n",
        "    torch.autograd.set_detect_anomaly(False)\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            print(f\"Parameter name: {name}\")\n",
        "            print(f\"Weights: {param.data}\")\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "6Dk99vwwLcPN"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# states_output, states_first_output, states_last_output = testing.pass_states(model, padded_state_tensors, states_first_tensor, states_last_tensor)\n",
        "# sums_states_weight_diff = testing.states_weight_diff_sums(states_output, padded_weight_diff_tensors)\n",
        "# gamma_weights_states_last_sub_states_first = testing.last_first_terms_operations(gamma_weights_last_tensor, states_last_output, states_first_output, weight_first_tensor)\n",
        "\n",
        "\n",
        "# sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, samples_all_shaping, samples_IS_SCOPE = testing.bootstrap_shaping_terms(sums_states_weight_diff, gamma_weights_states_last_sub_states_first, IS_tensor)\n",
        "# samples_IS, sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, samples_all_shaping, samples_IS_SCOPE = testing.bootstrap_all_terms(sums_states_weight_diff, gamma_weights_states_last_sub_states_first, IS_tensor)\n"
      ],
      "metadata": {
        "id": "fHvR4UmfMh6h"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Class play"
      ],
      "metadata": {
        "id": "GKFk2XRHQeQ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b = action_probs_top_n_epsilon(q_table, 1, 0.4)\n",
        "pi_b = experiment_actions(1000, env, P_pi_b)\n",
        "P_pi_e = action_probs_top_n_epsilon(q_table, 2, 0.05)\n",
        "pi_e = experiment_actions(1000, env, P_pi_e)"
      ],
      "metadata": {
        "id": "TnCDINz7AoG1"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CustomizableFeatureNet(input_dim=2, hidden_dims=[16, 32], output_dim=1, dtype = torch.float64)"
      ],
      "metadata": {
        "id": "gEgO1QxNLnCZ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing = SCOPE_variance_play(model, 0.9, 10000, pi_b, P_pi_b, P_pi_e, dtype = torch.float64)"
      ],
      "metadata": {
        "id": "I2S6fvyWQgjM"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IS_tensor, padded_state_tensors, padded_weight_diff_tensors, gamma_weights_last_tensor, states_first_tensor, states_last_tensor, weight_first_tensor = testing.prepare()"
      ],
      "metadata": {
        "id": "Uz6hDK3ZJjM6"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# P_pi_b[tuple(np.append(pi_b[0]['state'][0].astype(int) , (pi_b[0]['action'][0],)))]"
      ],
      "metadata": {
        "id": "5WwYv6SGDudT"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# padded_timesteps, padded_rewards, padded_actions, padded_weights = testing.padding_IS_terms(timesteps, actions, rewards, weights)"
      ],
      "metadata": {
        "id": "dmpbvgzDRSlz"
      },
=======
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
<<<<<<< HEAD
        "# padded_states, padded_weights_difference = testing.padding_states_weights_difference(states, weights_difference)\n",
        "# padded_state_tensors, padded_weight_diff_tensors = testing.tensorize_padded_terms(padded_states, padded_weights_difference)\n",
        "# states_first_tensor, states_last_tensor, gamma_last_tensor, weights_last_tensor = testing.tensorize_last_and_first_terms(states_first, states_last, gamma_last, weights_last)\n",
        "# IS_tensor = testing.calc_IS_terms(testing.gamma, padded_timesteps, padded_rewards, padded_weights)"
      ],
      "metadata": {
        "id": "x68IJ4fcRYjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# states_output, states_first_output, states_last_output = testing.pass_states(model, padded_state_tensors, states_first_tensor, states_last_tensor)\n",
        "# sums_states_weight_diff = testing.states_weight_diff_sums(states_output, padded_weight_diff_tensors)\n",
        "\n",
        "# gamma_weights_last_tensor = testing.calc_gamma_weight_last(testing.gamma, gamma_last, weights_last)\n",
        "\n",
        "# gamma_weights_states_last_sub_states_first = testing.last_first_terms_operations(gamma_weights_last_tensor, states_last_output, states_first_output, weight_first_tensor)\n"
      ],
      "metadata": {
        "id": "JTJBak1Gco7n"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "XBOko5a3I0y_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 200 trajectories"
      ],
      "metadata": {
        "id": "mP1Eorc7oaMn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "200 Trajectories:"
      ],
      "metadata": {
        "id": "QWksRYNyI5dG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b = action_probs_top_n_epsilon(q_table, 1, 0.4)\n",
        "pi_b = experiment_actions(200, env, P_pi_b)\n",
        "P_pi_e = action_probs_top_n_epsilon(q_table, 2, 0.05)\n",
        "pi_e = experiment_actions(200, env, P_pi_e)"
      ],
      "metadata": {
        "id": "v4PMaoImI8LA"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_200 = CustomizableFeatureNet(input_dim=2, hidden_dims=[16, 32], output_dim=1, dtype = torch.float64)"
      ],
      "metadata": {
        "id": "gdGaF6NLJKVS"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing = SCOPE_variance_play(model, 0.9, 10000, pi_b, P_pi_b, P_pi_e, dtype = torch.float64)"
      ],
      "metadata": {
        "id": "vjYDF_4AJ2_j"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IS_tensor, padded_state_tensors, padded_weight_diff_tensors, gamma_weights_last_tensor, states_first_tensor, states_last_tensor, weight_first_tensor = testing.prepare()"
      ],
      "metadata": {
        "id": "pCRa5GCXJrrs"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# single cumprod\n",
        "# 200 trajectories\n",
        "model_200_1 = train_var_play(model_200_1, 10000, 0.00001, padded_state_tensors, states_first_tensor, states_last_tensor, 1, 1, testing)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-W1dMNu9G2LG",
        "outputId": "2e7afe83-b464-466d-b915-183ffb10c2be"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "E_s_wdiff_sq: 4.38847191911032e-06\n",
            "E_s_wdiff_all_sq: 3.15800391788682e-06\n",
            "E_IS_SCOPE: -5.766325127812846e-06\n",
            "E_IS_E_SCOPE: -5.66172682299423e-06\n",
            "Total Loss: 1.091068815126523e-06\n",
            "----------------------------------------\n",
            "Epoch 9518\n",
            "Var loss:  tensor(1.0953e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.527863768198031e-06\n",
            "E_s_wdiff_all_sq: 2.2941945960291768e-06\n",
            "E_IS_SCOPE: -5.899649424598025e-06\n",
            "E_IS_E_SCOPE: -5.795563533271517e-06\n",
            "Total Loss: 1.0952948130560935e-06\n",
            "----------------------------------------\n",
            "Epoch 9519\n",
            "Var loss:  tensor(1.0954e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 4.456038072800653e-06\n",
            "E_s_wdiff_all_sq: 3.221473215770739e-06\n",
            "E_IS_SCOPE: -5.755665235763313e-06\n",
            "E_IS_E_SCOPE: -5.6511831324721756e-06\n",
            "Total Loss: 1.0953980739878948e-06\n",
            "----------------------------------------\n",
            "Epoch 9520\n",
            "Var loss:  tensor(1.0904e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.569436205812138e-06\n",
            "E_s_wdiff_all_sq: 2.339867639627138e-06\n",
            "E_IS_SCOPE: -5.891617265209445e-06\n",
            "E_IS_E_SCOPE: -5.7871237325456215e-06\n",
            "Total Loss: 1.0903789243976095e-06\n",
            "----------------------------------------\n",
            "Epoch 9521\n",
            "Var loss:  tensor(1.0827e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 4.225270331206992e-06\n",
            "E_s_wdiff_all_sq: 3.003524367052593e-06\n",
            "E_IS_SCOPE: -5.785854881969517e-06\n",
            "E_IS_E_SCOPE: -5.68145123387259e-06\n",
            "Total Loss: 1.0827360915007997e-06\n",
            "----------------------------------------\n",
            "Epoch 9522\n",
            "Var loss:  tensor(1.0773e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.851088252790376e-06\n",
            "E_s_wdiff_all_sq: 2.635047627777052e-06\n",
            "E_IS_SCOPE: -5.841420702792026e-06\n",
            "E_IS_E_SCOPE: -5.73716362511739e-06\n",
            "Total Loss: 1.0773238932043069e-06\n",
            "----------------------------------------\n",
            "Epoch 9523\n",
            "Var loss:  tensor(1.0771e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.855634100325013e-06\n",
            "E_s_wdiff_all_sq: 2.639351582019644e-06\n",
            "E_IS_SCOPE: -5.84080100449255e-06\n",
            "E_IS_E_SCOPE: -5.736301388550214e-06\n",
            "Total Loss: 1.0770807099609526e-06\n",
            "----------------------------------------\n",
            "Epoch 9524\n",
            "Var loss:  tensor(1.0807e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 4.167082845004065e-06\n",
            "E_s_wdiff_all_sq: 2.94716623148433e-06\n",
            "E_IS_SCOPE: -5.7929223654373915e-06\n",
            "E_IS_E_SCOPE: -5.688417256273382e-06\n",
            "Total Loss: 1.0807038187319713e-06\n",
            "----------------------------------------\n",
            "Epoch 9525\n",
            "Var loss:  tensor(1.0843e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.656068581850934e-06\n",
            "E_s_wdiff_all_sq: 2.433195466787049e-06\n",
            "E_IS_SCOPE: -5.87289028017247e-06\n",
            "E_IS_E_SCOPE: -5.7686815229026415e-06\n",
            "Total Loss: 1.084253024064484e-06\n",
            "----------------------------------------\n",
            "Epoch 9526\n",
            "Var loss:  tensor(1.0844e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 4.261290190173776e-06\n",
            "E_s_wdiff_all_sq: 3.0377447596015306e-06\n",
            "E_IS_SCOPE: -5.7787546766885674e-06\n",
            "E_IS_E_SCOPE: -5.674298642529952e-06\n",
            "Total Loss: 1.0844307857952703e-06\n",
            "----------------------------------------\n",
            "Epoch 9527\n",
            "Var loss:  tensor(1.0812e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.7076295474075283e-06\n",
            "E_s_wdiff_all_sq: 2.4872354563238173e-06\n",
            "E_IS_SCOPE: -5.8640267821748395e-06\n",
            "E_IS_E_SCOPE: -5.759515209450636e-06\n",
            "Total Loss: 1.0811683691755597e-06\n",
            "----------------------------------------\n",
            "Epoch 9528\n",
            "Var loss:  tensor(1.0775e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 4.059578886802948e-06\n",
            "E_s_wdiff_all_sq: 2.8431598409512067e-06\n",
            "E_IS_SCOPE: -5.807284597208764e-06\n",
            "E_IS_E_SCOPE: -5.702904479801622e-06\n",
            "Total Loss: 1.0774562345777122e-06\n",
            "----------------------------------------\n",
            "Epoch 9529\n",
            "Var loss:  tensor(1.0763e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.9662635189238415e-06\n",
            "E_s_wdiff_all_sq: 2.7509288615917255e-06\n",
            "E_IS_SCOPE: -5.821645165371173e-06\n",
            "E_IS_E_SCOPE: -5.717237137112339e-06\n",
            "Total Loss: 1.0763160243547038e-06\n",
            "----------------------------------------\n",
            "Epoch 9530\n",
            "Var loss:  tensor(1.0780e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.8034582897068277e-06\n",
            "E_s_wdiff_all_sq: 2.5862139849894355e-06\n",
            "E_IS_SCOPE: -5.848276863306319e-06\n",
            "E_IS_E_SCOPE: -5.7437422552475626e-06\n",
            "Total Loss: 1.0779725121401352e-06\n",
            "----------------------------------------\n",
            "Epoch 9531\n",
            "Var loss:  tensor(1.0801e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 4.167646927178352e-06\n",
            "E_s_wdiff_all_sq: 2.9483655143922953e-06\n",
            "E_IS_SCOPE: -5.792038982595728e-06\n",
            "E_IS_E_SCOPE: -5.687542412813375e-06\n",
            "Total Loss: 1.0800856967616053e-06\n",
            "----------------------------------------\n",
            "Epoch 9532\n",
            "Var loss:  tensor(1.0803e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.7359083723781273e-06\n",
            "E_s_wdiff_all_sq: 2.5167543458658393e-06\n",
            "E_IS_SCOPE: -5.858832801780097e-06\n",
            "E_IS_E_SCOPE: -5.754531093294928e-06\n",
            "Total Loss: 1.0803480330822072e-06\n",
            "----------------------------------------\n",
            "Epoch 9533\n",
            "Var loss:  tensor(1.0786e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 4.120110834137758e-06\n",
            "E_s_wdiff_all_sq: 2.902266211881479e-06\n",
            "E_IS_SCOPE: -5.799021233031091e-06\n",
            "E_IS_E_SCOPE: -5.6944889661857555e-06\n",
            "Total Loss: 1.078577512105863e-06\n",
            "----------------------------------------\n",
            "Epoch 9534\n",
            "Var loss:  tensor(1.0766e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.871233787169449e-06\n",
            "E_s_wdiff_all_sq: 2.6555786766473875e-06\n",
            "E_IS_SCOPE: -5.8371102178909225e-06\n",
            "E_IS_E_SCOPE: -5.732672319239351e-06\n",
            "Total Loss: 1.0765767367591735e-06\n",
            "----------------------------------------\n",
            "Epoch 9535\n",
            "Var loss:  tensor(1.0761e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.925663883123361e-06\n",
            "E_s_wdiff_all_sq: 2.7106849246065947e-06\n",
            "E_IS_SCOPE: -5.828562608352199e-06\n",
            "E_IS_E_SCOPE: -5.724218302927668e-06\n",
            "Total Loss: 1.07608777120796e-06\n",
            "----------------------------------------\n",
            "Epoch 9536\n",
            "Var loss:  tensor(1.0771e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 4.0683892861776586e-06\n",
            "E_s_wdiff_all_sq: 2.8521836100943184e-06\n",
            "E_IS_SCOPE: -5.807228484830178e-06\n",
            "E_IS_E_SCOPE: -5.7027736796891254e-06\n",
            "Total Loss: 1.07709348934149e-06\n",
            "----------------------------------------\n",
            "Epoch 9537\n",
            "Var loss:  tensor(1.0782e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.79561881913546e-06\n",
            "E_s_wdiff_all_sq: 2.578320250066223e-06\n",
            "E_IS_SCOPE: -5.850417583285323e-06\n",
            "E_IS_E_SCOPE: -5.745951607627239e-06\n",
            "Total Loss: 1.078164041293325e-06\n",
            "----------------------------------------\n",
            "Epoch 9538\n",
            "Var loss:  tensor(1.0781e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 4.1213733623807385e-06\n",
            "E_s_wdiff_all_sq: 2.9042152304330397e-06\n",
            "E_IS_SCOPE: -5.799814667242595e-06\n",
            "E_IS_E_SCOPE: -5.695377861527511e-06\n",
            "Total Loss: 1.0780819440577855e-06\n",
            "----------------------------------------\n",
            "Epoch 9539\n",
            "Var loss:  tensor(1.0770e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.8473732666517165e-06\n",
            "E_s_wdiff_all_sq: 2.6315026451193964e-06\n",
            "E_IS_SCOPE: -5.8420379750974015e-06\n",
            "E_IS_E_SCOPE: -5.73769223145354e-06\n",
            "Total Loss: 1.0769765577848535e-06\n",
            "----------------------------------------\n",
            "Epoch 9540\n",
            "Var loss:  tensor(1.0760e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 4.003414652300106e-06\n",
            "E_s_wdiff_all_sq: 2.7883307908411615e-06\n",
            "E_IS_SCOPE: -5.8180339423575645e-06\n",
            "E_IS_E_SCOPE: -5.713574734299089e-06\n",
            "Total Loss: 1.0759628688822491e-06\n",
            "----------------------------------------\n",
            "Epoch 9541\n",
            "Var loss:  tensor(1.0759e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.99534777732715e-06\n",
            "E_s_wdiff_all_sq: 2.7799888129748508e-06\n",
            "E_IS_SCOPE: -5.820095225083768e-06\n",
            "E_IS_E_SCOPE: -5.715459257661103e-06\n",
            "Total Loss: 1.0758844530472255e-06\n",
            "----------------------------------------\n",
            "Epoch 9542\n",
            "Var loss:  tensor(1.0765e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.874124288879443e-06\n",
            "E_s_wdiff_all_sq: 2.6587021971418038e-06\n",
            "E_IS_SCOPE: -5.838215372195986e-06\n",
            "E_IS_E_SCOPE: -5.733856376674704e-06\n",
            "Total Loss: 1.0765015242353297e-06\n",
            "----------------------------------------\n",
            "Epoch 9543\n",
            "Var loss:  tensor(1.0770e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 4.091512004917439e-06\n",
            "E_s_wdiff_all_sq: 2.8755379082232386e-06\n",
            "E_IS_SCOPE: -5.804204020250739e-06\n",
            "E_IS_E_SCOPE: -5.6998048042516095e-06\n",
            "Total Loss: 1.0769730882361975e-06\n",
            "----------------------------------------\n",
            "Epoch 9544\n",
            "Var loss:  tensor(1.0768e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.846162429157586e-06\n",
            "E_s_wdiff_all_sq: 2.63011389879988e-06\n",
            "E_IS_SCOPE: -5.8420673499846804e-06\n",
            "E_IS_E_SCOPE: -5.737522053561445e-06\n",
            "Total Loss: 1.07675536105149e-06\n",
            "----------------------------------------\n",
            "Epoch 9545\n",
            "Var loss:  tensor(1.0761e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 4.031871178701712e-06\n",
            "E_s_wdiff_all_sq: 2.816542423739114e-06\n",
            "E_IS_SCOPE: -5.8122630308835385e-06\n",
            "E_IS_E_SCOPE: -5.707737775187899e-06\n",
            "Total Loss: 1.0760756671115747e-06\n",
            "----------------------------------------\n",
            "Epoch 9546\n",
            "Var loss:  tensor(1.0756e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.942381420179745e-06\n",
            "E_s_wdiff_all_sq: 2.7279595183613128e-06\n",
            "E_IS_SCOPE: -5.824951025956383e-06\n",
            "E_IS_E_SCOPE: -5.720638287882957e-06\n",
            "Total Loss: 1.0755938492118365e-06\n",
            "----------------------------------------\n",
            "Epoch 9547\n",
            "Var loss:  tensor(1.0756e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.919503552634352e-06\n",
            "E_s_wdiff_all_sq: 2.704785862528621e-06\n",
            "E_IS_SCOPE: -5.828510636828593e-06\n",
            "E_IS_E_SCOPE: -5.7240737456803715e-06\n",
            "Total Loss: 1.0756413313495438e-06\n",
            "----------------------------------------\n",
            "Epoch 9548\n",
            "Var loss:  tensor(1.0760e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 4.029462932548948e-06\n",
            "E_s_wdiff_all_sq: 2.814135017876321e-06\n",
            "E_IS_SCOPE: -5.811397335361469e-06\n",
            "E_IS_E_SCOPE: -5.706829403294591e-06\n",
            "Total Loss: 1.0759894740791265e-06\n",
            "----------------------------------------\n",
            "Epoch 9549\n",
            "Var loss:  tensor(1.0762e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.863422619014278e-06\n",
            "E_s_wdiff_all_sq: 2.6482831429891915e-06\n",
            "E_IS_SCOPE: -5.836357507704218e-06\n",
            "E_IS_E_SCOPE: -5.731968544171137e-06\n",
            "Total Loss: 1.0761589724991796e-06\n",
            "----------------------------------------\n",
            "Epoch 9550\n",
            "Var loss:  tensor(1.0759e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 4.035788100990695e-06\n",
            "E_s_wdiff_all_sq: 2.820886368339202e-06\n",
            "E_IS_SCOPE: -5.8090639535050874e-06\n",
            "E_IS_E_SCOPE: -5.704687212183915e-06\n",
            "Total Loss: 1.0759456735494035e-06\n",
            "----------------------------------------\n",
            "Epoch 9551\n",
            "Var loss:  tensor(1.0756e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.903292573172841e-06\n",
            "E_s_wdiff_all_sq: 2.688543108677672e-06\n",
            "E_IS_SCOPE: -5.829640153208724e-06\n",
            "E_IS_E_SCOPE: -5.725142515927759e-06\n",
            "Total Loss: 1.0755516134734965e-06\n",
            "----------------------------------------\n",
            "Epoch 9552\n",
            "Var loss:  tensor(1.0753e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.957301701232845e-06\n",
            "E_s_wdiff_all_sq: 2.742830951640444e-06\n",
            "E_IS_SCOPE: -5.820876806433726e-06\n",
            "E_IS_E_SCOPE: -5.716401204749131e-06\n",
            "Total Loss: 1.0753169697634657e-06\n",
            "----------------------------------------\n",
            "Epoch 9553\n",
            "Var loss:  tensor(1.0754e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.985644027029507e-06\n",
            "E_s_wdiff_all_sq: 2.7713432228822173e-06\n",
            "E_IS_SCOPE: -5.815522510217386e-06\n",
            "E_IS_E_SCOPE: -5.711157696396474e-06\n",
            "Total Loss: 1.0753686000457206e-06\n",
            "----------------------------------------\n",
            "Epoch 9554\n",
            "Var loss:  tensor(1.0755e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.882931259844198e-06\n",
            "E_s_wdiff_all_sq: 2.6680481145799096e-06\n",
            "E_IS_SCOPE: -5.831451623704472e-06\n",
            "E_IS_E_SCOPE: -5.726881077219263e-06\n",
            "Total Loss: 1.075539475834127e-06\n",
            "----------------------------------------\n",
            "Epoch 9555\n",
            "Var loss:  tensor(1.0756e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 4.0113633796403845e-06\n",
            "E_s_wdiff_all_sq: 2.7965002380854335e-06\n",
            "E_IS_SCOPE: -5.8108718608473986e-06\n",
            "E_IS_E_SCOPE: -5.7063337689816405e-06\n",
            "Total Loss: 1.0755843813636904e-06\n",
            "----------------------------------------\n",
            "Epoch 9556\n",
            "Var loss:  tensor(1.0754e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.8886507153162675e-06\n",
            "E_s_wdiff_all_sq: 2.6741765979220202e-06\n",
            "E_IS_SCOPE: -5.8293500042319455e-06\n",
            "E_IS_E_SCOPE: -5.724928205631947e-06\n",
            "Total Loss: 1.0754279437345073e-06\n",
            "----------------------------------------\n",
            "Epoch 9557\n",
            "Var loss:  tensor(1.0752e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.976436276877046e-06\n",
            "E_s_wdiff_all_sq: 2.7619853098803687e-06\n",
            "E_IS_SCOPE: -5.81567725544246e-06\n",
            "E_IS_E_SCOPE: -5.711150416008945e-06\n",
            "Total Loss: 1.0751947116699034e-06\n",
            "----------------------------------------\n",
            "Epoch 9558\n",
            "Var loss:  tensor(1.0751e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.94208790572713e-06\n",
            "E_s_wdiff_all_sq: 2.727647860217762e-06\n",
            "E_IS_SCOPE: -5.821062849672837e-06\n",
            "E_IS_E_SCOPE: -5.7164762070333824e-06\n",
            "Total Loss: 1.0750641837707151e-06\n",
            "----------------------------------------\n",
            "Epoch 9559\n",
            "Var loss:  tensor(1.0751e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.919419404742822e-06\n",
            "E_s_wdiff_all_sq: 2.7051686484026517e-06\n",
            "E_IS_SCOPE: -5.824136942276194e-06\n",
            "E_IS_E_SCOPE: -5.7196530600088736e-06\n",
            "Total Loss: 1.0750804153457854e-06\n",
            "----------------------------------------\n",
            "Epoch 9560\n",
            "Var loss:  tensor(1.0752e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.996969016680997e-06\n",
            "E_s_wdiff_all_sq: 2.782939639770638e-06\n",
            "E_IS_SCOPE: -5.811598131854365e-06\n",
            "E_IS_E_SCOPE: -5.707263142624173e-06\n",
            "Total Loss: 1.0751568219902305e-06\n",
            "----------------------------------------\n",
            "Epoch 9561\n",
            "Var loss:  tensor(1.0752e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.895886615770948e-06\n",
            "E_s_wdiff_all_sq: 2.681333967524385e-06\n",
            "E_IS_SCOPE: -5.828156807151202e-06\n",
            "E_IS_E_SCOPE: -5.723560205318076e-06\n",
            "Total Loss: 1.0751568681205664e-06\n",
            "----------------------------------------\n",
            "Epoch 9562\n",
            "Var loss:  tensor(1.0750e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.989767126879498e-06\n",
            "E_s_wdiff_all_sq: 2.775458421304949e-06\n",
            "E_IS_SCOPE: -5.8131300098450824e-06\n",
            "E_IS_E_SCOPE: -5.708600138328558e-06\n",
            "Total Loss: 1.0750463860817563e-06\n",
            "----------------------------------------\n",
            "Epoch 9563\n",
            "Var loss:  tensor(1.0749e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.929177878035876e-06\n",
            "E_s_wdiff_all_sq: 2.7154887547501436e-06\n",
            "E_IS_SCOPE: -5.821563981589223e-06\n",
            "E_IS_E_SCOPE: -5.717273200383936e-06\n",
            "Total Loss: 1.0749049844154137e-06\n",
            "----------------------------------------\n",
            "Epoch 9564\n",
            "Var loss:  tensor(1.0748e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.948352369915289e-06\n",
            "E_s_wdiff_all_sq: 2.7343919145347295e-06\n",
            "E_IS_SCOPE: -5.818845220834585e-06\n",
            "E_IS_E_SCOPE: -5.714372230203928e-06\n",
            "Total Loss: 1.0748118976595017e-06\n",
            "----------------------------------------\n",
            "Epoch 9565\n",
            "Var loss:  tensor(1.0748e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.961079816149422e-06\n",
            "E_s_wdiff_all_sq: 2.746812542140073e-06\n",
            "E_IS_SCOPE: -5.816973894750032e-06\n",
            "E_IS_E_SCOPE: -5.712343878302566e-06\n",
            "Total Loss: 1.0748046646546716e-06\n",
            "----------------------------------------\n",
            "Epoch 9566\n",
            "Var loss:  tensor(1.0748e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.914638254972246e-06\n",
            "E_s_wdiff_all_sq: 2.700818459626638e-06\n",
            "E_IS_SCOPE: -5.82337168411315e-06\n",
            "E_IS_E_SCOPE: -5.7189731371340405e-06\n",
            "Total Loss: 1.074820124927645e-06\n",
            "----------------------------------------\n",
            "Epoch 9567\n",
            "Var loss:  tensor(1.0748e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.9850242790767755e-06\n",
            "E_s_wdiff_all_sq: 2.771222756889631e-06\n",
            "E_IS_SCOPE: -5.81221297018405e-06\n",
            "E_IS_E_SCOPE: -5.707814967644949e-06\n",
            "Total Loss: 1.0748029406491977e-06\n",
            "----------------------------------------\n",
            "Epoch 9568\n",
            "Var loss:  tensor(1.0747e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.908292263342644e-06\n",
            "E_s_wdiff_all_sq: 2.694027298990937e-06\n",
            "E_IS_SCOPE: -5.824662241856221e-06\n",
            "E_IS_E_SCOPE: -5.7199970677033685e-06\n",
            "Total Loss: 1.074732039586258e-06\n",
            "----------------------------------------\n",
            "Epoch 9569\n",
            "Var loss:  tensor(1.0746e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.963741810407853e-06\n",
            "E_s_wdiff_all_sq: 2.7498704232199987e-06\n",
            "E_IS_SCOPE: -5.815416063788513e-06\n",
            "E_IS_E_SCOPE: -5.710897040438026e-06\n",
            "Total Loss: 1.0746307640271364e-06\n",
            "----------------------------------------\n",
            "Epoch 9570\n",
            "Var loss:  tensor(1.0746e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.945907023144082e-06\n",
            "E_s_wdiff_all_sq: 2.7324721991707438e-06\n",
            "E_IS_SCOPE: -5.817145805125406e-06\n",
            "E_IS_E_SCOPE: -5.712811079062603e-06\n",
            "Total Loss: 1.0745627953879878e-06\n",
            "----------------------------------------\n",
            "Epoch 9571\n",
            "Var loss:  tensor(1.0745e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.929320898136943e-06\n",
            "E_s_wdiff_all_sq: 2.7154086787147724e-06\n",
            "E_IS_SCOPE: -5.8201204578907224e-06\n",
            "E_IS_E_SCOPE: -5.715531286641313e-06\n",
            "Total Loss: 1.074531300463608e-06\n",
            "----------------------------------------\n",
            "Epoch 9572\n",
            "Var loss:  tensor(1.0745e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.966056576864586e-06\n",
            "E_s_wdiff_all_sq: 2.7522103655874765e-06\n",
            "E_IS_SCOPE: -5.813853370218785e-06\n",
            "E_IS_E_SCOPE: -5.709292721964163e-06\n",
            "Total Loss: 1.0745223383081218e-06\n",
            "----------------------------------------\n",
            "Epoch 9573\n",
            "Var loss:  tensor(1.0745e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.919330264340184e-06\n",
            "E_s_wdiff_all_sq: 2.7060030291724672e-06\n",
            "E_IS_SCOPE: -5.819896830832007e-06\n",
            "E_IS_E_SCOPE: -5.715586627344493e-06\n",
            "Total Loss: 1.0745042517329447e-06\n",
            "----------------------------------------\n",
            "Epoch 9574\n",
            "Var loss:  tensor(1.0744e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.962966791600763e-06\n",
            "E_s_wdiff_all_sq: 2.7491446556950943e-06\n",
            "E_IS_SCOPE: -5.813548066856493e-06\n",
            "E_IS_E_SCOPE: -5.708961333417384e-06\n",
            "Total Loss: 1.074446092567707e-06\n",
            "----------------------------------------\n",
            "Epoch 9575\n",
            "Var loss:  tensor(1.0744e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.922440620655106e-06\n",
            "E_s_wdiff_all_sq: 2.7086917224639757e-06\n",
            "E_IS_SCOPE: -5.819756672833493e-06\n",
            "E_IS_E_SCOPE: -5.715171708974242e-06\n",
            "Total Loss: 1.0743763940128838e-06\n",
            "----------------------------------------\n",
            "Epoch 9576\n",
            "Var loss:  tensor(1.0743e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.951214824095171e-06\n",
            "E_s_wdiff_all_sq: 2.7379870994173274e-06\n",
            "E_IS_SCOPE: -5.814586522586674e-06\n",
            "E_IS_E_SCOPE: -5.710231257330604e-06\n",
            "Total Loss: 1.0743146177059592e-06\n",
            "----------------------------------------\n",
            "Epoch 9577\n",
            "Var loss:  tensor(1.0743e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.948334110116927e-06\n",
            "E_s_wdiff_all_sq: 2.734735059401108e-06\n",
            "E_IS_SCOPE: -5.815587571407392e-06\n",
            "E_IS_E_SCOPE: -5.711023487347607e-06\n",
            "Total Loss: 1.0742683061365053e-06\n",
            "----------------------------------------\n",
            "Epoch 9578\n",
            "Var loss:  tensor(1.0742e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.92802202032099e-06\n",
            "E_s_wdiff_all_sq: 2.714430166001091e-06\n",
            "E_IS_SCOPE: -5.8187689706820826e-06\n",
            "E_IS_E_SCOPE: -5.714195428166172e-06\n",
            "Total Loss: 1.0742421928283334e-06\n",
            "----------------------------------------\n",
            "Epoch 9579\n",
            "Var loss:  tensor(1.0742e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.969613025850328e-06\n",
            "E_s_wdiff_all_sq: 2.7564711269817356e-06\n",
            "E_IS_SCOPE: -5.8116832712198455e-06\n",
            "E_IS_E_SCOPE: -5.707321615030433e-06\n",
            "Total Loss: 1.0742160100300227e-06\n",
            "----------------------------------------\n",
            "Epoch 9580\n",
            "Var loss:  tensor(1.0742e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.925092203985045e-06\n",
            "E_s_wdiff_all_sq: 2.7116374947526263e-06\n",
            "E_IS_SCOPE: -5.818977469186906e-06\n",
            "E_IS_E_SCOPE: -5.714436053673389e-06\n",
            "Total Loss: 1.074169301745639e-06\n",
            "----------------------------------------\n",
            "Epoch 9581\n",
            "Var loss:  tensor(1.0741e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.95405982089028e-06\n",
            "E_s_wdiff_all_sq: 2.740470555282086e-06\n",
            "E_IS_SCOPE: -5.814358283763257e-06\n",
            "E_IS_E_SCOPE: -5.7097228233778835e-06\n",
            "Total Loss: 1.0741157683777022e-06\n",
            "----------------------------------------\n",
            "Epoch 9582\n",
            "Var loss:  tensor(1.0741e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.939507957241941e-06\n",
            "E_s_wdiff_all_sq: 2.726479233005817e-06\n",
            "E_IS_SCOPE: -5.815849041030463e-06\n",
            "E_IS_E_SCOPE: -5.711469632900799e-06\n",
            "Total Loss: 1.0740673315170499e-06\n",
            "----------------------------------------\n",
            "Epoch 9583\n",
            "Var loss:  tensor(1.0740e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.9393351835994596e-06\n",
            "E_s_wdiff_all_sq: 2.72597864916395e-06\n",
            "E_IS_SCOPE: -5.815930303566883e-06\n",
            "E_IS_E_SCOPE: -5.7113596494042445e-06\n",
            "Total Loss: 1.0740126496504885e-06\n",
            "----------------------------------------\n",
            "Epoch 9584\n",
            "Var loss:  tensor(1.0740e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.947474475533888e-06\n",
            "E_s_wdiff_all_sq: 2.7341700111681443e-06\n",
            "E_IS_SCOPE: -5.8142854846817275e-06\n",
            "E_IS_E_SCOPE: -5.70972226132603e-06\n",
            "Total Loss: 1.0739754411946037e-06\n",
            "----------------------------------------\n",
            "Epoch 9585\n",
            "Var loss:  tensor(1.0739e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.930937066642501e-06\n",
            "E_s_wdiff_all_sq: 2.7178914378103065e-06\n",
            "E_IS_SCOPE: -5.816223927034968e-06\n",
            "E_IS_E_SCOPE: -5.711773304765712e-06\n",
            "Total Loss: 1.0739418078339392e-06\n",
            "----------------------------------------\n",
            "Epoch 9586\n",
            "Var loss:  tensor(1.0739e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.9540510214990854e-06\n",
            "E_s_wdiff_all_sq: 2.7407904040056616e-06\n",
            "E_IS_SCOPE: -5.812698829549256e-06\n",
            "E_IS_E_SCOPE: -5.708120119558738e-06\n",
            "Total Loss: 1.0739006210526431e-06\n",
            "----------------------------------------\n",
            "Epoch 9587\n",
            "Var loss:  tensor(1.0739e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.9322147882311825e-06\n",
            "E_s_wdiff_all_sq: 2.719132050623814e-06\n",
            "E_IS_SCOPE: -5.815869973992492e-06\n",
            "E_IS_E_SCOPE: -5.711358022246202e-06\n",
            "Total Loss: 1.0738562576550432e-06\n",
            "----------------------------------------\n",
            "Epoch 9588\n",
            "Var loss:  tensor(1.0738e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.952334247814229e-06\n",
            "E_s_wdiff_all_sq: 2.739310250075963e-06\n",
            "E_IS_SCOPE: -5.812391668555188e-06\n",
            "E_IS_E_SCOPE: -5.70788418583142e-06\n",
            "Total Loss: 1.0738064558309855e-06\n",
            "----------------------------------------\n",
            "Epoch 9589\n",
            "Var loss:  tensor(1.0738e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.938444106643734e-06\n",
            "E_s_wdiff_all_sq: 2.7254037079995596e-06\n",
            "E_IS_SCOPE: -5.814233475509035e-06\n",
            "E_IS_E_SCOPE: -5.709694274662253e-06\n",
            "Total Loss: 1.0737594204908649e-06\n",
            "----------------------------------------\n",
            "Epoch 9590\n",
            "Var loss:  tensor(1.0737e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.938638016548185e-06\n",
            "E_s_wdiff_all_sq: 2.7257989489370287e-06\n",
            "E_IS_SCOPE: -5.813603521947348e-06\n",
            "E_IS_E_SCOPE: -5.70914518960819e-06\n",
            "Total Loss: 1.0737198264730951e-06\n",
            "----------------------------------------\n",
            "Epoch 9591\n",
            "Var loss:  tensor(1.0737e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.943499433739511e-06\n",
            "E_s_wdiff_all_sq: 2.7303757276572974e-06\n",
            "E_IS_SCOPE: -5.813129279861824e-06\n",
            "E_IS_E_SCOPE: -5.708508652001433e-06\n",
            "Total Loss: 1.0736798739016875e-06\n",
            "----------------------------------------\n",
            "Epoch 9592\n",
            "Var loss:  tensor(1.0736e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.93208086978371e-06\n",
            "E_s_wdiff_all_sq: 2.719202643434479e-06\n",
            "E_IS_SCOPE: -5.8145703867406966e-06\n",
            "E_IS_E_SCOPE: -5.710051937791656e-06\n",
            "Total Loss: 1.0736387519914057e-06\n",
            "----------------------------------------\n",
            "Epoch 9593\n",
            "Var loss:  tensor(1.0736e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.95466815886939e-06\n",
            "E_s_wdiff_all_sq: 2.7419436424321114e-06\n",
            "E_IS_SCOPE: -5.8110599791493505e-06\n",
            "E_IS_E_SCOPE: -5.706599910294798e-06\n",
            "Total Loss: 1.07360180226843e-06\n",
            "----------------------------------------\n",
            "Epoch 9594\n",
            "Var loss:  tensor(1.0736e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.933933061200255e-06\n",
            "E_s_wdiff_all_sq: 2.721023286181836e-06\n",
            "E_IS_SCOPE: -5.8144030144240254e-06\n",
            "E_IS_E_SCOPE: -5.709827252339738e-06\n",
            "Total Loss: 1.0735556743901003e-06\n",
            "----------------------------------------\n",
            "Epoch 9595\n",
            "Var loss:  tensor(1.0735e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.94460636209975e-06\n",
            "E_s_wdiff_all_sq: 2.7316942397551837e-06\n",
            "E_IS_SCOPE: -5.8124157051877535e-06\n",
            "E_IS_E_SCOPE: -5.707814903135125e-06\n",
            "Total Loss: 1.073507941779565e-06\n",
            "----------------------------------------\n",
            "Epoch 9596\n",
            "Var loss:  tensor(1.0735e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.941181073800531e-06\n",
            "E_s_wdiff_all_sq: 2.7285795332041495e-06\n",
            "E_IS_SCOPE: -5.812250126540444e-06\n",
            "E_IS_E_SCOPE: -5.707781982551437e-06\n",
            "Total Loss: 1.0734626761586223e-06\n",
            "----------------------------------------\n",
            "Epoch 9597\n",
            "Var loss:  tensor(1.0734e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.94040248803598e-06\n",
            "E_s_wdiff_all_sq: 2.7277775212099046e-06\n",
            "E_IS_SCOPE: -5.812167856432682e-06\n",
            "E_IS_E_SCOPE: -5.707668328166796e-06\n",
            "Total Loss: 1.07342333383456e-06\n",
            "----------------------------------------\n",
            "Epoch 9598\n",
            "Var loss:  tensor(1.0734e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.946034399120729e-06\n",
            "E_s_wdiff_all_sq: 2.7332747543834e-06\n",
            "E_IS_SCOPE: -5.811337094069115e-06\n",
            "E_IS_E_SCOPE: -5.706749679262831e-06\n",
            "Total Loss: 1.073382238665017e-06\n",
            "----------------------------------------\n",
            "Epoch 9599\n",
            "Var loss:  tensor(1.0733e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.938314736545158e-06\n",
            "E_s_wdiff_all_sq: 2.7258077138446847e-06\n",
            "E_IS_SCOPE: -5.81201606735636e-06\n",
            "E_IS_E_SCOPE: -5.707533817329983e-06\n",
            "Total Loss: 1.0733399461879755e-06\n",
            "----------------------------------------\n",
            "Epoch 9600\n",
            "Var loss:  tensor(1.0733e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.948446050399372e-06\n",
            "E_s_wdiff_all_sq: 2.7357541978575907e-06\n",
            "E_IS_SCOPE: -5.810696234173896e-06\n",
            "E_IS_E_SCOPE: -5.706101884133201e-06\n",
            "Total Loss: 1.0733005760006475e-06\n",
            "----------------------------------------\n",
            "Epoch 9601\n",
            "Var loss:  tensor(1.0733e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.936834964250435e-06\n",
            "E_s_wdiff_all_sq: 2.724324686648794e-06\n",
            "E_IS_SCOPE: -5.8119670686199925e-06\n",
            "E_IS_E_SCOPE: -5.707440840412593e-06\n",
            "Total Loss: 1.0732552447270971e-06\n",
            "----------------------------------------\n",
            "Epoch 9602\n",
            "Var loss:  tensor(1.0732e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.942282188220127e-06\n",
            "E_s_wdiff_all_sq: 2.7298020582307285e-06\n",
            "E_IS_SCOPE: -5.810667065728477e-06\n",
            "E_IS_E_SCOPE: -5.706134147392061e-06\n",
            "Total Loss: 1.073211716856822e-06\n",
            "----------------------------------------\n",
            "Epoch 9603\n",
            "Var loss:  tensor(1.0732e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.934623106372909e-06\n",
            "E_s_wdiff_all_sq: 2.722073609033301e-06\n",
            "E_IS_SCOPE: -5.811648874768441e-06\n",
            "E_IS_E_SCOPE: -5.707060707358901e-06\n",
            "Total Loss: 1.0731705860607848e-06\n",
            "----------------------------------------\n",
            "Epoch 9604\n",
            "Var loss:  tensor(1.0731e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.936002201325239e-06\n",
            "E_s_wdiff_all_sq: 2.7235448242145295e-06\n",
            "E_IS_SCOPE: -5.811164360090738e-06\n",
            "E_IS_E_SCOPE: -5.706599616356169e-06\n",
            "Total Loss: 1.0731253131818268e-06\n",
            "----------------------------------------\n",
            "Epoch 9605\n",
            "Var loss:  tensor(1.0731e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.9425465729724615e-06\n",
            "E_s_wdiff_all_sq: 2.730106827291687e-06\n",
            "E_IS_SCOPE: -5.810120197412343e-06\n",
            "E_IS_E_SCOPE: -5.7055415537226e-06\n",
            "Total Loss: 1.073079881841543e-06\n",
            "----------------------------------------\n",
            "Epoch 9606\n",
            "Var loss:  tensor(1.0730e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.941776252817635e-06\n",
            "E_s_wdiff_all_sq: 2.729579624256728e-06\n",
            "E_IS_SCOPE: -5.810185819416531e-06\n",
            "E_IS_E_SCOPE: -5.705711550840494e-06\n",
            "Total Loss: 1.073045514949088e-06\n",
            "----------------------------------------\n",
            "Epoch 9607\n",
            "Var loss:  tensor(1.0730e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.948268697846695e-06\n",
            "E_s_wdiff_all_sq: 2.7359879295013125e-06\n",
            "E_IS_SCOPE: -5.809063847849908e-06\n",
            "E_IS_E_SCOPE: -5.704526275583204e-06\n",
            "Total Loss: 1.0730030473522313e-06\n",
            "----------------------------------------\n",
            "Epoch 9608\n",
            "Var loss:  tensor(1.0730e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.933489932724908e-06\n",
            "E_s_wdiff_all_sq: 2.721102969572892e-06\n",
            "E_IS_SCOPE: -5.8108220991845e-06\n",
            "E_IS_E_SCOPE: -5.70620797892988e-06\n",
            "Total Loss: 1.0729561461830312e-06\n",
            "----------------------------------------\n",
            "Epoch 9609\n",
            "Var loss:  tensor(1.0729e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.939333802816171e-06\n",
            "E_s_wdiff_all_sq: 2.7272057146004457e-06\n",
            "E_IS_SCOPE: -5.80892499479508e-06\n",
            "E_IS_E_SCOPE: -5.70441918315416e-06\n",
            "Total Loss: 1.0729138884741393e-06\n",
            "----------------------------------------\n",
            "Epoch 9610\n",
            "Var loss:  tensor(1.0729e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.930730803574866e-06\n",
            "E_s_wdiff_all_sq: 2.7185225777651528e-06\n",
            "E_IS_SCOPE: -5.809977404978618e-06\n",
            "E_IS_E_SCOPE: -5.705410564487327e-06\n",
            "Total Loss: 1.0728719683673877e-06\n",
            "----------------------------------------\n",
            "Epoch 9611\n",
            "Var loss:  tensor(1.0728e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.9324312178321056e-06\n",
            "E_s_wdiff_all_sq: 2.720289811690701e-06\n",
            "E_IS_SCOPE: -5.809425184515536e-06\n",
            "E_IS_E_SCOPE: -5.7048706189013e-06\n",
            "Total Loss: 1.0728296984531877e-06\n",
            "----------------------------------------\n",
            "Epoch 9612\n",
            "Var loss:  tensor(1.0728e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.935830362118415e-06\n",
            "E_s_wdiff_all_sq: 2.723719027934753e-06\n",
            "E_IS_SCOPE: -5.808864646319983e-06\n",
            "E_IS_E_SCOPE: -5.704303578910324e-06\n",
            "Total Loss: 1.072786622904599e-06\n",
            "----------------------------------------\n",
            "Epoch 9613\n",
            "Var loss:  tensor(1.0727e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.932592950385503e-06\n",
            "E_s_wdiff_all_sq: 2.720354288813391e-06\n",
            "E_IS_SCOPE: -5.809791774766355e-06\n",
            "E_IS_E_SCOPE: -5.705145519074519e-06\n",
            "Total Loss: 1.072743573728696e-06\n",
            "----------------------------------------\n",
            "Epoch 9614\n",
            "Var loss:  tensor(1.0727e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.947775946507709e-06\n",
            "E_s_wdiff_all_sq: 2.735930891253106e-06\n",
            "E_IS_SCOPE: -5.807241262316267e-06\n",
            "E_IS_E_SCOPE: -5.702770330611871e-06\n",
            "Total Loss: 1.0727006153860667e-06\n",
            "----------------------------------------\n",
            "Epoch 9615\n",
            "Var loss:  tensor(1.0727e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.942240646184035e-06\n",
            "E_s_wdiff_all_sq: 2.7302206414966886e-06\n",
            "E_IS_SCOPE: -5.808797972321756e-06\n",
            "E_IS_E_SCOPE: -5.7042196727153834e-06\n",
            "Total Loss: 1.0726608290148578e-06\n",
            "----------------------------------------\n",
            "Epoch 9616\n",
            "Var loss:  tensor(1.0726e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.9467168895106935e-06\n",
            "E_s_wdiff_all_sq: 2.734640281526077e-06\n",
            "E_IS_SCOPE: -5.808009518683002e-06\n",
            "E_IS_E_SCOPE: -5.7033814523988165e-06\n",
            "Total Loss: 1.0726178989565018e-06\n",
            "----------------------------------------\n",
            "Epoch 9617\n",
            "Var loss:  tensor(1.0726e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.942411081881476e-06\n",
            "E_s_wdiff_all_sq: 2.7307434488000366e-06\n",
            "E_IS_SCOPE: -5.807373853571861e-06\n",
            "E_IS_E_SCOPE: -5.702926939415184e-06\n",
            "Total Loss: 1.0725712283083407e-06\n",
            "----------------------------------------\n",
            "Epoch 9618\n",
            "Var loss:  tensor(1.0725e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.937600742793658e-06\n",
            "E_s_wdiff_all_sq: 2.7257164115478807e-06\n",
            "E_IS_SCOPE: -5.80781533521821e-06\n",
            "E_IS_E_SCOPE: -5.703238814673175e-06\n",
            "Total Loss: 1.0725287136959618e-06\n",
            "----------------------------------------\n",
            "Epoch 9619\n",
            "Var loss:  tensor(1.0725e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.93357885553312e-06\n",
            "E_s_wdiff_all_sq: 2.7216510135823942e-06\n",
            "E_IS_SCOPE: -5.80799714327942e-06\n",
            "E_IS_E_SCOPE: -5.703378062452391e-06\n",
            "Total Loss: 1.0724871038369234e-06\n",
            "----------------------------------------\n",
            "Epoch 9620\n",
            "Var loss:  tensor(1.0724e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.932184519556574e-06\n",
            "E_s_wdiff_all_sq: 2.7204393778662964e-06\n",
            "E_IS_SCOPE: -5.807623162702378e-06\n",
            "E_IS_E_SCOPE: -5.703073969153971e-06\n",
            "Total Loss: 1.0724441781337178e-06\n",
            "----------------------------------------\n",
            "Epoch 9621\n",
            "Var loss:  tensor(1.0724e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.936348012069664e-06\n",
            "E_s_wdiff_all_sq: 2.7246477936677027e-06\n",
            "E_IS_SCOPE: -5.806765396596557e-06\n",
            "E_IS_E_SCOPE: -5.70221705152822e-06\n",
            "Total Loss: 1.0724009518055434e-06\n",
            "----------------------------------------\n",
            "Epoch 9622\n",
            "Var loss:  tensor(1.0724e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.931140363043599e-06\n",
            "E_s_wdiff_all_sq: 2.71935106977695e-06\n",
            "E_IS_SCOPE: -5.807638380197756e-06\n",
            "E_IS_E_SCOPE: -5.7030231259455e-06\n",
            "Total Loss: 1.0723562083023925e-06\n",
            "----------------------------------------\n",
            "Epoch 9623\n",
            "Var loss:  tensor(1.0723e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.9382969102348315e-06\n",
            "E_s_wdiff_all_sq: 2.7265843071985685e-06\n",
            "E_IS_SCOPE: -5.806540079657957e-06\n",
            "E_IS_E_SCOPE: -5.70194229915923e-06\n",
            "Total Loss: 1.072314465579065e-06\n",
            "----------------------------------------\n",
            "Epoch 9624\n",
            "Var loss:  tensor(1.0723e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.937730806452765e-06\n",
            "E_s_wdiff_all_sq: 2.7262820483739305e-06\n",
            "E_IS_SCOPE: -5.8060991687665e-06\n",
            "E_IS_E_SCOPE: -5.701613280740297e-06\n",
            "Total Loss: 1.0722744055666842e-06\n",
            "----------------------------------------\n",
            "Epoch 9625\n",
            "Var loss:  tensor(1.0722e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.932307155781905e-06\n",
            "E_s_wdiff_all_sq: 2.7204803749006677e-06\n",
            "E_IS_SCOPE: -5.806882047227565e-06\n",
            "E_IS_E_SCOPE: -5.7021843971763415e-06\n",
            "Total Loss: 1.0722289043190463e-06\n",
            "----------------------------------------\n",
            "Epoch 9626\n",
            "Var loss:  tensor(1.0722e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.930597068778785e-06\n",
            "E_s_wdiff_all_sq: 2.7191110576063745e-06\n",
            "E_IS_SCOPE: -5.806013579081531e-06\n",
            "E_IS_E_SCOPE: -5.701465102673197e-06\n",
            "Total Loss: 1.0721864818959966e-06\n",
            "----------------------------------------\n",
            "Epoch 9627\n",
            "Var loss:  tensor(1.0721e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.929142768071378e-06\n",
            "E_s_wdiff_all_sq: 2.7177736329348166e-06\n",
            "E_IS_SCOPE: -5.805616409247593e-06\n",
            "E_IS_E_SCOPE: -5.701106050088218e-06\n",
            "Total Loss: 1.072145840358066e-06\n",
            "----------------------------------------\n",
            "Epoch 9628\n",
            "Var loss:  tensor(1.0721e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.92546972722118e-06\n",
            "E_s_wdiff_all_sq: 2.7137154539869607e-06\n",
            "E_IS_SCOPE: -5.806481990188997e-06\n",
            "E_IS_E_SCOPE: -5.70175818806221e-06\n",
            "Total Loss: 1.0721040925209006e-06\n",
            "----------------------------------------\n",
            "Epoch 9629\n",
            "Var loss:  tensor(1.0721e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.9284673099618115e-06\n",
            "E_s_wdiff_all_sq: 2.7170916693769394e-06\n",
            "E_IS_SCOPE: -5.8053841345244165e-06\n",
            "E_IS_E_SCOPE: -5.700827400401758e-06\n",
            "Total Loss: 1.0720595958798105e-06\n",
            "----------------------------------------\n",
            "Epoch 9630\n",
            "Var loss:  tensor(1.0720e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.938558184530261e-06\n",
            "E_s_wdiff_all_sq: 2.727473948075044e-06\n",
            "E_IS_SCOPE: -5.803532786991777e-06\n",
            "E_IS_E_SCOPE: -5.699104544698134e-06\n",
            "Total Loss: 1.072025175408186e-06\n",
            "----------------------------------------\n",
            "Epoch 9631\n",
            "Var loss:  tensor(1.0720e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.923612563778288e-06\n",
            "E_s_wdiff_all_sq: 2.7119137619430264e-06\n",
            "E_IS_SCOPE: -5.806557886777012e-06\n",
            "E_IS_E_SCOPE: -5.70179961547179e-06\n",
            "Total Loss: 1.0719796827650735e-06\n",
            "----------------------------------------\n",
            "Epoch 9632\n",
            "Var loss:  tensor(1.0719e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.930803995721538e-06\n",
            "E_s_wdiff_all_sq: 2.7193934210962525e-06\n",
            "E_IS_SCOPE: -5.8047934147438626e-06\n",
            "E_IS_E_SCOPE: -5.7001546634089005e-06\n",
            "Total Loss: 1.0719304954956172e-06\n",
            "----------------------------------------\n",
            "Epoch 9633\n",
            "Var loss:  tensor(1.0719e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.930786982963748e-06\n",
            "E_s_wdiff_all_sq: 2.7198312604862796e-06\n",
            "E_IS_SCOPE: -5.803999371870178e-06\n",
            "E_IS_E_SCOPE: -5.699568586048933e-06\n",
            "Total Loss: 1.0718915743752335e-06\n",
            "----------------------------------------\n",
            "Epoch 9634\n",
            "Var loss:  tensor(1.0718e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.927560941052892e-06\n",
            "E_s_wdiff_all_sq: 2.716139205636883e-06\n",
            "E_IS_SCOPE: -5.805064728967088e-06\n",
            "E_IS_E_SCOPE: -5.70037897641939e-06\n",
            "Total Loss: 1.0718476538608697e-06\n",
            "----------------------------------------\n",
            "Epoch 9635\n",
            "Var loss:  tensor(1.0718e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.928180831556701e-06\n",
            "E_s_wdiff_all_sq: 2.716904633909965e-06\n",
            "E_IS_SCOPE: -5.804726109379155e-06\n",
            "E_IS_E_SCOPE: -5.700091139716648e-06\n",
            "Total Loss: 1.0718036818619782e-06\n",
            "----------------------------------------\n",
            "Epoch 9636\n",
            "Var loss:  tensor(1.0718e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.935776960938969e-06\n",
            "E_s_wdiff_all_sq: 2.724964015135427e-06\n",
            "E_IS_SCOPE: -5.802935351675061e-06\n",
            "E_IS_E_SCOPE: -5.698510608027736e-06\n",
            "Total Loss: 1.0717608820491485e-06\n",
            "----------------------------------------\n",
            "Epoch 9637\n",
            "Var loss:  tensor(1.0717e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.932024363930523e-06\n",
            "E_s_wdiff_all_sq: 2.720680198182218e-06\n",
            "E_IS_SCOPE: -5.804417066916807e-06\n",
            "E_IS_E_SCOPE: -5.699702909412384e-06\n",
            "Total Loss: 1.0717132742797143e-06\n",
            "----------------------------------------\n",
            "Epoch 9638\n",
            "Var loss:  tensor(1.0717e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.933305001699247e-06\n",
            "E_s_wdiff_all_sq: 2.7220586608515046e-06\n",
            "E_IS_SCOPE: -5.804466258001449e-06\n",
            "E_IS_E_SCOPE: -5.699781812182368e-06\n",
            "Total Loss: 1.0716748727498357e-06\n",
            "----------------------------------------\n",
            "Epoch 9639\n",
            "Var loss:  tensor(1.0716e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.943755560481936e-06\n",
            "E_s_wdiff_all_sq: 2.73301983805665e-06\n",
            "E_IS_SCOPE: -5.802059681638942e-06\n",
            "E_IS_E_SCOPE: -5.697611661846621e-06\n",
            "Total Loss: 1.071637106380899e-06\n",
            "----------------------------------------\n",
            "Epoch 9640\n",
            "Var loss:  tensor(1.0716e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.9304776085407475e-06\n",
            "E_s_wdiff_all_sq: 2.719234720547257e-06\n",
            "E_IS_SCOPE: -5.8042177059648345e-06\n",
            "E_IS_E_SCOPE: -5.699490201074927e-06\n",
            "Total Loss: 1.0715853017539321e-06\n",
            "----------------------------------------\n",
            "Epoch 9641\n",
            "Var loss:  tensor(1.0715e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.930782716341462e-06\n",
            "E_s_wdiff_all_sq: 2.7195747936922835e-06\n",
            "E_IS_SCOPE: -5.803517299427897e-06\n",
            "E_IS_E_SCOPE: -5.698786045431162e-06\n",
            "Total Loss: 1.0715428381959645e-06\n",
            "----------------------------------------\n",
            "Epoch 9642\n",
            "Var loss:  tensor(1.0715e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.932902540460129e-06\n",
            "E_s_wdiff_all_sq: 2.7222992668870886e-06\n",
            "E_IS_SCOPE: -5.801819912968e-06\n",
            "E_IS_E_SCOPE: -5.69737228264073e-06\n",
            "Total Loss: 1.0715054364587573e-06\n",
            "----------------------------------------\n",
            "Epoch 9643\n",
            "Var loss:  tensor(1.0715e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.9274064447340506e-06\n",
            "E_s_wdiff_all_sq: 2.716441001511959e-06\n",
            "E_IS_SCOPE: -5.802878561361199e-06\n",
            "E_IS_E_SCOPE: -5.698226849854336e-06\n",
            "Total Loss: 1.0714594437486219e-06\n",
            "----------------------------------------\n",
            "Epoch 9644\n",
            "Var loss:  tensor(1.0714e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.926855792186078e-06\n",
            "E_s_wdiff_all_sq: 2.715844128209888e-06\n",
            "E_IS_SCOPE: -5.802993299044411e-06\n",
            "E_IS_E_SCOPE: -5.6982963429934636e-06\n",
            "Total Loss: 1.0714151754145503e-06\n",
            "----------------------------------------\n",
            "Epoch 9645\n",
            "Var loss:  tensor(1.0714e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.93423869864944e-06\n",
            "E_s_wdiff_all_sq: 2.723648896662629e-06\n",
            "E_IS_SCOPE: -5.801364024194784e-06\n",
            "E_IS_E_SCOPE: -5.696855665473075e-06\n",
            "Total Loss: 1.071370508083648e-06\n",
            "----------------------------------------\n",
            "Epoch 9646\n",
            "Var loss:  tensor(1.0713e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.9345310916263305e-06\n",
            "E_s_wdiff_all_sq: 2.7236584972698282e-06\n",
            "E_IS_SCOPE: -5.801843415935576e-06\n",
            "E_IS_E_SCOPE: -5.697171830648903e-06\n",
            "Total Loss: 1.0713268473234119e-06\n",
            "----------------------------------------\n",
            "Epoch 9647\n",
            "Var loss:  tensor(1.0713e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.9338329021383515e-06\n",
            "E_s_wdiff_all_sq: 2.7230512740369674e-06\n",
            "E_IS_SCOPE: -5.801888724674498e-06\n",
            "E_IS_E_SCOPE: -5.697242099234272e-06\n",
            "Total Loss: 1.0712858007611882e-06\n",
            "----------------------------------------\n",
            "Epoch 9648\n",
            "Var loss:  tensor(1.0712e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.93862701426999e-06\n",
            "E_s_wdiff_all_sq: 2.7281163496878137e-06\n",
            "E_IS_SCOPE: -5.8003638081863e-06\n",
            "E_IS_E_SCOPE: -5.695830295635245e-06\n",
            "Total Loss: 1.0712410630203216e-06\n",
            "----------------------------------------\n",
            "Epoch 9649\n",
            "Var loss:  tensor(1.0712e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.929945320005155e-06\n",
            "E_s_wdiff_all_sq: 2.7193499184339388e-06\n",
            "E_IS_SCOPE: -5.801190190487415e-06\n",
            "E_IS_E_SCOPE: -5.696590618529534e-06\n",
            "Total Loss: 1.0711936811957106e-06\n",
            "----------------------------------------\n",
            "Epoch 9650\n",
            "Var loss:  tensor(1.0712e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.9274880285716645e-06\n",
            "E_s_wdiff_all_sq: 2.7166880714812894e-06\n",
            "E_IS_SCOPE: -5.801436309813315e-06\n",
            "E_IS_E_SCOPE: -5.696715244704838e-06\n",
            "Total Loss: 1.0711552504136774e-06\n",
            "----------------------------------------\n",
            "Epoch 9651\n",
            "Var loss:  tensor(1.0711e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.925507580498306e-06\n",
            "E_s_wdiff_all_sq: 2.7149951206460785e-06\n",
            "E_IS_SCOPE: -5.800866450218374e-06\n",
            "E_IS_E_SCOPE: -5.69626762786663e-06\n",
            "Total Loss: 1.0711122386889952e-06\n",
            "----------------------------------------\n",
            "Epoch 9652\n",
            "Var loss:  tensor(1.0711e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.926774392208068e-06\n",
            "E_s_wdiff_all_sq: 2.7162412935345164e-06\n",
            "E_IS_SCOPE: -5.80041853223031e-06\n",
            "E_IS_E_SCOPE: -5.69578617651687e-06\n",
            "Total Loss: 1.0710658107869271e-06\n",
            "----------------------------------------\n",
            "Epoch 9653\n",
            "Var loss:  tensor(1.0710e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.9235491034385426e-06\n",
            "E_s_wdiff_all_sq: 2.7128275803571495e-06\n",
            "E_IS_SCOPE: -5.801049547283711e-06\n",
            "E_IS_E_SCOPE: -5.696301428959359e-06\n",
            "Total Loss: 1.0710227099729462e-06\n",
            "----------------------------------------\n",
            "Epoch 9654\n",
            "Var loss:  tensor(1.0710e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.931503807415652e-06\n",
            "E_s_wdiff_all_sq: 2.7212084547635103e-06\n",
            "E_IS_SCOPE: -5.799427498780159e-06\n",
            "E_IS_E_SCOPE: -5.694871650671992e-06\n",
            "Total Loss: 1.0709810799760624e-06\n",
            "----------------------------------------\n",
            "Epoch 9655\n",
            "Var loss:  tensor(1.0709e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.930030492994465e-06\n",
            "E_s_wdiff_all_sq: 2.7196034864837718e-06\n",
            "E_IS_SCOPE: -5.799758009636068e-06\n",
            "E_IS_E_SCOPE: -5.695115308081301e-06\n",
            "Total Loss: 1.0709390269414141e-06\n",
            "----------------------------------------\n",
            "Epoch 9656\n",
            "Var loss:  tensor(1.0709e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.927264920367074e-06\n",
            "E_s_wdiff_all_sq: 2.716880271131953e-06\n",
            "E_IS_SCOPE: -5.7996129796802124e-06\n",
            "E_IS_E_SCOPE: -5.6949681867532335e-06\n",
            "Total Loss: 1.0708924869214188e-06\n",
            "----------------------------------------\n",
            "Epoch 9657\n",
            "Var loss:  tensor(1.0708e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.927037883707555e-06\n",
            "E_s_wdiff_all_sq: 2.7167966840412846e-06\n",
            "E_IS_SCOPE: -5.79879122701213e-06\n",
            "E_IS_E_SCOPE: -5.694196263375477e-06\n",
            "Total Loss: 1.0708486959332195e-06\n",
            "----------------------------------------\n",
            "Epoch 9658\n",
            "Var loss:  tensor(1.0708e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.919789717089267e-06\n",
            "E_s_wdiff_all_sq: 2.709319335241824e-06\n",
            "E_IS_SCOPE: -5.7998899938493375e-06\n",
            "E_IS_E_SCOPE: -5.69515965065415e-06\n",
            "Total Loss: 1.0708071189973239e-06\n",
            "----------------------------------------\n",
            "Epoch 9659\n",
            "Var loss:  tensor(1.0708e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.9241434326747586e-06\n",
            "E_s_wdiff_all_sq: 2.713885519743136e-06\n",
            "E_IS_SCOPE: -5.79874655750621e-06\n",
            "E_IS_E_SCOPE: -5.694100780015172e-06\n",
            "Total Loss: 1.0707637814898025e-06\n",
            "----------------------------------------\n",
            "Epoch 9660\n",
            "Var loss:  tensor(1.0707e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.9225825191467384e-06\n",
            "E_s_wdiff_all_sq: 2.712440913213796e-06\n",
            "E_IS_SCOPE: -5.798682997200211e-06\n",
            "E_IS_E_SCOPE: -5.694073274621082e-06\n",
            "Total Loss: 1.0707195843149413e-06\n",
            "----------------------------------------\n",
            "Epoch 9661\n",
            "Var loss:  tensor(1.0707e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.9239069324152325e-06\n",
            "E_s_wdiff_all_sq: 2.7136694957659087e-06\n",
            "E_IS_SCOPE: -5.798509300332809e-06\n",
            "E_IS_E_SCOPE: -5.693830308932842e-06\n",
            "Total Loss: 1.0706768773896454e-06\n",
            "----------------------------------------\n",
            "Epoch 9662\n",
            "Var loss:  tensor(1.0706e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.923977772106703e-06\n",
            "E_s_wdiff_all_sq: 2.7138886921181412e-06\n",
            "E_IS_SCOPE: -5.798211682513586e-06\n",
            "E_IS_E_SCOPE: -5.693585259033539e-06\n",
            "Total Loss: 1.070633656568723e-06\n",
            "----------------------------------------\n",
            "Epoch 9663\n",
            "Var loss:  tensor(1.0706e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.927192261570338e-06\n",
            "E_s_wdiff_all_sq: 2.717202472129351e-06\n",
            "E_IS_SCOPE: -5.797452230411248e-06\n",
            "E_IS_E_SCOPE: -5.692853024257356e-06\n",
            "Total Loss: 1.0705888006734585e-06\n",
            "----------------------------------------\n",
            "Epoch 9664\n",
            "Var loss:  tensor(1.0705e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.922739584895092e-06\n",
            "E_s_wdiff_all_sq: 2.7126889345749687e-06\n",
            "E_IS_SCOPE: -5.798188801378898e-06\n",
            "E_IS_E_SCOPE: -5.693537245605163e-06\n",
            "Total Loss: 1.070544962312908e-06\n",
            "----------------------------------------\n",
            "Epoch 9665\n",
            "Var loss:  tensor(1.0705e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.924114154424828e-06\n",
            "E_s_wdiff_all_sq: 2.7140386525507207e-06\n",
            "E_IS_SCOPE: -5.79794931643358e-06\n",
            "E_IS_E_SCOPE: -5.693263604544719e-06\n",
            "Total Loss: 1.0705015016366418e-06\n",
            "----------------------------------------\n",
            "Epoch 9666\n",
            "Var loss:  tensor(1.0705e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.923604532653468e-06\n",
            "E_s_wdiff_all_sq: 2.713648914997358e-06\n",
            "E_IS_SCOPE: -5.797831598891411e-06\n",
            "E_IS_E_SCOPE: -5.69318386477657e-06\n",
            "Total Loss: 1.0704575729666835e-06\n",
            "----------------------------------------\n",
            "Epoch 9667\n",
            "Var loss:  tensor(1.0704e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.926619733073959e-06\n",
            "E_s_wdiff_all_sq: 2.716734052930698e-06\n",
            "E_IS_SCOPE: -5.797302294940487e-06\n",
            "E_IS_E_SCOPE: -5.692668487199996e-06\n",
            "Total Loss: 1.0704154882025334e-06\n",
            "----------------------------------------\n",
            "Epoch 9668\n",
            "Var loss:  tensor(1.0704e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.924209421455457e-06\n",
            "E_s_wdiff_all_sq: 2.7141900000644926e-06\n",
            "E_IS_SCOPE: -5.797618812692672e-06\n",
            "E_IS_E_SCOPE: -5.692896617777243e-06\n",
            "Total Loss: 1.070372455100362e-06\n",
            "----------------------------------------\n",
            "Epoch 9669\n",
            "Var loss:  tensor(1.0703e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.9247524036953915e-06\n",
            "E_s_wdiff_all_sq: 2.714945972018589e-06\n",
            "E_IS_SCOPE: -5.796742822075723e-06\n",
            "E_IS_E_SCOPE: -5.692104130324832e-06\n",
            "Total Loss: 1.0703264717152763e-06\n",
            "----------------------------------------\n",
            "Epoch 9670\n",
            "Var loss:  tensor(1.0703e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.92470361799335e-06\n",
            "E_s_wdiff_all_sq: 2.7148177051008134e-06\n",
            "E_IS_SCOPE: -5.7966281275326005e-06\n",
            "E_IS_E_SCOPE: -5.691929130049007e-06\n",
            "Total Loss: 1.070285341465605e-06\n",
            "----------------------------------------\n",
            "Epoch 9671\n",
            "Var loss:  tensor(1.0702e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.924530193673768e-06\n",
            "E_s_wdiff_all_sq: 2.714814324350438e-06\n",
            "E_IS_SCOPE: -5.796031714792305e-06\n",
            "E_IS_E_SCOPE: -5.691395943735255e-06\n",
            "Total Loss: 1.0702417507494852e-06\n",
            "----------------------------------------\n",
            "Epoch 9672\n",
            "Var loss:  tensor(1.0702e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.922620672319681e-06\n",
            "E_s_wdiff_all_sq: 2.7128507472098144e-06\n",
            "E_IS_SCOPE: -5.796021830050626e-06\n",
            "E_IS_E_SCOPE: -5.691337235269383e-06\n",
            "Total Loss: 1.0701981590876367e-06\n",
            "----------------------------------------\n",
            "Epoch 9673\n",
            "Var loss:  tensor(1.0702e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.9199338822777305e-06\n",
            "E_s_wdiff_all_sq: 2.710129842496962e-06\n",
            "E_IS_SCOPE: -5.79626916983816e-06\n",
            "E_IS_E_SCOPE: -5.691546105849325e-06\n",
            "Total Loss: 1.0701553353433556e-06\n",
            "----------------------------------------\n",
            "Epoch 9674\n",
            "Var loss:  tensor(1.0701e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.923501220533099e-06\n",
            "E_s_wdiff_all_sq: 2.714064431658488e-06\n",
            "E_IS_SCOPE: -5.794952039284963e-06\n",
            "E_IS_E_SCOPE: -5.690392077155784e-06\n",
            "Total Loss: 1.07011428815651e-06\n",
            "----------------------------------------\n",
            "Epoch 9675\n",
            "Var loss:  tensor(1.0701e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.9187850884209286e-06\n",
            "E_s_wdiff_all_sq: 2.709138211644971e-06\n",
            "E_IS_SCOPE: -5.795855794829045e-06\n",
            "E_IS_E_SCOPE: -5.691167984019353e-06\n",
            "Total Loss: 1.0700686786968293e-06\n",
            "----------------------------------------\n",
            "Epoch 9676\n",
            "Var loss:  tensor(1.0700e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.9189761649332436e-06\n",
            "E_s_wdiff_all_sq: 2.7093218918449547e-06\n",
            "E_IS_SCOPE: -5.795766703324704e-06\n",
            "E_IS_E_SCOPE: -5.691052678432856e-06\n",
            "Total Loss: 1.0700236468448488e-06\n",
            "----------------------------------------\n",
            "Epoch 9677\n",
            "Var loss:  tensor(1.0700e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.924072216330619e-06\n",
            "E_s_wdiff_all_sq: 2.71470706331023e-06\n",
            "E_IS_SCOPE: -5.794528899593096e-06\n",
            "E_IS_E_SCOPE: -5.689938400996162e-06\n",
            "Total Loss: 1.0699815793667777e-06\n",
            "----------------------------------------\n",
            "Epoch 9678\n",
            "Var loss:  tensor(1.0699e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.9217768780846835e-06\n",
            "E_s_wdiff_all_sq: 2.712148484105927e-06\n",
            "E_IS_SCOPE: -5.795234795685375e-06\n",
            "E_IS_E_SCOPE: -5.690491146085848e-06\n",
            "Total Loss: 1.0699385183199585e-06\n",
            "----------------------------------------\n",
            "Epoch 9679\n",
            "Var loss:  tensor(1.0699e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.923323104166921e-06\n",
            "E_s_wdiff_all_sq: 2.7138239420301137e-06\n",
            "E_IS_SCOPE: -5.7947262656843345e-06\n",
            "E_IS_E_SCOPE: -5.690024574029587e-06\n",
            "Total Loss: 1.0698932023675676e-06\n",
            "----------------------------------------\n",
            "Epoch 9680\n",
            "Var loss:  tensor(1.0698e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.921474075197059e-06\n",
            "E_s_wdiff_all_sq: 2.7120904810473046e-06\n",
            "E_IS_SCOPE: -5.7944563536083794e-06\n",
            "E_IS_E_SCOPE: -5.6897899100053644e-06\n",
            "Total Loss: 1.0698481304839804e-06\n",
            "----------------------------------------\n",
            "Epoch 9681\n",
            "Var loss:  tensor(1.0698e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.9187835559498875e-06\n",
            "E_s_wdiff_all_sq: 2.709416430711733e-06\n",
            "E_IS_SCOPE: -5.794418361353094e-06\n",
            "E_IS_E_SCOPE: -5.689738909754406e-06\n",
            "Total Loss: 1.069805645581034e-06\n",
            "----------------------------------------\n",
            "Epoch 9682\n",
            "Var loss:  tensor(1.0698e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.915808607487851e-06\n",
            "E_s_wdiff_all_sq: 2.7064122416571094e-06\n",
            "E_IS_SCOPE: -5.794679258161744e-06\n",
            "E_IS_E_SCOPE: -5.689964970123779e-06\n",
            "Total Loss: 1.0697652132950667e-06\n",
            "----------------------------------------\n",
            "Epoch 9683\n",
            "Var loss:  tensor(1.0697e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.919075633608442e-06\n",
            "E_s_wdiff_all_sq: 2.709870747483294e-06\n",
            "E_IS_SCOPE: -5.793853440195372e-06\n",
            "E_IS_E_SCOPE: -5.689212078785125e-06\n",
            "Total Loss: 1.0697195868449092e-06\n",
            "----------------------------------------\n",
            "Epoch 9684\n",
            "Var loss:  tensor(1.0697e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.921078777931152e-06\n",
            "E_s_wdiff_all_sq: 2.711911253376389e-06\n",
            "E_IS_SCOPE: -5.793571774759883e-06\n",
            "E_IS_E_SCOPE: -5.688926792562121e-06\n",
            "Total Loss: 1.0696749836994952e-06\n",
            "----------------------------------------\n",
            "Epoch 9685\n",
            "Var loss:  tensor(1.0696e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.9193294861031215e-06\n",
            "E_s_wdiff_all_sq: 2.710066324530794e-06\n",
            "E_IS_SCOPE: -5.79396364679044e-06\n",
            "E_IS_E_SCOPE: -5.6892481882777205e-06\n",
            "Total Loss: 1.0696296680871448e-06\n",
            "----------------------------------------\n",
            "Epoch 9686\n",
            "Var loss:  tensor(1.0696e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.92087541535904e-06\n",
            "E_s_wdiff_all_sq: 2.711725998473707e-06\n",
            "E_IS_SCOPE: -5.7933840987116025e-06\n",
            "E_IS_E_SCOPE: -5.688704297812169e-06\n",
            "Total Loss: 1.0695872386267218e-06\n",
            "----------------------------------------\n",
            "Epoch 9687\n",
            "Var loss:  tensor(1.0695e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.919694368508222e-06\n",
            "E_s_wdiff_all_sq: 2.7105186459049792e-06\n",
            "E_IS_SCOPE: -5.79343360916867e-06\n",
            "E_IS_E_SCOPE: -5.6887179696857855e-06\n",
            "Total Loss: 1.0695418671777291e-06\n",
            "----------------------------------------\n",
            "Epoch 9688\n",
            "Var loss:  tensor(1.0695e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.920538623589199e-06\n",
            "E_s_wdiff_all_sq: 2.7112962901533706e-06\n",
            "E_IS_SCOPE: -5.7932454190622895e-06\n",
            "E_IS_E_SCOPE: -5.688475729229058e-06\n",
            "Total Loss: 1.0695003773096211e-06\n",
            "----------------------------------------\n",
            "Epoch 9689\n",
            "Var loss:  tensor(1.0695e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.922001480606283e-06\n",
            "E_s_wdiff_all_sq: 2.7129596864231194e-06\n",
            "E_IS_SCOPE: -5.792482964125691e-06\n",
            "E_IS_E_SCOPE: -5.687790850334968e-06\n",
            "Total Loss: 1.0694549901419734e-06\n",
            "----------------------------------------\n",
            "Epoch 9690\n",
            "Var loss:  tensor(1.0694e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.9215925724612726e-06\n",
            "E_s_wdiff_all_sq: 2.7126089006251173e-06\n",
            "E_IS_SCOPE: -5.792138478305591e-06\n",
            "E_IS_E_SCOPE: -5.687453339908906e-06\n",
            "Total Loss: 1.0694108185830407e-06\n",
            "----------------------------------------\n",
            "Epoch 9691\n",
            "Var loss:  tensor(1.0694e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.914850385594636e-06\n",
            "E_s_wdiff_all_sq: 2.7056997665181173e-06\n",
            "E_IS_SCOPE: -5.792890170713907e-06\n",
            "E_IS_E_SCOPE: -5.688100796325111e-06\n",
            "Total Loss: 1.0693692938391828e-06\n",
            "----------------------------------------\n",
            "Epoch 9692\n",
            "Var loss:  tensor(1.0693e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.917849120602241e-06\n",
            "E_s_wdiff_all_sq: 2.709058431986999e-06\n",
            "E_IS_SCOPE: -5.791547320746263e-06\n",
            "E_IS_E_SCOPE: -5.6869160636649675e-06\n",
            "Total Loss: 1.069325597992906e-06\n",
            "----------------------------------------\n",
            "Epoch 9693\n",
            "Var loss:  tensor(1.0693e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.916369338107281e-06\n",
            "E_s_wdiff_all_sq: 2.7076760030359585e-06\n",
            "E_IS_SCOPE: -5.79140158625629e-06\n",
            "E_IS_E_SCOPE: -5.686797299608601e-06\n",
            "Total Loss: 1.0692821853161997e-06\n",
            "----------------------------------------\n",
            "Epoch 9694\n",
            "Var loss:  tensor(1.0692e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.918366843459585e-06\n",
            "E_s_wdiff_all_sq: 2.709398775907144e-06\n",
            "E_IS_SCOPE: -5.791360196949086e-06\n",
            "E_IS_E_SCOPE: -5.686596668610056e-06\n",
            "Total Loss: 1.0692384344146368e-06\n",
            "----------------------------------------\n",
            "Epoch 9695\n",
            "Var loss:  tensor(1.0692e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.904596725258685e-06\n",
            "E_s_wdiff_all_sq: 2.695712411020977e-06\n",
            "E_IS_SCOPE: -5.79353076335182e-06\n",
            "E_IS_E_SCOPE: -5.688792387134888e-06\n",
            "Total Loss: 1.0692049853441013e-06\n",
            "----------------------------------------\n",
            "Epoch 9696\n",
            "Var loss:  tensor(1.0692e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.951953271076561e-06\n",
            "E_s_wdiff_all_sq: 2.743307464966331e-06\n",
            "E_IS_SCOPE: -5.785519385006136e-06\n",
            "E_IS_E_SCOPE: -5.6809145418633004e-06\n",
            "Total Loss: 1.0692335433648142e-06\n",
            "----------------------------------------\n",
            "Epoch 9697\n",
            "Var loss:  tensor(1.0694e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.8630957222076966e-06\n",
            "E_s_wdiff_all_sq: 2.654220750520997e-06\n",
            "E_IS_SCOPE: -5.7992229689657766e-06\n",
            "E_IS_E_SCOPE: -5.69456857417616e-06\n",
            "Total Loss: 1.0693636056477234e-06\n",
            "----------------------------------------\n",
            "Epoch 9698\n",
            "Var loss:  tensor(1.0695e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.986471129497797e-06\n",
            "E_s_wdiff_all_sq: 2.7769536626184023e-06\n",
            "E_IS_SCOPE: -5.780236180795572e-06\n",
            "E_IS_E_SCOPE: -5.675351079934316e-06\n",
            "Total Loss: 1.0695446886971386e-06\n",
            "----------------------------------------\n",
            "Epoch 9699\n",
            "Var loss:  tensor(1.0697e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.825410782093054e-06\n",
            "E_s_wdiff_all_sq: 2.6161864843447493e-06\n",
            "E_IS_SCOPE: -5.8044292578388485e-06\n",
            "E_IS_E_SCOPE: -5.699789121105711e-06\n",
            "Total Loss: 1.069741447822287e-06\n",
            "----------------------------------------\n",
            "Epoch 9700\n",
            "Var loss:  tensor(1.0699e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 4.022065084062894e-06\n",
            "E_s_wdiff_all_sq: 2.812461574422831e-06\n",
            "E_IS_SCOPE: -5.773638030969424e-06\n",
            "E_IS_E_SCOPE: -5.668907625627853e-06\n",
            "Total Loss: 1.069940122497176e-06\n",
            "----------------------------------------\n",
            "Epoch 9701\n",
            "Var loss:  tensor(1.0701e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.7941135092041493e-06\n",
            "E_s_wdiff_all_sq: 2.5841360260009355e-06\n",
            "E_IS_SCOPE: -5.809154187565252e-06\n",
            "E_IS_E_SCOPE: -5.704323013857034e-06\n",
            "Total Loss: 1.0701125593270331e-06\n",
            "----------------------------------------\n",
            "Epoch 9702\n",
            "Var loss:  tensor(1.0702e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 4.038240652940323e-06\n",
            "E_s_wdiff_all_sq: 2.8283728394301675e-06\n",
            "E_IS_SCOPE: -5.770074310142293e-06\n",
            "E_IS_E_SCOPE: -5.665360561346426e-06\n",
            "Total Loss: 1.0702377394586761e-06\n",
            "----------------------------------------\n",
            "Epoch 9703\n",
            "Var loss:  tensor(1.0703e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.785728659218337e-06\n",
            "E_s_wdiff_all_sq: 2.576144820905563e-06\n",
            "E_IS_SCOPE: -5.8088960022461165e-06\n",
            "E_IS_E_SCOPE: -5.704360690720896e-06\n",
            "Total Loss: 1.0703106388025887e-06\n",
            "----------------------------------------\n",
            "Epoch 9704\n",
            "Var loss:  tensor(1.0703e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 4.042434258155763e-06\n",
            "E_s_wdiff_all_sq: 2.8322361352257517e-06\n",
            "E_IS_SCOPE: -5.769490618035336e-06\n",
            "E_IS_E_SCOPE: -5.6646457505829044e-06\n",
            "Total Loss: 1.070305811565404e-06\n",
            "----------------------------------------\n",
            "Epoch 9705\n",
            "Var loss:  tensor(1.0702e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.783969107998824e-06\n",
            "E_s_wdiff_all_sq: 2.574031220437137e-06\n",
            "E_IS_SCOPE: -5.8098122590771464e-06\n",
            "E_IS_E_SCOPE: -5.705058844122284e-06\n",
            "Total Loss: 1.0702284811922178e-06\n",
            "----------------------------------------\n",
            "Epoch 9706\n",
            "Var loss:  tensor(1.0701e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 4.049634185845784e-06\n",
            "E_s_wdiff_all_sq: 2.8401478957078713e-06\n",
            "E_IS_SCOPE: -5.767873779457592e-06\n",
            "E_IS_E_SCOPE: -5.663275589121904e-06\n",
            "Total Loss: 1.070087333006793e-06\n",
            "----------------------------------------\n",
            "Epoch 9707\n",
            "Var loss:  tensor(1.0699e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.8006935705477653e-06\n",
            "E_s_wdiff_all_sq: 2.5911801005398265e-06\n",
            "E_IS_SCOPE: -5.807085658728722e-06\n",
            "E_IS_E_SCOPE: -5.702372574647898e-06\n",
            "Total Loss: 1.0698847253865465e-06\n",
            "----------------------------------------\n",
            "Epoch 9708\n",
            "Var loss:  tensor(1.0696e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 4.024179734198307e-06\n",
            "E_s_wdiff_all_sq: 2.8147007794374814e-06\n",
            "E_IS_SCOPE: -5.771869419423183e-06\n",
            "E_IS_E_SCOPE: -5.667053529898238e-06\n",
            "Total Loss: 1.0696445992511914e-06\n",
            "----------------------------------------\n",
            "Epoch 9709\n",
            "Var loss:  tensor(1.0694e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.82087852478506e-06\n",
            "E_s_wdiff_all_sq: 2.6120278441011666e-06\n",
            "E_IS_SCOPE: -5.802773214085393e-06\n",
            "E_IS_E_SCOPE: -5.6981440093660915e-06\n",
            "Total Loss: 1.0693896947855464e-06\n",
            "----------------------------------------\n",
            "Epoch 9710\n",
            "Var loss:  tensor(1.0691e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.99711527487973e-06\n",
            "E_s_wdiff_all_sq: 2.7881835901260442e-06\n",
            "E_IS_SCOPE: -5.7753883636344785e-06\n",
            "E_IS_E_SCOPE: -5.670589773956778e-06\n",
            "Total Loss: 1.0691319289385407e-06\n",
            "----------------------------------------\n",
            "Epoch 9711\n",
            "Var loss:  tensor(1.0689e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.8423246396073325e-06\n",
            "E_s_wdiff_all_sq: 2.6334904365940614e-06\n",
            "E_IS_SCOPE: -5.799505634381143e-06\n",
            "E_IS_E_SCOPE: -5.694638963962568e-06\n",
            "Total Loss: 1.068898285716377e-06\n",
            "----------------------------------------\n",
            "Epoch 9712\n",
            "Var loss:  tensor(1.0687e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.968605279113411e-06\n",
            "E_s_wdiff_all_sq: 2.7603892298840323e-06\n",
            "E_IS_SCOPE: -5.778751139147173e-06\n",
            "E_IS_E_SCOPE: -5.674090983727497e-06\n",
            "Total Loss: 1.0686931619302811e-06\n",
            "----------------------------------------\n",
            "Epoch 9713\n",
            "Var loss:  tensor(1.0685e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.875178177237829e-06\n",
            "E_s_wdiff_all_sq: 2.6670115189928807e-06\n",
            "E_IS_SCOPE: -5.7933363804928016e-06\n",
            "E_IS_E_SCOPE: -5.688618595552064e-06\n",
            "Total Loss: 1.068528511903728e-06\n",
            "----------------------------------------\n",
            "Epoch 9714\n",
            "Var loss:  tensor(1.0684e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.9344637963034705e-06\n",
            "E_s_wdiff_all_sq: 2.7261862025858728e-06\n",
            "E_IS_SCOPE: -5.784200960230762e-06\n",
            "E_IS_E_SCOPE: -5.679367988621892e-06\n",
            "Total Loss: 1.0684090740401137e-06\n",
            "----------------------------------------\n",
            "Epoch 9715\n",
            "Var loss:  tensor(1.0683e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.907027204187875e-06\n",
            "E_s_wdiff_all_sq: 2.6991463342304907e-06\n",
            "E_IS_SCOPE: -5.7880494764521e-06\n",
            "E_IS_E_SCOPE: -5.6833732636025705e-06\n",
            "Total Loss: 1.0683258677985809e-06\n",
            "----------------------------------------\n",
            "Epoch 9716\n",
            "Var loss:  tensor(1.0683e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.914987787198767e-06\n",
            "E_s_wdiff_all_sq: 2.707273211785796e-06\n",
            "E_IS_SCOPE: -5.786367552124311e-06\n",
            "E_IS_E_SCOPE: -5.681748660362919e-06\n",
            "Total Loss: 1.0682742154304428e-06\n",
            "----------------------------------------\n",
            "Epoch 9717\n",
            "Var loss:  tensor(1.0682e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.925644565925842e-06\n",
            "E_s_wdiff_all_sq: 2.717655977394828e-06\n",
            "E_IS_SCOPE: -5.784707664412923e-06\n",
            "E_IS_E_SCOPE: -5.679937894123324e-06\n",
            "Total Loss: 1.0682464714920706e-06\n",
            "----------------------------------------\n",
            "Epoch 9718\n",
            "Var loss:  tensor(1.0682e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.885439963424764e-06\n",
            "E_s_wdiff_all_sq: 2.6773354510472138e-06\n",
            "E_IS_SCOPE: -5.790769682974928e-06\n",
            "E_IS_E_SCOPE: -5.685937021699016e-06\n",
            "Total Loss: 1.0682366133659821e-06\n",
            "----------------------------------------\n",
            "Epoch 9719\n",
            "Var loss:  tensor(1.0682e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.944934794693956e-06\n",
            "E_s_wdiff_all_sq: 2.737187733969716e-06\n",
            "E_IS_SCOPE: -5.780366184482251e-06\n",
            "E_IS_E_SCOPE: -5.675711497887549e-06\n",
            "Total Loss: 1.0682351110750918e-06\n",
            "----------------------------------------\n",
            "Epoch 9720\n",
            "Var loss:  tensor(1.0682e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.868173204261257e-06\n",
            "E_s_wdiff_all_sq: 2.660181417399232e-06\n",
            "E_IS_SCOPE: -5.792304881254991e-06\n",
            "E_IS_E_SCOPE: -5.687528766941757e-06\n",
            "Total Loss: 1.0682369817758144e-06\n",
            "----------------------------------------\n",
            "Epoch 9721\n",
            "Var loss:  tensor(1.0682e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.951054248523926e-06\n",
            "E_s_wdiff_all_sq: 2.7427958713902024e-06\n",
            "E_IS_SCOPE: -5.779423220555619e-06\n",
            "E_IS_E_SCOPE: -5.674515617849699e-06\n",
            "Total Loss: 1.0682405952621395e-06\n",
            "----------------------------------------\n",
            "Epoch 9722\n",
            "Var loss:  tensor(1.0682e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.862485008505822e-06\n",
            "E_s_wdiff_all_sq: 2.654736358200313e-06\n",
            "E_IS_SCOPE: -5.792553879717167e-06\n",
            "E_IS_E_SCOPE: -5.687898812331241e-06\n",
            "Total Loss: 1.0682359390739145e-06\n",
            "----------------------------------------\n",
            "Epoch 9723\n",
            "Var loss:  tensor(1.0682e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.965992503204274e-06\n",
            "E_s_wdiff_all_sq: 2.758065688091772e-06\n",
            "E_IS_SCOPE: -5.776484467273327e-06\n",
            "E_IS_E_SCOPE: -5.671733971589933e-06\n",
            "Total Loss: 1.0682232472859701e-06\n",
            "----------------------------------------\n",
            "Epoch 9724\n",
            "Var loss:  tensor(1.0682e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.849788375160972e-06\n",
            "E_s_wdiff_all_sq: 2.641560284995052e-06\n",
            "E_IS_SCOPE: -5.7950720698293876e-06\n",
            "E_IS_E_SCOPE: -5.690165566729964e-06\n",
            "Total Loss: 1.0682125075073282e-06\n",
            "----------------------------------------\n",
            "Epoch 9725\n",
            "Var loss:  tensor(1.0682e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.974924851992303e-06\n",
            "E_s_wdiff_all_sq: 2.7672136698800887e-06\n",
            "E_IS_SCOPE: -5.7746878531478266e-06\n",
            "E_IS_E_SCOPE: -5.670026752914706e-06\n",
            "Total Loss: 1.068186405186229e-06\n",
            "----------------------------------------\n",
            "Epoch 9726\n",
            "Var loss:  tensor(1.0682e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.852877212354253e-06\n",
            "E_s_wdiff_all_sq: 2.6452888120992117e-06\n",
            "E_IS_SCOPE: -5.793677106112255e-06\n",
            "E_IS_E_SCOPE: -5.689081246923322e-06\n",
            "Total Loss: 1.0681941054174326e-06\n",
            "----------------------------------------\n",
            "Epoch 9727\n",
            "Var loss:  tensor(1.0685e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.996555407667347e-06\n",
            "E_s_wdiff_all_sq: 2.788143898523884e-06\n",
            "E_IS_SCOPE: -5.771287163531914e-06\n",
            "E_IS_E_SCOPE: -5.666416687820918e-06\n",
            "Total Loss: 1.0684679812617262e-06\n",
            "----------------------------------------\n",
            "Epoch 9728\n",
            "Var loss:  tensor(1.0688e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.794188348003165e-06\n",
            "E_s_wdiff_all_sq: 2.585599573815394e-06\n",
            "E_IS_SCOPE: -5.8020182242686565e-06\n",
            "E_IS_E_SCOPE: -5.697242201013494e-06\n",
            "Total Loss: 1.0688341512177007e-06\n",
            "----------------------------------------\n",
            "Epoch 9729\n",
            "Var loss:  tensor(1.0692e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 4.041448609185324e-06\n",
            "E_s_wdiff_all_sq: 2.8327363015584885e-06\n",
            "E_IS_SCOPE: -5.762275806154278e-06\n",
            "E_IS_E_SCOPE: -5.657633571783421e-06\n",
            "Total Loss: 1.0692252624253772e-06\n",
            "----------------------------------------\n",
            "Epoch 9730\n",
            "Var loss:  tensor(1.0696e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.7558700367635693e-06\n",
            "E_s_wdiff_all_sq: 2.5465706605771058e-06\n",
            "E_IS_SCOPE: -5.806959964565463e-06\n",
            "E_IS_E_SCOPE: -5.702211213013038e-06\n",
            "Total Loss: 1.0695992966218694e-06\n",
            "----------------------------------------\n",
            "Epoch 9731\n",
            "Var loss:  tensor(1.0699e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 4.063855300722225e-06\n",
            "E_s_wdiff_all_sq: 2.8537682778661095e-06\n",
            "E_IS_SCOPE: -5.75883332227496e-06\n",
            "E_IS_E_SCOPE: -5.653858426164167e-06\n",
            "Total Loss: 1.0699346541747855e-06\n",
            "----------------------------------------\n",
            "Epoch 9732\n",
            "Var loss:  tensor(1.0702e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.733278149479214e-06\n",
            "E_s_wdiff_all_sq: 2.5236348333814383e-06\n",
            "E_IS_SCOPE: -5.809028973635512e-06\n",
            "E_IS_E_SCOPE: -5.704395974967467e-06\n",
            "Total Loss: 1.0701747423019418e-06\n",
            "----------------------------------------\n",
            "Epoch 9733\n",
            "Var loss:  tensor(1.0703e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 4.079270547648551e-06\n",
            "E_s_wdiff_all_sq: 2.86922479014141e-06\n",
            "E_IS_SCOPE: -5.754349238745117e-06\n",
            "E_IS_E_SCOPE: -5.6495763410825515e-06\n",
            "Total Loss: 1.0702973857222653e-06\n",
            "----------------------------------------\n",
            "Epoch 9734\n",
            "Var loss:  tensor(1.0703e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.714409240890118e-06\n",
            "E_s_wdiff_all_sq: 2.5040771773782942e-06\n",
            "E_IS_SCOPE: -5.811424190494025e-06\n",
            "E_IS_E_SCOPE: -5.7064969361278954e-06\n",
            "Total Loss: 1.0702749783198204e-06\n",
            "----------------------------------------\n",
            "Epoch 9735\n",
            "Var loss:  tensor(1.0701e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 4.071034549605717e-06\n",
            "E_s_wdiff_all_sq: 2.8611715345072615e-06\n",
            "E_IS_SCOPE: -5.7543438796620856e-06\n",
            "E_IS_E_SCOPE: -5.649556471510541e-06\n",
            "Total Loss: 1.0700856223356218e-06\n",
            "----------------------------------------\n",
            "Epoch 9736\n",
            "Var loss:  tensor(1.0697e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.7399999667434085e-06\n",
            "E_s_wdiff_all_sq: 2.5309863809761764e-06\n",
            "E_IS_SCOPE: -5.805307389908447e-06\n",
            "E_IS_E_SCOPE: -5.700776140429227e-06\n",
            "Total Loss: 1.0697485103490493e-06\n",
            "----------------------------------------\n",
            "Epoch 9737\n",
            "Var loss:  tensor(1.0693e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 4.042988865555589e-06\n",
            "E_s_wdiff_all_sq: 2.833632927691678e-06\n",
            "E_IS_SCOPE: -5.758590400645969e-06\n",
            "E_IS_E_SCOPE: -5.653654975402954e-06\n",
            "Total Loss: 1.069282510918138e-06\n",
            "----------------------------------------\n",
            "Epoch 9738\n",
            "Var loss:  tensor(1.0688e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.7684329422210706e-06\n",
            "E_s_wdiff_all_sq: 2.559746249596134e-06\n",
            "E_IS_SCOPE: -5.801406495350593e-06\n",
            "E_IS_E_SCOPE: -5.69653992407187e-06\n",
            "Total Loss: 1.068750973607745e-06\n",
            "----------------------------------------\n",
            "Epoch 9739\n",
            "Var loss:  tensor(1.0682e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 4.008441200830008e-06\n",
            "E_s_wdiff_all_sq: 2.8008159802004252e-06\n",
            "E_IS_SCOPE: -5.762915326771942e-06\n",
            "E_IS_E_SCOPE: -5.6583149491334115e-06\n",
            "Total Loss: 1.0682218888927778e-06\n",
            "----------------------------------------\n",
            "Epoch 9740\n",
            "Var loss:  tensor(1.0678e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.823603853548886e-06\n",
            "E_s_wdiff_all_sq: 2.616127835523448e-06\n",
            "E_IS_SCOPE: -5.792312379187766e-06\n",
            "E_IS_E_SCOPE: -5.687554062054136e-06\n",
            "Total Loss: 1.0677568072984363e-06\n",
            "----------------------------------------\n",
            "Epoch 9741\n",
            "Var loss:  tensor(1.0674e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.946072987675786e-06\n",
            "E_s_wdiff_all_sq: 2.738543304270844e-06\n",
            "E_IS_SCOPE: -5.773839954031832e-06\n",
            "E_IS_E_SCOPE: -5.668885738542568e-06\n",
            "Total Loss: 1.067418675966671e-06\n",
            "----------------------------------------\n",
            "Epoch 9742\n",
            "Var loss:  tensor(1.0672e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.883398172163604e-06\n",
            "E_s_wdiff_all_sq: 2.676568759744413e-06\n",
            "E_IS_SCOPE: -5.783120141163119e-06\n",
            "E_IS_E_SCOPE: -5.678409256032035e-06\n",
            "Total Loss: 1.067205065697279e-06\n",
            "----------------------------------------\n",
            "Epoch 9743\n",
            "Var loss:  tensor(1.0671e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.9034859912208525e-06\n",
            "E_s_wdiff_all_sq: 2.6968732890565724e-06\n",
            "E_IS_SCOPE: -5.779739842672571e-06\n",
            "E_IS_E_SCOPE: -5.675097725569081e-06\n",
            "Total Loss: 1.0671258914975564e-06\n",
            "----------------------------------------\n",
            "Epoch 9744\n",
            "Var loss:  tensor(1.0671e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.925707788375478e-06\n",
            "E_s_wdiff_all_sq: 2.7183607100333473e-06\n",
            "E_IS_SCOPE: -5.777428170939671e-06\n",
            "E_IS_E_SCOPE: -5.672427946837224e-06\n",
            "Total Loss: 1.067144053677493e-06\n",
            "----------------------------------------\n",
            "Epoch 9745\n",
            "Var loss:  tensor(1.0672e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.860793191559291e-06\n",
            "E_s_wdiff_all_sq: 2.6536782050631985e-06\n",
            "E_IS_SCOPE: -5.787563256739946e-06\n",
            "E_IS_E_SCOPE: -5.68271532350271e-06\n",
            "Total Loss: 1.0672165435618765e-06\n",
            "----------------------------------------\n",
            "Epoch 9746\n",
            "Var loss:  tensor(1.0673e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.978497086667336e-06\n",
            "E_s_wdiff_all_sq: 2.7716166795895916e-06\n",
            "E_IS_SCOPE: -5.769142871980943e-06\n",
            "E_IS_E_SCOPE: -5.664465841980059e-06\n",
            "Total Loss: 1.067323770616233e-06\n",
            "----------------------------------------\n",
            "Epoch 9747\n",
            "Var loss:  tensor(1.0674e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.838925641647548e-06\n",
            "E_s_wdiff_all_sq: 2.631540813061633e-06\n",
            "E_IS_SCOPE: -5.791666485677968e-06\n",
            "E_IS_E_SCOPE: -5.686782437065943e-06\n",
            "Total Loss: 1.0674141549021223e-06\n",
            "----------------------------------------\n",
            "Epoch 9748\n",
            "Var loss:  tensor(1.0675e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.993728329022238e-06\n",
            "E_s_wdiff_all_sq: 2.7863034888210844e-06\n",
            "E_IS_SCOPE: -5.767192590647305e-06\n",
            "E_IS_E_SCOPE: -5.6623191307405725e-06\n",
            "Total Loss: 1.067475343927944e-06\n",
            "----------------------------------------\n",
            "Epoch 9749\n",
            "Var loss:  tensor(1.0675e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.831677389454209e-06\n",
            "E_s_wdiff_all_sq: 2.624803905838729e-06\n",
            "E_IS_SCOPE: -5.791456225019714e-06\n",
            "E_IS_E_SCOPE: -5.686871677048966e-06\n",
            "Total Loss: 1.0675018112142399e-06\n",
            "----------------------------------------\n",
            "Epoch 9750\n",
            "Var loss:  tensor(1.0675e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.996397971277985e-06\n",
            "E_s_wdiff_all_sq: 2.7889193214450754e-06\n",
            "E_IS_SCOPE: -5.7664040709266686e-06\n",
            "E_IS_E_SCOPE: -5.661499724725939e-06\n",
            "Total Loss: 1.0674673809717058e-06\n",
            "----------------------------------------\n",
            "Epoch 9751\n",
            "Var loss:  tensor(1.0674e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.826589006300239e-06\n",
            "E_s_wdiff_all_sq: 2.6192339622849567e-06\n",
            "E_IS_SCOPE: -5.792848792868506e-06\n",
            "E_IS_E_SCOPE: -5.687966675431914e-06\n",
            "Total Loss: 1.0673882326823543e-06\n",
            "----------------------------------------\n",
            "Epoch 9752\n",
            "Var loss:  tensor(1.0673e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.998567086504562e-06\n",
            "E_s_wdiff_all_sq: 2.7917731797559e-06\n",
            "E_IS_SCOPE: -5.765264781005255e-06\n",
            "E_IS_E_SCOPE: -5.660605546779967e-06\n",
            "Total Loss: 1.0672728618383412e-06\n",
            "----------------------------------------\n",
            "Epoch 9753\n",
            "Var loss:  tensor(1.0671e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.845106902058925e-06\n",
            "E_s_wdiff_all_sq: 2.6383491502330967e-06\n",
            "E_IS_SCOPE: -5.789097725492289e-06\n",
            "E_IS_E_SCOPE: -5.684384312016968e-06\n",
            "Total Loss: 1.0671283484154424e-06\n",
            "----------------------------------------\n",
            "Epoch 9754\n",
            "Var loss:  tensor(1.0670e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.9705267682101066e-06\n",
            "E_s_wdiff_all_sq: 2.763433260062955e-06\n",
            "E_IS_SCOPE: -5.769693659544489e-06\n",
            "E_IS_E_SCOPE: -5.664738474393115e-06\n",
            "Total Loss: 1.0669805613846603e-06\n",
            "----------------------------------------\n",
            "Epoch 9755\n",
            "Var loss:  tensor(1.0668e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.85970718988977e-06\n",
            "E_s_wdiff_all_sq: 2.6531277555607176e-06\n",
            "E_IS_SCOPE: -5.786277084030401e-06\n",
            "E_IS_E_SCOPE: -5.68150437144293e-06\n",
            "Total Loss: 1.0668314326943669e-06\n",
            "----------------------------------------\n",
            "Epoch 9756\n",
            "Var loss:  tensor(1.0667e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.955310693283952e-06\n",
            "E_s_wdiff_all_sq: 2.7490104373022022e-06\n",
            "E_IS_SCOPE: -5.770856742384372e-06\n",
            "E_IS_E_SCOPE: -5.666161135448587e-06\n",
            "Total Loss: 1.0667064656504365e-06\n",
            "----------------------------------------\n",
            "Epoch 9757\n",
            "Var loss:  tensor(1.0666e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.878596362669808e-06\n",
            "E_s_wdiff_all_sq: 2.6719884933177844e-06\n",
            "E_IS_SCOPE: -5.7831965053129485e-06\n",
            "E_IS_E_SCOPE: -5.678289700946992e-06\n",
            "Total Loss: 1.0665916841603662e-06\n",
            "----------------------------------------\n",
            "Epoch 9758\n",
            "Var loss:  tensor(1.0665e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.927041752641331e-06\n",
            "E_s_wdiff_all_sq: 2.720472825323923e-06\n",
            "E_IS_SCOPE: -5.7753710802612e-06\n",
            "E_IS_E_SCOPE: -5.670438019864892e-06\n",
            "Total Loss: 1.0665002300650463e-06\n",
            "----------------------------------------\n",
            "Epoch 9759\n",
            "Var loss:  tensor(1.0664e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.90452893851029e-06\n",
            "E_s_wdiff_all_sq: 2.698530043952782e-06\n",
            "E_IS_SCOPE: -5.77792314484312e-06\n",
            "E_IS_E_SCOPE: -5.67324201778747e-06\n",
            "Total Loss: 1.066434063986464e-06\n",
            "----------------------------------------\n",
            "Epoch 9760\n",
            "Var loss:  tensor(1.0664e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.9055832495159126e-06\n",
            "E_s_wdiff_all_sq: 2.699318658914392e-06\n",
            "E_IS_SCOPE: -5.777646424491664e-06\n",
            "E_IS_E_SCOPE: -5.672806169517295e-06\n",
            "Total Loss: 1.0663815041930383e-06\n",
            "----------------------------------------\n",
            "Epoch 9761\n",
            "Var loss:  tensor(1.0663e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.912299619910361e-06\n",
            "E_s_wdiff_all_sq: 2.705985265786531e-06\n",
            "E_IS_SCOPE: -5.776285309257434e-06\n",
            "E_IS_E_SCOPE: -5.671403606252116e-06\n",
            "Total Loss: 1.0663483716534504e-06\n",
            "----------------------------------------\n",
            "Epoch 9762\n",
            "Var loss:  tensor(1.0663e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.88956913083324e-06\n",
            "E_s_wdiff_all_sq: 2.683524199502128e-06\n",
            "E_IS_SCOPE: -5.779148200533571e-06\n",
            "E_IS_E_SCOPE: -5.67438613846033e-06\n",
            "Total Loss: 1.0663182307248854e-06\n",
            "----------------------------------------\n",
            "Epoch 9763\n",
            "Var loss:  tensor(1.0663e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.930585501825976e-06\n",
            "E_s_wdiff_all_sq: 2.7246219136287258e-06\n",
            "E_IS_SCOPE: -5.772357477464562e-06\n",
            "E_IS_E_SCOPE: -5.667624793659292e-06\n",
            "Total Loss: 1.0662956441269653e-06\n",
            "----------------------------------------\n",
            "Epoch 9764\n",
            "Var loss:  tensor(1.0663e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.874468960044417e-06\n",
            "E_s_wdiff_all_sq: 2.668140526049108e-06\n",
            "E_IS_SCOPE: -5.781430452940134e-06\n",
            "E_IS_E_SCOPE: -5.676505381372382e-06\n",
            "Total Loss: 1.0662757144000596e-06\n",
            "----------------------------------------\n",
            "Epoch 9765\n",
            "Var loss:  tensor(1.0663e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.9397074286475525e-06\n",
            "E_s_wdiff_all_sq: 2.733615846166135e-06\n",
            "E_IS_SCOPE: -5.770750386497242e-06\n",
            "E_IS_E_SCOPE: -5.665933347017799e-06\n",
            "Total Loss: 1.0662549270627863e-06\n",
            "----------------------------------------\n",
            "Epoch 9766\n",
            "Var loss:  tensor(1.0662e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.8702883175293565e-06\n",
            "E_s_wdiff_all_sq: 2.664267750960361e-06\n",
            "E_IS_SCOPE: -5.781083161270536e-06\n",
            "E_IS_E_SCOPE: -5.676290390364671e-06\n",
            "Total Loss: 1.0662324482975203e-06\n",
            "----------------------------------------\n",
            "Epoch 9767\n",
            "Var loss:  tensor(1.0662e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.940768392652483e-06\n",
            "E_s_wdiff_all_sq: 2.734579696527091e-06\n",
            "E_IS_SCOPE: -5.769832891064231e-06\n",
            "E_IS_E_SCOPE: -5.66494200860455e-06\n",
            "Total Loss: 1.0662043547462864e-06\n",
            "----------------------------------------\n",
            "Epoch 9768\n",
            "Var loss:  tensor(1.0662e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.862218393644427e-06\n",
            "E_s_wdiff_all_sq: 2.6562826405852045e-06\n",
            "E_IS_SCOPE: -5.78134133982699e-06\n",
            "E_IS_E_SCOPE: -5.676560065910401e-06\n",
            "Total Loss: 1.0661706287663008e-06\n",
            "----------------------------------------\n",
            "Epoch 9769\n",
            "Var loss:  tensor(1.0661e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.943416144081086e-06\n",
            "E_s_wdiff_all_sq: 2.7375105432991473e-06\n",
            "E_IS_SCOPE: -5.768312683328843e-06\n",
            "E_IS_E_SCOPE: -5.663529517260413e-06\n",
            "Total Loss: 1.066136692185335e-06\n",
            "----------------------------------------\n",
            "Epoch 9770\n",
            "Var loss:  tensor(1.0661e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.856548062436804e-06\n",
            "E_s_wdiff_all_sq: 2.6505914180626085e-06\n",
            "E_IS_SCOPE: -5.781679986178404e-06\n",
            "E_IS_E_SCOPE: -5.676851346480738e-06\n",
            "Total Loss: 1.0660967885191203e-06\n",
            "----------------------------------------\n",
            "Epoch 9771\n",
            "Var loss:  tensor(1.0661e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.9393298293934665e-06\n",
            "E_s_wdiff_all_sq: 2.7333937141633577e-06\n",
            "E_IS_SCOPE: -5.768341851361596e-06\n",
            "E_IS_E_SCOPE: -5.66350335679616e-06\n",
            "Total Loss: 1.0660565496394934e-06\n",
            "----------------------------------------\n",
            "Epoch 9772\n",
            "Var loss:  tensor(1.0660e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.856864398659947e-06\n",
            "E_s_wdiff_all_sq: 2.651119156996725e-06\n",
            "E_IS_SCOPE: -5.780935754771554e-06\n",
            "E_IS_E_SCOPE: -5.676169812646606e-06\n",
            "Total Loss: 1.0660107809535823e-06\n",
            "----------------------------------------\n",
            "Epoch 9773\n",
            "Var loss:  tensor(1.0660e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.941296459866316e-06\n",
            "E_s_wdiff_all_sq: 2.735406078873133e-06\n",
            "E_IS_SCOPE: -5.7678848497623e-06\n",
            "E_IS_E_SCOPE: -5.663023467929462e-06\n",
            "Total Loss: 1.065965040867764e-06\n",
            "----------------------------------------\n",
            "Epoch 9774\n",
            "Var loss:  tensor(1.0659e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.85851836614883e-06\n",
            "E_s_wdiff_all_sq: 2.6525864901767975e-06\n",
            "E_IS_SCOPE: -5.781053877453146e-06\n",
            "E_IS_E_SCOPE: -5.676148745394699e-06\n",
            "Total Loss: 1.065919035395395e-06\n",
            "----------------------------------------\n",
            "Epoch 9775\n",
            "Var loss:  tensor(1.0659e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.9468179769401744e-06\n",
            "E_s_wdiff_all_sq: 2.7411424558689947e-06\n",
            "E_IS_SCOPE: -5.766690012864138e-06\n",
            "E_IS_E_SCOPE: -5.661890939273417e-06\n",
            "Total Loss: 1.0658747974299944e-06\n",
            "----------------------------------------\n",
            "Epoch 9776\n",
            "Var loss:  tensor(1.0658e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.860931973792815e-06\n",
            "E_s_wdiff_all_sq: 2.6552564032266878e-06\n",
            "E_IS_SCOPE: -5.779860247804487e-06\n",
            "E_IS_E_SCOPE: -5.675038058667598e-06\n",
            "Total Loss: 1.0658286158326043e-06\n",
            "----------------------------------------\n",
            "Epoch 9777\n",
            "Var loss:  tensor(1.0658e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.940468110653908e-06\n",
            "E_s_wdiff_all_sq: 2.734707909834473e-06\n",
            "E_IS_SCOPE: -5.767185222991093e-06\n",
            "E_IS_E_SCOPE: -5.662298599053525e-06\n",
            "Total Loss: 1.0657843764845546e-06\n",
            "----------------------------------------\n",
            "Epoch 9778\n",
            "Var loss:  tensor(1.0657e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.85756368089902e-06\n",
            "E_s_wdiff_all_sq: 2.6519265815315277e-06\n",
            "E_IS_SCOPE: -5.7797834042176515e-06\n",
            "E_IS_E_SCOPE: -5.674937453997389e-06\n",
            "Total Loss: 1.0657426224672234e-06\n",
            "----------------------------------------\n",
            "Epoch 9779\n",
            "Var loss:  tensor(1.0657e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.942307923187479e-06\n",
            "E_s_wdiff_all_sq: 2.7367499659859526e-06\n",
            "E_IS_SCOPE: -5.7663040322409194e-06\n",
            "E_IS_E_SCOPE: -5.661476481982702e-06\n",
            "Total Loss: 1.0657002802253472e-06\n",
            "----------------------------------------\n",
            "Epoch 9780\n",
            "Var loss:  tensor(1.0657e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.858452556816033e-06\n",
            "E_s_wdiff_all_sq: 2.6528955081449217e-06\n",
            "E_IS_SCOPE: -5.779449835545488e-06\n",
            "E_IS_E_SCOPE: -5.674602490291202e-06\n",
            "Total Loss: 1.0656597817027942e-06\n",
            "----------------------------------------\n",
            "Epoch 9781\n",
            "Var loss:  tensor(1.0656e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.946048573932493e-06\n",
            "E_s_wdiff_all_sq: 2.7405788020893108e-06\n",
            "E_IS_SCOPE: -5.765602242958681e-06\n",
            "E_IS_E_SCOPE: -5.66077927995342e-06\n",
            "Total Loss: 1.0656212693729168e-06\n",
            "----------------------------------------\n",
            "Epoch 9782\n",
            "Var loss:  tensor(1.0656e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.858485378135631e-06\n",
            "E_s_wdiff_all_sq: 2.65312004670263e-06\n",
            "E_IS_SCOPE: -5.778962782941983e-06\n",
            "E_IS_E_SCOPE: -5.674172583329791e-06\n",
            "Total Loss: 1.065582355748872e-06\n",
            "----------------------------------------\n",
            "Epoch 9783\n",
            "Var loss:  tensor(1.0656e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.945519326823773e-06\n",
            "E_s_wdiff_all_sq: 2.7399774391768097e-06\n",
            "E_IS_SCOPE: -5.765420478889687e-06\n",
            "E_IS_E_SCOPE: -5.660526105555373e-06\n",
            "Total Loss: 1.065550564518591e-06\n",
            "----------------------------------------\n",
            "Epoch 9784\n",
            "Var loss:  tensor(1.0655e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.853311490659203e-06\n",
            "E_s_wdiff_all_sq: 2.6478747763631993e-06\n",
            "E_IS_SCOPE: -5.779569382240877e-06\n",
            "E_IS_E_SCOPE: -5.674712689363899e-06\n",
            "Total Loss: 1.0655207520823033e-06\n",
            "----------------------------------------\n",
            "Epoch 9785\n",
            "Var loss:  tensor(1.0655e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.953551945304626e-06\n",
            "E_s_wdiff_all_sq: 2.748228587759201e-06\n",
            "E_IS_SCOPE: -5.763539705691563e-06\n",
            "E_IS_E_SCOPE: -5.658730042880979e-06\n",
            "Total Loss: 1.0655014554645125e-06\n",
            "----------------------------------------\n",
            "Epoch 9786\n",
            "Var loss:  tensor(1.0655e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.846075112071241e-06\n",
            "E_s_wdiff_all_sq: 2.6406180839504805e-06\n",
            "E_IS_SCOPE: -5.780011137903828e-06\n",
            "E_IS_E_SCOPE: -5.67512508604941e-06\n",
            "Total Loss: 1.06548234795218e-06\n",
            "----------------------------------------\n",
            "Epoch 9787\n",
            "Var loss:  tensor(1.0655e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.953341989752557e-06\n",
            "E_s_wdiff_all_sq: 2.747950001731433e-06\n",
            "E_IS_SCOPE: -5.762475179248723e-06\n",
            "E_IS_E_SCOPE: -5.657614290156992e-06\n",
            "Total Loss: 1.0654676333779186e-06\n",
            "----------------------------------------\n",
            "Epoch 9788\n",
            "Var loss:  tensor(1.0655e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.838537525694809e-06\n",
            "E_s_wdiff_all_sq: 2.633375367080708e-06\n",
            "E_IS_SCOPE: -5.779778767310351e-06\n",
            "E_IS_E_SCOPE: -5.675031591247232e-06\n",
            "Total Loss: 1.0654652300281178e-06\n",
            "----------------------------------------\n",
            "Epoch 9789\n",
            "Var loss:  tensor(1.0655e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.961698801357908e-06\n",
            "E_s_wdiff_all_sq: 2.7563003048561136e-06\n",
            "E_IS_SCOPE: -5.76059541124052e-06\n",
            "E_IS_E_SCOPE: -5.655734232910077e-06\n",
            "Total Loss: 1.0654735633811641e-06\n",
            "----------------------------------------\n",
            "Epoch 9790\n",
            "Var loss:  tensor(1.0655e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.823894269963532e-06\n",
            "E_s_wdiff_all_sq: 2.618415657380596e-06\n",
            "E_IS_SCOPE: -5.781882486661044e-06\n",
            "E_IS_E_SCOPE: -5.67699048380297e-06\n",
            "Total Loss: 1.0654920304070445e-06\n",
            "----------------------------------------\n",
            "Epoch 9791\n",
            "Var loss:  tensor(1.0655e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.970274758647685e-06\n",
            "E_s_wdiff_all_sq: 2.764828511398702e-06\n",
            "E_IS_SCOPE: -5.758251121256491e-06\n",
            "E_IS_E_SCOPE: -5.653390914183864e-06\n",
            "Total Loss: 1.0655232566439842e-06\n",
            "----------------------------------------\n",
            "Epoch 9792\n",
            "Var loss:  tensor(1.0656e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.8087093535072796e-06\n",
            "E_s_wdiff_all_sq: 2.6031635024124215e-06\n",
            "E_IS_SCOPE: -5.783409392892006e-06\n",
            "E_IS_E_SCOPE: -5.67852652839977e-06\n",
            "Total Loss: 1.0655775456506435e-06\n",
            "----------------------------------------\n",
            "Epoch 9793\n",
            "Var loss:  tensor(1.0657e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.983384826205316e-06\n",
            "E_s_wdiff_all_sq: 2.777629392242659e-06\n",
            "E_IS_SCOPE: -5.7561089608597725e-06\n",
            "E_IS_E_SCOPE: -5.651159978269085e-06\n",
            "Total Loss: 1.065654892321538e-06\n",
            "----------------------------------------\n",
            "Epoch 9794\n",
            "Var loss:  tensor(1.0658e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.7965434872326243e-06\n",
            "E_s_wdiff_all_sq: 2.5909450871768747e-06\n",
            "E_IS_SCOPE: -5.7852079305254136e-06\n",
            "E_IS_E_SCOPE: -5.680387639466922e-06\n",
            "Total Loss: 1.0657552414790223e-06\n",
            "----------------------------------------\n",
            "Epoch 9795\n",
            "Var loss:  tensor(1.0659e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 4.010409820749114e-06\n",
            "E_s_wdiff_all_sq: 2.804706407132211e-06\n",
            "E_IS_SCOPE: -5.7517538257453215e-06\n",
            "E_IS_E_SCOPE: -5.646951172204947e-06\n",
            "Total Loss: 1.0658955300764095e-06\n",
            "----------------------------------------\n",
            "Epoch 9796\n",
            "Var loss:  tensor(1.0661e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.779894984545633e-06\n",
            "E_s_wdiff_all_sq: 2.5739545706545083e-06\n",
            "E_IS_SCOPE: -5.788233619896098e-06\n",
            "E_IS_E_SCOPE: -5.6834014985027e-06\n",
            "Total Loss: 1.0660735946445853e-06\n",
            "----------------------------------------\n",
            "Epoch 9797\n",
            "Var loss:  tensor(1.0663e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 4.037543607096375e-06\n",
            "E_s_wdiff_all_sq: 2.8312001585893516e-06\n",
            "E_IS_SCOPE: -5.748401104152213e-06\n",
            "E_IS_E_SCOPE: -5.643481971456878e-06\n",
            "Total Loss: 1.0663026066566083e-06\n",
            "----------------------------------------\n",
            "Epoch 9798\n",
            "Var loss:  tensor(1.0666e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.7603490857369414e-06\n",
            "E_s_wdiff_all_sq: 2.5539912790348184e-06\n",
            "E_IS_SCOPE: -5.791574519403468e-06\n",
            "E_IS_E_SCOPE: -5.686784635042448e-06\n",
            "Total Loss: 1.0665754615203386e-06\n",
            "----------------------------------------\n",
            "Epoch 9799\n",
            "Var loss:  tensor(1.0669e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 4.066559652909606e-06\n",
            "E_s_wdiff_all_sq: 2.8597474126386293e-06\n",
            "E_IS_SCOPE: -5.7434005174954965e-06\n",
            "E_IS_E_SCOPE: -5.638542518624594e-06\n",
            "Total Loss: 1.0668936660694275e-06\n",
            "----------------------------------------\n",
            "Epoch 9800\n",
            "Var loss:  tensor(1.0673e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.7272384365906206e-06\n",
            "E_s_wdiff_all_sq: 2.5199229672464372e-06\n",
            "E_IS_SCOPE: -5.796666117374897e-06\n",
            "E_IS_E_SCOPE: -5.6917432965025756e-06\n",
            "Total Loss: 1.0672672511397963e-06\n",
            "----------------------------------------\n",
            "Epoch 9801\n",
            "Var loss:  tensor(1.0677e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 4.0937045916929785e-06\n",
            "E_s_wdiff_all_sq: 2.8860158044748493e-06\n",
            "E_IS_SCOPE: -5.739056793219513e-06\n",
            "E_IS_E_SCOPE: -5.634139083830586e-06\n",
            "Total Loss: 1.0676507919805303e-06\n",
            "----------------------------------------\n",
            "Epoch 9802\n",
            "Var loss:  tensor(1.0680e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.7079568707643167e-06\n",
            "E_s_wdiff_all_sq: 2.5001008591335905e-06\n",
            "E_IS_SCOPE: -5.799365442429919e-06\n",
            "E_IS_E_SCOPE: -5.694546117367002e-06\n",
            "Total Loss: 1.068014785045149e-06\n",
            "----------------------------------------\n",
            "Epoch 9803\n",
            "Var loss:  tensor(1.0683e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 4.117678256788296e-06\n",
            "E_s_wdiff_all_sq: 2.90927060013123e-06\n",
            "E_IS_SCOPE: -5.7352277846112035e-06\n",
            "E_IS_E_SCOPE: -5.630271078066144e-06\n",
            "Total Loss: 1.0682916671072034e-06\n",
            "----------------------------------------\n",
            "Epoch 9804\n",
            "Var loss:  tensor(1.0684e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.691599751362439e-06\n",
            "E_s_wdiff_all_sq: 2.483222809676068e-06\n",
            "E_IS_SCOPE: -5.8012288829684915e-06\n",
            "E_IS_E_SCOPE: -5.696351637248089e-06\n",
            "Total Loss: 1.0684198737858215e-06\n",
            "----------------------------------------\n",
            "Epoch 9805\n",
            "Var loss:  tensor(1.0683e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 4.117349268084081e-06\n",
            "E_s_wdiff_all_sq: 2.909117900409112e-06\n",
            "E_IS_SCOPE: -5.7335399586498595e-06\n",
            "E_IS_E_SCOPE: -5.628696084920444e-06\n",
            "Total Loss: 1.0683410437563936e-06\n",
            "----------------------------------------\n",
            "Epoch 9806\n",
            "Var loss:  tensor(1.0680e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.6925565718680996e-06\n",
            "E_s_wdiff_all_sq: 2.4846444148595947e-06\n",
            "E_IS_SCOPE: -5.799521271868758e-06\n",
            "E_IS_E_SCOPE: -5.6946760942044295e-06\n",
            "Total Loss: 1.0680192252201027e-06\n",
            "----------------------------------------\n",
            "Epoch 9807\n",
            "Var loss:  tensor(1.0675e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 4.084730799446572e-06\n",
            "E_s_wdiff_all_sq: 2.877205246457813e-06\n",
            "E_IS_SCOPE: -5.737469940101575e-06\n",
            "E_IS_E_SCOPE: -5.6325350036021615e-06\n",
            "Total Loss: 1.0674531035301882e-06\n",
            "----------------------------------------\n",
            "Epoch 9808\n",
            "Var loss:  tensor(1.0667e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.7286212830267213e-06\n",
            "E_s_wdiff_all_sq: 2.5221462995898427e-06\n",
            "E_IS_SCOPE: -5.7924749430131835e-06\n",
            "E_IS_E_SCOPE: -5.687692293642523e-06\n",
            "Total Loss: 1.0667071082358134e-06\n",
            "----------------------------------------\n",
            "Epoch 9809\n",
            "Var loss:  tensor(1.0659e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 4.032810023129904e-06\n",
            "E_s_wdiff_all_sq: 2.826976008262119e-06\n",
            "E_IS_SCOPE: -5.744510355499031e-06\n",
            "E_IS_E_SCOPE: -5.639639347594131e-06\n",
            "Total Loss: 1.0658894225982392e-06\n",
            "----------------------------------------\n",
            "Epoch 9810\n",
            "Var loss:  tensor(1.0651e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.7894497372652327e-06\n",
            "E_s_wdiff_all_sq: 2.584366697601932e-06\n",
            "E_IS_SCOPE: -5.782485012331979e-06\n",
            "E_IS_E_SCOPE: -5.677609350872037e-06\n",
            "Total Loss: 1.0651291402836735e-06\n",
            "----------------------------------------\n",
            "Epoch 9811\n",
            "Var loss:  tensor(1.0645e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.96144350447178e-06\n",
            "E_s_wdiff_all_sq: 2.7568490678125102e-06\n",
            "E_IS_SCOPE: -5.7554508615152e-06\n",
            "E_IS_E_SCOPE: -5.650524138974904e-06\n",
            "Total Loss: 1.0645384151189334e-06\n",
            "----------------------------------------\n",
            "Epoch 9812\n",
            "Var loss:  tensor(1.0642e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.863951975033927e-06\n",
            "E_s_wdiff_all_sq: 2.6597087020472608e-06\n",
            "E_IS_SCOPE: -5.770720066805717e-06\n",
            "E_IS_E_SCOPE: -5.665791611323474e-06\n",
            "Total Loss: 1.0641837855624357e-06\n",
            "----------------------------------------\n",
            "Epoch 9813\n",
            "Var loss:  tensor(1.0641e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.8941385615882704e-06\n",
            "E_s_wdiff_all_sq: 2.6902380283353276e-06\n",
            "E_IS_SCOPE: -5.765644616368272e-06\n",
            "E_IS_E_SCOPE: -5.660826703184127e-06\n",
            "Total Loss: 1.0640621304249096e-06\n",
            "----------------------------------------\n",
            "Epoch 9814\n",
            "Var loss:  tensor(1.0641e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.92843479295151e-06\n",
            "E_s_wdiff_all_sq: 2.7242382621566488e-06\n",
            "E_IS_SCOPE: -5.760201045256586e-06\n",
            "E_IS_E_SCOPE: -5.6552644645867394e-06\n",
            "Total Loss: 1.0641207929954227e-06\n",
            "----------------------------------------\n",
            "Epoch 9815\n",
            "Var loss:  tensor(1.0643e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.828772115882944e-06\n",
            "E_s_wdiff_all_sq: 2.6244015424453074e-06\n",
            "E_IS_SCOPE: -5.775439474666635e-06\n",
            "E_IS_E_SCOPE: -5.670504645901297e-06\n",
            "Total Loss: 1.0642983394472179e-06\n",
            "----------------------------------------\n",
            "Epoch 9816\n",
            "Var loss:  tensor(1.0645e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.975175201520497e-06\n",
            "E_s_wdiff_all_sq: 2.770850855132051e-06\n",
            "E_IS_SCOPE: -5.751822534216767e-06\n",
            "E_IS_E_SCOPE: -5.647017779370758e-06\n",
            "Total Loss: 1.0645122602366836e-06\n",
            "----------------------------------------\n",
            "Epoch 9817\n",
            "Var loss:  tensor(1.0647e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.7939372481816337e-06\n",
            "E_s_wdiff_all_sq: 2.589191576252755e-06\n",
            "E_IS_SCOPE: -5.7804693971412205e-06\n",
            "E_IS_E_SCOPE: -5.675541990748481e-06\n",
            "Total Loss: 1.0646882826836545e-06\n",
            "----------------------------------------\n",
            "Epoch 9818\n",
            "Var loss:  tensor(1.0648e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.996761849725583e-06\n",
            "E_s_wdiff_all_sq: 2.791883433714823e-06\n",
            "E_IS_SCOPE: -5.7485755496627334e-06\n",
            "E_IS_E_SCOPE: -5.643630046935358e-06\n",
            "Total Loss: 1.0647848340962647e-06\n",
            "----------------------------------------\n",
            "Epoch 9819\n",
            "Var loss:  tensor(1.0648e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.7903014754296387e-06\n",
            "E_s_wdiff_all_sq: 2.5857690614203018e-06\n",
            "E_IS_SCOPE: -5.780288817740997e-06\n",
            "E_IS_E_SCOPE: -5.6755146164338145e-06\n",
            "Total Loss: 1.064781434935227e-06\n",
            "----------------------------------------\n",
            "Epoch 9820\n",
            "Var loss:  tensor(1.0647e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.993337333975683e-06\n",
            "E_s_wdiff_all_sq: 2.7884360400594034e-06\n",
            "E_IS_SCOPE: -5.74852255832803e-06\n",
            "E_IS_E_SCOPE: -5.643509232248985e-06\n",
            "Total Loss: 1.0646720652984465e-06\n",
            "----------------------------------------\n",
            "Epoch 9821\n",
            "Var loss:  tensor(1.0645e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.799029572486283e-06\n",
            "E_s_wdiff_all_sq: 2.5945913946767717e-06\n",
            "E_IS_SCOPE: -5.778354178518636e-06\n",
            "E_IS_E_SCOPE: -5.673478438068583e-06\n",
            "Total Loss: 1.0644841204496628e-06\n",
            "----------------------------------------\n",
            "Epoch 9822\n",
            "Var loss:  tensor(1.0642e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.975366493794659e-06\n",
            "E_s_wdiff_all_sq: 2.77116248522971e-06\n",
            "E_IS_SCOPE: -5.750272434767253e-06\n",
            "E_IS_E_SCOPE: -5.645395767504072e-06\n",
            "Total Loss: 1.0642480975788418e-06\n",
            "----------------------------------------\n",
            "Epoch 9823\n",
            "Var loss:  tensor(1.0640e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.823668645778719e-06\n",
            "E_s_wdiff_all_sq: 2.6195072109510653e-06\n",
            "E_IS_SCOPE: -5.774139615063048e-06\n",
            "E_IS_E_SCOPE: -5.669162939870845e-06\n",
            "Total Loss: 1.0640055079835044e-06\n",
            "----------------------------------------\n",
            "Epoch 9824\n",
            "Var loss:  tensor(1.0638e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.941559954207423e-06\n",
            "E_s_wdiff_all_sq: 2.737829927879485e-06\n",
            "E_IS_SCOPE: -5.754979864516642e-06\n",
            "E_IS_E_SCOPE: -5.650110171834712e-06\n",
            "Total Loss: 1.063788064504333e-06\n",
            "----------------------------------------\n",
            "Epoch 9825\n",
            "Var loss:  tensor(1.0636e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.862713849483785e-06\n",
            "E_s_wdiff_all_sq: 2.659359276810609e-06\n",
            "E_IS_SCOPE: -5.76663790596315e-06\n",
            "E_IS_E_SCOPE: -5.66187334361173e-06\n",
            "Total Loss: 1.0636228715105918e-06\n",
            "----------------------------------------\n",
            "Epoch 9826\n",
            "Var loss:  tensor(1.0635e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.898826419131418e-06\n",
            "E_s_wdiff_all_sq: 2.695094827334058e-06\n",
            "E_IS_SCOPE: -5.761221545599357e-06\n",
            "E_IS_E_SCOPE: -5.6562124019869235e-06\n",
            "Total Loss: 1.063510728112749e-06\n",
            "----------------------------------------\n",
            "Epoch 9827\n",
            "Var loss:  tensor(1.0635e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.889845480017443e-06\n",
            "E_s_wdiff_all_sq: 2.686284434811947e-06\n",
            "E_IS_SCOPE: -5.762106106327501e-06\n",
            "E_IS_E_SCOPE: -5.6571529389462035e-06\n",
            "Total Loss: 1.0634521339831566e-06\n",
            "----------------------------------------\n",
            "Epoch 9828\n",
            "Var loss:  tensor(1.0634e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.872465976906733e-06\n",
            "E_s_wdiff_all_sq: 2.6692139603821677e-06\n",
            "E_IS_SCOPE: -5.764252887857977e-06\n",
            "E_IS_E_SCOPE: -5.65944712108417e-06\n",
            "Total Loss: 1.0634379065172063e-06\n",
            "----------------------------------------\n",
            "Epoch 9829\n",
            "Var loss:  tensor(1.0634e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.915926299597202e-06\n",
            "E_s_wdiff_all_sq: 2.7122897152056777e-06\n",
            "E_IS_SCOPE: -5.757715334180063e-06\n",
            "E_IS_E_SCOPE: -5.6527214621457534e-06\n",
            "Total Loss: 1.063446263863161e-06\n",
            "----------------------------------------\n",
            "Epoch 9830\n",
            "Var loss:  tensor(1.0635e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.847036857123876e-06\n",
            "E_s_wdiff_all_sq: 2.6435510273175894e-06\n",
            "E_IS_SCOPE: -5.768213119219606e-06\n",
            "E_IS_E_SCOPE: -5.6633041049448925e-06\n",
            "Total Loss: 1.0634652247971153e-06\n",
            "----------------------------------------\n",
            "Epoch 9831\n",
            "Var loss:  tensor(1.0635e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.939059893727834e-06\n",
            "E_s_wdiff_all_sq: 2.735726471995673e-06\n",
            "E_IS_SCOPE: -5.753419051879515e-06\n",
            "E_IS_E_SCOPE: -5.648594253514931e-06\n",
            "Total Loss: 1.0634812485432465e-06\n",
            "----------------------------------------\n",
            "Epoch 9832\n",
            "Var loss:  tensor(1.0635e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.8296988204655635e-06\n",
            "E_s_wdiff_all_sq: 2.6259335161707243e-06\n",
            "E_IS_SCOPE: -5.770800125409702e-06\n",
            "E_IS_E_SCOPE: -5.665760156016074e-06\n",
            "Total Loss: 1.0634827890478398e-06\n",
            "----------------------------------------\n",
            "Epoch 9833\n",
            "Var loss:  tensor(1.0635e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.941612972242506e-06\n",
            "E_s_wdiff_all_sq: 2.7381070363691935e-06\n",
            "E_IS_SCOPE: -5.752557037644981e-06\n",
            "E_IS_E_SCOPE: -5.647635002678938e-06\n",
            "Total Loss: 1.0634592894814816e-06\n",
            "----------------------------------------\n",
            "Epoch 9834\n",
            "Var loss:  tensor(1.0634e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.8340357934997916e-06\n",
            "E_s_wdiff_all_sq: 2.6309101878607298e-06\n",
            "E_IS_SCOPE: -5.7686586503505735e-06\n",
            "E_IS_E_SCOPE: -5.6639081580229735e-06\n",
            "Total Loss: 1.0634220445241183e-06\n",
            "----------------------------------------\n",
            "Epoch 9835\n",
            "Var loss:  tensor(1.0634e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.935799963440471e-06\n",
            "E_s_wdiff_all_sq: 2.7320748308568895e-06\n",
            "E_IS_SCOPE: -5.753415878833668e-06\n",
            "E_IS_E_SCOPE: -5.648333914814566e-06\n",
            "Total Loss: 1.0633586280856339e-06\n",
            "----------------------------------------\n",
            "Epoch 9836\n",
            "Var loss:  tensor(1.0633e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.837614046296041e-06\n",
            "E_s_wdiff_all_sq: 2.6342281803726224e-06\n",
            "E_IS_SCOPE: -5.768561159627483e-06\n",
            "E_IS_E_SCOPE: -5.6636100380192205e-06\n",
            "Total Loss: 1.063281046247149e-06\n",
            "----------------------------------------\n",
            "Epoch 9837\n",
            "Var loss:  tensor(1.0632e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.940047709823934e-06\n",
            "E_s_wdiff_all_sq: 2.7371773095373606e-06\n",
            "E_IS_SCOPE: -5.7516786637469235e-06\n",
            "E_IS_E_SCOPE: -5.646947131026126e-06\n",
            "Total Loss: 1.063204758385234e-06\n",
            "----------------------------------------\n",
            "Epoch 9838\n",
            "Var loss:  tensor(1.0631e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.845746067644886e-06\n",
            "E_s_wdiff_all_sq: 2.642364169276232e-06\n",
            "E_IS_SCOPE: -5.766934864702202e-06\n",
            "E_IS_E_SCOPE: -5.661900141254341e-06\n",
            "Total Loss: 1.0631098750131862e-06\n",
            "----------------------------------------\n",
            "Epoch 9839\n",
            "Var loss:  tensor(1.0630e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.9185162796830865e-06\n",
            "E_s_wdiff_all_sq: 2.715265697242558e-06\n",
            "E_IS_SCOPE: -5.7552083328448244e-06\n",
            "E_IS_E_SCOPE: -5.650196649586716e-06\n",
            "Total Loss: 1.0630246394645666e-06\n",
            "----------------------------------------\n",
            "Epoch 9840\n",
            "Var loss:  tensor(1.0629e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.863650332663275e-06\n",
            "E_s_wdiff_all_sq: 2.6607612968343086e-06\n",
            "E_IS_SCOPE: -5.7633235054143e-06\n",
            "E_IS_E_SCOPE: -5.658454614516078e-06\n",
            "Total Loss: 1.0629486775727767e-06\n",
            "----------------------------------------\n",
            "Epoch 9841\n",
            "Var loss:  tensor(1.0629e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.908148876219575e-06\n",
            "E_s_wdiff_all_sq: 2.7052106679203832e-06\n",
            "E_IS_SCOPE: -5.756265299134916e-06\n",
            "E_IS_E_SCOPE: -5.651336140129956e-06\n",
            "Total Loss: 1.062877313829527e-06\n",
            "----------------------------------------\n",
            "Epoch 9842\n",
            "Var loss:  tensor(1.0628e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.874001728044121e-06\n",
            "E_s_wdiff_all_sq: 2.6711741930412715e-06\n",
            "E_IS_SCOPE: -5.761169474978452e-06\n",
            "E_IS_E_SCOPE: -5.65626459346198e-06\n",
            "Total Loss: 1.0628151955101624e-06\n",
            "----------------------------------------\n",
            "Epoch 9843\n",
            "Var loss:  tensor(1.0628e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.893824154407205e-06\n",
            "E_s_wdiff_all_sq: 2.691055180606718e-06\n",
            "E_IS_SCOPE: -5.7576489663281386e-06\n",
            "E_IS_E_SCOPE: -5.652746548456018e-06\n",
            "Total Loss: 1.0627615615965018e-06\n",
            "----------------------------------------\n",
            "Epoch 9844\n",
            "Var loss:  tensor(1.0627e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.883619077164271e-06\n",
            "E_s_wdiff_all_sq: 2.680859168831828e-06\n",
            "E_IS_SCOPE: -5.759058113424522e-06\n",
            "E_IS_E_SCOPE: -5.654136234007517e-06\n",
            "Total Loss: 1.0627135730386882e-06\n",
            "----------------------------------------\n",
            "Epoch 9845\n",
            "Var loss:  tensor(1.0627e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.881243252825346e-06\n",
            "E_s_wdiff_all_sq: 2.6785225067578132e-06\n",
            "E_IS_SCOPE: -5.75905832827377e-06\n",
            "E_IS_E_SCOPE: -5.6541345836888576e-06\n",
            "Total Loss: 1.0626706804379647e-06\n",
            "----------------------------------------\n",
            "Epoch 9846\n",
            "Var loss:  tensor(1.0626e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.888497070941192e-06\n",
            "E_s_wdiff_all_sq: 2.6857350027570684e-06\n",
            "E_IS_SCOPE: -5.757577185656912e-06\n",
            "E_IS_E_SCOPE: -5.652615047550346e-06\n",
            "Total Loss: 1.0626352155112485e-06\n",
            "----------------------------------------\n",
            "Epoch 9847\n",
            "Var loss:  tensor(1.0626e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.8704773340371405e-06\n",
            "E_s_wdiff_all_sq: 2.667721846778627e-06\n",
            "E_IS_SCOPE: -5.7601120331033686e-06\n",
            "E_IS_E_SCOPE: -5.655132540711465e-06\n",
            "Total Loss: 1.0625939260149611e-06\n",
            "----------------------------------------\n",
            "Epoch 9848\n",
            "Var loss:  tensor(1.0626e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.899919203336422e-06\n",
            "E_s_wdiff_all_sq: 2.6973486931695365e-06\n",
            "E_IS_SCOPE: -5.755131575739125e-06\n",
            "E_IS_E_SCOPE: -5.6502262320010994e-06\n",
            "Total Loss: 1.0625572462310896e-06\n",
            "----------------------------------------\n",
            "Epoch 9849\n",
            "Var loss:  tensor(1.0625e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.867315597910701e-06\n",
            "E_s_wdiff_all_sq: 2.66457993470441e-06\n",
            "E_IS_SCOPE: -5.760278428411105e-06\n",
            "E_IS_E_SCOPE: -5.655274540585723e-06\n",
            "Total Loss: 1.0625253110957825e-06\n",
            "----------------------------------------\n",
            "Epoch 9850\n",
            "Var loss:  tensor(1.0625e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.900668388436519e-06\n",
            "E_s_wdiff_all_sq: 2.6979173894627433e-06\n",
            "E_IS_SCOPE: -5.754495678957242e-06\n",
            "E_IS_E_SCOPE: -5.649464342914067e-06\n",
            "Total Loss: 1.0624857504276815e-06\n",
            "----------------------------------------\n",
            "Epoch 9851\n",
            "Var loss:  tensor(1.0625e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.861884593227913e-06\n",
            "E_s_wdiff_all_sq: 2.659538139247704e-06\n",
            "E_IS_SCOPE: -5.759572155991859e-06\n",
            "E_IS_E_SCOPE: -5.654725230827986e-06\n",
            "Total Loss: 1.0624500271927183e-06\n",
            "----------------------------------------\n",
            "Epoch 9852\n",
            "Var loss:  tensor(1.0624e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.900330198034684e-06\n",
            "E_s_wdiff_all_sq: 2.697701269272705e-06\n",
            "E_IS_SCOPE: -5.753638264319599e-06\n",
            "E_IS_E_SCOPE: -5.648632556739034e-06\n",
            "Total Loss: 1.062414937141104e-06\n",
            "----------------------------------------\n",
            "Epoch 9853\n",
            "Var loss:  tensor(1.0624e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.853926090987537e-06\n",
            "E_s_wdiff_all_sq: 2.6513879050351377e-06\n",
            "E_IS_SCOPE: -5.760701421096917e-06\n",
            "E_IS_E_SCOPE: -5.655721887713873e-06\n",
            "Total Loss: 1.0623765427265662e-06\n",
            "----------------------------------------\n",
            "Epoch 9854\n",
            "Var loss:  tensor(1.0623e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.90827017383962e-06\n",
            "E_s_wdiff_all_sq: 2.7059945331402496e-06\n",
            "E_IS_SCOPE: -5.751844982697991e-06\n",
            "E_IS_E_SCOPE: -5.646977080195424e-06\n",
            "Total Loss: 1.0623372592344923e-06\n",
            "----------------------------------------\n",
            "Epoch 9855\n",
            "Var loss:  tensor(1.0623e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.856785073110023e-06\n",
            "E_s_wdiff_all_sq: 2.6544309543784537e-06\n",
            "E_IS_SCOPE: -5.760178500008602e-06\n",
            "E_IS_E_SCOPE: -5.655250524309149e-06\n",
            "Total Loss: 1.0622955908729181e-06\n",
            "----------------------------------------\n",
            "Epoch 9856\n",
            "Var loss:  tensor(1.0623e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.907935473988449e-06\n",
            "E_s_wdiff_all_sq: 2.7054353452994843e-06\n",
            "E_IS_SCOPE: -5.752348239693837e-06\n",
            "E_IS_E_SCOPE: -5.647327563040284e-06\n",
            "Total Loss: 1.062256198922115e-06\n",
            "----------------------------------------\n",
            "Epoch 9857\n",
            "Var loss:  tensor(1.0622e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.857066093993215e-06\n",
            "E_s_wdiff_all_sq: 2.6548387022139076e-06\n",
            "E_IS_SCOPE: -5.75999046883382e-06\n",
            "E_IS_E_SCOPE: -5.655085253867425e-06\n",
            "Total Loss: 1.0622143853867745e-06\n",
            "----------------------------------------\n",
            "Epoch 9858\n",
            "Var loss:  tensor(1.0622e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.91414633319054e-06\n",
            "E_s_wdiff_all_sq: 2.711853960411312e-06\n",
            "E_IS_SCOPE: -5.751091702800236e-06\n",
            "E_IS_E_SCOPE: -5.646133963859528e-06\n",
            "Total Loss: 1.062174318438068e-06\n",
            "----------------------------------------\n",
            "Epoch 9859\n",
            "Var loss:  tensor(1.0621e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.855108348178435e-06\n",
            "E_s_wdiff_all_sq: 2.652775148720873e-06\n",
            "E_IS_SCOPE: -5.7602879121580105e-06\n",
            "E_IS_E_SCOPE: -5.655290020734939e-06\n",
            "Total Loss: 1.062134840151674e-06\n",
            "----------------------------------------\n",
            "Epoch 9860\n",
            "Var loss:  tensor(1.0621e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.91435030556641e-06\n",
            "E_s_wdiff_all_sq: 2.712121102818798e-06\n",
            "E_IS_SCOPE: -5.750285987326461e-06\n",
            "E_IS_E_SCOPE: -5.645320582906151e-06\n",
            "Total Loss: 1.0620958174472481e-06\n",
            "----------------------------------------\n",
            "Epoch 9861\n",
            "Var loss:  tensor(1.0621e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.847552897283524e-06\n",
            "E_s_wdiff_all_sq: 2.64526526068351e-06\n",
            "E_IS_SCOPE: -5.760363467383563e-06\n",
            "E_IS_E_SCOPE: -5.655351787403228e-06\n",
            "Total Loss: 1.0620617001795993e-06\n",
            "----------------------------------------\n",
            "Epoch 9862\n",
            "Var loss:  tensor(1.0620e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.913591401410904e-06\n",
            "E_s_wdiff_all_sq: 2.7114273998794234e-06\n",
            "E_IS_SCOPE: -5.749564735023406e-06\n",
            "E_IS_E_SCOPE: -5.644596553462674e-06\n",
            "Total Loss: 1.0620250619502722e-06\n",
            "----------------------------------------\n",
            "Epoch 9863\n",
            "Var loss:  tensor(1.0620e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.8479124302938175e-06\n",
            "E_s_wdiff_all_sq: 2.6458649097711104e-06\n",
            "E_IS_SCOPE: -5.759785117757881e-06\n",
            "E_IS_E_SCOPE: -5.654859338348734e-06\n",
            "Total Loss: 1.0619933852446695e-06\n",
            "----------------------------------------\n",
            "Epoch 9864\n",
            "Var loss:  tensor(1.0620e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.917249208318123e-06\n",
            "E_s_wdiff_all_sq: 2.7149670981890613e-06\n",
            "E_IS_SCOPE: -5.7490251744974866e-06\n",
            "E_IS_E_SCOPE: -5.643966416639177e-06\n",
            "Total Loss: 1.0619620179526977e-06\n",
            "----------------------------------------\n",
            "Epoch 9865\n",
            "Var loss:  tensor(1.0619e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.843108435955303e-06\n",
            "E_s_wdiff_all_sq: 2.6411113386801233e-06\n",
            "E_IS_SCOPE: -5.759884833789325e-06\n",
            "E_IS_E_SCOPE: -5.654953728241115e-06\n",
            "Total Loss: 1.0619323097190155e-06\n",
            "----------------------------------------\n",
            "Epoch 9866\n",
            "Var loss:  tensor(1.0619e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.924765207594123e-06\n",
            "E_s_wdiff_all_sq: 2.7227954144300036e-06\n",
            "E_IS_SCOPE: -5.746789012091307e-06\n",
            "E_IS_E_SCOPE: -5.641859972161001e-06\n",
            "Total Loss: 1.061909136843763e-06\n",
            "----------------------------------------\n",
            "Epoch 9867\n",
            "Var loss:  tensor(1.0619e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.834473361196208e-06\n",
            "E_s_wdiff_all_sq: 2.6323600543540976e-06\n",
            "E_IS_SCOPE: -5.761106011732938e-06\n",
            "E_IS_E_SCOPE: -5.6560966680777595e-06\n",
            "Total Loss: 1.0618920430720088e-06\n",
            "----------------------------------------\n",
            "Epoch 9868\n",
            "Var loss:  tensor(1.0619e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.932610286161419e-06\n",
            "E_s_wdiff_all_sq: 2.730533133926683e-06\n",
            "E_IS_SCOPE: -5.7455946037386836e-06\n",
            "E_IS_E_SCOPE: -5.640599181799503e-06\n",
            "Total Loss: 1.0618837318966296e-06\n",
            "----------------------------------------\n",
            "Epoch 9869\n",
            "Var loss:  tensor(1.0619e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.830958161820697e-06\n",
            "E_s_wdiff_all_sq: 2.6290808207348395e-06\n",
            "E_IS_SCOPE: -5.761123582674074e-06\n",
            "E_IS_E_SCOPE: -5.65622763814292e-06\n",
            "Total Loss: 1.0618828755638052e-06\n",
            "----------------------------------------\n",
            "Epoch 9870\n",
            "Var loss:  tensor(1.0619e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.9433541185310744e-06\n",
            "E_s_wdiff_all_sq: 2.7412791207279096e-06\n",
            "E_IS_SCOPE: -5.743345027621018e-06\n",
            "E_IS_E_SCOPE: -5.638355205353032e-06\n",
            "Total Loss: 1.0618927768074477e-06\n",
            "----------------------------------------\n",
            "Epoch 9871\n",
            "Var loss:  tensor(1.0619e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.816434987145726e-06\n",
            "E_s_wdiff_all_sq: 2.6143874586045185e-06\n",
            "E_IS_SCOPE: -5.763048068410706e-06\n",
            "E_IS_E_SCOPE: -5.65808657282136e-06\n",
            "Total Loss: 1.0619219609027724e-06\n",
            "----------------------------------------\n",
            "Epoch 9872\n",
            "Var loss:  tensor(1.0620e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.956924732016769e-06\n",
            "E_s_wdiff_all_sq: 2.7548494255025653e-06\n",
            "E_IS_SCOPE: -5.740364325850819e-06\n",
            "E_IS_E_SCOPE: -5.635413019508154e-06\n",
            "Total Loss: 1.0619701173691286e-06\n",
            "----------------------------------------\n",
            "Epoch 9873\n",
            "Var loss:  tensor(1.0620e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.7967345294982856e-06\n",
            "E_s_wdiff_all_sq: 2.5946053759366044e-06\n",
            "E_IS_SCOPE: -5.7650072890751915e-06\n",
            "E_IS_E_SCOPE: -5.660066933919017e-06\n",
            "Total Loss: 1.0620458667895883e-06\n",
            "----------------------------------------\n",
            "Epoch 9874\n",
            "Var loss:  tensor(1.0622e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.9672305647493745e-06\n",
            "E_s_wdiff_all_sq: 2.7646003244591953e-06\n",
            "E_IS_SCOPE: -5.738401959183972e-06\n",
            "E_IS_E_SCOPE: -5.633266293125696e-06\n",
            "Total Loss: 1.0621563317138822e-06\n",
            "----------------------------------------\n",
            "Epoch 9875\n",
            "Var loss:  tensor(1.0623e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.7749808759403604e-06\n",
            "E_s_wdiff_all_sq: 2.5725817660006597e-06\n",
            "E_IS_SCOPE: -5.768069957641833e-06\n",
            "E_IS_E_SCOPE: -5.66312590469785e-06\n",
            "Total Loss: 1.0623084275919906e-06\n",
            "----------------------------------------\n",
            "Epoch 9876\n",
            "Var loss:  tensor(1.0625e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.999031687471945e-06\n",
            "E_s_wdiff_all_sq: 2.7963439902124354e-06\n",
            "E_IS_SCOPE: -5.73297456189638e-06\n",
            "E_IS_E_SCOPE: -5.627988587934278e-06\n",
            "Total Loss: 1.0625131728755614e-06\n",
            "----------------------------------------\n",
            "Epoch 9877\n",
            "Var loss:  tensor(1.0628e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.7488917961128033e-06\n",
            "E_s_wdiff_all_sq: 2.5457479057455127e-06\n",
            "E_IS_SCOPE: -5.772786050420817e-06\n",
            "E_IS_E_SCOPE: -5.6677087654315695e-06\n",
            "Total Loss: 1.0627867439290517e-06\n",
            "----------------------------------------\n",
            "Epoch 9878\n",
            "Var loss:  tensor(1.0631e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 4.0336434511384755e-06\n",
            "E_s_wdiff_all_sq: 2.8303474823238985e-06\n",
            "E_IS_SCOPE: -5.727496264267499e-06\n",
            "E_IS_E_SCOPE: -5.6225145255692985e-06\n",
            "Total Loss: 1.063129914958432e-06\n",
            "----------------------------------------\n",
            "Epoch 9879\n",
            "Var loss:  tensor(1.0636e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.7221102082629488e-06\n",
            "E_s_wdiff_all_sq: 2.518740912273291e-06\n",
            "E_IS_SCOPE: -5.775567853415782e-06\n",
            "E_IS_E_SCOPE: -5.670761776532738e-06\n",
            "Total Loss: 1.0635545657638265e-06\n",
            "----------------------------------------\n",
            "Epoch 9880\n",
            "Var loss:  tensor(1.0641e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 4.062216345116192e-06\n",
            "E_s_wdiff_all_sq: 2.857670746039233e-06\n",
            "E_IS_SCOPE: -5.7227717169224426e-06\n",
            "E_IS_E_SCOPE: -5.617627563407061e-06\n",
            "Total Loss: 1.0640547155864507e-06\n",
            "----------------------------------------\n",
            "Epoch 9881\n",
            "Var loss:  tensor(1.0646e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.682394924006945e-06\n",
            "E_s_wdiff_all_sq: 2.4775793389854754e-06\n",
            "E_IS_SCOPE: -5.7822170938730194e-06\n",
            "E_IS_E_SCOPE: -5.677212621624851e-06\n",
            "Total Loss: 1.0646040640653878e-06\n",
            "----------------------------------------\n",
            "Epoch 9882\n",
            "Var loss:  tensor(1.0652e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 4.108894072397876e-06\n",
            "E_s_wdiff_all_sq: 2.903754410554286e-06\n",
            "E_IS_SCOPE: -5.7149792631334816e-06\n",
            "E_IS_E_SCOPE: -5.610098069953113e-06\n",
            "Total Loss: 1.065174699023109e-06\n",
            "----------------------------------------\n",
            "Epoch 9883\n",
            "Var loss:  tensor(1.0657e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.6542054178551502e-06\n",
            "E_s_wdiff_all_sq: 2.4482528128413386e-06\n",
            "E_IS_SCOPE: -5.786931727037601e-06\n",
            "E_IS_E_SCOPE: -5.681889095242024e-06\n",
            "Total Loss: 1.065664764962915e-06\n",
            "----------------------------------------\n",
            "Epoch 9884\n",
            "Var loss:  tensor(1.0660e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 4.124624809634952e-06\n",
            "E_s_wdiff_all_sq: 2.9182144431852104e-06\n",
            "E_IS_SCOPE: -5.712601657104102e-06\n",
            "E_IS_E_SCOPE: -5.607489979782473e-06\n",
            "Total Loss: 1.0659844353467402e-06\n",
            "----------------------------------------\n",
            "Epoch 9885\n",
            "Var loss:  tensor(1.0660e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.647227104171859e-06\n",
            "E_s_wdiff_all_sq: 2.4413452198228663e-06\n",
            "E_IS_SCOPE: -5.786677375491311e-06\n",
            "E_IS_E_SCOPE: -5.68184506407613e-06\n",
            "Total Loss: 1.0660146850588864e-06\n",
            "----------------------------------------\n",
            "Epoch 9886\n",
            "Var loss:  tensor(1.0657e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 4.117471019219623e-06\n",
            "E_s_wdiff_all_sq: 2.911405371628954e-06\n",
            "E_IS_SCOPE: -5.713016790772675e-06\n",
            "E_IS_E_SCOPE: -5.60791277304249e-06\n",
            "Total Loss: 1.0656550356705556e-06\n",
            "----------------------------------------\n",
            "Epoch 9887\n",
            "Var loss:  tensor(1.0649e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.663240169290908e-06\n",
            "E_s_wdiff_all_sq: 2.457938823993579e-06\n",
            "E_IS_SCOPE: -5.783990480715275e-06\n",
            "E_IS_E_SCOPE: -5.6788960822847e-06\n",
            "Total Loss: 1.0649099719764367e-06\n",
            "----------------------------------------\n",
            "Epoch 9888\n",
            "Var loss:  tensor(1.0639e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 4.072509565792577e-06\n",
            "E_s_wdiff_all_sq: 2.8687036460423966e-06\n",
            "E_IS_SCOPE: -5.718225027129889e-06\n",
            "E_IS_E_SCOPE: -5.613355126792643e-06\n",
            "Total Loss: 1.063863542615943e-06\n",
            "----------------------------------------\n",
            "Epoch 9889\n",
            "Var loss:  tensor(1.0627e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.7276586970977047e-06\n",
            "E_s_wdiff_all_sq: 2.524846147435766e-06\n",
            "E_IS_SCOPE: -5.772071896488237e-06\n",
            "E_IS_E_SCOPE: -5.66712032205709e-06\n",
            "Total Loss: 1.062706824339901e-06\n",
            "----------------------------------------\n",
            "Epoch 9890\n",
            "Var loss:  tensor(1.0617e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.9744964102409226e-06\n",
            "E_s_wdiff_all_sq: 2.7722852131851997e-06\n",
            "E_IS_SCOPE: -5.733033538858144e-06\n",
            "E_IS_E_SCOPE: -5.627870455530987e-06\n",
            "Total Loss: 1.0616824539416653e-06\n",
            "----------------------------------------\n",
            "Epoch 9891\n",
            "Var loss:  tensor(1.0610e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.8136907309007074e-06\n",
            "E_s_wdiff_all_sq: 2.612648858962192e-06\n",
            "E_IS_SCOPE: -5.757303167304642e-06\n",
            "E_IS_E_SCOPE: -5.652363776557545e-06\n",
            "Total Loss: 1.0609605139845779e-06\n",
            "----------------------------------------\n",
            "Epoch 9892\n",
            "Var loss:  tensor(1.0606e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.8842783821382866e-06\n",
            "E_s_wdiff_all_sq: 2.683566274560116e-06\n",
            "E_IS_SCOPE: -5.745929123011426e-06\n",
            "E_IS_E_SCOPE: -5.640991381708561e-06\n",
            "Total Loss: 1.0606340485126958e-06\n",
            "----------------------------------------\n",
            "Epoch 9893\n",
            "Var loss:  tensor(1.0607e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.899348650931831e-06\n",
            "E_s_wdiff_all_sq: 2.6981639797077606e-06\n",
            "E_IS_SCOPE: -5.744095374824111e-06\n",
            "E_IS_E_SCOPE: -5.638935290664478e-06\n",
            "Total Loss: 1.0606619264450612e-06\n",
            "----------------------------------------\n",
            "Epoch 9894\n",
            "Var loss:  tensor(1.0609e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.806660888176892e-06\n",
            "E_s_wdiff_all_sq: 2.605561031802756e-06\n",
            "E_IS_SCOPE: -5.758134465141949e-06\n",
            "E_IS_E_SCOPE: -5.653150518866183e-06\n",
            "Total Loss: 1.0609293873628607e-06\n",
            "----------------------------------------\n",
            "Epoch 9895\n",
            "Var loss:  tensor(1.0613e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.974482752484872e-06\n",
            "E_s_wdiff_all_sq: 2.7731557986049246e-06\n",
            "E_IS_SCOPE: -5.731451706394584e-06\n",
            "E_IS_E_SCOPE: -5.6265363567707225e-06\n",
            "Total Loss: 1.0612936781724793e-06\n",
            "----------------------------------------\n",
            "Epoch 9896\n",
            "Var loss:  tensor(1.0616e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.758519606359031e-06\n",
            "E_s_wdiff_all_sq: 2.5565146868103726e-06\n",
            "E_IS_SCOPE: -5.766005871978698e-06\n",
            "E_IS_E_SCOPE: -5.660907694531022e-06\n",
            "Total Loss: 1.0616059881935642e-06\n",
            "----------------------------------------\n",
            "Epoch 9897\n",
            "Var loss:  tensor(1.0618e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.999135718474509e-06\n",
            "E_s_wdiff_all_sq: 2.7969806769230786e-06\n",
            "E_IS_SCOPE: -5.727664792582809e-06\n",
            "E_IS_E_SCOPE: -5.622572939932503e-06\n",
            "Total Loss: 1.0617687597910746e-06\n",
            "----------------------------------------\n",
            "Epoch 9898\n",
            "Var loss:  tensor(1.0617e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.7482182141069923e-06\n",
            "E_s_wdiff_all_sq: 2.546345070777139e-06\n",
            "E_IS_SCOPE: -5.766393628413578e-06\n",
            "E_IS_E_SCOPE: -5.661427150786404e-06\n",
            "Total Loss: 1.0617376116157621e-06\n",
            "----------------------------------------\n",
            "Epoch 9899\n",
            "Var loss:  tensor(1.0615e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.990455266474672e-06\n",
            "E_s_wdiff_all_sq: 2.7888129252316445e-06\n",
            "E_IS_SCOPE: -5.727724857874414e-06\n",
            "E_IS_E_SCOPE: -5.622765664006614e-06\n",
            "Total Loss: 1.0615213770476827e-06\n",
            "----------------------------------------\n",
            "Epoch 9900\n",
            "Var loss:  tensor(1.0612e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.7653383297856178e-06\n",
            "E_s_wdiff_all_sq: 2.563775447736814e-06\n",
            "E_IS_SCOPE: -5.763146015011924e-06\n",
            "E_IS_E_SCOPE: -5.658055752212048e-06\n",
            "Total Loss: 1.061179779989307e-06\n",
            "----------------------------------------\n",
            "Epoch 9901\n",
            "Var loss:  tensor(1.0608e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.949235312735197e-06\n",
            "E_s_wdiff_all_sq: 2.748157280524681e-06\n",
            "E_IS_SCOPE: -5.733752751156248e-06\n",
            "E_IS_E_SCOPE: -5.628712559290315e-06\n",
            "Total Loss: 1.0607950720189053e-06\n",
            "----------------------------------------\n",
            "Epoch 9902\n",
            "Var loss:  tensor(1.0605e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.818364420466528e-06\n",
            "E_s_wdiff_all_sq: 2.61790293445557e-06\n",
            "E_IS_SCOPE: -5.7539252484681045e-06\n",
            "E_IS_E_SCOPE: -5.649023875122956e-06\n",
            "Total Loss: 1.0604561628609165e-06\n",
            "----------------------------------------\n",
            "Epoch 9903\n",
            "Var loss:  tensor(1.0602e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.898643971135346e-06\n",
            "E_s_wdiff_all_sq: 2.697985431094826e-06\n",
            "E_IS_SCOPE: -5.741852487100575e-06\n",
            "E_IS_E_SCOPE: -5.636733646005153e-06\n",
            "Total Loss: 1.0602182813899326e-06\n",
            "----------------------------------------\n",
            "Epoch 9904\n",
            "Var loss:  tensor(1.0601e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.870434011853391e-06\n",
            "E_s_wdiff_all_sq: 2.669992881269274e-06\n",
            "E_IS_SCOPE: -5.746163910210224e-06\n",
            "E_IS_E_SCOPE: -5.6410952101772e-06\n",
            "Total Loss: 1.060101154058325e-06\n",
            "----------------------------------------\n",
            "Epoch 9905\n",
            "Var loss:  tensor(1.0601e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.856833952404051e-06\n",
            "E_s_wdiff_all_sq: 2.6566248341095262e-06\n",
            "E_IS_SCOPE: -5.74776162550458e-06\n",
            "E_IS_E_SCOPE: -5.6428069226662294e-06\n",
            "Total Loss: 1.0600971361580788e-06\n",
            "----------------------------------------\n",
            "Epoch 9906\n",
            "Var loss:  tensor(1.0602e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.912833502772202e-06\n",
            "E_s_wdiff_all_sq: 2.7122844917594853e-06\n",
            "E_IS_SCOPE: -5.73895441807843e-06\n",
            "E_IS_E_SCOPE: -5.633859696945716e-06\n",
            "Total Loss: 1.0601569922875443e-06\n",
            "----------------------------------------\n",
            "Epoch 9907\n",
            "Var loss:  tensor(1.0602e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.816577842062457e-06\n",
            "E_s_wdiff_all_sq: 2.616017699928661e-06\n",
            "E_IS_SCOPE: -5.753608588126298e-06\n",
            "E_IS_E_SCOPE: -5.648548409466958e-06\n",
            "Total Loss: 1.0602372083553713e-06\n",
            "----------------------------------------\n",
            "Epoch 9908\n",
            "Var loss:  tensor(1.0603e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.936658021960701e-06\n",
            "E_s_wdiff_all_sq: 2.7361250259801518e-06\n",
            "E_IS_SCOPE: -5.734107862896497e-06\n",
            "E_IS_E_SCOPE: -5.629094082895247e-06\n",
            "Total Loss: 1.060302859518306e-06\n",
            "----------------------------------------\n",
            "Epoch 9909\n",
            "Var loss:  tensor(1.0603e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.798274243050389e-06\n",
            "E_s_wdiff_all_sq: 2.5977024798000107e-06\n",
            "E_IS_SCOPE: -5.7556421642647025e-06\n",
            "E_IS_E_SCOPE: -5.650618237931602e-06\n",
            "Total Loss: 1.0603213341244337e-06\n",
            "----------------------------------------\n",
            "Epoch 9910\n",
            "Var loss:  tensor(1.0603e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.940156947773974e-06\n",
            "E_s_wdiff_all_sq: 2.7395588726892945e-06\n",
            "E_IS_SCOPE: -5.733228955519114e-06\n",
            "E_IS_E_SCOPE: -5.6281731629875045e-06\n",
            "Total Loss: 1.0602839135617156e-06\n",
            "----------------------------------------\n",
            "Epoch 9911\n",
            "Var loss:  tensor(1.0602e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.8020254568661524e-06\n",
            "E_s_wdiff_all_sq: 2.6015496290562937e-06\n",
            "E_IS_SCOPE: -5.754659046242327e-06\n",
            "E_IS_E_SCOPE: -5.649617084689176e-06\n",
            "Total Loss: 1.060189328243814e-06\n",
            "----------------------------------------\n",
            "Epoch 9912\n",
            "Var loss:  tensor(1.0601e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.927168815604243e-06\n",
            "E_s_wdiff_all_sq: 2.726769013885844e-06\n",
            "E_IS_SCOPE: -5.734534333574023e-06\n",
            "E_IS_E_SCOPE: -5.629467558887863e-06\n",
            "Total Loss: 1.0600636758863343e-06\n",
            "----------------------------------------\n",
            "Epoch 9913\n",
            "Var loss:  tensor(1.0599e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.8144738291666003e-06\n",
            "E_s_wdiff_all_sq: 2.614105719757934e-06\n",
            "E_IS_SCOPE: -5.7521159158963605e-06\n",
            "E_IS_E_SCOPE: -5.6470077829086495e-06\n",
            "Total Loss: 1.0599492669734992e-06\n",
            "----------------------------------------\n",
            "Epoch 9914\n",
            "Var loss:  tensor(1.0600e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.926729204721579e-06\n",
            "E_s_wdiff_all_sq: 2.7265154272511332e-06\n",
            "E_IS_SCOPE: -5.733443265998187e-06\n",
            "E_IS_E_SCOPE: -5.628427427345255e-06\n",
            "Total Loss: 1.0599795237048364e-06\n",
            "----------------------------------------\n",
            "Epoch 9915\n",
            "Var loss:  tensor(1.0600e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.79976329813672e-06\n",
            "E_s_wdiff_all_sq: 2.5994312183339626e-06\n",
            "E_IS_SCOPE: -5.75306823375664e-06\n",
            "E_IS_E_SCOPE: -5.648004230556326e-06\n",
            "Total Loss: 1.0600014969423847e-06\n",
            "----------------------------------------\n",
            "Epoch 9916\n",
            "Var loss:  tensor(1.0600e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.931520972577899e-06\n",
            "E_s_wdiff_all_sq: 2.731252210707524e-06\n",
            "E_IS_SCOPE: -5.7317578397195545e-06\n",
            "E_IS_E_SCOPE: -5.626714725512014e-06\n",
            "Total Loss: 1.0599799569955502e-06\n",
            "----------------------------------------\n",
            "Epoch 9917\n",
            "Var loss:  tensor(1.0599e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.796427911862826e-06\n",
            "E_s_wdiff_all_sq: 2.5961917692724824e-06\n",
            "E_IS_SCOPE: -5.752457901795667e-06\n",
            "E_IS_E_SCOPE: -5.6473980041715524e-06\n",
            "Total Loss: 1.0599137708823703e-06\n",
            "----------------------------------------\n",
            "Epoch 9918\n",
            "Var loss:  tensor(1.0598e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.9187464537890655e-06\n",
            "E_s_wdiff_all_sq: 2.718699915228644e-06\n",
            "E_IS_SCOPE: -5.732323252699577e-06\n",
            "E_IS_E_SCOPE: -5.627309920926168e-06\n",
            "Total Loss: 1.0598172985538595e-06\n",
            "----------------------------------------\n",
            "Epoch 9919\n",
            "Var loss:  tensor(1.0597e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.8055016206094417e-06\n",
            "E_s_wdiff_all_sq: 2.605576876637493e-06\n",
            "E_IS_SCOPE: -5.749589061696169e-06\n",
            "E_IS_E_SCOPE: -5.6445781435245134e-06\n",
            "Total Loss: 1.0597003311688935e-06\n",
            "----------------------------------------\n",
            "Epoch 9920\n",
            "Var loss:  tensor(1.0596e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.895188292722022e-06\n",
            "E_s_wdiff_all_sq: 2.695121458966643e-06\n",
            "E_IS_SCOPE: -5.7352362278473675e-06\n",
            "E_IS_E_SCOPE: -5.630094516634864e-06\n",
            "Total Loss: 1.0595808348706268e-06\n",
            "----------------------------------------\n",
            "Epoch 9921\n",
            "Var loss:  tensor(1.0595e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.823984276417718e-06\n",
            "E_s_wdiff_all_sq: 2.624162437997001e-06\n",
            "E_IS_SCOPE: -5.74607701093439e-06\n",
            "E_IS_E_SCOPE: -5.641003131471026e-06\n",
            "Total Loss: 1.0594715030342441e-06\n",
            "----------------------------------------\n",
            "Epoch 9922\n",
            "Var loss:  tensor(1.0594e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.8774390228380474e-06\n",
            "E_s_wdiff_all_sq: 2.677834612075074e-06\n",
            "E_IS_SCOPE: -5.737140623855634e-06\n",
            "E_IS_E_SCOPE: -5.632129087929118e-06\n",
            "Total Loss: 1.0593787624501974e-06\n",
            "----------------------------------------\n",
            "Epoch 9923\n",
            "Var loss:  tensor(1.0593e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.845172958579139e-06\n",
            "E_s_wdiff_all_sq: 2.645503504157926e-06\n",
            "E_IS_SCOPE: -5.742048677420226e-06\n",
            "E_IS_E_SCOPE: -5.636969195213511e-06\n",
            "Total Loss: 1.0593079135480388e-06\n",
            "----------------------------------------\n",
            "Epoch 9924\n",
            "Var loss:  tensor(1.0593e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.853644043408721e-06\n",
            "E_s_wdiff_all_sq: 2.654101069060702e-06\n",
            "E_IS_SCOPE: -5.740362977360621e-06\n",
            "E_IS_E_SCOPE: -5.635321841157058e-06\n",
            "Total Loss: 1.0592581254811484e-06\n",
            "----------------------------------------\n",
            "Epoch 9925\n",
            "Var loss:  tensor(1.0592e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.865214081467446e-06\n",
            "E_s_wdiff_all_sq: 2.6656994168741212e-06\n",
            "E_IS_SCOPE: -5.738367484235282e-06\n",
            "E_IS_E_SCOPE: -5.63332319807697e-06\n",
            "Total Loss: 1.0592235158169563e-06\n",
            "----------------------------------------\n",
            "Epoch 9926\n",
            "Var loss:  tensor(1.0592e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.837040909252116e-06\n",
            "E_s_wdiff_all_sq: 2.6375203982377044e-06\n",
            "E_IS_SCOPE: -5.742927577119927e-06\n",
            "E_IS_E_SCOPE: -5.637871524688151e-06\n",
            "Total Loss: 1.0592058296911148e-06\n",
            "----------------------------------------\n",
            "Epoch 9927\n",
            "Var loss:  tensor(1.0592e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.878357489285842e-06\n",
            "E_s_wdiff_all_sq: 2.6786669939589958e-06\n",
            "E_IS_SCOPE: -5.736434298871858e-06\n",
            "E_IS_E_SCOPE: -5.6312850705388815e-06\n",
            "Total Loss: 1.0591894622011484e-06\n",
            "----------------------------------------\n",
            "Epoch 9928\n",
            "Var loss:  tensor(1.0592e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.82527159866661e-06\n",
            "E_s_wdiff_all_sq: 2.625883858357445e-06\n",
            "E_IS_SCOPE: -5.744033999189029e-06\n",
            "E_IS_E_SCOPE: -5.639026411408581e-06\n",
            "Total Loss: 1.0591699882885243e-06\n",
            "----------------------------------------\n",
            "Epoch 9929\n",
            "Var loss:  tensor(1.0591e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.886331292338981e-06\n",
            "E_s_wdiff_all_sq: 2.686738122366644e-06\n",
            "E_IS_SCOPE: -5.7345738674909e-06\n",
            "E_IS_E_SCOPE: -5.6294514224096686e-06\n",
            "Total Loss: 1.0591457033501296e-06\n",
            "----------------------------------------\n",
            "Epoch 9930\n",
            "Var loss:  tensor(1.0591e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.816741884604484e-06\n",
            "E_s_wdiff_all_sq: 2.6169541522428793e-06\n",
            "E_IS_SCOPE: -5.745873437273162e-06\n",
            "E_IS_E_SCOPE: -5.640638642169838e-06\n",
            "Total Loss: 1.0591155656952126e-06\n",
            "----------------------------------------\n",
            "Epoch 9931\n",
            "Var loss:  tensor(1.0591e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.900752043235513e-06\n",
            "E_s_wdiff_all_sq: 2.7015968644263936e-06\n",
            "E_IS_SCOPE: -5.7320293185658385e-06\n",
            "E_IS_E_SCOPE: -5.6270904132517786e-06\n",
            "Total Loss: 1.0590747917212552e-06\n",
            "----------------------------------------\n",
            "Epoch 9932\n",
            "Var loss:  tensor(1.0590e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.831732513107844e-06\n",
            "E_s_wdiff_all_sq: 2.632364544773645e-06\n",
            "E_IS_SCOPE: -5.743854894154106e-06\n",
            "E_IS_E_SCOPE: -5.638785435681372e-06\n",
            "Total Loss: 1.0590264749289864e-06\n",
            "----------------------------------------\n",
            "Epoch 9933\n",
            "Var loss:  tensor(1.0590e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.8959702015626495e-06\n",
            "E_s_wdiff_all_sq: 2.6961499255638525e-06\n",
            "E_IS_SCOPE: -5.734637890316675e-06\n",
            "E_IS_E_SCOPE: -5.629320886090093e-06\n",
            "Total Loss: 1.0589836910858885e-06\n",
            "----------------------------------------\n",
            "Epoch 9934\n",
            "Var loss:  tensor(1.0589e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.841811344667338e-06\n",
            "E_s_wdiff_all_sq: 2.6428186801794307e-06\n",
            "E_IS_SCOPE: -5.741878093795679e-06\n",
            "E_IS_E_SCOPE: -5.636940255091353e-06\n",
            "Total Loss: 1.0589144106195103e-06\n",
            "----------------------------------------\n",
            "Epoch 9935\n",
            "Var loss:  tensor(1.0589e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.898030230006175e-06\n",
            "E_s_wdiff_all_sq: 2.6992003580616553e-06\n",
            "E_IS_SCOPE: -5.7325228048536626e-06\n",
            "E_IS_E_SCOPE: -5.6276409153763024e-06\n",
            "Total Loss: 1.0588635165300554e-06\n",
            "----------------------------------------\n",
            "Epoch 9936\n",
            "Var loss:  tensor(1.0588e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.835230507367798e-06\n",
            "E_s_wdiff_all_sq: 2.635732976444248e-06\n",
            "E_IS_SCOPE: -5.74328867059802e-06\n",
            "E_IS_E_SCOPE: -5.6380446161257e-06\n",
            "Total Loss: 1.0588068455191652e-06\n",
            "----------------------------------------\n",
            "Epoch 9937\n",
            "Var loss:  tensor(1.0587e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.883164815458951e-06\n",
            "E_s_wdiff_all_sq: 2.6838491912768386e-06\n",
            "E_IS_SCOPE: -5.735660314878495e-06\n",
            "E_IS_E_SCOPE: -5.630474899637421e-06\n",
            "Total Loss: 1.0587422172402205e-06\n",
            "----------------------------------------\n",
            "Epoch 9938\n",
            "Var loss:  tensor(1.0587e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.858791956664002e-06\n",
            "E_s_wdiff_all_sq: 2.6601536325444595e-06\n",
            "E_IS_SCOPE: -5.738983287174277e-06\n",
            "E_IS_E_SCOPE: -5.634110444352545e-06\n",
            "Total Loss: 1.058690062016334e-06\n",
            "----------------------------------------\n",
            "Epoch 9939\n",
            "Var loss:  tensor(1.0586e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.885077033201649e-06\n",
            "E_s_wdiff_all_sq: 2.6858881862718816e-06\n",
            "E_IS_SCOPE: -5.736152986632863e-06\n",
            "E_IS_E_SCOPE: -5.630976905282643e-06\n",
            "Total Loss: 1.0586341077695841e-06\n",
            "----------------------------------------\n",
            "Epoch 9940\n",
            "Var loss:  tensor(1.0586e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.861670503377598e-06\n",
            "E_s_wdiff_all_sq: 2.662346665941491e-06\n",
            "E_IS_SCOPE: -5.740289361474604e-06\n",
            "E_IS_E_SCOPE: -5.63502330214106e-06\n",
            "Total Loss: 1.0585891423092743e-06\n",
            "----------------------------------------\n",
            "Epoch 9941\n",
            "Var loss:  tensor(1.0585e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.885591225383785e-06\n",
            "E_s_wdiff_all_sq: 2.686908961918054e-06\n",
            "E_IS_SCOPE: -5.735399548514873e-06\n",
            "E_IS_E_SCOPE: -5.6304296108863174e-06\n",
            "Total Loss: 1.0585398117488756e-06\n",
            "----------------------------------------\n",
            "Epoch 9942\n",
            "Var loss:  tensor(1.0585e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.8718545447979936e-06\n",
            "E_s_wdiff_all_sq: 2.6731027720786256e-06\n",
            "E_IS_SCOPE: -5.737209320035634e-06\n",
            "E_IS_E_SCOPE: -5.6321791712066845e-06\n",
            "Total Loss: 1.0584888986017253e-06\n",
            "----------------------------------------\n",
            "Epoch 9943\n",
            "Var loss:  tensor(1.0584e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.867812423153443e-06\n",
            "E_s_wdiff_all_sq: 2.668746791545319e-06\n",
            "E_IS_SCOPE: -5.737724010433882e-06\n",
            "E_IS_E_SCOPE: -5.632516180060202e-06\n",
            "Total Loss: 1.0584473944010185e-06\n",
            "----------------------------------------\n",
            "Epoch 9944\n",
            "Var loss:  tensor(1.0584e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.87114390178223e-06\n",
            "E_s_wdiff_all_sq: 2.6724540553167875e-06\n",
            "E_IS_SCOPE: -5.7360779842123814e-06\n",
            "E_IS_E_SCOPE: -5.6310351763533776e-06\n",
            "Total Loss: 1.0584016542876903e-06\n",
            "----------------------------------------\n",
            "Epoch 9945\n",
            "Var loss:  tensor(1.0584e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.861918112830813e-06\n",
            "E_s_wdiff_all_sq: 2.663135914088526e-06\n",
            "E_IS_SCOPE: -5.737228430595885e-06\n",
            "E_IS_E_SCOPE: -5.632118991583055e-06\n",
            "Total Loss: 1.0583607442568824e-06\n",
            "----------------------------------------\n",
            "Epoch 9946\n",
            "Var loss:  tensor(1.0583e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.873207124267569e-06\n",
            "E_s_wdiff_all_sq: 2.67446020858507e-06\n",
            "E_IS_SCOPE: -5.735195152110435e-06\n",
            "E_IS_E_SCOPE: -5.630082388446646e-06\n",
            "Total Loss: 1.0583188118951764e-06\n",
            "----------------------------------------\n",
            "Epoch 9947\n",
            "Var loss:  tensor(1.0583e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.862259581729726e-06\n",
            "E_s_wdiff_all_sq: 2.6636736164261126e-06\n",
            "E_IS_SCOPE: -5.736650101506917e-06\n",
            "E_IS_E_SCOPE: -5.631596540960561e-06\n",
            "Total Loss: 1.058276267751157e-06\n",
            "----------------------------------------\n",
            "Epoch 9948\n",
            "Var loss:  tensor(1.0582e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.8793744107786145e-06\n",
            "E_s_wdiff_all_sq: 2.6806382392880112e-06\n",
            "E_IS_SCOPE: -5.7341804653982485e-06\n",
            "E_IS_E_SCOPE: -5.629030121688463e-06\n",
            "Total Loss: 1.0582329076112888e-06\n",
            "----------------------------------------\n",
            "Epoch 9949\n",
            "Var loss:  tensor(1.0582e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.860086395214738e-06\n",
            "E_s_wdiff_all_sq: 2.661354301084274e-06\n",
            "E_IS_SCOPE: -5.7373396004472205e-06\n",
            "E_IS_E_SCOPE: -5.632171878464282e-06\n",
            "Total Loss: 1.058194073704843e-06\n",
            "----------------------------------------\n",
            "Epoch 9950\n",
            "Var loss:  tensor(1.0582e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.884606732318066e-06\n",
            "E_s_wdiff_all_sq: 2.6861299235059703e-06\n",
            "E_IS_SCOPE: -5.732844029944969e-06\n",
            "E_IS_E_SCOPE: -5.627782873541735e-06\n",
            "Total Loss: 1.0581519195458827e-06\n",
            "----------------------------------------\n",
            "Epoch 9951\n",
            "Var loss:  tensor(1.0581e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.853114283382277e-06\n",
            "E_s_wdiff_all_sq: 2.6544757763887936e-06\n",
            "E_IS_SCOPE: -5.73737682081229e-06\n",
            "E_IS_E_SCOPE: -5.632212745396405e-06\n",
            "Total Loss: 1.0581077797019684e-06\n",
            "----------------------------------------\n",
            "Epoch 9952\n",
            "Var loss:  tensor(1.0581e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.877370508668526e-06\n",
            "E_s_wdiff_all_sq: 2.678856151362264e-06\n",
            "E_IS_SCOPE: -5.732744848164771e-06\n",
            "E_IS_E_SCOPE: -5.627622057713042e-06\n",
            "Total Loss: 1.0580661999430594e-06\n",
            "----------------------------------------\n",
            "Epoch 9953\n",
            "Var loss:  tensor(1.0580e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.848536528922923e-06\n",
            "E_s_wdiff_all_sq: 2.6502982842010238e-06\n",
            "E_IS_SCOPE: -5.73638262463931e-06\n",
            "E_IS_E_SCOPE: -5.631378816126012e-06\n",
            "Total Loss: 1.0580280512355574e-06\n",
            "----------------------------------------\n",
            "Epoch 9954\n",
            "Var loss:  tensor(1.0580e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.8723885920323055e-06\n",
            "E_s_wdiff_all_sq: 2.6737416817251833e-06\n",
            "E_IS_SCOPE: -5.732806481270216e-06\n",
            "E_IS_E_SCOPE: -5.627578981066626e-06\n",
            "Total Loss: 1.057989333440198e-06\n",
            "----------------------------------------\n",
            "Epoch 9955\n",
            "Var loss:  tensor(1.0579e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.8422174094435575e-06\n",
            "E_s_wdiff_all_sq: 2.6438937830901584e-06\n",
            "E_IS_SCOPE: -5.736838960842703e-06\n",
            "E_IS_E_SCOPE: -5.631751086135336e-06\n",
            "Total Loss: 1.0579453004789218e-06\n",
            "----------------------------------------\n",
            "Epoch 9956\n",
            "Var loss:  tensor(1.0579e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.880866017827628e-06\n",
            "E_s_wdiff_all_sq: 2.68270690528171e-06\n",
            "E_IS_SCOPE: -5.730341771361615e-06\n",
            "E_IS_E_SCOPE: -5.625317076092317e-06\n",
            "Total Loss: 1.0579071455475768e-06\n",
            "----------------------------------------\n",
            "Epoch 9957\n",
            "Var loss:  tensor(1.0579e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.839000166984695e-06\n",
            "E_s_wdiff_all_sq: 2.6406666725179935e-06\n",
            "E_IS_SCOPE: -5.736894285265839e-06\n",
            "E_IS_E_SCOPE: -5.631762699431283e-06\n",
            "Total Loss: 1.0578677463378456e-06\n",
            "----------------------------------------\n",
            "Epoch 9958\n",
            "Var loss:  tensor(1.0578e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.877163073213863e-06\n",
            "E_s_wdiff_all_sq: 2.6786969094716843e-06\n",
            "E_IS_SCOPE: -5.730547178887561e-06\n",
            "E_IS_E_SCOPE: -5.625330321099765e-06\n",
            "Total Loss: 1.0578298717068417e-06\n",
            "----------------------------------------\n",
            "Epoch 9959\n",
            "Var loss:  tensor(1.0578e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.833826351395468e-06\n",
            "E_s_wdiff_all_sq: 2.635680268137865e-06\n",
            "E_IS_SCOPE: -5.736421013129063e-06\n",
            "E_IS_E_SCOPE: -5.631346079364762e-06\n",
            "Total Loss: 1.0577936392692563e-06\n",
            "----------------------------------------\n",
            "Epoch 9960\n",
            "Var loss:  tensor(1.0578e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.8811726886758826e-06\n",
            "E_s_wdiff_all_sq: 2.6829323523577035e-06\n",
            "E_IS_SCOPE: -5.728784727781492e-06\n",
            "E_IS_E_SCOPE: -5.623646008202814e-06\n",
            "Total Loss: 1.0577603207010785e-06\n",
            "----------------------------------------\n",
            "Epoch 9961\n",
            "Var loss:  tensor(1.0577e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.825068252351952e-06\n",
            "E_s_wdiff_all_sq: 2.626699828728922e-06\n",
            "E_IS_SCOPE: -5.7377459086724385e-06\n",
            "E_IS_E_SCOPE: -5.632528004167281e-06\n",
            "Total Loss: 1.0577300381529703e-06\n",
            "----------------------------------------\n",
            "Epoch 9962\n",
            "Var loss:  tensor(1.0577e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.889780376545751e-06\n",
            "E_s_wdiff_all_sq: 2.691738271319378e-06\n",
            "E_IS_SCOPE: -5.726987911201125e-06\n",
            "E_IS_E_SCOPE: -5.621917698884957e-06\n",
            "Total Loss: 1.0576991041342935e-06\n",
            "----------------------------------------\n",
            "Epoch 9963\n",
            "Var loss:  tensor(1.0577e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.824387576418327e-06\n",
            "E_s_wdiff_all_sq: 2.6263760435316457e-06\n",
            "E_IS_SCOPE: -5.737286677318445e-06\n",
            "E_IS_E_SCOPE: -5.632219452737134e-06\n",
            "Total Loss: 1.0576745072643133e-06\n",
            "----------------------------------------\n",
            "Epoch 9964\n",
            "Var loss:  tensor(1.0577e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.898412687233832e-06\n",
            "E_s_wdiff_all_sq: 2.7002452755153438e-06\n",
            "E_IS_SCOPE: -5.725853070472191e-06\n",
            "E_IS_E_SCOPE: -5.620699422962883e-06\n",
            "Total Loss: 1.057657540240128e-06\n",
            "----------------------------------------\n",
            "Epoch 9965\n",
            "Var loss:  tensor(1.0576e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.815600662886559e-06\n",
            "E_s_wdiff_all_sq: 2.617575382118044e-06\n",
            "E_IS_SCOPE: -5.7384241582160296e-06\n",
            "E_IS_E_SCOPE: -5.633337084581377e-06\n",
            "Total Loss: 1.0576485570394663e-06\n",
            "----------------------------------------\n",
            "Epoch 9966\n",
            "Var loss:  tensor(1.0577e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.908061821515231e-06\n",
            "E_s_wdiff_all_sq: 2.710040878423264e-06\n",
            "E_IS_SCOPE: -5.723421531127794e-06\n",
            "E_IS_E_SCOPE: -5.618338951132322e-06\n",
            "Total Loss: 1.0576532066412788e-06\n",
            "----------------------------------------\n",
            "Epoch 9967\n",
            "Var loss:  tensor(1.0577e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.7980073371808713e-06\n",
            "E_s_wdiff_all_sq: 2.5998034140484846e-06\n",
            "E_IS_SCOPE: -5.740792693222939e-06\n",
            "E_IS_E_SCOPE: -5.635628324407033e-06\n",
            "Total Loss: 1.05767260904083e-06\n",
            "----------------------------------------\n",
            "Epoch 9968\n",
            "Var loss:  tensor(1.0577e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.919710003372472e-06\n",
            "E_s_wdiff_all_sq: 2.7214532474047357e-06\n",
            "E_IS_SCOPE: -5.72142303273403e-06\n",
            "E_IS_E_SCOPE: -5.616252350970195e-06\n",
            "Total Loss: 1.0577128159803217e-06\n",
            "----------------------------------------\n",
            "Epoch 9969\n",
            "Var loss:  tensor(1.0578e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.785127409252414e-06\n",
            "E_s_wdiff_all_sq: 2.58702993781115e-06\n",
            "E_IS_SCOPE: -5.742293720146432e-06\n",
            "E_IS_E_SCOPE: -5.6372369485473965e-06\n",
            "Total Loss: 1.0577813517834492e-06\n",
            "----------------------------------------\n",
            "Epoch 9970\n",
            "Var loss:  tensor(1.0579e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.941267030502321e-06\n",
            "E_s_wdiff_all_sq: 2.7427330016016477e-06\n",
            "E_IS_SCOPE: -5.718006965490738e-06\n",
            "E_IS_E_SCOPE: -5.6127853493283235e-06\n",
            "Total Loss: 1.0578882201161004e-06\n",
            "----------------------------------------\n",
            "Epoch 9971\n",
            "Var loss:  tensor(1.0580e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.761070632751129e-06\n",
            "E_s_wdiff_all_sq: 2.562591736826585e-06\n",
            "E_IS_SCOPE: -5.745943005686361e-06\n",
            "E_IS_E_SCOPE: -5.6408275298853905e-06\n",
            "Total Loss: 1.0580453678628587e-06\n",
            "----------------------------------------\n",
            "Epoch 9972\n",
            "Var loss:  tensor(1.0583e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.973384297725041e-06\n",
            "E_s_wdiff_all_sq: 2.7747431755902247e-06\n",
            "E_IS_SCOPE: -5.712171170194945e-06\n",
            "E_IS_E_SCOPE: -5.607086948900093e-06\n",
            "Total Loss: 1.0582701030853684e-06\n",
            "----------------------------------------\n",
            "Epoch 9973\n",
            "Var loss:  tensor(1.0586e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.7287034355541745e-06\n",
            "E_s_wdiff_all_sq: 2.529574516799038e-06\n",
            "E_IS_SCOPE: -5.750772578535793e-06\n",
            "E_IS_E_SCOPE: -5.645600428123695e-06\n",
            "Total Loss: 1.0585820414711958e-06\n",
            "----------------------------------------\n",
            "Epoch 9974\n",
            "Var loss:  tensor(1.0590e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 4.006012241345335e-06\n",
            "E_s_wdiff_all_sq: 2.80646791352652e-06\n",
            "E_IS_SCOPE: -5.706625316534984e-06\n",
            "E_IS_E_SCOPE: -5.601454392183693e-06\n",
            "Total Loss: 1.058999902656488e-06\n",
            "----------------------------------------\n",
            "Epoch 9975\n",
            "Var loss:  tensor(1.0595e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.6888894225170796e-06\n",
            "E_s_wdiff_all_sq: 2.4889294960961745e-06\n",
            "E_IS_SCOPE: -5.7562941349125445e-06\n",
            "E_IS_E_SCOPE: -5.651185645912707e-06\n",
            "Total Loss: 1.059540371961486e-06\n",
            "----------------------------------------\n",
            "Epoch 9976\n",
            "Var loss:  tensor(1.0602e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 4.050807689515576e-06\n",
            "E_s_wdiff_all_sq: 2.850021019853874e-06\n",
            "E_IS_SCOPE: -5.6992750208165925e-06\n",
            "E_IS_E_SCOPE: -5.594095794446925e-06\n",
            "Total Loss: 1.060225640462623e-06\n",
            "----------------------------------------\n",
            "Epoch 9977\n",
            "Var loss:  tensor(1.0610e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.6462096165645564e-06\n",
            "E_s_wdiff_all_sq: 2.444724058153297e-06\n",
            "E_IS_SCOPE: -5.763250869507011e-06\n",
            "E_IS_E_SCOPE: -5.658134239023355e-06\n",
            "Total Loss: 1.061049720984202e-06\n",
            "----------------------------------------\n",
            "Epoch 9978\n",
            "Var loss:  tensor(1.0620e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 4.109200219427245e-06\n",
            "E_s_wdiff_all_sq: 2.9067589917508526e-06\n",
            "E_IS_SCOPE: -5.690709876954115e-06\n",
            "E_IS_E_SCOPE: -5.585572762263587e-06\n",
            "Total Loss: 1.0619644218355914e-06\n",
            "----------------------------------------\n",
            "Epoch 9979\n",
            "Var loss:  tensor(1.0629e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.6078118060442713e-06\n",
            "E_s_wdiff_all_sq: 2.4044964385860087e-06\n",
            "E_IS_SCOPE: -5.770085377859615e-06\n",
            "E_IS_E_SCOPE: -5.664964507320652e-06\n",
            "Total Loss: 1.0628710499205939e-06\n",
            "----------------------------------------\n",
            "Epoch 9980\n",
            "Var loss:  tensor(1.0636e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 4.147209766516293e-06\n",
            "E_s_wdiff_all_sq: 2.94306955325488e-06\n",
            "E_IS_SCOPE: -5.6846269684951375e-06\n",
            "E_IS_E_SCOPE: -5.579443619079838e-06\n",
            "Total Loss: 1.0635709379710697e-06\n",
            "----------------------------------------\n",
            "Epoch 9981\n",
            "Var loss:  tensor(1.0638e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.5834158367350363e-06\n",
            "E_s_wdiff_all_sq: 2.379232219127618e-06\n",
            "E_IS_SCOPE: -5.772888092509082e-06\n",
            "E_IS_E_SCOPE: -5.66781362800534e-06\n",
            "Total Loss: 1.0638321121401906e-06\n",
            "----------------------------------------\n",
            "Epoch 9982\n",
            "Var loss:  tensor(1.0634e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 4.138757859966671e-06\n",
            "E_s_wdiff_all_sq: 2.9346345816368796e-06\n",
            "E_IS_SCOPE: -5.685019682955815e-06\n",
            "E_IS_E_SCOPE: -5.579777748346253e-06\n",
            "Total Loss: 1.0634368326509241e-06\n",
            "----------------------------------------\n",
            "Epoch 9983\n",
            "Var loss:  tensor(1.0623e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.608220979811007e-06\n",
            "E_s_wdiff_all_sq: 2.405498426037189e-06\n",
            "E_IS_SCOPE: -5.767950702926708e-06\n",
            "E_IS_E_SCOPE: -5.662848654390354e-06\n",
            "Total Loss: 1.0623158802413654e-06\n",
            "----------------------------------------\n",
            "Epoch 9984\n",
            "Var loss:  tensor(1.0607e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 4.073091484758638e-06\n",
            "E_s_wdiff_all_sq: 2.8718806190647024e-06\n",
            "E_IS_SCOPE: -5.69410739160234e-06\n",
            "E_IS_E_SCOPE: -5.5889295848946495e-06\n",
            "Total Loss: 1.0606526758188105e-06\n",
            "----------------------------------------\n",
            "Epoch 9985\n",
            "Var loss:  tensor(1.0589e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.6984404520756187e-06\n",
            "E_s_wdiff_all_sq: 2.499277420120224e-06\n",
            "E_IS_SCOPE: -5.752328987370821e-06\n",
            "E_IS_E_SCOPE: -5.6472774509027985e-06\n",
            "Total Loss: 1.0588573825596054e-06\n",
            "----------------------------------------\n",
            "Epoch 9986\n",
            "Var loss:  tensor(1.0574e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.949994567888996e-06\n",
            "E_s_wdiff_all_sq: 2.7518954528553537e-06\n",
            "E_IS_SCOPE: -5.712459787109577e-06\n",
            "E_IS_E_SCOPE: -5.607212210530595e-06\n",
            "Total Loss: 1.0574013854159348e-06\n",
            "----------------------------------------\n",
            "Epoch 9987\n",
            "Var loss:  tensor(1.0566e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.82135137372686e-06\n",
            "E_s_wdiff_all_sq: 2.62424348167593e-06\n",
            "E_IS_SCOPE: -5.732071312730444e-06\n",
            "E_IS_E_SCOPE: -5.62692666554265e-06\n",
            "Total Loss: 1.056616021215598e-06\n",
            "----------------------------------------\n",
            "Epoch 9988\n",
            "Var loss:  tensor(1.0566e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.823766905010393e-06\n",
            "E_s_wdiff_all_sq: 2.626640819210683e-06\n",
            "E_IS_SCOPE: -5.73170187046837e-06\n",
            "E_IS_E_SCOPE: -5.626518848193401e-06\n",
            "Total Loss: 1.0565574647900285e-06\n",
            "----------------------------------------\n",
            "Epoch 9989\n",
            "Var loss:  tensor(1.0570e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.934061816546236e-06\n",
            "E_s_wdiff_all_sq: 2.736406483483081e-06\n",
            "E_IS_SCOPE: -5.714000076014139e-06\n",
            "E_IS_E_SCOPE: -5.608789163118767e-06\n",
            "Total Loss: 1.0570309308126658e-06\n",
            "----------------------------------------\n",
            "Epoch 9990\n",
            "Var loss:  tensor(1.0577e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.728712775116077e-06\n",
            "E_s_wdiff_all_sq: 2.5305141802670275e-06\n",
            "E_IS_SCOPE: -5.745940834299032e-06\n",
            "E_IS_E_SCOPE: -5.640802684811368e-06\n",
            "Total Loss: 1.0577197194139769e-06\n",
            "----------------------------------------\n",
            "Epoch 9991\n",
            "Var loss:  tensor(1.0583e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.99859330008773e-06\n",
            "E_s_wdiff_all_sq: 2.7996284754095014e-06\n",
            "E_IS_SCOPE: -5.703388910607347e-06\n",
            "E_IS_E_SCOPE: -5.598151043729998e-06\n",
            "Total Loss: 1.0582865144637854e-06\n",
            "----------------------------------------\n",
            "Epoch 9992\n",
            "Var loss:  tensor(1.0585e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.695364655092816e-06\n",
            "E_s_wdiff_all_sq: 2.496385937205639e-06\n",
            "E_IS_SCOPE: -5.751015857462708e-06\n",
            "E_IS_E_SCOPE: -5.6458764330042165e-06\n",
            "Total Loss: 1.0584972925104509e-06\n",
            "----------------------------------------\n",
            "Epoch 9993\n",
            "Var loss:  tensor(1.0583e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 4.00890458691938e-06\n",
            "E_s_wdiff_all_sq: 2.8102044002072042e-06\n",
            "E_IS_SCOPE: -5.701282910685858e-06\n",
            "E_IS_E_SCOPE: -5.59617854886753e-06\n",
            "Total Loss: 1.0582888866157754e-06\n",
            "----------------------------------------\n",
            "Epoch 9994\n",
            "Var loss:  tensor(1.0577e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.720456169519537e-06\n",
            "E_s_wdiff_all_sq: 2.522092384458969e-06\n",
            "E_IS_SCOPE: -5.746760405283331e-06\n",
            "E_IS_E_SCOPE: -5.6415505490240206e-06\n",
            "Total Loss: 1.057741496082203e-06\n",
            "----------------------------------------\n",
            "Epoch 9995\n",
            "Var loss:  tensor(1.0571e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.950537230593134e-06\n",
            "E_s_wdiff_all_sq: 2.752860135531771e-06\n",
            "E_IS_SCOPE: -5.709589943274671e-06\n",
            "E_IS_E_SCOPE: -5.604381593263799e-06\n",
            "Total Loss: 1.057057818579875e-06\n",
            "----------------------------------------\n",
            "Epoch 9996\n",
            "Var loss:  tensor(1.0565e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.788824244550243e-06\n",
            "E_s_wdiff_all_sq: 2.5919983414464513e-06\n",
            "E_IS_SCOPE: -5.734092729417496e-06\n",
            "E_IS_E_SCOPE: -5.629017124676901e-06\n",
            "Total Loss: 1.0564721171628577e-06\n",
            "----------------------------------------\n",
            "Epoch 9997\n",
            "Var loss:  tensor(1.0561e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.866269639556846e-06\n",
            "E_s_wdiff_all_sq: 2.6695826219705005e-06\n",
            "E_IS_SCOPE: -5.721405122152921e-06\n",
            "E_IS_E_SCOPE: -5.616230118694677e-06\n",
            "Total Loss: 1.0561344342101121e-06\n",
            "----------------------------------------\n",
            "Epoch 9998\n",
            "Var loss:  tensor(1.0561e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.859640229671094e-06\n",
            "E_s_wdiff_all_sq: 2.662827925168569e-06\n",
            "E_IS_SCOPE: -5.722231717834596e-06\n",
            "E_IS_E_SCOPE: -5.616968242087895e-06\n",
            "Total Loss: 1.0560827765493794e-06\n",
            "----------------------------------------\n",
            "Epoch 9999\n",
            "Var loss:  tensor(1.0562e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.793758664972749e-06\n",
            "E_s_wdiff_all_sq: 2.597095966835473e-06\n",
            "E_IS_SCOPE: -5.731887853271098e-06\n",
            "E_IS_E_SCOPE: -5.626777681584121e-06\n",
            "Total Loss: 1.0562397783035764e-06\n",
            "----------------------------------------\n",
            "Epoch 10000\n",
            "Var loss:  tensor(1.0565e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.49205552828799e-07\n",
            "E_IS_all_sq: 2.7940812928854376e-07\n",
            "E_s_wdiff_sq: 3.919439956329745e-06\n",
            "E_s_wdiff_all_sq: 2.7224487112947596e-06\n",
            "E_IS_SCOPE: -5.711948511093659e-06\n",
            "E_IS_E_SCOPE: -5.606791759546804e-06\n",
            "Total Loss: 1.0564751654815319e-06\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[-0.2872,  0.1149],\n",
            "        [-0.6451, -0.4023],\n",
            "        [-0.4156,  0.3997],\n",
            "        [-0.1697, -0.3042],\n",
            "        [-0.4606, -0.4015],\n",
            "        [-0.3087,  0.2917],\n",
            "        [-0.4615, -0.1523],\n",
            "        [-0.3690,  0.5015],\n",
            "        [-0.2806, -0.4794],\n",
            "        [-0.2019, -0.0516],\n",
            "        [ 0.5572,  0.2897],\n",
            "        [ 1.1280, -0.4642],\n",
            "        [-0.0493, -0.6923],\n",
            "        [-0.3638,  0.3389],\n",
            "        [ 0.2282,  0.3819],\n",
            "        [-0.2326,  0.2042]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([ 0.5883, -0.6385, -0.3188,  0.2629, -0.4104,  0.6669,  0.6100,  0.0834,\n",
            "        -0.5882, -0.0103, -0.4307,  0.1607, -0.1526, -0.2209,  0.3870, -0.3857],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[ 1.6510e-01,  7.6330e-02,  1.8990e-01,  1.4859e-01, -8.6881e-02,\n",
            "          8.1918e-02, -5.8520e-03,  1.0580e-01,  2.1541e-01,  1.4687e-02,\n",
            "          9.4842e-02, -5.7339e-01, -9.0246e-02, -7.3798e-02,  1.9376e-01,\n",
            "          2.4263e-03],\n",
            "        [ 1.3689e-03, -1.0703e-01,  8.8128e-02, -6.3849e-02, -5.3713e-02,\n",
            "          2.6552e-02,  2.5267e-02, -1.0048e-01,  1.6108e-01, -1.5711e-01,\n",
            "          3.2009e-01,  4.5637e-01,  1.3483e-01, -2.4500e-01, -1.6303e-01,\n",
            "         -2.2419e-01],\n",
            "        [ 4.0875e-02, -1.5309e-01,  6.3589e-02,  1.6029e-01,  5.3916e-02,\n",
            "         -1.0947e-01,  1.0576e-01,  1.7822e-01,  1.7326e-01,  1.5991e-01,\n",
            "          1.1133e-01, -3.2512e-01,  7.5838e-02, -2.3609e-01,  1.5797e-01,\n",
            "          1.2736e-01],\n",
            "        [-1.1877e-01, -9.7579e-02, -3.5960e-03, -1.1006e-01,  1.9412e-01,\n",
            "          1.2628e-01,  3.0825e-01, -2.2731e-02, -1.1483e-02,  4.6827e-02,\n",
            "         -4.8820e-02, -2.4399e-02,  1.1707e-01,  2.0005e-01, -4.3770e-01,\n",
            "         -2.1171e-01],\n",
            "        [-8.9957e-02, -2.1186e-01,  1.0771e-01,  9.1112e-02,  1.5293e-01,\n",
            "          3.2999e-02,  2.1350e-01,  1.3975e-01, -9.6390e-02,  2.3548e-01,\n",
            "         -4.5987e-02, -1.9365e-01, -2.7147e-02, -1.8367e-01, -1.3774e-01,\n",
            "         -7.9707e-02],\n",
            "        [-2.3836e-01, -5.2126e-02, -2.3808e-01,  1.3283e-01,  2.0711e-01,\n",
            "         -1.1476e-01,  1.6267e-01, -9.3714e-02,  1.5447e-02,  2.5722e-02,\n",
            "         -6.3762e-02, -1.3430e-01, -1.0549e-01,  1.2067e-01, -1.1995e-01,\n",
            "         -3.2316e-02],\n",
            "        [-2.8480e-01,  8.8274e-04,  6.9881e-02, -2.4176e-01, -1.6407e-01,\n",
            "          1.5884e-01,  1.1782e-01, -1.5996e-01, -3.9814e-02, -1.9913e-01,\n",
            "          1.2880e-01, -2.6152e-01, -2.1390e-01, -1.8887e-01, -1.5257e-01,\n",
            "         -2.7611e-01],\n",
            "        [-3.2898e-02, -1.1633e-01,  1.1776e-01,  1.9255e-01,  1.6966e-01,\n",
            "          2.2105e-01, -1.6796e-01,  1.8948e-01, -2.1185e-01,  6.7899e-02,\n",
            "          1.5331e-01, -1.3869e-02,  1.0879e-01, -3.2773e-03, -1.3764e-01,\n",
            "         -1.1974e-01],\n",
            "        [-7.2775e-03,  1.3517e-01, -8.7017e-02,  1.9151e-02,  1.7796e-01,\n",
            "          1.6520e-01,  1.2217e-01, -1.9399e-02, -6.6721e-02, -1.7592e-03,\n",
            "         -5.5942e-01, -3.2027e-01, -9.9305e-02, -9.6100e-02, -6.0698e-02,\n",
            "         -8.1558e-01],\n",
            "        [-1.5942e-01,  1.1624e-01, -5.9306e-02,  1.7153e-01,  1.4553e-01,\n",
            "          1.7453e-01,  1.5181e-01, -2.0114e-01,  2.0408e-01, -1.2711e-02,\n",
            "          1.4488e-01,  2.4686e-01, -2.4814e-02,  5.3637e-02,  7.5080e-02,\n",
            "         -1.0119e-01],\n",
            "        [-1.7510e-01, -1.4826e-01,  2.2683e-01,  1.9243e-02, -7.4912e-02,\n",
            "         -1.1920e-01, -2.1158e-01,  8.9656e-02,  1.0793e-01, -1.2665e-01,\n",
            "         -2.3003e-01,  1.0339e+00,  2.0642e-01, -1.6895e-02,  1.3090e-01,\n",
            "          3.1511e-02],\n",
            "        [ 2.3667e-02, -5.1742e-03,  1.2283e-01, -8.2360e-02, -1.3475e-02,\n",
            "          1.1166e-01,  5.3694e-01, -1.7928e-01, -4.9028e-02,  2.4708e-01,\n",
            "         -5.2685e-02,  1.9866e-02,  8.3677e-02,  8.8102e-02,  9.4187e-03,\n",
            "         -1.5623e-01],\n",
            "        [-3.6603e-02, -1.3139e-01, -1.7378e-01, -1.4787e-01,  1.6670e-01,\n",
            "          2.1459e-01, -3.3040e-01,  7.8321e-02, -2.2207e-01, -1.8789e-02,\n",
            "         -1.4093e-01, -6.7800e-02,  1.9634e-01, -8.9612e-02, -9.0589e-02,\n",
            "         -1.0200e-01],\n",
            "        [-2.7392e-01,  1.5616e-01, -1.4750e-02, -8.0517e-03,  1.3448e-01,\n",
            "         -1.7662e-01, -2.0802e-01,  6.0013e-02,  1.8590e-01, -1.5933e-02,\n",
            "          1.1683e-01, -2.9586e-01, -2.1508e-01, -1.4860e-01,  1.9701e-01,\n",
            "         -9.8508e-02],\n",
            "        [-1.6417e-01,  4.3002e-02,  2.1925e-01,  8.2336e-02,  1.7426e-01,\n",
            "         -2.6368e-01,  8.8824e-02,  8.9334e-02, -3.3743e-02, -9.2787e-02,\n",
            "          1.9128e-01,  3.2979e-01,  8.3215e-02, -2.5015e-01,  6.7271e-02,\n",
            "         -2.7263e-01],\n",
            "        [ 1.1384e-01, -9.9779e-02, -1.6548e-01, -1.8391e-01, -1.1907e-01,\n",
            "         -8.9996e-02, -3.2240e-02,  1.7304e-01, -2.4521e-01,  1.2691e-01,\n",
            "          1.7820e-03, -1.1258e-01,  4.0477e-02,  1.7015e-01, -7.0563e-02,\n",
            "          1.6398e-01],\n",
            "        [ 3.5054e-02,  8.8668e-02, -8.4191e-02,  2.2034e-01, -6.2513e-02,\n",
            "         -8.3795e-03,  6.3808e-02, -2.1227e-01, -1.5115e-01,  7.6012e-02,\n",
            "         -3.3715e-02,  2.4672e-03, -2.9804e-02,  5.6579e-02, -2.4846e-01,\n",
            "         -1.1329e-01],\n",
            "        [ 1.5860e-01,  2.2160e-01,  1.9055e-02, -8.8225e-02,  1.6626e-01,\n",
            "          1.7373e-01, -3.7396e-01, -2.0336e-01,  1.4658e-01, -2.3671e-01,\n",
            "         -3.9551e-02,  1.9500e-02,  1.7614e-01,  4.4266e-02,  7.7087e-03,\n",
            "         -2.1965e-01],\n",
            "        [-5.6538e-04,  2.1446e-01, -7.7190e-02,  1.3884e-01, -1.2873e-01,\n",
            "          1.2621e-02, -6.1766e-02,  8.9176e-02,  1.2391e-01, -1.7978e-01,\n",
            "         -2.1960e-01, -1.1680e-01, -3.7810e-02,  5.5836e-02,  1.1315e-01,\n",
            "         -5.5512e-02],\n",
            "        [-2.2858e-01,  2.2273e-01,  1.5435e-01, -2.0077e-01, -1.3076e-01,\n",
            "         -1.3356e-01,  6.1782e-02,  4.0735e-03,  2.2420e-01,  3.3224e-02,\n",
            "         -1.4512e-01, -3.1802e-02, -1.3391e-01,  1.3501e-01,  5.1470e-02,\n",
            "         -1.2334e-01],\n",
            "        [ 3.2975e-01,  1.4322e-01, -2.9666e-01,  1.4632e-01,  2.0465e-01,\n",
            "          1.3821e-01, -1.8792e-01, -1.0431e-01,  1.0907e-01,  2.1412e-01,\n",
            "         -2.7480e-02,  3.0841e-01, -2.2952e-01, -8.2469e-01, -3.0878e-01,\n",
            "         -2.0047e-02],\n",
            "        [-2.1003e-01, -1.8413e-01,  4.0177e-02,  2.1898e-02, -1.7271e-01,\n",
            "         -2.3834e-01,  1.0809e-01,  1.2278e-01,  7.8494e-02,  1.8792e-01,\n",
            "          7.1322e-02, -8.3794e-02, -9.2322e-02, -2.4939e-01, -7.2016e-02,\n",
            "          3.5499e-01],\n",
            "        [ 1.5597e-01, -2.4938e-01,  2.0718e-02,  2.0787e-01, -2.4195e-01,\n",
            "          8.7608e-02, -1.6843e-01, -1.5340e-01,  7.6705e-02,  2.5913e-02,\n",
            "         -8.6986e-02,  2.9173e-01,  2.3788e-01, -2.5869e-01,  1.8549e-01,\n",
            "         -1.0747e-01],\n",
            "        [ 1.3736e-01, -1.6633e-01, -2.6794e-01,  2.2076e-01, -5.6276e-03,\n",
            "         -2.2342e-01, -6.9837e-02,  2.3895e-01, -1.9251e-01, -1.6566e-01,\n",
            "          2.0480e-01, -8.2115e-02, -2.2928e-01, -4.9863e-01, -5.9977e-02,\n",
            "         -2.4840e-01],\n",
            "        [-1.0031e-02,  8.5472e-02,  2.1358e-01,  1.0683e-01,  1.5720e-01,\n",
            "         -2.1047e-01, -3.9220e-01,  1.3857e-01,  2.9344e-02,  2.2748e-01,\n",
            "          6.9066e-02,  2.0122e-01, -1.9366e-01, -2.3551e-01,  1.0997e-01,\n",
            "         -2.3496e-01],\n",
            "        [-5.3314e-01, -1.2964e-01,  4.8522e-02, -1.3298e-01, -2.9042e-02,\n",
            "         -2.6010e-02, -1.2246e-02, -9.4174e-02, -4.6521e-02,  4.6327e-02,\n",
            "          1.6455e-01, -1.1113e-01, -1.7407e-01,  2.6567e-02, -4.4896e-01,\n",
            "         -1.7333e-01],\n",
            "        [ 4.3176e-02,  2.3982e-01,  8.7702e-02,  5.0481e-02, -2.3167e-01,\n",
            "          7.4377e-02, -4.3711e-01,  4.2143e-03, -6.0900e-02,  8.4708e-02,\n",
            "         -1.1983e-01, -2.2262e-02,  1.6405e-01, -9.4936e-02, -1.2218e-01,\n",
            "          1.7691e-01],\n",
            "        [-4.8219e-01, -1.0058e-01,  1.9494e-01,  1.8444e-01,  3.0213e-03,\n",
            "          6.6613e-02,  2.0011e-01, -7.7243e-01, -1.5634e-01, -1.3472e-01,\n",
            "         -3.6840e-02, -9.1976e-02,  5.4565e-03, -1.0434e-01, -2.1016e-02,\n",
            "         -2.0413e-01],\n",
            "        [-1.9317e-01,  1.3955e-02,  9.2184e-02,  1.4414e-01, -9.0372e-02,\n",
            "          3.6247e-02,  2.5508e-01,  6.5692e-02,  1.8715e-01,  1.7958e-01,\n",
            "         -3.0237e-02,  3.7455e-01,  1.0294e-01, -2.2419e-02, -2.6805e-02,\n",
            "         -8.4471e-03],\n",
            "        [-1.0272e-01,  6.2806e-02,  1.4934e-01, -2.1119e-02,  4.5962e-02,\n",
            "          1.4171e-01,  1.9559e-01, -1.2942e-02, -1.3294e-01, -2.1621e-01,\n",
            "         -1.3951e-01,  5.8165e-01, -2.0447e-01, -2.0497e-01,  1.1925e-01,\n",
            "          1.3123e-01],\n",
            "        [-2.0973e-02,  3.4482e-02,  4.9605e-02, -2.0167e-01, -2.3637e-01,\n",
            "         -2.3487e-01, -1.4091e-01, -1.9641e-01,  4.7760e-02,  1.2048e-01,\n",
            "          1.5118e-01, -1.3902e-01, -1.6583e-01, -8.4249e-02,  1.8319e-01,\n",
            "         -9.5421e-02],\n",
            "        [ 1.0138e-01,  2.7709e-03,  1.7794e-01, -3.5709e-02, -8.6351e-02,\n",
            "          3.2371e-02,  7.7450e-02,  6.2336e-02, -6.5540e-02, -1.8380e-01,\n",
            "         -7.5722e-02,  2.9852e-01,  1.3593e-01, -2.1230e-01,  1.5437e-02,\n",
            "         -2.2573e-01]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([ 0.0174, -0.0584, -0.0511, -0.0435,  0.0258, -0.2109,  0.2108, -0.1102,\n",
            "         0.1053,  0.1853, -0.1866, -0.0381,  0.0759,  0.0838,  0.0863,  0.0116,\n",
            "        -0.2039, -0.1485, -0.2361,  0.0332,  0.0262,  0.1502, -0.0507, -0.1415,\n",
            "        -0.0290,  0.1694,  0.2171,  0.3762,  0.0254,  0.1233, -0.0098,  0.0728],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[ 0.0088, -0.1970, -0.0005, -0.1528, -0.1012, -0.1677,  0.2812,  0.0051,\n",
            "         -0.3622, -0.0605, -0.1012,  0.0661,  0.0530,  0.0530, -0.0133,  0.0067,\n",
            "          0.1050,  0.0452,  0.0294,  0.0906,  0.3587,  0.0826,  0.0271, -0.1440,\n",
            "         -0.0144,  0.2492,  0.0618, -0.1751,  0.0392, -0.0104,  0.0300,  0.0622]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([-0.0133], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 400 Trajectories"
      ],
      "metadata": {
        "id": "yPC_HXwnofdg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "400 Trajectories:"
      ],
      "metadata": {
        "id": "Scyb9IqfnsrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b = action_probs_top_n_epsilon(q_table, 1, 0.4)\n",
        "pi_b = experiment_actions(400, env, P_pi_b)\n",
        "P_pi_e = action_probs_top_n_epsilon(q_table, 2, 0.05)\n",
        "pi_e = experiment_actions(400, env, P_pi_e)"
      ],
      "metadata": {
        "id": "doNhEhzfn1gg"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_400 = CustomizableFeatureNet(input_dim=2, hidden_dims=[16, 32], output_dim=1, dtype = torch.float64)"
      ],
      "metadata": {
        "id": "xdkFnhHDn1gz"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing_400 = SCOPE_variance_play(model_400, 0.9, 10000, pi_b, P_pi_b, P_pi_e, dtype = torch.float64)"
      ],
      "metadata": {
        "id": "hGLJ8iDxn1g0"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IS_tensor, padded_state_tensors, padded_weight_diff_tensors, gamma_weights_last_tensor, states_first_tensor, states_last_tensor, weight_first_tensor = testing_400.prepare()"
      ],
      "metadata": {
        "id": "yMk8bwNKn1g0"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_400 = train_var_play(model_400, 800, 0.0007, padded_state_tensors, states_first_tensor, states_last_tensor, testing_400)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCPsi8VmoFGu",
        "outputId": "6462a410-c38e-4c68-f343-3e8dc651c28c"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "E_s_wdiff_sq: 3.818623501816317e-06\n",
            "E_s_wdiff_all_sq: 5.1504677041227486e-08\n",
            "E_IS_SCOPE: -1.5581479430685247e-06\n",
            "E_IS_E_SCOPE: 4.658730291707227e-08\n",
            "Total Loss: 1.9661124687824543e-06\n",
            "----------------------------------------\n",
            "Epoch 318\n",
            "Var loss:  tensor(1.9614e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.820825995560044e-06\n",
            "E_s_wdiff_all_sq: 5.349843717599916e-08\n",
            "E_IS_SCOPE: -1.5618117588208178e-06\n",
            "E_IS_E_SCOPE: 4.537144321640203e-08\n",
            "Total Loss: 1.9614252902881636e-06\n",
            "----------------------------------------\n",
            "Epoch 319\n",
            "Var loss:  tensor(1.9567e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.817179748592323e-06\n",
            "E_s_wdiff_all_sq: 5.362001030560776e-08\n",
            "E_IS_SCOPE: -1.5574684865952953e-06\n",
            "E_IS_E_SCOPE: 5.019030585161591e-08\n",
            "Total Loss: 1.9567062893714516e-06\n",
            "----------------------------------------\n",
            "Epoch 320\n",
            "Var loss:  tensor(1.9520e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.8102695496245794e-06\n",
            "E_s_wdiff_all_sq: 5.351965390706791e-08\n",
            "E_IS_SCOPE: -1.5496881090180883e-06\n",
            "E_IS_E_SCOPE: 5.692225929859327e-08\n",
            "Total Loss: 1.951993295062707e-06\n",
            "----------------------------------------\n",
            "Epoch 321\n",
            "Var loss:  tensor(1.9473e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.8042120855996862e-06\n",
            "E_s_wdiff_all_sq: 5.426719255537616e-08\n",
            "E_IS_SCOPE: -1.5483929261767892e-06\n",
            "E_IS_E_SCOPE: 5.716407988774271e-08\n",
            "Total Loss: 1.9472950168938054e-06\n",
            "----------------------------------------\n",
            "Epoch 322\n",
            "Var loss:  tensor(1.9426e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.804982542069374e-06\n",
            "E_s_wdiff_all_sq: 5.652200043327136e-08\n",
            "E_IS_SCOPE: -1.5548999760581681e-06\n",
            "E_IS_E_SCOPE: 5.227641349899561e-08\n",
            "Total Loss: 1.942571898500334e-06\n",
            "----------------------------------------\n",
            "Epoch 323\n",
            "Var loss:  tensor(1.9378e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.8055618655664216e-06\n",
            "E_s_wdiff_all_sq: 5.757077220552158e-08\n",
            "E_IS_SCOPE: -1.5552189103616716e-06\n",
            "E_IS_E_SCOPE: 5.4087554592914954e-08\n",
            "Total Loss: 1.9378422994302857e-06\n",
            "----------------------------------------\n",
            "Epoch 324\n",
            "Var loss:  tensor(1.9331e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.798510727209711e-06\n",
            "E_s_wdiff_all_sq: 5.552828002125418e-08\n",
            "E_IS_SCOPE: -1.5405495333573405e-06\n",
            "E_IS_E_SCOPE: 6.862668615973915e-08\n",
            "Total Loss: 1.9330941441328564e-06\n",
            "----------------------------------------\n",
            "Epoch 325\n",
            "Var loss:  tensor(1.9283e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.790270148934778e-06\n",
            "E_s_wdiff_all_sq: 5.453871222568934e-08\n",
            "E_IS_SCOPE: -1.526064641576727e-06\n",
            "E_IS_E_SCOPE: 8.187589334726548e-08\n",
            "Total Loss: 1.9283145028396626e-06\n",
            "----------------------------------------\n",
            "Epoch 326\n",
            "Var loss:  tensor(1.9235e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7904909764953464e-06\n",
            "E_s_wdiff_all_sq: 5.804889935451536e-08\n",
            "E_IS_SCOPE: -1.525884690446034e-06\n",
            "E_IS_E_SCOPE: 8.282463292799453e-08\n",
            "Total Loss: 1.9234875663713328e-06\n",
            "----------------------------------------\n",
            "Epoch 327\n",
            "Var loss:  tensor(1.9187e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7955571837747704e-06\n",
            "E_s_wdiff_all_sq: 6.22212492840062e-08\n",
            "E_IS_SCOPE: -1.5302552007573844e-06\n",
            "E_IS_E_SCOPE: 8.130789834674959e-08\n",
            "Total Loss: 1.9186738722610547e-06\n",
            "----------------------------------------\n",
            "Epoch 328\n",
            "Var loss:  tensor(1.9138e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7961569280716486e-06\n",
            "E_s_wdiff_all_sq: 6.32911379046613e-08\n",
            "E_IS_SCOPE: -1.520454075290415e-06\n",
            "E_IS_E_SCOPE: 9.331385745585897e-08\n",
            "Total Loss: 1.9137940606529974e-06\n",
            "----------------------------------------\n",
            "Epoch 329\n",
            "Var loss:  tensor(1.9090e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.786826922531497e-06\n",
            "E_s_wdiff_all_sq: 6.279261447199095e-08\n",
            "E_IS_SCOPE: -1.5020486290623589e-06\n",
            "E_IS_E_SCOPE: 1.0972541021573765e-07\n",
            "Total Loss: 1.9089503654818712e-06\n",
            "----------------------------------------\n",
            "Epoch 330\n",
            "Var loss:  tensor(1.9041e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7803770914590023e-06\n",
            "E_s_wdiff_all_sq: 6.524564717558048e-08\n",
            "E_IS_SCOPE: -1.4966451475433453e-06\n",
            "E_IS_E_SCOPE: 1.1311330835956638e-07\n",
            "Total Loss: 1.9040786684561571e-06\n",
            "----------------------------------------\n",
            "Epoch 331\n",
            "Var loss:  tensor(1.8992e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7854346408474362e-06\n",
            "E_s_wdiff_all_sq: 7.059717420984574e-08\n",
            "E_IS_SCOPE: -1.509038371437111e-06\n",
            "E_IS_E_SCOPE: 1.0300913241957995e-07\n",
            "Total Loss: 1.899206594902767e-06\n",
            "----------------------------------------\n",
            "Epoch 332\n",
            "Var loss:  tensor(1.8943e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.790529699127186e-06\n",
            "E_s_wdiff_all_sq: 7.327126745700238e-08\n",
            "E_IS_SCOPE: -1.5142739244543384e-06\n",
            "E_IS_E_SCOPE: 1.0144351016462772e-07\n",
            "Total Loss: 1.8942876984108102e-06\n",
            "----------------------------------------\n",
            "Epoch 333\n",
            "Var loss:  tensor(1.8894e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.784337306223748e-06\n",
            "E_s_wdiff_all_sq: 7.185574116858227e-08\n",
            "E_IS_SCOPE: -1.5034674115412997e-06\n",
            "E_IS_E_SCOPE: 1.1231163642986695e-07\n",
            "Total Loss: 1.8893876050913911e-06\n",
            "----------------------------------------\n",
            "Epoch 334\n",
            "Var loss:  tensor(1.8845e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.775160057954662e-06\n",
            "E_s_wdiff_all_sq: 7.111456637286677e-08\n",
            "E_IS_SCOPE: -1.491516488524886e-06\n",
            "E_IS_E_SCOPE: 1.2250551507475027e-07\n",
            "Total Loss: 1.8844656203610816e-06\n",
            "----------------------------------------\n",
            "Epoch 335\n",
            "Var loss:  tensor(1.8796e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7721808310783007e-06\n",
            "E_s_wdiff_all_sq: 7.287105642659794e-08\n",
            "E_IS_SCOPE: -1.4879690464282344e-06\n",
            "E_IS_E_SCOPE: 1.2613027706393712e-07\n",
            "Total Loss: 1.8795752636459187e-06\n",
            "----------------------------------------\n",
            "Epoch 336\n",
            "Var loss:  tensor(1.8747e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.77234942339239e-06\n",
            "E_s_wdiff_all_sq: 7.42446496567738e-08\n",
            "E_IS_SCOPE: -1.4875964440226083e-06\n",
            "E_IS_E_SCOPE: 1.2834126577762234e-07\n",
            "Total Loss: 1.8746934901137132e-06\n",
            "----------------------------------------\n",
            "Epoch 337\n",
            "Var loss:  tensor(1.8698e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.770752326655044e-06\n",
            "E_s_wdiff_all_sq: 7.506216453541281e-08\n",
            "E_IS_SCOPE: -1.4864272481605577e-06\n",
            "E_IS_E_SCOPE: 1.307279170841289e-07\n",
            "Total Loss: 1.8698439676088166e-06\n",
            "----------------------------------------\n",
            "Epoch 338\n",
            "Var loss:  tensor(1.8650e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.767129891637057e-06\n",
            "E_s_wdiff_all_sq: 7.709446967845876e-08\n",
            "E_IS_SCOPE: -1.4842984384256124e-06\n",
            "E_IS_E_SCOPE: 1.324603360923526e-07\n",
            "Total Loss: 1.8649820089012273e-06\n",
            "----------------------------------------\n",
            "Epoch 339\n",
            "Var loss:  tensor(1.8601e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.765181548532679e-06\n",
            "E_s_wdiff_all_sq: 8.095025465855577e-08\n",
            "E_IS_SCOPE: -1.4844289737992038e-06\n",
            "E_IS_E_SCOPE: 1.3185627707224403e-07\n",
            "Total Loss: 1.860124928109786e-06\n",
            "----------------------------------------\n",
            "Epoch 340\n",
            "Var loss:  tensor(1.8553e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7658642025493426e-06\n",
            "E_s_wdiff_all_sq: 8.40229706435564e-08\n",
            "E_IS_SCOPE: -1.4798727318029115e-06\n",
            "E_IS_E_SCOPE: 1.3765119477300723e-07\n",
            "Total Loss: 1.8552575147325072e-06\n",
            "----------------------------------------\n",
            "Epoch 341\n",
            "Var loss:  tensor(1.8504e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7660326784611444e-06\n",
            "E_s_wdiff_all_sq: 8.497646873087636e-08\n",
            "E_IS_SCOPE: -1.468849553543189e-06\n",
            "E_IS_E_SCOPE: 1.5071685731312529e-07\n",
            "Total Loss: 1.8503875239961976e-06\n",
            "----------------------------------------\n",
            "Epoch 342\n",
            "Var loss:  tensor(1.8455e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7619343606472476e-06\n",
            "E_s_wdiff_all_sq: 8.544964234426646e-08\n",
            "E_IS_SCOPE: -1.4579249354077354e-06\n",
            "E_IS_E_SCOPE: 1.6178454674744187e-07\n",
            "Total Loss: 1.8455298899711852e-06\n",
            "----------------------------------------\n",
            "Epoch 343\n",
            "Var loss:  tensor(1.8406e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7600946228670487e-06\n",
            "E_s_wdiff_all_sq: 8.809450522234825e-08\n",
            "E_IS_SCOPE: -1.451416259351488e-06\n",
            "E_IS_E_SCOPE: 1.6849118292055114e-07\n",
            "Total Loss: 1.8406493690791807e-06\n",
            "----------------------------------------\n",
            "Epoch 344\n",
            "Var loss:  tensor(1.8359e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.757682342016531e-06\n",
            "E_s_wdiff_all_sq: 9.00458463095084e-08\n",
            "E_IS_SCOPE: -1.447039587416338e-06\n",
            "E_IS_E_SCOPE: 1.7306437678869136e-07\n",
            "Total Loss: 1.8358927032755224e-06\n",
            "----------------------------------------\n",
            "Epoch 345\n",
            "Var loss:  tensor(1.8312e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.75551507572102e-06\n",
            "E_s_wdiff_all_sq: 9.182863367047385e-08\n",
            "E_IS_SCOPE: -1.4435375108617628e-06\n",
            "E_IS_E_SCOPE: 1.7695480182390263e-07\n",
            "Total Loss: 1.8311659526577743e-06\n",
            "----------------------------------------\n",
            "Epoch 346\n",
            "Var loss:  tensor(1.8265e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7544158042732373e-06\n",
            "E_s_wdiff_all_sq: 9.472205138403982e-08\n",
            "E_IS_SCOPE: -1.4428416693245636e-06\n",
            "E_IS_E_SCOPE: 1.780022642462238e-07\n",
            "Total Loss: 1.826470021726181e-06\n",
            "----------------------------------------\n",
            "Epoch 347\n",
            "Var loss:  tensor(1.8218e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7575855619220727e-06\n",
            "E_s_wdiff_all_sq: 1.0064280470814462e-07\n",
            "E_IS_SCOPE: -1.4439179643524032e-06\n",
            "E_IS_E_SCOPE: 1.7790018014021756e-07\n",
            "Total Loss: 1.8217706042072454e-06\n",
            "----------------------------------------\n",
            "Epoch 348\n",
            "Var loss:  tensor(1.8171e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7575885667816687e-06\n",
            "E_s_wdiff_all_sq: 1.0474023214216893e-07\n",
            "E_IS_SCOPE: -1.4374300987860145e-06\n",
            "E_IS_E_SCOPE: 1.846938871137807e-07\n",
            "Total Loss: 1.8170644988184686e-06\n",
            "----------------------------------------\n",
            "Epoch 349\n",
            "Var loss:  tensor(1.8124e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7551798133805533e-06\n",
            "E_s_wdiff_all_sq: 1.0675741232987876e-07\n",
            "E_IS_SCOPE: -1.4272305366414886e-06\n",
            "E_IS_E_SCOPE: 1.9500581185486548e-07\n",
            "Total Loss: 1.8124138400365254e-06\n",
            "----------------------------------------\n",
            "Epoch 350\n",
            "Var loss:  tensor(1.8077e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7576141519037626e-06\n",
            "E_s_wdiff_all_sq: 1.1116752776569916e-07\n",
            "E_IS_SCOPE: -1.424151582533098e-06\n",
            "E_IS_E_SCOPE: 1.994640913343094e-07\n",
            "Total Loss: 1.8076794123818077e-06\n",
            "----------------------------------------\n",
            "Epoch 351\n",
            "Var loss:  tensor(1.8030e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7584396618938392e-06\n",
            "E_s_wdiff_all_sq: 1.1533044203138325e-07\n",
            "E_IS_SCOPE: -1.4223715772081997e-06\n",
            "E_IS_E_SCOPE: 2.0191730685428918e-07\n",
            "Total Loss: 1.8029955877160362e-06\n",
            "----------------------------------------\n",
            "Epoch 352\n",
            "Var loss:  tensor(1.7982e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7567478209384725e-06\n",
            "E_s_wdiff_all_sq: 1.1827526883093285e-07\n",
            "E_IS_SCOPE: -1.4217130358130593e-06\n",
            "E_IS_E_SCOPE: 2.026406721772029e-07\n",
            "Total Loss: 1.7982292721055736e-06\n",
            "----------------------------------------\n",
            "Epoch 353\n",
            "Var loss:  tensor(1.7935e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7556132728851553e-06\n",
            "E_s_wdiff_all_sq: 1.199461052158855e-07\n",
            "E_IS_SCOPE: -1.424675153612149e-06\n",
            "E_IS_E_SCOPE: 2.0065871131143753e-07\n",
            "Total Loss: 1.7934635738006547e-06\n",
            "----------------------------------------\n",
            "Epoch 354\n",
            "Var loss:  tensor(1.7887e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7584566417691074e-06\n",
            "E_s_wdiff_all_sq: 1.232436856877907e-07\n",
            "E_IS_SCOPE: -1.4321889419080717e-06\n",
            "E_IS_E_SCOPE: 1.953038850081046e-07\n",
            "Total Loss: 1.7886914382275232e-06\n",
            "----------------------------------------\n",
            "Epoch 355\n",
            "Var loss:  tensor(1.7839e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.751909393234119e-06\n",
            "E_s_wdiff_all_sq: 1.2300531513482188e-07\n",
            "E_IS_SCOPE: -1.4301044991237712e-06\n",
            "E_IS_E_SCOPE: 1.9661735392965532e-07\n",
            "Total Loss: 1.783924507971003e-06\n",
            "----------------------------------------\n",
            "Epoch 356\n",
            "Var loss:  tensor(1.7792e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7426702296057616e-06\n",
            "E_s_wdiff_all_sq: 1.2102976332236097e-07\n",
            "E_IS_SCOPE: -1.4225149171005258e-06\n",
            "E_IS_E_SCOPE: 2.0295571758882008e-07\n",
            "Total Loss: 1.7791633328832678e-06\n",
            "----------------------------------------\n",
            "Epoch 357\n",
            "Var loss:  tensor(1.7744e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.740613562403396e-06\n",
            "E_s_wdiff_all_sq: 1.2129520375643128e-07\n",
            "E_IS_SCOPE: -1.421493970805026e-06\n",
            "E_IS_E_SCOPE: 2.0520371671411655e-07\n",
            "Total Loss: 1.7743871195872385e-06\n",
            "----------------------------------------\n",
            "Epoch 358\n",
            "Var loss:  tensor(1.7696e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7454435670910924e-06\n",
            "E_s_wdiff_all_sq: 1.2530839961673778e-07\n",
            "E_IS_SCOPE: -1.4276185079663123e-06\n",
            "E_IS_E_SCOPE: 2.0187165068873773e-07\n",
            "Total Loss: 1.7696189861428132e-06\n",
            "----------------------------------------\n",
            "Epoch 359\n",
            "Var loss:  tensor(1.7648e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7459221415122328e-06\n",
            "E_s_wdiff_all_sq: 1.291212062427238e-07\n",
            "E_IS_SCOPE: -1.4272799753946659e-06\n",
            "E_IS_E_SCOPE: 2.0293544445274298e-07\n",
            "Total Loss: 1.7648342315532504e-06\n",
            "----------------------------------------\n",
            "Epoch 360\n",
            "Var loss:  tensor(1.7600e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7399299154704283e-06\n",
            "E_s_wdiff_all_sq: 1.3072748312426112e-07\n",
            "E_IS_SCOPE: -1.4184960631559778e-06\n",
            "E_IS_E_SCOPE: 2.1031858057901672e-07\n",
            "Total Loss: 1.760037280854737e-06\n",
            "----------------------------------------\n",
            "Epoch 361\n",
            "Var loss:  tensor(1.7552e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7406837829684978e-06\n",
            "E_s_wdiff_all_sq: 1.3506336664358868e-07\n",
            "E_IS_SCOPE: -1.4137671276307386e-06\n",
            "E_IS_E_SCOPE: 2.1565822352646195e-07\n",
            "Total Loss: 1.755233849989067e-06\n",
            "----------------------------------------\n",
            "Epoch 362\n",
            "Var loss:  tensor(1.7504e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.743654280630289e-06\n",
            "E_s_wdiff_all_sq: 1.3996351476917186e-07\n",
            "E_IS_SCOPE: -1.412867440924263e-06\n",
            "E_IS_E_SCOPE: 2.1798604547829635e-07\n",
            "Total Loss: 1.7504479290345572e-06\n",
            "----------------------------------------\n",
            "Epoch 363\n",
            "Var loss:  tensor(1.7456e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7452597737330147e-06\n",
            "E_s_wdiff_all_sq: 1.4489302309243449e-07\n",
            "E_IS_SCOPE: -1.411155266132268e-06\n",
            "E_IS_E_SCOPE: 2.2043579042434372e-07\n",
            "Total Loss: 1.7456487735059155e-06\n",
            "----------------------------------------\n",
            "Epoch 364\n",
            "Var loss:  tensor(1.7408e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.742935734773599e-06\n",
            "E_s_wdiff_all_sq: 1.4824170450959423e-07\n",
            "E_IS_SCOPE: -1.4071952729822862e-06\n",
            "E_IS_E_SCOPE: 2.2396555480479237e-07\n",
            "Total Loss: 1.7408365106684064e-06\n",
            "----------------------------------------\n",
            "Epoch 365\n",
            "Var loss:  tensor(1.7360e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.742488938219067e-06\n",
            "E_s_wdiff_all_sq: 1.5197996303608735e-07\n",
            "E_IS_SCOPE: -1.4070947990651948e-06\n",
            "E_IS_E_SCOPE: 2.2437819815570512e-07\n",
            "Total Loss: 1.736027116719738e-06\n",
            "----------------------------------------\n",
            "Epoch 366\n",
            "Var loss:  tensor(1.7312e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7472165992098974e-06\n",
            "E_s_wdiff_all_sq: 1.5714471267095792e-07\n",
            "E_IS_SCOPE: -1.4139285904421034e-06\n",
            "E_IS_E_SCOPE: 2.1973647611496104e-07\n",
            "Total Loss: 1.731205889403369e-06\n",
            "----------------------------------------\n",
            "Epoch 367\n",
            "Var loss:  tensor(1.7264e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7478797292148425e-06\n",
            "E_s_wdiff_all_sq: 1.603551335452879e-07\n",
            "E_IS_SCOPE: -1.416830747439832e-06\n",
            "E_IS_E_SCOPE: 2.1795558749652212e-07\n",
            "Total Loss: 1.7264160617754051e-06\n",
            "----------------------------------------\n",
            "Epoch 368\n",
            "Var loss:  tensor(1.7216e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.747125464557556e-06\n",
            "E_s_wdiff_all_sq: 1.6376491046864126e-07\n",
            "E_IS_SCOPE: -1.4171718278892545e-06\n",
            "E_IS_E_SCOPE: 2.1794605881402009e-07\n",
            "Total Loss: 1.7215889166609243e-06\n",
            "----------------------------------------\n",
            "Epoch 369\n",
            "Var loss:  tensor(1.7168e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.743677530338166e-06\n",
            "E_s_wdiff_all_sq: 1.6536708407784184e-07\n",
            "E_IS_SCOPE: -1.4133458031491908e-06\n",
            "E_IS_E_SCOPE: 2.2163739987140744e-07\n",
            "Total Loss: 1.7168081761976867e-06\n",
            "----------------------------------------\n",
            "Epoch 370\n",
            "Var loss:  tensor(1.7120e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.743135663728983e-06\n",
            "E_s_wdiff_all_sq: 1.6805534344425272e-07\n",
            "E_IS_SCOPE: -1.4103977949929978e-06\n",
            "E_IS_E_SCOPE: 2.25376434877616e-07\n",
            "Total Loss: 1.7119959965220617e-06\n",
            "----------------------------------------\n",
            "Epoch 371\n",
            "Var loss:  tensor(1.7072e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7464769811575023e-06\n",
            "E_s_wdiff_all_sq: 1.7297790838333208e-07\n",
            "E_IS_SCOPE: -1.411372401843724e-06\n",
            "E_IS_E_SCOPE: 2.2602025910766937e-07\n",
            "Total Loss: 1.7071778868499418e-06\n",
            "----------------------------------------\n",
            "Epoch 372\n",
            "Var loss:  tensor(1.7023e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.742690478060719e-06\n",
            "E_s_wdiff_all_sq: 1.7469352512173506e-07\n",
            "E_IS_SCOPE: -1.402651821751086e-06\n",
            "E_IS_E_SCOPE: 2.344387526909342e-07\n",
            "Total Loss: 1.702279940033502e-06\n",
            "----------------------------------------\n",
            "Epoch 373\n",
            "Var loss:  tensor(1.6974e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.740070497218484e-06\n",
            "E_s_wdiff_all_sq: 1.7689496259153805e-07\n",
            "E_IS_SCOPE: -1.3948534541085544e-06\n",
            "E_IS_E_SCOPE: 2.4225427373524025e-07\n",
            "Total Loss: 1.6974242149179154e-06\n",
            "----------------------------------------\n",
            "Epoch 374\n",
            "Var loss:  tensor(1.6925e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7459210321486768e-06\n",
            "E_s_wdiff_all_sq: 1.8417374814302758e-07\n",
            "E_IS_SCOPE: -1.396955224597356e-06\n",
            "E_IS_E_SCOPE: 2.4190074952931134e-07\n",
            "Total Loss: 1.692499471730873e-06\n",
            "----------------------------------------\n",
            "Epoch 375\n",
            "Var loss:  tensor(1.6877e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7502183338530655e-06\n",
            "E_s_wdiff_all_sq: 1.9073759554846822e-07\n",
            "E_IS_SCOPE: -1.3996379264033374e-06\n",
            "E_IS_E_SCOPE: 2.4050724203488344e-07\n",
            "Total Loss: 1.6876545374067142e-06\n",
            "----------------------------------------\n",
            "Epoch 376\n",
            "Var loss:  tensor(1.6828e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7463995776071264e-06\n",
            "E_s_wdiff_all_sq: 1.9217561524712215e-07\n",
            "E_IS_SCOPE: -1.3918575403442332e-06\n",
            "E_IS_E_SCOPE: 2.480801264846274e-07\n",
            "Total Loss: 1.6828127646808418e-06\n",
            "----------------------------------------\n",
            "Epoch 377\n",
            "Var loss:  tensor(1.6780e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.739305576892997e-06\n",
            "E_s_wdiff_all_sq: 1.9146786191367652e-07\n",
            "E_IS_SCOPE: -1.380567570855371e-06\n",
            "E_IS_E_SCOPE: 2.585787639672729e-07\n",
            "Total Loss: 1.6780091813125916e-06\n",
            "----------------------------------------\n",
            "Epoch 378\n",
            "Var loss:  tensor(1.6732e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7410151775673873e-06\n",
            "E_s_wdiff_all_sq: 1.9549242251886063e-07\n",
            "E_IS_SCOPE: -1.3779588562947253e-06\n",
            "E_IS_E_SCOPE: 2.624393516898577e-07\n",
            "Total Loss: 1.6731904750579195e-06\n",
            "----------------------------------------\n",
            "Epoch 379\n",
            "Var loss:  tensor(1.6684e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7455530745300376e-06\n",
            "E_s_wdiff_all_sq: 2.01158412097493e-07\n",
            "E_IS_SCOPE: -1.38334563855428e-06\n",
            "E_IS_E_SCOPE: 2.588716606512735e-07\n",
            "Total Loss: 1.668424199999996e-06\n",
            "----------------------------------------\n",
            "Epoch 380\n",
            "Var loss:  tensor(1.6636e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7501052772351773e-06\n",
            "E_s_wdiff_all_sq: 2.0742591861500623e-07\n",
            "E_IS_SCOPE: -1.3860683019681373e-06\n",
            "E_IS_E_SCOPE: 2.5770096230991907e-07\n",
            "Total Loss: 1.6636049660426175e-06\n",
            "----------------------------------------\n",
            "Epoch 381\n",
            "Var loss:  tensor(1.6588e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.751099399516157e-06\n",
            "E_s_wdiff_all_sq: 2.1262164529500984e-07\n",
            "E_IS_SCOPE: -1.3792124210670561e-06\n",
            "E_IS_E_SCOPE: 2.648487392210459e-07\n",
            "Total Loss: 1.6588195696235012e-06\n",
            "----------------------------------------\n",
            "Epoch 382\n",
            "Var loss:  tensor(1.6541e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7472180455995486e-06\n",
            "E_s_wdiff_all_sq: 2.1505658122803808e-07\n",
            "E_IS_SCOPE: -1.3668088352684067e-06\n",
            "E_IS_E_SCOPE: 2.7647569318881015e-07\n",
            "Total Loss: 1.6540565434356356e-06\n",
            "----------------------------------------\n",
            "Epoch 383\n",
            "Var loss:  tensor(1.6493e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7460206580818403e-06\n",
            "E_s_wdiff_all_sq: 2.1772452818406725e-07\n",
            "E_IS_SCOPE: -1.3593780695239962e-06\n",
            "E_IS_E_SCOPE: 2.8434016107163497e-07\n",
            "Total Loss: 1.6493238046850694e-06\n",
            "----------------------------------------\n",
            "Epoch 384\n",
            "Var loss:  tensor(1.6445e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.749322940113768e-06\n",
            "E_s_wdiff_all_sq: 2.213497710932818e-07\n",
            "E_IS_SCOPE: -1.359077015244714e-06\n",
            "E_IS_E_SCOPE: 2.868813943877622e-07\n",
            "Total Loss: 1.6445204857340927e-06\n",
            "----------------------------------------\n",
            "Epoch 385\n",
            "Var loss:  tensor(1.6397e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.751085476935327e-06\n",
            "E_s_wdiff_all_sq: 2.2440283954132547e-07\n",
            "E_IS_SCOPE: -1.3589898115617542e-06\n",
            "E_IS_E_SCOPE: 2.8871694145279737e-07\n",
            "Total Loss: 1.6397332673434577e-06\n",
            "----------------------------------------\n",
            "Epoch 386\n",
            "Var loss:  tensor(1.6350e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7488744400602235e-06\n",
            "E_s_wdiff_all_sq: 2.2706389181355593e-07\n",
            "E_IS_SCOPE: -1.3567963216485892e-06\n",
            "E_IS_E_SCOPE: 2.9086140833976304e-07\n",
            "Total Loss: 1.6349592242485213e-06\n",
            "----------------------------------------\n",
            "Epoch 387\n",
            "Var loss:  tensor(1.6302e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7453884821816675e-06\n",
            "E_s_wdiff_all_sq: 2.2967286991824668e-07\n",
            "E_IS_SCOPE: -1.354037450894136e-06\n",
            "E_IS_E_SCOPE: 2.9293482473688615e-07\n",
            "Total Loss: 1.6302351969799352e-06\n",
            "----------------------------------------\n",
            "Epoch 388\n",
            "Var loss:  tensor(1.6255e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.745579093843386e-06\n",
            "E_s_wdiff_all_sq: 2.3228658053430124e-07\n",
            "E_IS_SCOPE: -1.365751038023357e-06\n",
            "E_IS_E_SCOPE: 2.8238184335064324e-07\n",
            "Total Loss: 1.6254908865396433e-06\n",
            "----------------------------------------\n",
            "Epoch 389\n",
            "Var loss:  tensor(1.6208e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7466368694702266e-06\n",
            "E_s_wdiff_all_sq: 2.2705108223306518e-07\n",
            "E_IS_SCOPE: -1.3673089839566357e-06\n",
            "E_IS_E_SCOPE: 2.863336112846768e-07\n",
            "Total Loss: 1.6207647327330956e-06\n",
            "----------------------------------------\n",
            "Epoch 390\n",
            "Var loss:  tensor(1.6161e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7375278461262e-06\n",
            "E_s_wdiff_all_sq: 2.2098184848318766e-07\n",
            "E_IS_SCOPE: -1.3642222554430255e-06\n",
            "E_IS_E_SCOPE: 2.90256742464175e-07\n",
            "Total Loss: 1.61605213780717e-06\n",
            "----------------------------------------\n",
            "Epoch 391\n",
            "Var loss:  tensor(1.6113e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.720502086214623e-06\n",
            "E_s_wdiff_all_sq: 2.1725404238589962e-07\n",
            "E_IS_SCOPE: -1.353322662874933e-06\n",
            "E_IS_E_SCOPE: 2.9686151329541016e-07\n",
            "Total Loss: 1.6113438274665955e-06\n",
            "----------------------------------------\n",
            "Epoch 392\n",
            "Var loss:  tensor(1.6065e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.712703118201409e-06\n",
            "E_s_wdiff_all_sq: 2.149431397466573e-07\n",
            "E_IS_SCOPE: -1.3382770086223922e-06\n",
            "E_IS_E_SCOPE: 3.1156094268531476e-07\n",
            "Total Loss: 1.6065482118178968e-06\n",
            "----------------------------------------\n",
            "Epoch 393\n",
            "Var loss:  tensor(1.6019e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7251849971683343e-06\n",
            "E_s_wdiff_all_sq: 2.2349395161766086e-07\n",
            "E_IS_SCOPE: -1.3425902736630272e-06\n",
            "E_IS_E_SCOPE: 3.1154206701379904e-07\n",
            "Total Loss: 1.6018905001755793e-06\n",
            "----------------------------------------\n",
            "Epoch 394\n",
            "Var loss:  tensor(1.5971e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7373969395080364e-06\n",
            "E_s_wdiff_all_sq: 2.384194880786483e-07\n",
            "E_IS_SCOPE: -1.3512160726635145e-06\n",
            "E_IS_E_SCOPE: 3.0392982637468794e-07\n",
            "Total Loss: 1.5971497893315418e-06\n",
            "----------------------------------------\n",
            "Epoch 395\n",
            "Var loss:  tensor(1.5924e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7392545157030625e-06\n",
            "E_s_wdiff_all_sq: 2.495504532859129e-07\n",
            "E_IS_SCOPE: -1.3477076154061413e-06\n",
            "E_IS_E_SCOPE: 3.051568355030115e-07\n",
            "Total Loss: 1.592439296577403e-06\n",
            "----------------------------------------\n",
            "Epoch 396\n",
            "Var loss:  tensor(1.5877e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7409323118094446e-06\n",
            "E_s_wdiff_all_sq: 2.548608922213331e-07\n",
            "E_IS_SCOPE: -1.342025435620398e-06\n",
            "E_IS_E_SCOPE: 3.1139431764437166e-07\n",
            "Total Loss: 1.587696049037131e-06\n",
            "----------------------------------------\n",
            "Epoch 397\n",
            "Var loss:  tensor(1.5830e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.748567610954559e-06\n",
            "E_s_wdiff_all_sq: 2.615906875608306e-07\n",
            "E_IS_SCOPE: -1.3449718900186018e-06\n",
            "E_IS_E_SCOPE: 3.112651543621337e-07\n",
            "Total Loss: 1.5829669706108162e-06\n",
            "----------------------------------------\n",
            "Epoch 398\n",
            "Var loss:  tensor(1.5782e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.759652988542204e-06\n",
            "E_s_wdiff_all_sq: 2.7418898696117585e-07\n",
            "E_IS_SCOPE: -1.356542395276024e-06\n",
            "E_IS_E_SCOPE: 3.0132635434269886e-07\n",
            "Total Loss: 1.578190638322141e-06\n",
            "----------------------------------------\n",
            "Epoch 399\n",
            "Var loss:  tensor(1.5735e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7618154766621997e-06\n",
            "E_s_wdiff_all_sq: 2.8210032607811246e-07\n",
            "E_IS_SCOPE: -1.3560982069093842e-06\n",
            "E_IS_E_SCOPE: 3.012565088407858e-07\n",
            "Total Loss: 1.5734698550623055e-06\n",
            "----------------------------------------\n",
            "Epoch 400\n",
            "Var loss:  tensor(1.5687e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.758254989233864e-06\n",
            "E_s_wdiff_all_sq: 2.8183095522839206e-07\n",
            "E_IS_SCOPE: -1.3444956353737346e-06\n",
            "E_IS_E_SCOPE: 3.1359420840800636e-07\n",
            "Total Loss: 1.5687084824205487e-06\n",
            "----------------------------------------\n",
            "Epoch 401\n",
            "Var loss:  tensor(1.5640e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.755043489220429e-06\n",
            "E_s_wdiff_all_sq: 2.8067314710883147e-07\n",
            "E_IS_SCOPE: -1.3323661147600035e-06\n",
            "E_IS_E_SCOPE: 3.2704234041358693e-07\n",
            "Total Loss: 1.5640175677429752e-06\n",
            "----------------------------------------\n",
            "Epoch 402\n",
            "Var loss:  tensor(1.5594e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7625846336782344e-06\n",
            "E_s_wdiff_all_sq: 2.906330252911993e-07\n",
            "E_IS_SCOPE: -1.3437126650934921e-06\n",
            "E_IS_E_SCOPE: 3.1681796035712197e-07\n",
            "Total Loss: 1.5593544934643657e-06\n",
            "----------------------------------------\n",
            "Epoch 403\n",
            "Var loss:  tensor(1.5546e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.762547634438664e-06\n",
            "E_s_wdiff_all_sq: 2.922522754478302e-07\n",
            "E_IS_SCOPE: -1.3379844211646806e-06\n",
            "E_IS_E_SCOPE: 3.2408548016188727e-07\n",
            "Total Loss: 1.5546196923162562e-06\n",
            "----------------------------------------\n",
            "Epoch 404\n",
            "Var loss:  tensor(1.5499e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.753189705947865e-06\n",
            "E_s_wdiff_all_sq: 2.868534118545917e-07\n",
            "E_IS_SCOPE: -1.3147036320283895e-06\n",
            "E_IS_E_SCOPE: 3.4776432736449364e-07\n",
            "Total Loss: 1.5498645112860658e-06\n",
            "----------------------------------------\n",
            "Epoch 405\n",
            "Var loss:  tensor(1.5451e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.752215430533863e-06\n",
            "E_s_wdiff_all_sq: 2.9281913586413326e-07\n",
            "E_IS_SCOPE: -1.3134717719000487e-06\n",
            "E_IS_E_SCOPE: 3.47913784844198e-07\n",
            "Total Loss: 1.5450893171597948e-06\n",
            "----------------------------------------\n",
            "Epoch 406\n",
            "Var loss:  tensor(1.5403e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.75487814348829e-06\n",
            "E_s_wdiff_all_sq: 2.9831710795449065e-07\n",
            "E_IS_SCOPE: -1.3125516701270509e-06\n",
            "E_IS_E_SCOPE: 3.4980927764650574e-07\n",
            "Total Loss: 1.5403032759652447e-06\n",
            "----------------------------------------\n",
            "Epoch 407\n",
            "Var loss:  tensor(1.5355e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.755177046278001e-06\n",
            "E_s_wdiff_all_sq: 2.989732586061748e-07\n",
            "E_IS_SCOPE: -1.3062496971230502e-06\n",
            "E_IS_E_SCOPE: 3.58321502842614e-07\n",
            "Total Loss: 1.5355255237190563e-06\n",
            "----------------------------------------\n",
            "Epoch 408\n",
            "Var loss:  tensor(1.5308e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.752468427954843e-06\n",
            "E_s_wdiff_all_sq: 3.0089541563336845e-07\n",
            "E_IS_SCOPE: -1.3012178510730047e-06\n",
            "E_IS_E_SCOPE: 3.6342197609071736e-07\n",
            "Total Loss: 1.5307574939725887e-06\n",
            "----------------------------------------\n",
            "Epoch 409\n",
            "Var loss:  tensor(1.5259e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7600367114648257e-06\n",
            "E_s_wdiff_all_sq: 3.1236374093555465e-07\n",
            "E_IS_SCOPE: -1.309320581109729e-06\n",
            "E_IS_E_SCOPE: 3.5578475583458984e-07\n",
            "Total Loss: 1.5259264326191921e-06\n",
            "----------------------------------------\n",
            "Epoch 410\n",
            "Var loss:  tensor(1.5213e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.756094318116278e-06\n",
            "E_s_wdiff_all_sq: 3.121064595646069e-07\n",
            "E_IS_SCOPE: -1.302936584048671e-06\n",
            "E_IS_E_SCOPE: 3.626635461363251e-07\n",
            "Total Loss: 1.5212517341602377e-06\n",
            "----------------------------------------\n",
            "Epoch 411\n",
            "Var loss:  tensor(1.5166e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7474764836068174e-06\n",
            "E_s_wdiff_all_sq: 3.0397611191504755e-07\n",
            "E_IS_SCOPE: -1.2866927611447982e-06\n",
            "E_IS_E_SCOPE: 3.80983708024956e-07\n",
            "Total Loss: 1.5166115693308203e-06\n",
            "----------------------------------------\n",
            "Epoch 412\n",
            "Var loss:  tensor(1.5120e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7539559920475177e-06\n",
            "E_s_wdiff_all_sq: 3.0839886551085054e-07\n",
            "E_IS_SCOPE: -1.2872832263561059e-06\n",
            "E_IS_E_SCOPE: 3.837313864896423e-07\n",
            "Total Loss: 1.51199203682373e-06\n",
            "----------------------------------------\n",
            "Epoch 413\n",
            "Var loss:  tensor(1.5074e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.740737000661189e-06\n",
            "E_s_wdiff_all_sq: 3.0169994041305435e-07\n",
            "E_IS_SCOPE: -1.2636705185887066e-06\n",
            "E_IS_E_SCOPE: 4.064026897954621e-07\n",
            "Total Loss: 1.5073547794583557e-06\n",
            "----------------------------------------\n",
            "Epoch 414\n",
            "Var loss:  tensor(1.5028e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7278571314921667e-06\n",
            "E_s_wdiff_all_sq: 2.94747608294448e-07\n",
            "E_IS_SCOPE: -1.2466123027637484e-06\n",
            "E_IS_E_SCOPE: 4.2279484864373064e-07\n",
            "Total Loss: 1.502759356361319e-06\n",
            "----------------------------------------\n",
            "Epoch 415\n",
            "Var loss:  tensor(1.4981e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.725483374065858e-06\n",
            "E_s_wdiff_all_sq: 2.904339128789451e-07\n",
            "E_IS_SCOPE: -1.2323050473859563e-06\n",
            "E_IS_E_SCOPE: 4.403818091713779e-07\n",
            "Total Loss: 1.4981398840508035e-06\n",
            "----------------------------------------\n",
            "Epoch 416\n",
            "Var loss:  tensor(1.4935e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7366223147538553e-06\n",
            "E_s_wdiff_all_sq: 2.988428166898859e-07\n",
            "E_IS_SCOPE: -1.2349199781380993e-06\n",
            "E_IS_E_SCOPE: 4.414482696978233e-07\n",
            "Total Loss: 1.4935071383706828e-06\n",
            "----------------------------------------\n",
            "Epoch 417\n",
            "Var loss:  tensor(1.4888e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.722593824490437e-06\n",
            "E_s_wdiff_all_sq: 2.941718101689284e-07\n",
            "E_IS_SCOPE: -1.2064584311039298e-06\n",
            "E_IS_E_SCOPE: 4.6756157132480894e-07\n",
            "Total Loss: 1.4888461454425902e-06\n",
            "----------------------------------------\n",
            "Epoch 418\n",
            "Var loss:  tensor(1.4843e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7061335766712023e-06\n",
            "E_s_wdiff_all_sq: 2.866564002074007e-07\n",
            "E_IS_SCOPE: -1.1710859838790565e-06\n",
            "E_IS_E_SCOPE: 5.007566719636895e-07\n",
            "Total Loss: 1.4842560007568688e-06\n",
            "----------------------------------------\n",
            "Epoch 419\n",
            "Var loss:  tensor(1.4796e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7189337950232425e-06\n",
            "E_s_wdiff_all_sq: 2.9563104953641707e-07\n",
            "E_IS_SCOPE: -1.1770483979169515e-06\n",
            "E_IS_E_SCOPE: 4.990418264715687e-07\n",
            "Total Loss: 1.4795864326883438e-06\n",
            "----------------------------------------\n",
            "Epoch 420\n",
            "Var loss:  tensor(1.4749e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.72112850651415e-06\n",
            "E_s_wdiff_all_sq: 2.959918044232878e-07\n",
            "E_IS_SCOPE: -1.1692935334654473e-06\n",
            "E_IS_E_SCOPE: 5.100507928800983e-07\n",
            "Total Loss: 1.47491218537833e-06\n",
            "----------------------------------------\n",
            "Epoch 421\n",
            "Var loss:  tensor(1.4703e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.701307205934347e-06\n",
            "E_s_wdiff_all_sq: 2.8542510510415807e-07\n",
            "E_IS_SCOPE: -1.1362016822438057e-06\n",
            "E_IS_E_SCOPE: 5.408393081750521e-07\n",
            "Total Loss: 1.470264255971032e-06\n",
            "----------------------------------------\n",
            "Epoch 422\n",
            "Var loss:  tensor(1.4656e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7036067926532814e-06\n",
            "E_s_wdiff_all_sq: 2.927366336885657e-07\n",
            "E_IS_SCOPE: -1.1307752969213912e-06\n",
            "E_IS_E_SCOPE: 5.460997362049857e-07\n",
            "Total Loss: 1.4655842286905205e-06\n",
            "----------------------------------------\n",
            "Epoch 423\n",
            "Var loss:  tensor(1.4610e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7107308609997365e-06\n",
            "E_s_wdiff_all_sq: 2.998801820890259e-07\n",
            "E_IS_SCOPE: -1.112060850149784e-06\n",
            "E_IS_E_SCOPE: 5.671193485342748e-07\n",
            "Total Loss: 1.4609544175211516e-06\n",
            "----------------------------------------\n",
            "Epoch 424\n",
            "Var loss:  tensor(1.4563e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7073832957764196e-06\n",
            "E_s_wdiff_all_sq: 3.003135579709834e-07\n",
            "E_IS_SCOPE: -1.070969577014724e-06\n",
            "E_IS_E_SCOPE: 6.086241867557526e-07\n",
            "Total Loss: 1.456346346243042e-06\n",
            "----------------------------------------\n",
            "Epoch 425\n",
            "Var loss:  tensor(1.4517e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.711183108731413e-06\n",
            "E_s_wdiff_all_sq: 3.095989715065367e-07\n",
            "E_IS_SCOPE: -1.0403316321263186e-06\n",
            "E_IS_E_SCOPE: 6.388194344499697e-07\n",
            "Total Loss: 1.4517461400508576e-06\n",
            "----------------------------------------\n",
            "Epoch 426\n",
            "Var loss:  tensor(1.4471e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7138121633721766e-06\n",
            "E_s_wdiff_all_sq: 3.1595078627347233e-07\n",
            "E_IS_SCOPE: -1.0106825893833673e-06\n",
            "E_IS_E_SCOPE: 6.689095343399825e-07\n",
            "Total Loss: 1.4471412656305633e-06\n",
            "----------------------------------------\n",
            "Epoch 427\n",
            "Var loss:  tensor(1.4425e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.717041075296832e-06\n",
            "E_s_wdiff_all_sq: 3.1878800334639753e-07\n",
            "E_IS_SCOPE: -9.889551286483555e-07\n",
            "E_IS_E_SCOPE: 6.93148032694191e-07\n",
            "Total Loss: 1.4425108852439005e-06\n",
            "----------------------------------------\n",
            "Epoch 428\n",
            "Var loss:  tensor(1.4379e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7275789113781396e-06\n",
            "E_s_wdiff_all_sq: 3.296381045853426e-07\n",
            "E_IS_SCOPE: -9.8469828593951e-07\n",
            "E_IS_E_SCOPE: 6.995774071769918e-07\n",
            "Total Loss: 1.437853556538352e-06\n",
            "----------------------------------------\n",
            "Epoch 429\n",
            "Var loss:  tensor(1.4333e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.715838720156469e-06\n",
            "E_s_wdiff_all_sq: 3.257874921906111e-07\n",
            "E_IS_SCOPE: -9.584520895988967e-07\n",
            "E_IS_E_SCOPE: 7.241689071885246e-07\n",
            "Total Loss: 1.4332733703695735e-06\n",
            "----------------------------------------\n",
            "Epoch 430\n",
            "Var loss:  tensor(1.4286e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.708255918302871e-06\n",
            "E_s_wdiff_all_sq: 3.221182711131142e-07\n",
            "E_IS_SCOPE: -9.284794460953982e-07\n",
            "E_IS_E_SCOPE: 7.54497271866315e-07\n",
            "Total Loss: 1.4286483472448896e-06\n",
            "----------------------------------------\n",
            "Epoch 431\n",
            "Var loss:  tensor(1.4240e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7251369517226818e-06\n",
            "E_s_wdiff_all_sq: 3.365281045530681e-07\n",
            "E_IS_SCOPE: -9.292150582936742e-07\n",
            "E_IS_E_SCOPE: 7.5730880232476e-07\n",
            "Total Loss: 1.4240252619113036e-06\n",
            "----------------------------------------\n",
            "Epoch 432\n",
            "Var loss:  tensor(1.4194e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.72744964036164e-06\n",
            "E_s_wdiff_all_sq: 3.413379691140472e-07\n",
            "E_IS_SCOPE: -9.088756325548706e-07\n",
            "E_IS_E_SCOPE: 7.787148994098935e-07\n",
            "Total Loss: 1.4193947432966233e-06\n",
            "----------------------------------------\n",
            "Epoch 433\n",
            "Var loss:  tensor(1.4148e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7174960765215632e-06\n",
            "E_s_wdiff_all_sq: 3.3905800039700267e-07\n",
            "E_IS_SCOPE: -8.735584500414855e-07\n",
            "E_IS_E_SCOPE: 8.125051535324349e-07\n",
            "Total Loss: 1.4147750049552784e-06\n",
            "----------------------------------------\n",
            "Epoch 434\n",
            "Var loss:  tensor(1.4101e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7247134728654896e-06\n",
            "E_s_wdiff_all_sq: 3.4964853697414283e-07\n",
            "E_IS_SCOPE: -8.596682622577166e-07\n",
            "E_IS_E_SCOPE: 8.270379061569652e-07\n",
            "Total Loss: 1.4101167350405418e-06\n",
            "----------------------------------------\n",
            "Epoch 435\n",
            "Var loss:  tensor(1.4055e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7453445371596323e-06\n",
            "E_s_wdiff_all_sq: 3.6754034482146097e-07\n",
            "E_IS_SCOPE: -8.612777410335783e-07\n",
            "E_IS_E_SCOPE: 8.291069435615396e-07\n",
            "Total Loss: 1.405498959126494e-06\n",
            "----------------------------------------\n",
            "Epoch 436\n",
            "Var loss:  tensor(1.4009e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.745564364312256e-06\n",
            "E_s_wdiff_all_sq: 3.69290933310109e-07\n",
            "E_IS_SCOPE: -8.471947699105281e-07\n",
            "E_IS_E_SCOPE: 8.447198839361625e-07\n",
            "Total Loss: 1.400908259287324e-06\n",
            "----------------------------------------\n",
            "Epoch 437\n",
            "Var loss:  tensor(1.3962e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.743307666757351e-06\n",
            "E_s_wdiff_all_sq: 3.71329037774109e-07\n",
            "E_IS_SCOPE: -8.40325914106005e-07\n",
            "E_IS_E_SCOPE: 8.517784403424936e-07\n",
            "Total Loss: 1.3962340560648037e-06\n",
            "----------------------------------------\n",
            "Epoch 438\n",
            "Var loss:  tensor(1.3915e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.740737120430676e-06\n",
            "E_s_wdiff_all_sq: 3.7436745475053383e-07\n",
            "E_IS_SCOPE: -8.304732731095192e-07\n",
            "E_IS_E_SCOPE: 8.611840247497515e-07\n",
            "Total Loss: 1.3915192059401594e-06\n",
            "----------------------------------------\n",
            "Epoch 439\n",
            "Var loss:  tensor(1.3868e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.722972043391154e-06\n",
            "E_s_wdiff_all_sq: 3.627565786164752e-07\n",
            "E_IS_SCOPE: -7.967301987972164e-07\n",
            "E_IS_E_SCOPE: 8.941869815145724e-07\n",
            "Total Loss: 1.3868452401296596e-06\n",
            "----------------------------------------\n",
            "Epoch 440\n",
            "Var loss:  tensor(1.3821e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7234338088890284e-06\n",
            "E_s_wdiff_all_sq: 3.636145233051429e-07\n",
            "E_IS_SCOPE: -7.864448866277558e-07\n",
            "E_IS_E_SCOPE: 9.066366692220122e-07\n",
            "Total Loss: 1.3821203098629088e-06\n",
            "----------------------------------------\n",
            "Epoch 441\n",
            "Var loss:  tensor(1.3774e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7196165205281044e-06\n",
            "E_s_wdiff_all_sq: 3.605660297946987e-07\n",
            "E_IS_SCOPE: -7.672509450290234e-07\n",
            "E_IS_E_SCOPE: 9.278102227404734e-07\n",
            "Total Loss: 1.3773922911729707e-06\n",
            "----------------------------------------\n",
            "Epoch 442\n",
            "Var loss:  tensor(1.3727e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.709122403254167e-06\n",
            "E_s_wdiff_all_sq: 3.5315071270738495e-07\n",
            "E_IS_SCOPE: -7.384426585372165e-07\n",
            "E_IS_E_SCOPE: 9.5742099995424e-07\n",
            "Total Loss: 1.3727085095424283e-06\n",
            "----------------------------------------\n",
            "Epoch 443\n",
            "Var loss:  tensor(1.3680e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7052186909483435e-06\n",
            "E_s_wdiff_all_sq: 3.5090121267833935e-07\n",
            "E_IS_SCOPE: -7.172211194756187e-07\n",
            "E_IS_E_SCOPE: 9.801821453638037e-07\n",
            "Total Loss: 1.367975084569718e-06\n",
            "----------------------------------------\n",
            "Epoch 444\n",
            "Var loss:  tensor(1.3632e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7053520543423403e-06\n",
            "E_s_wdiff_all_sq: 3.540269779905107e-07\n",
            "E_IS_SCOPE: -7.019967594788145e-07\n",
            "E_IS_E_SCOPE: 9.962859068039721e-07\n",
            "Total Loss: 1.3632238797648153e-06\n",
            "----------------------------------------\n",
            "Epoch 445\n",
            "Var loss:  tensor(1.3587e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.7049906949673404e-06\n",
            "E_s_wdiff_all_sq: 3.594510382908651e-07\n",
            "E_IS_SCOPE: -6.927479029122061e-07\n",
            "E_IS_E_SCOPE: 1.004922125467472e-06\n",
            "Total Loss: 1.3586637358956783e-06\n",
            "----------------------------------------\n",
            "Epoch 446\n",
            "Var loss:  tensor(1.3540e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.684894341476923e-06\n",
            "E_s_wdiff_all_sq: 3.444793092830471e-07\n",
            "E_IS_SCOPE: -6.609904172128256e-07\n",
            "E_IS_E_SCOPE: 1.0364532849590214e-06\n",
            "Total Loss: 1.35399176382874e-06\n",
            "----------------------------------------\n",
            "Epoch 447\n",
            "Var loss:  tensor(1.3493e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6842293358547605e-06\n",
            "E_s_wdiff_all_sq: 3.4278917735311077e-07\n",
            "E_IS_SCOPE: -6.527745853790643e-07\n",
            "E_IS_E_SCOPE: 1.0475354877759652e-06\n",
            "Total Loss: 1.3492841481701497e-06\n",
            "----------------------------------------\n",
            "Epoch 448\n",
            "Var loss:  tensor(1.3447e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6931913604960196e-06\n",
            "E_s_wdiff_all_sq: 3.5117272378026866e-07\n",
            "E_IS_SCOPE: -6.55310041063344e-07\n",
            "E_IS_E_SCOPE: 1.0475709943210972e-06\n",
            "Total Loss: 1.344720701925427e-06\n",
            "----------------------------------------\n",
            "Epoch 449\n",
            "Var loss:  tensor(1.3400e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6688525884057924e-06\n",
            "E_s_wdiff_all_sq: 3.3454902167581115e-07\n",
            "E_IS_SCOPE: -6.20728128629836e-07\n",
            "E_IS_E_SCOPE: 1.0806689627654011e-06\n",
            "Total Loss: 1.3399735199180662e-06\n",
            "----------------------------------------\n",
            "Epoch 450\n",
            "Var loss:  tensor(1.3354e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6506737067700954e-06\n",
            "E_s_wdiff_all_sq: 3.225442689258651e-07\n",
            "E_IS_SCOPE: -5.904343829066517e-07\n",
            "E_IS_E_SCOPE: 1.1101762266275103e-06\n",
            "Total Loss: 1.3353723547544648e-06\n",
            "----------------------------------------\n",
            "Epoch 451\n",
            "Var loss:  tensor(1.3307e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.67012449735074e-06\n",
            "E_s_wdiff_all_sq: 3.388453089776718e-07\n",
            "E_IS_SCOPE: -5.988028461405958e-07\n",
            "E_IS_E_SCOPE: 1.1057354207249696e-06\n",
            "Total Loss: 1.330666790620496e-06\n",
            "----------------------------------------\n",
            "Epoch 452\n",
            "Var loss:  tensor(1.3260e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6764452517959514e-06\n",
            "E_s_wdiff_all_sq: 3.464867799201417e-07\n",
            "E_IS_SCOPE: -5.980970440678996e-07\n",
            "E_IS_E_SCOPE: 1.1080969099132497e-06\n",
            "Total Loss: 1.3260346998920704e-06\n",
            "----------------------------------------\n",
            "Epoch 453\n",
            "Var loss:  tensor(1.3213e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6602887153357954e-06\n",
            "E_s_wdiff_all_sq: 3.384652210883837e-07\n",
            "E_IS_SCOPE: -5.697098015919344e-07\n",
            "E_IS_E_SCOPE: 1.1347735428484275e-06\n",
            "Total Loss: 1.3213209413452468e-06\n",
            "----------------------------------------\n",
            "Epoch 454\n",
            "Var loss:  tensor(1.3167e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6518039988815964e-06\n",
            "E_s_wdiff_all_sq: 3.358485190144739e-07\n",
            "E_IS_SCOPE: -5.494345060661692e-07\n",
            "E_IS_E_SCOPE: 1.154416602163211e-06\n",
            "Total Loss: 1.3167173993869206e-06\n",
            "----------------------------------------\n",
            "Epoch 455\n",
            "Var loss:  tensor(1.3121e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6734349789204215e-06\n",
            "E_s_wdiff_all_sq: 3.542595761603766e-07\n",
            "E_IS_SCOPE: -5.690013307291845e-07\n",
            "E_IS_E_SCOPE: 1.1387916937001761e-06\n",
            "Total Loss: 1.3120534898798826e-06\n",
            "----------------------------------------\n",
            "Epoch 456\n",
            "Var loss:  tensor(1.3073e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.67665439723695e-06\n",
            "E_s_wdiff_all_sq: 3.553254703187007e-07\n",
            "E_IS_SCOPE: -5.597407204733542e-07\n",
            "E_IS_E_SCOPE: 1.1514923032417123e-06\n",
            "Total Loss: 1.3073270154666756e-06\n",
            "----------------------------------------\n",
            "Epoch 457\n",
            "Var loss:  tensor(1.3028e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.656420350347485e-06\n",
            "E_s_wdiff_all_sq: 3.43169780077778e-07\n",
            "E_IS_SCOPE: -5.207055724448497e-07\n",
            "E_IS_E_SCOPE: 1.188765962374532e-06\n",
            "Total Loss: 1.3027716366095021e-06\n",
            "----------------------------------------\n",
            "Epoch 458\n",
            "Var loss:  tensor(1.2980e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.657639173793408e-06\n",
            "E_s_wdiff_all_sq: 3.5260250044506715e-07\n",
            "E_IS_SCOPE: -5.161867804789939e-07\n",
            "E_IS_E_SCOPE: 1.191563267272757e-06\n",
            "Total Loss: 1.2980007138233978e-06\n",
            "----------------------------------------\n",
            "Epoch 459\n",
            "Var loss:  tensor(1.2934e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6658378971273284e-06\n",
            "E_s_wdiff_all_sq: 3.589546642980271e-07\n",
            "E_IS_SCOPE: -5.137367652874253e-07\n",
            "E_IS_E_SCOPE: 1.1972563830260448e-06\n",
            "Total Loss: 1.2933610721809207e-06\n",
            "----------------------------------------\n",
            "Epoch 460\n",
            "Var loss:  tensor(1.2887e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.665170767759705e-06\n",
            "E_s_wdiff_all_sq: 3.547676503966962e-07\n",
            "E_IS_SCOPE: -4.98137472450447e-07\n",
            "E_IS_E_SCOPE: 1.2169301764082806e-06\n",
            "Total Loss: 1.2887319556241125e-06\n",
            "----------------------------------------\n",
            "Epoch 461\n",
            "Var loss:  tensor(1.2841e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.66337748467118e-06\n",
            "E_s_wdiff_all_sq: 3.593580316941041e-07\n",
            "E_IS_SCOPE: -4.930735032023892e-07\n",
            "E_IS_E_SCOPE: 1.2211358927371779e-06\n",
            "Total Loss: 1.2840647970765002e-06\n",
            "----------------------------------------\n",
            "Epoch 462\n",
            "Var loss:  tensor(1.2794e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6481303306288423e-06\n",
            "E_s_wdiff_all_sq: 3.5446873981014144e-07\n",
            "E_IS_SCOPE: -4.7517195383065676e-07\n",
            "E_IS_E_SCOPE: 1.2361773360811475e-06\n",
            "Total Loss: 1.2794271469736514e-06\n",
            "----------------------------------------\n",
            "Epoch 463\n",
            "Var loss:  tensor(1.2748e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6484291868625776e-06\n",
            "E_s_wdiff_all_sq: 3.5194010206331017e-07\n",
            "E_IS_SCOPE: -4.681770176758478e-07\n",
            "E_IS_E_SCOPE: 1.2469015048648512e-06\n",
            "Total Loss: 1.2747961756964282e-06\n",
            "----------------------------------------\n",
            "Epoch 464\n",
            "Var loss:  tensor(1.2701e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.655330293986913e-06\n",
            "E_s_wdiff_all_sq: 3.5588760831577515e-07\n",
            "E_IS_SCOPE: -4.770702681223267e-07\n",
            "E_IS_E_SCOPE: 1.2418190311004153e-06\n",
            "Total Loss: 1.2701282232042117e-06\n",
            "----------------------------------------\n",
            "Epoch 465\n",
            "Var loss:  tensor(1.2654e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6380200122257304e-06\n",
            "E_s_wdiff_all_sq: 3.453374052018818e-07\n",
            "E_IS_SCOPE: -4.542794409011055e-07\n",
            "E_IS_E_SCOPE: 1.2635779705779653e-06\n",
            "Total Loss: 1.2654319200442663e-06\n",
            "----------------------------------------\n",
            "Epoch 466\n",
            "Var loss:  tensor(1.2609e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6127329069354105e-06\n",
            "E_s_wdiff_all_sq: 3.296337368249763e-07\n",
            "E_IS_SCOPE: -4.1985657318941675e-07\n",
            "E_IS_E_SCOPE: 1.2954949301673838e-06\n",
            "Total Loss: 1.2608602993753916e-06\n",
            "----------------------------------------\n",
            "Epoch 467\n",
            "Var loss:  tensor(1.2561e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.624626709786013e-06\n",
            "E_s_wdiff_all_sq: 3.384330782440186e-07\n",
            "E_IS_SCOPE: -4.350812319838775e-07\n",
            "E_IS_E_SCOPE: 1.2841925473810677e-06\n",
            "Total Loss: 1.2561102087906624e-06\n",
            "----------------------------------------\n",
            "Epoch 468\n",
            "Var loss:  tensor(1.2514e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6274774965519695e-06\n",
            "E_s_wdiff_all_sq: 3.371782655468369e-07\n",
            "E_IS_SCOPE: -4.3615717909493693e-07\n",
            "E_IS_E_SCOPE: 1.287510435784748e-06\n",
            "Total Loss: 1.2514281372243222e-06\n",
            "----------------------------------------\n",
            "Epoch 469\n",
            "Var loss:  tensor(1.2467e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6090682181265514e-06\n",
            "E_s_wdiff_all_sq: 3.2606445907943604e-07\n",
            "E_IS_SCOPE: -4.112748865842019e-07\n",
            "E_IS_E_SCOPE: 1.3110980477202574e-06\n",
            "Total Loss: 1.2467220264167562e-06\n",
            "----------------------------------------\n",
            "Epoch 470\n",
            "Var loss:  tensor(1.2420e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6043023738013406e-06\n",
            "E_s_wdiff_all_sq: 3.306992658496966e-07\n",
            "E_IS_SCOPE: -4.093905695203989e-07\n",
            "E_IS_E_SCOPE: 1.310630979272599e-06\n",
            "Total Loss: 1.2420241463442078e-06\n",
            "----------------------------------------\n",
            "Epoch 471\n",
            "Var loss:  tensor(1.2373e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6028323969153168e-06\n",
            "E_s_wdiff_all_sq: 3.301461512934993e-07\n",
            "E_IS_SCOPE: -4.027179353864232e-07\n",
            "E_IS_E_SCOPE: 1.3191946959029834e-06\n",
            "Total Loss: 1.2373251190215627e-06\n",
            "----------------------------------------\n",
            "Epoch 472\n",
            "Var loss:  tensor(1.2326e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.602423585482048e-06\n",
            "E_s_wdiff_all_sq: 3.2613945801074136e-07\n",
            "E_IS_SCOPE: -3.894080461043317e-07\n",
            "E_IS_E_SCOPE: 1.3366518294729172e-06\n",
            "Total Loss: 1.2326285122953682e-06\n",
            "----------------------------------------\n",
            "Epoch 473\n",
            "Var loss:  tensor(1.2279e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6002941348766907e-06\n",
            "E_s_wdiff_all_sq: 3.2914595761856106e-07\n",
            "E_IS_SCOPE: -3.776772494163136e-07\n",
            "E_IS_E_SCOPE: 1.348196492851575e-06\n",
            "Total Loss: 1.227864828700911e-06\n",
            "----------------------------------------\n",
            "Epoch 474\n",
            "Var loss:  tensor(1.2233e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6062507022259564e-06\n",
            "E_s_wdiff_all_sq: 3.406286059980217e-07\n",
            "E_IS_SCOPE: -3.833109980330767e-07\n",
            "E_IS_E_SCOPE: 1.342087704079982e-06\n",
            "Total Loss: 1.2232888279803754e-06\n",
            "----------------------------------------\n",
            "Epoch 475\n",
            "Var loss:  tensor(1.2185e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5944311783900964e-06\n",
            "E_s_wdiff_all_sq: 3.260843579370695e-07\n",
            "E_IS_SCOPE: -3.6624450968369543e-07\n",
            "E_IS_E_SCOPE: 1.3629349348629589e-06\n",
            "Total Loss: 1.218452067338277e-06\n",
            "----------------------------------------\n",
            "Epoch 476\n",
            "Var loss:  tensor(1.2139e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.588392377153539e-06\n",
            "E_s_wdiff_all_sq: 3.1460288260310413e-07\n",
            "E_IS_SCOPE: -3.566548733662667e-07\n",
            "E_IS_E_SCOPE: 1.3774993597158968e-06\n",
            "Total Loss: 1.2139451643646664e-06\n",
            "----------------------------------------\n",
            "Epoch 477\n",
            "Var loss:  tensor(1.2091e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5858137149028245e-06\n",
            "E_s_wdiff_all_sq: 3.248301013552922e-07\n",
            "E_IS_SCOPE: -3.6759749803127946e-07\n",
            "E_IS_E_SCOPE: 1.3625722379761376e-06\n",
            "Total Loss: 1.2091082775112562e-06\n",
            "----------------------------------------\n",
            "Epoch 478\n",
            "Var loss:  tensor(1.2044e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5676226845114784e-06\n",
            "E_s_wdiff_all_sq: 3.1724046796797173e-07\n",
            "E_IS_SCOPE: -3.4928904516306433e-07\n",
            "E_IS_E_SCOPE: 1.3779278617553458e-06\n",
            "Total Loss: 1.2044125386852446e-06\n",
            "----------------------------------------\n",
            "Epoch 479\n",
            "Var loss:  tensor(1.1998e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.552115093582697e-06\n",
            "E_s_wdiff_all_sq: 2.9671958057661634e-07\n",
            "E_IS_SCOPE: -3.251725548647698e-07\n",
            "E_IS_E_SCOPE: 1.4068794512567106e-06\n",
            "Total Loss: 1.199755636741678e-06\n",
            "----------------------------------------\n",
            "Epoch 480\n",
            "Var loss:  tensor(1.1949e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5670716365731242e-06\n",
            "E_s_wdiff_all_sq: 3.058961915772816e-07\n",
            "E_IS_SCOPE: -3.4649380644341864e-07\n",
            "E_IS_E_SCOPE: 1.3908754326247297e-06\n",
            "Total Loss: 1.1949011028381054e-06\n",
            "----------------------------------------\n",
            "Epoch 481\n",
            "Var loss:  tensor(1.1903e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5522815306847804e-06\n",
            "E_s_wdiff_all_sq: 3.0303673931773955e-07\n",
            "E_IS_SCOPE: -3.3883030984845536e-07\n",
            "E_IS_E_SCOPE: 1.394873639808846e-06\n",
            "Total Loss: 1.1903010280309976e-06\n",
            "----------------------------------------\n",
            "Epoch 482\n",
            "Var loss:  tensor(1.1854e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5307691197474295e-06\n",
            "E_s_wdiff_all_sq: 2.8861386466366956e-07\n",
            "E_IS_SCOPE: -3.1332336215917054e-07\n",
            "E_IS_E_SCOPE: 1.4192689708507235e-06\n",
            "Total Loss: 1.1854347250425312e-06\n",
            "----------------------------------------\n",
            "Epoch 483\n",
            "Var loss:  tensor(1.1807e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5310952663841764e-06\n",
            "E_s_wdiff_all_sq: 2.856752674045547e-07\n",
            "E_IS_SCOPE: -3.112673245747488e-07\n",
            "E_IS_E_SCOPE: 1.4253444780443323e-06\n",
            "Total Loss: 1.1806605297200177e-06\n",
            "----------------------------------------\n",
            "Epoch 484\n",
            "Var loss:  tensor(1.1763e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5439879118109864e-06\n",
            "E_s_wdiff_all_sq: 2.9833835268361765e-07\n",
            "E_IS_SCOPE: -3.398376464326774e-07\n",
            "E_IS_E_SCOPE: 1.3990499782035256e-06\n",
            "Total Loss: 1.1763384458335222e-06\n",
            "----------------------------------------\n",
            "Epoch 485\n",
            "Var loss:  tensor(1.1717e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.523267616828793e-06\n",
            "E_s_wdiff_all_sq: 2.858504248740101e-07\n",
            "E_IS_SCOPE: -3.147568598110546e-07\n",
            "E_IS_E_SCOPE: 1.4223536613818165e-06\n",
            "Total Loss: 1.1716602855476002e-06\n",
            "----------------------------------------\n",
            "Epoch 486\n",
            "Var loss:  tensor(1.1669e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5111527833469365e-06\n",
            "E_s_wdiff_all_sq: 2.76095715784863e-07\n",
            "E_IS_SCOPE: -2.7971585854232595e-07\n",
            "E_IS_E_SCOPE: 1.4585743269271751e-06\n",
            "Total Loss: 1.1669408326016309e-06\n",
            "----------------------------------------\n",
            "Epoch 487\n",
            "Var loss:  tensor(1.1619e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5452715477127113e-06\n",
            "E_s_wdiff_all_sq: 3.063036292871815e-07\n",
            "E_IS_SCOPE: -3.035400612288751e-07\n",
            "E_IS_E_SCOPE: 1.4392440902151802e-06\n",
            "Total Loss: 1.1618637515159777e-06\n",
            "----------------------------------------\n",
            "Epoch 488\n",
            "Var loss:  tensor(1.1568e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5666294062931416e-06\n",
            "E_s_wdiff_all_sq: 3.313364607337118e-07\n",
            "E_IS_SCOPE: -2.9901660533893945e-07\n",
            "E_IS_E_SCOPE: 1.4444703338020722e-06\n",
            "Total Loss: 1.1567832032559658e-06\n",
            "----------------------------------------\n",
            "Epoch 489\n",
            "Var loss:  tensor(1.1520e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5522898352250197e-06\n",
            "E_s_wdiff_all_sq: 3.300578559025089e-07\n",
            "E_IS_SCOPE: -2.545240438189341e-07\n",
            "E_IS_E_SCOPE: 1.484806468037377e-06\n",
            "Total Loss: 1.152035091588448e-06\n",
            "----------------------------------------\n",
            "Epoch 490\n",
            "Var loss:  tensor(1.1472e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.574759226415247e-06\n",
            "E_s_wdiff_all_sq: 3.5124092545962335e-07\n",
            "E_IS_SCOPE: -2.560800460447048e-07\n",
            "E_IS_E_SCOPE: 1.486322406816008e-06\n",
            "Total Loss: 1.1471775312127564e-06\n",
            "----------------------------------------\n",
            "Epoch 491\n",
            "Var loss:  tensor(1.1425e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.6151598375966348e-06\n",
            "E_s_wdiff_all_sq: 3.837623745627552e-07\n",
            "E_IS_SCOPE: -2.7164040315312084e-07\n",
            "E_IS_E_SCOPE: 1.4770583163841091e-06\n",
            "Total Loss: 1.1424641599379786e-06\n",
            "----------------------------------------\n",
            "Epoch 492\n",
            "Var loss:  tensor(1.1377e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5966670072784368e-06\n",
            "E_s_wdiff_all_sq: 3.749540017223243e-07\n",
            "E_IS_SCOPE: -2.300635852588895e-07\n",
            "E_IS_E_SCOPE: 1.5161990752487697e-06\n",
            "Total Loss: 1.1376518205193522e-06\n",
            "----------------------------------------\n",
            "Epoch 493\n",
            "Var loss:  tensor(1.1329e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.563717018182249e-06\n",
            "E_s_wdiff_all_sq: 3.5065680614558654e-07\n",
            "E_IS_SCOPE: -1.753706522282408e-07\n",
            "E_IS_E_SCOPE: 1.5689563040878393e-06\n",
            "Total Loss: 1.1328704353830611e-06\n",
            "----------------------------------------\n",
            "Epoch 494\n",
            "Var loss:  tensor(1.1279e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5775804686306615e-06\n",
            "E_s_wdiff_all_sq: 3.5708371471849924e-07\n",
            "E_IS_SCOPE: -1.8871209763990661e-07\n",
            "E_IS_E_SCOPE: 1.5617980374542223e-06\n",
            "Total Loss: 1.1279406197024632e-06\n",
            "----------------------------------------\n",
            "Epoch 495\n",
            "Var loss:  tensor(1.1231e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5785497299628545e-06\n",
            "E_s_wdiff_all_sq: 3.554789180354352e-07\n",
            "E_IS_SCOPE: -1.9421090597116048e-07\n",
            "E_IS_E_SCOPE: 1.5600016057719315e-06\n",
            "Total Loss: 1.1231099244197943e-06\n",
            "----------------------------------------\n",
            "Epoch 496\n",
            "Var loss:  tensor(1.1181e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5383568396543407e-06\n",
            "E_s_wdiff_all_sq: 3.294208887378156e-07\n",
            "E_IS_SCOPE: -1.630648650978581e-07\n",
            "E_IS_E_SCOPE: 1.586567600342272e-06\n",
            "Total Loss: 1.1181351560148237e-06\n",
            "----------------------------------------\n",
            "Epoch 497\n",
            "Var loss:  tensor(1.1132e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5279845343856435e-06\n",
            "E_s_wdiff_all_sq: 3.2309526926079003e-07\n",
            "E_IS_SCOPE: -1.589709907138961e-07\n",
            "E_IS_E_SCOPE: 1.5910911524173708e-06\n",
            "Total Loss: 1.113229114840879e-06\n",
            "----------------------------------------\n",
            "Epoch 498\n",
            "Var loss:  tensor(1.1085e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5439871784071778e-06\n",
            "E_s_wdiff_all_sq: 3.3321895674672623e-07\n",
            "E_IS_SCOPE: -1.88579701816442e-07\n",
            "E_IS_E_SCOPE: 1.5667987083756743e-06\n",
            "Total Loss: 1.108475537254778e-06\n",
            "----------------------------------------\n",
            "Epoch 499\n",
            "Var loss:  tensor(1.1034e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5164694099650797e-06\n",
            "E_s_wdiff_all_sq: 3.115646712449736e-07\n",
            "E_IS_SCOPE: -1.578153267550474e-07\n",
            "E_IS_E_SCOPE: 1.5971700489893454e-06\n",
            "Total Loss: 1.1033981232098801e-06\n",
            "----------------------------------------\n",
            "Epoch 500\n",
            "Var loss:  tensor(1.0985e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.483104198168579e-06\n",
            "E_s_wdiff_all_sq: 2.8778581097846616e-07\n",
            "E_IS_SCOPE: -1.2972428091473122e-07\n",
            "E_IS_E_SCOPE: 1.622906243743605e-06\n",
            "Total Loss: 1.0985214738519987e-06\n",
            "----------------------------------------\n",
            "Epoch 501\n",
            "Var loss:  tensor(1.0936e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.4849916467112685e-06\n",
            "E_s_wdiff_all_sq: 2.872598495613236e-07\n",
            "E_IS_SCOPE: -1.452391977904693e-07\n",
            "E_IS_E_SCOPE: 1.6110820540271775e-06\n",
            "Total Loss: 1.09355342949321e-06\n",
            "----------------------------------------\n",
            "Epoch 502\n",
            "Var loss:  tensor(1.0886e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.478667769516438e-06\n",
            "E_s_wdiff_all_sq: 2.7883543588256686e-07\n",
            "E_IS_SCOPE: -1.432553024370776e-07\n",
            "E_IS_E_SCOPE: 1.6165959351903953e-06\n",
            "Total Loss: 1.088593994357484e-06\n",
            "----------------------------------------\n",
            "Epoch 503\n",
            "Var loss:  tensor(1.0837e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.4565458640844045e-06\n",
            "E_s_wdiff_all_sq: 2.631715958131597e-07\n",
            "E_IS_SCOPE: -1.1956570898491096e-07\n",
            "E_IS_E_SCOPE: 1.6395166137309017e-06\n",
            "Total Loss: 1.083673758818178e-06\n",
            "----------------------------------------\n",
            "Epoch 504\n",
            "Var loss:  tensor(1.0787e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.4548831351813566e-06\n",
            "E_s_wdiff_all_sq: 2.650946240422019e-07\n",
            "E_IS_SCOPE: -1.155052288157122e-07\n",
            "E_IS_E_SCOPE: 1.6442569100500567e-06\n",
            "Total Loss: 1.0787283693861757e-06\n",
            "----------------------------------------\n",
            "Epoch 505\n",
            "Var loss:  tensor(1.0738e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.465087808469193e-06\n",
            "E_s_wdiff_all_sq: 2.758110009278863e-07\n",
            "E_IS_SCOPE: -1.113295887784626e-07\n",
            "E_IS_E_SCOPE: 1.650629754236833e-06\n",
            "Total Loss: 1.073822257489274e-06\n",
            "----------------------------------------\n",
            "Epoch 506\n",
            "Var loss:  tensor(1.0688e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.4701431272946627e-06\n",
            "E_s_wdiff_all_sq: 2.8297003950673194e-07\n",
            "E_IS_SCOPE: -8.883718003764979e-08\n",
            "E_IS_E_SCOPE: 1.6745620430586162e-06\n",
            "Total Loss: 1.0688387775739574e-06\n",
            "----------------------------------------\n",
            "Epoch 507\n",
            "Var loss:  tensor(1.0639e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.479558632450947e-06\n",
            "E_s_wdiff_all_sq: 2.9625651263771743e-07\n",
            "E_IS_SCOPE: -7.411651194172792e-08\n",
            "E_IS_E_SCOPE: 1.689816200102954e-06\n",
            "Total Loss: 1.0639008317024248e-06\n",
            "----------------------------------------\n",
            "Epoch 508\n",
            "Var loss:  tensor(1.0589e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.494518711439973e-06\n",
            "E_s_wdiff_all_sq: 3.1697249082094597e-07\n",
            "E_IS_SCOPE: -7.161354398856198e-08\n",
            "E_IS_E_SCOPE: 1.6919241144335295e-06\n",
            "Total Loss: 1.0589350397534022e-06\n",
            "----------------------------------------\n",
            "Epoch 509\n",
            "Var loss:  tensor(1.0541e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5182283382487674e-06\n",
            "E_s_wdiff_all_sq: 3.4082589421245063e-07\n",
            "E_IS_SCOPE: -8.384262878065107e-08\n",
            "E_IS_E_SCOPE: 1.6820374974735112e-06\n",
            "Total Loss: 1.054106327506551e-06\n",
            "----------------------------------------\n",
            "Epoch 510\n",
            "Var loss:  tensor(1.0491e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.508065782611709e-06\n",
            "E_s_wdiff_all_sq: 3.326114617527011e-07\n",
            "E_IS_SCOPE: -4.860318181738458e-08\n",
            "E_IS_E_SCOPE: 1.7188263603833655e-06\n",
            "Total Loss: 1.0490593724360664e-06\n",
            "----------------------------------------\n",
            "Epoch 511\n",
            "Var loss:  tensor(1.0440e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.4972270238243245e-06\n",
            "E_s_wdiff_all_sq: 3.245245732985573e-07\n",
            "E_IS_SCOPE: -2.0794457659769346e-08\n",
            "E_IS_E_SCOPE: 1.7477772843165786e-06\n",
            "Total Loss: 1.0440231025516304e-06\n",
            "----------------------------------------\n",
            "Epoch 512\n",
            "Var loss:  tensor(1.0390e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5040246122140136e-06\n",
            "E_s_wdiff_all_sq: 3.2979533141986e-07\n",
            "E_IS_SCOPE: 1.7583021453380573e-09\n",
            "E_IS_E_SCOPE: 1.7735934405987265e-06\n",
            "Total Loss: 1.0390231398659363e-06\n",
            "----------------------------------------\n",
            "Epoch 513\n",
            "Var loss:  tensor(1.0338e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.511331025423321e-06\n",
            "E_s_wdiff_all_sq: 3.395054552692379e-07\n",
            "E_IS_SCOPE: 3.8476661175087284e-08\n",
            "E_IS_E_SCOPE: 1.8117166591286964e-06\n",
            "Total Loss: 1.033809710225424e-06\n",
            "----------------------------------------\n",
            "Epoch 514\n",
            "Var loss:  tensor(1.0286e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5241897883428174e-06\n",
            "E_s_wdiff_all_sq: 3.5620939611105895e-07\n",
            "E_IS_SCOPE: 6.920002924773044e-08\n",
            "E_IS_E_SCOPE: 1.8431176398549179e-06\n",
            "Total Loss: 1.028609306995943e-06\n",
            "----------------------------------------\n",
            "Epoch 515\n",
            "Var loss:  tensor(1.0233e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.529468609956791e-06\n",
            "E_s_wdiff_all_sq: 3.7248924205169757e-07\n",
            "E_IS_SCOPE: 9.132871273982721e-08\n",
            "E_IS_E_SCOPE: 1.8623799509293993e-06\n",
            "Total Loss: 1.0233410275045073e-06\n",
            "----------------------------------------\n",
            "Epoch 516\n",
            "Var loss:  tensor(1.0182e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5359721053216926e-06\n",
            "E_s_wdiff_all_sq: 3.755604612772865e-07\n",
            "E_IS_SCOPE: 1.0861843096253558e-07\n",
            "E_IS_E_SCOPE: 1.883935739862553e-06\n",
            "Total Loss: 1.0182411622229307e-06\n",
            "----------------------------------------\n",
            "Epoch 517\n",
            "Var loss:  tensor(1.0131e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.5167741066266598e-06\n",
            "E_s_wdiff_all_sq: 3.5432769309532145e-07\n",
            "E_IS_SCOPE: 1.6390066609524085e-07\n",
            "E_IS_E_SCOPE: 1.942788625242543e-06\n",
            "Total Loss: 1.0131346312152934e-06\n",
            "----------------------------------------\n",
            "Epoch 518\n",
            "Var loss:  tensor(1.0078e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.4989745680307993e-06\n",
            "E_s_wdiff_all_sq: 3.437604540204291e-07\n",
            "E_IS_SCOPE: 1.9395057051719974e-07\n",
            "E_IS_E_SCOPE: 1.971895286643644e-06\n",
            "Total Loss: 1.007788817736041e-06\n",
            "----------------------------------------\n",
            "Epoch 519\n",
            "Var loss:  tensor(1.0026e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.477694584050073e-06\n",
            "E_s_wdiff_all_sq: 3.2995746663107966e-07\n",
            "E_IS_SCOPE: 2.2807655885630748e-07\n",
            "E_IS_E_SCOPE: 2.0048924803563488e-06\n",
            "Total Loss: 1.002569410397469e-06\n",
            "----------------------------------------\n",
            "Epoch 520\n",
            "Var loss:  tensor(9.9739e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.4648311696786713e-06\n",
            "E_s_wdiff_all_sq: 3.1410498897722506e-07\n",
            "E_IS_SCOPE: 2.6342053454882864e-07\n",
            "E_IS_E_SCOPE: 2.0443224765256672e-06\n",
            "Total Loss: 9.973864327263275e-07\n",
            "----------------------------------------\n",
            "Epoch 521\n",
            "Var loss:  tensor(9.9241e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.4493259041314948e-06\n",
            "E_s_wdiff_all_sq: 2.998450127260865e-07\n",
            "E_IS_SCOPE: 2.9151293984649727e-07\n",
            "E_IS_E_SCOPE: 2.0742814270167033e-06\n",
            "Total Loss: 9.924080530435554e-07\n",
            "----------------------------------------\n",
            "Epoch 522\n",
            "Var loss:  tensor(9.8730e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.4340537426367405e-06\n",
            "E_s_wdiff_all_sq: 2.92550120950839e-07\n",
            "E_IS_SCOPE: 3.136378635543762e-07\n",
            "E_IS_E_SCOPE: 2.0949726417353936e-06\n",
            "Total Loss: 9.872982013024261e-07\n",
            "----------------------------------------\n",
            "Epoch 523\n",
            "Var loss:  tensor(9.8222e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.4107512852180625e-06\n",
            "E_s_wdiff_all_sq: 2.749367678009918e-07\n",
            "E_IS_SCOPE: 3.4875055307737153e-07\n",
            "E_IS_E_SCOPE: 2.129781434059878e-06\n",
            "Total Loss: 9.82216891430616e-07\n",
            "----------------------------------------\n",
            "Epoch 524\n",
            "Var loss:  tensor(9.7714e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.3881162221668003e-06\n",
            "E_s_wdiff_all_sq: 2.49648914192941e-07\n",
            "E_IS_SCOPE: 3.878757895189034e-07\n",
            "E_IS_E_SCOPE: 2.1727737457859645e-06\n",
            "Total Loss: 9.771355314182957e-07\n",
            "----------------------------------------\n",
            "Epoch 525\n",
            "Var loss:  tensor(9.7211e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.375535360053185e-06\n",
            "E_s_wdiff_all_sq: 2.3624399751505148e-07\n",
            "E_IS_SCOPE: 4.180962125437981e-07\n",
            "E_IS_E_SCOPE: 2.205921092099959e-06\n",
            "Total Loss: 9.721057394043713e-07\n",
            "----------------------------------------\n",
            "Epoch 526\n",
            "Var loss:  tensor(9.6697e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.374041214750001e-06\n",
            "E_s_wdiff_all_sq: 2.397109233794132e-07\n",
            "E_IS_SCOPE: 4.2220140820767134e-07\n",
            "E_IS_E_SCOPE: 2.2101135157819226e-06\n",
            "Total Loss: 9.669702122006458e-07\n",
            "----------------------------------------\n",
            "Epoch 527\n",
            "Var loss:  tensor(9.6186e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.3684811263663434e-06\n",
            "E_s_wdiff_all_sq: 2.406802859674399e-07\n",
            "E_IS_SCOPE: 4.303277070029541e-07\n",
            "E_IS_E_SCOPE: 2.2175326488834573e-06\n",
            "Total Loss: 9.618550926164564e-07\n",
            "----------------------------------------\n",
            "Epoch 528\n",
            "Var loss:  tensor(9.5683e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.358535269797179e-06\n",
            "E_s_wdiff_all_sq: 2.323200046314562e-07\n",
            "E_IS_SCOPE: 4.5110311429922485e-07\n",
            "E_IS_E_SCOPE: 2.240026973126505e-06\n",
            "Total Loss: 9.568316834897216e-07\n",
            "----------------------------------------\n",
            "Epoch 529\n",
            "Var loss:  tensor(9.5170e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.3620020369289875e-06\n",
            "E_s_wdiff_all_sq: 2.3250695195186088e-07\n",
            "E_IS_SCOPE: 4.504298982350662e-07\n",
            "E_IS_E_SCOPE: 2.2435584879318826e-06\n",
            "Total Loss: 9.51702041562053e-07\n",
            "----------------------------------------\n",
            "Epoch 530\n",
            "Var loss:  tensor(9.4662e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.3500387913000986e-06\n",
            "E_s_wdiff_all_sq: 2.2563479422573821e-07\n",
            "E_IS_SCOPE: 4.747231070875723e-07\n",
            "E_IS_E_SCOPE: 2.2678462701723916e-06\n",
            "Total Loss: 9.466218068832802e-07\n",
            "----------------------------------------\n",
            "Epoch 531\n",
            "Var loss:  tensor(9.4147e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.3196778271908347e-06\n",
            "E_s_wdiff_all_sq: 2.0390468247378302e-07\n",
            "E_IS_SCOPE: 5.249494163242715e-07\n",
            "E_IS_E_SCOPE: 2.316334840994085e-06\n",
            "Total Loss: 9.414664313559847e-07\n",
            "----------------------------------------\n",
            "Epoch 532\n",
            "Var loss:  tensor(9.3634e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.3218431358265216e-06\n",
            "E_s_wdiff_all_sq: 2.0243242527511517e-07\n",
            "E_IS_SCOPE: 5.280742812763871e-07\n",
            "E_IS_E_SCOPE: 2.323840154996881e-06\n",
            "Total Loss: 9.363430990889774e-07\n",
            "----------------------------------------\n",
            "Epoch 533\n",
            "Var loss:  tensor(9.3115e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.342172868691773e-06\n",
            "E_s_wdiff_all_sq: 2.194594294825539e-07\n",
            "E_IS_SCOPE: 4.967995098551083e-07\n",
            "E_IS_E_SCOPE: 2.296815094714371e-06\n",
            "Total Loss: 9.31146405469253e-07\n",
            "----------------------------------------\n",
            "Epoch 534\n",
            "Var loss:  tensor(9.2598e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.327762116871752e-06\n",
            "E_s_wdiff_all_sq: 2.170625207192059e-07\n",
            "E_IS_SCOPE: 5.13309360879156e-07\n",
            "E_IS_E_SCOPE: 2.309899750934738e-06\n",
            "Total Loss: 9.259829520199418e-07\n",
            "----------------------------------------\n",
            "Epoch 535\n",
            "Var loss:  tensor(9.2078e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.3119972708255965e-06\n",
            "E_s_wdiff_all_sq: 2.0564178625416984e-07\n",
            "E_IS_SCOPE: 5.501371890321096e-07\n",
            "E_IS_E_SCOPE: 2.3471558553751172e-06\n",
            "Total Loss: 9.207822878639707e-07\n",
            "----------------------------------------\n",
            "Epoch 536\n",
            "Var loss:  tensor(9.1558e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.3253801975728497e-06\n",
            "E_s_wdiff_all_sq: 2.109767497081109e-07\n",
            "E_IS_SCOPE: 5.562859486609559e-07\n",
            "E_IS_E_SCOPE: 2.3599284475257275e-06\n",
            "Total Loss: 9.155825861137541e-07\n",
            "----------------------------------------\n",
            "Epoch 537\n",
            "Var loss:  tensor(9.1059e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.337550332161378e-06\n",
            "E_s_wdiff_all_sq: 2.2528703872876508e-07\n",
            "E_IS_SCOPE: 5.46760145956851e-07\n",
            "E_IS_E_SCOPE: 2.3518266021462456e-06\n",
            "Total Loss: 9.105945170323835e-07\n",
            "----------------------------------------\n",
            "Epoch 538\n",
            "Var loss:  tensor(9.0516e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.314824321668004e-06\n",
            "E_s_wdiff_all_sq: 2.1680207403452635e-07\n",
            "E_IS_SCOPE: 5.844538868358498e-07\n",
            "E_IS_E_SCOPE: 2.3851159495944985e-06\n",
            "Total Loss: 9.051622580947388e-07\n",
            "----------------------------------------\n",
            "Epoch 539\n",
            "Var loss:  tensor(9.0024e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.321349796331393e-06\n",
            "E_s_wdiff_all_sq: 2.2059596149437426e-07\n",
            "E_IS_SCOPE: 5.964055187885204e-07\n",
            "E_IS_E_SCOPE: 2.4008938099048138e-06\n",
            "Total Loss: 9.002413885829908e-07\n",
            "----------------------------------------\n",
            "Epoch 540\n",
            "Var loss:  tensor(8.9482e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.363158581773909e-06\n",
            "E_s_wdiff_all_sq: 2.553644584754136e-07\n",
            "E_IS_SCOPE: 5.624322985627716e-07\n",
            "E_IS_E_SCOPE: 2.3731490307337948e-06\n",
            "Total Loss: 8.948247949350081e-07\n",
            "----------------------------------------\n",
            "Epoch 541\n",
            "Var loss:  tensor(8.8967e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.360509131830154e-06\n",
            "E_s_wdiff_all_sq: 2.671528440987714e-07\n",
            "E_IS_SCOPE: 5.925885455038943e-07\n",
            "E_IS_E_SCOPE: 2.3986643423545854e-06\n",
            "Total Loss: 8.896688300085596e-07\n",
            "----------------------------------------\n",
            "Epoch 542\n",
            "Var loss:  tensor(8.8446e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.3485736396592803e-06\n",
            "E_s_wdiff_all_sq: 2.6366212927795933e-07\n",
            "E_IS_SCOPE: 6.383123001918757e-07\n",
            "E_IS_E_SCOPE: 2.44277206711968e-06\n",
            "Total Loss: 8.84456112504271e-07\n",
            "----------------------------------------\n",
            "Epoch 543\n",
            "Var loss:  tensor(8.7920e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.382536755359707e-06\n",
            "E_s_wdiff_all_sq: 2.855849285969228e-07\n",
            "E_IS_SCOPE: 6.26025592869842e-07\n",
            "E_IS_E_SCOPE: 2.4391355105526775e-06\n",
            "Total Loss: 8.791961273756725e-07\n",
            "----------------------------------------\n",
            "Epoch 544\n",
            "Var loss:  tensor(8.7395e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.4111496776856536e-06\n",
            "E_s_wdiff_all_sq: 3.1385171851739187e-07\n",
            "E_IS_SCOPE: 6.07573696435432e-07\n",
            "E_IS_E_SCOPE: 2.4234816174814246e-06\n",
            "Total Loss: 8.739462530548367e-07\n",
            "----------------------------------------\n",
            "Epoch 545\n",
            "Var loss:  tensor(8.6865e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.39190018510043e-06\n",
            "E_s_wdiff_all_sq: 3.11750779570572e-07\n",
            "E_IS_SCOPE: 6.385865772324036e-07\n",
            "E_IS_E_SCOPE: 2.4485703763529165e-06\n",
            "Total Loss: 8.686459432673921e-07\n",
            "----------------------------------------\n",
            "Epoch 546\n",
            "Var loss:  tensor(8.6339e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.385550073317731e-06\n",
            "E_s_wdiff_all_sq: 3.049868780979512e-07\n",
            "E_IS_SCOPE: 6.631253473645205e-07\n",
            "E_IS_E_SCOPE: 2.475946060957529e-06\n",
            "Total Loss: 8.633859040123226e-07\n",
            "----------------------------------------\n",
            "Epoch 547\n",
            "Var loss:  tensor(8.5816e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.4136156409642333e-06\n",
            "E_s_wdiff_all_sq: 3.203966626129653e-07\n",
            "E_IS_SCOPE: 6.358985878724776e-07\n",
            "E_IS_E_SCOPE: 2.457660941943333e-06\n",
            "Total Loss: 8.581584061881171e-07\n",
            "----------------------------------------\n",
            "Epoch 548\n",
            "Var loss:  tensor(8.5293e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.4028237450551566e-06\n",
            "E_s_wdiff_all_sq: 3.181367955926596e-07\n",
            "E_IS_SCOPE: 6.598797607274771e-07\n",
            "E_IS_E_SCOPE: 2.479989448063332e-06\n",
            "Total Loss: 8.529317107693466e-07\n",
            "----------------------------------------\n",
            "Epoch 549\n",
            "Var loss:  tensor(8.4758e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.3742837054722646e-06\n",
            "E_s_wdiff_all_sq: 3.041193285133988e-07\n",
            "E_IS_SCOPE: 7.145141413028322e-07\n",
            "E_IS_E_SCOPE: 2.5300398215614535e-06\n",
            "Total Loss: 8.475771524201818e-07\n",
            "----------------------------------------\n",
            "Epoch 550\n",
            "Var loss:  tensor(8.4228e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.3886530909878345e-06\n",
            "E_s_wdiff_all_sq: 3.127574044352277e-07\n",
            "E_IS_SCOPE: 7.287337673638515e-07\n",
            "E_IS_E_SCOPE: 2.5497760318600706e-06\n",
            "Total Loss: 8.422752935387266e-07\n",
            "----------------------------------------\n",
            "Epoch 551\n",
            "Var loss:  tensor(8.3717e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.4096685433341626e-06\n",
            "E_s_wdiff_all_sq: 3.283089858929502e-07\n",
            "E_IS_SCOPE: 7.133035892236453e-07\n",
            "E_IS_E_SCOPE: 2.5396288049708485e-06\n",
            "Total Loss: 8.371732619253656e-07\n",
            "----------------------------------------\n",
            "Epoch 552\n",
            "Var loss:  tensor(8.3168e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.365715142557619e-06\n",
            "E_s_wdiff_all_sq: 3.001793636042781e-07\n",
            "E_IS_SCOPE: 7.635050298302513e-07\n",
            "E_IS_E_SCOPE: 2.5846628890965473e-06\n",
            "Total Loss: 8.316841963993083e-07\n",
            "----------------------------------------\n",
            "Epoch 553\n",
            "Var loss:  tensor(8.2655e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.3357859880676876e-06\n",
            "E_s_wdiff_all_sq: 2.7473434659939234e-07\n",
            "E_IS_SCOPE: 7.98510586119516e-07\n",
            "E_IS_E_SCOPE: 2.619993395727129e-06\n",
            "Total Loss: 8.265501582316279e-07\n",
            "----------------------------------------\n",
            "Epoch 554\n",
            "Var loss:  tensor(8.2112e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.360619460922551e-06\n",
            "E_s_wdiff_all_sq: 2.8695176854611784e-07\n",
            "E_IS_SCOPE: 7.580564628876725e-07\n",
            "E_IS_E_SCOPE: 2.588562026033967e-06\n",
            "Total Loss: 8.211207020624032e-07\n",
            "----------------------------------------\n",
            "Epoch 555\n",
            "Var loss:  tensor(8.1582e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.3360509003450214e-06\n",
            "E_s_wdiff_all_sq: 2.71697104015717e-07\n",
            "E_IS_SCOPE: 7.724734973689556e-07\n",
            "E_IS_E_SCOPE: 2.600971226624614e-06\n",
            "Total Loss: 8.158224737965464e-07\n",
            "----------------------------------------\n",
            "Epoch 556\n",
            "Var loss:  tensor(8.1054e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.293044923825829e-06\n",
            "E_s_wdiff_all_sq: 2.433512101694557e-07\n",
            "E_IS_SCOPE: 8.247794193773799e-07\n",
            "E_IS_E_SCOPE: 2.6485878266891566e-06\n",
            "Total Loss: 8.10541035011379e-07\n",
            "----------------------------------------\n",
            "Epoch 557\n",
            "Var loss:  tensor(8.0509e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.3237435271787477e-06\n",
            "E_s_wdiff_all_sq: 2.6078814302389933e-07\n",
            "E_IS_SCOPE: 8.093561853480716e-07\n",
            "E_IS_E_SCOPE: 2.6425205287706166e-06\n",
            "Total Loss: 8.050908332883164e-07\n",
            "----------------------------------------\n",
            "Epoch 558\n",
            "Var loss:  tensor(7.9986e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.3481078208938927e-06\n",
            "E_s_wdiff_all_sq: 2.835182640307836e-07\n",
            "E_IS_SCOPE: 7.974583444265722e-07\n",
            "E_IS_E_SCOPE: 2.6340576728982256e-06\n",
            "Total Loss: 7.998550358983602e-07\n",
            "----------------------------------------\n",
            "Epoch 559\n",
            "Var loss:  tensor(7.9425e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.3152878849611015e-06\n",
            "E_s_wdiff_all_sq: 2.7368967796703703e-07\n",
            "E_IS_SCOPE: 8.565788856113689e-07\n",
            "E_IS_E_SCOPE: 2.6844830769333082e-06\n",
            "Total Loss: 7.942539603287457e-07\n",
            "----------------------------------------\n",
            "Epoch 560\n",
            "Var loss:  tensor(7.8877e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.3196744874502874e-06\n",
            "E_s_wdiff_all_sq: 2.7581113541973036e-07\n",
            "E_IS_SCOPE: 8.801671849796558e-07\n",
            "E_IS_E_SCOPE: 2.7119456810305083e-06\n",
            "Total Loss: 7.887704959074106e-07\n",
            "----------------------------------------\n",
            "Epoch 561\n",
            "Var loss:  tensor(7.8307e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.359977945636433e-06\n",
            "E_s_wdiff_all_sq: 3.0120599238277874e-07\n",
            "E_IS_SCOPE: 8.540437190806817e-07\n",
            "E_IS_E_SCOPE: 2.696126083290906e-06\n",
            "Total Loss: 7.830713608117638e-07\n",
            "----------------------------------------\n",
            "Epoch 562\n",
            "Var loss:  tensor(7.7737e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.3434260313169704e-06\n",
            "E_s_wdiff_all_sq: 3.004792332012123e-07\n",
            "E_IS_SCOPE: 8.767247077018864e-07\n",
            "E_IS_E_SCOPE: 2.713744536288786e-06\n",
            "Total Loss: 7.773712769205187e-07\n",
            "----------------------------------------\n",
            "Epoch 563\n",
            "Var loss:  tensor(7.7156e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.3132141055767504e-06\n",
            "E_s_wdiff_all_sq: 2.839358197315507e-07\n",
            "E_IS_SCOPE: 9.284779350008981e-07\n",
            "E_IS_E_SCOPE: 2.7615714038299336e-06\n",
            "Total Loss: 7.715554841656873e-07\n",
            "----------------------------------------\n",
            "Epoch 564\n",
            "Var loss:  tensor(7.6568e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.327260328666214e-06\n",
            "E_s_wdiff_all_sq: 2.8459144578216434e-07\n",
            "E_IS_SCOPE: 9.183533886726573e-07\n",
            "E_IS_E_SCOPE: 2.7610791942494697e-06\n",
            "Total Loss: 7.656814077089839e-07\n",
            "----------------------------------------\n",
            "Epoch 565\n",
            "Var loss:  tensor(7.5985e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.313065907773008e-06\n",
            "E_s_wdiff_all_sq: 2.7111636150155737e-07\n",
            "E_IS_SCOPE: 9.275580941112353e-07\n",
            "E_IS_E_SCOPE: 2.772841870614562e-06\n",
            "Total Loss: 7.598461292433556e-07\n",
            "----------------------------------------\n",
            "Epoch 566\n",
            "Var loss:  tensor(7.5400e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2747675496398786e-06\n",
            "E_s_wdiff_all_sq: 2.4966599967107475e-07\n",
            "E_IS_SCOPE: 9.54882593483937e-07\n",
            "E_IS_E_SCOPE: 2.794666691557691e-06\n",
            "Total Loss: 7.539974897998555e-07\n",
            "----------------------------------------\n",
            "Epoch 567\n",
            "Var loss:  tensor(7.4809e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2758471234957413e-06\n",
            "E_s_wdiff_all_sq: 2.4919380508846974e-07\n",
            "E_IS_SCOPE: 9.528831033253221e-07\n",
            "E_IS_E_SCOPE: 2.796399307660811e-06\n",
            "Total Loss: 7.480850457148536e-07\n",
            "----------------------------------------\n",
            "Epoch 568\n",
            "Var loss:  tensor(7.4222e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.28534784546399e-06\n",
            "E_s_wdiff_all_sq: 2.5328436686638846e-07\n",
            "E_IS_SCOPE: 9.521969573341137e-07\n",
            "E_IS_E_SCOPE: 2.8013516714726305e-06\n",
            "Total Loss: 7.42218186299128e-07\n",
            "----------------------------------------\n",
            "Epoch 569\n",
            "Var loss:  tensor(7.3642e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.26876202014923e-06\n",
            "E_s_wdiff_all_sq: 2.474010169668449e-07\n",
            "E_IS_SCOPE: 9.620718804151543e-07\n",
            "E_IS_E_SCOPE: 2.8087732421960435e-06\n",
            "Total Loss: 7.364224155991663e-07\n",
            "----------------------------------------\n",
            "Epoch 570\n",
            "Var loss:  tensor(7.3059e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2380850026762347e-06\n",
            "E_s_wdiff_all_sq: 2.2708536917950652e-07\n",
            "E_IS_SCOPE: 9.879423762282973e-07\n",
            "E_IS_E_SCOPE: 2.8323774983897072e-06\n",
            "Total Loss: 7.305935251524686e-07\n",
            "----------------------------------------\n",
            "Epoch 571\n",
            "Var loss:  tensor(7.2476e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.242436625429426e-06\n",
            "E_s_wdiff_all_sq: 2.2283247953127813e-07\n",
            "E_IS_SCOPE: 9.719357859589976e-07\n",
            "E_IS_E_SCOPE: 2.8235881377075237e-06\n",
            "Total Loss: 7.247635783796555e-07\n",
            "----------------------------------------\n",
            "Epoch 572\n",
            "Var loss:  tensor(7.1895e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.245431335916404e-06\n",
            "E_s_wdiff_all_sq: 2.253343637762248e-07\n",
            "E_IS_SCOPE: 9.479160903770389e-07\n",
            "E_IS_E_SCOPE: 2.8027207618430355e-06\n",
            "Total Loss: 7.189517651867441e-07\n",
            "----------------------------------------\n",
            "Epoch 573\n",
            "Var loss:  tensor(7.1316e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2242145034961603e-06\n",
            "E_s_wdiff_all_sq: 2.179519422330686e-07\n",
            "E_IS_SCOPE: 9.536334886719746e-07\n",
            "E_IS_E_SCOPE: 2.8044152235614846e-06\n",
            "Total Loss: 7.131632274626307e-07\n",
            "----------------------------------------\n",
            "Epoch 574\n",
            "Var loss:  tensor(7.0751e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2175548987348582e-06\n",
            "E_s_wdiff_all_sq: 2.1357076724375218e-07\n",
            "E_IS_SCOPE: 9.55035417457024e-07\n",
            "E_IS_E_SCOPE: 2.8075069580042206e-06\n",
            "Total Loss: 7.075051863752712e-07\n",
            "----------------------------------------\n",
            "Epoch 575\n",
            "Var loss:  tensor(7.0162e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2443120809384886e-06\n",
            "E_s_wdiff_all_sq: 2.303126884631337e-07\n",
            "E_IS_SCOPE: 9.460544644619706e-07\n",
            "E_IS_E_SCOPE: 2.8064753725579298e-06\n",
            "Total Loss: 7.016217122619957e-07\n",
            "----------------------------------------\n",
            "Epoch 576\n",
            "Var loss:  tensor(6.9590e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.256966186647496e-06\n",
            "E_s_wdiff_all_sq: 2.4853295466455e-07\n",
            "E_IS_SCOPE: 9.605822843952324e-07\n",
            "E_IS_E_SCOPE: 2.8210821803351186e-06\n",
            "Total Loss: 6.958975760817337e-07\n",
            "----------------------------------------\n",
            "Epoch 577\n",
            "Var loss:  tensor(6.9018e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2481963600095037e-06\n",
            "E_s_wdiff_all_sq: 2.5245817604058577e-07\n",
            "E_IS_SCOPE: 9.953626566780299e-07\n",
            "E_IS_E_SCOPE: 2.8523734069939096e-06\n",
            "Total Loss: 6.901808193157171e-07\n",
            "----------------------------------------\n",
            "Epoch 578\n",
            "Var loss:  tensor(6.8444e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2630195807514883e-06\n",
            "E_s_wdiff_all_sq: 2.620398413360083e-07\n",
            "E_IS_SCOPE: 9.86636227250106e-07\n",
            "E_IS_E_SCOPE: 2.8491384384127056e-06\n",
            "Total Loss: 6.844394530688394e-07\n",
            "----------------------------------------\n",
            "Epoch 579\n",
            "Var loss:  tensor(6.7866e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.259966896968272e-06\n",
            "E_s_wdiff_all_sq: 2.5726983027610436e-07\n",
            "E_IS_SCOPE: 9.91336332246803e-07\n",
            "E_IS_E_SCOPE: 2.8575879645287056e-06\n",
            "Total Loss: 6.786579381069211e-07\n",
            "----------------------------------------\n",
            "Epoch 580\n",
            "Var loss:  tensor(6.7292e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2377891808439822e-06\n",
            "E_s_wdiff_all_sq: 2.460655023019545e-07\n",
            "E_IS_SCOPE: 1.0069740327810735e-06\n",
            "E_IS_E_SCOPE: 2.870607562117859e-06\n",
            "Total Loss: 6.729207558470156e-07\n",
            "----------------------------------------\n",
            "Epoch 581\n",
            "Var loss:  tensor(6.6717e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2396206617120114e-06\n",
            "E_s_wdiff_all_sq: 2.4896257524898126e-07\n",
            "E_IS_SCOPE: 1.0103404212662166e-06\n",
            "E_IS_E_SCOPE: 2.876318513696291e-06\n",
            "Total Loss: 6.671660375814393e-07\n",
            "----------------------------------------\n",
            "Epoch 582\n",
            "Var loss:  tensor(6.6145e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2515026209267924e-06\n",
            "E_s_wdiff_all_sq: 2.5508822580974487e-07\n",
            "E_IS_SCOPE: 1.0217880822326667e-06\n",
            "E_IS_E_SCOPE: 2.8935019958460915e-06\n",
            "Total Loss: 6.614507038687561e-07\n",
            "----------------------------------------\n",
            "Epoch 583\n",
            "Var loss:  tensor(6.5569e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2386554800298082e-06\n",
            "E_s_wdiff_all_sq: 2.496319742964593e-07\n",
            "E_IS_SCOPE: 1.056521790259119e-06\n",
            "E_IS_E_SCOPE: 2.9274197008362333e-06\n",
            "Total Loss: 6.556918205576788e-07\n",
            "----------------------------------------\n",
            "Epoch 584\n",
            "Var loss:  tensor(6.4997e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2346614154506105e-06\n",
            "E_s_wdiff_all_sq: 2.5247205584933055e-07\n",
            "E_IS_SCOPE: 1.0739716834098287e-06\n",
            "E_IS_E_SCOPE: 2.944314608438794e-06\n",
            "Total Loss: 6.499676455219086e-07\n",
            "----------------------------------------\n",
            "Epoch 585\n",
            "Var loss:  tensor(6.4424e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2544586100178715e-06\n",
            "E_s_wdiff_all_sq: 2.671753970777127e-07\n",
            "E_IS_SCOPE: 1.0605874796125552e-06\n",
            "E_IS_E_SCOPE: 2.9363394351522946e-06\n",
            "Total Loss: 6.442434378392392e-07\n",
            "----------------------------------------\n",
            "Epoch 586\n",
            "Var loss:  tensor(6.3832e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2328612122660064e-06\n",
            "E_s_wdiff_all_sq: 2.5190805239984467e-07\n",
            "E_IS_SCOPE: 1.091219356054754e-06\n",
            "E_IS_E_SCOPE: 2.9667690462757404e-06\n",
            "Total Loss: 6.383179154027489e-07\n",
            "----------------------------------------\n",
            "Epoch 587\n",
            "Var loss:  tensor(6.3260e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2186032915325535e-06\n",
            "E_s_wdiff_all_sq: 2.4297226274069125e-07\n",
            "E_IS_SCOPE: 1.1066325904542337e-06\n",
            "E_IS_E_SCOPE: 2.982381391458476e-06\n",
            "Total Loss: 6.325975627619371e-07\n",
            "----------------------------------------\n",
            "Epoch 588\n",
            "Var loss:  tensor(6.2667e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.245450229569289e-06\n",
            "E_s_wdiff_all_sq: 2.643781986539962e-07\n",
            "E_IS_SCOPE: 1.0828514917318629e-06\n",
            "E_IS_E_SCOPE: 2.9642866123561433e-06\n",
            "Total Loss: 6.26665925645291e-07\n",
            "----------------------------------------\n",
            "Epoch 589\n",
            "Var loss:  tensor(6.2087e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2506931005722597e-06\n",
            "E_s_wdiff_all_sq: 2.731598519289033e-07\n",
            "E_IS_SCOPE: 1.1001358648993774e-06\n",
            "E_IS_E_SCOPE: 2.9826987669571877e-06\n",
            "Total Loss: 6.208715805062946e-07\n",
            "----------------------------------------\n",
            "Epoch 590\n",
            "Var loss:  tensor(6.1496e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.224578514839616e-06\n",
            "E_s_wdiff_all_sq: 2.5776070367807746e-07\n",
            "E_IS_SCOPE: 1.1526845079833364e-06\n",
            "E_IS_E_SCOPE: 3.0328451075844708e-06\n",
            "Total Loss: 6.1496074793783e-07\n",
            "----------------------------------------\n",
            "Epoch 591\n",
            "Var loss:  tensor(6.0907e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2338171935493808e-06\n",
            "E_s_wdiff_all_sq: 2.6247295333835034e-07\n",
            "E_IS_SCOPE: 1.1577970066024917e-06\n",
            "E_IS_E_SCOPE: 3.0431653404325645e-06\n",
            "Total Loss: 6.090717085294444e-07\n",
            "----------------------------------------\n",
            "Epoch 592\n",
            "Var loss:  tensor(6.0319e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.255812124927235e-06\n",
            "E_s_wdiff_all_sq: 2.8037102912613373e-07\n",
            "E_IS_SCOPE: 1.1407861260691787e-06\n",
            "E_IS_E_SCOPE: 3.031144127141823e-06\n",
            "Total Loss: 6.031892296343713e-07\n",
            "----------------------------------------\n",
            "Epoch 593\n",
            "Var loss:  tensor(5.9724e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2373597155475642e-06\n",
            "E_s_wdiff_all_sq: 2.751042362829088e-07\n",
            "E_IS_SCOPE: 1.1687487227325792e-06\n",
            "E_IS_E_SCOPE: 3.0554879458425094e-06\n",
            "Total Loss: 5.972411690233541e-07\n",
            "----------------------------------------\n",
            "Epoch 594\n",
            "Var loss:  tensor(5.9135e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.236311794409092e-06\n",
            "E_s_wdiff_all_sq: 2.7554724281664347e-07\n",
            "E_IS_SCOPE: 1.1999130952292998e-06\n",
            "E_IS_E_SCOPE: 3.088854478596763e-06\n",
            "Total Loss: 5.913459208360809e-07\n",
            "----------------------------------------\n",
            "Epoch 595\n",
            "Var loss:  tensor(5.8534e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.259056513968531e-06\n",
            "E_s_wdiff_all_sq: 2.921823138868684e-07\n",
            "E_IS_SCOPE: 1.2016164648519363e-06\n",
            "E_IS_E_SCOPE: 3.096614818317503e-06\n",
            "Total Loss: 5.853416291290886e-07\n",
            "----------------------------------------\n",
            "Epoch 596\n",
            "Var loss:  tensor(5.7946e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2603674142689595e-06\n",
            "E_s_wdiff_all_sq: 2.9862288665872444e-07\n",
            "E_IS_SCOPE: 1.2186685531483593e-06\n",
            "E_IS_E_SCOPE: 3.1140406149983536e-06\n",
            "Total Loss: 5.794645398888054e-07\n",
            "----------------------------------------\n",
            "Epoch 597\n",
            "Var loss:  tensor(5.7351e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2493606345147583e-06\n",
            "E_s_wdiff_all_sq: 2.94017530014984e-07\n",
            "E_IS_SCOPE: 1.2583283525569934e-06\n",
            "E_IS_E_SCOPE: 3.1534770755035275e-06\n",
            "Total Loss: 5.735097945852653e-07\n",
            "----------------------------------------\n",
            "Epoch 598\n",
            "Var loss:  tensor(5.6760e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2648275807414475e-06\n",
            "E_s_wdiff_all_sq: 3.059412412976035e-07\n",
            "E_IS_SCOPE: 1.2515249232587657e-06\n",
            "E_IS_E_SCOPE: 3.1513992129459098e-06\n",
            "Total Loss: 5.67601896048115e-07\n",
            "----------------------------------------\n",
            "Epoch 599\n",
            "Var loss:  tensor(5.6170e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2683119282771434e-06\n",
            "E_s_wdiff_all_sq: 3.1193924330705117e-07\n",
            "E_IS_SCOPE: 1.2651455914750896e-06\n",
            "E_IS_E_SCOPE: 3.1667149436453927e-06\n",
            "Total Loss: 5.616981166080451e-07\n",
            "----------------------------------------\n",
            "Epoch 600\n",
            "Var loss:  tensor(5.5566e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.262860249660549e-06\n",
            "E_s_wdiff_all_sq: 3.1366037323848016e-07\n",
            "E_IS_SCOPE: 1.297199785871814e-06\n",
            "E_IS_E_SCOPE: 3.1982020546143883e-06\n",
            "Total Loss: 5.556594749154793e-07\n",
            "----------------------------------------\n",
            "Epoch 601\n",
            "Var loss:  tensor(5.4969e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2703606043011167e-06\n",
            "E_s_wdiff_all_sq: 3.2060713648989347e-07\n",
            "E_IS_SCOPE: 1.3235397288968974e-06\n",
            "E_IS_E_SCOPE: 3.2278022194288265e-06\n",
            "Total Loss: 5.496926227259242e-07\n",
            "----------------------------------------\n",
            "Epoch 602\n",
            "Var loss:  tensor(5.4372e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2697680734298e-06\n",
            "E_s_wdiff_all_sq: 3.196204264181271e-07\n",
            "E_IS_SCOPE: 1.3480231068186936e-06\n",
            "E_IS_E_SCOPE: 3.2554711827819735e-06\n",
            "Total Loss: 5.437156310636709e-07\n",
            "----------------------------------------\n",
            "Epoch 603\n",
            "Var loss:  tensor(5.3771e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2524601652807135e-06\n",
            "E_s_wdiff_all_sq: 3.073298066734993e-07\n",
            "E_IS_SCOPE: 1.3772414289651956e-06\n",
            "E_IS_E_SCOPE: 3.285184003140716e-06\n",
            "Total Loss: 5.377093462347327e-07\n",
            "----------------------------------------\n",
            "Epoch 604\n",
            "Var loss:  tensor(5.3169e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.24185760120832e-06\n",
            "E_s_wdiff_all_sq: 2.994421034708892e-07\n",
            "E_IS_SCOPE: 1.3884126024038948e-06\n",
            "E_IS_E_SCOPE: 3.2980070785378944e-06\n",
            "Total Loss: 5.316906814479915e-07\n",
            "----------------------------------------\n",
            "Epoch 605\n",
            "Var loss:  tensor(5.2563e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.248607857830798e-06\n",
            "E_s_wdiff_all_sq: 3.0396387269468115e-07\n",
            "E_IS_SCOPE: 1.3774438794764842e-06\n",
            "E_IS_E_SCOPE: 3.2911825218383936e-06\n",
            "Total Loss: 5.25630836390858e-07\n",
            "----------------------------------------\n",
            "Epoch 606\n",
            "Var loss:  tensor(5.1966e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2445200607587246e-06\n",
            "E_s_wdiff_all_sq: 3.0443667617570873e-07\n",
            "E_IS_SCOPE: 1.3795284815736202e-06\n",
            "E_IS_E_SCOPE: 3.2939715949572012e-06\n",
            "Total Loss: 5.196612937944133e-07\n",
            "----------------------------------------\n",
            "Epoch 607\n",
            "Var loss:  tensor(5.1370e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2339100196109417e-06\n",
            "E_s_wdiff_all_sq: 2.999064497742989e-07\n",
            "E_IS_SCOPE: 1.4005414695064846e-06\n",
            "E_IS_E_SCOPE: 3.3149260067031952e-06\n",
            "Total Loss: 5.13698631421781e-07\n",
            "----------------------------------------\n",
            "Epoch 608\n",
            "Var loss:  tensor(5.0767e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2474089085945262e-06\n",
            "E_s_wdiff_all_sq: 3.090719138220447e-07\n",
            "E_IS_SCOPE: 1.4111958381512922e-06\n",
            "E_IS_E_SCOPE: 3.330759768156135e-06\n",
            "Total Loss: 5.076732707413548e-07\n",
            "----------------------------------------\n",
            "Epoch 609\n",
            "Var loss:  tensor(5.0157e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2283751821163657e-06\n",
            "E_s_wdiff_all_sq: 2.941630005280119e-07\n",
            "E_IS_SCOPE: 1.461473452852798e-06\n",
            "E_IS_E_SCOPE: 3.3820260028339968e-06\n",
            "Total Loss: 5.015712176045159e-07\n",
            "----------------------------------------\n",
            "Epoch 610\n",
            "Var loss:  tensor(4.9555e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2253938355385383e-06\n",
            "E_s_wdiff_all_sq: 2.916215801783846e-07\n",
            "E_IS_SCOPE: 1.5021794932598151e-06\n",
            "E_IS_E_SCOPE: 3.4255246355886665e-06\n",
            "Total Loss: 4.955461066810106e-07\n",
            "----------------------------------------\n",
            "Epoch 611\n",
            "Var loss:  tensor(4.8957e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2369926623585634e-06\n",
            "E_s_wdiff_all_sq: 3.0349467552556477e-07\n",
            "E_IS_SCOPE: 1.509484363856347e-06\n",
            "E_IS_E_SCOPE: 3.435682227540257e-06\n",
            "Total Loss: 4.895663954437371e-07\n",
            "----------------------------------------\n",
            "Epoch 612\n",
            "Var loss:  tensor(4.8344e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2411539812723383e-06\n",
            "E_s_wdiff_all_sq: 3.1038036726619944e-07\n",
            "E_IS_SCOPE: 1.5276020175121659e-06\n",
            "E_IS_E_SCOPE: 3.4555013077409027e-06\n",
            "Total Loss: 4.834391695272244e-07\n",
            "----------------------------------------\n",
            "Epoch 613\n",
            "Var loss:  tensor(4.7742e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.236210509755638e-06\n",
            "E_s_wdiff_all_sq: 3.093381307434432e-07\n",
            "E_IS_SCOPE: 1.5509363462286457e-06\n",
            "E_IS_E_SCOPE: 3.4798957107565637e-06\n",
            "Total Loss: 4.77417785934918e-07\n",
            "----------------------------------------\n",
            "Epoch 614\n",
            "Var loss:  tensor(4.7144e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2411157037868107e-06\n",
            "E_s_wdiff_all_sq: 3.154044169670031e-07\n",
            "E_IS_SCOPE: 1.5601004371754655e-06\n",
            "E_IS_E_SCOPE: 3.491467353143743e-06\n",
            "Total Loss: 4.7144159086181054e-07\n",
            "----------------------------------------\n",
            "Epoch 615\n",
            "Var loss:  tensor(4.6542e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.255977162871443e-06\n",
            "E_s_wdiff_all_sq: 3.3002967116542693e-07\n",
            "E_IS_SCOPE: 1.5758054723984116e-06\n",
            "E_IS_E_SCOPE: 3.5103031986305652e-06\n",
            "Total Loss: 4.654161752202675e-07\n",
            "----------------------------------------\n",
            "Epoch 616\n",
            "Var loss:  tensor(4.5936e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.262139180139065e-06\n",
            "E_s_wdiff_all_sq: 3.3824121584286047e-07\n",
            "E_IS_SCOPE: 1.6241902957967752e-06\n",
            "E_IS_E_SCOPE: 3.560692986682212e-06\n",
            "Total Loss: 4.5935671850388954e-07\n",
            "----------------------------------------\n",
            "Epoch 617\n",
            "Var loss:  tensor(4.5343e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.258246892995184e-06\n",
            "E_s_wdiff_all_sq: 3.392610865360801e-07\n",
            "E_IS_SCOPE: 1.6825371484604408e-06\n",
            "E_IS_E_SCOPE: 3.619548082462443e-06\n",
            "Total Loss: 4.5342807443365795e-07\n",
            "----------------------------------------\n",
            "Epoch 618\n",
            "Var loss:  tensor(4.4742e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.271098463660864e-06\n",
            "E_s_wdiff_all_sq: 3.519092089353212e-07\n",
            "E_IS_SCOPE: 1.7017096076100197e-06\n",
            "E_IS_E_SCOPE: 3.6418239847815672e-06\n",
            "Total Loss: 4.474246363610073e-07\n",
            "----------------------------------------\n",
            "Epoch 619\n",
            "Var loss:  tensor(4.4137e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.260784366413786e-06\n",
            "E_s_wdiff_all_sq: 3.433957072542021e-07\n",
            "E_IS_SCOPE: 1.7395763553163468e-06\n",
            "E_IS_E_SCOPE: 3.6818182077071913e-06\n",
            "Total Loss: 4.4136909035645504e-07\n",
            "----------------------------------------\n",
            "Epoch 620\n",
            "Var loss:  tensor(4.3540e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.244331577786646e-06\n",
            "E_s_wdiff_all_sq: 3.2985247931569267e-07\n",
            "E_IS_SCOPE: 1.7742486251398483e-06\n",
            "E_IS_E_SCOPE: 3.7180184475059403e-06\n",
            "Total Loss: 4.3540358971732795e-07\n",
            "----------------------------------------\n",
            "Epoch 621\n",
            "Var loss:  tensor(4.2926e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2462736541017063e-06\n",
            "E_s_wdiff_all_sq: 3.328562377262064e-07\n",
            "E_IS_SCOPE: 1.7756284541919687e-06\n",
            "E_IS_E_SCOPE: 3.7219368639357985e-06\n",
            "Total Loss: 4.292647328663994e-07\n",
            "----------------------------------------\n",
            "Epoch 622\n",
            "Var loss:  tensor(4.2323e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2426472388389147e-06\n",
            "E_s_wdiff_all_sq: 3.3209011374722853e-07\n",
            "E_IS_SCOPE: 1.7713313656761881e-06\n",
            "E_IS_E_SCOPE: 3.7192249391182126e-06\n",
            "Total Loss: 4.232341141861951e-07\n",
            "----------------------------------------\n",
            "Epoch 623\n",
            "Var loss:  tensor(4.1723e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.225430846563035e-06\n",
            "E_s_wdiff_all_sq: 3.1664773408779603e-07\n",
            "E_IS_SCOPE: 1.7868687048432554e-06\n",
            "E_IS_E_SCOPE: 3.7368767815882548e-06\n",
            "Total Loss: 4.1723109496379933e-07\n",
            "----------------------------------------\n",
            "Epoch 624\n",
            "Var loss:  tensor(4.1117e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2266819022807336e-06\n",
            "E_s_wdiff_all_sq: 3.1524439814264154e-07\n",
            "E_IS_SCOPE: 1.800910216802975e-06\n",
            "E_IS_E_SCOPE: 3.755278054555724e-06\n",
            "Total Loss: 4.1116596461115303e-07\n",
            "----------------------------------------\n",
            "Epoch 625\n",
            "Var loss:  tensor(4.0515e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.232707061654333e-06\n",
            "E_s_wdiff_all_sq: 3.244018384611563e-07\n",
            "E_IS_SCOPE: 1.8212656364516573e-06\n",
            "E_IS_E_SCOPE: 3.7770748579451977e-06\n",
            "Total Loss: 4.0515091618465476e-07\n",
            "----------------------------------------\n",
            "Epoch 626\n",
            "Var loss:  tensor(3.9902e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2344898824431702e-06\n",
            "E_s_wdiff_all_sq: 3.307909705194295e-07\n",
            "E_IS_SCOPE: 1.8552415168141906e-06\n",
            "E_IS_E_SCOPE: 3.8118136778402394e-06\n",
            "Total Loss: 3.990187258502019e-07\n",
            "----------------------------------------\n",
            "Epoch 627\n",
            "Var loss:  tensor(3.9292e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.248367576496485e-06\n",
            "E_s_wdiff_all_sq: 3.43862129643813e-07\n",
            "E_IS_SCOPE: 1.8726897216058854e-06\n",
            "E_IS_E_SCOPE: 3.8327137779035945e-06\n",
            "Total Loss: 3.929214702358144e-07\n",
            "----------------------------------------\n",
            "Epoch 628\n",
            "Var loss:  tensor(3.8679e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.260869063382661e-06\n",
            "E_s_wdiff_all_sq: 3.6069737381370897e-07\n",
            "E_IS_SCOPE: 1.8801491230879224e-06\n",
            "E_IS_E_SCOPE: 3.8410706121151966e-06\n",
            "Total Loss: 3.8679284749296443e-07\n",
            "----------------------------------------\n",
            "Epoch 629\n",
            "Var loss:  tensor(3.8067e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.264616896994879e-06\n",
            "E_s_wdiff_all_sq: 3.682851366391215e-07\n",
            "E_IS_SCOPE: 1.8943935062112193e-06\n",
            "E_IS_E_SCOPE: 3.856456126225359e-06\n",
            "Total Loss: 3.8067065630603817e-07\n",
            "----------------------------------------\n",
            "Epoch 630\n",
            "Var loss:  tensor(3.7452e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2572150824266753e-06\n",
            "E_s_wdiff_all_sq: 3.607300366438496e-07\n",
            "E_IS_SCOPE: 1.9206233529533897e-06\n",
            "E_IS_E_SCOPE: 3.885836010835969e-06\n",
            "Total Loss: 3.745238659962272e-07\n",
            "----------------------------------------\n",
            "Epoch 631\n",
            "Var loss:  tensor(3.6834e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2580045290487592e-06\n",
            "E_s_wdiff_all_sq: 3.59086048450775e-07\n",
            "E_IS_SCOPE: 1.951631221834988e-06\n",
            "E_IS_E_SCOPE: 3.921153279813743e-06\n",
            "Total Loss: 3.683385006190324e-07\n",
            "----------------------------------------\n",
            "Epoch 632\n",
            "Var loss:  tensor(3.6217e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2549791378680485e-06\n",
            "E_s_wdiff_all_sq: 3.5994234711898803e-07\n",
            "E_IS_SCOPE: 1.9768041458399792e-06\n",
            "E_IS_E_SCOPE: 3.947470724443539e-06\n",
            "Total Loss: 3.621677695205016e-07\n",
            "----------------------------------------\n",
            "Epoch 633\n",
            "Var loss:  tensor(3.5599e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.245187905299043e-06\n",
            "E_s_wdiff_all_sq: 3.551960195024832e-07\n",
            "E_IS_SCOPE: 2.00172149623202e-06\n",
            "E_IS_E_SCOPE: 3.972956032475408e-06\n",
            "Total Loss: 3.559869492883433e-07\n",
            "----------------------------------------\n",
            "Epoch 634\n",
            "Var loss:  tensor(3.4981e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2465072993399152e-06\n",
            "E_s_wdiff_all_sq: 3.541057065301905e-07\n",
            "E_IS_SCOPE: 2.0272032385386057e-06\n",
            "E_IS_E_SCOPE: 4.002731448984982e-06\n",
            "Total Loss: 3.4980930789553057e-07\n",
            "----------------------------------------\n",
            "Epoch 635\n",
            "Var loss:  tensor(3.4356e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2491637759123156e-06\n",
            "E_s_wdiff_all_sq: 3.5752096802892586e-07\n",
            "E_IS_SCOPE: 2.029248788347472e-06\n",
            "E_IS_E_SCOPE: 4.007522705921879e-06\n",
            "Total Loss: 3.435591087131344e-07\n",
            "----------------------------------------\n",
            "Epoch 636\n",
            "Var loss:  tensor(3.3715e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.218155327345463e-06\n",
            "E_s_wdiff_all_sq: 3.3565485004275365e-07\n",
            "E_IS_SCOPE: 2.0627585028486317e-06\n",
            "E_IS_E_SCOPE: 4.039667479989844e-06\n",
            "Total Loss: 3.3714665899884415e-07\n",
            "----------------------------------------\n",
            "Epoch 637\n",
            "Var loss:  tensor(3.3083e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.214276610319048e-06\n",
            "E_s_wdiff_all_sq: 3.276810249641645e-07\n",
            "E_IS_SCOPE: 2.0687528059994885e-06\n",
            "E_IS_E_SCOPE: 4.0508692251862965e-06\n",
            "Total Loss: 3.3082688295982615e-07\n",
            "----------------------------------------\n",
            "Epoch 638\n",
            "Var loss:  tensor(3.2436e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.223425138507047e-06\n",
            "E_s_wdiff_all_sq: 3.367636720942219e-07\n",
            "E_IS_SCOPE: 2.0686714879413473e-06\n",
            "E_IS_E_SCOPE: 4.05405444516103e-06\n",
            "Total Loss: 3.243596879520188e-07\n",
            "----------------------------------------\n",
            "Epoch 639\n",
            "Var loss:  tensor(3.1793e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2005812260195713e-06\n",
            "E_s_wdiff_all_sq: 3.2630361330439466e-07\n",
            "E_IS_SCOPE: 2.097007097911657e-06\n",
            "E_IS_E_SCOPE: 4.079411682920377e-06\n",
            "Total Loss: 3.179325786762952e-07\n",
            "----------------------------------------\n",
            "Epoch 640\n",
            "Var loss:  tensor(3.1147e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2032392870881816e-06\n",
            "E_s_wdiff_all_sq: 3.2223829777810466e-07\n",
            "E_IS_SCOPE: 2.106631353276159e-06\n",
            "E_IS_E_SCOPE: 4.095627284646267e-06\n",
            "Total Loss: 3.114732625484206e-07\n",
            "----------------------------------------\n",
            "Epoch 641\n",
            "Var loss:  tensor(3.0500e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2165749105955744e-06\n",
            "E_s_wdiff_all_sq: 3.3160252721753573e-07\n",
            "E_IS_SCOPE: 2.1168202711440745e-06\n",
            "E_IS_E_SCOPE: 4.111037282931814e-06\n",
            "Total Loss: 3.050024957811201e-07\n",
            "----------------------------------------\n",
            "Epoch 642\n",
            "Var loss:  tensor(2.9852e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1985805243726655e-06\n",
            "E_s_wdiff_all_sq: 3.2944675124329226e-07\n",
            "E_IS_SCOPE: 2.151706422022086e-06\n",
            "E_IS_E_SCOPE: 4.141244383912663e-06\n",
            "Total Loss: 2.985219853267777e-07\n",
            "----------------------------------------\n",
            "Epoch 643\n",
            "Var loss:  tensor(2.9196e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2014093753835503e-06\n",
            "E_s_wdiff_all_sq: 3.2927412838136677e-07\n",
            "E_IS_SCOPE: 2.1714671013577705e-06\n",
            "E_IS_E_SCOPE: 4.165784430989039e-06\n",
            "Total Loss: 2.9196472371820533e-07\n",
            "----------------------------------------\n",
            "Epoch 644\n",
            "Var loss:  tensor(2.8548e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2153522326579296e-06\n",
            "E_s_wdiff_all_sq: 3.3625427255201523e-07\n",
            "E_IS_SCOPE: 2.176964936786311e-06\n",
            "E_IS_E_SCOPE: 4.1780076569731285e-06\n",
            "Total Loss: 2.854766557108393e-07\n",
            "----------------------------------------\n",
            "Epoch 645\n",
            "Var loss:  tensor(2.7891e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.207290320937804e-06\n",
            "E_s_wdiff_all_sq: 3.409992874475864e-07\n",
            "E_IS_SCOPE: 2.202420876625219e-06\n",
            "E_IS_E_SCOPE: 4.20034544887669e-06\n",
            "Total Loss: 2.789060249658347e-07\n",
            "----------------------------------------\n",
            "Epoch 646\n",
            "Var loss:  tensor(2.7237e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2219898924947574e-06\n",
            "E_s_wdiff_all_sq: 3.55972586045192e-07\n",
            "E_IS_SCOPE: 2.2196038711529585e-06\n",
            "E_IS_E_SCOPE: 4.220660610605615e-06\n",
            "Total Loss: 2.7236796352281136e-07\n",
            "----------------------------------------\n",
            "Epoch 647\n",
            "Var loss:  tensor(2.6578e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.242007600763104e-06\n",
            "E_s_wdiff_all_sq: 3.704228191913165e-07\n",
            "E_IS_SCOPE: 2.2257822598856357e-06\n",
            "E_IS_E_SCOPE: 4.2329164882856714e-06\n",
            "Total Loss: 2.6578046075027464e-07\n",
            "----------------------------------------\n",
            "Epoch 648\n",
            "Var loss:  tensor(2.5917e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.234759966936325e-06\n",
            "E_s_wdiff_all_sq: 3.711542004520499e-07\n",
            "E_IS_SCOPE: 2.247656604695954e-06\n",
            "E_IS_E_SCOPE: 4.254107199829561e-06\n",
            "Total Loss: 2.591687121956201e-07\n",
            "----------------------------------------\n",
            "Epoch 649\n",
            "Var loss:  tensor(2.5249e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2389468845821076e-06\n",
            "E_s_wdiff_all_sq: 3.772520219882266e-07\n",
            "E_IS_SCOPE: 2.270816283522902e-06\n",
            "E_IS_E_SCOPE: 4.27964868209955e-06\n",
            "Total Loss: 2.5249420141914345e-07\n",
            "----------------------------------------\n",
            "Epoch 650\n",
            "Var loss:  tensor(2.4587e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.246734408239045e-06\n",
            "E_s_wdiff_all_sq: 3.8188370945548316e-07\n",
            "E_IS_SCOPE: 2.284497072633958e-06\n",
            "E_IS_E_SCOPE: 4.298220488394748e-06\n",
            "Total Loss: 2.458680032405411e-07\n",
            "----------------------------------------\n",
            "Epoch 651\n",
            "Var loss:  tensor(2.3921e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2398732584382196e-06\n",
            "E_s_wdiff_all_sq: 3.8049429669704534e-07\n",
            "E_IS_SCOPE: 2.303701660149864e-06\n",
            "E_IS_E_SCOPE: 4.3180202019836855e-06\n",
            "Total Loss: 2.3920601405209076e-07\n",
            "----------------------------------------\n",
            "Epoch 652\n",
            "Var loss:  tensor(2.3257e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2570998837393893e-06\n",
            "E_s_wdiff_all_sq: 3.9763588834061256e-07\n",
            "E_IS_SCOPE: 2.302122399532701e-06\n",
            "E_IS_E_SCOPE: 4.319799633003183e-06\n",
            "Total Loss: 2.3257366443637271e-07\n",
            "----------------------------------------\n",
            "Epoch 653\n",
            "Var loss:  tensor(2.2572e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2487263200924656e-06\n",
            "E_s_wdiff_all_sq: 3.9350040767359296e-07\n",
            "E_IS_SCOPE: 2.325695806428968e-06\n",
            "E_IS_E_SCOPE: 4.344683054459093e-06\n",
            "Total Loss: 2.2571555233718153e-07\n",
            "----------------------------------------\n",
            "Epoch 654\n",
            "Var loss:  tensor(2.1893e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2412212393661758e-06\n",
            "E_s_wdiff_all_sq: 3.8879511596531374e-07\n",
            "E_IS_SCOPE: 2.3414048259137336e-06\n",
            "E_IS_E_SCOPE: 4.3623850673042e-06\n",
            "Total Loss: 2.1892977659848854e-07\n",
            "----------------------------------------\n",
            "Epoch 655\n",
            "Var loss:  tensor(2.1206e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2479970421876607e-06\n",
            "E_s_wdiff_all_sq: 3.947274892870171e-07\n",
            "E_IS_SCOPE: 2.3348581666094702e-06\n",
            "E_IS_E_SCOPE: 4.3596944993372585e-06\n",
            "Total Loss: 2.1206102342362628e-07\n",
            "----------------------------------------\n",
            "Epoch 656\n",
            "Var loss:  tensor(2.0520e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2339635315825162e-06\n",
            "E_s_wdiff_all_sq: 3.844018133698357e-07\n",
            "E_IS_SCOPE: 2.346557263040534e-06\n",
            "E_IS_E_SCOPE: 4.372971564161654e-06\n",
            "Total Loss: 2.0519725194900078e-07\n",
            "----------------------------------------\n",
            "Epoch 657\n",
            "Var loss:  tensor(1.9833e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2205388662363778e-06\n",
            "E_s_wdiff_all_sq: 3.7274134122040383e-07\n",
            "E_IS_SCOPE: 2.3740470411101714e-06\n",
            "E_IS_E_SCOPE: 4.403012227765751e-06\n",
            "Total Loss: 1.9833128768337412e-07\n",
            "----------------------------------------\n",
            "Epoch 658\n",
            "Var loss:  tensor(1.9140e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2248885560726926e-06\n",
            "E_s_wdiff_all_sq: 3.7549395818298113e-07\n",
            "E_IS_SCOPE: 2.379264954457476e-06\n",
            "E_IS_E_SCOPE: 4.412492695295546e-06\n",
            "Total Loss: 1.9140325219213023e-07\n",
            "----------------------------------------\n",
            "Epoch 659\n",
            "Var loss:  tensor(1.8447e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2205181739947852e-06\n",
            "E_s_wdiff_all_sq: 3.7681578702998515e-07\n",
            "E_IS_SCOPE: 2.3915451687938433e-06\n",
            "E_IS_E_SCOPE: 4.425391640058188e-06\n",
            "Total Loss: 1.8447358041466998e-07\n",
            "----------------------------------------\n",
            "Epoch 660\n",
            "Var loss:  tensor(1.7753e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2066982178729144e-06\n",
            "E_s_wdiff_all_sq: 3.657486106293631e-07\n",
            "E_IS_SCOPE: 2.417758113108464e-06\n",
            "E_IS_E_SCOPE: 4.4536987405378595e-06\n",
            "Total Loss: 1.7753248836331821e-07\n",
            "----------------------------------------\n",
            "Epoch 661\n",
            "Var loss:  tensor(1.7053e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.214022114399888e-06\n",
            "E_s_wdiff_all_sq: 3.6733575601006134e-07\n",
            "E_IS_SCOPE: 2.4426972488885567e-06\n",
            "E_IS_E_SCOPE: 4.485005305041184e-06\n",
            "Total Loss: 1.7053438206313275e-07\n",
            "----------------------------------------\n",
            "Epoch 662\n",
            "Var loss:  tensor(1.6354e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.206137412145002e-06\n",
            "E_s_wdiff_all_sq: 3.6865937071009277e-07\n",
            "E_IS_SCOPE: 2.468569393324447e-06\n",
            "E_IS_E_SCOPE: 4.509772171447652e-06\n",
            "Total Loss: 1.6353662116705657e-07\n",
            "----------------------------------------\n",
            "Epoch 663\n",
            "Var loss:  tensor(1.5649e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2124525750186468e-06\n",
            "E_s_wdiff_all_sq: 3.767388825823589e-07\n",
            "E_IS_SCOPE: 2.4754162560248673e-06\n",
            "E_IS_E_SCOPE: 4.519258361521757e-06\n",
            "Total Loss: 1.5649361742106732e-07\n",
            "----------------------------------------\n",
            "Epoch 664\n",
            "Var loss:  tensor(1.4945e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2248339704008734e-06\n",
            "E_s_wdiff_all_sq: 3.8490516519282626e-07\n",
            "E_IS_SCOPE: 2.474739778043193e-06\n",
            "E_IS_E_SCOPE: 4.524210960346207e-06\n",
            "Total Loss: 1.494505765805798e-07\n",
            "----------------------------------------\n",
            "Epoch 665\n",
            "Var loss:  tensor(1.4239e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2269800221462008e-06\n",
            "E_s_wdiff_all_sq: 3.9261517892597944e-07\n",
            "E_IS_SCOPE: 2.4994624871682766e-06\n",
            "E_IS_E_SCOPE: 4.549683695255213e-06\n",
            "Total Loss: 1.423865630249059e-07\n",
            "----------------------------------------\n",
            "Epoch 666\n",
            "Var loss:  tensor(1.3528e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.221661133561339e-06\n",
            "E_s_wdiff_all_sq: 3.944651808145178e-07\n",
            "E_IS_SCOPE: 2.528040470007649e-06\n",
            "E_IS_E_SCOPE: 4.578231325275946e-06\n",
            "Total Loss: 1.3527837818878599e-07\n",
            "----------------------------------------\n",
            "Epoch 667\n",
            "Var loss:  tensor(1.2816e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.230141934987435e-06\n",
            "E_s_wdiff_all_sq: 3.970999121424454e-07\n",
            "E_IS_SCOPE: 2.540352555526112e-06\n",
            "E_IS_E_SCOPE: 4.5970231660103335e-06\n",
            "Total Loss: 1.2816493785510673e-07\n",
            "----------------------------------------\n",
            "Epoch 668\n",
            "Var loss:  tensor(1.2104e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.222622133813054e-06\n",
            "E_s_wdiff_all_sq: 3.9312473121636056e-07\n",
            "E_IS_SCOPE: 2.5560931543532927e-06\n",
            "E_IS_E_SCOPE: 4.614554102840906e-06\n",
            "Total Loss: 1.2103964160002676e-07\n",
            "----------------------------------------\n",
            "Epoch 669\n",
            "Var loss:  tensor(1.1394e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.237442028358048e-06\n",
            "E_s_wdiff_all_sq: 4.085595275811587e-07\n",
            "E_IS_SCOPE: 2.5562405120262396e-06\n",
            "E_IS_E_SCOPE: 4.6179433188798005e-06\n",
            "Total Loss: 1.139410230483267e-07\n",
            "----------------------------------------\n",
            "Epoch 670\n",
            "Var loss:  tensor(1.0670e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.219833436629302e-06\n",
            "E_s_wdiff_all_sq: 3.9519493939255096e-07\n",
            "E_IS_SCOPE: 2.5888784987358574e-06\n",
            "E_IS_E_SCOPE: 4.652079872229377e-06\n",
            "Total Loss: 1.0669988622827038e-07\n",
            "----------------------------------------\n",
            "Epoch 671\n",
            "Var loss:  tensor(9.9560e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2179417698391487e-06\n",
            "E_s_wdiff_all_sq: 3.912730294567337e-07\n",
            "E_IS_SCOPE: 2.604621424182304e-06\n",
            "E_IS_E_SCOPE: 4.672407824936846e-06\n",
            "Total Loss: 9.956007485188981e-08\n",
            "----------------------------------------\n",
            "Epoch 672\n",
            "Var loss:  tensor(9.2390e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.239969242618583e-06\n",
            "E_s_wdiff_all_sq: 4.120811604776457e-07\n",
            "E_IS_SCOPE: 2.6093328720222905e-06\n",
            "E_IS_E_SCOPE: 4.681313856339143e-06\n",
            "Total Loss: 9.239024948578986e-08\n",
            "----------------------------------------\n",
            "Epoch 673\n",
            "Var loss:  tensor(8.5174e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.218249656883264e-06\n",
            "E_s_wdiff_all_sq: 4.0388497269451034e-07\n",
            "E_IS_SCOPE: 2.648579602258282e-06\n",
            "E_IS_E_SCOPE: 4.717406843806228e-06\n",
            "Total Loss: 8.517433707141983e-08\n",
            "----------------------------------------\n",
            "Epoch 674\n",
            "Var loss:  tensor(7.8165e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.219244329124313e-06\n",
            "E_s_wdiff_all_sq: 3.9907255397436496e-07\n",
            "E_IS_SCOPE: 2.6618092943317736e-06\n",
            "E_IS_E_SCOPE: 4.737044733077263e-06\n",
            "Total Loss: 7.816503363752776e-08\n",
            "----------------------------------------\n",
            "Epoch 675\n",
            "Var loss:  tensor(7.1034e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2311028027516063e-06\n",
            "E_s_wdiff_all_sq: 4.0752270807000004e-07\n",
            "E_IS_SCOPE: 2.6497953447688235e-06\n",
            "E_IS_E_SCOPE: 4.7303003501949066e-06\n",
            "Total Loss: 7.103421980800053e-08\n",
            "----------------------------------------\n",
            "Epoch 676\n",
            "Var loss:  tensor(6.4026e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2136506769488574e-06\n",
            "E_s_wdiff_all_sq: 4.019766030158652e-07\n",
            "E_IS_SCOPE: 2.658413986767181e-06\n",
            "E_IS_E_SCOPE: 4.736470318388636e-06\n",
            "Total Loss: 6.402554666864195e-08\n",
            "----------------------------------------\n",
            "Epoch 677\n",
            "Var loss:  tensor(5.6904e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.217226240723488e-06\n",
            "E_s_wdiff_all_sq: 3.991001956603457e-07\n",
            "E_IS_SCOPE: 2.677503019811535e-06\n",
            "E_IS_E_SCOPE: 4.762345948756039e-06\n",
            "Total Loss: 5.690432315269246e-08\n",
            "----------------------------------------\n",
            "Epoch 678\n",
            "Var loss:  tensor(4.9829e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2259802611471376e-06\n",
            "E_s_wdiff_all_sq: 4.0558208641675033e-07\n",
            "E_IS_SCOPE: 2.7181638404328417e-06\n",
            "E_IS_E_SCOPE: 4.8076806572741305e-06\n",
            "Total Loss: 4.9828677026369124e-08\n",
            "----------------------------------------\n",
            "Epoch 679\n",
            "Var loss:  tensor(4.2727e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2160419020424935e-06\n",
            "E_s_wdiff_all_sq: 4.1104971141012735e-07\n",
            "E_IS_SCOPE: 2.755885116637818e-06\n",
            "E_IS_E_SCOPE: 4.84124982964535e-06\n",
            "Total Loss: 4.272690059586125e-08\n",
            "----------------------------------------\n",
            "Epoch 680\n",
            "Var loss:  tensor(3.5568e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.232510576964226e-06\n",
            "E_s_wdiff_all_sq: 4.2220155578569636e-07\n",
            "E_IS_SCOPE: 2.7600485524319895e-06\n",
            "E_IS_E_SCOPE: 4.85165121203897e-06\n",
            "Total Loss: 3.55678379431267e-08\n",
            "----------------------------------------\n",
            "Epoch 681\n",
            "Var loss:  tensor(2.8353e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.234523568397558e-06\n",
            "E_s_wdiff_all_sq: 4.1878277227783956e-07\n",
            "E_IS_SCOPE: 2.765806558426553e-06\n",
            "E_IS_E_SCOPE: 4.863732584522189e-06\n",
            "Total Loss: 2.8352879907004707e-08\n",
            "----------------------------------------\n",
            "Epoch 682\n",
            "Var loss:  tensor(2.1068e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.2138873931998373e-06\n",
            "E_s_wdiff_all_sq: 4.1079884777412644e-07\n",
            "E_IS_SCOPE: 2.7784712623707886e-06\n",
            "E_IS_E_SCOPE: 4.873713697461967e-06\n",
            "Total Loss: 2.1067811221913172e-08\n",
            "----------------------------------------\n",
            "Epoch 683\n",
            "Var loss:  tensor(1.3764e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.218517778787585e-06\n",
            "E_s_wdiff_all_sq: 4.1361715760921757e-07\n",
            "E_IS_SCOPE: 2.7657590317054747e-06\n",
            "E_IS_E_SCOPE: 4.865559470430571e-06\n",
            "Total Loss: 1.3763879706734249e-08\n",
            "----------------------------------------\n",
            "Epoch 684\n",
            "Var loss:  tensor(6.4754e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.216419957893575e-06\n",
            "E_s_wdiff_all_sq: 4.0593360974084905e-07\n",
            "E_IS_SCOPE: 2.764133565171533e-06\n",
            "E_IS_E_SCOPE: 4.870371088192987e-06\n",
            "Total Loss: 6.4754380883766755e-09\n",
            "----------------------------------------\n",
            "Epoch 685\n",
            "Var loss:  tensor(-8.7346e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.192023810815136e-06\n",
            "E_s_wdiff_all_sq: 3.917722140356828e-07\n",
            "E_IS_SCOPE: 2.8005205297130975e-06\n",
            "E_IS_E_SCOPE: 4.905315125480908e-06\n",
            "Total Loss: -8.734587776073519e-10\n",
            "----------------------------------------\n",
            "Epoch 686\n",
            "Var loss:  tensor(-8.1300e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.198966065080738e-06\n",
            "E_s_wdiff_all_sq: 3.9721632945296996e-07\n",
            "E_IS_SCOPE: 2.8222695926208903e-06\n",
            "E_IS_E_SCOPE: 4.931441543804423e-06\n",
            "Total Loss: -8.130030760738776e-09\n",
            "----------------------------------------\n",
            "Epoch 687\n",
            "Var loss:  tensor(-1.5540e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.19664384581796e-06\n",
            "E_s_wdiff_all_sq: 3.9372311542898034e-07\n",
            "E_IS_SCOPE: 2.842225184623148e-06\n",
            "E_IS_E_SCOPE: 4.955687696675159e-06\n",
            "Total Loss: -1.5540157736482686e-08\n",
            "----------------------------------------\n",
            "Epoch 688\n",
            "Var loss:  tensor(-2.2913e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1758770228611676e-06\n",
            "E_s_wdiff_all_sq: 3.7833399758750514e-07\n",
            "E_IS_SCOPE: 2.8642699617149128e-06\n",
            "E_IS_E_SCOPE: 4.978730044557252e-06\n",
            "Total Loss: -2.2913004432458894e-08\n",
            "----------------------------------------\n",
            "Epoch 689\n",
            "Var loss:  tensor(-3.0377e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.165711171252185e-06\n",
            "E_s_wdiff_all_sq: 3.701717544263617e-07\n",
            "E_IS_SCOPE: 2.8625782464171955e-06\n",
            "E_IS_E_SCOPE: 4.979768379703445e-06\n",
            "Total Loss: -3.0376713768115125e-08\n",
            "----------------------------------------\n",
            "Epoch 690\n",
            "Var loss:  tensor(-3.7802e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1578267367809873e-06\n",
            "E_s_wdiff_all_sq: 3.611305089646108e-07\n",
            "E_IS_SCOPE: 2.8568876364340063e-06\n",
            "E_IS_E_SCOPE: 4.978368821670012e-06\n",
            "Total Loss: -3.780200667707595e-08\n",
            "----------------------------------------\n",
            "Epoch 691\n",
            "Var loss:  tensor(-4.5234e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.142587040652238e-06\n",
            "E_s_wdiff_all_sq: 3.48900420131752e-07\n",
            "E_IS_SCOPE: 2.8638578739285097e-06\n",
            "E_IS_E_SCOPE: 4.987550066043329e-06\n",
            "Total Loss: -4.523362773059468e-08\n",
            "----------------------------------------\n",
            "Epoch 692\n",
            "Var loss:  tensor(-5.2582e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1343480863200594e-06\n",
            "E_s_wdiff_all_sq: 3.44549991828731e-07\n",
            "E_IS_SCOPE: 2.8698952818452054e-06\n",
            "E_IS_E_SCOPE: 4.995317220430851e-06\n",
            "Total Loss: -5.258164670140358e-08\n",
            "----------------------------------------\n",
            "Epoch 693\n",
            "Var loss:  tensor(-6.0074e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1532292420893308e-06\n",
            "E_s_wdiff_all_sq: 3.588089947823437e-07\n",
            "E_IS_SCOPE: 2.8770197534503663e-06\n",
            "E_IS_E_SCOPE: 5.008499089993374e-06\n",
            "Total Loss: -6.007428980046829e-08\n",
            "----------------------------------------\n",
            "Epoch 694\n",
            "Var loss:  tensor(-6.7624e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1540187497757097e-06\n",
            "E_s_wdiff_all_sq: 3.647603869189331e-07\n",
            "E_IS_SCOPE: 2.925601228676869e-06\n",
            "E_IS_E_SCOPE: 5.058274287775611e-06\n",
            "Total Loss: -6.762361936214938e-08\n",
            "----------------------------------------\n",
            "Epoch 695\n",
            "Var loss:  tensor(-7.5057e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1461448107593807e-06\n",
            "E_s_wdiff_all_sq: 3.627639499753416e-07\n",
            "E_IS_SCOPE: 2.9727680416739703e-06\n",
            "E_IS_E_SCOPE: 5.106218838060197e-06\n",
            "Total Loss: -7.505659600985647e-08\n",
            "----------------------------------------\n",
            "Epoch 696\n",
            "Var loss:  tensor(-8.2509e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.168610354038713e-06\n",
            "E_s_wdiff_all_sq: 3.771637732812805e-07\n",
            "E_IS_SCOPE: 2.9760128338689633e-06\n",
            "E_IS_E_SCOPE: 5.117222726946844e-06\n",
            "Total Loss: -8.250906941977129e-08\n",
            "----------------------------------------\n",
            "Epoch 697\n",
            "Var loss:  tensor(-9.0098e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1631263389906168e-06\n",
            "E_s_wdiff_all_sq: 3.7886717648543557e-07\n",
            "E_IS_SCOPE: 2.9903937979974394e-06\n",
            "E_IS_E_SCOPE: 5.131804516063354e-06\n",
            "Total Loss: -9.009813764808906e-08\n",
            "----------------------------------------\n",
            "Epoch 698\n",
            "Var loss:  tensor(-9.7598e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1513108983343003e-06\n",
            "E_s_wdiff_all_sq: 3.7246799101047157e-07\n",
            "E_IS_SCOPE: 3.003060633319871e-06\n",
            "E_IS_E_SCOPE: 5.1455130753156614e-06\n",
            "Total Loss: -9.759784068919363e-08\n",
            "----------------------------------------\n",
            "Epoch 699\n",
            "Var loss:  tensor(-1.0518e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1694999826964936e-06\n",
            "E_s_wdiff_all_sq: 3.824302165580049e-07\n",
            "E_IS_SCOPE: 2.986393996952071e-06\n",
            "E_IS_E_SCOPE: 5.136752657404982e-06\n",
            "Total Loss: -1.0518341878877455e-07\n",
            "----------------------------------------\n",
            "Epoch 700\n",
            "Var loss:  tensor(-1.1276e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1634131803429882e-06\n",
            "E_s_wdiff_all_sq: 3.849534748473212e-07\n",
            "E_IS_SCOPE: 2.991501467808162e-06\n",
            "E_IS_E_SCOPE: 5.141343473501514e-06\n",
            "Total Loss: -1.1276016991247555e-07\n",
            "----------------------------------------\n",
            "Epoch 701\n",
            "Var loss:  tensor(-1.2051e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.168711884278917e-06\n",
            "E_s_wdiff_all_sq: 3.909251585004982e-07\n",
            "E_IS_SCOPE: 3.017478458870808e-06\n",
            "E_IS_E_SCOPE: 5.170856621322277e-06\n",
            "Total Loss: -1.2050546314596074e-07\n",
            "----------------------------------------\n",
            "Epoch 702\n",
            "Var loss:  tensor(-1.2818e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.187866968294477e-06\n",
            "E_s_wdiff_all_sq: 4.036823321257661e-07\n",
            "E_IS_SCOPE: 3.05396627639253e-06\n",
            "E_IS_E_SCOPE: 5.214383083334594e-06\n",
            "Total Loss: -1.2818484173686007e-07\n",
            "----------------------------------------\n",
            "Epoch 703\n",
            "Var loss:  tensor(-1.3586e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.176922352476698e-06\n",
            "E_s_wdiff_all_sq: 4.0422159818280197e-07\n",
            "E_IS_SCOPE: 3.0968558740180356e-06\n",
            "E_IS_E_SCOPE: 5.25536605419755e-06\n",
            "Total Loss: -1.3585547008657246e-07\n",
            "----------------------------------------\n",
            "Epoch 704\n",
            "Var loss:  tensor(-1.4361e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.186610518042121e-06\n",
            "E_s_wdiff_all_sq: 4.102687798323156e-07\n",
            "E_IS_SCOPE: 3.1049086105441973e-06\n",
            "E_IS_E_SCOPE: 5.269117003515328e-06\n",
            "Total Loss: -1.4361091175389688e-07\n",
            "----------------------------------------\n",
            "Epoch 705\n",
            "Var loss:  tensor(-1.5143e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1802172087106727e-06\n",
            "E_s_wdiff_all_sq: 4.0188429889342385e-07\n",
            "E_IS_SCOPE: 3.1130656673006285e-06\n",
            "E_IS_E_SCOPE: 5.282177455153178e-06\n",
            "Total Loss: -1.5142652990929133e-07\n",
            "----------------------------------------\n",
            "Epoch 706\n",
            "Var loss:  tensor(-1.5928e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1452255888893165e-06\n",
            "E_s_wdiff_all_sq: 3.803186916924095e-07\n",
            "E_IS_SCOPE: 3.1314473245382724e-06\n",
            "E_IS_E_SCOPE: 5.297772148867724e-06\n",
            "Total Loss: -1.592786154834378e-07\n",
            "----------------------------------------\n",
            "Epoch 707\n",
            "Var loss:  tensor(-1.6709e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.155409829654846e-06\n",
            "E_s_wdiff_all_sq: 3.81153807022229e-07\n",
            "E_IS_SCOPE: 3.106863489872129e-06\n",
            "E_IS_E_SCOPE: 5.281770723597994e-06\n",
            "Total Loss: -1.6709430884055352e-07\n",
            "----------------------------------------\n",
            "Epoch 708\n",
            "Var loss:  tensor(-1.7503e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.136453626385599e-06\n",
            "E_s_wdiff_all_sq: 3.667476783225624e-07\n",
            "E_IS_SCOPE: 3.1179172153262666e-06\n",
            "E_IS_E_SCOPE: 5.294516746641607e-06\n",
            "Total Loss: -1.7502897858908568e-07\n",
            "----------------------------------------\n",
            "Epoch 709\n",
            "Var loss:  tensor(-1.8296e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1241163914761923e-06\n",
            "E_s_wdiff_all_sq: 3.592087020909724e-07\n",
            "E_IS_SCOPE: 3.1573390198471316e-06\n",
            "E_IS_E_SCOPE: 5.335505638050516e-06\n",
            "Total Loss: -1.8296141104298901e-07\n",
            "----------------------------------------\n",
            "Epoch 710\n",
            "Var loss:  tensor(-1.9092e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.124286545389344e-06\n",
            "E_s_wdiff_all_sq: 3.587385404126041e-07\n",
            "E_IS_SCOPE: 3.185488271773368e-06\n",
            "E_IS_E_SCOPE: 5.367954355410877e-06\n",
            "Total Loss: -1.909200263197181e-07\n",
            "----------------------------------------\n",
            "Epoch 711\n",
            "Var loss:  tensor(-1.9889e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1226179705285843e-06\n",
            "E_s_wdiff_all_sq: 3.5597927412710063e-07\n",
            "E_IS_SCOPE: 3.2109899538314583e-06\n",
            "E_IS_E_SCOPE: 5.39798661134649e-06\n",
            "Total Loss: -1.9889048265002177e-07\n",
            "----------------------------------------\n",
            "Epoch 712\n",
            "Var loss:  tensor(-2.0691e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.105652481774636e-06\n",
            "E_s_wdiff_all_sq: 3.4397952088840187e-07\n",
            "E_IS_SCOPE: 3.243341585794253e-06\n",
            "E_IS_E_SCOPE: 5.431867492194809e-06\n",
            "Total Loss: -2.0691471593631847e-07\n",
            "----------------------------------------\n",
            "Epoch 713\n",
            "Var loss:  tensor(-2.1498e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1075416311182507e-06\n",
            "E_s_wdiff_all_sq: 3.4246578648589413e-07\n",
            "E_IS_SCOPE: 3.2501495293829724e-06\n",
            "E_IS_E_SCOPE: 5.444409016254061e-06\n",
            "Total Loss: -2.1497899313126103e-07\n",
            "----------------------------------------\n",
            "Epoch 714\n",
            "Var loss:  tensor(-2.2301e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1099030756869733e-06\n",
            "E_s_wdiff_all_sq: 3.459868492970389e-07\n",
            "E_IS_SCOPE: 3.25275936805232e-06\n",
            "E_IS_E_SCOPE: 5.450453954421132e-06\n",
            "Total Loss: -2.2300881036913072e-07\n",
            "----------------------------------------\n",
            "Epoch 715\n",
            "Var loss:  tensor(-2.3103e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.107323640706436e-06\n",
            "E_s_wdiff_all_sq: 3.499325185512293e-07\n",
            "E_IS_SCOPE: 3.2849624682961487e-06\n",
            "E_IS_E_SCOPE: 5.483403854393409e-06\n",
            "Total Loss: -2.3102751406075509e-07\n",
            "----------------------------------------\n",
            "Epoch 716\n",
            "Var loss:  tensor(-2.3922e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1179054726252854e-06\n",
            "E_s_wdiff_all_sq: 3.5883367818620923e-07\n",
            "E_IS_SCOPE: 3.3230168410047516e-06\n",
            "E_IS_E_SCOPE: 5.526396628866261e-06\n",
            "Total Loss: -2.3922364530538257e-07\n",
            "----------------------------------------\n",
            "Epoch 717\n",
            "Var loss:  tensor(-2.4732e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1245205834678274e-06\n",
            "E_s_wdiff_all_sq: 3.648458748225593e-07\n",
            "E_IS_SCOPE: 3.3538746536054863e-06\n",
            "E_IS_E_SCOPE: 5.561605623315239e-06\n",
            "Total Loss: -2.4732309479567937e-07\n",
            "----------------------------------------\n",
            "Epoch 718\n",
            "Var loss:  tensor(-2.5533e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.127594949515942e-06\n",
            "E_s_wdiff_all_sq: 3.7319424596456715e-07\n",
            "E_IS_SCOPE: 3.3713082442443526e-06\n",
            "E_IS_E_SCOPE: 5.580407739513489e-06\n",
            "Total Loss: -2.5533415100834017e-07\n",
            "----------------------------------------\n",
            "Epoch 719\n",
            "Var loss:  tensor(-2.6350e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.109224818069403e-06\n",
            "E_s_wdiff_all_sq: 3.674608664147079e-07\n",
            "E_IS_SCOPE: 3.382674124659334e-06\n",
            "E_IS_E_SCOPE: 5.589537529161913e-06\n",
            "Total Loss: -2.634987213719061e-07\n",
            "----------------------------------------\n",
            "Epoch 720\n",
            "Var loss:  tensor(-2.7188e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.1238002692976843e-06\n",
            "E_s_wdiff_all_sq: 3.6924797287982615e-07\n",
            "E_IS_SCOPE: 3.3558921797260775e-06\n",
            "E_IS_E_SCOPE: 5.573341382589681e-06\n",
            "Total Loss: -2.7188197333078773e-07\n",
            "----------------------------------------\n",
            "Epoch 721\n",
            "Var loss:  tensor(-2.8014e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.103008914657725e-06\n",
            "E_s_wdiff_all_sq: 3.524267890220313e-07\n",
            "E_IS_SCOPE: 3.3669356175350163e-06\n",
            "E_IS_E_SCOPE: 5.586526320379058e-06\n",
            "Total Loss: -2.8013514407383055e-07\n",
            "----------------------------------------\n",
            "Epoch 722\n",
            "Var loss:  tensor(-2.8843e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0786766142257008e-06\n",
            "E_s_wdiff_all_sq: 3.3244651114402825e-07\n",
            "E_IS_SCOPE: 3.401397183307897e-06\n",
            "E_IS_E_SCOPE: 5.622961262198842e-06\n",
            "Total Loss: -2.884339187216588e-07\n",
            "----------------------------------------\n",
            "Epoch 723\n",
            "Var loss:  tensor(-2.9685e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0761669359793313e-06\n",
            "E_s_wdiff_all_sq: 3.2404463718489614e-07\n",
            "E_IS_SCOPE: 3.4294435872171873e-06\n",
            "E_IS_E_SCOPE: 5.6581608671347e-06\n",
            "Total Loss: -2.9684812506203107e-07\n",
            "----------------------------------------\n",
            "Epoch 724\n",
            "Var loss:  tensor(-3.0512e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.062894178701117e-06\n",
            "E_s_wdiff_all_sq: 3.1945953827691666e-07\n",
            "E_IS_SCOPE: 3.4800837625988977e-06\n",
            "E_IS_E_SCOPE: 5.708595257357734e-06\n",
            "Total Loss: -3.0512421311491384e-07\n",
            "----------------------------------------\n",
            "Epoch 725\n",
            "Var loss:  tensor(-3.1352e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.057828298933219e-06\n",
            "E_s_wdiff_all_sq: 3.167609887407062e-07\n",
            "E_IS_SCOPE: 3.5125891269353406e-06\n",
            "E_IS_E_SCOPE: 5.744114261752265e-06\n",
            "Total Loss: -3.135188234627771e-07\n",
            "----------------------------------------\n",
            "Epoch 726\n",
            "Var loss:  tensor(-3.2196e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0686168680589623e-06\n",
            "E_s_wdiff_all_sq: 3.173708441928323e-07\n",
            "E_IS_SCOPE: 3.5188134865739183e-06\n",
            "E_IS_E_SCOPE: 5.759648174094778e-06\n",
            "Total Loss: -3.2195921519702957e-07\n",
            "----------------------------------------\n",
            "Epoch 727\n",
            "Var loss:  tensor(-3.3041e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.047781534838904e-06\n",
            "E_s_wdiff_all_sq: 3.0420771208301935e-07\n",
            "E_IS_SCOPE: 3.5447682185362727e-06\n",
            "E_IS_E_SCOPE: 5.785993119921861e-06\n",
            "Total Loss: -3.3041184403673155e-07\n",
            "----------------------------------------\n",
            "Epoch 728\n",
            "Var loss:  tensor(-3.3895e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0383349548343983e-06\n",
            "E_s_wdiff_all_sq: 2.978050985821209e-07\n",
            "E_IS_SCOPE: 3.5574460679082086e-06\n",
            "E_IS_E_SCOPE: 5.8014176852758055e-06\n",
            "Total Loss: -3.389492425043577e-07\n",
            "----------------------------------------\n",
            "Epoch 729\n",
            "Var loss:  tensor(-3.4748e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0319265106654663e-06\n",
            "E_s_wdiff_all_sq: 2.94510434230972e-07\n",
            "E_IS_SCOPE: 3.5589077610890363e-06\n",
            "E_IS_E_SCOPE: 5.805585375263834e-06\n",
            "Total Loss: -3.4747501593654147e-07\n",
            "----------------------------------------\n",
            "Epoch 730\n",
            "Var loss:  tensor(-3.5601e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0319111465337423e-06\n",
            "E_s_wdiff_all_sq: 2.995058499450461e-07\n",
            "E_IS_SCOPE: 3.560268357163045e-06\n",
            "E_IS_E_SCOPE: 5.808707839807212e-06\n",
            "Total Loss: -3.560095327210797e-07\n",
            "----------------------------------------\n",
            "Epoch 731\n",
            "Var loss:  tensor(-3.6455e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0447726832261414e-06\n",
            "E_s_wdiff_all_sq: 3.101694441526059e-07\n",
            "E_IS_SCOPE: 3.564110529182254e-06\n",
            "E_IS_E_SCOPE: 5.817919078255877e-06\n",
            "Total Loss: -3.6454972309515247e-07\n",
            "----------------------------------------\n",
            "Epoch 732\n",
            "Var loss:  tensor(-3.7316e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0400345920438134e-06\n",
            "E_s_wdiff_all_sq: 3.0633408419870785e-07\n",
            "E_IS_SCOPE: 3.587066553742199e-06\n",
            "E_IS_E_SCOPE: 5.8447266774264856e-06\n",
            "Total Loss: -3.7315560354490776e-07\n",
            "----------------------------------------\n",
            "Epoch 733\n",
            "Var loss:  tensor(-3.8180e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0471060803784323e-06\n",
            "E_s_wdiff_all_sq: 3.0897245822012535e-07\n",
            "E_IS_SCOPE: 3.6006079186489196e-06\n",
            "E_IS_E_SCOPE: 5.86480856749889e-06\n",
            "Total Loss: -3.8180353956307454e-07\n",
            "----------------------------------------\n",
            "Epoch 734\n",
            "Var loss:  tensor(-3.9044e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0413076141775414e-06\n",
            "E_s_wdiff_all_sq: 3.1051617571744453e-07\n",
            "E_IS_SCOPE: 3.62115977546814e-06\n",
            "E_IS_E_SCOPE: 5.886006356256191e-06\n",
            "Total Loss: -3.904375871374455e-07\n",
            "----------------------------------------\n",
            "Epoch 735\n",
            "Var loss:  tensor(-3.9915e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.052332140002009e-06\n",
            "E_s_wdiff_all_sq: 3.218573869325448e-07\n",
            "E_IS_SCOPE: 3.623395575816802e-06\n",
            "E_IS_E_SCOPE: 5.8924410077439845e-06\n",
            "Total Loss: -3.9915197480634147e-07\n",
            "----------------------------------------\n",
            "Epoch 736\n",
            "Var loss:  tensor(-4.0779e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0743407879542705e-06\n",
            "E_s_wdiff_all_sq: 3.4361902913480013e-07\n",
            "E_IS_SCOPE: 3.6069181728785595e-06\n",
            "E_IS_E_SCOPE: 5.880406116508807e-06\n",
            "Total Loss: -4.077899924624655e-07\n",
            "----------------------------------------\n",
            "Epoch 737\n",
            "Var loss:  tensor(-4.1648e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0786159991261933e-06\n",
            "E_s_wdiff_all_sq: 3.5505263720969733e-07\n",
            "E_IS_SCOPE: 3.62265510825836e-06\n",
            "E_IS_E_SCOPE: 5.896909376658757e-06\n",
            "Total Loss: -4.164810389057407e-07\n",
            "----------------------------------------\n",
            "Epoch 738\n",
            "Var loss:  tensor(-4.2530e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0882113208343096e-06\n",
            "E_s_wdiff_all_sq: 3.602326821572391e-07\n",
            "E_IS_SCOPE: 3.6528662796464826e-06\n",
            "E_IS_E_SCOPE: 5.933737262962837e-06\n",
            "Total Loss: -4.2529919197708057e-07\n",
            "----------------------------------------\n",
            "Epoch 739\n",
            "Var loss:  tensor(-4.3411e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0642948391944915e-06\n",
            "E_s_wdiff_all_sq: 3.4236332246993466e-07\n",
            "E_IS_SCOPE: 3.6979202389928883e-06\n",
            "E_IS_E_SCOPE: 5.980172160093632e-06\n",
            "Total Loss: -4.341081894983701e-07\n",
            "----------------------------------------\n",
            "Epoch 740\n",
            "Var loss:  tensor(-4.4291e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0652530072399695e-06\n",
            "E_s_wdiff_all_sq: 3.376169002655587e-07\n",
            "E_IS_SCOPE: 3.7022957209876627e-06\n",
            "E_IS_E_SCOPE: 5.991798666360888e-06\n",
            "Total Loss: -4.429056477934809e-07\n",
            "----------------------------------------\n",
            "Epoch 741\n",
            "Var loss:  tensor(-4.5178e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0537555122186042e-06\n",
            "E_s_wdiff_all_sq: 3.3029125673973804e-07\n",
            "E_IS_SCOPE: 3.705163304286882e-06\n",
            "E_IS_E_SCOPE: 5.997015048402889e-06\n",
            "Total Loss: -4.517750967745895e-07\n",
            "----------------------------------------\n",
            "Epoch 742\n",
            "Var loss:  tensor(-4.6060e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.03900920917432e-06\n",
            "E_s_wdiff_all_sq: 3.2316636454005534e-07\n",
            "E_IS_SCOPE: 3.703140054801031e-06\n",
            "E_IS_E_SCOPE: 5.995595972794404e-06\n",
            "Total Loss: -4.6060485537392393e-07\n",
            "----------------------------------------\n",
            "Epoch 743\n",
            "Var loss:  tensor(-4.6951e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0783177025873812e-06\n",
            "E_s_wdiff_all_sq: 3.4575741338047373e-07\n",
            "E_IS_SCOPE: 3.680149975731143e-06\n",
            "E_IS_E_SCOPE: 5.98541819377382e-06\n",
            "Total Loss: -4.695120108998878e-07\n",
            "----------------------------------------\n",
            "Epoch 744\n",
            "Var loss:  tensor(-4.7844e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.027732188777844e-06\n",
            "E_s_wdiff_all_sq: 3.262678370164713e-07\n",
            "E_IS_SCOPE: 3.7617703530210137e-06\n",
            "E_IS_E_SCOPE: 6.055954382135507e-06\n",
            "Total Loss: -4.784395704890537e-07\n",
            "----------------------------------------\n",
            "Epoch 745\n",
            "Var loss:  tensor(-4.8739e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.055411551874332e-06\n",
            "E_s_wdiff_all_sq: 3.3458214470726427e-07\n",
            "E_IS_SCOPE: 3.7704412606527694e-06\n",
            "E_IS_E_SCOPE: 6.078783723847466e-06\n",
            "Total Loss: -4.873913832437676e-07\n",
            "----------------------------------------\n",
            "Epoch 746\n",
            "Var loss:  tensor(-4.9638e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0512168625873768e-06\n",
            "E_s_wdiff_all_sq: 3.33163438920146e-07\n",
            "E_IS_SCOPE: 3.78868974206363e-06\n",
            "E_IS_E_SCOPE: 6.100140050768993e-06\n",
            "Total Loss: -4.963830577649354e-07\n",
            "----------------------------------------\n",
            "Epoch 747\n",
            "Var loss:  tensor(-5.0533e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0313573659213543e-06\n",
            "E_s_wdiff_all_sq: 3.264368681271281e-07\n",
            "E_IS_SCOPE: 3.8121620147823774e-06\n",
            "E_IS_E_SCOPE: 6.1215188311129815e-06\n",
            "Total Loss: -5.053289988884228e-07\n",
            "----------------------------------------\n",
            "Epoch 748\n",
            "Var loss:  tensor(-5.1432e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0744923706999868e-06\n",
            "E_s_wdiff_all_sq: 3.46938199612164e-07\n",
            "E_IS_SCOPE: 3.7833857218673302e-06\n",
            "E_IS_E_SCOPE: 6.108553759398549e-06\n",
            "Total Loss: -5.143177679960562e-07\n",
            "----------------------------------------\n",
            "Epoch 749\n",
            "Var loss:  tensor(-5.2335e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0386783087216076e-06\n",
            "E_s_wdiff_all_sq: 3.381153400866165e-07\n",
            "E_IS_SCOPE: 3.819235245775253e-06\n",
            "E_IS_E_SCOPE: 6.13542399047777e-06\n",
            "Total Loss: -5.233503847914826e-07\n",
            "----------------------------------------\n",
            "Epoch 750\n",
            "Var loss:  tensor(-5.3238e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.059994697913937e-06\n",
            "E_s_wdiff_all_sq: 3.519304239747502e-07\n",
            "E_IS_SCOPE: 3.80836076133578e-06\n",
            "E_IS_E_SCOPE: 6.132815692177749e-06\n",
            "Total Loss: -5.323814517661912e-07\n",
            "----------------------------------------\n",
            "Epoch 751\n",
            "Var loss:  tensor(-5.4133e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.070301346742258e-06\n",
            "E_s_wdiff_all_sq: 3.565867574786752e-07\n",
            "E_IS_SCOPE: 3.810397379214318e-06\n",
            "E_IS_E_SCOPE: 6.142149766366932e-06\n",
            "Total Loss: -5.41326049063086e-07\n",
            "----------------------------------------\n",
            "Epoch 752\n",
            "Var loss:  tensor(-5.5034e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0521703936787464e-06\n",
            "E_s_wdiff_all_sq: 3.521147000170833e-07\n",
            "E_IS_SCOPE: 3.850546963449476e-06\n",
            "E_IS_E_SCOPE: 6.179975632902327e-06\n",
            "Total Loss: -5.503375092654792e-07\n",
            "----------------------------------------\n",
            "Epoch 753\n",
            "Var loss:  tensor(-5.5944e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0846144797706574e-06\n",
            "E_s_wdiff_all_sq: 3.6975960542903886e-07\n",
            "E_IS_SCOPE: 3.86519459060483e-06\n",
            "E_IS_E_SCOPE: 6.206574606928937e-06\n",
            "Total Loss: -5.594410223280377e-07\n",
            "----------------------------------------\n",
            "Epoch 754\n",
            "Var loss:  tensor(-5.6851e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0361606432999415e-06\n",
            "E_s_wdiff_all_sq: 3.435527471985542e-07\n",
            "E_IS_SCOPE: 3.929959647182713e-06\n",
            "E_IS_E_SCOPE: 6.2647496623949235e-06\n",
            "Total Loss: -5.685079983444743e-07\n",
            "----------------------------------------\n",
            "Epoch 755\n",
            "Var loss:  tensor(-5.7761e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0778771995937987e-06\n",
            "E_s_wdiff_all_sq: 3.5948439261209797e-07\n",
            "E_IS_SCOPE: 3.90165337162576e-06\n",
            "E_IS_E_SCOPE: 6.253885553565891e-06\n",
            "Total Loss: -5.776074209200019e-07\n",
            "----------------------------------------\n",
            "Epoch 756\n",
            "Var loss:  tensor(-5.8683e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0379451623391963e-06\n",
            "E_s_wdiff_all_sq: 3.412981827102453e-07\n",
            "E_IS_SCOPE: 3.935093503820433e-06\n",
            "E_IS_E_SCOPE: 6.281061904643728e-06\n",
            "Total Loss: -5.868256860390779e-07\n",
            "----------------------------------------\n",
            "Epoch 757\n",
            "Var loss:  tensor(-5.9600e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.038319496816368e-06\n",
            "E_s_wdiff_all_sq: 3.375432256615336e-07\n",
            "E_IS_SCOPE: 3.936436839013202e-06\n",
            "E_IS_E_SCOPE: 6.289056852939141e-06\n",
            "Total Loss: -5.959996207184835e-07\n",
            "----------------------------------------\n",
            "Epoch 758\n",
            "Var loss:  tensor(-6.0516e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0640838014452687e-06\n",
            "E_s_wdiff_all_sq: 3.521273868603615e-07\n",
            "E_IS_SCOPE: 3.919839491785449e-06\n",
            "E_IS_E_SCOPE: 6.282630881107641e-06\n",
            "Total Loss: -6.051622280809183e-07\n",
            "----------------------------------------\n",
            "Epoch 759\n",
            "Var loss:  tensor(-6.1437e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0088320476867788e-06\n",
            "E_s_wdiff_all_sq: 3.309480713339651e-07\n",
            "E_IS_SCOPE: 3.975953413339222e-06\n",
            "E_IS_E_SCOPE: 6.326310847171899e-06\n",
            "Total Loss: -6.143667553339804e-07\n",
            "----------------------------------------\n",
            "Epoch 760\n",
            "Var loss:  tensor(-6.2357e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0808448131253804e-06\n",
            "E_s_wdiff_all_sq: 3.6516256061058247e-07\n",
            "E_IS_SCOPE: 3.948899070839503e-06\n",
            "E_IS_E_SCOPE: 6.322755425777901e-06\n",
            "Total Loss: -6.235663213834382e-07\n",
            "----------------------------------------\n",
            "Epoch 761\n",
            "Var loss:  tensor(-6.3289e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0174085972526533e-06\n",
            "E_s_wdiff_all_sq: 3.383472904444125e-07\n",
            "E_IS_SCOPE: 4.025271317685544e-06\n",
            "E_IS_E_SCOPE: 6.385479921541343e-06\n",
            "Total Loss: -6.328917649247992e-07\n",
            "----------------------------------------\n",
            "Epoch 762\n",
            "Var loss:  tensor(-6.4227e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.068098922457691e-06\n",
            "E_s_wdiff_all_sq: 3.6191634774684413e-07\n",
            "E_IS_SCOPE: 4.00150455722143e-06\n",
            "E_IS_E_SCOPE: 6.379962217026623e-06\n",
            "Total Loss: -6.4226860892098e-07\n",
            "----------------------------------------\n",
            "Epoch 763\n",
            "Var loss:  tensor(-6.5161e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.045923490519792e-06\n",
            "E_s_wdiff_all_sq: 3.503289610563573e-07\n",
            "E_IS_SCOPE: 4.034391232533908e-06\n",
            "E_IS_E_SCOPE: 6.412225052916715e-06\n",
            "Total Loss: -6.516089753236196e-07\n",
            "----------------------------------------\n",
            "Epoch 764\n",
            "Var loss:  tensor(-6.6098e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.032554056536242e-06\n",
            "E_s_wdiff_all_sq: 3.4313920637561816e-07\n",
            "E_IS_SCOPE: 4.0586818170206864e-06\n",
            "E_IS_E_SCOPE: 6.438112073353694e-06\n",
            "Total Loss: -6.609815265268321e-07\n",
            "----------------------------------------\n",
            "Epoch 765\n",
            "Var loss:  tensor(-6.7052e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.034854670523985e-06\n",
            "E_s_wdiff_all_sq: 3.502246619691924e-07\n",
            "E_IS_SCOPE: 4.062111169146976e-06\n",
            "E_IS_E_SCOPE: 6.443919297300515e-06\n",
            "Total Loss: -6.70522111773726e-07\n",
            "----------------------------------------\n",
            "Epoch 766\n",
            "Var loss:  tensor(-6.8001e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.066876412807272e-06\n",
            "E_s_wdiff_all_sq: 3.6713648371796174e-07\n",
            "E_IS_SCOPE: 4.04105858349118e-06\n",
            "E_IS_E_SCOPE: 6.4351667041354534e-06\n",
            "Total Loss: -6.800121762206762e-07\n",
            "----------------------------------------\n",
            "Epoch 767\n",
            "Var loss:  tensor(-6.8968e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0500978691180493e-06\n",
            "E_s_wdiff_all_sq: 3.636693538338914e-07\n",
            "E_IS_SCOPE: 4.081218621374629e-06\n",
            "E_IS_E_SCOPE: 6.473506817170802e-06\n",
            "Total Loss: -6.896837403296295e-07\n",
            "----------------------------------------\n",
            "Epoch 768\n",
            "Var loss:  tensor(-6.9936e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0387106811367784e-06\n",
            "E_s_wdiff_all_sq: 3.5905047796792627e-07\n",
            "E_IS_SCOPE: 4.112049156263923e-06\n",
            "E_IS_E_SCOPE: 6.5057922519417e-06\n",
            "Total Loss: -6.993618522081422e-07\n",
            "----------------------------------------\n",
            "Epoch 769\n",
            "Var loss:  tensor(-7.0910e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0675448197973273e-06\n",
            "E_s_wdiff_all_sq: 3.685929263658305e-07\n",
            "E_IS_SCOPE: 4.112753908574567e-06\n",
            "E_IS_E_SCOPE: 6.521012915330103e-06\n",
            "Total Loss: -7.091019841010166e-07\n",
            "----------------------------------------\n",
            "Epoch 770\n",
            "Var loss:  tensor(-7.1879e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.033958944222384e-06\n",
            "E_s_wdiff_all_sq: 3.516758197577221e-07\n",
            "E_IS_SCOPE: 4.161718787332086e-06\n",
            "E_IS_E_SCOPE: 6.566488948714031e-06\n",
            "Total Loss: -7.187930623206686e-07\n",
            "----------------------------------------\n",
            "Epoch 771\n",
            "Var loss:  tensor(-7.2867e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0602669333541986e-06\n",
            "E_s_wdiff_all_sq: 3.732567687349644e-07\n",
            "E_IS_SCOPE: 4.168844129144753e-06\n",
            "E_IS_E_SCOPE: 6.580918431599129e-06\n",
            "Total Loss: -7.286743043109576e-07\n",
            "----------------------------------------\n",
            "Epoch 772\n",
            "Var loss:  tensor(-7.3851e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.063643731465503e-06\n",
            "E_s_wdiff_all_sq: 3.7778048760762687e-07\n",
            "E_IS_SCOPE: 4.188846306924983e-06\n",
            "E_IS_E_SCOPE: 6.6052628771347706e-06\n",
            "Total Loss: -7.385057605831386e-07\n",
            "----------------------------------------\n",
            "Epoch 773\n",
            "Var loss:  tensor(-7.4831e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.053578707676068e-06\n",
            "E_s_wdiff_all_sq: 3.7379372268945334e-07\n",
            "E_IS_SCOPE: 4.208789234631935e-06\n",
            "E_IS_E_SCOPE: 6.627070065296009e-06\n",
            "Total Loss: -7.483125403629736e-07\n",
            "----------------------------------------\n",
            "Epoch 774\n",
            "Var loss:  tensor(-7.5806e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0605687061960756e-06\n",
            "E_s_wdiff_all_sq: 3.7733101838150575e-07\n",
            "E_IS_SCOPE: 4.2047444729654745e-06\n",
            "E_IS_E_SCOPE: 6.6296263485037105e-06\n",
            "Total Loss: -7.580619272833421e-07\n",
            "----------------------------------------\n",
            "Epoch 775\n",
            "Var loss:  tensor(-7.6780e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.037281486752338e-06\n",
            "E_s_wdiff_all_sq: 3.598870244396641e-07\n",
            "E_IS_SCOPE: 4.223802736145082e-06\n",
            "E_IS_E_SCOPE: 6.650630805532408e-06\n",
            "Total Loss: -7.677975404834171e-07\n",
            "----------------------------------------\n",
            "Epoch 776\n",
            "Var loss:  tensor(-7.7760e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0469147495204895e-06\n",
            "E_s_wdiff_all_sq: 3.6378422746896024e-07\n",
            "E_IS_SCOPE: 4.235551414327332e-06\n",
            "E_IS_E_SCOPE: 6.670146915876548e-06\n",
            "Total Loss: -7.77596345068342e-07\n",
            "----------------------------------------\n",
            "Epoch 777\n",
            "Var loss:  tensor(-7.8740e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0417879956615836e-06\n",
            "E_s_wdiff_all_sq: 3.643132118868019e-07\n",
            "E_IS_SCOPE: 4.257923970658039e-06\n",
            "E_IS_E_SCOPE: 6.694595883989451e-06\n",
            "Total Loss: -7.874049069094815e-07\n",
            "----------------------------------------\n",
            "Epoch 778\n",
            "Var loss:  tensor(-7.9728e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0456905814243524e-06\n",
            "E_s_wdiff_all_sq: 3.6829748977334657e-07\n",
            "E_IS_SCOPE: 4.279311790877318e-06\n",
            "E_IS_E_SCOPE: 6.720880273398584e-06\n",
            "Total Loss: -7.972797374129676e-07\n",
            "----------------------------------------\n",
            "Epoch 779\n",
            "Var loss:  tensor(-8.0718e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.047025358808702e-06\n",
            "E_s_wdiff_all_sq: 3.697834083077351e-07\n",
            "E_IS_SCOPE: 4.301610919141212e-06\n",
            "E_IS_E_SCOPE: 6.748052578133692e-06\n",
            "Total Loss: -8.071772315054321e-07\n",
            "----------------------------------------\n",
            "Epoch 780\n",
            "Var loss:  tensor(-8.1707e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0461294213040288e-06\n",
            "E_s_wdiff_all_sq: 3.7153755311488405e-07\n",
            "E_IS_SCOPE: 4.314251990000706e-06\n",
            "E_IS_E_SCOPE: 6.764313370064592e-06\n",
            "Total Loss: -8.17066755960068e-07\n",
            "----------------------------------------\n",
            "Epoch 781\n",
            "Var loss:  tensor(-8.2702e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0378265482864607e-06\n",
            "E_s_wdiff_all_sq: 3.656290915995199e-07\n",
            "E_IS_SCOPE: 4.3316311791046965e-06\n",
            "E_IS_E_SCOPE: 6.785473505728808e-06\n",
            "Total Loss: -8.270230605827223e-07\n",
            "----------------------------------------\n",
            "Epoch 782\n",
            "Var loss:  tensor(-8.3700e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0540634187364966e-06\n",
            "E_s_wdiff_all_sq: 3.730796519704696e-07\n",
            "E_IS_SCOPE: 4.349047450982452e-06\n",
            "E_IS_E_SCOPE: 6.812272602353364e-06\n",
            "Total Loss: -8.370023999972383e-07\n",
            "----------------------------------------\n",
            "Epoch 783\n",
            "Var loss:  tensor(-8.4693e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.025820587393504e-06\n",
            "E_s_wdiff_all_sq: 3.5779382016998275e-07\n",
            "E_IS_SCOPE: 4.402405167748186e-06\n",
            "E_IS_E_SCOPE: 6.864117201469917e-06\n",
            "Total Loss: -8.469331642413797e-07\n",
            "----------------------------------------\n",
            "Epoch 784\n",
            "Var loss:  tensor(-8.5700e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.040870792478602e-06\n",
            "E_s_wdiff_all_sq: 3.6551280855800986e-07\n",
            "E_IS_SCOPE: 4.402904312010249e-06\n",
            "E_IS_E_SCOPE: 6.873312944806299e-06\n",
            "Total Loss: -8.569951456929499e-07\n",
            "----------------------------------------\n",
            "Epoch 785\n",
            "Var loss:  tensor(-8.6702e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.040750094335649e-06\n",
            "E_s_wdiff_all_sq: 3.674692639166787e-07\n",
            "E_IS_SCOPE: 4.411050847861418e-06\n",
            "E_IS_E_SCOPE: 6.885435553072269e-06\n",
            "Total Loss: -8.670244440241705e-07\n",
            "----------------------------------------\n",
            "Epoch 786\n",
            "Var loss:  tensor(-8.7715e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0123251882406296e-06\n",
            "E_s_wdiff_all_sq: 3.5396420514422423e-07\n",
            "E_IS_SCOPE: 4.44209508743256e-06\n",
            "E_IS_E_SCOPE: 6.9140823146932825e-06\n",
            "Total Loss: -8.771493354464799e-07\n",
            "----------------------------------------\n",
            "Epoch 787\n",
            "Var loss:  tensor(-8.8725e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.055684304113495e-06\n",
            "E_s_wdiff_all_sq: 3.7780670135583337e-07\n",
            "E_IS_SCOPE: 4.411957899075286e-06\n",
            "E_IS_E_SCOPE: 6.898752324498526e-06\n",
            "Total Loss: -8.87247112110258e-07\n",
            "----------------------------------------\n",
            "Epoch 788\n",
            "Var loss:  tensor(-8.9743e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0252919242764872e-06\n",
            "E_s_wdiff_all_sq: 3.6571292117889163e-07\n",
            "E_IS_SCOPE: 4.449863126438341e-06\n",
            "E_IS_E_SCOPE: 6.9325985394216905e-06\n",
            "Total Loss: -8.974276868905454e-07\n",
            "----------------------------------------\n",
            "Epoch 789\n",
            "Var loss:  tensor(-9.0765e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0301619336670165e-06\n",
            "E_s_wdiff_all_sq: 3.668977394341801e-07\n",
            "E_IS_SCOPE: 4.468705782773913e-06\n",
            "E_IS_E_SCOPE: 6.958394407759049e-06\n",
            "Total Loss: -9.076489197588761e-07\n",
            "----------------------------------------\n",
            "Epoch 790\n",
            "Var loss:  tensor(-9.1781e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0536565231403957e-06\n",
            "E_s_wdiff_all_sq: 3.770607403085796e-07\n",
            "E_IS_SCOPE: 4.480029674728229e-06\n",
            "E_IS_E_SCOPE: 6.9814664315787665e-06\n",
            "Total Loss: -9.178135948906999e-07\n",
            "----------------------------------------\n",
            "Epoch 791\n",
            "Var loss:  tensor(-9.2812e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0210649696846432e-06\n",
            "E_s_wdiff_all_sq: 3.6463538609427086e-07\n",
            "E_IS_SCOPE: 4.53656558186158e-06\n",
            "E_IS_E_SCOPE: 7.033071291371119e-06\n",
            "Total Loss: -9.281176994501453e-07\n",
            "----------------------------------------\n",
            "Epoch 792\n",
            "Var loss:  tensor(-9.3841e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.047564159354765e-06\n",
            "E_s_wdiff_all_sq: 3.8029164952458495e-07\n",
            "E_IS_SCOPE: 4.533444915923928e-06\n",
            "E_IS_E_SCOPE: 7.0405192489034726e-06\n",
            "Total Loss: -9.384120201503481e-07\n",
            "----------------------------------------\n",
            "Epoch 793\n",
            "Var loss:  tensor(-9.4872e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.049996955768787e-06\n",
            "E_s_wdiff_all_sq: 3.8343599880537776e-07\n",
            "E_IS_SCOPE: 4.54529371596278e-06\n",
            "E_IS_E_SCOPE: 7.057166333054909e-06\n",
            "Total Loss: -9.487201412422898e-07\n",
            "----------------------------------------\n",
            "Epoch 794\n",
            "Var loss:  tensor(-9.5903e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0395068576079766e-06\n",
            "E_s_wdiff_all_sq: 3.827065524153703e-07\n",
            "E_IS_SCOPE: 4.568952787874859e-06\n",
            "E_IS_E_SCOPE: 7.081099462047242e-06\n",
            "Total Loss: -9.590289071736007e-07\n",
            "----------------------------------------\n",
            "Epoch 795\n",
            "Var loss:  tensor(-9.6941e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0746225349984714e-06\n",
            "E_s_wdiff_all_sq: 4.04933745229206e-07\n",
            "E_IS_SCOPE: 4.569498240934756e-06\n",
            "E_IS_E_SCOPE: 7.093278765512181e-06\n",
            "Total Loss: -9.694081234070247e-07\n",
            "----------------------------------------\n",
            "Epoch 796\n",
            "Var loss:  tensor(-9.7987e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.043896229358623e-06\n",
            "E_s_wdiff_all_sq: 3.9214733516951315e-07\n",
            "E_IS_SCOPE: 4.6367800458094015e-06\n",
            "E_IS_E_SCOPE: 7.156819749051491e-06\n",
            "Total Loss: -9.798663763165084e-07\n",
            "----------------------------------------\n",
            "Epoch 797\n",
            "Var loss:  tensor(-9.9034e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.07928840870102e-06\n",
            "E_s_wdiff_all_sq: 4.144918568912612e-07\n",
            "E_IS_SCOPE: 4.648476512774259e-06\n",
            "E_IS_E_SCOPE: 7.180276656975907e-06\n",
            "Total Loss: -9.903396006149787e-07\n",
            "----------------------------------------\n",
            "Epoch 798\n",
            "Var loss:  tensor(-1.0008e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0780719935220448e-06\n",
            "E_s_wdiff_all_sq: 4.1902959465881336e-07\n",
            "E_IS_SCOPE: 4.68180222620281e-06\n",
            "E_IS_E_SCOPE: 7.215977640868414e-06\n",
            "Total Loss: -1.0008442944894167e-06\n",
            "----------------------------------------\n",
            "Epoch 799\n",
            "Var loss:  tensor(-1.0114e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.0661765077220837e-06\n",
            "E_s_wdiff_all_sq: 4.142220359928117e-07\n",
            "E_IS_SCOPE: 4.717416946911178e-06\n",
            "E_IS_E_SCOPE: 7.253311642677324e-06\n",
            "Total Loss: -1.0113707838244597e-06\n",
            "----------------------------------------\n",
            "Epoch 800\n",
            "Var loss:  tensor(-1.0219e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.5443728380345596e-06\n",
            "E_IS_all_sq: 2.135908702056001e-06\n",
            "E_s_wdiff_sq: 3.091108202447605e-06\n",
            "E_s_wdiff_all_sq: 4.260959702009109e-07\n",
            "E_IS_SCOPE: 4.7175237866153015e-06\n",
            "E_IS_E_SCOPE: 7.2652323297086695e-06\n",
            "Total Loss: -1.021940717961484e-06\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[-0.8062,  0.5339],\n",
            "        [-0.1972, -0.4208],\n",
            "        [ 0.6107,  0.1833],\n",
            "        [ 0.1100, -0.3393],\n",
            "        [-0.0469,  0.4383],\n",
            "        [ 0.1967,  0.3041],\n",
            "        [-0.0265, -0.4809],\n",
            "        [ 0.6737, -0.2494],\n",
            "        [ 0.1594, -0.6898],\n",
            "        [-0.3210,  0.0304],\n",
            "        [ 0.3898,  0.0076],\n",
            "        [ 0.1543,  0.5288],\n",
            "        [-0.6948, -0.0398],\n",
            "        [-0.2316,  0.1893],\n",
            "        [-0.2966, -0.2733],\n",
            "        [ 0.0087, -0.1834]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([ 0.3518, -0.0830, -0.0474,  0.5771,  0.3440, -0.1348,  0.3951, -0.3842,\n",
            "        -0.4929, -0.6301,  0.5189,  0.0884,  0.2289,  0.2196, -0.0453, -0.4175],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[-8.0332e-02, -9.6393e-02, -3.0631e-01, -5.3021e-02, -6.4791e-02,\n",
            "          1.5885e-01,  1.7243e-01, -1.9679e-01,  8.0992e-02, -3.4376e-02,\n",
            "          8.6558e-02,  6.0149e-02, -1.5966e-01, -1.9643e-01,  2.6262e-02,\n",
            "          9.7768e-02],\n",
            "        [-1.8631e-01, -4.7563e-02,  1.0468e-01,  7.8847e-02, -1.8044e-01,\n",
            "          9.0671e-02,  1.6094e-01,  1.6128e-01,  1.0846e-01,  7.4880e-02,\n",
            "          1.3432e-01,  1.1134e-01,  1.9639e-01,  2.1434e-01, -8.8973e-02,\n",
            "          5.1494e-02],\n",
            "        [-8.3696e-02,  2.3390e-02, -1.9553e-01,  2.0819e-01,  3.3464e-02,\n",
            "          9.1040e-02, -2.2174e-01, -4.0349e-02, -1.7039e-01, -1.2196e-01,\n",
            "          2.3892e-01,  4.4670e-02,  9.1598e-02, -1.4442e-01, -9.2240e-03,\n",
            "         -1.5019e-01],\n",
            "        [ 1.6635e-01,  1.3661e-01,  4.7544e-02, -1.2729e-01, -1.9802e-01,\n",
            "          1.0363e-01,  2.1950e-01,  1.1609e-01, -9.6209e-02,  1.6007e-01,\n",
            "          1.9251e-02, -9.7342e-02, -3.6885e-02, -9.6853e-02,  2.4558e-01,\n",
            "         -2.0681e-01],\n",
            "        [-4.0992e-01, -2.0711e-01, -3.3693e-02,  2.6252e-01,  1.2579e-01,\n",
            "          1.3540e-01,  1.0068e-01,  1.5353e-01,  2.2798e-01,  2.0321e-01,\n",
            "          1.2280e-02, -8.3059e-02, -2.9253e-02,  1.4174e-01, -6.7642e-02,\n",
            "          5.7888e-03],\n",
            "        [-1.2552e-01,  1.9502e-01,  1.5227e-01, -2.1612e-01,  1.2873e-01,\n",
            "         -2.4643e-01, -1.4887e-01,  5.0036e-02, -7.1466e-02,  7.1605e-02,\n",
            "         -8.6758e-04,  1.8790e-01, -2.4318e-01,  7.5170e-02, -2.1491e-01,\n",
            "          2.4828e-01],\n",
            "        [ 4.5420e-02, -9.1232e-02,  2.7557e-01,  5.1251e-01,  2.1220e-02,\n",
            "         -1.7437e-01,  1.9662e-03,  6.1231e-01,  1.6596e-01,  9.9712e-02,\n",
            "         -2.2019e-01, -4.1986e-01, -7.0665e-02, -1.3922e-01,  2.9088e-02,\n",
            "         -1.1662e-04],\n",
            "        [-1.0585e-01,  1.3251e-02, -1.9701e-01, -9.0187e-02,  1.0414e-01,\n",
            "         -3.2789e-01,  7.0949e-02, -7.2965e-02,  1.0380e-01, -2.0536e-01,\n",
            "         -5.2456e-02, -2.2061e-01,  1.8478e-01,  8.2254e-02, -2.2522e-01,\n",
            "         -2.3713e-01],\n",
            "        [ 1.2925e-01,  7.9379e-02, -2.2730e-01, -2.0200e-01, -2.1043e-01,\n",
            "         -1.3539e-01, -1.5416e-01,  2.3083e-01, -1.4306e-01,  1.7335e-01,\n",
            "          1.6987e-01,  1.8717e-01, -2.1875e-01, -2.0191e-01,  4.6794e-02,\n",
            "          7.6969e-02],\n",
            "        [ 8.7817e-02, -2.2005e-01,  4.2939e-02,  3.7799e-01, -3.1136e-01,\n",
            "          1.2048e-01, -1.4484e-01,  1.7240e-01,  1.0482e-01,  1.3989e-01,\n",
            "         -7.7966e-02,  1.7182e-01,  8.7622e-02, -6.1079e-02,  1.6320e-01,\n",
            "          1.0936e-01],\n",
            "        [ 1.6316e-01,  1.0953e-01, -1.8309e-01, -2.4273e-01, -2.3144e-01,\n",
            "          1.1643e-01,  1.4265e-02, -4.2267e-01, -4.9015e-02,  2.4643e-01,\n",
            "         -1.5186e-01,  1.2151e-01,  1.0054e-01, -7.1616e-02,  7.7135e-02,\n",
            "         -1.9369e-01],\n",
            "        [ 1.3604e-01, -1.6816e-01,  2.9183e-02,  1.0745e-02, -6.1637e-02,\n",
            "         -2.4122e-01,  9.9546e-02,  1.1543e-01,  2.1404e-01,  6.1753e-02,\n",
            "          1.7705e-01, -1.0031e-01,  1.3965e-01, -8.4073e-02, -1.6164e-02,\n",
            "          4.7825e-02],\n",
            "        [-3.9372e-02, -1.2222e-01, -1.0357e-01,  2.2564e-01,  1.3276e-01,\n",
            "          1.7604e-01, -4.6910e-03, -1.7045e-01, -2.1251e-01,  1.6377e-01,\n",
            "         -2.0832e-01, -6.5124e-04, -2.2523e-01,  5.1690e-03,  8.2869e-02,\n",
            "          2.9326e-03],\n",
            "        [ 1.4313e-01,  6.1983e-02, -1.7447e-01,  1.0219e-01,  3.5456e-03,\n",
            "         -9.1232e-02,  5.5059e-02,  1.2665e-02, -9.5868e-02,  2.0192e-01,\n",
            "          1.8017e-02, -1.1104e-01,  1.7337e-01,  2.1884e-01, -9.2691e-02,\n",
            "         -1.8502e-01],\n",
            "        [-2.8324e-02,  1.0509e-01, -2.3856e-01,  2.2916e-02, -1.5650e-01,\n",
            "          8.7366e-03, -1.3547e-02,  8.6640e-02,  2.4301e-01,  1.2325e-01,\n",
            "         -1.4718e-01,  2.4406e-01,  3.1490e-01,  5.0178e-02,  1.1804e-01,\n",
            "         -9.6842e-03],\n",
            "        [ 8.1960e-02,  1.7264e-01,  2.3116e-02,  5.1466e-02, -1.7134e-02,\n",
            "         -2.5587e-01, -3.5853e-02, -2.7169e-01, -1.9165e-01, -1.4184e-01,\n",
            "          1.3712e-01,  3.2616e-02, -1.5610e-01, -5.0204e-02,  1.3383e-02,\n",
            "         -1.4695e-01],\n",
            "        [ 1.1471e-01, -1.2229e-01, -7.9304e-02,  1.6964e-01,  8.6664e-02,\n",
            "          2.1409e-01, -1.5925e-01, -1.0394e-01,  2.0021e-01,  1.4388e-01,\n",
            "          4.4371e-02, -1.0489e-01, -5.4600e-02, -1.5409e-01,  2.2961e-02,\n",
            "         -4.8558e-02],\n",
            "        [ 4.2582e-02, -1.1919e-01, -2.0727e-01,  2.8174e-01,  1.2924e-01,\n",
            "         -6.2074e-02,  1.9561e-01,  2.2852e-01, -2.1636e-01, -6.1592e-02,\n",
            "          8.9014e-02, -1.6651e-01,  3.0950e-01,  1.6304e-01, -2.8709e-02,\n",
            "         -1.5392e-01],\n",
            "        [-1.9705e-02,  1.0558e-02,  1.1735e-02, -3.7344e-02, -1.7287e-01,\n",
            "          3.6988e-02,  8.8957e-02, -2.0629e-01,  1.1976e-01,  1.4371e-01,\n",
            "          6.3613e-03,  1.5588e-01, -1.6702e-01, -1.0444e-01, -1.5333e-01,\n",
            "         -2.4597e-01],\n",
            "        [-3.0996e-01, -1.1673e-01,  5.0675e-02, -1.5127e-01,  1.3807e-01,\n",
            "         -4.8340e-02, -1.4436e-01,  6.4084e-02, -2.0163e-01, -1.1742e-01,\n",
            "         -4.6827e-02,  1.4351e-01, -1.3174e-02,  1.4764e-01,  6.0138e-02,\n",
            "         -1.8953e-01],\n",
            "        [-2.0683e-01, -5.6450e-02, -5.8739e-02,  7.7284e-02, -4.1912e-02,\n",
            "         -9.8821e-02, -1.1429e-01, -3.5937e-01,  8.7345e-02, -1.7022e-01,\n",
            "         -1.2511e-01,  1.5426e-01,  3.2253e-01, -1.4470e-02, -2.4544e-01,\n",
            "          1.5933e-01],\n",
            "        [ 1.1519e-01, -5.0207e-02, -8.2738e-02, -8.1500e-02, -2.7266e-01,\n",
            "          1.2192e-01,  1.8188e-01, -9.8487e-02,  1.8022e-01,  8.9168e-02,\n",
            "         -1.7937e-01, -8.3197e-02, -1.2280e-01,  2.0865e-01,  2.4836e-01,\n",
            "         -3.9604e-02],\n",
            "        [ 8.1174e-03, -1.1488e-01,  1.8652e-02, -1.7440e-01, -7.7156e-02,\n",
            "         -1.4428e-01,  7.9087e-02,  3.8629e-02, -1.1265e-01, -1.1626e-01,\n",
            "          2.6143e-01,  7.3711e-02,  4.5519e-01, -1.4862e-01,  8.1638e-02,\n",
            "          1.8737e-01],\n",
            "        [-2.2407e-01, -1.5138e-01,  6.2191e-02, -1.4322e-01,  1.6100e-01,\n",
            "         -1.7743e-01, -1.8073e-01, -2.1175e-01, -2.2617e-02, -2.2088e-01,\n",
            "         -1.0865e-01,  3.7797e-02,  3.4240e-01, -2.3606e-02, -6.7025e-02,\n",
            "         -1.2654e-01],\n",
            "        [ 1.1590e-01,  1.4031e-01, -3.1718e-02, -1.8930e-01, -2.0172e-01,\n",
            "          1.6705e-01, -3.9715e-03,  1.4416e-02, -1.4847e-01, -8.5948e-02,\n",
            "         -1.5479e-01, -2.0814e-01, -1.0915e-01, -6.4937e-02,  1.3536e-01,\n",
            "         -1.1252e-01],\n",
            "        [ 1.1400e-01,  1.2670e-01, -9.4142e-02,  2.2125e-01,  8.7769e-02,\n",
            "         -1.4122e-01, -2.1704e-01,  2.5342e-01, -2.3804e-01, -2.2721e-01,\n",
            "          1.4857e-01, -6.4671e-02,  1.9436e-01,  1.2261e-02, -1.0116e-01,\n",
            "          1.2413e-01],\n",
            "        [ 1.4834e-01,  8.0033e-02, -2.4048e-01,  1.7771e-01, -2.3158e-01,\n",
            "         -7.6329e-02, -2.0996e-01, -6.3100e-02,  1.5372e-02,  1.3870e-01,\n",
            "         -1.4880e-01, -2.1168e-01,  2.0207e-01,  1.1287e-01,  1.4759e-01,\n",
            "         -6.6902e-02],\n",
            "        [-3.4798e-01,  1.6081e-01,  2.0357e-02,  1.9081e-01,  5.0584e-02,\n",
            "          1.9415e-03,  1.7567e-01, -6.2626e-03, -2.0720e-01, -1.1828e-01,\n",
            "          5.8440e-03,  6.1712e-02,  3.9281e-01, -2.9780e-01, -5.9036e-02,\n",
            "         -1.2758e-01],\n",
            "        [-2.0107e-01,  1.6456e-01,  1.8407e-01, -1.2933e-01,  6.4227e-02,\n",
            "         -1.3238e-01,  2.1583e-01,  1.3864e-01,  2.6785e-02,  1.4554e-01,\n",
            "          1.4246e-01, -2.1732e-01,  3.6441e-01,  1.5745e-01, -2.2281e-01,\n",
            "         -7.5553e-02],\n",
            "        [ 9.3545e-02, -1.8865e-01,  8.2021e-02,  2.0978e-01,  4.2600e-02,\n",
            "         -9.7730e-03, -1.8544e-01, -2.1497e-01,  6.3763e-02, -1.5792e-01,\n",
            "          1.3635e-01, -8.8699e-02, -1.5875e-02, -2.1054e-01, -2.1461e-01,\n",
            "          9.2810e-02],\n",
            "        [-1.9315e-01,  1.2705e-02,  1.6118e-02, -8.3285e-02,  2.0793e-01,\n",
            "          9.9304e-02,  1.7240e-01,  9.4548e-02,  2.2899e-01, -1.2062e-01,\n",
            "         -1.3881e-01,  2.5905e-01, -6.1791e-02, -2.7566e-02, -7.4084e-02,\n",
            "         -1.7856e-01],\n",
            "        [-1.4232e-01, -6.0751e-02, -7.0747e-02,  9.9476e-02,  6.8895e-03,\n",
            "          9.1614e-02,  2.3037e-01,  2.6472e-01,  1.1738e-01, -2.1740e-02,\n",
            "         -3.0149e-01, -7.2115e-02,  6.7484e-02, -3.1745e-02, -2.1295e-01,\n",
            "         -1.7590e-01]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([ 0.1089,  0.0497, -0.2502,  0.0047, -0.0178,  0.0242, -0.1570,  0.1806,\n",
            "        -0.1977,  0.1025,  0.1536, -0.1971,  0.0304, -0.0693, -0.1604, -0.0634,\n",
            "         0.1852, -0.2088,  0.0131, -0.3451, -0.0474, -0.0816, -0.1148, -0.2092,\n",
            "         0.1305,  0.0433, -0.0430, -0.0532, -0.3834,  0.0726, -0.1029, -0.0379],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[ 0.0968, -0.0247, -0.0150, -0.0238, -0.0143, -0.0005, -0.1188,  0.2026,\n",
            "          0.0780, -0.0192, -0.0174,  0.1575,  0.0075,  0.0150, -0.0807, -0.0064,\n",
            "         -0.0051, -0.0360,  0.1045,  0.0205,  0.0333,  0.0411, -0.1346, -0.0768,\n",
            "          0.0724,  0.0403, -0.1625, -0.0562,  0.0378, -0.0261,  0.0085, -0.1008]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([-0.0030], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1000 Trajectories:"
      ],
      "metadata": {
        "id": "vkoraLdAJMad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# single cumprod\n",
        "# 1000 trajectories\n",
        "model11 = train_var_play(model10, 500, 0.0001, padded_state_tensors, states_first_tensor, states_last_tensor, 1, 1, testing)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7wNPtMDLjuq",
        "outputId": "7f9ffd94-4372-425f-a352-08a0eeb8e8a7"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8435369920087568e-06\n",
            "E_s_wdiff_all_sq: 9.069579199805096e-08\n",
            "E_IS_SCOPE: -1.1038198776012357e-05\n",
            "E_IS_E_SCOPE: -9.750861916403596e-06\n",
            "Total Loss: 3.032905472266013e-07\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "Var loss:  tensor(2.8471e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6681551818117882e-06\n",
            "E_s_wdiff_all_sq: 1.4820307511116906e-10\n",
            "E_IS_SCOPE: -1.013852417975717e-05\n",
            "E_IS_E_SCOPE: -8.884314617475877e-06\n",
            "Total Loss: 2.8471092060750724e-07\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "Var loss:  tensor(3.2981e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7046211317725032e-06\n",
            "E_s_wdiff_all_sq: 4.237948817006082e-08\n",
            "E_IS_SCOPE: -9.460547193621885e-06\n",
            "E_IS_E_SCOPE: -8.231770336608416e-06\n",
            "Total Loss: 3.2981099600892257e-07\n",
            "----------------------------------------\n",
            "Epoch 14\n",
            "Var loss:  tensor(3.4469e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7323293298567792e-06\n",
            "E_s_wdiff_all_sq: 6.635520273798164e-08\n",
            "E_IS_SCOPE: -9.318184677880333e-06\n",
            "E_IS_E_SCOPE: -8.09497858587953e-06\n",
            "Total Loss: 3.446850095506056e-07\n",
            "----------------------------------------\n",
            "Epoch 15\n",
            "Var loss:  tensor(3.0606e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6771839375519107e-06\n",
            "E_s_wdiff_all_sq: 2.1624156834102108e-08\n",
            "E_IS_SCOPE: -9.697189173535676e-06\n",
            "E_IS_E_SCOPE: -8.4598758712155e-06\n",
            "Total Loss: 3.0605624251087236e-07\n",
            "----------------------------------------\n",
            "Epoch 16\n",
            "Var loss:  tensor(2.7890e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6809097910442335e-06\n",
            "E_s_wdiff_all_sq: 2.7394327085961113e-09\n",
            "E_IS_SCOPE: -1.0353392876240718e-05\n",
            "E_IS_E_SCOPE: -9.091198577162251e-06\n",
            "Total Loss: 2.789048266121174e-07\n",
            "----------------------------------------\n",
            "Epoch 17\n",
            "Var loss:  tensor(2.9800e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8017804567123004e-06\n",
            "E_s_wdiff_all_sq: 5.819853221471494e-08\n",
            "E_IS_SCOPE: -1.09555982516869e-05\n",
            "E_IS_E_SCOPE: -9.670246106715022e-06\n",
            "Total Loss: 2.9800070098724416e-07\n",
            "----------------------------------------\n",
            "Epoch 18\n",
            "Var loss:  tensor(3.2048e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8969961180210046e-06\n",
            "E_s_wdiff_all_sq: 1.1019503763098044e-07\n",
            "E_IS_SCOPE: -1.1214237305682962e-05\n",
            "E_IS_E_SCOPE: -9.91851288625117e-06\n",
            "Total Loss: 3.20475307959855e-07\n",
            "----------------------------------------\n",
            "Epoch 19\n",
            "Var loss:  tensor(3.0660e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8480626340308605e-06\n",
            "E_s_wdiff_all_sq: 8.716692414689072e-08\n",
            "E_IS_SCOPE: -1.1039250381753849e-05\n",
            "E_IS_E_SCOPE: -9.749540773018597e-06\n",
            "Total Loss: 3.0659955884688105e-07\n",
            "----------------------------------------\n",
            "Epoch 20\n",
            "Var loss:  tensor(2.8092e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7263589137825757e-06\n",
            "E_s_wdiff_all_sq: 2.7093288370840447e-08\n",
            "E_IS_SCOPE: -1.0549193306570451e-05\n",
            "E_IS_E_SCOPE: -9.277456981699345e-06\n",
            "Total Loss: 2.809160421029356e-07\n",
            "----------------------------------------\n",
            "Epoch 21\n",
            "Var loss:  tensor(2.8161e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6585675003353047e-06\n",
            "E_s_wdiff_all_sq: 1.5048879050382775e-10\n",
            "E_IS_SCOPE: -9.988300349096995e-06\n",
            "E_IS_E_SCOPE: -8.73733477946256e-06\n",
            "Total Loss: 2.81608938709348e-07\n",
            "----------------------------------------\n",
            "Epoch 22\n",
            "Var loss:  tensor(2.9975e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.656183210809849e-06\n",
            "E_s_wdiff_all_sq: 7.0180357459615034e-09\n",
            "E_IS_SCOPE: -9.619636655739366e-06\n",
            "E_IS_E_SCOPE: -8.382369874497133e-06\n",
            "Total Loss: 2.9975467901283864e-07\n",
            "----------------------------------------\n",
            "Epoch 23\n",
            "Var loss:  tensor(3.0090e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6546854679117633e-06\n",
            "E_s_wdiff_all_sq: 6.07679079287042e-09\n",
            "E_IS_SCOPE: -9.597536756834598e-06\n",
            "E_IS_E_SCOPE: -8.361122973005699e-06\n",
            "Total Loss: 3.009041758945099e-07\n",
            "----------------------------------------\n",
            "Epoch 24\n",
            "Var loss:  tensor(2.8374e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6540051363120575e-06\n",
            "E_s_wdiff_all_sq: 4.834190648879977e-10\n",
            "E_IS_SCOPE: -9.897225454613175e-06\n",
            "E_IS_E_SCOPE: -8.649775199159999e-06\n",
            "Total Loss: 2.8374427277423233e-07\n",
            "----------------------------------------\n",
            "Epoch 25\n",
            "Var loss:  tensor(2.7597e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7066197763006891e-06\n",
            "E_s_wdiff_all_sq: 2.7509847190423823e-08\n",
            "E_IS_SCOPE: -1.0351394058015706e-05\n",
            "E_IS_E_SCOPE: -9.087261235238343e-06\n",
            "Total Loss: 2.759673499889514e-07\n",
            "----------------------------------------\n",
            "Epoch 26\n",
            "Var loss:  tensor(2.8587e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7992694006032959e-06\n",
            "E_s_wdiff_all_sq: 8.221050283084085e-08\n",
            "E_IS_SCOPE: -1.0736313291300548e-05\n",
            "E_IS_E_SCOPE: -9.458159443730113e-06\n",
            "Total Loss: 2.858742690650022e-07\n",
            "----------------------------------------\n",
            "Epoch 27\n",
            "Var loss:  tensor(2.9223e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8438440398062562e-06\n",
            "E_s_wdiff_all_sq: 1.1061199634434994e-07\n",
            "E_IS_SCOPE: -1.0875971347590517e-05\n",
            "E_IS_E_SCOPE: -9.592908058398854e-06\n",
            "Total Loss: 2.922285315119952e-07\n",
            "----------------------------------------\n",
            "Epoch 28\n",
            "Var loss:  tensor(2.8333e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7985129581236776e-06\n",
            "E_s_wdiff_all_sq: 8.522802025912445e-08\n",
            "E_IS_SCOPE: -1.073060654579793e-05\n",
            "E_IS_E_SCOPE: -9.453065219652134e-06\n",
            "Total Loss: 2.8332535200637716e-07\n",
            "----------------------------------------\n",
            "Epoch 29\n",
            "Var loss:  tensor(2.7433e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7183258676331013e-06\n",
            "E_s_wdiff_all_sq: 3.825185134239775e-08\n",
            "E_IS_SCOPE: -1.040134421201283e-05\n",
            "E_IS_E_SCOPE: -9.135909792211953e-06\n",
            "Total Loss: 2.7432824312236516e-07\n",
            "----------------------------------------\n",
            "Epoch 30\n",
            "Var loss:  tensor(2.7817e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6695471996792159e-06\n",
            "E_s_wdiff_all_sq: 9.579788770699002e-09\n",
            "E_IS_SCOPE: -1.0070098569364722e-05\n",
            "E_IS_E_SCOPE: -8.816638982144357e-06\n",
            "Total Loss: 2.781713029012037e-07\n",
            "----------------------------------------\n",
            "Epoch 31\n",
            "Var loss:  tensor(2.8465e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6574289329627577e-06\n",
            "E_s_wdiff_all_sq: 2.383153220342337e-09\n",
            "E_IS_SCOPE: -9.90547208542088e-06\n",
            "E_IS_E_SCOPE: -8.657711996004091e-06\n",
            "Total Loss: 2.8464866734225333e-07\n",
            "----------------------------------------\n",
            "Epoch 32\n",
            "Var loss:  tensor(2.8093e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6621009246577875e-06\n",
            "E_s_wdiff_all_sq: 4.828221179828129e-09\n",
            "E_IS_SCOPE: -9.9761540331261e-06\n",
            "E_IS_E_SCOPE: -8.72542341588035e-06\n",
            "Total Loss: 2.8093453541987614e-07\n",
            "----------------------------------------\n",
            "Epoch 33\n",
            "Var loss:  tensor(2.7343e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.688675314338477e-06\n",
            "E_s_wdiff_all_sq: 2.0101730256030135e-08\n",
            "E_IS_SCOPE: -1.02256004733299e-05\n",
            "E_IS_E_SCOPE: -8.965468562112827e-06\n",
            "Total Loss: 2.7343282808171837e-07\n",
            "----------------------------------------\n",
            "Epoch 34\n",
            "Var loss:  tensor(2.7392e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7395695851463808e-06\n",
            "E_s_wdiff_all_sq: 4.9720805790818394e-08\n",
            "E_IS_SCOPE: -1.0509647848056694e-05\n",
            "E_IS_E_SCOPE: -9.239123962011318e-06\n",
            "Total Loss: 2.7392407369822753e-07\n",
            "----------------------------------------\n",
            "Epoch 35\n",
            "Var loss:  tensor(2.7874e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7779000417897504e-06\n",
            "E_s_wdiff_all_sq: 7.144356849692458e-08\n",
            "E_IS_SCOPE: -1.0674123965770139e-05\n",
            "E_IS_E_SCOPE: -9.397703046751705e-06\n",
            "Total Loss: 2.7873770168937406e-07\n",
            "----------------------------------------\n",
            "Epoch 36\n",
            "Var loss:  tensor(2.7748e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7653944115231058e-06\n",
            "E_s_wdiff_all_sq: 6.282728384254235e-08\n",
            "E_IS_SCOPE: -1.0638127519760087e-05\n",
            "E_IS_E_SCOPE: -9.363020197556958e-06\n",
            "Total Loss: 2.774755497077237e-07\n",
            "----------------------------------------\n",
            "Epoch 37\n",
            "Var loss:  tensor(2.7209e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.71610358233623e-06\n",
            "E_s_wdiff_all_sq: 3.3356438660741866e-08\n",
            "E_IS_SCOPE: -1.043233953055605e-05\n",
            "E_IS_E_SCOPE: -9.164451798514617e-06\n",
            "Total Loss: 2.7209474602603907e-07\n",
            "----------------------------------------\n",
            "Epoch 38\n",
            "Var loss:  tensor(2.7146e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6743945915731427e-06\n",
            "E_s_wdiff_all_sq: 9.699209097463843e-09\n",
            "E_IS_SCOPE: -1.0177104032858885e-05\n",
            "E_IS_E_SCOPE: -8.91792466823561e-06\n",
            "Total Loss: 2.714597196625433e-07\n",
            "----------------------------------------\n",
            "Epoch 39\n",
            "Var loss:  tensor(2.7465e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6588719987574969e-06\n",
            "E_s_wdiff_all_sq: 1.569561423769858e-09\n",
            "E_IS_SCOPE: -1.0010334931618548e-05\n",
            "E_IS_E_SCOPE: -8.756444857804298e-06\n",
            "Total Loss: 2.746453561386403e-07\n",
            "----------------------------------------\n",
            "Epoch 40\n",
            "Var loss:  tensor(2.7412e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.659312993395853e-06\n",
            "E_s_wdiff_all_sq: 9.675658626765192e-10\n",
            "E_IS_SCOPE: -1.0014069263921202e-05\n",
            "E_IS_E_SCOPE: -8.759394030441759e-06\n",
            "Total Loss: 2.7411802700770695e-07\n",
            "----------------------------------------\n",
            "Epoch 41\n",
            "Var loss:  tensor(2.7031e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.671059484881144e-06\n",
            "E_s_wdiff_all_sq: 4.646271766222259e-09\n",
            "E_IS_SCOPE: -1.0169902172356884e-05\n",
            "E_IS_E_SCOPE: -8.909287000225669e-06\n",
            "Total Loss: 2.7030593528590487e-07\n",
            "----------------------------------------\n",
            "Epoch 42\n",
            "Var loss:  tensor(2.6953e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6955407571355302e-06\n",
            "E_s_wdiff_all_sq: 1.4921697913525555e-08\n",
            "E_IS_SCOPE: -1.0378385203481073e-05\n",
            "E_IS_E_SCOPE: -9.110281596144436e-06\n",
            "Total Loss: 2.6953491098214627e-07\n",
            "----------------------------------------\n",
            "Epoch 43\n",
            "Var loss:  tensor(2.7160e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7169536650224805e-06\n",
            "E_s_wdiff_all_sq: 2.4886194164612132e-08\n",
            "E_IS_SCOPE: -1.051738333373614e-05\n",
            "E_IS_E_SCOPE: -9.2445875011386e-06\n",
            "Total Loss: 2.715988720962057e-07\n",
            "----------------------------------------\n",
            "Epoch 44\n",
            "Var loss:  tensor(2.7114e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7144924018112085e-06\n",
            "E_s_wdiff_all_sq: 2.3781199635505362e-08\n",
            "E_IS_SCOPE: -1.0514133680660362e-05\n",
            "E_IS_E_SCOPE: -9.24178548497944e-06\n",
            "Total Loss: 2.711378772472746e-07\n",
            "----------------------------------------\n",
            "Epoch 45\n",
            "Var loss:  tensor(2.6839e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6915426963399843e-06\n",
            "E_s_wdiff_all_sq: 1.3317684808283942e-08\n",
            "E_IS_SCOPE: -1.038222583466663e-05\n",
            "E_IS_E_SCOPE: -9.114749085637569e-06\n",
            "Total Loss: 2.68394579906992e-07\n",
            "----------------------------------------\n",
            "Epoch 46\n",
            "Var loss:  tensor(2.6782e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6700411080063385e-06\n",
            "E_s_wdiff_all_sq: 4.535386397575181e-09\n",
            "E_IS_SCOPE: -1.020833430254202e-05\n",
            "E_IS_E_SCOPE: -8.946932347961355e-06\n",
            "Total Loss: 2.6782487888084654e-07\n",
            "----------------------------------------\n",
            "Epoch 47\n",
            "Var loss:  tensor(2.6908e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6610411768665737e-06\n",
            "E_s_wdiff_all_sq: 1.7326342566753764e-09\n",
            "E_IS_SCOPE: -1.00977639026607e-05\n",
            "E_IS_E_SCOPE: -8.840088954133444e-06\n",
            "Total Loss: 2.6908171198880004e-07\n",
            "----------------------------------------\n",
            "Epoch 48\n",
            "Var loss:  tensor(2.6843e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6628066778868443e-06\n",
            "E_s_wdiff_all_sq: 3.0908016453067334e-09\n",
            "E_IS_SCOPE: -1.0111004029943194e-05\n",
            "E_IS_E_SCOPE: -8.852801825385503e-06\n",
            "Total Loss: 2.684345335595736e-07\n",
            "----------------------------------------\n",
            "Epoch 49\n",
            "Var loss:  tensor(2.6645e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6764625717159275e-06\n",
            "E_s_wdiff_all_sq: 1.0667099139353596e-08\n",
            "E_IS_SCOPE: -1.0229238553510087e-05\n",
            "E_IS_E_SCOPE: -8.96700363585541e-06\n",
            "Total Loss: 2.664487037006344e-07\n",
            "----------------------------------------\n",
            "Epoch 50\n",
            "Var loss:  tensor(2.6617e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7007742196165464e-06\n",
            "E_s_wdiff_all_sq: 2.5642278851107286e-08\n",
            "E_IS_SCOPE: -1.037407816013836e-05\n",
            "E_IS_E_SCOPE: -9.107036118964874e-06\n",
            "Total Loss: 2.661709248518852e-07\n",
            "----------------------------------------\n",
            "Epoch 51\n",
            "Var loss:  tensor(2.6684e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7205066919778037e-06\n",
            "E_s_wdiff_all_sq: 3.941964509775908e-08\n",
            "E_IS_SCOPE: -1.0457372341022442e-05\n",
            "E_IS_E_SCOPE: -9.18768873797364e-06\n",
            "Total Loss: 2.6684290721585447e-07\n",
            "----------------------------------------\n",
            "Epoch 52\n",
            "Var loss:  tensor(2.6599e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7201163618590407e-06\n",
            "E_s_wdiff_all_sq: 4.1737694905049835e-08\n",
            "E_IS_SCOPE: -1.0432515549215233e-05\n",
            "E_IS_E_SCOPE: -9.163757980750616e-06\n",
            "Total Loss: 2.659865964581729e-07\n",
            "----------------------------------------\n",
            "Epoch 53\n",
            "Var loss:  tensor(2.6456e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7033898788555505e-06\n",
            "E_s_wdiff_all_sq: 3.360087996965589e-08\n",
            "E_IS_SCOPE: -1.0323273068031307e-05\n",
            "E_IS_E_SCOPE: -9.058094584576157e-06\n",
            "Total Loss: 2.645550984090112e-07\n",
            "----------------------------------------\n",
            "Epoch 54\n",
            "Var loss:  tensor(2.6451e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6866974174824644e-06\n",
            "E_s_wdiff_all_sq: 2.449915043027074e-08\n",
            "E_IS_SCOPE: -1.0204731180126292e-05\n",
            "E_IS_E_SCOPE: -8.94332793802133e-06\n",
            "Total Loss: 2.6451484927568523e-07\n",
            "----------------------------------------\n",
            "Epoch 55\n",
            "Var loss:  tensor(2.6471e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6805090730716287e-06\n",
            "E_s_wdiff_all_sq: 2.1157753439095683e-08\n",
            "E_IS_SCOPE: -1.0153382997093178e-05\n",
            "E_IS_E_SCOPE: -8.893499534188353e-06\n",
            "Total Loss: 2.6470746025629633e-07\n",
            "----------------------------------------\n",
            "Epoch 56\n",
            "Var loss:  tensor(2.6373e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6859556244337802e-06\n",
            "E_s_wdiff_all_sq: 2.4679244959016808e-08\n",
            "E_IS_SCOPE: -1.0194442276697134e-05\n",
            "E_IS_E_SCOPE: -8.933107365418894e-06\n",
            "Total Loss: 2.6372962335170036e-07\n",
            "----------------------------------------\n",
            "Epoch 57\n",
            "Var loss:  tensor(2.6277e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6999397898224377e-06\n",
            "E_s_wdiff_all_sq: 3.309090192137437e-08\n",
            "E_IS_SCOPE: -1.0293761592938672e-05\n",
            "E_IS_E_SCOPE: -9.029161518063023e-06\n",
            "Total Loss: 2.6277180458318033e-07\n",
            "----------------------------------------\n",
            "Epoch 58\n",
            "Var loss:  tensor(2.6278e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.712900179163878e-06\n",
            "E_s_wdiff_all_sq: 4.0354741865224495e-08\n",
            "E_IS_SCOPE: -1.0383789899492356e-05\n",
            "E_IS_E_SCOPE: -9.116343933255279e-06\n",
            "Total Loss: 2.6277657125791473e-07\n",
            "----------------------------------------\n",
            "Epoch 59\n",
            "Var loss:  tensor(2.6256e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7133490944394828e-06\n",
            "E_s_wdiff_all_sq: 3.976445027982784e-08\n",
            "E_IS_SCOPE: -1.040930318296914e-05\n",
            "E_IS_E_SCOPE: -9.141227590330314e-06\n",
            "Total Loss: 2.625565253154178e-07\n",
            "----------------------------------------\n",
            "Epoch 60\n",
            "Var loss:  tensor(2.6160e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7005683027948266e-06\n",
            "E_s_wdiff_all_sq: 3.1409142139555215e-08\n",
            "E_IS_SCOPE: -1.0358677924371899e-05\n",
            "E_IS_E_SCOPE: -9.092338059636917e-06\n",
            "Total Loss: 2.6160249761872307e-07\n",
            "----------------------------------------\n",
            "Epoch 61\n",
            "Var loss:  tensor(2.6102e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6846679473639299e-06\n",
            "E_s_wdiff_all_sq: 2.1525628806611662e-08\n",
            "E_IS_SCOPE: -1.0273607892391687e-05\n",
            "E_IS_E_SCOPE: -9.009984759264032e-06\n",
            "Total Loss: 2.6101911873542425e-07\n",
            "----------------------------------------\n",
            "Epoch 62\n",
            "Var loss:  tensor(2.6095e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6753804916220374e-06\n",
            "E_s_wdiff_all_sq: 1.5767248312170563e-08\n",
            "E_IS_SCOPE: -1.021932237921305e-05\n",
            "E_IS_E_SCOPE: -8.95743031263865e-06\n",
            "Total Loss: 2.609521765944829e-07\n",
            "----------------------------------------\n",
            "Epoch 63\n",
            "Var loss:  tensor(2.6043e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6754474621028189e-06\n",
            "E_s_wdiff_all_sq: 1.555849222252975e-08\n",
            "E_IS_SCOPE: -1.023144871980216e-05\n",
            "E_IS_E_SCOPE: -8.969156838861936e-06\n",
            "Total Loss: 2.6042827443325253e-07\n",
            "----------------------------------------\n",
            "Epoch 64\n",
            "Var loss:  tensor(2.5963e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6833450004286785e-06\n",
            "E_s_wdiff_all_sq: 2.00222283492076e-08\n",
            "E_IS_SCOPE: -1.0297261690842088e-05\n",
            "E_IS_E_SCOPE: -9.032854478472763e-06\n",
            "Total Loss: 2.5963141377423665e-07\n",
            "----------------------------------------\n",
            "Epoch 65\n",
            "Var loss:  tensor(2.5928e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6938466470010356e-06\n",
            "E_s_wdiff_all_sq: 2.6212260038095294e-08\n",
            "E_IS_SCOPE: -1.0368941428475684e-05\n",
            "E_IS_E_SCOPE: -9.102200319473801e-06\n",
            "Total Loss: 2.592752353925906e-07\n",
            "----------------------------------------\n",
            "Epoch 66\n",
            "Var loss:  tensor(2.5901e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6991444088206006e-06\n",
            "E_s_wdiff_all_sq: 2.968474046573108e-08\n",
            "E_IS_SCOPE: -1.040033976517296e-05\n",
            "E_IS_E_SCOPE: -9.132553826772803e-06\n",
            "Total Loss: 2.5901085798797174e-07\n",
            "----------------------------------------\n",
            "Epoch 67\n",
            "Var loss:  tensor(2.5836e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6952385391430819e-06\n",
            "E_s_wdiff_all_sq: 2.8056837322549774e-08\n",
            "E_IS_SCOPE: -1.0375143866669837e-05\n",
            "E_IS_E_SCOPE: -9.108169757822188e-06\n",
            "Total Loss: 2.583565505586515e-07\n",
            "----------------------------------------\n",
            "Epoch 68\n",
            "Var loss:  tensor(2.5774e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6861299915438776e-06\n",
            "E_s_wdiff_all_sq: 2.3616246356267666e-08\n",
            "E_IS_SCOPE: -1.0313852323114753e-05\n",
            "E_IS_E_SCOPE: -9.04890338540679e-06\n",
            "Total Loss: 2.5773893620509985e-07\n",
            "----------------------------------------\n",
            "Epoch 69\n",
            "Var loss:  tensor(2.5744e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6795925224295217e-06\n",
            "E_s_wdiff_all_sq: 2.0777977201148218e-08\n",
            "E_IS_SCOPE: -1.026252868496401e-05\n",
            "E_IS_E_SCOPE: -8.999280305833908e-06\n",
            "Total Loss: 2.5744085340158523e-07\n",
            "----------------------------------------\n",
            "Epoch 70\n",
            "Var loss:  tensor(2.5700e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6800677379171797e-06\n",
            "E_s_wdiff_all_sq: 2.178652902639422e-08\n",
            "E_IS_SCOPE: -1.0259703383982257e-05\n",
            "E_IS_E_SCOPE: -8.996499770074034e-06\n",
            "Total Loss: 2.5699704750775524e-07\n",
            "----------------------------------------\n",
            "Epoch 71\n",
            "Var loss:  tensor(2.5633e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6873302316837961e-06\n",
            "E_s_wdiff_all_sq: 2.6672399417262403e-08\n",
            "E_IS_SCOPE: -1.0302736744762634e-05\n",
            "E_IS_E_SCOPE: -9.038011193109923e-06\n",
            "Total Loss: 2.5632979539452785e-07\n",
            "----------------------------------------\n",
            "Epoch 72\n",
            "Var loss:  tensor(2.5589e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6969551657655534e-06\n",
            "E_s_wdiff_all_sq: 3.2926729684886056e-08\n",
            "E_IS_SCOPE: -1.0357699113701884e-05\n",
            "E_IS_E_SCOPE: -9.09106912618483e-06\n",
            "Total Loss: 2.558915274799738e-07\n",
            "----------------------------------------\n",
            "Epoch 73\n",
            "Var loss:  tensor(2.5553e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7018017089726907e-06\n",
            "E_s_wdiff_all_sq: 3.6382618581506375e-08\n",
            "E_IS_SCOPE: -1.0383623092620069e-05\n",
            "E_IS_E_SCOPE: -9.116117253468467e-06\n",
            "Total Loss: 2.555304785213972e-07\n",
            "----------------------------------------\n",
            "Epoch 74\n",
            "Var loss:  tensor(2.5494e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6986675579630156e-06\n",
            "E_s_wdiff_all_sq: 3.5138170036746104e-08\n",
            "E_IS_SCOPE: -1.0367479227714155e-05\n",
            "E_IS_E_SCOPE: -9.100623491040543e-06\n",
            "Total Loss: 2.5494098101245916e-07\n",
            "----------------------------------------\n",
            "Epoch 75\n",
            "Var loss:  tensor(2.5439e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.691336738703416e-06\n",
            "E_s_wdiff_all_sq: 3.1319864072879146e-08\n",
            "E_IS_SCOPE: -1.0327295495612857e-05\n",
            "E_IS_E_SCOPE: -9.061919254679542e-06\n",
            "Total Loss: 2.5438745919732187e-07\n",
            "----------------------------------------\n",
            "Epoch 76\n",
            "Var loss:  tensor(2.5399e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.68625377228405e-06\n",
            "E_s_wdiff_all_sq: 2.8847371466938995e-08\n",
            "E_IS_SCOPE: -1.0297841802881952e-05\n",
            "E_IS_E_SCOPE: -9.033572898476192e-06\n",
            "Total Loss: 2.5399165843900944e-07\n",
            "----------------------------------------\n",
            "Epoch 77\n",
            "Var loss:  tensor(2.5350e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6869615427594639e-06\n",
            "E_s_wdiff_all_sq: 2.991807328767732e-08\n",
            "E_IS_SCOPE: -1.0303328543166916e-05\n",
            "E_IS_E_SCOPE: -9.038996351620883e-06\n",
            "Total Loss: 2.53502152813134e-07\n",
            "----------------------------------------\n",
            "Epoch 78\n",
            "Var loss:  tensor(2.5291e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6926371057306124e-06\n",
            "E_s_wdiff_all_sq: 3.401659189511269e-08\n",
            "E_IS_SCOPE: -1.033884027112403e-05\n",
            "E_IS_E_SCOPE: -9.07342309635166e-06\n",
            "Total Loss: 2.5290923072417385e-07\n",
            "----------------------------------------\n",
            "Epoch 79\n",
            "Var loss:  tensor(2.5245e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6991088449331352e-06\n",
            "E_s_wdiff_all_sq: 3.856102807188364e-08\n",
            "E_IS_SCOPE: -1.0377310638533448e-05\n",
            "E_IS_E_SCOPE: -9.110698742504925e-06\n",
            "Total Loss: 2.524470912376194e-07\n",
            "----------------------------------------\n",
            "Epoch 80\n",
            "Var loss:  tensor(2.5200e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7009310612530155e-06\n",
            "E_s_wdiff_all_sq: 4.005269032608846e-08\n",
            "E_IS_SCOPE: -1.0392116091667854e-05\n",
            "E_IS_E_SCOPE: -9.125115354444773e-06\n",
            "Total Loss: 2.519999629141794e-07\n",
            "----------------------------------------\n",
            "Epoch 81\n",
            "Var loss:  tensor(2.5144e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6966764378245395e-06\n",
            "E_s_wdiff_all_sq: 3.771075791094428e-08\n",
            "E_IS_SCOPE: -1.0374844450179033e-05\n",
            "E_IS_E_SCOPE: -9.108519528487823e-06\n",
            "Total Loss: 2.5143890296459267e-07\n",
            "----------------------------------------\n",
            "Epoch 82\n",
            "Var loss:  tensor(2.5092e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6903567823540141e-06\n",
            "E_s_wdiff_all_sq: 3.3946121441320736e-08\n",
            "E_IS_SCOPE: -1.0343716826748964e-05\n",
            "E_IS_E_SCOPE: -9.078407923984629e-06\n",
            "Total Loss: 2.5091592181743857e-07\n",
            "----------------------------------------\n",
            "Epoch 83\n",
            "Var loss:  tensor(2.5046e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6868975641107207e-06\n",
            "E_s_wdiff_all_sq: 3.191221886486607e-08\n",
            "E_IS_SCOPE: -1.0326249017078746e-05\n",
            "E_IS_E_SCOPE: -9.06142505098491e-06\n",
            "Total Loss: 2.5046047949159915e-07\n",
            "----------------------------------------\n",
            "Epoch 84\n",
            "Var loss:  tensor(2.4993e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6877545976774454e-06\n",
            "E_s_wdiff_all_sq: 3.255838336680427e-08\n",
            "E_IS_SCOPE: -1.0337004492665508e-05\n",
            "E_IS_E_SCOPE: -9.071809217210522e-06\n",
            "Total Loss: 2.499287298340844e-07\n",
            "----------------------------------------\n",
            "Epoch 85\n",
            "Var loss:  tensor(2.4940e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6913967052814574e-06\n",
            "E_s_wdiff_all_sq: 3.499453223176534e-08\n",
            "E_IS_SCOPE: -1.0367684007349612e-05\n",
            "E_IS_E_SCOPE: -9.101620531403742e-06\n",
            "Total Loss: 2.4939828759136826e-07\n",
            "----------------------------------------\n",
            "Epoch 86\n",
            "Var loss:  tensor(2.4892e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6942272265366266e-06\n",
            "E_s_wdiff_all_sq: 3.718146574746891e-08\n",
            "E_IS_SCOPE: -1.0391048031284924e-05\n",
            "E_IS_E_SCOPE: -9.124421282249255e-06\n",
            "Total Loss: 2.4891532915123697e-07\n",
            "----------------------------------------\n",
            "Epoch 87\n",
            "Var loss:  tensor(2.4840e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6936831451070829e-06\n",
            "E_s_wdiff_all_sq: 3.7277709581075264e-08\n",
            "E_IS_SCOPE: -1.0391378522643025e-05\n",
            "E_IS_E_SCOPE: -9.124813721269722e-06\n",
            "Total Loss: 2.483988992128177e-07\n",
            "----------------------------------------\n",
            "Epoch 88\n",
            "Var loss:  tensor(2.4785e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6910714802243535e-06\n",
            "E_s_wdiff_all_sq: 3.5850913573887225e-08\n",
            "E_IS_SCOPE: -1.0373839366150871e-05\n",
            "E_IS_E_SCOPE: -9.107594570107407e-06\n",
            "Total Loss: 2.4785404099695315e-07\n",
            "----------------------------------------\n",
            "Epoch 89\n",
            "Var loss:  tensor(2.4735e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6885233322919809e-06\n",
            "E_s_wdiff_all_sq: 3.4403133696025766e-08\n",
            "E_IS_SCOPE: -1.0355011283800988e-05\n",
            "E_IS_E_SCOPE: -9.089064857947725e-06\n",
            "Total Loss: 2.47350413322845e-07\n",
            "----------------------------------------\n",
            "Epoch 90\n",
            "Var loss:  tensor(2.4685e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6879839029304935e-06\n",
            "E_s_wdiff_all_sq: 3.4323003697155966e-08\n",
            "E_IS_SCOPE: -1.0352187993372817e-05\n",
            "E_IS_E_SCOPE: -9.086222531448017e-06\n",
            "Total Loss: 2.4685304181715416e-07\n",
            "----------------------------------------\n",
            "Epoch 91\n",
            "Var loss:  tensor(2.4630e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.689582004464503e-06\n",
            "E_s_wdiff_all_sq: 3.584407588348409e-08\n",
            "E_IS_SCOPE: -1.0366366812968455e-05\n",
            "E_IS_E_SCOPE: -9.100088251447194e-06\n",
            "Total Loss: 2.463038719719139e-07\n",
            "----------------------------------------\n",
            "Epoch 92\n",
            "Var loss:  tensor(2.4577e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6922601381365734e-06\n",
            "E_s_wdiff_all_sq: 3.82415669918161e-08\n",
            "E_IS_SCOPE: -1.038658169615555e-05\n",
            "E_IS_E_SCOPE: -9.11989819409313e-06\n",
            "Total Loss: 2.4577463345332984e-07\n",
            "----------------------------------------\n",
            "Epoch 93\n",
            "Var loss:  tensor(2.4528e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6942455261185151e-06\n",
            "E_s_wdiff_all_sq: 4.0139691320894116e-08\n",
            "E_IS_SCOPE: -1.0398199454984302e-05\n",
            "E_IS_E_SCOPE: -9.131224824202295e-06\n",
            "Total Loss: 2.452796396670227e-07\n",
            "----------------------------------------\n",
            "Epoch 94\n",
            "Var loss:  tensor(2.4475e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6938742135876403e-06\n",
            "E_s_wdiff_all_sq: 4.037903109110672e-08\n",
            "E_IS_SCOPE: -1.0393696280311245e-05\n",
            "E_IS_E_SCOPE: -9.126760406711929e-06\n",
            "Total Loss: 2.447465017313164e-07\n",
            "----------------------------------------\n",
            "Epoch 95\n",
            "Var loss:  tensor(2.4420e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6918426142135116e-06\n",
            "E_s_wdiff_all_sq: 3.9567049451739617e-08\n",
            "E_IS_SCOPE: -1.0376156647799441e-05\n",
            "E_IS_E_SCOPE: -9.109558037984783e-06\n",
            "Total Loss: 2.442014115658689e-07\n",
            "----------------------------------------\n",
            "Epoch 96\n",
            "Var loss:  tensor(2.4368e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6903665787824395e-06\n",
            "E_s_wdiff_all_sq: 3.927720108231916e-08\n",
            "E_IS_SCOPE: -1.0361112924344464e-05\n",
            "E_IS_E_SCOPE: -9.094848024353296e-06\n",
            "Total Loss: 2.436826441511998e-07\n",
            "----------------------------------------\n",
            "Epoch 97\n",
            "Var loss:  tensor(2.4315e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6910058003735774e-06\n",
            "E_s_wdiff_all_sq: 4.005393060803126e-08\n",
            "E_IS_SCOPE: -1.0363375386530902e-05\n",
            "E_IS_E_SCOPE: -9.096913128895688e-06\n",
            "Total Loss: 2.4315042092853646e-07\n",
            "----------------------------------------\n",
            "Epoch 98\n",
            "Var loss:  tensor(2.4261e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6934241213630255e-06\n",
            "E_s_wdiff_all_sq: 4.1913488305550946e-08\n",
            "E_IS_SCOPE: -1.0377952679624788e-05\n",
            "E_IS_E_SCOPE: -9.110942065715619e-06\n",
            "Total Loss: 2.4261247167255045e-07\n",
            "----------------------------------------\n",
            "Epoch 99\n",
            "Var loss:  tensor(2.4210e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6957348936007011e-06\n",
            "E_s_wdiff_all_sq: 4.37335787672969e-08\n",
            "E_IS_SCOPE: -1.039187745577729e-05\n",
            "E_IS_E_SCOPE: -9.12436320385075e-06\n",
            "Total Loss: 2.4209587741373775e-07\n",
            "----------------------------------------\n",
            "Epoch 100\n",
            "Var loss:  tensor(2.4155e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6955513509714145e-06\n",
            "E_s_wdiff_all_sq: 4.390050913286332e-08\n",
            "E_IS_SCOPE: -1.0393149810482465e-05\n",
            "E_IS_E_SCOPE: -9.125539995224102e-06\n",
            "Total Loss: 2.4155427775523903e-07\n",
            "----------------------------------------\n",
            "Epoch 101\n",
            "Var loss:  tensor(2.4101e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.693310366680318e-06\n",
            "E_s_wdiff_all_sq: 4.2784238234586944e-08\n",
            "E_IS_SCOPE: -1.0383414445967806e-05\n",
            "E_IS_E_SCOPE: -9.11609238191256e-06\n",
            "Total Loss: 2.4100506676865403e-07\n",
            "----------------------------------------\n",
            "Epoch 102\n",
            "Var loss:  tensor(2.4047e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6910721691234906e-06\n",
            "E_s_wdiff_all_sq: 4.1670012133977186e-08\n",
            "E_IS_SCOPE: -1.0374398585770705e-05\n",
            "E_IS_E_SCOPE: -9.107370197455367e-06\n",
            "Total Loss: 2.4046844679225396e-07\n",
            "----------------------------------------\n",
            "Epoch 103\n",
            "Var loss:  tensor(2.3993e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6907452870210213e-06\n",
            "E_s_wdiff_all_sq: 4.180688744621543e-08\n",
            "E_IS_SCOPE: -1.037615061671181e-05\n",
            "E_IS_E_SCOPE: -9.109087350303633e-06\n",
            "Total Loss: 2.3993493319187044e-07\n",
            "----------------------------------------\n",
            "Epoch 104\n",
            "Var loss:  tensor(2.3939e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6921768464942244e-06\n",
            "E_s_wdiff_all_sq: 4.3324733919751014e-08\n",
            "E_IS_SCOPE: -1.0383226306463651e-05\n",
            "E_IS_E_SCOPE: -9.115933902185967e-06\n",
            "Total Loss: 2.393903704525204e-07\n",
            "----------------------------------------\n",
            "Epoch 105\n",
            "Var loss:  tensor(2.3884e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6941442222748227e-06\n",
            "E_s_wdiff_all_sq: 4.522637198548534e-08\n",
            "E_IS_SCOPE: -1.0389058919109852e-05\n",
            "E_IS_E_SCOPE: -9.12146036377818e-06\n",
            "Total Loss: 2.388438060594112e-07\n",
            "----------------------------------------\n",
            "Epoch 106\n",
            "Var loss:  tensor(2.3831e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6955026987577546e-06\n",
            "E_s_wdiff_all_sq: 4.658804669621946e-08\n",
            "E_IS_SCOPE: -1.0390998961024602e-05\n",
            "E_IS_E_SCOPE: -9.1231332967459e-06\n",
            "Total Loss: 2.3830638993754683e-07\n",
            "----------------------------------------\n",
            "Epoch 107\n",
            "Var loss:  tensor(2.3776e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6954669787093733e-06\n",
            "E_s_wdiff_all_sq: 4.6974658778947935e-08\n",
            "E_IS_SCOPE: -1.0387279545201746e-05\n",
            "E_IS_E_SCOPE: -9.119351867391869e-06\n",
            "Total Loss: 2.377600307440864e-07\n",
            "----------------------------------------\n",
            "Epoch 108\n",
            "Var loss:  tensor(2.3721e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6943973761721936e-06\n",
            "E_s_wdiff_all_sq: 4.674336415783465e-08\n",
            "E_IS_SCOPE: -1.0381463972924126e-05\n",
            "E_IS_E_SCOPE: -9.113681468071017e-06\n",
            "Total Loss: 2.3721206874155453e-07\n",
            "----------------------------------------\n",
            "Epoch 109\n",
            "Var loss:  tensor(2.3666e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6937746231358054e-06\n",
            "E_s_wdiff_all_sq: 4.698390400374258e-08\n",
            "E_IS_SCOPE: -1.0380116958032229e-05\n",
            "E_IS_E_SCOPE: -9.112490477741196e-06\n",
            "Total Loss: 2.3666082498341224e-07\n",
            "----------------------------------------\n",
            "Epoch 110\n",
            "Var loss:  tensor(2.3613e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6942466542058214e-06\n",
            "E_s_wdiff_all_sq: 4.8049587185144714e-08\n",
            "E_IS_SCOPE: -1.0386131933832583e-05\n",
            "E_IS_E_SCOPE: -9.118534410799879e-06\n",
            "Total Loss: 2.3612508738868452e-07\n",
            "----------------------------------------\n",
            "Epoch 111\n",
            "Var loss:  tensor(2.3557e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6960244447846707e-06\n",
            "E_s_wdiff_all_sq: 4.974454904358387e-08\n",
            "E_IS_SCOPE: -1.0396315503461139e-05\n",
            "E_IS_E_SCOPE: -9.128399292362523e-06\n",
            "Total Loss: 2.355705399772714e-07\n",
            "----------------------------------------\n",
            "Epoch 112\n",
            "Var loss:  tensor(2.3503e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.697802853075147e-06\n",
            "E_s_wdiff_all_sq: 5.1228372862228884e-08\n",
            "E_IS_SCOPE: -1.0403935574847117e-05\n",
            "E_IS_E_SCOPE: -9.13560020199953e-06\n",
            "Total Loss: 2.3502680095116249e-07\n",
            "----------------------------------------\n",
            "Epoch 113\n",
            "Var loss:  tensor(2.3447e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6978178911561667e-06\n",
            "E_s_wdiff_all_sq: 5.17062830162525e-08\n",
            "E_IS_SCOPE: -1.0401195667281405e-05\n",
            "E_IS_E_SCOPE: -9.132815290468971e-06\n",
            "Total Loss: 2.3447392094846063e-07\n",
            "----------------------------------------\n",
            "Epoch 114\n",
            "Var loss:  tensor(2.3391e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6963813834446498e-06\n",
            "E_s_wdiff_all_sq: 5.1389901165742885e-08\n",
            "E_IS_SCOPE: -1.0390740111433067e-05\n",
            "E_IS_E_SCOPE: -9.12263869855524e-06\n",
            "Total Loss: 2.3391172295666906e-07\n",
            "----------------------------------------\n",
            "Epoch 115\n",
            "Var loss:  tensor(2.3337e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6956038350990175e-06\n",
            "E_s_wdiff_all_sq: 5.1307639145693544e-08\n",
            "E_IS_SCOPE: -1.0385789382678743e-05\n",
            "E_IS_E_SCOPE: -9.117762276342346e-06\n",
            "Total Loss: 2.3336504971394498e-07\n",
            "----------------------------------------\n",
            "Epoch 116\n",
            "Var loss:  tensor(2.3281e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6964062628256837e-06\n",
            "E_s_wdiff_all_sq: 5.219462837219457e-08\n",
            "E_IS_SCOPE: -1.0388617328441866e-05\n",
            "E_IS_E_SCOPE: -9.120356145481202e-06\n",
            "Total Loss: 2.32812334965574e-07\n",
            "----------------------------------------\n",
            "Epoch 117\n",
            "Var loss:  tensor(2.3226e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.697969708123644e-06\n",
            "E_s_wdiff_all_sq: 5.356150422228303e-08\n",
            "E_IS_SCOPE: -1.0396512373483222e-05\n",
            "E_IS_E_SCOPE: -9.127874657124376e-06\n",
            "Total Loss: 2.322558376170834e-07\n",
            "----------------------------------------\n",
            "Epoch 118\n",
            "Var loss:  tensor(2.3170e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6985046476447504e-06\n",
            "E_s_wdiff_all_sq: 5.421227944654942e-08\n",
            "E_IS_SCOPE: -1.0403259580456e-05\n",
            "E_IS_E_SCOPE: -9.13440324291294e-06\n",
            "Total Loss: 2.3170275954549535e-07\n",
            "----------------------------------------\n",
            "Epoch 119\n",
            "Var loss:  tensor(2.3114e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.697402565253607e-06\n",
            "E_s_wdiff_all_sq: 5.366662050549304e-08\n",
            "E_IS_SCOPE: -1.0404202521657255e-05\n",
            "E_IS_E_SCOPE: -9.135342909318728e-06\n",
            "Total Loss: 2.3113978650447428e-07\n",
            "----------------------------------------\n",
            "Epoch 120\n",
            "Var loss:  tensor(2.3059e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6958400272508577e-06\n",
            "E_s_wdiff_all_sq: 5.2882884795770964e-08\n",
            "E_IS_SCOPE: -1.0403002927344853e-05\n",
            "E_IS_E_SCOPE: -9.134256792710523e-06\n",
            "Total Loss: 2.3058793961984435e-07\n",
            "----------------------------------------\n",
            "Epoch 121\n",
            "Var loss:  tensor(2.3004e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6950071719017815e-06\n",
            "E_s_wdiff_all_sq: 5.287300646841153e-08\n",
            "E_IS_SCOPE: -1.0402737494062908e-05\n",
            "E_IS_E_SCOPE: -9.134131168138253e-06\n",
            "Total Loss: 2.300445800174791e-07\n",
            "----------------------------------------\n",
            "Epoch 122\n",
            "Var loss:  tensor(2.2947e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6957747610661316e-06\n",
            "E_s_wdiff_all_sq: 5.4118831831198214e-08\n",
            "E_IS_SCOPE: -1.0403672859566108e-05\n",
            "E_IS_E_SCOPE: -9.135018404395334e-06\n",
            "Total Loss: 2.2947008532680272e-07\n",
            "----------------------------------------\n",
            "Epoch 123\n",
            "Var loss:  tensor(2.2891e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.69851863161317e-06\n",
            "E_s_wdiff_all_sq: 5.67128952213179e-08\n",
            "E_IS_SCOPE: -1.0406459704759436e-05\n",
            "E_IS_E_SCOPE: -9.137450141731153e-06\n",
            "Total Loss: 2.2890967676870108e-07\n",
            "----------------------------------------\n",
            "Epoch 124\n",
            "Var loss:  tensor(2.2835e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7010557006088108e-06\n",
            "E_s_wdiff_all_sq: 5.893392402523617e-08\n",
            "E_IS_SCOPE: -1.0409975838248118e-05\n",
            "E_IS_E_SCOPE: -9.140527125576497e-06\n",
            "Total Loss: 2.2834741767374788e-07\n",
            "----------------------------------------\n",
            "Epoch 125\n",
            "Var loss:  tensor(2.2778e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7020085298071291e-06\n",
            "E_s_wdiff_all_sq: 6.02912642130195e-08\n",
            "E_IS_SCOPE: -1.0408199075962801e-05\n",
            "E_IS_E_SCOPE: -9.138668603874811e-06\n",
            "Total Loss: 2.2777938785154696e-07\n",
            "----------------------------------------\n",
            "Epoch 126\n",
            "Var loss:  tensor(2.2723e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.701659749145655e-06\n",
            "E_s_wdiff_all_sq: 6.090723139718416e-08\n",
            "E_IS_SCOPE: -1.0403745362550728e-05\n",
            "E_IS_E_SCOPE: -9.134420515844493e-06\n",
            "Total Loss: 2.2722589076941738e-07\n",
            "----------------------------------------\n",
            "Epoch 127\n",
            "Var loss:  tensor(2.2666e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.700795388892347e-06\n",
            "E_s_wdiff_all_sq: 6.101620390606548e-08\n",
            "E_IS_SCOPE: -1.0400947318483681e-05\n",
            "E_IS_E_SCOPE: -9.131826865352494e-06\n",
            "Total Loss: 2.2666134515732097e-07\n",
            "----------------------------------------\n",
            "Epoch 128\n",
            "Var loss:  tensor(2.2609e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.700873716511624e-06\n",
            "E_s_wdiff_all_sq: 6.167522075369433e-08\n",
            "E_IS_SCOPE: -1.0402518703684154e-05\n",
            "E_IS_E_SCOPE: -9.13340402443894e-06\n",
            "Total Loss: 2.260922037009197e-07\n",
            "----------------------------------------\n",
            "Epoch 129\n",
            "Var loss:  tensor(2.2553e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7018749746582914e-06\n",
            "E_s_wdiff_all_sq: 6.264836856268655e-08\n",
            "E_IS_SCOPE: -1.040950574467023e-05\n",
            "E_IS_E_SCOPE: -9.140093721868505e-06\n",
            "Total Loss: 2.2552562692556936e-07\n",
            "----------------------------------------\n",
            "Epoch 130\n",
            "Var loss:  tensor(2.2496e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7022694267960429e-06\n",
            "E_s_wdiff_all_sq: 6.30416565482383e-08\n",
            "E_IS_SCOPE: -1.0415347616012765e-05\n",
            "E_IS_E_SCOPE: -9.14565050009191e-06\n",
            "Total Loss: 2.2495660483951133e-07\n",
            "----------------------------------------\n",
            "Epoch 131\n",
            "Var loss:  tensor(2.2439e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7013074287000594e-06\n",
            "E_s_wdiff_all_sq: 6.265066625149345e-08\n",
            "E_IS_SCOPE: -1.041671187699621e-05\n",
            "E_IS_E_SCOPE: -9.147014996766318e-06\n",
            "Total Loss: 2.243860684221955e-07\n",
            "----------------------------------------\n",
            "Epoch 132\n",
            "Var loss:  tensor(2.2382e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6994294308797075e-06\n",
            "E_s_wdiff_all_sq: 6.168922816930543e-08\n",
            "E_IS_SCOPE: -1.0414172975997192e-05\n",
            "E_IS_E_SCOPE: -9.144649020327792e-06\n",
            "Total Loss: 2.23815357805018e-07\n",
            "----------------------------------------\n",
            "Epoch 133\n",
            "Var loss:  tensor(2.2325e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.698384583052252e-06\n",
            "E_s_wdiff_all_sq: 6.120496692043343e-08\n",
            "E_IS_SCOPE: -1.0409773608868885e-05\n",
            "E_IS_E_SCOPE: -9.140246914816254e-06\n",
            "Total Loss: 2.2324929445997285e-07\n",
            "----------------------------------------\n",
            "Epoch 134\n",
            "Var loss:  tensor(2.2267e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.698706581263278e-06\n",
            "E_s_wdiff_all_sq: 6.139619114807361e-08\n",
            "E_IS_SCOPE: -1.0410608347198275e-05\n",
            "E_IS_E_SCOPE: -9.140728080671488e-06\n",
            "Total Loss: 2.2267292349504542e-07\n",
            "----------------------------------------\n",
            "Epoch 135\n",
            "Var loss:  tensor(2.2210e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6996372802864986e-06\n",
            "E_s_wdiff_all_sq: 6.231204021279156e-08\n",
            "E_IS_SCOPE: -1.0414164877965922e-05\n",
            "E_IS_E_SCOPE: -9.1439918637015e-06\n",
            "Total Loss: 2.2210227797827772e-07\n",
            "----------------------------------------\n",
            "Epoch 136\n",
            "Var loss:  tensor(2.2153e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.700150948826653e-06\n",
            "E_s_wdiff_all_sq: 6.337514200244276e-08\n",
            "E_IS_SCOPE: -1.0416964770545659e-05\n",
            "E_IS_E_SCOPE: -9.146780753096974e-06\n",
            "Total Loss: 2.2153083836025473e-07\n",
            "----------------------------------------\n",
            "Epoch 137\n",
            "Var loss:  tensor(2.2096e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7001853845114823e-06\n",
            "E_s_wdiff_all_sq: 6.40722658488198e-08\n",
            "E_IS_SCOPE: -1.0415142982660786e-05\n",
            "E_IS_E_SCOPE: -9.145002456863424e-06\n",
            "Total Loss: 2.2095513350135527e-07\n",
            "----------------------------------------\n",
            "Epoch 138\n",
            "Var loss:  tensor(2.2038e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.700336935356198e-06\n",
            "E_s_wdiff_all_sq: 6.450455268205415e-08\n",
            "E_IS_SCOPE: -1.0413839856563347e-05\n",
            "E_IS_E_SCOPE: -9.143553208250958e-06\n",
            "Total Loss: 2.2038215248278098e-07\n",
            "----------------------------------------\n",
            "Epoch 139\n",
            "Var loss:  tensor(2.1980e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.70073000796727e-06\n",
            "E_s_wdiff_all_sq: 6.51601200043887e-08\n",
            "E_IS_SCOPE: -1.0410683402799105e-05\n",
            "E_IS_E_SCOPE: -9.140239063230867e-06\n",
            "Total Loss: 2.1980427525982243e-07\n",
            "----------------------------------------\n",
            "Epoch 140\n",
            "Var loss:  tensor(2.1923e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7016242297254215e-06\n",
            "E_s_wdiff_all_sq: 6.636783752210958e-08\n",
            "E_IS_SCOPE: -1.04111836054932e-05\n",
            "E_IS_E_SCOPE: -9.140607506436531e-06\n",
            "Total Loss: 2.192272605233931e-07\n",
            "----------------------------------------\n",
            "Epoch 141\n",
            "Var loss:  tensor(2.1865e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.70209247112664e-06\n",
            "E_s_wdiff_all_sq: 6.750382769594642e-08\n",
            "E_IS_SCOPE: -1.0413373099092052e-05\n",
            "E_IS_E_SCOPE: -9.142843192822936e-06\n",
            "Total Loss: 2.1865189732588006e-07\n",
            "----------------------------------------\n",
            "Epoch 142\n",
            "Var loss:  tensor(2.1807e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7027760235211135e-06\n",
            "E_s_wdiff_all_sq: 6.864748985716881e-08\n",
            "E_IS_SCOPE: -1.0415065482949937e-05\n",
            "E_IS_E_SCOPE: -9.144473710799512e-06\n",
            "Total Loss: 2.1806805579650863e-07\n",
            "----------------------------------------\n",
            "Epoch 143\n",
            "Var loss:  tensor(2.1749e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7038463483038857e-06\n",
            "E_s_wdiff_all_sq: 6.979197028130445e-08\n",
            "E_IS_SCOPE: -1.0418568634975906e-05\n",
            "E_IS_E_SCOPE: -9.147726830880647e-06\n",
            "Total Loss: 2.174938362654792e-07\n",
            "----------------------------------------\n",
            "Epoch 144\n",
            "Var loss:  tensor(2.1691e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7046050242152406e-06\n",
            "E_s_wdiff_all_sq: 7.076870924395614e-08\n",
            "E_IS_SCOPE: -1.0420269067433244e-05\n",
            "E_IS_E_SCOPE: -9.149245575545964e-06\n",
            "Total Loss: 2.1691239763014e-07\n",
            "----------------------------------------\n",
            "Epoch 145\n",
            "Var loss:  tensor(2.1633e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.704163996941872e-06\n",
            "E_s_wdiff_all_sq: 7.115115355790393e-08\n",
            "E_IS_SCOPE: -1.0419779603439644e-05\n",
            "E_IS_E_SCOPE: -9.148876310733231e-06\n",
            "Total Loss: 2.1632932440455889e-07\n",
            "----------------------------------------\n",
            "Epoch 146\n",
            "Var loss:  tensor(2.1574e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.703743349986532e-06\n",
            "E_s_wdiff_all_sq: 7.158100394097689e-08\n",
            "E_IS_SCOPE: -1.041949753880683e-05\n",
            "E_IS_E_SCOPE: -9.148724858682339e-06\n",
            "Total Loss: 2.1574005222998985e-07\n",
            "----------------------------------------\n",
            "Epoch 147\n",
            "Var loss:  tensor(2.1517e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.704881306793064e-06\n",
            "E_s_wdiff_all_sq: 7.29761579605587e-08\n",
            "E_IS_SCOPE: -1.042334750916372e-05\n",
            "E_IS_E_SCOPE: -9.15241677644011e-06\n",
            "Total Loss: 2.1516674981870118e-07\n",
            "----------------------------------------\n",
            "Epoch 148\n",
            "Var loss:  tensor(2.1457e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.706526462966463e-06\n",
            "E_s_wdiff_all_sq: 7.468658397501789e-08\n",
            "E_IS_SCOPE: -1.0425830804693136e-05\n",
            "E_IS_E_SCOPE: -9.154636642546336e-06\n",
            "Total Loss: 2.1457462113126327e-07\n",
            "----------------------------------------\n",
            "Epoch 149\n",
            "Var loss:  tensor(2.1398e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7073353526265044e-06\n",
            "E_s_wdiff_all_sq: 7.568064679151796e-08\n",
            "E_IS_SCOPE: -1.0424545452162448e-05\n",
            "E_IS_E_SCOPE: -9.153146914022824e-06\n",
            "Total Loss: 2.1398069598915475e-07\n",
            "----------------------------------------\n",
            "Epoch 150\n",
            "Var loss:  tensor(2.1339e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7075917525626392e-06\n",
            "E_s_wdiff_all_sq: 7.643839728698429e-08\n",
            "E_IS_SCOPE: -1.0423523362632808e-05\n",
            "E_IS_E_SCOPE: -9.152080233363606e-06\n",
            "Total Loss: 2.1339016317066636e-07\n",
            "----------------------------------------\n",
            "Epoch 151\n",
            "Var loss:  tensor(2.1280e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7078299536913499e-06\n",
            "E_s_wdiff_all_sq: 7.724555179965625e-08\n",
            "E_IS_SCOPE: -1.0424512142401866e-05\n",
            "E_IS_E_SCOPE: -9.153056235838831e-06\n",
            "Total Loss: 2.1279565519904254e-07\n",
            "----------------------------------------\n",
            "Epoch 152\n",
            "Var loss:  tensor(2.1220e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7082781032454724e-06\n",
            "E_s_wdiff_all_sq: 7.806736512043233e-08\n",
            "E_IS_SCOPE: -1.0427942903354655e-05\n",
            "E_IS_E_SCOPE: -9.156377872765391e-06\n",
            "Total Loss: 2.1220374337992803e-07\n",
            "----------------------------------------\n",
            "Epoch 153\n",
            "Var loss:  tensor(2.1160e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.708568759826612e-06\n",
            "E_s_wdiff_all_sq: 7.871783454508083e-08\n",
            "E_IS_SCOPE: -1.0433217699207887e-05\n",
            "E_IS_E_SCOPE: -9.161532762380687e-06\n",
            "Total Loss: 2.11604118060549e-07\n",
            "----------------------------------------\n",
            "Epoch 154\n",
            "Var loss:  tensor(2.1101e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7084688874579642e-06\n",
            "E_s_wdiff_all_sq: 7.909059645483918e-08\n",
            "E_IS_SCOPE: -1.0438542273060671e-05\n",
            "E_IS_E_SCOPE: -9.166796163663358e-06\n",
            "Total Loss: 2.1100913864191442e-07\n",
            "----------------------------------------\n",
            "Epoch 155\n",
            "Var loss:  tensor(2.1041e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.708303795026502e-06\n",
            "E_s_wdiff_all_sq: 7.926201236738958e-08\n",
            "E_IS_SCOPE: -1.0440453771266503e-05\n",
            "E_IS_E_SCOPE: -9.168577922326337e-06\n",
            "Total Loss: 2.1041315121219585e-07\n",
            "----------------------------------------\n",
            "Epoch 156\n",
            "Var loss:  tensor(2.0981e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7080340101613432e-06\n",
            "E_s_wdiff_all_sq: 7.923693768346928e-08\n",
            "E_IS_SCOPE: -1.0439586837222441e-05\n",
            "E_IS_E_SCOPE: -9.16753270655807e-06\n",
            "Total Loss: 2.098118775825455e-07\n",
            "----------------------------------------\n",
            "Epoch 157\n",
            "Var loss:  tensor(2.0923e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7080283953366558e-06\n",
            "E_s_wdiff_all_sq: 7.955349817834871e-08\n",
            "E_IS_SCOPE: -1.0439310461240315e-05\n",
            "E_IS_E_SCOPE: -9.167124172576366e-06\n",
            "Total Loss: 2.092253862638251e-07\n",
            "----------------------------------------\n",
            "Epoch 158\n",
            "Var loss:  tensor(2.0862e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7079757548128708e-06\n",
            "E_s_wdiff_all_sq: 7.999676288417485e-08\n",
            "E_IS_SCOPE: -1.0436883870383106e-05\n",
            "E_IS_E_SCOPE: -9.164644665974267e-06\n",
            "Total Loss: 2.0862364954443146e-07\n",
            "----------------------------------------\n",
            "Epoch 159\n",
            "Var loss:  tensor(2.0803e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.708330970077691e-06\n",
            "E_s_wdiff_all_sq: 8.088002561406657e-08\n",
            "E_IS_SCOPE: -1.0433130740160609e-05\n",
            "E_IS_E_SCOPE: -9.160858207723582e-06\n",
            "Total Loss: 2.0802894602298896e-07\n",
            "----------------------------------------\n",
            "Epoch 160\n",
            "Var loss:  tensor(2.0743e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.709019016623315e-06\n",
            "E_s_wdiff_all_sq: 8.207071238494628e-08\n",
            "E_IS_SCOPE: -1.0431320276234265e-05\n",
            "E_IS_E_SCOPE: -9.159000032642425e-06\n",
            "Total Loss: 2.0743088348810276e-07\n",
            "----------------------------------------\n",
            "Epoch 161\n",
            "Var loss:  tensor(2.0683e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7103031097056667e-06\n",
            "E_s_wdiff_all_sq: 8.380759168718288e-08\n",
            "E_IS_SCOPE: -1.0431156919964509e-05\n",
            "E_IS_E_SCOPE: -9.15876051458732e-06\n",
            "Total Loss: 2.0682577369752173e-07\n",
            "----------------------------------------\n",
            "Epoch 162\n",
            "Var loss:  tensor(2.0622e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7123492956274973e-06\n",
            "E_s_wdiff_all_sq: 8.606888702136915e-08\n",
            "E_IS_SCOPE: -1.0433878608359117e-05\n",
            "E_IS_E_SCOPE: -9.161289259063609e-06\n",
            "Total Loss: 2.0622477644852845e-07\n",
            "----------------------------------------\n",
            "Epoch 163\n",
            "Var loss:  tensor(2.0562e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7141243928982958e-06\n",
            "E_s_wdiff_all_sq: 8.800319821687563e-08\n",
            "E_IS_SCOPE: -1.044067593195617e-05\n",
            "E_IS_E_SCOPE: -9.167862827271305e-06\n",
            "Total Loss: 2.0561805174510257e-07\n",
            "----------------------------------------\n",
            "Epoch 164\n",
            "Var loss:  tensor(2.0501e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.714989118281085e-06\n",
            "E_s_wdiff_all_sq: 8.940586552271192e-08\n",
            "E_IS_SCOPE: -1.04458955906296e-05\n",
            "E_IS_E_SCOPE: -9.173047560859309e-06\n",
            "Total Loss: 2.0501025965120602e-07\n",
            "----------------------------------------\n",
            "Epoch 165\n",
            "Var loss:  tensor(2.0441e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7150420385287583e-06\n",
            "E_s_wdiff_all_sq: 9.026742676778557e-08\n",
            "E_IS_SCOPE: -1.0447472080533019e-05\n",
            "E_IS_E_SCOPE: -9.174726956670623e-06\n",
            "Total Loss: 2.044074304695993e-07\n",
            "----------------------------------------\n",
            "Epoch 166\n",
            "Var loss:  tensor(2.0380e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7150233900783379e-06\n",
            "E_s_wdiff_all_sq: 9.076086845161332e-08\n",
            "E_IS_SCOPE: -1.044817350808377e-05\n",
            "E_IS_E_SCOPE: -9.175382120740345e-06\n",
            "Total Loss: 2.0380281337329128e-07\n",
            "----------------------------------------\n",
            "Epoch 167\n",
            "Var loss:  tensor(2.0319e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.714684134000113e-06\n",
            "E_s_wdiff_all_sq: 9.07823287646796e-08\n",
            "E_IS_SCOPE: -1.044470971861531e-05\n",
            "E_IS_E_SCOPE: -9.17179377110062e-06\n",
            "Total Loss: 2.0319297663946922e-07\n",
            "----------------------------------------\n",
            "Epoch 168\n",
            "Var loss:  tensor(2.0259e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7142792231291026e-06\n",
            "E_s_wdiff_all_sq: 9.088367823687257e-08\n",
            "E_IS_SCOPE: -1.0439042449084305e-05\n",
            "E_IS_E_SCOPE: -9.166076618949615e-06\n",
            "Total Loss: 2.0258695105626508e-07\n",
            "----------------------------------------\n",
            "Epoch 169\n",
            "Var loss:  tensor(2.0198e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7143008859048431e-06\n",
            "E_s_wdiff_all_sq: 9.124661605967578e-08\n",
            "E_IS_SCOPE: -1.0437127852287834e-05\n",
            "E_IS_E_SCOPE: -9.164029055795241e-06\n",
            "Total Loss: 2.0197974329339848e-07\n",
            "----------------------------------------\n",
            "Epoch 170\n",
            "Var loss:  tensor(2.0137e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7149624746731408e-06\n",
            "E_s_wdiff_all_sq: 9.199290324383039e-08\n",
            "E_IS_SCOPE: -1.043745719503757e-05\n",
            "E_IS_E_SCOPE: -9.164098110668817e-06\n",
            "Total Loss: 2.0137446912522212e-07\n",
            "----------------------------------------\n",
            "Epoch 171\n",
            "Var loss:  tensor(2.0077e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7155454576209854e-06\n",
            "E_s_wdiff_all_sq: 9.274613667832514e-08\n",
            "E_IS_SCOPE: -1.0438348513728235e-05\n",
            "E_IS_E_SCOPE: -9.164771543641058e-06\n",
            "Total Loss: 2.0076844720172417e-07\n",
            "----------------------------------------\n",
            "Epoch 172\n",
            "Var loss:  tensor(2.0016e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7148375854274172e-06\n",
            "E_s_wdiff_all_sq: 9.244574301399932e-08\n",
            "E_IS_SCOPE: -1.0440679426763994e-05\n",
            "E_IS_E_SCOPE: -9.166999917275983e-06\n",
            "Total Loss: 2.0015588987081168e-07\n",
            "----------------------------------------\n",
            "Epoch 173\n",
            "Var loss:  tensor(1.9954e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7138531755397577e-06\n",
            "E_s_wdiff_all_sq: 9.214785127596929e-08\n",
            "E_IS_SCOPE: -1.044163319320427e-05\n",
            "E_IS_E_SCOPE: -9.1679899811172e-06\n",
            "Total Loss: 1.9954196652306475e-07\n",
            "----------------------------------------\n",
            "Epoch 174\n",
            "Var loss:  tensor(1.9893e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.713380769159702e-06\n",
            "E_s_wdiff_all_sq: 9.235520111502931e-08\n",
            "E_IS_SCOPE: -1.0443403545279268e-05\n",
            "E_IS_E_SCOPE: -9.169792338344864e-06\n",
            "Total Loss: 1.989262206092816e-07\n",
            "----------------------------------------\n",
            "Epoch 175\n",
            "Var loss:  tensor(1.9831e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7133959268449226e-06\n",
            "E_s_wdiff_all_sq: 9.287441100003271e-08\n",
            "E_IS_SCOPE: -1.04463958878327e-05\n",
            "E_IS_E_SCOPE: -9.172729812795862e-06\n",
            "Total Loss: 1.9831243220463044e-07\n",
            "----------------------------------------\n",
            "Epoch 176\n",
            "Var loss:  tensor(1.9771e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7141422001143662e-06\n",
            "E_s_wdiff_all_sq: 9.37568210317337e-08\n",
            "E_IS_SCOPE: -1.0449494142420649e-05\n",
            "E_IS_E_SCOPE: -9.175595587878242e-06\n",
            "Total Loss: 1.9771133643123513e-07\n",
            "----------------------------------------\n",
            "Epoch 177\n",
            "Var loss:  tensor(1.9710e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.714938697370858e-06\n",
            "E_s_wdiff_all_sq: 9.484838885739729e-08\n",
            "E_IS_SCOPE: -1.0447289896169832e-05\n",
            "E_IS_E_SCOPE: -9.173233448721395e-06\n",
            "Total Loss: 1.9710048005000065e-07\n",
            "----------------------------------------\n",
            "Epoch 178\n",
            "Var loss:  tensor(1.9648e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7151310114866889e-06\n",
            "E_s_wdiff_all_sq: 9.591341123458748e-08\n",
            "E_IS_SCOPE: -1.0441534590894248e-05\n",
            "E_IS_E_SCOPE: -9.167603221962683e-06\n",
            "Total Loss: 1.9647792882238765e-07\n",
            "----------------------------------------\n",
            "Epoch 179\n",
            "Var loss:  tensor(1.9587e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.716399036857276e-06\n",
            "E_s_wdiff_all_sq: 9.760001273821185e-08\n",
            "E_IS_SCOPE: -1.0440011478520869e-05\n",
            "E_IS_E_SCOPE: -9.165987537125512e-06\n",
            "Total Loss: 1.9587420776176959e-07\n",
            "----------------------------------------\n",
            "Epoch 180\n",
            "Var loss:  tensor(1.9526e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7180315134008918e-06\n",
            "E_s_wdiff_all_sq: 9.934578389330224e-08\n",
            "E_IS_SCOPE: -1.0439635198325887e-05\n",
            "E_IS_E_SCOPE: -9.165360814883045e-06\n",
            "Total Loss: 1.9526002905532302e-07\n",
            "----------------------------------------\n",
            "Epoch 181\n",
            "Var loss:  tensor(1.9466e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.719278945048739e-06\n",
            "E_s_wdiff_all_sq: 1.0073459563086762e-07\n",
            "E_IS_SCOPE: -1.0441331265555423e-05\n",
            "E_IS_E_SCOPE: -9.166825373607993e-06\n",
            "Total Loss: 1.9465563195642943e-07\n",
            "----------------------------------------\n",
            "Epoch 182\n",
            "Var loss:  tensor(1.9404e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7195051868039151e-06\n",
            "E_s_wdiff_all_sq: 1.0179157921716129e-07\n",
            "E_IS_SCOPE: -1.044177470746082e-05\n",
            "E_IS_E_SCOPE: -9.167375609170886e-06\n",
            "Total Loss: 1.9403847744030355e-07\n",
            "----------------------------------------\n",
            "Epoch 183\n",
            "Var loss:  tensor(1.9342e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.71971936632737e-06\n",
            "E_s_wdiff_all_sq: 1.0277302578583528e-07\n",
            "E_IS_SCOPE: -1.0441981511066472e-05\n",
            "E_IS_E_SCOPE: -9.167659203949135e-06\n",
            "Total Loss: 1.9342479274027653e-07\n",
            "----------------------------------------\n",
            "Epoch 184\n",
            "Var loss:  tensor(1.9281e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.720767133913656e-06\n",
            "E_s_wdiff_all_sq: 1.0410892243526958e-07\n",
            "E_IS_SCOPE: -1.0444581593266387e-05\n",
            "E_IS_E_SCOPE: -9.17009570714204e-06\n",
            "Total Loss: 1.9280950566310651e-07\n",
            "----------------------------------------\n",
            "Epoch 185\n",
            "Var loss:  tensor(1.9221e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7223746467932628e-06\n",
            "E_s_wdiff_all_sq: 1.0588183463741387e-07\n",
            "E_IS_SCOPE: -1.0449157086870558e-05\n",
            "E_IS_E_SCOPE: -9.17445396007162e-06\n",
            "Total Loss: 1.922096249913897e-07\n",
            "----------------------------------------\n",
            "Epoch 186\n",
            "Var loss:  tensor(1.9160e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7226960672892019e-06\n",
            "E_s_wdiff_all_sq: 1.0692704899490493e-07\n",
            "E_IS_SCOPE: -1.0447822006216919e-05\n",
            "E_IS_E_SCOPE: -9.173175711528422e-06\n",
            "Total Loss: 1.9159949535071872e-07\n",
            "----------------------------------------\n",
            "Epoch 187\n",
            "Var loss:  tensor(1.9096e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7224130672504917e-06\n",
            "E_s_wdiff_all_sq: 1.0720692662475948e-07\n",
            "E_IS_SCOPE: -1.0443916558488135e-05\n",
            "E_IS_E_SCOPE: -9.169232855815979e-06\n",
            "Total Loss: 1.9096180171483554e-07\n",
            "----------------------------------------\n",
            "Epoch 188\n",
            "Var loss:  tensor(1.9034e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7227344015824336e-06\n",
            "E_s_wdiff_all_sq: 1.0772253661179434e-07\n",
            "E_IS_SCOPE: -1.0442362299428787e-05\n",
            "E_IS_E_SCOPE: -9.167463164315124e-06\n",
            "Total Loss: 1.9033666117672883e-07\n",
            "----------------------------------------\n",
            "Epoch 189\n",
            "Var loss:  tensor(1.8972e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7233639369202324e-06\n",
            "E_s_wdiff_all_sq: 1.0842819253161865e-07\n",
            "E_IS_SCOPE: -1.0443262325054855e-05\n",
            "E_IS_E_SCOPE: -9.168090832328354e-06\n",
            "Total Loss: 1.8971582536903026e-07\n",
            "----------------------------------------\n",
            "Epoch 190\n",
            "Var loss:  tensor(1.8908e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7230384519659143e-06\n",
            "E_s_wdiff_all_sq: 1.0866143855188347e-07\n",
            "E_IS_SCOPE: -1.0445539829426368e-05\n",
            "E_IS_E_SCOPE: -9.170327335717571e-06\n",
            "Total Loss: 1.89075092429853e-07\n",
            "----------------------------------------\n",
            "Epoch 191\n",
            "Var loss:  tensor(1.8844e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7226990171295225e-06\n",
            "E_s_wdiff_all_sq: 1.0887440998449516e-07\n",
            "E_IS_SCOPE: -1.0449000422631478e-05\n",
            "E_IS_E_SCOPE: -9.17374429138492e-06\n",
            "Total Loss: 1.8843541108532622e-07\n",
            "----------------------------------------\n",
            "Epoch 192\n",
            "Var loss:  tensor(1.8780e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7230148480187744e-06\n",
            "E_s_wdiff_all_sq: 1.0957287832379168e-07\n",
            "E_IS_SCOPE: -1.0453193396838864e-05\n",
            "E_IS_E_SCOPE: -9.17781049109356e-06\n",
            "Total Loss: 1.8779922463779116e-07\n",
            "----------------------------------------\n",
            "Epoch 193\n",
            "Var loss:  tensor(1.8716e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7230192625681622e-06\n",
            "E_s_wdiff_all_sq: 1.1020617955513921e-07\n",
            "E_IS_SCOPE: -1.045542505775823e-05\n",
            "E_IS_E_SCOPE: -9.180037327734094e-06\n",
            "Total Loss: 1.8716068939816883e-07\n",
            "----------------------------------------\n",
            "Epoch 194\n",
            "Var loss:  tensor(1.8652e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.723418170197592e-06\n",
            "E_s_wdiff_all_sq: 1.1132096869441049e-07\n",
            "E_IS_SCOPE: -1.0457086456780676e-05\n",
            "E_IS_E_SCOPE: -9.181735373253577e-06\n",
            "Total Loss: 1.8651810088239956e-07\n",
            "----------------------------------------\n",
            "Epoch 195\n",
            "Var loss:  tensor(1.8587e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.725134996679335e-06\n",
            "E_s_wdiff_all_sq: 1.1327215750803653e-07\n",
            "E_IS_SCOPE: -1.0457613485451725e-05\n",
            "E_IS_E_SCOPE: -9.182056556914457e-06\n",
            "Total Loss: 1.858720485301789e-07\n",
            "----------------------------------------\n",
            "Epoch 196\n",
            "Var loss:  tensor(1.8523e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7263861565252912e-06\n",
            "E_s_wdiff_all_sq: 1.1457308750735867e-07\n",
            "E_IS_SCOPE: -1.0454635683127434e-05\n",
            "E_IS_E_SCOPE: -9.178781067782621e-06\n",
            "Total Loss: 1.8522690476172425e-07\n",
            "----------------------------------------\n",
            "Epoch 197\n",
            "Var loss:  tensor(1.8460e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7262274636466883e-06\n",
            "E_s_wdiff_all_sq: 1.1474472310223615e-07\n",
            "E_IS_SCOPE: -1.0448940117619234e-05\n",
            "E_IS_E_SCOPE: -9.172935124474828e-06\n",
            "Total Loss: 1.845958206890553e-07\n",
            "----------------------------------------\n",
            "Epoch 198\n",
            "Var loss:  tensor(1.8396e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7252281279163673e-06\n",
            "E_s_wdiff_all_sq: 1.146281708498043e-07\n",
            "E_IS_SCOPE: -1.0442044173968287e-05\n",
            "E_IS_E_SCOPE: -9.166160327899965e-06\n",
            "Total Loss: 1.8395533136333594e-07\n",
            "----------------------------------------\n",
            "Epoch 199\n",
            "Var loss:  tensor(1.8331e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7245681465705244e-06\n",
            "E_s_wdiff_all_sq: 1.1478215948688134e-07\n",
            "E_IS_SCOPE: -1.0436700538330691e-05\n",
            "E_IS_E_SCOPE: -9.160903498556177e-06\n",
            "Total Loss: 1.833149739680298e-07\n",
            "----------------------------------------\n",
            "Epoch 200\n",
            "Var loss:  tensor(1.8267e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.726202836007298e-06\n",
            "E_s_wdiff_all_sq: 1.1636894732942425e-07\n",
            "E_IS_SCOPE: -1.0437970769880636e-05\n",
            "E_IS_E_SCOPE: -9.161827114107383e-06\n",
            "Total Loss: 1.826696435647838e-07\n",
            "----------------------------------------\n",
            "Epoch 201\n",
            "Var loss:  tensor(1.8202e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7281986799814096e-06\n",
            "E_s_wdiff_all_sq: 1.1822123678621458e-07\n",
            "E_IS_SCOPE: -1.044332322256738e-05\n",
            "E_IS_E_SCOPE: -9.166784863441305e-06\n",
            "Total Loss: 1.820237913764627e-07\n",
            "----------------------------------------\n",
            "Epoch 202\n",
            "Var loss:  tensor(1.8137e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7286511002036993e-06\n",
            "E_s_wdiff_all_sq: 1.1928660492142464e-07\n",
            "E_IS_SCOPE: -1.0447630709563186e-05\n",
            "E_IS_E_SCOPE: -9.171071307005e-06\n",
            "Total Loss: 1.8136875659931734e-07\n",
            "----------------------------------------\n",
            "Epoch 203\n",
            "Var loss:  tensor(1.8072e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7281667532991113e-06\n",
            "E_s_wdiff_all_sq: 1.199473123109744e-07\n",
            "E_IS_SCOPE: -1.0448892381943267e-05\n",
            "E_IS_E_SCOPE: -9.17257926313901e-06\n",
            "Total Loss: 1.8071626981303944e-07\n",
            "----------------------------------------\n",
            "Epoch 204\n",
            "Var loss:  tensor(1.8008e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7288458342981847e-06\n",
            "E_s_wdiff_all_sq: 1.2131666079459246e-07\n",
            "E_IS_SCOPE: -1.0449804815504884e-05\n",
            "E_IS_E_SCOPE: -9.17352014580186e-06\n",
            "Total Loss: 1.8008290053096103e-07\n",
            "----------------------------------------\n",
            "Epoch 205\n",
            "Var loss:  tensor(1.7944e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.73012698474879e-06\n",
            "E_s_wdiff_all_sq: 1.2276587322528217e-07\n",
            "E_IS_SCOPE: -1.0448439266615675e-05\n",
            "E_IS_E_SCOPE: -9.171915224447814e-06\n",
            "Total Loss: 1.7943609362120188e-07\n",
            "----------------------------------------\n",
            "Epoch 206\n",
            "Var loss:  tensor(1.7879e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7314723255312158e-06\n",
            "E_s_wdiff_all_sq: 1.2441889666259154e-07\n",
            "E_IS_SCOPE: -1.044588618773662e-05\n",
            "E_IS_E_SCOPE: -9.169192811441629e-06\n",
            "Total Loss: 1.787897427120558e-07\n",
            "----------------------------------------\n",
            "Epoch 207\n",
            "Var loss:  tensor(1.7815e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7314718123529534e-06\n",
            "E_s_wdiff_all_sq: 1.2497368843671597e-07\n",
            "E_IS_SCOPE: -1.044355001031678e-05\n",
            "E_IS_E_SCOPE: -9.166812085278547e-06\n",
            "Total Loss: 1.781453402731871e-07\n",
            "----------------------------------------\n",
            "Epoch 208\n",
            "Var loss:  tensor(1.7750e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7313581090285558e-06\n",
            "E_s_wdiff_all_sq: 1.255611359360994e-07\n",
            "E_IS_SCOPE: -1.0441436487574397e-05\n",
            "E_IS_E_SCOPE: -9.164728213518812e-06\n",
            "Total Loss: 1.7750349141470122e-07\n",
            "----------------------------------------\n",
            "Epoch 209\n",
            "Var loss:  tensor(1.7686e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.732254380250222e-06\n",
            "E_s_wdiff_all_sq: 1.2673335891493593e-07\n",
            "E_IS_SCOPE: -1.044224526833879e-05\n",
            "E_IS_E_SCOPE: -9.165354040357223e-06\n",
            "Total Loss: 1.768616318055687e-07\n",
            "----------------------------------------\n",
            "Epoch 210\n",
            "Var loss:  tensor(1.7622e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7334322496411794e-06\n",
            "E_s_wdiff_all_sq: 1.2801544705381397e-07\n",
            "E_IS_SCOPE: -1.0445846846929028e-05\n",
            "E_IS_E_SCOPE: -9.168684814141537e-06\n",
            "Total Loss: 1.762158034457966e-07\n",
            "----------------------------------------\n",
            "Epoch 211\n",
            "Var loss:  tensor(1.7557e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7342935530482898e-06\n",
            "E_s_wdiff_all_sq: 1.2933596106128676e-07\n",
            "E_IS_SCOPE: -1.0450796369171591e-05\n",
            "E_IS_E_SCOPE: -9.173539167685017e-06\n",
            "Total Loss: 1.7556625544726995e-07\n",
            "----------------------------------------\n",
            "Epoch 212\n",
            "Var loss:  tensor(1.7492e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7348823894473463e-06\n",
            "E_s_wdiff_all_sq: 1.3057577563522624e-07\n",
            "E_IS_SCOPE: -1.0455836529418268e-05\n",
            "E_IS_E_SCOPE: -9.178582595232803e-06\n",
            "Total Loss: 1.7492181187460597e-07\n",
            "----------------------------------------\n",
            "Epoch 213\n",
            "Var loss:  tensor(1.7427e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7348368761451904e-06\n",
            "E_s_wdiff_all_sq: 1.3107353068898027e-07\n",
            "E_IS_SCOPE: -1.0458450486876691e-05\n",
            "E_IS_E_SCOPE: -9.18114251407371e-06\n",
            "Total Loss: 1.7427046628366533e-07\n",
            "----------------------------------------\n",
            "Epoch 214\n",
            "Var loss:  tensor(1.7362e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7347099235538289e-06\n",
            "E_s_wdiff_all_sq: 1.312764416852881e-07\n",
            "E_IS_SCOPE: -1.0459172140731963e-05\n",
            "E_IS_E_SCOPE: -9.181704466914928e-06\n",
            "Total Loss: 1.7362120066788649e-07\n",
            "----------------------------------------\n",
            "Epoch 215\n",
            "Var loss:  tensor(1.7298e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.734987009221059e-06\n",
            "E_s_wdiff_all_sq: 1.3200271406801536e-07\n",
            "E_IS_SCOPE: -1.0456045981331547e-05\n",
            "E_IS_E_SCOPE: -9.178481639155905e-06\n",
            "Total Loss: 1.7297867723517795e-07\n",
            "----------------------------------------\n",
            "Epoch 216\n",
            "Var loss:  tensor(1.7234e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7356993957767622e-06\n",
            "E_s_wdiff_all_sq: 1.3337644820277146e-07\n",
            "E_IS_SCOPE: -1.0453085206119747e-05\n",
            "E_IS_E_SCOPE: -9.175533701182518e-06\n",
            "Total Loss: 1.7234300413294596e-07\n",
            "----------------------------------------\n",
            "Epoch 217\n",
            "Var loss:  tensor(1.7169e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.736584547819053e-06\n",
            "E_s_wdiff_all_sq: 1.3474950551539924e-07\n",
            "E_IS_SCOPE: -1.045132080476293e-05\n",
            "E_IS_E_SCOPE: -9.173687022459105e-06\n",
            "Total Loss: 1.7169054412941905e-07\n",
            "----------------------------------------\n",
            "Epoch 218\n",
            "Var loss:  tensor(1.7105e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7378456335274344e-06\n",
            "E_s_wdiff_all_sq: 1.3635409772614254e-07\n",
            "E_IS_SCOPE: -1.0451318561646616e-05\n",
            "E_IS_E_SCOPE: -9.173538168921441e-06\n",
            "Total Loss: 1.7105381678435864e-07\n",
            "----------------------------------------\n",
            "Epoch 219\n",
            "Var loss:  tensor(1.7042e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7389556440313436e-06\n",
            "E_s_wdiff_all_sq: 1.377811526933446e-07\n",
            "E_IS_SCOPE: -1.0451330095824766e-05\n",
            "E_IS_E_SCOPE: -9.17338915795263e-06\n",
            "Total Loss: 1.704156820271425e-07\n",
            "----------------------------------------\n",
            "Epoch 220\n",
            "Var loss:  tensor(1.6977e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7392665028421308e-06\n",
            "E_s_wdiff_all_sq: 1.386087277063833e-07\n",
            "E_IS_SCOPE: -1.0452244048437906e-05\n",
            "E_IS_E_SCOPE: -9.174239774450834e-06\n",
            "Total Loss: 1.697722935950181e-07\n",
            "----------------------------------------\n",
            "Epoch 221\n",
            "Var loss:  tensor(1.6912e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7385596932136388e-06\n",
            "E_s_wdiff_all_sq: 1.3858609099367413e-07\n",
            "E_IS_SCOPE: -1.0453109069422676e-05\n",
            "E_IS_E_SCOPE: -9.175123224702976e-06\n",
            "Total Loss: 1.691249792139804e-07\n",
            "----------------------------------------\n",
            "Epoch 222\n",
            "Var loss:  tensor(1.6848e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7385066676488703e-06\n",
            "E_s_wdiff_all_sq: 1.389511094917098e-07\n",
            "E_IS_SCOPE: -1.0455118799583097e-05\n",
            "E_IS_E_SCOPE: -9.177019978671165e-06\n",
            "Total Loss: 1.6848098276671291e-07\n",
            "----------------------------------------\n",
            "Epoch 223\n",
            "Var loss:  tensor(1.6783e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7393821108027646e-06\n",
            "E_s_wdiff_all_sq: 1.3989979736613458e-07\n",
            "E_IS_SCOPE: -1.0459703977310559e-05\n",
            "E_IS_E_SCOPE: -9.181315995543567e-06\n",
            "Total Loss: 1.6782941633605957e-07\n",
            "----------------------------------------\n",
            "Epoch 224\n",
            "Var loss:  tensor(1.6718e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.740273654646725e-06\n",
            "E_s_wdiff_all_sq: 1.410474862471362e-07\n",
            "E_IS_SCOPE: -1.0459643617122113e-05\n",
            "E_IS_E_SCOPE: -9.181060657244333e-06\n",
            "Total Loss: 1.6718331507744353e-07\n",
            "----------------------------------------\n",
            "Epoch 225\n",
            "Var loss:  tensor(1.6655e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7411817674774657e-06\n",
            "E_s_wdiff_all_sq: 1.424647795281127e-07\n",
            "E_IS_SCOPE: -1.0459903344764308e-05\n",
            "E_IS_E_SCOPE: -9.181257151825665e-06\n",
            "Total Loss: 1.6654766850548166e-07\n",
            "----------------------------------------\n",
            "Epoch 226\n",
            "Var loss:  tensor(1.6590e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7417042984427773e-06\n",
            "E_s_wdiff_all_sq: 1.4386432174723282e-07\n",
            "E_IS_SCOPE: -1.0456258586706909e-05\n",
            "E_IS_E_SCOPE: -9.177729233962356e-06\n",
            "Total Loss: 1.659043376398569e-07\n",
            "----------------------------------------\n",
            "Epoch 227\n",
            "Var loss:  tensor(1.6527e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7434479808515223e-06\n",
            "E_s_wdiff_all_sq: 1.4597025657158138e-07\n",
            "E_IS_SCOPE: -1.0454784482197305e-05\n",
            "E_IS_E_SCOPE: -9.176117668950777e-06\n",
            "Total Loss: 1.6526716422030155e-07\n",
            "----------------------------------------\n",
            "Epoch 228\n",
            "Var loss:  tensor(1.6463e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7454947317432827e-06\n",
            "E_s_wdiff_all_sq: 1.4812983423275126e-07\n",
            "E_IS_SCOPE: -1.0454754252648039e-05\n",
            "E_IS_E_SCOPE: -9.175824730557847e-06\n",
            "Total Loss: 1.6462891976356403e-07\n",
            "----------------------------------------\n",
            "Epoch 229\n",
            "Var loss:  tensor(1.6398e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7473079231103659e-06\n",
            "E_s_wdiff_all_sq: 1.500898268054322e-07\n",
            "E_IS_SCOPE: -1.045644023072339e-05\n",
            "E_IS_E_SCOPE: -9.17725833563972e-06\n",
            "Total Loss: 1.639773725710098e-07\n",
            "----------------------------------------\n",
            "Epoch 230\n",
            "Var loss:  tensor(1.6333e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7471696707860037e-06\n",
            "E_s_wdiff_all_sq: 1.5075674336481026e-07\n",
            "E_IS_SCOPE: -1.0455776458203247e-05\n",
            "E_IS_E_SCOPE: -9.176675251591441e-06\n",
            "Total Loss: 1.6333358063099792e-07\n",
            "----------------------------------------\n",
            "Epoch 231\n",
            "Var loss:  tensor(1.6270e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.745256333981652e-06\n",
            "E_s_wdiff_all_sq: 1.4978696654863541e-07\n",
            "E_IS_SCOPE: -1.0454565870824841e-05\n",
            "E_IS_E_SCOPE: -9.17561748314054e-06\n",
            "Total Loss: 1.6269565849782852e-07\n",
            "----------------------------------------\n",
            "Epoch 232\n",
            "Var loss:  tensor(1.6205e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7437798831952323e-06\n",
            "E_s_wdiff_all_sq: 1.487689221174582e-07\n",
            "E_IS_SCOPE: -1.0454678057638115e-05\n",
            "E_IS_E_SCOPE: -9.175637973142926e-06\n",
            "Total Loss: 1.6205385852081215e-07\n",
            "----------------------------------------\n",
            "Epoch 233\n",
            "Var loss:  tensor(1.6142e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7442396759684765e-06\n",
            "E_s_wdiff_all_sq: 1.4941162801690616e-07\n",
            "E_IS_SCOPE: -1.0458061000412243e-05\n",
            "E_IS_E_SCOPE: -9.178794473640043e-06\n",
            "Total Loss: 1.6141806084058316e-07\n",
            "----------------------------------------\n",
            "Epoch 234\n",
            "Var loss:  tensor(1.6078e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7456679839955844e-06\n",
            "E_s_wdiff_all_sq: 1.5123773315250453e-07\n",
            "E_IS_SCOPE: -1.0459716808749948e-05\n",
            "E_IS_E_SCOPE: -9.180328428986796e-06\n",
            "Total Loss: 1.6077655775019172e-07\n",
            "----------------------------------------\n",
            "Epoch 235\n",
            "Var loss:  tensor(1.6014e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7468399993177723e-06\n",
            "E_s_wdiff_all_sq: 1.530051479814524e-07\n",
            "E_IS_SCOPE: -1.045734105343696e-05\n",
            "E_IS_E_SCOPE: -9.17793062692639e-06\n",
            "Total Loss: 1.601370647485958e-07\n",
            "----------------------------------------\n",
            "Epoch 236\n",
            "Var loss:  tensor(1.5949e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7484830711520996e-06\n",
            "E_s_wdiff_all_sq: 1.54786100023696e-07\n",
            "E_IS_SCOPE: -1.0458052182294134e-05\n",
            "E_IS_E_SCOPE: -9.178388101406893e-06\n",
            "Total Loss: 1.59491875787338e-07\n",
            "----------------------------------------\n",
            "Epoch 237\n",
            "Var loss:  tensor(1.5885e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7507326501469544e-06\n",
            "E_s_wdiff_all_sq: 1.5700627626755758e-07\n",
            "E_IS_SCOPE: -1.045989639186633e-05\n",
            "E_IS_E_SCOPE: -9.179898414596901e-06\n",
            "Total Loss: 1.5885348577395397e-07\n",
            "----------------------------------------\n",
            "Epoch 238\n",
            "Var loss:  tensor(1.5821e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.751565671510783e-06\n",
            "E_s_wdiff_all_sq: 1.584821597114168e-07\n",
            "E_IS_SCOPE: -1.0460484734337986e-05\n",
            "E_IS_E_SCOPE: -9.18048751262316e-06\n",
            "Total Loss: 1.582121348031317e-07\n",
            "----------------------------------------\n",
            "Epoch 239\n",
            "Var loss:  tensor(1.5757e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7516173472166448e-06\n",
            "E_s_wdiff_all_sq: 1.594104393135381e-07\n",
            "E_IS_SCOPE: -1.0460008210153274e-05\n",
            "E_IS_E_SCOPE: -9.180126192850398e-06\n",
            "Total Loss: 1.5756593973077322e-07\n",
            "----------------------------------------\n",
            "Epoch 240\n",
            "Var loss:  tensor(1.5692e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.752702207286652e-06\n",
            "E_s_wdiff_all_sq: 1.6078765936794585e-07\n",
            "E_IS_SCOPE: -1.0461080246618529e-05\n",
            "E_IS_E_SCOPE: -9.181023103050093e-06\n",
            "Total Loss: 1.5692332721524754e-07\n",
            "----------------------------------------\n",
            "Epoch 241\n",
            "Var loss:  tensor(1.5628e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7523995269052183e-06\n",
            "E_s_wdiff_all_sq: 1.6078051001768047e-07\n",
            "E_IS_SCOPE: -1.046048271620256e-05\n",
            "E_IS_E_SCOPE: -9.180252251235532e-06\n",
            "Total Loss: 1.562811533868966e-07\n",
            "----------------------------------------\n",
            "Epoch 242\n",
            "Var loss:  tensor(1.5564e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7509988101800129e-06\n",
            "E_s_wdiff_all_sq: 1.5956252102996786e-07\n",
            "E_IS_SCOPE: -1.0460839370505924e-05\n",
            "E_IS_E_SCOPE: -9.180380992616438e-06\n",
            "Total Loss: 1.5564259980448994e-07\n",
            "----------------------------------------\n",
            "Epoch 243\n",
            "Var loss:  tensor(1.5500e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.748630436049306e-06\n",
            "E_s_wdiff_all_sq: 1.5795472743779332e-07\n",
            "E_IS_SCOPE: -1.0460836271398226e-05\n",
            "E_IS_E_SCOPE: -9.180436086459448e-06\n",
            "Total Loss: 1.549984051673694e-07\n",
            "----------------------------------------\n",
            "Epoch 244\n",
            "Var loss:  tensor(1.5436e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.747823058915892e-06\n",
            "E_s_wdiff_all_sq: 1.578094731979114e-07\n",
            "E_IS_SCOPE: -1.0457820966329391e-05\n",
            "E_IS_E_SCOPE: -9.177433532822301e-06\n",
            "Total Loss: 1.5436178513721452e-07\n",
            "----------------------------------------\n",
            "Epoch 245\n",
            "Var loss:  tensor(1.5372e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7495722502941363e-06\n",
            "E_s_wdiff_all_sq: 1.5949434645601895e-07\n",
            "E_IS_SCOPE: -1.0458696722046427e-05\n",
            "E_IS_E_SCOPE: -9.177957132727783e-06\n",
            "Total Loss: 1.5372179163424397e-07\n",
            "----------------------------------------\n",
            "Epoch 246\n",
            "Var loss:  tensor(1.5308e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7518526970942281e-06\n",
            "E_s_wdiff_all_sq: 1.621680460030213e-07\n",
            "E_IS_SCOPE: -1.0460095358712852e-05\n",
            "E_IS_E_SCOPE: -9.17923165663916e-06\n",
            "Total Loss: 1.5308031337723694e-07\n",
            "----------------------------------------\n",
            "Epoch 247\n",
            "Var loss:  tensor(1.5244e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.75447432477904e-06\n",
            "E_s_wdiff_all_sq: 1.6536910705884774e-07\n",
            "E_IS_SCOPE: -1.046280501500442e-05\n",
            "E_IS_E_SCOPE: -9.181913262289017e-06\n",
            "Total Loss: 1.524447787228019e-07\n",
            "----------------------------------------\n",
            "Epoch 248\n",
            "Var loss:  tensor(1.5180e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7567182860073056e-06\n",
            "E_s_wdiff_all_sq: 1.6840025226733468e-07\n",
            "E_IS_SCOPE: -1.0461486258712005e-05\n",
            "E_IS_E_SCOPE: -9.180666878423921e-06\n",
            "Total Loss: 1.5180233959721798e-07\n",
            "----------------------------------------\n",
            "Epoch 249\n",
            "Var loss:  tensor(1.5116e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7591926759199087e-06\n",
            "E_s_wdiff_all_sq: 1.7128499260436842e-07\n",
            "E_IS_SCOPE: -1.0460876800915892e-05\n",
            "E_IS_E_SCOPE: -9.179939976177304e-06\n",
            "Total Loss: 1.511571002717782e-07\n",
            "----------------------------------------\n",
            "Epoch 250\n",
            "Var loss:  tensor(1.5053e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7612708060504384e-06\n",
            "E_s_wdiff_all_sq: 1.735193010791507e-07\n",
            "E_IS_SCOPE: -1.0460753271206583e-05\n",
            "E_IS_E_SCOPE: -9.179580263859504e-06\n",
            "Total Loss: 1.5052855671054326e-07\n",
            "----------------------------------------\n",
            "Epoch 251\n",
            "Var loss:  tensor(1.4989e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7612159817841874e-06\n",
            "E_s_wdiff_all_sq: 1.7398767486133782e-07\n",
            "E_IS_SCOPE: -1.046046556140337e-05\n",
            "E_IS_E_SCOPE: -9.179232549581669e-06\n",
            "Total Loss: 1.4988534971286493e-07\n",
            "----------------------------------------\n",
            "Epoch 252\n",
            "Var loss:  tensor(1.4924e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7597609463033071e-06\n",
            "E_s_wdiff_all_sq: 1.732982009341844e-07\n",
            "E_IS_SCOPE: -1.0460757960355661e-05\n",
            "E_IS_E_SCOPE: -9.179586688669593e-06\n",
            "Total Loss: 1.4924326843040171e-07\n",
            "----------------------------------------\n",
            "Epoch 253\n",
            "Var loss:  tensor(1.4860e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7593921587130802e-06\n",
            "E_s_wdiff_all_sq: 1.7322126226950647e-07\n",
            "E_IS_SCOPE: -1.046192579287724e-05\n",
            "E_IS_E_SCOPE: -9.180578689378714e-06\n",
            "Total Loss: 1.4859975587993454e-07\n",
            "----------------------------------------\n",
            "Epoch 254\n",
            "Var loss:  tensor(1.4795e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7599302888829527e-06\n",
            "E_s_wdiff_all_sq: 1.7357964344731667e-07\n",
            "E_IS_SCOPE: -1.046460037451883e-05\n",
            "E_IS_E_SCOPE: -9.182839976327962e-06\n",
            "Total Loss: 1.4795291548731723e-07\n",
            "----------------------------------------\n",
            "Epoch 255\n",
            "Var loss:  tensor(1.4731e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7600955930526417e-06\n",
            "E_s_wdiff_all_sq: 1.7394179096784093e-07\n",
            "E_IS_SCOPE: -1.0464514090801401e-05\n",
            "E_IS_E_SCOPE: -9.182530029627216e-06\n",
            "Total Loss: 1.4730874616984876e-07\n",
            "----------------------------------------\n",
            "Epoch 256\n",
            "Var loss:  tensor(1.4666e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7600552270100056e-06\n",
            "E_s_wdiff_all_sq: 1.7448501591811216e-07\n",
            "E_IS_SCOPE: -1.0463452047713957e-05\n",
            "E_IS_E_SCOPE: -9.181437868345602e-06\n",
            "Total Loss: 1.466649187885999e-07\n",
            "----------------------------------------\n",
            "Epoch 257\n",
            "Var loss:  tensor(1.4602e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7599482329442396e-06\n",
            "E_s_wdiff_all_sq: 1.7489761560690423e-07\n",
            "E_IS_SCOPE: -1.0463911700489385e-05\n",
            "E_IS_E_SCOPE: -9.181832929029563e-06\n",
            "Total Loss: 1.460161408511103e-07\n",
            "----------------------------------------\n",
            "Epoch 258\n",
            "Var loss:  tensor(1.4537e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7597081048368775e-06\n",
            "E_s_wdiff_all_sq: 1.7546909543590988e-07\n",
            "E_IS_SCOPE: -1.0462726451589788e-05\n",
            "E_IS_E_SCOPE: -9.180730911284939e-06\n",
            "Total Loss: 1.4537099522468424e-07\n",
            "----------------------------------------\n",
            "Epoch 259\n",
            "Var loss:  tensor(1.4473e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.760441119439797e-06\n",
            "E_s_wdiff_all_sq: 1.7682921079583578e-07\n",
            "E_IS_SCOPE: -1.046238172181875e-05\n",
            "E_IS_E_SCOPE: -9.180380576380438e-06\n",
            "Total Loss: 1.4473268420075234e-07\n",
            "----------------------------------------\n",
            "Epoch 260\n",
            "Var loss:  tensor(1.4408e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7624567909047894e-06\n",
            "E_s_wdiff_all_sq: 1.789674116711514e-07\n",
            "E_IS_SCOPE: -1.0459599646463285e-05\n",
            "E_IS_E_SCOPE: -9.177331624509329e-06\n",
            "Total Loss: 1.4407640175914274e-07\n",
            "----------------------------------------\n",
            "Epoch 261\n",
            "Var loss:  tensor(1.4343e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7633982811940541e-06\n",
            "E_s_wdiff_all_sq: 1.8002966405584798e-07\n",
            "E_IS_SCOPE: -1.045430413598943e-05\n",
            "E_IS_E_SCOPE: -9.171771191314112e-06\n",
            "Total Loss: 1.4342579422098563e-07\n",
            "----------------------------------------\n",
            "Epoch 262\n",
            "Var loss:  tensor(1.4278e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7640436953847062e-06\n",
            "E_s_wdiff_all_sq: 1.8098976762098602e-07\n",
            "E_IS_SCOPE: -1.045028098644712e-05\n",
            "E_IS_E_SCOPE: -9.167584760592755e-06\n",
            "Total Loss: 1.4278454248840528e-07\n",
            "----------------------------------------\n",
            "Epoch 263\n",
            "Var loss:  tensor(1.4214e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7634472847825978e-06\n",
            "E_s_wdiff_all_sq: 1.8131989982456647e-07\n",
            "E_IS_SCOPE: -1.0445941598797853e-05\n",
            "E_IS_E_SCOPE: -9.163384501255257e-06\n",
            "Total Loss: 1.4213625630625622e-07\n",
            "----------------------------------------\n",
            "Epoch 264\n",
            "Var loss:  tensor(1.4149e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.764415700787053e-06\n",
            "E_s_wdiff_all_sq: 1.8280952148201338e-07\n",
            "E_IS_SCOPE: -1.0443944949440603e-05\n",
            "E_IS_E_SCOPE: -9.16132344407908e-06\n",
            "Total Loss: 1.4148623501540997e-07\n",
            "----------------------------------------\n",
            "Epoch 265\n",
            "Var loss:  tensor(1.4083e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7671742281428323e-06\n",
            "E_s_wdiff_all_sq: 1.8564507388594667e-07\n",
            "E_IS_SCOPE: -1.0445721299336475e-05\n",
            "E_IS_E_SCOPE: -9.16280967134644e-06\n",
            "Total Loss: 1.4082896471023093e-07\n",
            "----------------------------------------\n",
            "Epoch 266\n",
            "Var loss:  tensor(1.4018e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.769720434306535e-06\n",
            "E_s_wdiff_all_sq: 1.8841869647411404e-07\n",
            "E_IS_SCOPE: -1.0449456372247518e-05\n",
            "E_IS_E_SCOPE: -9.166334744924064e-06\n",
            "Total Loss: 1.401815496189308e-07\n",
            "----------------------------------------\n",
            "Epoch 267\n",
            "Var loss:  tensor(1.3952e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7698575739975834e-06\n",
            "E_s_wdiff_all_sq: 1.89644373950154e-07\n",
            "E_IS_SCOPE: -1.0448901594213123e-05\n",
            "E_IS_E_SCOPE: -9.165991806060456e-06\n",
            "Total Loss: 1.395166901755122e-07\n",
            "----------------------------------------\n",
            "Epoch 268\n",
            "Var loss:  tensor(1.3886e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7695085445879618e-06\n",
            "E_s_wdiff_all_sq: 1.9023336487219613e-07\n",
            "E_IS_SCOPE: -1.044690595751027e-05\n",
            "E_IS_E_SCOPE: -9.164135335141611e-06\n",
            "Total Loss: 1.388570014118631e-07\n",
            "----------------------------------------\n",
            "Epoch 269\n",
            "Var loss:  tensor(1.3820e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7701907405958831e-06\n",
            "E_s_wdiff_all_sq: 1.9062438202763115e-07\n",
            "E_IS_SCOPE: -1.0449437209335548e-05\n",
            "E_IS_E_SCOPE: -9.166191412145714e-06\n",
            "Total Loss: 1.3819783062200228e-07\n",
            "----------------------------------------\n",
            "Epoch 270\n",
            "Var loss:  tensor(1.3754e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.769137553642356e-06\n",
            "E_s_wdiff_all_sq: 1.8973285243082855e-07\n",
            "E_IS_SCOPE: -1.0450713624069527e-05\n",
            "E_IS_E_SCOPE: -9.16722071488748e-06\n",
            "Total Loss: 1.3754194928085e-07\n",
            "----------------------------------------\n",
            "Epoch 271\n",
            "Var loss:  tensor(1.3689e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7666987737461143e-06\n",
            "E_s_wdiff_all_sq: 1.8836787820051664e-07\n",
            "E_IS_SCOPE: -1.0449605819564161e-05\n",
            "E_IS_E_SCOPE: -9.166321918644114e-06\n",
            "Total Loss: 1.3688616013891785e-07\n",
            "----------------------------------------\n",
            "Epoch 272\n",
            "Var loss:  tensor(1.3622e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7656016011496945e-06\n",
            "E_s_wdiff_all_sq: 1.8807953362166853e-07\n",
            "E_IS_SCOPE: -1.0443620799949787e-05\n",
            "E_IS_E_SCOPE: -9.160409831614131e-06\n",
            "Total Loss: 1.3622319729013106e-07\n",
            "----------------------------------------\n",
            "Epoch 273\n",
            "Var loss:  tensor(1.3556e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7680662107946642e-06\n",
            "E_s_wdiff_all_sq: 1.9001257585059638e-07\n",
            "E_IS_SCOPE: -1.0440787953824423e-05\n",
            "E_IS_E_SCOPE: -9.156981943277473e-06\n",
            "Total Loss: 1.355646802835842e-07\n",
            "----------------------------------------\n",
            "Epoch 274\n",
            "Var loss:  tensor(1.3490e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.770323516887919e-06\n",
            "E_s_wdiff_all_sq: 1.9224045769489836e-07\n",
            "E_IS_SCOPE: -1.043931798237091e-05\n",
            "E_IS_E_SCOPE: -9.155166123176814e-06\n",
            "Total Loss: 1.3490240723824424e-07\n",
            "----------------------------------------\n",
            "Epoch 275\n",
            "Var loss:  tensor(1.3424e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7708356349537273e-06\n",
            "E_s_wdiff_all_sq: 1.940186427273107e-07\n",
            "E_IS_SCOPE: -1.0435779307134885e-05\n",
            "E_IS_E_SCOPE: -9.151931646308486e-06\n",
            "Total Loss: 1.3424473700703312e-07\n",
            "----------------------------------------\n",
            "Epoch 276\n",
            "Var loss:  tensor(1.3359e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.77196356560798e-06\n",
            "E_s_wdiff_all_sq: 1.9612187149287854e-07\n",
            "E_IS_SCOPE: -1.0430617236285214e-05\n",
            "E_IS_E_SCOPE: -9.146929711222686e-06\n",
            "Total Loss: 1.335897104234637e-07\n",
            "----------------------------------------\n",
            "Epoch 277\n",
            "Var loss:  tensor(1.3293e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.77548909727145e-06\n",
            "E_s_wdiff_all_sq: 1.995698041428827e-07\n",
            "E_IS_SCOPE: -1.0429004590830635e-05\n",
            "E_IS_E_SCOPE: -9.144947696388625e-06\n",
            "Total Loss: 1.329285706779634e-07\n",
            "----------------------------------------\n",
            "Epoch 278\n",
            "Var loss:  tensor(1.3227e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7785523855361568e-06\n",
            "E_s_wdiff_all_sq: 2.0269590318062503e-07\n",
            "E_IS_SCOPE: -1.042805965285692e-05\n",
            "E_IS_E_SCOPE: -9.14370388279196e-06\n",
            "Total Loss: 1.3226800865902796e-07\n",
            "----------------------------------------\n",
            "Epoch 279\n",
            "Var loss:  tensor(1.3162e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7796341427694831e-06\n",
            "E_s_wdiff_all_sq: 2.046307716417365e-07\n",
            "E_IS_SCOPE: -1.0425262641072191e-05\n",
            "E_IS_E_SCOPE: -9.141009510331204e-06\n",
            "Total Loss: 1.3162017607918817e-07\n",
            "----------------------------------------\n",
            "Epoch 280\n",
            "Var loss:  tensor(1.3096e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7789890088167458e-06\n",
            "E_s_wdiff_all_sq: 2.049856178529891e-07\n",
            "E_IS_SCOPE: -1.0421360817532884e-05\n",
            "E_IS_E_SCOPE: -9.13727903172707e-06\n",
            "Total Loss: 1.309628857855432e-07\n",
            "----------------------------------------\n",
            "Epoch 281\n",
            "Var loss:  tensor(1.3029e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7781198842584413e-06\n",
            "E_s_wdiff_all_sq: 2.0438164743723147e-07\n",
            "E_IS_SCOPE: -1.0419984664052013e-05\n",
            "E_IS_E_SCOPE: -9.13570107677164e-06\n",
            "Total Loss: 1.3029412869388135e-07\n",
            "----------------------------------------\n",
            "Epoch 282\n",
            "Var loss:  tensor(1.2964e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.777361957653897e-06\n",
            "E_s_wdiff_all_sq: 2.0380817626837826e-07\n",
            "E_IS_SCOPE: -1.0417414752588068e-05\n",
            "E_IS_E_SCOPE: -9.132895603981939e-06\n",
            "Total Loss: 1.2963855060667575e-07\n",
            "----------------------------------------\n",
            "Epoch 283\n",
            "Var loss:  tensor(1.2899e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7763105401164026e-06\n",
            "E_s_wdiff_all_sq: 2.0341013893713345e-07\n",
            "E_IS_SCOPE: -1.0416539458764655e-05\n",
            "E_IS_E_SCOPE: -9.132020244212534e-06\n",
            "Total Loss: 1.2898503850844248e-07\n",
            "----------------------------------------\n",
            "Epoch 284\n",
            "Var loss:  tensor(1.2832e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7751777161232545e-06\n",
            "E_s_wdiff_all_sq: 2.029930363698069e-07\n",
            "E_IS_SCOPE: -1.0415670960538858e-05\n",
            "E_IS_E_SCOPE: -9.131178060387017e-06\n",
            "Total Loss: 1.2832194588318155e-07\n",
            "----------------------------------------\n",
            "Epoch 285\n",
            "Var loss:  tensor(1.2766e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7763876577993641e-06\n",
            "E_s_wdiff_all_sq: 2.0411471294798634e-07\n",
            "E_IS_SCOPE: -1.0417525046655218e-05\n",
            "E_IS_E_SCOPE: -9.1326588564687e-06\n",
            "Total Loss: 1.2766363091175617e-07\n",
            "----------------------------------------\n",
            "Epoch 286\n",
            "Var loss:  tensor(1.2702e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7789918351959847e-06\n",
            "E_s_wdiff_all_sq: 2.0646381043275854e-07\n",
            "E_IS_SCOPE: -1.0420175725332962e-05\n",
            "E_IS_E_SCOPE: -9.13486013848053e-06\n",
            "Total Loss: 1.2701991749178068e-07\n",
            "----------------------------------------\n",
            "Epoch 287\n",
            "Var loss:  tensor(1.2635e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7796083787126626e-06\n",
            "E_s_wdiff_all_sq: 2.0810291646705268e-07\n",
            "E_IS_SCOPE: -1.041348378287602e-05\n",
            "E_IS_E_SCOPE: -9.12834679623124e-06\n",
            "Total Loss: 1.2635455538946315e-07\n",
            "----------------------------------------\n",
            "Epoch 288\n",
            "Var loss:  tensor(1.2569e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7799369660920976e-06\n",
            "E_s_wdiff_all_sq: 2.0953812730450945e-07\n",
            "E_IS_SCOPE: -1.0407141406025578e-05\n",
            "E_IS_E_SCOPE: -9.122224712898652e-06\n",
            "Total Loss: 1.2568851896715273e-07\n",
            "----------------------------------------\n",
            "Epoch 289\n",
            "Var loss:  tensor(1.2504e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7834675224954335e-06\n",
            "E_s_wdiff_all_sq: 2.130356633332161e-07\n",
            "E_IS_SCOPE: -1.040680094322707e-05\n",
            "E_IS_E_SCOPE: -9.121544642465962e-06\n",
            "Total Loss: 1.250423240734157e-07\n",
            "----------------------------------------\n",
            "Epoch 290\n",
            "Var loss:  tensor(1.2440e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7866853823331606e-06\n",
            "E_s_wdiff_all_sq: 2.1632412594151053e-07\n",
            "E_IS_SCOPE: -1.0408179001069024e-05\n",
            "E_IS_E_SCOPE: -9.122639266020722e-06\n",
            "Total Loss: 1.2440485272846273e-07\n",
            "----------------------------------------\n",
            "Epoch 291\n",
            "Var loss:  tensor(1.2376e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7868240593460986e-06\n",
            "E_s_wdiff_all_sq: 2.175604824046332e-07\n",
            "E_IS_SCOPE: -1.0403423051419139e-05\n",
            "E_IS_E_SCOPE: -9.11811180243828e-06\n",
            "Total Loss: 1.2376414541316366e-07\n",
            "----------------------------------------\n",
            "Epoch 292\n",
            "Var loss:  tensor(1.2312e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7868524714920438e-06\n",
            "E_s_wdiff_all_sq: 2.1867561328055697e-07\n",
            "E_IS_SCOPE: -1.0399227293205882e-05\n",
            "E_IS_E_SCOPE: -9.11413872178555e-06\n",
            "Total Loss: 1.2312278180424125e-07\n",
            "----------------------------------------\n",
            "Epoch 293\n",
            "Var loss:  tensor(1.2250e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7902801220221295e-06\n",
            "E_s_wdiff_all_sq: 2.2162535083602078e-07\n",
            "E_IS_SCOPE: -1.0401451241030636e-05\n",
            "E_IS_E_SCOPE: -9.11581042789991e-06\n",
            "Total Loss: 1.2249621135807247e-07\n",
            "----------------------------------------\n",
            "Epoch 294\n",
            "Var loss:  tensor(1.2186e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7920082654065135e-06\n",
            "E_s_wdiff_all_sq: 2.2299257574964347e-07\n",
            "E_IS_SCOPE: -1.0403110665061582e-05\n",
            "E_IS_E_SCOPE: -9.116969695554372e-06\n",
            "Total Loss: 1.2185681707586308e-07\n",
            "----------------------------------------\n",
            "Epoch 295\n",
            "Var loss:  tensor(1.2122e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7888360740298392e-06\n",
            "E_s_wdiff_all_sq: 2.2123878833948505e-07\n",
            "E_IS_SCOPE: -1.0396548224484091e-05\n",
            "E_IS_E_SCOPE: -9.110795849409268e-06\n",
            "Total Loss: 1.2121560197412344e-07\n",
            "----------------------------------------\n",
            "Epoch 296\n",
            "Var loss:  tensor(1.2058e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7862276753803672e-06\n",
            "E_s_wdiff_all_sq: 2.1942278040138897e-07\n",
            "E_IS_SCOPE: -1.0392967167857434e-05\n",
            "E_IS_E_SCOPE: -9.107293872774308e-06\n",
            "Total Loss: 1.2058137124614278e-07\n",
            "----------------------------------------\n",
            "Epoch 297\n",
            "Var loss:  tensor(1.1995e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7866842556344687e-06\n",
            "E_s_wdiff_all_sq: 2.196125024758515e-07\n",
            "E_IS_SCOPE: -1.0394038691874905e-05\n",
            "E_IS_E_SCOPE: -9.10791580431767e-06\n",
            "Total Loss: 1.1994904447756047e-07\n",
            "----------------------------------------\n",
            "Epoch 298\n",
            "Var loss:  tensor(1.1932e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.787005008038995e-06\n",
            "E_s_wdiff_all_sq: 2.2035834332368694e-07\n",
            "E_IS_SCOPE: -1.039511007922034e-05\n",
            "E_IS_E_SCOPE: -9.108886012504627e-06\n",
            "Total Loss: 1.1932159771729535e-07\n",
            "----------------------------------------\n",
            "Epoch 299\n",
            "Var loss:  tensor(1.1869e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7869275095264578e-06\n",
            "E_s_wdiff_all_sq: 2.2111929944694488e-07\n",
            "E_IS_SCOPE: -1.0393742402430107e-05\n",
            "E_IS_E_SCOPE: -9.107619929835728e-06\n",
            "Total Loss: 1.1868633132416935e-07\n",
            "----------------------------------------\n",
            "Epoch 300\n",
            "Var loss:  tensor(1.1805e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7878777394131112e-06\n",
            "E_s_wdiff_all_sq: 2.2242493350761248e-07\n",
            "E_IS_SCOPE: -1.0394241320850136e-05\n",
            "E_IS_E_SCOPE: -9.107979237051593e-06\n",
            "Total Loss: 1.1805170474182911e-07\n",
            "----------------------------------------\n",
            "Epoch 301\n",
            "Var loss:  tensor(1.1742e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.789271556648441e-06\n",
            "E_s_wdiff_all_sq: 2.2418822445444706e-07\n",
            "E_IS_SCOPE: -1.0393910768304846e-05\n",
            "E_IS_E_SCOPE: -9.107519044389159e-06\n",
            "Total Loss: 1.1742295079603649e-07\n",
            "----------------------------------------\n",
            "Epoch 302\n",
            "Var loss:  tensor(1.1680e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7908770319842185e-06\n",
            "E_s_wdiff_all_sq: 2.2607898292583807e-07\n",
            "E_IS_SCOPE: -1.03922041704708e-05\n",
            "E_IS_E_SCOPE: -9.105642324505715e-06\n",
            "Total Loss: 1.1679742356162505e-07\n",
            "----------------------------------------\n",
            "Epoch 303\n",
            "Var loss:  tensor(1.1617e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7919382745084536e-06\n",
            "E_s_wdiff_all_sq: 2.2750067128988802e-07\n",
            "E_IS_SCOPE: -1.0389273056368621e-05\n",
            "E_IS_E_SCOPE: -9.102578475251142e-06\n",
            "Total Loss: 1.161715074170197e-07\n",
            "----------------------------------------\n",
            "Epoch 304\n",
            "Var loss:  tensor(1.1554e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.792143657592719e-06\n",
            "E_s_wdiff_all_sq: 2.2797854203732862e-07\n",
            "E_IS_SCOPE: -1.038773721774323e-05\n",
            "E_IS_E_SCOPE: -9.100863973648154e-06\n",
            "Total Loss: 1.1554169379865563e-07\n",
            "----------------------------------------\n",
            "Epoch 305\n",
            "Var loss:  tensor(1.1493e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7907459993759377e-06\n",
            "E_s_wdiff_all_sq: 2.2719775213939785e-07\n",
            "E_IS_SCOPE: -1.0383448312964843e-05\n",
            "E_IS_E_SCOPE: -9.096575543411794e-06\n",
            "Total Loss: 1.1492577456385684e-07\n",
            "----------------------------------------\n",
            "Epoch 306\n",
            "Var loss:  tensor(1.1431e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7891368126472525e-06\n",
            "E_s_wdiff_all_sq: 2.2667283941292478e-07\n",
            "E_IS_SCOPE: -1.0377694310915142e-05\n",
            "E_IS_E_SCOPE: -9.091053504862099e-06\n",
            "Total Loss: 1.1430542756165728e-07\n",
            "----------------------------------------\n",
            "Epoch 307\n",
            "Var loss:  tensor(1.1367e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7899119733127507e-06\n",
            "E_s_wdiff_all_sq: 2.2813610952904193e-07\n",
            "E_IS_SCOPE: -1.03759071398555e-05\n",
            "E_IS_E_SCOPE: -9.089294115208419e-06\n",
            "Total Loss: 1.1367288092296075e-07\n",
            "----------------------------------------\n",
            "Epoch 308\n",
            "Var loss:  tensor(1.1304e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7936552441597232e-06\n",
            "E_s_wdiff_all_sq: 2.3202224055865683e-07\n",
            "E_IS_SCOPE: -1.0380146763917824e-05\n",
            "E_IS_E_SCOPE: -9.093290758524629e-06\n",
            "Total Loss: 1.130440592480939e-07\n",
            "----------------------------------------\n",
            "Epoch 309\n",
            "Var loss:  tensor(1.1243e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7971000373839665e-06\n",
            "E_s_wdiff_all_sq: 2.354888071559719e-07\n",
            "E_IS_SCOPE: -1.0386152808417919e-05\n",
            "E_IS_E_SCOPE: -9.098999324263099e-06\n",
            "Total Loss: 1.1242732835177043e-07\n",
            "----------------------------------------\n",
            "Epoch 310\n",
            "Var loss:  tensor(1.1180e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7969682693787913e-06\n",
            "E_s_wdiff_all_sq: 2.361542953821434e-07\n",
            "E_IS_SCOPE: -1.038216046557734e-05\n",
            "E_IS_E_SCOPE: -9.095089457404167e-06\n",
            "Total Loss: 1.1179502408371662e-07\n",
            "----------------------------------------\n",
            "Epoch 311\n",
            "Var loss:  tensor(1.1117e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7966095231007444e-06\n",
            "E_s_wdiff_all_sq: 2.365775962092629e-07\n",
            "E_IS_SCOPE: -1.0372975909110613e-05\n",
            "E_IS_E_SCOPE: -9.085985679040843e-06\n",
            "Total Loss: 1.1117453318535594e-07\n",
            "----------------------------------------\n",
            "Epoch 312\n",
            "Var loss:  tensor(1.1056e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7987056443128666e-06\n",
            "E_s_wdiff_all_sq: 2.3850206938688644e-07\n",
            "E_IS_SCOPE: -1.0368712039555494e-05\n",
            "E_IS_E_SCOPE: -9.081328937663862e-06\n",
            "Total Loss: 1.1056043757613148e-07\n",
            "----------------------------------------\n",
            "Epoch 313\n",
            "Var loss:  tensor(1.0993e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.799605218506197e-06\n",
            "E_s_wdiff_all_sq: 2.3919681381749194e-07\n",
            "E_IS_SCOPE: -1.0369280290589961e-05\n",
            "E_IS_E_SCOPE: -9.081479491550445e-06\n",
            "Total Loss: 1.0992987304308782e-07\n",
            "----------------------------------------\n",
            "Epoch 314\n",
            "Var loss:  tensor(1.0930e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.797164722089172e-06\n",
            "E_s_wdiff_all_sq: 2.374055471136057e-07\n",
            "E_IS_SCOPE: -1.0368029803934094e-05\n",
            "E_IS_E_SCOPE: -9.080239587607725e-06\n",
            "Total Loss: 1.0930180875624557e-07\n",
            "----------------------------------------\n",
            "Epoch 315\n",
            "Var loss:  tensor(1.0868e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7928762227193067e-06\n",
            "E_s_wdiff_all_sq: 2.3393090430943315e-07\n",
            "E_IS_SCOPE: -1.036439421159407e-05\n",
            "E_IS_E_SCOPE: -9.076699960883182e-06\n",
            "Total Loss: 1.0867988342151072e-07\n",
            "----------------------------------------\n",
            "Epoch 316\n",
            "Var loss:  tensor(1.0806e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.789914254803339e-06\n",
            "E_s_wdiff_all_sq: 2.316438975205221e-07\n",
            "E_IS_SCOPE: -1.0361254986746827e-05\n",
            "E_IS_E_SCOPE: -9.073588716656031e-06\n",
            "Total Loss: 1.0806088353464069e-07\n",
            "----------------------------------------\n",
            "Epoch 317\n",
            "Var loss:  tensor(1.0743e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7904555065522625e-06\n",
            "E_s_wdiff_all_sq: 2.3241589233025768e-07\n",
            "E_IS_SCOPE: -1.0361915728598315e-05\n",
            "E_IS_E_SCOPE: -9.074050448855403e-06\n",
            "Total Loss: 1.074321211695986e-07\n",
            "----------------------------------------\n",
            "Epoch 318\n",
            "Var loss:  tensor(1.0681e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.79363136683934e-06\n",
            "E_s_wdiff_all_sq: 2.3542894080123295e-07\n",
            "E_IS_SCOPE: -1.0366592564989412e-05\n",
            "E_IS_E_SCOPE: -9.078332806464287e-06\n",
            "Total Loss: 1.0680597542127319e-07\n",
            "----------------------------------------\n",
            "Epoch 319\n",
            "Var loss:  tensor(1.0618e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7954871822353848e-06\n",
            "E_s_wdiff_all_sq: 2.3772076166190373e-07\n",
            "E_IS_SCOPE: -1.0368545578542543e-05\n",
            "E_IS_E_SCOPE: -9.080191764511522e-06\n",
            "Total Loss: 1.0618185894485306e-07\n",
            "----------------------------------------\n",
            "Epoch 320\n",
            "Var loss:  tensor(1.0557e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.796094286448647e-06\n",
            "E_s_wdiff_all_sq: 2.3925479616587945e-07\n",
            "E_IS_SCOPE: -1.0367660109871508e-05\n",
            "E_IS_E_SCOPE: -9.07946382712844e-06\n",
            "Total Loss: 1.0556999123004566e-07\n",
            "----------------------------------------\n",
            "Epoch 321\n",
            "Var loss:  tensor(1.0495e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7974176418106343e-06\n",
            "E_s_wdiff_all_sq: 2.4163849454421917e-07\n",
            "E_IS_SCOPE: -1.0361000675555545e-05\n",
            "E_IS_E_SCOPE: -9.07302383794864e-06\n",
            "Total Loss: 1.0494853848601913e-07\n",
            "----------------------------------------\n",
            "Epoch 322\n",
            "Var loss:  tensor(1.0432e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8036874862586164e-06\n",
            "E_s_wdiff_all_sq: 2.4749250547790794e-07\n",
            "E_IS_SCOPE: -1.0359895685103116e-05\n",
            "E_IS_E_SCOPE: -9.071395124762296e-06\n",
            "Total Loss: 1.0431692653248355e-07\n",
            "----------------------------------------\n",
            "Epoch 323\n",
            "Var loss:  tensor(1.0370e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8106445901650156e-06\n",
            "E_s_wdiff_all_sq: 2.5391256072762406e-07\n",
            "E_IS_SCOPE: -1.0364616507943786e-05\n",
            "E_IS_E_SCOPE: -9.075538677267025e-06\n",
            "Total Loss: 1.0369943451728638e-07\n",
            "----------------------------------------\n",
            "Epoch 324\n",
            "Var loss:  tensor(1.0308e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8120113503744706e-06\n",
            "E_s_wdiff_all_sq: 2.5616298922386205e-07\n",
            "E_IS_SCOPE: -1.036250862856882e-05\n",
            "E_IS_E_SCOPE: -9.073560448369175e-06\n",
            "Total Loss: 1.0307506718473634e-07\n",
            "----------------------------------------\n",
            "Epoch 325\n",
            "Var loss:  tensor(1.0246e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.809645521938129e-06\n",
            "E_s_wdiff_all_sq: 2.552108537319324e-07\n",
            "E_IS_SCOPE: -1.0353187276728851e-05\n",
            "E_IS_E_SCOPE: -9.064636247226528e-06\n",
            "Total Loss: 1.0245567563496757e-07\n",
            "----------------------------------------\n",
            "Epoch 326\n",
            "Var loss:  tensor(1.0184e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8090177758928519e-06\n",
            "E_s_wdiff_all_sq: 2.547402845703968e-07\n",
            "E_IS_SCOPE: -1.0347670537270873e-05\n",
            "E_IS_E_SCOPE: -9.058892002823624e-06\n",
            "Total Loss: 1.0184348886137021e-07\n",
            "----------------------------------------\n",
            "Epoch 327\n",
            "Var loss:  tensor(1.0122e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8099851319002228e-06\n",
            "E_s_wdiff_all_sq: 2.551755251734757e-07\n",
            "E_IS_SCOPE: -1.0351712268160344e-05\n",
            "E_IS_E_SCOPE: -9.062357432849048e-06\n",
            "Total Loss: 1.0122300253757114e-07\n",
            "----------------------------------------\n",
            "Epoch 328\n",
            "Var loss:  tensor(1.0060e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8073908457370315e-06\n",
            "E_s_wdiff_all_sq: 2.532226102058629e-07\n",
            "E_IS_SCOPE: -1.0354904938504863e-05\n",
            "E_IS_E_SCOPE: -9.06556073912949e-06\n",
            "Total Loss: 1.0060290321383896e-07\n",
            "----------------------------------------\n",
            "Epoch 329\n",
            "Var loss:  tensor(9.9988e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8024382439765327e-06\n",
            "E_s_wdiff_all_sq: 2.4960834715332584e-07\n",
            "E_IS_SCOPE: -1.0347692701347623e-05\n",
            "E_IS_E_SCOPE: -9.05871036073377e-06\n",
            "Total Loss: 9.998828202891707e-08\n",
            "----------------------------------------\n",
            "Epoch 330\n",
            "Var loss:  tensor(9.9369e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8020365575015896e-06\n",
            "E_s_wdiff_all_sq: 2.4927179088168595e-07\n",
            "E_IS_SCOPE: -1.034288681475707e-05\n",
            "E_IS_E_SCOPE: -9.053627299224829e-06\n",
            "Total Loss: 9.936880198883544e-08\n",
            "----------------------------------------\n",
            "Epoch 331\n",
            "Var loss:  tensor(9.8755e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8059413079658765e-06\n",
            "E_s_wdiff_all_sq: 2.5271658810291076e-07\n",
            "E_IS_SCOPE: -1.0344971079032945e-05\n",
            "E_IS_E_SCOPE: -9.05517460541063e-06\n",
            "Total Loss: 9.875483905175465e-08\n",
            "----------------------------------------\n",
            "Epoch 332\n",
            "Var loss:  tensor(9.8129e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8087379248865416e-06\n",
            "E_s_wdiff_all_sq: 2.563609343439698e-07\n",
            "E_IS_SCOPE: -1.0348890346872117e-05\n",
            "E_IS_E_SCOPE: -9.059204992786168e-06\n",
            "Total Loss: 9.812934880408833e-08\n",
            "----------------------------------------\n",
            "Epoch 333\n",
            "Var loss:  tensor(9.7524e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8101969854755372e-06\n",
            "E_s_wdiff_all_sq: 2.5904382213906636e-07\n",
            "E_IS_SCOPE: -1.0351197089628065e-05\n",
            "E_IS_E_SCOPE: -9.061821140632929e-06\n",
            "Total Loss: 9.752433177961212e-08\n",
            "----------------------------------------\n",
            "Epoch 334\n",
            "Var loss:  tensor(9.6905e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8129369998475493e-06\n",
            "E_s_wdiff_all_sq: 2.6188957876502213e-07\n",
            "E_IS_SCOPE: -1.0349291910870698e-05\n",
            "E_IS_E_SCOPE: -9.059659296367752e-06\n",
            "Total Loss: 9.690525851005231e-08\n",
            "----------------------------------------\n",
            "Epoch 335\n",
            "Var loss:  tensor(9.6281e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8153851242992811e-06\n",
            "E_s_wdiff_all_sq: 2.6405561122287423e-07\n",
            "E_IS_SCOPE: -1.0347852240092736e-05\n",
            "E_IS_E_SCOPE: -9.057766547064224e-06\n",
            "Total Loss: 9.628119345280041e-08\n",
            "----------------------------------------\n",
            "Epoch 336\n",
            "Var loss:  tensor(9.5660e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8161308231553348e-06\n",
            "E_s_wdiff_all_sq: 2.653033467737564e-07\n",
            "E_IS_SCOPE: -1.0348077058037463e-05\n",
            "E_IS_E_SCOPE: -9.057931677670204e-06\n",
            "Total Loss: 9.565978208047432e-08\n",
            "----------------------------------------\n",
            "Epoch 337\n",
            "Var loss:  tensor(9.5047e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8168862539513685e-06\n",
            "E_s_wdiff_all_sq: 2.6672989349135306e-07\n",
            "E_IS_SCOPE: -1.0348822372452423e-05\n",
            "E_IS_E_SCOPE: -9.058706301059348e-06\n",
            "Total Loss: 9.50472841072792e-08\n",
            "----------------------------------------\n",
            "Epoch 338\n",
            "Var loss:  tensor(9.4435e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8178079689416856e-06\n",
            "E_s_wdiff_all_sq: 2.6747287871556757e-07\n",
            "E_IS_SCOPE: -1.0348756534917272e-05\n",
            "E_IS_E_SCOPE: -9.058244722546864e-06\n",
            "Total Loss: 9.443453191871724e-08\n",
            "----------------------------------------\n",
            "Epoch 339\n",
            "Var loss:  tensor(9.3814e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8159476781140604e-06\n",
            "E_s_wdiff_all_sq: 2.661700704995671e-07\n",
            "E_IS_SCOPE: -1.0340605077764634e-05\n",
            "E_IS_E_SCOPE: -9.050061535741709e-06\n",
            "Total Loss: 9.381359000205804e-08\n",
            "----------------------------------------\n",
            "Epoch 340\n",
            "Var loss:  tensor(9.3194e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8150493608844139e-06\n",
            "E_s_wdiff_all_sq: 2.6633188539830744e-07\n",
            "E_IS_SCOPE: -1.0335514466200388e-05\n",
            "E_IS_E_SCOPE: -9.04519113096402e-06\n",
            "Total Loss: 9.319387144678703e-08\n",
            "----------------------------------------\n",
            "Epoch 341\n",
            "Var loss:  tensor(9.2578e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8184523268055284e-06\n",
            "E_s_wdiff_all_sq: 2.6965573088217917e-07\n",
            "E_IS_SCOPE: -1.0339562369459293e-05\n",
            "E_IS_E_SCOPE: -9.048891651550014e-06\n",
            "Total Loss: 9.257822653820746e-08\n",
            "----------------------------------------\n",
            "Epoch 342\n",
            "Var loss:  tensor(9.1973e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8227743827776751e-06\n",
            "E_s_wdiff_all_sq: 2.7372057672716976e-07\n",
            "E_IS_SCOPE: -1.0343876525829274e-05\n",
            "E_IS_E_SCOPE: -9.052774495894961e-06\n",
            "Total Loss: 9.19728126152952e-08\n",
            "----------------------------------------\n",
            "Epoch 343\n",
            "Var loss:  tensor(9.1361e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8240343634623943e-06\n",
            "E_s_wdiff_all_sq: 2.7561818180105647e-07\n",
            "E_IS_SCOPE: -1.0342583762812455e-05\n",
            "E_IS_E_SCOPE: -9.051494664761084e-06\n",
            "Total Loss: 9.136105199201496e-08\n",
            "----------------------------------------\n",
            "Epoch 344\n",
            "Var loss:  tensor(9.0757e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8240842497709499e-06\n",
            "E_s_wdiff_all_sq: 2.765325262641265e-07\n",
            "E_IS_SCOPE: -1.0340055834849804e-05\n",
            "E_IS_E_SCOPE: -9.049097150987182e-06\n",
            "Total Loss: 9.075742221499456e-08\n",
            "----------------------------------------\n",
            "Epoch 345\n",
            "Var loss:  tensor(9.0147e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.824537297462487e-06\n",
            "E_s_wdiff_all_sq: 2.7771191304310383e-07\n",
            "E_IS_SCOPE: -1.0336628489948187e-05\n",
            "E_IS_E_SCOPE: -9.045727976229757e-06\n",
            "Total Loss: 9.014742341593825e-08\n",
            "----------------------------------------\n",
            "Epoch 346\n",
            "Var loss:  tensor(8.9546e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8292504105494805e-06\n",
            "E_s_wdiff_all_sq: 2.819569413978799e-07\n",
            "E_IS_SCOPE: -1.0336719875042142e-05\n",
            "E_IS_E_SCOPE: -9.045284423582013e-06\n",
            "Total Loss: 8.954563266475817e-08\n",
            "----------------------------------------\n",
            "Epoch 347\n",
            "Var loss:  tensor(8.8950e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8316428938779768e-06\n",
            "E_s_wdiff_all_sq: 2.845387036444346e-07\n",
            "E_IS_SCOPE: -1.0334778595459528e-05\n",
            "E_IS_E_SCOPE: -9.043139976395644e-06\n",
            "Total Loss: 8.89500185391897e-08\n",
            "----------------------------------------\n",
            "Epoch 348\n",
            "Var loss:  tensor(8.8347e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8302399655883206e-06\n",
            "E_s_wdiff_all_sq: 2.8384834913232284e-07\n",
            "E_IS_SCOPE: -1.033271864118667e-05\n",
            "E_IS_E_SCOPE: -9.041134579747029e-06\n",
            "Total Loss: 8.834656001013166e-08\n",
            "----------------------------------------\n",
            "Epoch 349\n",
            "Var loss:  tensor(8.7751e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8299523008747598e-06\n",
            "E_s_wdiff_all_sq: 2.8425101840628476e-07\n",
            "E_IS_SCOPE: -1.0333430923017393e-05\n",
            "E_IS_E_SCOPE: -9.04189412742951e-06\n",
            "Total Loss: 8.775075772612055e-08\n",
            "----------------------------------------\n",
            "Epoch 350\n",
            "Var loss:  tensor(8.7151e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8317749612539097e-06\n",
            "E_s_wdiff_all_sq: 2.860129220690963e-07\n",
            "E_IS_SCOPE: -1.033777496352962e-05\n",
            "E_IS_E_SCOPE: -9.045907695781059e-06\n",
            "Total Loss: 8.7150570121106e-08\n",
            "----------------------------------------\n",
            "Epoch 351\n",
            "Var loss:  tensor(8.6553e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8340378911640413e-06\n",
            "E_s_wdiff_all_sq: 2.881645550946215e-07\n",
            "E_IS_SCOPE: -1.0342370425020625e-05\n",
            "E_IS_E_SCOPE: -9.050148605802377e-06\n",
            "Total Loss: 8.655276406633746e-08\n",
            "----------------------------------------\n",
            "Epoch 352\n",
            "Var loss:  tensor(8.5947e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.833374224959294e-06\n",
            "E_s_wdiff_all_sq: 2.885023528716069e-07\n",
            "E_IS_SCOPE: -1.034095832096228e-05\n",
            "E_IS_E_SCOPE: -9.048934364541016e-06\n",
            "Total Loss: 8.594702567857271e-08\n",
            "----------------------------------------\n",
            "Epoch 353\n",
            "Var loss:  tensor(8.5363e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8345458505696458e-06\n",
            "E_s_wdiff_all_sq: 2.905258782244738e-07\n",
            "E_IS_SCOPE: -1.034068835371835e-05\n",
            "E_IS_E_SCOPE: -9.048798522546331e-06\n",
            "Total Loss: 8.536337643454943e-08\n",
            "----------------------------------------\n",
            "Epoch 354\n",
            "Var loss:  tensor(8.4763e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8382635928979762e-06\n",
            "E_s_wdiff_all_sq: 2.9377076046009085e-07\n",
            "E_IS_SCOPE: -1.0345106652618594e-05\n",
            "E_IS_E_SCOPE: -9.05268013420536e-06\n",
            "Total Loss: 8.476286204483232e-08\n",
            "----------------------------------------\n",
            "Epoch 355\n",
            "Var loss:  tensor(8.4165e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8410891513533072e-06\n",
            "E_s_wdiff_all_sq: 2.96541423453398e-07\n",
            "E_IS_SCOPE: -1.0348866636237782e-05\n",
            "E_IS_E_SCOPE: -9.05611393707684e-06\n",
            "Total Loss: 8.416539601144338e-08\n",
            "----------------------------------------\n",
            "Epoch 356\n",
            "Var loss:  tensor(8.3571e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.839962371354311e-06\n",
            "E_s_wdiff_all_sq: 2.9660907993746774e-07\n",
            "E_IS_SCOPE: -1.0343066525123418e-05\n",
            "E_IS_E_SCOPE: -9.050613678561328e-06\n",
            "Total Loss: 8.357066472607879e-08\n",
            "----------------------------------------\n",
            "Epoch 357\n",
            "Var loss:  tensor(8.2979e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8401116317700725e-06\n",
            "E_s_wdiff_all_sq: 2.9733365488619694e-07\n",
            "E_IS_SCOPE: -1.0334660170572307e-05\n",
            "E_IS_E_SCOPE: -9.042199070996025e-06\n",
            "Total Loss: 8.297884416472764e-08\n",
            "----------------------------------------\n",
            "Epoch 358\n",
            "Var loss:  tensor(8.2392e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8448962370485599e-06\n",
            "E_s_wdiff_all_sq: 3.0158148573267923e-07\n",
            "E_IS_SCOPE: -1.033480636250772e-05\n",
            "E_IS_E_SCOPE: -9.041783488554047e-06\n",
            "Total Loss: 8.239206984195125e-08\n",
            "----------------------------------------\n",
            "Epoch 359\n",
            "Var loss:  tensor(8.1802e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.848633549892066e-06\n",
            "E_s_wdiff_all_sq: 3.056729590876866e-07\n",
            "E_IS_SCOPE: -1.0335611585361874e-05\n",
            "E_IS_E_SCOPE: -9.042470579321423e-06\n",
            "Total Loss: 8.180164515689151e-08\n",
            "----------------------------------------\n",
            "Epoch 360\n",
            "Var loss:  tensor(8.1206e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8486309924552107e-06\n",
            "E_s_wdiff_all_sq: 3.066268593174746e-07\n",
            "E_IS_SCOPE: -1.0333586690667498e-05\n",
            "E_IS_E_SCOPE: -9.040626156865051e-06\n",
            "Total Loss: 8.120613196625841e-08\n",
            "----------------------------------------\n",
            "Epoch 361\n",
            "Var loss:  tensor(8.0613e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8491148360019207e-06\n",
            "E_s_wdiff_all_sq: 3.072831325904955e-07\n",
            "E_IS_SCOPE: -1.0334127471472567e-05\n",
            "E_IS_E_SCOPE: -9.040956723359244e-06\n",
            "Total Loss: 8.061327361819397e-08\n",
            "----------------------------------------\n",
            "Epoch 362\n",
            "Var loss:  tensor(8.0025e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8494941103721963e-06\n",
            "E_s_wdiff_all_sq: 3.0780308985469343e-07\n",
            "E_IS_SCOPE: -1.0335757340960319e-05\n",
            "E_IS_E_SCOPE: -9.042362846083374e-06\n",
            "Total Loss: 8.002509719702872e-08\n",
            "----------------------------------------\n",
            "Epoch 363\n",
            "Var loss:  tensor(7.9428e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8495146721495728e-06\n",
            "E_s_wdiff_all_sq: 3.0846935347571106e-07\n",
            "E_IS_SCOPE: -1.0335895365578172e-05\n",
            "E_IS_E_SCOPE: -9.042525076801941e-06\n",
            "Total Loss: 7.942780755481887e-08\n",
            "----------------------------------------\n",
            "Epoch 364\n",
            "Var loss:  tensor(7.8835e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8496907828852022e-06\n",
            "E_s_wdiff_all_sq: 3.088716849800798e-07\n",
            "E_IS_SCOPE: -1.0335584283279913e-05\n",
            "E_IS_E_SCOPE: -9.04203072540654e-06\n",
            "Total Loss: 7.883504859179393e-08\n",
            "----------------------------------------\n",
            "Epoch 365\n",
            "Var loss:  tensor(7.8245e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8497122878233997e-06\n",
            "E_s_wdiff_all_sq: 3.0880752106345143e-07\n",
            "E_IS_SCOPE: -1.0333061473182443e-05\n",
            "E_IS_E_SCOPE: -9.03917022733646e-06\n",
            "Total Loss: 7.824534150139712e-08\n",
            "----------------------------------------\n",
            "Epoch 366\n",
            "Var loss:  tensor(7.7657e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8488429888800533e-06\n",
            "E_s_wdiff_all_sq: 3.0865484641433305e-07\n",
            "E_IS_SCOPE: -1.0324552984730756e-05\n",
            "E_IS_E_SCOPE: -9.030726109337433e-06\n",
            "Total Loss: 7.765745811248985e-08\n",
            "----------------------------------------\n",
            "Epoch 367\n",
            "Var loss:  tensor(7.7074e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8492435755341458e-06\n",
            "E_s_wdiff_all_sq: 3.094937148022092e-07\n",
            "E_IS_SCOPE: -1.0317479644424225e-05\n",
            "E_IS_E_SCOPE: -9.023580106171744e-06\n",
            "Total Loss: 7.70738506603917e-08\n",
            "----------------------------------------\n",
            "Epoch 368\n",
            "Var loss:  tensor(7.6491e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.854053715743091e-06\n",
            "E_s_wdiff_all_sq: 3.13887580722104e-07\n",
            "E_IS_SCOPE: -1.0318309661867713e-05\n",
            "E_IS_E_SCOPE: -9.023910456706952e-06\n",
            "Total Loss: 7.649079113288018e-08\n",
            "----------------------------------------\n",
            "Epoch 369\n",
            "Var loss:  tensor(7.5908e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8580182006351142e-06\n",
            "E_s_wdiff_all_sq: 3.1813788184245966e-07\n",
            "E_IS_SCOPE: -1.0319279635006984e-05\n",
            "E_IS_E_SCOPE: -9.024731949275916e-06\n",
            "Total Loss: 7.590801376393387e-08\n",
            "----------------------------------------\n",
            "Epoch 370\n",
            "Var loss:  tensor(7.5324e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8590351111638258e-06\n",
            "E_s_wdiff_all_sq: 3.201984763624952e-07\n",
            "E_IS_SCOPE: -1.0318070682949e-05\n",
            "E_IS_E_SCOPE: -9.023752928199771e-06\n",
            "Total Loss: 7.532419173629035e-08\n",
            "----------------------------------------\n",
            "Epoch 371\n",
            "Var loss:  tensor(7.4740e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8599573183867416e-06\n",
            "E_s_wdiff_all_sq: 3.2143856144486204e-07\n",
            "E_IS_SCOPE: -1.032172722953697e-05\n",
            "E_IS_E_SCOPE: -9.027276323559471e-06\n",
            "Total Loss: 7.474001142029603e-08\n",
            "----------------------------------------\n",
            "Epoch 372\n",
            "Var loss:  tensor(7.4155e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8599834629728588e-06\n",
            "E_s_wdiff_all_sq: 3.2176288193937834e-07\n",
            "E_IS_SCOPE: -1.0326212261310873e-05\n",
            "E_IS_E_SCOPE: -9.031618139537151e-06\n",
            "Total Loss: 7.415540391945212e-08\n",
            "----------------------------------------\n",
            "Epoch 373\n",
            "Var loss:  tensor(7.3566e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8616804326720498e-06\n",
            "E_s_wdiff_all_sq: 3.236606325783838e-07\n",
            "E_IS_SCOPE: -1.0331318756779252e-05\n",
            "E_IS_E_SCOPE: -9.036530383617665e-06\n",
            "Total Loss: 7.356612020390772e-08\n",
            "----------------------------------------\n",
            "Epoch 374\n",
            "Var loss:  tensor(7.2992e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.862586076969805e-06\n",
            "E_s_wdiff_all_sq: 3.2486816383940227e-07\n",
            "E_IS_SCOPE: -1.0332144661005726e-05\n",
            "E_IS_E_SCOPE: -9.037220019742587e-06\n",
            "Total Loss: 7.29916970375391e-08\n",
            "----------------------------------------\n",
            "Epoch 375\n",
            "Var loss:  tensor(7.2415e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.861561522809238e-06\n",
            "E_s_wdiff_all_sq: 3.2458534001938727e-07\n",
            "E_IS_SCOPE: -1.0328223483705207e-05\n",
            "E_IS_E_SCOPE: -9.033381580126701e-06\n",
            "Total Loss: 7.24154420662548e-08\n",
            "----------------------------------------\n",
            "Epoch 376\n",
            "Var loss:  tensor(7.1830e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8634452647169618e-06\n",
            "E_s_wdiff_all_sq: 3.2650501955743144e-07\n",
            "E_IS_SCOPE: -1.0323907472611562e-05\n",
            "E_IS_E_SCOPE: -9.028790606698202e-06\n",
            "Total Loss: 7.182957976622821e-08\n",
            "----------------------------------------\n",
            "Epoch 377\n",
            "Var loss:  tensor(7.1262e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8676502331548532e-06\n",
            "E_s_wdiff_all_sq: 3.303831036841755e-07\n",
            "E_IS_SCOPE: -1.0321619274773419e-05\n",
            "E_IS_E_SCOPE: -9.026054948291937e-06\n",
            "Total Loss: 7.126154294112883e-08\n",
            "----------------------------------------\n",
            "Epoch 378\n",
            "Var loss:  tensor(7.0677e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8681204770205192e-06\n",
            "E_s_wdiff_all_sq: 3.3139491307600796e-07\n",
            "E_IS_SCOPE: -1.0316836122740247e-05\n",
            "E_IS_E_SCOPE: -9.021250347513743e-06\n",
            "Total Loss: 7.067707992491899e-08\n",
            "----------------------------------------\n",
            "Epoch 379\n",
            "Var loss:  tensor(7.0102e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8669983469061603e-06\n",
            "E_s_wdiff_all_sq: 3.307291853931478e-07\n",
            "E_IS_SCOPE: -1.031377437964768e-05\n",
            "E_IS_E_SCOPE: -9.018129460907222e-06\n",
            "Total Loss: 7.0102390465511e-08\n",
            "----------------------------------------\n",
            "Epoch 380\n",
            "Var loss:  tensor(6.9521e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8676519147512837e-06\n",
            "E_s_wdiff_all_sq: 3.316985786358116e-07\n",
            "E_IS_SCOPE: -1.0315321764380118e-05\n",
            "E_IS_E_SCOPE: -9.019544189385059e-06\n",
            "Total Loss: 6.952125255876894e-08\n",
            "----------------------------------------\n",
            "Epoch 381\n",
            "Var loss:  tensor(6.8938e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.870940628827859e-06\n",
            "E_s_wdiff_all_sq: 3.3529385816867433e-07\n",
            "E_IS_SCOPE: -1.0318959180402473e-05\n",
            "E_IS_E_SCOPE: -9.023043027015365e-06\n",
            "Total Loss: 6.893753031838255e-08\n",
            "----------------------------------------\n",
            "Epoch 382\n",
            "Var loss:  tensor(6.8360e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.874489070021739e-06\n",
            "E_s_wdiff_all_sq: 3.392391729777743e-07\n",
            "E_IS_SCOPE: -1.032022593879432e-05\n",
            "E_IS_E_SCOPE: -9.024219372773333e-06\n",
            "Total Loss: 6.835983143540615e-08\n",
            "----------------------------------------\n",
            "Epoch 383\n",
            "Var loss:  tensor(6.7776e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8795333290878558e-06\n",
            "E_s_wdiff_all_sq: 3.4417118551940225e-07\n",
            "E_IS_SCOPE: -1.032156993597268e-05\n",
            "E_IS_E_SCOPE: -9.02521539240835e-06\n",
            "Total Loss: 6.777612287321225e-08\n",
            "----------------------------------------\n",
            "Epoch 384\n",
            "Var loss:  tensor(6.7201e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8825330268905687e-06\n",
            "E_s_wdiff_all_sq: 3.475911849865068e-07\n",
            "E_IS_SCOPE: -1.0319648464937042e-05\n",
            "E_IS_E_SCOPE: -9.023216723525299e-06\n",
            "Total Loss: 6.72014255139905e-08\n",
            "----------------------------------------\n",
            "Epoch 385\n",
            "Var loss:  tensor(6.6629e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8821120359793671e-06\n",
            "E_s_wdiff_all_sq: 3.481520009204671e-07\n",
            "E_IS_SCOPE: -1.0314261774066302e-05\n",
            "E_IS_E_SCOPE: -9.018034483617153e-06\n",
            "Total Loss: 6.66285205940154e-08\n",
            "----------------------------------------\n",
            "Epoch 386\n",
            "Var loss:  tensor(6.6051e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8823419332205307e-06\n",
            "E_s_wdiff_all_sq: 3.487557818776904e-07\n",
            "E_IS_SCOPE: -1.030952085576445e-05\n",
            "E_IS_E_SCOPE: -9.01319178759603e-06\n",
            "Total Loss: 6.605108143941231e-08\n",
            "----------------------------------------\n",
            "Epoch 387\n",
            "Var loss:  tensor(6.5471e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.885504268802815e-06\n",
            "E_s_wdiff_all_sq: 3.512676843518606e-07\n",
            "E_IS_SCOPE: -1.0311361925394809e-05\n",
            "E_IS_E_SCOPE: -9.014417560974977e-06\n",
            "Total Loss: 6.547092204470775e-08\n",
            "----------------------------------------\n",
            "Epoch 388\n",
            "Var loss:  tensor(6.4906e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.887933591448443e-06\n",
            "E_s_wdiff_all_sq: 3.53466754280809e-07\n",
            "E_IS_SCOPE: -1.0315666362387826e-05\n",
            "E_IS_E_SCOPE: -9.01832423622435e-06\n",
            "Total Loss: 6.490565127409993e-08\n",
            "----------------------------------------\n",
            "Epoch 389\n",
            "Var loss:  tensor(6.4317e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8850755718474016e-06\n",
            "E_s_wdiff_all_sq: 3.516648239895659e-07\n",
            "E_IS_SCOPE: -1.0313485464848984e-05\n",
            "E_IS_E_SCOPE: -9.016377079633204e-06\n",
            "Total Loss: 6.43170438596891e-08\n",
            "----------------------------------------\n",
            "Epoch 390\n",
            "Var loss:  tensor(6.3726e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8809827221564462e-06\n",
            "E_s_wdiff_all_sq: 3.483556380783978e-07\n",
            "E_IS_SCOPE: -1.0309813220813691e-05\n",
            "E_IS_E_SCOPE: -9.012800972668712e-06\n",
            "Total Loss: 6.372565422150538e-08\n",
            "----------------------------------------\n",
            "Epoch 391\n",
            "Var loss:  tensor(6.3141e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.880338003323336e-06\n",
            "E_s_wdiff_all_sq: 3.4750566505935696e-07\n",
            "E_IS_SCOPE: -1.0312759210735495e-05\n",
            "E_IS_E_SCOPE: -9.015352134769041e-06\n",
            "Total Loss: 6.314125276448568e-08\n",
            "----------------------------------------\n",
            "Epoch 392\n",
            "Var loss:  tensor(6.2529e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8819795373454795e-06\n",
            "E_s_wdiff_all_sq: 3.494679144676805e-07\n",
            "E_IS_SCOPE: -1.0318060142803307e-05\n",
            "E_IS_E_SCOPE: -9.020507060561814e-06\n",
            "Total Loss: 6.252852482822872e-08\n",
            "----------------------------------------\n",
            "Epoch 393\n",
            "Var loss:  tensor(6.1938e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8849082075612048e-06\n",
            "E_s_wdiff_all_sq: 3.5322293056670525e-07\n",
            "E_IS_SCOPE: -1.032171481721677e-05\n",
            "E_IS_E_SCOPE: -9.024279739247746e-06\n",
            "Total Loss: 6.193818748986602e-08\n",
            "----------------------------------------\n",
            "Epoch 394\n",
            "Var loss:  tensor(6.1343e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8905244518062983e-06\n",
            "E_s_wdiff_all_sq: 3.5850958950463845e-07\n",
            "E_IS_SCOPE: -1.0320892157275671e-05\n",
            "E_IS_E_SCOPE: -9.022994571556825e-06\n",
            "Total Loss: 6.134275729738373e-08\n",
            "----------------------------------------\n",
            "Epoch 395\n",
            "Var loss:  tensor(6.0731e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8945049780451192e-06\n",
            "E_s_wdiff_all_sq: 3.6242396586569633e-07\n",
            "E_IS_SCOPE: -1.0315906718008786e-05\n",
            "E_IS_E_SCOPE: -9.017669979755636e-06\n",
            "Total Loss: 6.07306021065379e-08\n",
            "----------------------------------------\n",
            "Epoch 396\n",
            "Var loss:  tensor(6.0128e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8933896283100598e-06\n",
            "E_s_wdiff_all_sq: 3.622817607253569e-07\n",
            "E_IS_SCOPE: -1.0308766163670232e-05\n",
            "E_IS_E_SCOPE: -9.010714791335528e-06\n",
            "Total Loss: 6.012818934871049e-08\n",
            "----------------------------------------\n",
            "Epoch 397\n",
            "Var loss:  tensor(5.9533e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8921185792208823e-06\n",
            "E_s_wdiff_all_sq: 3.619872245046737e-07\n",
            "E_IS_SCOPE: -1.0303741004338369e-05\n",
            "E_IS_E_SCOPE: -9.005880202986834e-06\n",
            "Total Loss: 5.953281844655509e-08\n",
            "----------------------------------------\n",
            "Epoch 398\n",
            "Var loss:  tensor(5.8929e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8946915887260108e-06\n",
            "E_s_wdiff_all_sq: 3.641635357853031e-07\n",
            "E_IS_SCOPE: -1.0305975408668714e-05\n",
            "E_IS_E_SCOPE: -9.007614569889478e-06\n",
            "Total Loss: 5.892944181565286e-08\n",
            "----------------------------------------\n",
            "Epoch 399\n",
            "Var loss:  tensor(5.8325e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8963814821725818e-06\n",
            "E_s_wdiff_all_sq: 3.656874957201422e-07\n",
            "E_IS_SCOPE: -1.0308182679635689e-05\n",
            "E_IS_E_SCOPE: -9.009436690409244e-06\n",
            "Total Loss: 5.832507443296512e-08\n",
            "----------------------------------------\n",
            "Epoch 400\n",
            "Var loss:  tensor(5.7720e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8962954565972808e-06\n",
            "E_s_wdiff_all_sq: 3.6654028664441846e-07\n",
            "E_IS_SCOPE: -1.0308799451297773e-05\n",
            "E_IS_E_SCOPE: -9.01022041947686e-06\n",
            "Total Loss: 5.772017274445536e-08\n",
            "----------------------------------------\n",
            "Epoch 401\n",
            "Var loss:  tensor(5.7117e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8992425019596346e-06\n",
            "E_s_wdiff_all_sq: 3.698782339621514e-07\n",
            "E_IS_SCOPE: -1.0310907302631664e-05\n",
            "E_IS_E_SCOPE: -9.012222295707965e-06\n",
            "Total Loss: 5.711732058350304e-08\n",
            "----------------------------------------\n",
            "Epoch 402\n",
            "Var loss:  tensor(5.6511e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.903375168422438e-06\n",
            "E_s_wdiff_all_sq: 3.7431849631479723e-07\n",
            "E_IS_SCOPE: -1.0311693879535486e-05\n",
            "E_IS_E_SCOPE: -9.012859653331763e-06\n",
            "Total Loss: 5.6511286133611004e-08\n",
            "----------------------------------------\n",
            "Epoch 403\n",
            "Var loss:  tensor(5.5912e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9068964534486692e-06\n",
            "E_s_wdiff_all_sq: 3.7841254345400153e-07\n",
            "E_IS_SCOPE: -1.0310228319411227e-05\n",
            "E_IS_E_SCOPE: -9.01138063858352e-06\n",
            "Total Loss: 5.591161477266701e-08\n",
            "----------------------------------------\n",
            "Epoch 404\n",
            "Var loss:  tensor(5.5315e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9090275103618617e-06\n",
            "E_s_wdiff_all_sq: 3.810555537619144e-07\n",
            "E_IS_SCOPE: -1.0308605153245816e-05\n",
            "E_IS_E_SCOPE: -9.00971519963542e-06\n",
            "Total Loss: 5.531511581257126e-08\n",
            "----------------------------------------\n",
            "Epoch 405\n",
            "Var loss:  tensor(5.4695e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9097894419856842e-06\n",
            "E_s_wdiff_all_sq: 3.818784353735083e-07\n",
            "E_IS_SCOPE: -1.0308717363608888e-05\n",
            "E_IS_E_SCOPE: -9.009547759632338e-06\n",
            "Total Loss: 5.469486509249143e-08\n",
            "----------------------------------------\n",
            "Epoch 406\n",
            "Var loss:  tensor(5.4094e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9095886597959903e-06\n",
            "E_s_wdiff_all_sq: 3.8175170597980735e-07\n",
            "E_IS_SCOPE: -1.0306582002584975e-05\n",
            "E_IS_E_SCOPE: -9.007148817107538e-06\n",
            "Total Loss: 5.4093649294724934e-08\n",
            "----------------------------------------\n",
            "Epoch 407\n",
            "Var loss:  tensor(5.3500e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9106805315814025e-06\n",
            "E_s_wdiff_all_sq: 3.8295038058861307e-07\n",
            "E_IS_SCOPE: -1.0306421080388691e-05\n",
            "E_IS_E_SCOPE: -9.00674427756139e-06\n",
            "Total Loss: 5.349961177160531e-08\n",
            "----------------------------------------\n",
            "Epoch 408\n",
            "Var loss:  tensor(5.2899e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9124749859369774e-06\n",
            "E_s_wdiff_all_sq: 3.8538953250880145e-07\n",
            "E_IS_SCOPE: -1.0305837511398478e-05\n",
            "E_IS_E_SCOPE: -9.006182886934876e-06\n",
            "Total Loss: 5.2899270934386346e-08\n",
            "----------------------------------------\n",
            "Epoch 409\n",
            "Var loss:  tensor(5.2288e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.916742737206139e-06\n",
            "E_s_wdiff_all_sq: 3.899225905310482e-07\n",
            "E_IS_SCOPE: -1.0308637794441105e-05\n",
            "E_IS_E_SCOPE: -9.008810123198848e-06\n",
            "Total Loss: 5.228787062399303e-08\n",
            "----------------------------------------\n",
            "Epoch 410\n",
            "Var loss:  tensor(5.1689e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.921960955053436e-06\n",
            "E_s_wdiff_all_sq: 3.953565836214308e-07\n",
            "E_IS_SCOPE: -1.0312402731527401e-05\n",
            "E_IS_E_SCOPE: -9.01238374838736e-06\n",
            "Total Loss: 5.168947158534095e-08\n",
            "----------------------------------------\n",
            "Epoch 411\n",
            "Var loss:  tensor(5.1088e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9263836476506966e-06\n",
            "E_s_wdiff_all_sq: 4.001696409414085e-07\n",
            "E_IS_SCOPE: -1.0315468640460884e-05\n",
            "E_IS_E_SCOPE: -9.015343983908966e-06\n",
            "Total Loss: 5.108776003886853e-08\n",
            "----------------------------------------\n",
            "Epoch 412\n",
            "Var loss:  tensor(5.0496e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.928243872312046e-06\n",
            "E_s_wdiff_all_sq: 4.026839433969053e-07\n",
            "E_IS_SCOPE: -1.0315367066493988e-05\n",
            "E_IS_E_SCOPE: -9.015273516281268e-06\n",
            "Total Loss: 5.0495894923119075e-08\n",
            "----------------------------------------\n",
            "Epoch 413\n",
            "Var loss:  tensor(4.9893e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.928279119808373e-06\n",
            "E_s_wdiff_all_sq: 4.0316330998112404e-07\n",
            "E_IS_SCOPE: -1.031276202353378e-05\n",
            "E_IS_E_SCOPE: -9.012589329517008e-06\n",
            "Total Loss: 4.9893488227120005e-08\n",
            "----------------------------------------\n",
            "Epoch 414\n",
            "Var loss:  tensor(4.9287e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9286787303341227e-06\n",
            "E_s_wdiff_all_sq: 4.035944525186352e-07\n",
            "E_IS_SCOPE: -1.0312871556318868e-05\n",
            "E_IS_E_SCOPE: -9.012411584664777e-06\n",
            "Total Loss: 4.928740094072229e-08\n",
            "----------------------------------------\n",
            "Epoch 415\n",
            "Var loss:  tensor(4.8683e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9277680282338125e-06\n",
            "E_s_wdiff_all_sq: 4.029852566040519e-07\n",
            "E_IS_SCOPE: -1.0311963799916697e-05\n",
            "E_IS_E_SCOPE: -9.01135224469221e-06\n",
            "Total Loss: 4.868272761420326e-08\n",
            "----------------------------------------\n",
            "Epoch 416\n",
            "Var loss:  tensor(4.8088e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.925455778907526e-06\n",
            "E_s_wdiff_all_sq: 4.011546046490546e-07\n",
            "E_IS_SCOPE: -1.030914507920772e-05\n",
            "E_IS_E_SCOPE: -9.008477149483244e-06\n",
            "Total Loss: 4.808838124293403e-08\n",
            "----------------------------------------\n",
            "Epoch 417\n",
            "Var loss:  tensor(4.7484e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9259531111147583e-06\n",
            "E_s_wdiff_all_sq: 4.0177157110714343e-07\n",
            "E_IS_SCOPE: -1.0302810841748247e-05\n",
            "E_IS_E_SCOPE: -9.001900469608946e-06\n",
            "Total Loss: 4.748386216242956e-08\n",
            "----------------------------------------\n",
            "Epoch 418\n",
            "Var loss:  tensor(4.6893e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.930656330309447e-06\n",
            "E_s_wdiff_all_sq: 4.0642532623652443e-07\n",
            "E_IS_SCOPE: -1.0296972168748347e-05\n",
            "E_IS_E_SCOPE: -8.995741575516742e-06\n",
            "Total Loss: 4.6892884043128745e-08\n",
            "----------------------------------------\n",
            "Epoch 419\n",
            "Var loss:  tensor(4.6310e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9371871025886784e-06\n",
            "E_s_wdiff_all_sq: 4.133183968838577e-07\n",
            "E_IS_SCOPE: -1.0294429272677638e-05\n",
            "E_IS_E_SCOPE: -8.993088372611993e-06\n",
            "Total Loss: 4.6309972006947576e-08\n",
            "----------------------------------------\n",
            "Epoch 420\n",
            "Var loss:  tensor(4.5700e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9423607590056343e-06\n",
            "E_s_wdiff_all_sq: 4.1892784958815415e-07\n",
            "E_IS_SCOPE: -1.0290417381247346e-05\n",
            "E_IS_E_SCOPE: -8.988989385913393e-06\n",
            "Total Loss: 4.569998518298775e-08\n",
            "----------------------------------------\n",
            "Epoch 421\n",
            "Var loss:  tensor(4.5103e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9452350853392965e-06\n",
            "E_s_wdiff_all_sq: 4.22396313785321e-07\n",
            "E_IS_SCOPE: -1.0285999651299317e-05\n",
            "E_IS_E_SCOPE: -8.984570377647036e-06\n",
            "Total Loss: 4.510329068283076e-08\n",
            "----------------------------------------\n",
            "Epoch 422\n",
            "Var loss:  tensor(4.4529e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9471939934897836e-06\n",
            "E_s_wdiff_all_sq: 4.247724661096949e-07\n",
            "E_IS_SCOPE: -1.0289086262470626e-05\n",
            "E_IS_E_SCOPE: -8.987578519233446e-06\n",
            "Total Loss: 4.452910733914403e-08\n",
            "----------------------------------------\n",
            "Epoch 423\n",
            "Var loss:  tensor(4.3930e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.947574658466445e-06\n",
            "E_s_wdiff_all_sq: 4.2558459641404884e-07\n",
            "E_IS_SCOPE: -1.0294991997778182e-05\n",
            "E_IS_E_SCOPE: -8.99340032609152e-06\n",
            "Total Loss: 4.392978511248535e-08\n",
            "----------------------------------------\n",
            "Epoch 424\n",
            "Var loss:  tensor(4.3359e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9479600237661343e-06\n",
            "E_s_wdiff_all_sq: 4.2597404088463045e-07\n",
            "E_IS_SCOPE: -1.0300030910587423e-05\n",
            "E_IS_E_SCOPE: -8.998156013432985e-06\n",
            "Total Loss: 4.335925500604425e-08\n",
            "----------------------------------------\n",
            "Epoch 425\n",
            "Var loss:  tensor(4.2790e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.947921239678948e-06\n",
            "E_s_wdiff_all_sq: 4.254612447949879e-07\n",
            "E_IS_SCOPE: -1.0302317154034801e-05\n",
            "E_IS_E_SCOPE: -8.999920495019092e-06\n",
            "Total Loss: 4.2789743285956995e-08\n",
            "----------------------------------------\n",
            "Epoch 426\n",
            "Var loss:  tensor(4.2206e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.94530247543964e-06\n",
            "E_s_wdiff_all_sq: 4.229146323097299e-07\n",
            "E_IS_SCOPE: -1.030173416437278e-05\n",
            "E_IS_E_SCOPE: -8.999081864077862e-06\n",
            "Total Loss: 4.220630897348957e-08\n",
            "----------------------------------------\n",
            "Epoch 427\n",
            "Var loss:  tensor(4.1624e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9401216619518816e-06\n",
            "E_s_wdiff_all_sq: 4.1866445602970125e-07\n",
            "E_IS_SCOPE: -1.0297414168841731e-05\n",
            "E_IS_E_SCOPE: -8.994936224371753e-06\n",
            "Total Loss: 4.162438341564022e-08\n",
            "----------------------------------------\n",
            "Epoch 428\n",
            "Var loss:  tensor(4.1048e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9388431987567555e-06\n",
            "E_s_wdiff_all_sq: 4.175990908218464e-07\n",
            "E_IS_SCOPE: -1.0295132022411679e-05\n",
            "E_IS_E_SCOPE: -8.992472580103146e-06\n",
            "Total Loss: 4.104828975125745e-08\n",
            "----------------------------------------\n",
            "Epoch 429\n",
            "Var loss:  tensor(4.0468e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.941982110452639e-06\n",
            "E_s_wdiff_all_sq: 4.2051051540512925e-07\n",
            "E_IS_SCOPE: -1.029263201829579e-05\n",
            "E_IS_E_SCOPE: -8.98956871717617e-06\n",
            "Total Loss: 4.0468059241684484e-08\n",
            "----------------------------------------\n",
            "Epoch 430\n",
            "Var loss:  tensor(3.9898e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9471119902807254e-06\n",
            "E_s_wdiff_all_sq: 4.2625371780903963e-07\n",
            "E_IS_SCOPE: -1.0288374890701507e-05\n",
            "E_IS_E_SCOPE: -8.985333177324015e-06\n",
            "Total Loss: 3.989791215011724e-08\n",
            "----------------------------------------\n",
            "Epoch 431\n",
            "Var loss:  tensor(3.9337e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.954560415571042e-06\n",
            "E_s_wdiff_all_sq: 4.339844567023788e-07\n",
            "E_IS_SCOPE: -1.0287451916620904e-05\n",
            "E_IS_E_SCOPE: -8.984270753892916e-06\n",
            "Total Loss: 3.9336699846103246e-08\n",
            "----------------------------------------\n",
            "Epoch 432\n",
            "Var loss:  tensor(3.8773e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9622411521689833e-06\n",
            "E_s_wdiff_all_sq: 4.4200240313091826e-07\n",
            "E_IS_SCOPE: -1.0285787726604281e-05\n",
            "E_IS_E_SCOPE: -8.982493069529045e-06\n",
            "Total Loss: 3.877250132100615e-08\n",
            "----------------------------------------\n",
            "Epoch 433\n",
            "Var loss:  tensor(3.8202e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9685726572620084e-06\n",
            "E_s_wdiff_all_sq: 4.490687293141164e-07\n",
            "E_IS_SCOPE: -1.028333315974993e-05\n",
            "E_IS_E_SCOPE: -8.980120613142e-06\n",
            "Total Loss: 3.820190116544822e-08\n",
            "----------------------------------------\n",
            "Epoch 434\n",
            "Var loss:  tensor(3.7642e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9726499148576263e-06\n",
            "E_s_wdiff_all_sq: 4.539485898120544e-07\n",
            "E_IS_SCOPE: -1.0282220308088313e-05\n",
            "E_IS_E_SCOPE: -8.979129358468066e-06\n",
            "Total Loss: 3.76424922384916e-08\n",
            "----------------------------------------\n",
            "Epoch 435\n",
            "Var loss:  tensor(3.7086e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.975743583839813e-06\n",
            "E_s_wdiff_all_sq: 4.5713783269794133e-07\n",
            "E_IS_SCOPE: -1.0285969785079868e-05\n",
            "E_IS_E_SCOPE: -8.98264828801081e-06\n",
            "Total Loss: 3.7085823437170286e-08\n",
            "----------------------------------------\n",
            "Epoch 436\n",
            "Var loss:  tensor(3.6525e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9757471303206706e-06\n",
            "E_s_wdiff_all_sq: 4.5706293198430473e-07\n",
            "E_IS_SCOPE: -1.029230595366593e-05\n",
            "E_IS_E_SCOPE: -8.988664774185958e-06\n",
            "Total Loss: 3.652490580983657e-08\n",
            "----------------------------------------\n",
            "Epoch 437\n",
            "Var loss:  tensor(3.5968e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9716167161454974e-06\n",
            "E_s_wdiff_all_sq: 4.533516761518446e-07\n",
            "E_IS_SCOPE: -1.0297272931334995e-05\n",
            "E_IS_E_SCOPE: -8.993562889114314e-06\n",
            "Total Loss: 3.596802198570827e-08\n",
            "----------------------------------------\n",
            "Epoch 438\n",
            "Var loss:  tensor(3.5410e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9667405396391795e-06\n",
            "E_s_wdiff_all_sq: 4.490371122098463e-07\n",
            "E_IS_SCOPE: -1.029872891911679e-05\n",
            "E_IS_E_SCOPE: -8.9950207235799e-06\n",
            "Total Loss: 3.541010278896939e-08\n",
            "----------------------------------------\n",
            "Epoch 439\n",
            "Var loss:  tensor(3.4848e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9658863268248642e-06\n",
            "E_s_wdiff_all_sq: 4.4828732170732727e-07\n",
            "E_IS_SCOPE: -1.0300728832402589e-05\n",
            "E_IS_E_SCOPE: -8.996791687024787e-06\n",
            "Total Loss: 3.484778079534966e-08\n",
            "----------------------------------------\n",
            "Epoch 440\n",
            "Var loss:  tensor(3.4293e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9685372005665407e-06\n",
            "E_s_wdiff_all_sq: 4.506852260804692e-07\n",
            "E_IS_SCOPE: -1.030413098421614e-05\n",
            "E_IS_E_SCOPE: -8.999789796555668e-06\n",
            "Total Loss: 3.429266559854117e-08\n",
            "----------------------------------------\n",
            "Epoch 441\n",
            "Var loss:  tensor(3.3741e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.967275125692619e-06\n",
            "E_s_wdiff_all_sq: 4.504043240216321e-07\n",
            "E_IS_SCOPE: -1.0299167883881777e-05\n",
            "E_IS_E_SCOPE: -8.995041237554212e-06\n",
            "Total Loss: 3.3740575449273e-08\n",
            "----------------------------------------\n",
            "Epoch 442\n",
            "Var loss:  tensor(3.3191e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9673300299335046e-06\n",
            "E_s_wdiff_all_sq: 4.50968007791106e-07\n",
            "E_IS_SCOPE: -1.0296486394932122e-05\n",
            "E_IS_E_SCOPE: -8.992339345408752e-06\n",
            "Total Loss: 3.3190989529073914e-08\n",
            "----------------------------------------\n",
            "Epoch 443\n",
            "Var loss:  tensor(3.2646e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.971708487182637e-06\n",
            "E_s_wdiff_all_sq: 4.5504771166667184e-07\n",
            "E_IS_SCOPE: -1.0299287893714963e-05\n",
            "E_IS_E_SCOPE: -8.994718758509122e-06\n",
            "Total Loss: 3.264557153769931e-08\n",
            "----------------------------------------\n",
            "Epoch 444\n",
            "Var loss:  tensor(3.2085e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.975958718338566e-06\n",
            "E_s_wdiff_all_sq: 4.592709909401639e-07\n",
            "E_IS_SCOPE: -1.0303370209107688e-05\n",
            "E_IS_E_SCOPE: -8.998507479317703e-06\n",
            "Total Loss: 3.2085334251847386e-08\n",
            "----------------------------------------\n",
            "Epoch 445\n",
            "Var loss:  tensor(3.1549e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9783750632307583e-06\n",
            "E_s_wdiff_all_sq: 4.6228985319246573e-07\n",
            "E_IS_SCOPE: -1.0301947276556897e-05\n",
            "E_IS_E_SCOPE: -8.997117435776314e-06\n",
            "Total Loss: 3.1548594910541065e-08\n",
            "----------------------------------------\n",
            "Epoch 446\n",
            "Var loss:  tensor(3.1004e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.979640589823085e-06\n",
            "E_s_wdiff_all_sq: 4.6378258893867996e-07\n",
            "E_IS_SCOPE: -1.0299063776970112e-05\n",
            "E_IS_E_SCOPE: -8.994075409726573e-06\n",
            "Total Loss: 3.1004332830741265e-08\n",
            "----------------------------------------\n",
            "Epoch 447\n",
            "Var loss:  tensor(3.0451e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9789138135608665e-06\n",
            "E_s_wdiff_all_sq: 4.632855400394444e-07\n",
            "E_IS_SCOPE: -1.0295340625861947e-05\n",
            "E_IS_E_SCOPE: -8.990190232283805e-06\n",
            "Total Loss: 3.045055279855164e-08\n",
            "----------------------------------------\n",
            "Epoch 448\n",
            "Var loss:  tensor(2.9913e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9750544455106806e-06\n",
            "E_s_wdiff_all_sq: 4.6057671334858063e-07\n",
            "E_IS_SCOPE: -1.0290084810830747e-05\n",
            "E_IS_E_SCOPE: -8.985240843047508e-06\n",
            "Total Loss: 2.9912863029036915e-08\n",
            "----------------------------------------\n",
            "Epoch 449\n",
            "Var loss:  tensor(2.9367e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.974880816956654e-06\n",
            "E_s_wdiff_all_sq: 4.608332820575906e-07\n",
            "E_IS_SCOPE: -1.0290867242869428e-05\n",
            "E_IS_E_SCOPE: -8.985965647594675e-06\n",
            "Total Loss: 2.9367410782973942e-08\n",
            "----------------------------------------\n",
            "Epoch 450\n",
            "Var loss:  tensor(2.8822e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9801333808803957e-06\n",
            "E_s_wdiff_all_sq: 4.655344720903491e-07\n",
            "E_IS_SCOPE: -1.0294914512798929e-05\n",
            "E_IS_E_SCOPE: -8.989464480203053e-06\n",
            "Total Loss: 2.882191003171197e-08\n",
            "----------------------------------------\n",
            "Epoch 451\n",
            "Var loss:  tensor(2.8284e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.982815472153122e-06\n",
            "E_s_wdiff_all_sq: 4.683797620209274e-07\n",
            "E_IS_SCOPE: -1.0295163194026595e-05\n",
            "E_IS_E_SCOPE: -8.989526020200222e-06\n",
            "Total Loss: 2.8284428912865203e-08\n",
            "----------------------------------------\n",
            "Epoch 452\n",
            "Var loss:  tensor(2.7740e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9823941336797825e-06\n",
            "E_s_wdiff_all_sq: 4.6915035507205683e-07\n",
            "E_IS_SCOPE: -1.0290395715213404e-05\n",
            "E_IS_E_SCOPE: -8.985082200798287e-06\n",
            "Total Loss: 2.7739816210904987e-08\n",
            "----------------------------------------\n",
            "Epoch 453\n",
            "Var loss:  tensor(2.7204e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9836686399468414e-06\n",
            "E_s_wdiff_all_sq: 4.7096921868742543e-07\n",
            "E_IS_SCOPE: -1.0288014591082486e-05\n",
            "E_IS_E_SCOPE: -8.9827054548465e-06\n",
            "Total Loss: 2.720421522085587e-08\n",
            "----------------------------------------\n",
            "Epoch 454\n",
            "Var loss:  tensor(2.6660e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.98827204289551e-06\n",
            "E_s_wdiff_all_sq: 4.7502999380114606e-07\n",
            "E_IS_SCOPE: -1.028764712693516e-05\n",
            "E_IS_E_SCOPE: -8.981794516470897e-06\n",
            "Total Loss: 2.6659894599252716e-08\n",
            "----------------------------------------\n",
            "Epoch 455\n",
            "Var loss:  tensor(2.6126e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9904602106515353e-06\n",
            "E_s_wdiff_all_sq: 4.771517346678013e-07\n",
            "E_IS_SCOPE: -1.028731356273192e-05\n",
            "E_IS_E_SCOPE: -8.981160915145488e-06\n",
            "Total Loss: 2.6126247244283324e-08\n",
            "----------------------------------------\n",
            "Epoch 456\n",
            "Var loss:  tensor(2.5589e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9876724712908743e-06\n",
            "E_s_wdiff_all_sq: 4.753837819776823e-07\n",
            "E_IS_SCOPE: -1.0284261785265774e-05\n",
            "E_IS_E_SCOPE: -8.978350454765674e-06\n",
            "Total Loss: 2.55890947464066e-08\n",
            "----------------------------------------\n",
            "Epoch 457\n",
            "Var loss:  tensor(2.5052e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.987519936935822e-06\n",
            "E_s_wdiff_all_sq: 4.753993171853836e-07\n",
            "E_IS_SCOPE: -1.028616789807712e-05\n",
            "E_IS_E_SCOPE: -8.980072237445806e-06\n",
            "Total Loss: 2.5052364921225227e-08\n",
            "----------------------------------------\n",
            "Epoch 458\n",
            "Var loss:  tensor(2.4525e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9890061147548036e-06\n",
            "E_s_wdiff_all_sq: 4.761384972290951e-07\n",
            "E_IS_SCOPE: -1.0292939354488937e-05\n",
            "E_IS_E_SCOPE: -8.986206490108061e-06\n",
            "Total Loss: 2.4524955197370838e-08\n",
            "----------------------------------------\n",
            "Epoch 459\n",
            "Var loss:  tensor(2.3984e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9859373187723843e-06\n",
            "E_s_wdiff_all_sq: 4.7415411311995065e-07\n",
            "E_IS_SCOPE: -1.028793910740668e-05\n",
            "E_IS_E_SCOPE: -8.98147812894845e-06\n",
            "Total Loss: 2.398431516939284e-08\n",
            "----------------------------------------\n",
            "Epoch 460\n",
            "Var loss:  tensor(2.3457e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.984895474743378e-06\n",
            "E_s_wdiff_all_sq: 4.7395057700158714e-07\n",
            "E_IS_SCOPE: -1.0284254263461434e-05\n",
            "E_IS_E_SCOPE: -8.977948825960277e-06\n",
            "Total Loss: 2.3457089172890808e-08\n",
            "----------------------------------------\n",
            "Epoch 461\n",
            "Var loss:  tensor(2.2930e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.989949091633991e-06\n",
            "E_s_wdiff_all_sq: 4.782974582663617e-07\n",
            "E_IS_SCOPE: -1.0284117899632877e-05\n",
            "E_IS_E_SCOPE: -8.977195746053177e-06\n",
            "Total Loss: 2.293039264164445e-08\n",
            "----------------------------------------\n",
            "Epoch 462\n",
            "Var loss:  tensor(2.2394e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9938142547301895e-06\n",
            "E_s_wdiff_all_sq: 4.830442677321873e-07\n",
            "E_IS_SCOPE: -1.0281112612798635e-05\n",
            "E_IS_E_SCOPE: -8.974362879895768e-06\n",
            "Total Loss: 2.2393587625682505e-08\n",
            "----------------------------------------\n",
            "Epoch 463\n",
            "Var loss:  tensor(2.1870e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9953250693956728e-06\n",
            "E_s_wdiff_all_sq: 4.859716830305691e-07\n",
            "E_IS_SCOPE: -1.0278185299983794e-05\n",
            "E_IS_E_SCOPE: -8.971881965660985e-06\n",
            "Total Loss: 2.1869784152900174e-08\n",
            "----------------------------------------\n",
            "Epoch 464\n",
            "Var loss:  tensor(2.1344e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.003164335266507e-06\n",
            "E_s_wdiff_all_sq: 4.931387667050078e-07\n",
            "E_IS_SCOPE: -1.0283250412551368e-05\n",
            "E_IS_E_SCOPE: -8.976348075778355e-06\n",
            "Total Loss: 2.1343961448888737e-08\n",
            "----------------------------------------\n",
            "Epoch 465\n",
            "Var loss:  tensor(2.0814e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.00596918495258e-06\n",
            "E_s_wdiff_all_sq: 4.952635587804395e-07\n",
            "E_IS_SCOPE: -1.0286195390715075e-05\n",
            "E_IS_E_SCOPE: -8.978688053113097e-06\n",
            "Total Loss: 2.0814017401600554e-08\n",
            "----------------------------------------\n",
            "Epoch 466\n",
            "Var loss:  tensor(2.0284e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9995584575920467e-06\n",
            "E_s_wdiff_all_sq: 4.903411498157026e-07\n",
            "E_IS_SCOPE: -1.0275274070393226e-05\n",
            "E_IS_E_SCOPE: -8.968245836771698e-06\n",
            "Total Loss: 2.0283906966706e-08\n",
            "----------------------------------------\n",
            "Epoch 467\n",
            "Var loss:  tensor(1.9758e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9959596161206824e-06\n",
            "E_s_wdiff_all_sq: 4.873287085325954e-07\n",
            "E_IS_SCOPE: -1.0270748177989506e-05\n",
            "E_IS_E_SCOPE: -8.963750194366115e-06\n",
            "Total Loss: 1.9758006774719977e-08\n",
            "----------------------------------------\n",
            "Epoch 468\n",
            "Var loss:  tensor(1.9230e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9985455291651874e-06\n",
            "E_s_wdiff_all_sq: 4.888012164532013e-07\n",
            "E_IS_SCOPE: -1.0275088649430562e-05\n",
            "E_IS_E_SCOPE: -8.967270113601776e-06\n",
            "Total Loss: 1.9230307487831258e-08\n",
            "----------------------------------------\n",
            "Epoch 469\n",
            "Var loss:  tensor(1.8714e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9984234763651494e-06\n",
            "E_s_wdiff_all_sq: 4.890398871504153e-07\n",
            "E_IS_SCOPE: -1.0274631358936603e-05\n",
            "E_IS_E_SCOPE: -8.966734901051235e-06\n",
            "Total Loss: 1.8713739877413158e-08\n",
            "----------------------------------------\n",
            "Epoch 470\n",
            "Var loss:  tensor(1.8188e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.995669330630659e-06\n",
            "E_s_wdiff_all_sq: 4.884849641922127e-07\n",
            "E_IS_SCOPE: -1.0268853852534552e-05\n",
            "E_IS_E_SCOPE: -8.961794348471656e-06\n",
            "Total Loss: 1.8188424746071312e-08\n",
            "----------------------------------------\n",
            "Epoch 471\n",
            "Var loss:  tensor(1.7654e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0009154834961565e-06\n",
            "E_s_wdiff_all_sq: 4.935294380987902e-07\n",
            "E_IS_SCOPE: -1.0270804474898572e-05\n",
            "E_IS_E_SCOPE: -8.96337667772767e-06\n",
            "Total Loss: 1.7653517488978252e-08\n",
            "----------------------------------------\n",
            "Epoch 472\n",
            "Var loss:  tensor(1.7130e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0106833652765395e-06\n",
            "E_s_wdiff_all_sq: 5.017487333839017e-07\n",
            "E_IS_SCOPE: -1.0281921310143514e-05\n",
            "E_IS_E_SCOPE: -8.973457569561061e-06\n",
            "Total Loss: 1.7130217161146577e-08\n",
            "----------------------------------------\n",
            "Epoch 473\n",
            "Var loss:  tensor(1.6605e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0089824588572434e-06\n",
            "E_s_wdiff_all_sq: 5.016492865707103e-07\n",
            "E_IS_SCOPE: -1.0278737323103787e-05\n",
            "E_IS_E_SCOPE: -8.970811548136593e-06\n",
            "Total Loss: 1.6604688785559573e-08\n",
            "----------------------------------------\n",
            "Epoch 474\n",
            "Var loss:  tensor(1.6084e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0070264155972893e-06\n",
            "E_s_wdiff_all_sq: 5.007549154991957e-07\n",
            "E_IS_SCOPE: -1.0272246898742075e-05\n",
            "E_IS_E_SCOPE: -8.964591637726033e-06\n",
            "Total Loss: 1.6084044499427647e-08\n",
            "----------------------------------------\n",
            "Epoch 475\n",
            "Var loss:  tensor(1.5556e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.012614379042489e-06\n",
            "E_s_wdiff_all_sq: 5.052714628275577e-07\n",
            "E_IS_SCOPE: -1.027195239757e-05\n",
            "E_IS_E_SCOPE: -8.96349746351898e-06\n",
            "Total Loss: 1.5556114546305388e-08\n",
            "----------------------------------------\n",
            "Epoch 476\n",
            "Var loss:  tensor(1.5031e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.013095232489268e-06\n",
            "E_s_wdiff_all_sq: 5.063400791984594e-07\n",
            "E_IS_SCOPE: -1.0270091308184446e-05\n",
            "E_IS_E_SCOPE: -8.961667628328162e-06\n",
            "Total Loss: 1.503086001165506e-08\n",
            "----------------------------------------\n",
            "Epoch 477\n",
            "Var loss:  tensor(1.4512e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0101912815628833e-06\n",
            "E_s_wdiff_all_sq: 5.042761565991641e-07\n",
            "E_IS_SCOPE: -1.026830339652073e-05\n",
            "E_IS_E_SCOPE: -8.960040412371295e-06\n",
            "Total Loss: 1.4512223098265357e-08\n",
            "----------------------------------------\n",
            "Epoch 478\n",
            "Var loss:  tensor(1.3997e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0084034273743267e-06\n",
            "E_s_wdiff_all_sq: 5.021976627636277e-07\n",
            "E_IS_SCOPE: -1.0267541684777306e-05\n",
            "E_IS_E_SCOPE: -8.958875817994713e-06\n",
            "Total Loss: 1.399709747892942e-08\n",
            "----------------------------------------\n",
            "Epoch 479\n",
            "Var loss:  tensor(1.3472e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.00511133658807e-06\n",
            "E_s_wdiff_all_sq: 4.990444905324619e-07\n",
            "E_IS_SCOPE: -1.0264668437748381e-05\n",
            "E_IS_E_SCOPE: -8.955809287950449e-06\n",
            "Total Loss: 1.347161289316056e-08\n",
            "----------------------------------------\n",
            "Epoch 480\n",
            "Var loss:  tensor(1.2957e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9995328352099963e-06\n",
            "E_s_wdiff_all_sq: 4.94920380580167e-07\n",
            "E_IS_SCOPE: -1.0259141565745345e-05\n",
            "E_IS_E_SCOPE: -8.950752446623513e-06\n",
            "Total Loss: 1.2957282819580681e-08\n",
            "----------------------------------------\n",
            "Epoch 481\n",
            "Var loss:  tensor(1.2438e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0043148972001274e-06\n",
            "E_s_wdiff_all_sq: 4.998115661188598e-07\n",
            "E_IS_SCOPE: -1.0260549988734314e-05\n",
            "E_IS_E_SCOPE: -8.951955932629254e-06\n",
            "Total Loss: 1.2438285304563134e-08\n",
            "----------------------------------------\n",
            "Epoch 482\n",
            "Var loss:  tensor(1.1928e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.017045923761808e-06\n",
            "E_s_wdiff_all_sq: 5.117629193993071e-07\n",
            "E_IS_SCOPE: -1.0264801530970467e-05\n",
            "E_IS_E_SCOPE: -8.95556260317696e-06\n",
            "Total Loss: 1.1928215208904065e-08\n",
            "----------------------------------------\n",
            "Epoch 483\n",
            "Var loss:  tensor(1.1407e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.022310496883602e-06\n",
            "E_s_wdiff_all_sq: 5.1807453639443e-07\n",
            "E_IS_SCOPE: -1.0263127367008421e-05\n",
            "E_IS_E_SCOPE: -8.954151553771795e-06\n",
            "Total Loss: 1.1407400449336221e-08\n",
            "----------------------------------------\n",
            "Epoch 484\n",
            "Var loss:  tensor(1.0893e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.022981893181914e-06\n",
            "E_s_wdiff_all_sq: 5.200435764492271e-07\n",
            "E_IS_SCOPE: -1.0261679164788244e-05\n",
            "E_IS_E_SCOPE: -8.95309509235394e-06\n",
            "Total Loss: 1.0893238297497883e-08\n",
            "----------------------------------------\n",
            "Epoch 485\n",
            "Var loss:  tensor(1.0363e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0252071081959425e-06\n",
            "E_s_wdiff_all_sq: 5.22072554799289e-07\n",
            "E_IS_SCOPE: -1.0264293230275965e-05\n",
            "E_IS_E_SCOPE: -8.955346017061737e-06\n",
            "Total Loss: 1.0363193401614356e-08\n",
            "----------------------------------------\n",
            "Epoch 486\n",
            "Var loss:  tensor(9.8518e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.024914653712312e-06\n",
            "E_s_wdiff_all_sq: 5.216232890060248e-07\n",
            "E_IS_SCOPE: -1.0265907213115858e-05\n",
            "E_IS_E_SCOPE: -8.956625919005472e-06\n",
            "Total Loss: 9.851842918931338e-09\n",
            "----------------------------------------\n",
            "Epoch 487\n",
            "Var loss:  tensor(9.3458e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.022858531667642e-06\n",
            "E_s_wdiff_all_sq: 5.203457590253743e-07\n",
            "E_IS_SCOPE: -1.0265113927732144e-05\n",
            "E_IS_E_SCOPE: -8.955968912106792e-06\n",
            "Total Loss: 9.34580782497589e-09\n",
            "----------------------------------------\n",
            "Epoch 488\n",
            "Var loss:  tensor(8.8433e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0267006036201575e-06\n",
            "E_s_wdiff_all_sq: 5.240024881718483e-07\n",
            "E_IS_SCOPE: -1.0265307938302357e-05\n",
            "E_IS_E_SCOPE: -8.955818984906495e-06\n",
            "Total Loss: 8.843275090000414e-09\n",
            "----------------------------------------\n",
            "Epoch 489\n",
            "Var loss:  tensor(8.3281e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0309187340696747e-06\n",
            "E_s_wdiff_all_sq: 5.27899398606759e-07\n",
            "E_IS_SCOPE: -1.0263623009476016e-05\n",
            "E_IS_E_SCOPE: -8.953715860084739e-06\n",
            "Total Loss: 8.32810311377693e-09\n",
            "----------------------------------------\n",
            "Epoch 490\n",
            "Var loss:  tensor(7.8280e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0281283746860327e-06\n",
            "E_s_wdiff_all_sq: 5.260273939485552e-07\n",
            "E_IS_SCOPE: -1.026008809391416e-05\n",
            "E_IS_E_SCOPE: -8.950390061989873e-06\n",
            "Total Loss: 7.82798332232031e-09\n",
            "----------------------------------------\n",
            "Epoch 491\n",
            "Var loss:  tensor(7.3177e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0227103279590094e-06\n",
            "E_s_wdiff_all_sq: 5.218185022823556e-07\n",
            "E_IS_SCOPE: -1.0256673059719374e-05\n",
            "E_IS_E_SCOPE: -8.947324450068174e-06\n",
            "Total Loss: 7.317672807668958e-09\n",
            "----------------------------------------\n",
            "Epoch 492\n",
            "Var loss:  tensor(6.8026e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.019462041337302e-06\n",
            "E_s_wdiff_all_sq: 5.181756571681855e-07\n",
            "E_IS_SCOPE: -1.0257478020974765e-05\n",
            "E_IS_E_SCOPE: -8.947674594732654e-06\n",
            "Total Loss: 6.802598118311215e-09\n",
            "----------------------------------------\n",
            "Epoch 493\n",
            "Var loss:  tensor(6.2937e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.017559307781662e-06\n",
            "E_s_wdiff_all_sq: 5.15767650089832e-07\n",
            "E_IS_SCOPE: -1.0259784859273294e-05\n",
            "E_IS_E_SCOPE: -8.949474326275213e-06\n",
            "Total Loss: 6.2936581290822296e-09\n",
            "----------------------------------------\n",
            "Epoch 494\n",
            "Var loss:  tensor(5.7918e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.015137596547622e-06\n",
            "E_s_wdiff_all_sq: 5.142496071136681e-07\n",
            "E_IS_SCOPE: -1.025826412532849e-05\n",
            "E_IS_E_SCOPE: -8.948154477142417e-06\n",
            "Total Loss: 5.791759495222871e-09\n",
            "----------------------------------------\n",
            "Epoch 495\n",
            "Var loss:  tensor(5.2869e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.018153880339629e-06\n",
            "E_s_wdiff_all_sq: 5.18282217484924e-07\n",
            "E_IS_SCOPE: -1.0253491659292948e-05\n",
            "E_IS_E_SCOPE: -8.943637756711987e-06\n",
            "Total Loss: 5.286924126199414e-09\n",
            "----------------------------------------\n",
            "Epoch 496\n",
            "Var loss:  tensor(4.7711e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0276998155701463e-06\n",
            "E_s_wdiff_all_sq: 5.273901922229109e-07\n",
            "E_IS_SCOPE: -1.0251325775400617e-05\n",
            "E_IS_E_SCOPE: -8.94099496396742e-06\n",
            "Total Loss: 4.7710669142541285e-09\n",
            "----------------------------------------\n",
            "Epoch 497\n",
            "Var loss:  tensor(4.2629e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0401389272714813e-06\n",
            "E_s_wdiff_all_sq: 5.397492775917084e-07\n",
            "E_IS_SCOPE: -1.0251847532007956e-05\n",
            "E_IS_E_SCOPE: -8.941222628017317e-06\n",
            "Total Loss: 4.26290813190995e-09\n",
            "----------------------------------------\n",
            "Epoch 498\n",
            "Var loss:  tensor(3.7534e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.046950732785681e-06\n",
            "E_s_wdiff_all_sq: 5.480995169849807e-07\n",
            "E_IS_SCOPE: -1.0251311878486663e-05\n",
            "E_IS_E_SCOPE: -8.941201447996694e-06\n",
            "Total Loss: 3.753421254179856e-09\n",
            "----------------------------------------\n",
            "Epoch 499\n",
            "Var loss:  tensor(3.2414e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.051876139884322e-06\n",
            "E_s_wdiff_all_sq: 5.528963214159742e-07\n",
            "E_IS_SCOPE: -1.0254595066316716e-05\n",
            "E_IS_E_SCOPE: -8.944164340235894e-06\n",
            "Total Loss: 3.2414327401195762e-09\n",
            "----------------------------------------\n",
            "Epoch 500\n",
            "Var loss:  tensor(2.7303e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0530651413587383e-06\n",
            "E_s_wdiff_all_sq: 5.533114186064268e-07\n",
            "E_IS_SCOPE: -1.0257403787613617e-05\n",
            "E_IS_E_SCOPE: -8.946330523549091e-06\n",
            "Total Loss: 2.7302610566741994e-09\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[-0.2101,  0.3801],\n",
            "        [ 0.7356, -0.4928],\n",
            "        [-0.0438, -0.4692],\n",
            "        [ 0.1624, -0.1203],\n",
            "        [-0.2191, -0.1823],\n",
            "        [-0.6192, -0.4586],\n",
            "        [ 0.4871,  0.4499],\n",
            "        [ 0.0730,  0.3805],\n",
            "        [-0.0262, -0.6044],\n",
            "        [-0.2140, -0.1630],\n",
            "        [-0.5518,  0.5047],\n",
            "        [ 0.6495, -0.4965],\n",
            "        [-0.6236, -0.0745],\n",
            "        [-0.0356,  0.3041],\n",
            "        [ 0.0052,  0.5972],\n",
            "        [-0.0604, -0.1989]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([-0.0844, -0.5681,  0.6441,  0.6516, -0.5922, -0.1688, -0.1012,  0.3523,\n",
            "        -0.0529,  0.7032,  0.4311,  0.7167,  0.5218, -0.4728,  0.1729,  0.0767],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[-0.0723,  0.0443, -0.2342,  0.2346,  0.2472, -0.1674, -0.2108,  0.2270,\n",
            "          0.2062, -0.2065, -0.0532,  0.0441, -0.1241,  0.0217,  0.0297,  0.2058],\n",
            "        [ 0.1407, -0.0838, -0.0309, -0.0524,  0.0307, -0.0390, -0.1469,  0.0782,\n",
            "         -0.1361,  0.3170, -0.2752, -0.2110, -0.1958, -0.0817, -0.2421,  0.2182],\n",
            "        [ 0.1490, -0.1923,  0.2114,  0.0494, -0.1272, -0.0874, -0.1222,  0.1429,\n",
            "          0.1397,  0.1364, -0.1316, -0.2463, -0.1448,  0.0281, -0.1215, -0.1329],\n",
            "        [ 0.1357, -0.1700, -0.1376, -0.0408, -0.2021, -0.0557,  0.0013, -0.0773,\n",
            "          0.2358,  0.1358, -0.1219,  0.0374,  0.0765,  0.2062,  0.0384, -0.2461],\n",
            "        [-0.1683,  0.2549, -0.0666, -0.2172, -0.2492,  0.2069,  0.2020, -0.0604,\n",
            "         -0.0837, -0.1553,  0.1239,  0.0097, -0.1396,  0.1377, -0.1685, -0.0125],\n",
            "        [-0.0887, -0.1167, -0.2472,  0.2480,  0.1460, -0.1333,  0.0869, -0.0297,\n",
            "          0.1020,  0.2673,  0.0181, -0.1046, -0.1542, -0.1216, -0.0773, -0.0919],\n",
            "        [ 0.0961, -0.1260,  0.2149,  0.0128, -0.0109, -0.1642,  0.0273,  0.1218,\n",
            "          0.0393,  0.1113, -0.1200, -0.2115,  0.0602,  0.0367, -0.0153, -0.1823],\n",
            "        [ 0.0389, -0.0843,  0.0426,  0.0417, -0.1042, -0.0314,  0.0859,  0.0507,\n",
            "          0.0765, -0.1602, -0.1115,  0.1037,  0.1218, -0.0143, -0.0750, -0.0884],\n",
            "        [ 0.0089,  0.4062,  0.1052, -0.0295,  0.1986, -0.1902,  0.2464, -0.0310,\n",
            "          0.1342,  0.0531, -0.2306,  0.0636, -0.1858, -0.2073, -0.1100, -0.2053],\n",
            "        [-0.0116, -0.2301, -0.0819, -0.0763,  0.1273, -0.1310,  0.1043,  0.1762,\n",
            "          0.1718,  0.0573, -0.1396, -0.1208,  0.1038,  0.1016, -0.1340,  0.2209],\n",
            "        [ 0.1314, -0.3478, -0.1507,  0.0981,  0.0243,  0.2286,  0.1045, -0.0915,\n",
            "         -0.0558,  0.0997, -0.1871,  0.1925,  0.0995,  0.0429, -0.0423, -0.1166],\n",
            "        [ 0.0751, -0.0163,  0.1346,  0.0925, -0.2416,  0.0813, -0.2958, -0.0724,\n",
            "          0.0433,  0.2542,  0.1256, -0.2655,  0.0154,  0.0138, -0.0757, -0.1927],\n",
            "        [ 0.2209, -0.0048,  0.0346, -0.2223,  0.0038,  0.0669, -0.1826,  0.1822,\n",
            "          0.2285,  0.0287, -0.1796, -0.0091,  0.0505, -0.1555, -0.0848,  0.1192],\n",
            "        [-0.0816,  0.0704,  0.0109, -0.1508, -0.0177,  0.2430,  0.1335, -0.2067,\n",
            "          0.0896, -0.2968,  0.2249, -0.1285, -0.0861, -0.0375,  0.1871,  0.0676],\n",
            "        [-0.1169, -0.1662,  0.0133,  0.1843, -0.2427, -0.2037, -0.1257, -0.0658,\n",
            "         -0.0482,  0.1870, -0.1433,  0.1704,  0.2412,  0.2343, -0.1149,  0.2100],\n",
            "        [-0.0814, -0.0236, -0.1137, -0.1326, -0.1443,  0.1173,  0.1302, -0.0051,\n",
            "          0.1721, -0.1738,  0.0825, -0.0336,  0.0855, -0.0797,  0.0132,  0.1194],\n",
            "        [-0.2904,  0.1067, -0.2938, -0.1049, -0.1551,  0.0998,  0.1479,  0.1157,\n",
            "         -0.1763, -0.1254,  0.0138,  0.2312, -0.1980,  0.1132, -0.2773, -0.2279],\n",
            "        [-0.1073, -0.1993,  0.1531,  0.0594,  0.0292,  0.0082,  0.0678, -0.0263,\n",
            "         -0.2444, -0.0980,  0.0504, -0.1207,  0.2453, -0.2473,  0.2290, -0.1811],\n",
            "        [ 0.0217,  0.1852, -0.0128,  0.0377, -0.0341,  0.1431, -0.2219,  0.0861,\n",
            "         -0.0946,  0.0917,  0.0913,  0.1392,  0.1109, -0.3874, -0.0792, -0.0132],\n",
            "        [ 0.1445, -0.0582, -0.2403, -0.0522,  0.1757,  0.0614,  0.1480, -0.0291,\n",
            "         -0.1732, -0.2209,  0.1266, -0.1022, -0.1371, -0.2013,  0.0909, -0.0258],\n",
            "        [-0.1988, -0.2591, -0.1653, -0.2291,  0.0325,  0.1640, -0.2165, -0.1013,\n",
            "          0.0831, -0.0624, -0.1373,  0.0671, -0.2039,  0.0062,  0.0244,  0.2164],\n",
            "        [ 0.0578,  0.1973, -0.0365,  0.2350, -0.1320, -0.0176, -0.2484,  0.0699,\n",
            "          0.1687, -0.1458,  0.0152,  0.1684, -0.2164, -0.1875,  0.2008,  0.1275],\n",
            "        [-0.2907,  0.1481,  0.2162,  0.1830, -0.0871, -0.1800,  0.0038,  0.1564,\n",
            "         -0.2033,  0.2414,  0.0755,  0.0118,  0.1514, -0.2136, -0.1369,  0.0037],\n",
            "        [ 0.0123,  0.1065,  0.1411,  0.1744,  0.0520,  0.0412, -0.2828, -0.1565,\n",
            "          0.2441,  0.0524,  0.2814, -0.1340,  0.0186, -0.1726, -0.1644,  0.1237],\n",
            "        [ 0.0383,  0.3420,  0.2942,  0.1720, -0.0857,  0.2014, -0.1948, -0.1641,\n",
            "         -0.0152,  0.1601,  0.1854, -0.0968,  0.3323, -0.0686, -0.0844,  0.1973],\n",
            "        [-0.2468, -0.1675, -0.1414,  0.1380,  0.2404, -0.1686, -0.0242,  0.0605,\n",
            "         -0.2336, -0.0629,  0.0349, -0.3694, -0.0238, -0.1747, -0.0088,  0.1758],\n",
            "        [-0.0784,  0.0665, -0.2722,  0.0654, -0.0289, -0.1542,  0.1631,  0.0431,\n",
            "         -0.2163,  0.1303,  0.1347, -0.1966, -0.1760, -0.0225, -0.2000,  0.1045],\n",
            "        [-0.0615,  0.3851,  0.2880, -0.1568, -0.1623, -0.1406, -0.2765,  0.0808,\n",
            "          0.0429,  0.0209, -0.1395,  0.0537,  0.1785,  0.1555,  0.1116, -0.2451],\n",
            "        [-0.0438, -0.0040, -0.2408, -0.1435, -0.0551,  0.1013, -0.0878,  0.0008,\n",
            "          0.2385, -0.1580,  0.1218, -0.1817, -0.0245,  0.0712, -0.0395,  0.0799],\n",
            "        [-0.0294, -0.1168, -0.1768, -0.4298, -0.0596, -0.1157, -0.0414, -0.1549,\n",
            "          0.0198,  0.2689,  0.0352, -0.1089,  0.0212, -0.1252,  0.1863,  0.1202],\n",
            "        [-0.0183, -0.0076, -0.0205,  0.2282, -0.0270, -0.0412, -0.0038, -0.0265,\n",
            "         -0.0269, -0.1750, -0.0062,  0.1763,  0.0688,  0.1550, -0.0042,  0.1926],\n",
            "        [-0.1474, -0.0022, -0.0472,  0.1161,  0.0839, -0.0988, -0.0731, -0.1240,\n",
            "          0.1890,  0.1056, -0.0994, -0.6337, -0.0903, -0.0600,  0.0467,  0.2175]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([ 0.0023, -0.1293,  0.1437, -0.2342, -0.0009,  0.0433,  0.0330, -0.2351,\n",
            "         0.1822, -0.1495, -0.0861, -0.2659,  0.2627, -0.0961,  0.1377, -0.0565,\n",
            "         0.1741, -0.2573,  0.1343,  0.0675, -0.1959,  0.0510, -0.1727,  0.1640,\n",
            "         0.0957, -0.1765,  0.2066, -0.0127, -0.1928,  0.0063, -0.1169,  0.3009],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[-9.1361e-03, -8.1587e-03, -8.1484e-02,  8.3674e-03, -1.3339e-02,\n",
            "         -5.7281e-02, -1.1561e-02,  7.4972e-02, -5.4146e-03,  1.7219e-02,\n",
            "         -2.5101e-02, -7.5459e-02,  7.2642e-02, -2.3989e-03, -1.5589e-01,\n",
            "         -8.0905e-03, -1.3245e-02,  9.6031e-05, -5.5253e-02,  3.6214e-03,\n",
            "         -2.3125e-01,  6.9517e-04, -1.6196e-02,  8.6999e-02, -6.9840e-02,\n",
            "          1.2434e-01,  1.4296e-02, -7.9747e-03,  5.2897e-02, -8.6052e-03,\n",
            "          7.8192e-02, -2.6261e-01]], dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([0.0026], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model12 = train_var_play(model11, 500, 0.0001, padded_state_tensors, states_first_tensor, states_last_tensor, 1, 1, testing)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TpygwFvCGOLV",
        "outputId": "2a9bcaca-aaaf-4e96-94e9-9f10930c3f3e"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Var loss:  tensor(2.2263e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0454397267940005e-06\n",
            "E_s_wdiff_all_sq: 5.467628114465457e-07\n",
            "E_IS_SCOPE: -1.0254970373924974e-05\n",
            "E_IS_E_SCOPE: -8.944183529765734e-06\n",
            "Total Loss: 2.2262934623888673e-09\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "Var loss:  tensor(6.5306e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.65793187982493e-06\n",
            "E_s_wdiff_all_sq: 1.2877612576471057e-07\n",
            "E_IS_SCOPE: -9.075641433495659e-06\n",
            "E_IS_E_SCOPE: -7.781154824562122e-06\n",
            "Total Loss: 6.530560262656123e-08\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "Var loss:  tensor(1.9184e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 3.6306633195734738e-06\n",
            "E_s_wdiff_all_sq: 1.7726246188113302e-06\n",
            "E_IS_SCOPE: -1.1890450153615224e-05\n",
            "E_IS_E_SCOPE: -1.0494788465396067e-05\n",
            "Total Loss: 1.9183839075724527e-07\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "Var loss:  tensor(3.7999e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.4990283990365634e-06\n",
            "E_s_wdiff_all_sq: 9.370953803085665e-07\n",
            "E_IS_SCOPE: -1.079701560358715e-05\n",
            "E_IS_E_SCOPE: -9.472486973329307e-06\n",
            "Total Loss: 3.799882464572611e-08\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "Var loss:  tensor(4.2666e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6728484945990395e-06\n",
            "E_s_wdiff_all_sq: 2.4253645884522285e-07\n",
            "E_IS_SCOPE: -9.249256192303062e-06\n",
            "E_IS_E_SCOPE: -7.992871776672937e-06\n",
            "Total Loss: 4.2666270926984354e-08\n",
            "----------------------------------------\n",
            "Epoch 6\n",
            "Var loss:  tensor(1.0662e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.608193151590466e-06\n",
            "E_s_wdiff_all_sq: 1.2806360816480075e-07\n",
            "E_IS_SCOPE: -8.765931068606625e-06\n",
            "E_IS_E_SCOPE: -7.51661677239007e-06\n",
            "Total Loss: 1.066240174259725e-07\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "Var loss:  tensor(4.5669e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8056038189969946e-06\n",
            "E_s_wdiff_all_sq: 3.2133003772692877e-07\n",
            "E_IS_SCOPE: -9.370670709967898e-06\n",
            "E_IS_E_SCOPE: -8.088806824909606e-06\n",
            "Total Loss: 4.566907758689896e-08\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "Var loss:  tensor(8.1549e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.3477212622009084e-06\n",
            "E_s_wdiff_all_sq: 8.180333063325221e-07\n",
            "E_IS_SCOPE: -1.0408065671711388e-05\n",
            "E_IS_E_SCOPE: -9.084737627037868e-06\n",
            "Total Loss: 8.154932954762701e-09\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "Var loss:  tensor(4.8483e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.9482423854384237e-06\n",
            "E_s_wdiff_all_sq: 1.328140216626351e-06\n",
            "E_IS_SCOPE: -1.1202955715851152e-05\n",
            "E_IS_E_SCOPE: -9.854584417812217e-06\n",
            "Total Loss: 4.8482639167617086e-08\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "Var loss:  tensor(5.7106e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.99805086697032e-06\n",
            "E_s_wdiff_all_sq: 1.3731808895837784e-06\n",
            "E_IS_SCOPE: -1.1319287672495042e-05\n",
            "E_IS_E_SCOPE: -9.972843998552723e-06\n",
            "Total Loss: 5.710569593531947e-08\n",
            "----------------------------------------\n",
            "Epoch 11\n",
            "Var loss:  tensor(1.5587e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.532865144912458e-06\n",
            "E_s_wdiff_all_sq: 9.922791607161005e-07\n",
            "E_IS_SCOPE: -1.0836657340886324e-05\n",
            "E_IS_E_SCOPE: -9.511596541181188e-06\n",
            "Total Loss: 1.5587451219502673e-08\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "Var loss:  tensor(2.8988e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0223316178676115e-06\n",
            "E_s_wdiff_all_sq: 5.476404855329914e-07\n",
            "E_IS_SCOPE: -1.0103498458886906e-05\n",
            "E_IS_E_SCOPE: -8.805040765470641e-06\n",
            "Total Loss: 2.8988119355073726e-09\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "Var loss:  tensor(3.1376e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7574157726583948e-06\n",
            "E_s_wdiff_all_sq: 2.883126171883475e-07\n",
            "E_IS_SCOPE: -9.535296196954057e-06\n",
            "E_IS_E_SCOPE: -8.25387102207524e-06\n",
            "Total Loss: 3.1375872145828754e-08\n",
            "----------------------------------------\n",
            "Epoch 14\n",
            "Var loss:  tensor(3.8228e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7052472153957135e-06\n",
            "E_s_wdiff_all_sq: 2.2872666677047923e-07\n",
            "E_IS_SCOPE: -9.418262156012151e-06\n",
            "E_IS_E_SCOPE: -8.136554509896575e-06\n",
            "Total Loss: 3.822832282749832e-08\n",
            "----------------------------------------\n",
            "Epoch 15\n",
            "Var loss:  tensor(1.1918e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7913785855639713e-06\n",
            "E_s_wdiff_all_sq: 3.1137623828872424e-07\n",
            "E_IS_SCOPE: -9.73522999509544e-06\n",
            "E_IS_E_SCOPE: -8.43862629482213e-06\n",
            "Total Loss: 1.191801316204334e-08\n",
            "----------------------------------------\n",
            "Epoch 16\n",
            "Var loss:  tensor(-4.8566e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0036845900537093e-06\n",
            "E_s_wdiff_all_sq: 4.94979475248252e-07\n",
            "E_IS_SCOPE: -1.0256996658681559e-05\n",
            "E_IS_E_SCOPE: -8.939839736762956e-06\n",
            "Total Loss: -4.85662598332864e-10\n",
            "----------------------------------------\n",
            "Epoch 17\n",
            "Var loss:  tensor(1.5389e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.2290155307542045e-06\n",
            "E_s_wdiff_all_sq: 6.732558133721486e-07\n",
            "E_IS_SCOPE: -1.0683645186787486e-05\n",
            "E_IS_E_SCOPE: -9.350898132367572e-06\n",
            "Total Loss: 1.5388674975643242e-08\n",
            "----------------------------------------\n",
            "Epoch 18\n",
            "Var loss:  tensor(2.3111e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.274936542776133e-06\n",
            "E_s_wdiff_all_sq: 7.047807549844749e-07\n",
            "E_IS_SCOPE: -1.079232018614846e-05\n",
            "E_IS_E_SCOPE: -9.456236285494397e-06\n",
            "Total Loss: 2.3111052916951816e-08\n",
            "----------------------------------------\n",
            "Epoch 19\n",
            "Var loss:  tensor(7.9511e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.1049937209070637e-06\n",
            "E_s_wdiff_all_sq: 5.683517889969924e-07\n",
            "E_IS_SCOPE: -1.055909797818024e-05\n",
            "E_IS_E_SCOPE: -9.23219100822281e-06\n",
            "Total Loss: 7.951058428624494e-09\n",
            "----------------------------------------\n",
            "Epoch 20\n",
            "Var loss:  tensor(-2.4889e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8704765994039856e-06\n",
            "E_s_wdiff_all_sq: 3.761509426158727e-07\n",
            "E_IS_SCOPE: -1.0139025399839854e-05\n",
            "E_IS_E_SCOPE: -8.828056573225597e-06\n",
            "Total Loss: -2.4889300069854286e-09\n",
            "----------------------------------------\n",
            "Epoch 21\n",
            "Var loss:  tensor(6.7332e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7188875842519047e-06\n",
            "E_s_wdiff_all_sq: 2.43736449977665e-07\n",
            "E_IS_SCOPE: -9.770997087798155e-06\n",
            "E_IS_E_SCOPE: -8.47422661181701e-06\n",
            "Total Loss: 6.733248745365261e-09\n",
            "----------------------------------------\n",
            "Epoch 22\n",
            "Var loss:  tensor(1.4259e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.6828102960631392e-06\n",
            "E_s_wdiff_all_sq: 2.107352975635334e-07\n",
            "E_IS_SCOPE: -9.654894028161382e-06\n",
            "E_IS_E_SCOPE: -8.363424427472517e-06\n",
            "Total Loss: 1.4258863555291614e-08\n",
            "----------------------------------------\n",
            "Epoch 23\n",
            "Var loss:  tensor(5.5985e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.7499156544064517e-06\n",
            "E_s_wdiff_all_sq: 2.753077209570467e-07\n",
            "E_IS_SCOPE: -9.836817859364206e-06\n",
            "E_IS_E_SCOPE: -8.539751623021573e-06\n",
            "Total Loss: 5.598527197554554e-09\n",
            "----------------------------------------\n",
            "Epoch 24\n",
            "Var loss:  tensor(-3.0188e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9199213315060747e-06\n",
            "E_s_wdiff_all_sq: 4.282633078187896e-07\n",
            "E_IS_SCOPE: -1.0199640373845419e-05\n",
            "E_IS_E_SCOPE: -8.889740407281066e-06\n",
            "Total Loss: -3.01884300800533e-09\n",
            "----------------------------------------\n",
            "Epoch 25\n",
            "Var loss:  tensor(1.6337e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.1379403932650914e-06\n",
            "E_s_wdiff_all_sq: 6.151188678561323e-07\n",
            "E_IS_SCOPE: -1.054162539355591e-05\n",
            "E_IS_E_SCOPE: -9.21846992273857e-06\n",
            "Total Loss: 1.633650207696397e-09\n",
            "----------------------------------------\n",
            "Epoch 26\n",
            "Var loss:  tensor(7.2470e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.272737573357248e-06\n",
            "E_s_wdiff_all_sq: 7.305798163246795e-07\n",
            "E_IS_SCOPE: -1.0679218140984182e-05\n",
            "E_IS_E_SCOPE: -9.349201205240987e-06\n",
            "Total Loss: 7.246951979593888e-09\n",
            "----------------------------------------\n",
            "Epoch 27\n",
            "Var loss:  tensor(2.0994e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.244149197724913e-06\n",
            "E_s_wdiff_all_sq: 7.125754440284311e-07\n",
            "E_IS_SCOPE: -1.0552396077269611e-05\n",
            "E_IS_E_SCOPE: -9.225097376676322e-06\n",
            "Total Loss: 2.0994189433187347e-09\n",
            "----------------------------------------\n",
            "Epoch 28\n",
            "Var loss:  tensor(-4.1642e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.1072409416105232e-06\n",
            "E_s_wdiff_all_sq: 6.025610774163309e-07\n",
            "E_IS_SCOPE: -1.0245847636005125e-05\n",
            "E_IS_E_SCOPE: -8.928864093977677e-06\n",
            "Total Loss: -4.1641534272860706e-09\n",
            "----------------------------------------\n",
            "Epoch 29\n",
            "Var loss:  tensor(-1.4225e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.977730430989686e-06\n",
            "E_s_wdiff_all_sq: 4.947392966653689e-07\n",
            "E_IS_SCOPE: -9.933041141213564e-06\n",
            "E_IS_E_SCOPE: -8.628272815129899e-06\n",
            "Total Loss: -1.4224514095970944e-09\n",
            "----------------------------------------\n",
            "Epoch 30\n",
            "Var loss:  tensor(2.7102e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9293878724989144e-06\n",
            "E_s_wdiff_all_sq: 4.577848917958676e-07\n",
            "E_IS_SCOPE: -9.779328763147705e-06\n",
            "E_IS_E_SCOPE: -8.482320857905994e-06\n",
            "Total Loss: 2.7102366530397027e-09\n",
            "----------------------------------------\n",
            "Epoch 31\n",
            "Var loss:  tensor(-4.5556e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9831465700422948e-06\n",
            "E_s_wdiff_all_sq: 5.13713300620971e-07\n",
            "E_IS_SCOPE: -9.851801228994431e-06\n",
            "E_IS_E_SCOPE: -8.554295278679982e-06\n",
            "Total Loss: -4.555647741596266e-10\n",
            "----------------------------------------\n",
            "Epoch 32\n",
            "Var loss:  tensor(-4.7566e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.1268637121412923e-06\n",
            "E_s_wdiff_all_sq: 6.461666938826711e-07\n",
            "E_IS_SCOPE: -1.00877837794804e-05\n",
            "E_IS_E_SCOPE: -8.782495414164582e-06\n",
            "Total Loss: -4.756645939598935e-09\n",
            "----------------------------------------\n",
            "Epoch 33\n",
            "Var loss:  tensor(-3.1391e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.296936988863881e-06\n",
            "E_s_wdiff_all_sq: 7.94248319390156e-07\n",
            "E_IS_SCOPE: -1.0341415715436838e-05\n",
            "E_IS_E_SCOPE: -9.025940283370465e-06\n",
            "Total Loss: -3.139128225602964e-09\n",
            "----------------------------------------\n",
            "Epoch 34\n",
            "Var loss:  tensor(-7.9965e-10, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.388167147307035e-06\n",
            "E_s_wdiff_all_sq: 8.697817398213587e-07\n",
            "E_IS_SCOPE: -1.0471372414918928e-05\n",
            "E_IS_E_SCOPE: -9.149218353156198e-06\n",
            "Total Loss: -7.996496063676509e-10\n",
            "----------------------------------------\n",
            "Epoch 35\n",
            "Var loss:  tensor(-3.2679e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.3424686913632853e-06\n",
            "E_s_wdiff_all_sq: 8.272612205428611e-07\n",
            "E_IS_SCOPE: -1.0422966314532416e-05\n",
            "E_IS_E_SCOPE: -9.10116710545891e-06\n",
            "Total Loss: -3.2678808931710317e-09\n",
            "----------------------------------------\n",
            "Epoch 36\n",
            "Var loss:  tensor(-5.8994e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.2035525446867224e-06\n",
            "E_s_wdiff_all_sq: 7.041061742223488e-07\n",
            "E_IS_SCOPE: -1.0251540354566407e-05\n",
            "E_IS_E_SCOPE: -8.936305940591546e-06\n",
            "Total Loss: -5.899391051932471e-09\n",
            "----------------------------------------\n",
            "Epoch 37\n",
            "Var loss:  tensor(-4.3999e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.065288766853955e-06\n",
            "E_s_wdiff_all_sq: 5.809361454438431e-07\n",
            "E_IS_SCOPE: -1.0080679131466384e-05\n",
            "E_IS_E_SCOPE: -8.773741318620893e-06\n",
            "Total Loss: -4.399937847453072e-09\n",
            "----------------------------------------\n",
            "Epoch 38\n",
            "Var loss:  tensor(-3.0209e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.991715851293202e-06\n",
            "E_s_wdiff_all_sq: 5.15309182209182e-07\n",
            "E_IS_SCOPE: -1.002294481857319e-05\n",
            "E_IS_E_SCOPE: -8.720669496919584e-06\n",
            "Total Loss: -3.020907789773035e-09\n",
            "----------------------------------------\n",
            "Epoch 39\n",
            "Var loss:  tensor(-5.0437e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9970586119530063e-06\n",
            "E_s_wdiff_all_sq: 5.188513016666733e-07\n",
            "E_IS_SCOPE: -1.0110620654553642e-05\n",
            "E_IS_E_SCOPE: -8.806433618906716e-06\n",
            "Total Loss: -5.043694574100036e-09\n",
            "----------------------------------------\n",
            "Epoch 40\n",
            "Var loss:  tensor(-6.6662e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0569913583397095e-06\n",
            "E_s_wdiff_all_sq: 5.659813749117779e-07\n",
            "E_IS_SCOPE: -1.0279330213865076e-05\n",
            "E_IS_E_SCOPE: -8.967930591941114e-06\n",
            "Total Loss: -6.666193986576173e-09\n",
            "----------------------------------------\n",
            "Epoch 41\n",
            "Var loss:  tensor(-5.6267e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.1153510287362964e-06\n",
            "E_s_wdiff_all_sq: 6.073533886343014e-07\n",
            "E_IS_SCOPE: -1.0414883075742426e-05\n",
            "E_IS_E_SCOPE: -9.095509383179949e-06\n",
            "Total Loss: -5.626678589540541e-09\n",
            "----------------------------------------\n",
            "Epoch 42\n",
            "Var loss:  tensor(-5.2464e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.112886907952283e-06\n",
            "E_s_wdiff_all_sq: 5.969161359064466e-07\n",
            "E_IS_SCOPE: -1.042978523463228e-05\n",
            "E_IS_E_SCOPE: -9.106615110591327e-06\n",
            "Total Loss: -5.246409602655439e-09\n",
            "----------------------------------------\n",
            "Epoch 43\n",
            "Var loss:  tensor(-6.8132e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.039923866230653e-06\n",
            "E_s_wdiff_all_sq: 5.30574700159961e-07\n",
            "E_IS_SCOPE: -1.031689196804094e-05\n",
            "E_IS_E_SCOPE: -8.99624923568608e-06\n",
            "Total Loss: -6.813232205611442e-09\n",
            "----------------------------------------\n",
            "Epoch 44\n",
            "Var loss:  tensor(-7.3928e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.9441578551521687e-06\n",
            "E_s_wdiff_all_sq: 4.4916410118914387e-07\n",
            "E_IS_SCOPE: -1.0151281513607879e-05\n",
            "E_IS_E_SCOPE: -8.837526703431912e-06\n",
            "Total Loss: -7.392799955492662e-09\n",
            "----------------------------------------\n",
            "Epoch 45\n",
            "Var loss:  tensor(-6.5178e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.8821676349355666e-06\n",
            "E_s_wdiff_all_sq: 3.9936381639448614e-07\n",
            "E_IS_SCOPE: -1.0037807575901622e-05\n",
            "E_IS_E_SCOPE: -8.7305852292044e-06\n",
            "Total Loss: -6.517808419948901e-09\n",
            "----------------------------------------\n",
            "Epoch 46\n",
            "Var loss:  tensor(-6.7853e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.883060704527282e-06\n",
            "E_s_wdiff_all_sq: 4.0428624088720274e-07\n",
            "E_IS_SCOPE: -1.0041732370649016e-05\n",
            "E_IS_E_SCOPE: -8.736390935578567e-06\n",
            "Total Loss: -6.785340067401595e-09\n",
            "----------------------------------------\n",
            "Epoch 47\n",
            "Var loss:  tensor(-8.0597e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 1.94533537712362e-06\n",
            "E_s_wdiff_all_sq: 4.603580130029238e-07\n",
            "E_IS_SCOPE: -1.0149056124069345e-05\n",
            "E_IS_E_SCOPE: -8.83997607268987e-06\n",
            "Total Loss: -8.059672204838145e-09\n",
            "----------------------------------------\n",
            "Epoch 48\n",
            "Var loss:  tensor(-8.1724e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.036555760763813e-06\n",
            "E_s_wdiff_all_sq: 5.386882930020705e-07\n",
            "E_IS_SCOPE: -1.0281581526552437e-05\n",
            "E_IS_E_SCOPE: -8.966000075588007e-06\n",
            "Total Loss: -8.172367733702172e-09\n",
            "----------------------------------------\n",
            "Epoch 49\n",
            "Var loss:  tensor(-7.7063e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.1039205169944664e-06\n",
            "E_s_wdiff_all_sq: 5.96166041379565e-07\n",
            "E_IS_SCOPE: -1.0353639049823191e-05\n",
            "E_IS_E_SCOPE: -9.033347149177912e-06\n",
            "Total Loss: -7.70625924224273e-09\n",
            "----------------------------------------\n",
            "Epoch 50\n",
            "Var loss:  tensor(-8.2901e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.1115693399332563e-06\n",
            "E_s_wdiff_all_sq: 6.047857123156647e-07\n",
            "E_IS_SCOPE: -1.0327009954743108e-05\n",
            "E_IS_E_SCOPE: -9.006911578708541e-06\n",
            "Total Loss: -8.290058018125898e-09\n",
            "----------------------------------------\n",
            "Epoch 51\n",
            "Var loss:  tensor(-9.0166e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0730990201433454e-06\n",
            "E_s_wdiff_all_sq: 5.76369688901628e-07\n",
            "E_IS_SCOPE: -1.0234164964291299e-05\n",
            "E_IS_E_SCOPE: -8.918730486870515e-06\n",
            "Total Loss: -9.016557166433678e-09\n",
            "----------------------------------------\n",
            "Epoch 52\n",
            "Var loss:  tensor(-8.8202e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0333898849087516e-06\n",
            "E_s_wdiff_all_sq: 5.476780900266462e-07\n",
            "E_IS_SCOPE: -1.0148520386632672e-05\n",
            "E_IS_E_SCOPE: -8.83869284565458e-06\n",
            "Total Loss: -8.820220640663851e-09\n",
            "----------------------------------------\n",
            "Epoch 53\n",
            "Var loss:  tensor(-8.8394e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0303466839366845e-06\n",
            "E_s_wdiff_all_sq: 5.496380813985817e-07\n",
            "E_IS_SCOPE: -1.0131618277069346e-05\n",
            "E_IS_E_SCOPE: -8.824282723437756e-06\n",
            "Total Loss: -8.839438291661334e-09\n",
            "----------------------------------------\n",
            "Epoch 54\n",
            "Var loss:  tensor(-9.5629e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.071353188420848e-06\n",
            "E_s_wdiff_all_sq: 5.870432309364803e-07\n",
            "E_IS_SCOPE: -1.0189145134420258e-05\n",
            "E_IS_E_SCOPE: -8.879647174873827e-06\n",
            "Total Loss: -9.5628951750787e-09\n",
            "----------------------------------------\n",
            "Epoch 55\n",
            "Var loss:  tensor(-9.8628e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.1319225434191327e-06\n",
            "E_s_wdiff_all_sq: 6.380365940098327e-07\n",
            "E_IS_SCOPE: -1.0273122960965279e-05\n",
            "E_IS_E_SCOPE: -8.958687054734043e-06\n",
            "Total Loss: -9.862796619757214e-09\n",
            "----------------------------------------\n",
            "Epoch 56\n",
            "Var loss:  tensor(-9.6851e-09, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.1696649498068823e-06\n",
            "E_s_wdiff_all_sq: 6.677167580673232e-07\n",
            "E_IS_SCOPE: -1.0319913981473181e-05\n",
            "E_IS_E_SCOPE: -9.001535783660428e-06\n",
            "Total Loss: -9.68513745252954e-09\n",
            "----------------------------------------\n",
            "Epoch 57\n",
            "Var loss:  tensor(-1.0012e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.157701761166814e-06\n",
            "E_s_wdiff_all_sq: 6.557746591509468e-07\n",
            "E_IS_SCOPE: -1.0298095446149528e-05\n",
            "E_IS_E_SCOPE: -8.979564532562231e-06\n",
            "Total Loss: -1.0011658725310767e-08\n",
            "----------------------------------------\n",
            "Epoch 58\n",
            "Var loss:  tensor(-1.0537e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.1083444142817814e-06\n",
            "E_s_wdiff_all_sq: 6.137402800020223e-07\n",
            "E_IS_SCOPE: -1.0229141090254144e-05\n",
            "E_IS_E_SCOPE: -8.914008818664182e-06\n",
            "Total Loss: -1.0537342466748804e-08\n",
            "----------------------------------------\n",
            "Epoch 59\n",
            "Var loss:  tensor(-1.0580e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0588787535783285e-06\n",
            "E_s_wdiff_all_sq: 5.723536189983016e-07\n",
            "E_IS_SCOPE: -1.0168141237396644e-05\n",
            "E_IS_E_SCOPE: -8.857026995763894e-06\n",
            "Total Loss: -1.0580282252057838e-08\n",
            "----------------------------------------\n",
            "Epoch 60\n",
            "Var loss:  tensor(-1.0683e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0404932774222043e-06\n",
            "E_s_wdiff_all_sq: 5.568538343567911e-07\n",
            "E_IS_SCOPE: -1.0160223961351329e-05\n",
            "E_IS_E_SCOPE: -8.85050113647764e-06\n",
            "Total Loss: -1.0683140248548155e-08\n",
            "----------------------------------------\n",
            "Epoch 61\n",
            "Var loss:  tensor(-1.1170e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.058299025902971e-06\n",
            "E_s_wdiff_all_sq: 5.705509876058819e-07\n",
            "E_IS_SCOPE: -1.0209825847674995e-05\n",
            "E_IS_E_SCOPE: -8.897805118531843e-06\n",
            "Total Loss: -1.1170353555799432e-08\n",
            "----------------------------------------\n",
            "Epoch 62\n",
            "Var loss:  tensor(-1.1406e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0901270627097105e-06\n",
            "E_s_wdiff_all_sq: 5.946714261195164e-07\n",
            "E_IS_SCOPE: -1.0275634508564324e-05\n",
            "E_IS_E_SCOPE: -8.959642263040774e-06\n",
            "Total Loss: -1.1405788023489006e-08\n",
            "----------------------------------------\n",
            "Epoch 63\n",
            "Var loss:  tensor(-1.1426e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.1044643209911997e-06\n",
            "E_s_wdiff_all_sq: 6.038609792329203e-07\n",
            "E_IS_SCOPE: -1.030907090466257e-05\n",
            "E_IS_E_SCOPE: -8.990494736880702e-06\n",
            "Total Loss: -1.142592737204359e-08\n",
            "----------------------------------------\n",
            "Epoch 64\n",
            "Var loss:  tensor(-1.1745e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.085697139219106e-06\n",
            "E_s_wdiff_all_sq: 5.868093456695682e-07\n",
            "E_IS_SCOPE: -1.0288330525939115e-05\n",
            "E_IS_E_SCOPE: -8.970452580051253e-06\n",
            "Total Loss: -1.1745031792772768e-08\n",
            "----------------------------------------\n",
            "Epoch 65\n",
            "Var loss:  tensor(-1.2092e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.047154380205936e-06\n",
            "E_s_wdiff_all_sq: 5.549632068238898e-07\n",
            "E_IS_SCOPE: -1.0234604895454022e-05\n",
            "E_IS_E_SCOPE: -8.919902012283507e-06\n",
            "Total Loss: -1.209152652556809e-08\n",
            "----------------------------------------\n",
            "Epoch 66\n",
            "Var loss:  tensor(-1.2192e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.017162186569903e-06\n",
            "E_s_wdiff_all_sq: 5.310615526495849e-07\n",
            "E_IS_SCOPE: -1.019084382793026e-05\n",
            "E_IS_E_SCOPE: -8.87913575983426e-06\n",
            "Total Loss: -1.2192435838268324e-08\n",
            "----------------------------------------\n",
            "Epoch 67\n",
            "Var loss:  tensor(-1.2409e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0161724200981404e-06\n",
            "E_s_wdiff_all_sq: 5.312603184207926e-07\n",
            "E_IS_SCOPE: -1.018788869146272e-05\n",
            "E_IS_E_SCOPE: -8.87666664007372e-06\n",
            "Total Loss: -1.240893466723844e-08\n",
            "----------------------------------------\n",
            "Epoch 68\n",
            "Var loss:  tensor(-1.2773e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0428988421615277e-06\n",
            "E_s_wdiff_all_sq: 5.539229937661871e-07\n",
            "E_IS_SCOPE: -1.0222739984150881e-05\n",
            "E_IS_E_SCOPE: -8.909303854742165e-06\n",
            "Total Loss: -1.2773343988675469e-08\n",
            "----------------------------------------\n",
            "Epoch 69\n",
            "Var loss:  tensor(-1.2941e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.076200481918031e-06\n",
            "E_s_wdiff_all_sq: 5.815902528574173e-07\n",
            "E_IS_SCOPE: -1.0263462195842254e-05\n",
            "E_IS_E_SCOPE: -8.947125245419527e-06\n",
            "Total Loss: -1.2940605351425109e-08\n",
            "----------------------------------------\n",
            "Epoch 70\n",
            "Var loss:  tensor(-1.3090e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0915139289719753e-06\n",
            "E_s_wdiff_all_sq: 5.947428316835495e-07\n",
            "E_IS_SCOPE: -1.0274280079701651e-05\n",
            "E_IS_E_SCOPE: -8.956788238687128e-06\n",
            "Total Loss: -1.3089518307204045e-08\n",
            "----------------------------------------\n",
            "Epoch 71\n",
            "Var loss:  tensor(-1.3410e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.081608196225933e-06\n",
            "E_s_wdiff_all_sq: 5.878709593076894e-07\n",
            "E_IS_SCOPE: -1.0249122306728301e-05\n",
            "E_IS_E_SCOPE: -8.93298711846665e-06\n",
            "Total Loss: -1.3410073171642398e-08\n",
            "----------------------------------------\n",
            "Epoch 72\n",
            "Var loss:  tensor(-1.3650e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0618559211137135e-06\n",
            "E_s_wdiff_all_sq: 5.733219881087013e-07\n",
            "E_IS_SCOPE: -1.021148406058251e-05\n",
            "E_IS_E_SCOPE: -8.897830473701985e-06\n",
            "Total Loss: -1.365017432262253e-08\n",
            "----------------------------------------\n",
            "Epoch 73\n",
            "Var loss:  tensor(-1.3805e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0535637637923985e-06\n",
            "E_s_wdiff_all_sq: 5.679519160408657e-07\n",
            "E_IS_SCOPE: -1.0192157862549516e-05\n",
            "E_IS_E_SCOPE: -8.879887826466524e-06\n",
            "Total Loss: -1.3805157981037316e-08\n",
            "----------------------------------------\n",
            "Epoch 74\n",
            "Var loss:  tensor(-1.4072e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0663840449086025e-06\n",
            "E_s_wdiff_all_sq: 5.793946264130268e-07\n",
            "E_IS_SCOPE: -1.0204611607333337e-05\n",
            "E_IS_E_SCOPE: -8.891519487590294e-06\n",
            "Total Loss: -1.4071754557094975e-08\n",
            "----------------------------------------\n",
            "Epoch 75\n",
            "Var loss:  tensor(-1.4331e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0909028504966113e-06\n",
            "E_s_wdiff_all_sq: 5.998950380494457e-07\n",
            "E_IS_SCOPE: -1.0233972282377307e-05\n",
            "E_IS_E_SCOPE: -8.918741358588417e-06\n",
            "Total Loss: -1.4330968697198656e-08\n",
            "----------------------------------------\n",
            "Epoch 76\n",
            "Var loss:  tensor(-1.4510e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.109465215007962e-06\n",
            "E_s_wdiff_all_sq: 6.154703433585179e-07\n",
            "E_IS_SCOPE: -1.0253579130586587e-05\n",
            "E_IS_E_SCOPE: -8.936765289734745e-06\n",
            "Total Loss: -1.4509743620823597e-08\n",
            "----------------------------------------\n",
            "Epoch 77\n",
            "Var loss:  tensor(-1.4764e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.1087995336194855e-06\n",
            "E_s_wdiff_all_sq: 6.155301512283624e-07\n",
            "E_IS_SCOPE: -1.0246530105306173e-05\n",
            "E_IS_E_SCOPE: -8.929951883834188e-06\n",
            "Total Loss: -1.4763994119431213e-08\n",
            "----------------------------------------\n",
            "Epoch 78\n",
            "Var loss:  tensor(-1.5028e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.093237095393229e-06\n",
            "E_s_wdiff_all_sq: 6.034111063565782e-07\n",
            "E_IS_SCOPE: -1.0219937106723515e-05\n",
            "E_IS_E_SCOPE: -8.904948493532769e-06\n",
            "Total Loss: -1.5028170911426167e-08\n",
            "----------------------------------------\n",
            "Epoch 79\n",
            "Var loss:  tensor(-1.5221e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.078180154434319e-06\n",
            "E_s_wdiff_all_sq: 5.91307000361544e-07\n",
            "E_IS_SCOPE: -1.019520344627778e-05\n",
            "E_IS_E_SCOPE: -8.88159497871888e-06\n",
            "Total Loss: -1.5220714611610247e-08\n",
            "----------------------------------------\n",
            "Epoch 80\n",
            "Var loss:  tensor(-1.5450e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.076155542762418e-06\n",
            "E_s_wdiff_all_sq: 5.893733451721251e-07\n",
            "E_IS_SCOPE: -1.0190543106159438e-05\n",
            "E_IS_E_SCOPE: -8.87686543224567e-06\n",
            "Total Loss: -1.545008380382493e-08\n",
            "----------------------------------------\n",
            "Epoch 81\n",
            "Var loss:  tensor(-1.5716e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0864177772724906e-06\n",
            "E_s_wdiff_all_sq: 5.971980885534593e-07\n",
            "E_IS_SCOPE: -1.0205015559041124e-05\n",
            "E_IS_E_SCOPE: -8.88998623011595e-06\n",
            "Total Loss: -1.5715902697901463e-08\n",
            "----------------------------------------\n",
            "Epoch 82\n",
            "Var loss:  tensor(-1.5931e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0969009367687504e-06\n",
            "E_s_wdiff_all_sq: 6.052145464012129e-07\n",
            "E_IS_SCOPE: -1.0222006612789805e-05\n",
            "E_IS_E_SCOPE: -8.905636546449801e-06\n",
            "Total Loss: -1.593067587905463e-08\n",
            "----------------------------------------\n",
            "Epoch 83\n",
            "Var loss:  tensor(-1.6155e-08, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 7.78221979305549e-06\n",
            "E_IS_all_sq: 6.657096726622074e-06\n",
            "E_s_wdiff_sq: 2.0955619619847117e-06\n",
            "E_s_wdiff_all_sq: 6.03834491251812e-07\n",
            "E_IS_SCOPE: -1.0222915566011725e-05\n",
            "E_IS_E_SCOPE: -8.906412696594876e-06\n",
            "Total Loss: -1.6155201667381245e-08\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-a8a140889831>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel12\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_var_play\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded_state_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates_first_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates_last_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-34-4dcebd0cbd6f>\u001b[0m in \u001b[0;36mtrain_var_play\u001b[0;34m(model, num_epochs, learning_rate, padded_state_tensors, states_first_tensor, states_last_tensor, samples_all_shaping, samples_IS_SCOPE, test1)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# sample_sums_states_weight_diff, samples_gamma_weight_states_last_sub_states_first, samples_all_shaping, samples_IS_SCOPE = test1.bootstrap_shaping_terms(sums_states_weight_diff, gamma_weights_states_last_sub_states_first, IS_tensor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0msamples_IS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_sums_states_weight_diff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_gamma_weight_states_last_sub_states_first\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_all_shaping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_IS_SCOPE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbootstrap_all_terms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msums_states_weight_diff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma_weights_states_last_sub_states_first\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIS_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-314ae88ec427>\u001b[0m in \u001b[0;36mbootstrap_all_terms\u001b[0;34m(self, sums_states_weight_diff, gamma_weights_states_last_sub_states_first, IS_tensor)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;31m# Sample indices with replacement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0msampled_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msums_states_weight_diff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_bootstraps_lin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mreshaped_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msums_states_weight_diff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Greater policy randomness in pi_b"
      ],
      "metadata": {
        "id": "mw24KxKZ4l8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b = action_probs_top_n_epsilon(q_table, 2, 0.4)\n",
        "pi_b = experiment_actions(200, env, P_pi_b)\n",
        "P_pi_e = action_probs_top_n_epsilon(q_table, 1, 0.05)\n",
        "pi_e = experiment_actions(200, env, P_pi_e)\n",
        "model_200_2_p4 = CustomizableFeatureNet(input_dim=2, hidden_dims=[16, 32], output_dim=1, dtype = torch.float64)\n",
        "testing = SCOPE_variance_play(model_200_2_p4, 0.9, 10000, pi_b, P_pi_b, P_pi_e, dtype = torch.float64)\n",
        "IS_tensor, padded_state_tensors, padded_weight_diff_tensors, gamma_weights_last_tensor, states_first_tensor, states_last_tensor, weight_first_tensor = testing.prepare()\n"
      ],
      "metadata": {
        "id": "Qsp5-eqR4owZ"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "timesteps, states, states_first, states_last, actions, rewards, gamma_last, weights_last, weights, weights_difference, weights_first = testing.prep_policies()"
      ],
      "metadata": {
        "id": "8ysYBr-r-AFW"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that the variance within trajectories is quite low, which keeps the variance quite low, might need to consider normalizing in some manner, found this function of PDIS that does this based on maximum and minimum possible discounted reward\n",
        "\n",
        "https://github.com/hari-sikchi/safeRL/blob/master/importance_sampling/importance_sampling.py\n",
        "\n"
      ],
      "metadata": {
        "id": "SNvSFJCaOD_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# '''\n",
        "# Per Decision Importance Sampling\n",
        "# reward: list of reward obtained per time step\n",
        "\n",
        "# gamma: discount factor\n",
        "# trajectory_reward_high: Maximum value of sum of discounted rewards in a trajectory\n",
        "# trajectory_reward_low: Minimum value of sum of discounted rewards in a trajectory\n",
        "\n",
        "# returns normalized estimate of reward under evaluation policy\n",
        "# '''\n",
        "\n",
        "# def per_decision_is(pi_b,pi_e,gamma,reward,trajectory_reward_high,trajectory_reward_low):\n",
        "#     horizon = len(reward)\n",
        "#     expected_reward = 0\n",
        "#     gamma_t = 1\n",
        "#     importance_weight = 1\n",
        "#     for t in range(1,horizon+1):\n",
        "#         importance_weight *= pi_e[t-1]/pi_b[t-1]\n",
        "#         expected_reward+= gamma_t * reward[t-1] *importance_weight\n",
        "#         gamma_t *= gamma\n",
        "\n",
        "#     return (expected_reward - trajectory_reward_low)/(trajectory_reward_high-trajectory_reward_low)"
      ],
      "metadata": {
        "id": "DYBdIiUKOP0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trajectory_reward_high = 0.9**16 * 1\n",
        "trajectory_reward_low = 0.9**7 * -1"
      ],
      "metadata": {
        "id": "jd8aOsLxVciK"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "0.9**80"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBzJV2LgXRRC",
        "outputId": "fb3ecaab-6753-4e24-be15-a207f564c369"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.00021847450052839255"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trajectory_reward_high"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZdhy9nIXAx-",
        "outputId": "c6ff4c60-09dd-4e07-fece-c372bb48a974"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.18530201888518416"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trajectory_reward_low"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKjqsz0hXD-s",
        "outputId": "48e2a73c-d7e8-4071-e919-3d6d09947e07"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.4782969000000001"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(trajectory_reward_high-trajectory_reward_low)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CLW6JGnW-Xc",
        "outputId": "3f557d92-d255-4a04-9f3a-84a5b61c9249"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6635989188851843"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cum_ratio = 1\n",
        "cumul_weights = []\n",
        "P_pi_e_probs = []\n",
        "P_pi_b_probs = []\n",
        "\n",
        "for step in pi_b[0]:\n",
        "    P_pi_b_prob = P_pi_b[tuple(np.append(step[0].astype(int), (step[1],)))]\n",
        "    P_pi_e_prob = P_pi_e[tuple(np.append(step[0].astype(int), (step[1],)))]\n",
        "\n",
        "    P_pi_b_probs.append(P_pi_b_prob)\n",
        "    P_pi_e_probs.append(P_pi_e_prob)\n",
        "\n",
        "    ratio = P_pi_e_prob / P_pi_b_prob\n",
        "    cum_ratio *= ratio\n",
        "    cumul_weights.append(cum_ratio)\n"
      ],
      "metadata": {
        "id": "aJX3KvmBZzvy"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_b_probs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8eE5sZAani4",
        "outputId": "59e0dfba-52dc-4ab6-e06f-8df805397465"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.38,\n",
              " 0.08,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.08,\n",
              " 0.38,\n",
              " 0.08,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.08,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.08,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.08,\n",
              " 0.08,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.38,\n",
              " 0.08,\n",
              " 0.38,\n",
              " 0.38]"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_e[2,8,0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HHyVC2nbugu",
        "outputId": "9078bda2-0225-44bc-af77-6a1bc4bc47fb"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.01"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pi_b[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eb9-8ChfbIP9",
        "outputId": "17463c14-6ac0-471a-f9b5-c613ebd1c11e"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([([2., 9.], 1, 0., [2., 8.],  0, 3.),\n",
              "       ([2., 8.], 0, 0., [2., 8.],  1, 3.),\n",
              "       ([2., 8.], 1, 0., [2., 7.],  2, 3.),\n",
              "       ([2., 7.], 1, 0., [2., 6.],  3, 3.),\n",
              "       ([2., 6.], 3, 0., [1., 6.],  4, 3.),\n",
              "       ([1., 6.], 2, 0., [1., 7.],  5, 4.),\n",
              "       ([1., 7.], 3, 0., [0., 7.],  6, 4.),\n",
              "       ([0., 7.], 0, 0., [0., 7.],  7, 5.),\n",
              "       ([0., 7.], 1, 0., [0., 6.],  8, 5.),\n",
              "       ([0., 6.], 3, 0., [0., 6.],  9, 5.),\n",
              "       ([0., 6.], 1, 0., [0., 5.], 10, 5.),\n",
              "       ([0., 5.], 1, 0., [0., 4.], 11, 5.),\n",
              "       ([0., 4.], 1, 0., [0., 3.], 12, 6.),\n",
              "       ([0., 3.], 2, 0., [0., 4.], 13, 7.),\n",
              "       ([0., 4.], 1, 0., [0., 3.], 14, 6.),\n",
              "       ([0., 3.], 4, 0., [1., 3.], 15, 7.),\n",
              "       ([1., 3.], 0, 0., [1., 3.], 16, 6.),\n",
              "       ([1., 3.], 2, 0., [1., 4.], 17, 6.),\n",
              "       ([1., 4.], 0, 0., [1., 4.], 18, 5.),\n",
              "       ([1., 4.], 0, 0., [1., 4.], 19, 5.),\n",
              "       ([1., 4.], 0, 0., [1., 4.], 20, 5.),\n",
              "       ([1., 4.], 0, 0., [1., 4.], 21, 5.),\n",
              "       ([1., 4.], 1, 0., [1., 3.], 22, 5.),\n",
              "       ([1., 3.], 0, 0., [1., 3.], 23, 6.),\n",
              "       ([1., 3.], 0, 0., [1., 3.], 24, 6.),\n",
              "       ([1., 3.], 2, 0., [1., 4.], 25, 6.),\n",
              "       ([1., 4.], 0, 0., [1., 4.], 26, 5.),\n",
              "       ([1., 4.], 1, 0., [1., 3.], 27, 5.),\n",
              "       ([1., 3.], 4, 0., [2., 3.], 28, 6.),\n",
              "       ([2., 3.], 1, 0., [2., 2.], 29, 5.),\n",
              "       ([2., 2.], 4, 0., [3., 2.], 30, 6.),\n",
              "       ([3., 2.], 4, 0., [4., 2.], 31, 5.),\n",
              "       ([4., 2.], 4, 0., [5., 2.], 32, 4.),\n",
              "       ([5., 2.], 3, 0., [4., 2.], 33, 3.),\n",
              "       ([4., 2.], 1, 0., [4., 1.], 34, 4.),\n",
              "       ([4., 1.], 0, 0., [4., 1.], 35, 5.),\n",
              "       ([4., 1.], 0, 0., [4., 1.], 36, 5.),\n",
              "       ([4., 1.], 0, 0., [4., 1.], 37, 5.),\n",
              "       ([4., 1.], 4, 0., [5., 1.], 38, 5.),\n",
              "       ([5., 1.], 0, 0., [5., 1.], 39, 4.),\n",
              "       ([5., 1.], 4, 0., [6., 1.], 40, 4.),\n",
              "       ([6., 1.], 3, 0., [5., 1.], 41, 4.),\n",
              "       ([5., 1.], 1, 1., [5., 0.], 42, 4.)],\n",
              "      dtype=[('state', '<f8', (2,)), ('action', '<i8'), ('reward', '<f8'), ('state_next', '<f8', (2,)), ('timestep', '<i8'), ('psi', '<f8')])"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "P_pi_e_probs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFZBF-V1av1q",
        "outputId": "029d57c9-0f53-4a66-f73d-a0b74b29ffd9"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.01,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.96,\n",
              " 0.01,\n",
              " 0.96,\n",
              " 0.01,\n",
              " 0.96,\n",
              " 0.01,\n",
              " 0.96,\n",
              " 0.96,\n",
              " 0.01,\n",
              " 0.96,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.96,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.96,\n",
              " 0.96,\n",
              " 0.96,\n",
              " 0.96,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.96,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.96,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.01,\n",
              " 0.96]"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pi_b[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHWedeeOZhg2",
        "outputId": "1d5f68a3-3695-475f-f14b-d7dda7f91c44"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([([2., 9.], 1, 0., [2., 8.],  0, 3.),\n",
              "       ([2., 8.], 0, 0., [2., 8.],  1, 3.),\n",
              "       ([2., 8.], 1, 0., [2., 7.],  2, 3.),\n",
              "       ([2., 7.], 1, 0., [2., 6.],  3, 3.),\n",
              "       ([2., 6.], 3, 0., [1., 6.],  4, 3.),\n",
              "       ([1., 6.], 2, 0., [1., 7.],  5, 4.),\n",
              "       ([1., 7.], 3, 0., [0., 7.],  6, 4.),\n",
              "       ([0., 7.], 0, 0., [0., 7.],  7, 5.),\n",
              "       ([0., 7.], 1, 0., [0., 6.],  8, 5.),\n",
              "       ([0., 6.], 3, 0., [0., 6.],  9, 5.),\n",
              "       ([0., 6.], 1, 0., [0., 5.], 10, 5.),\n",
              "       ([0., 5.], 1, 0., [0., 4.], 11, 5.),\n",
              "       ([0., 4.], 1, 0., [0., 3.], 12, 6.),\n",
              "       ([0., 3.], 2, 0., [0., 4.], 13, 7.),\n",
              "       ([0., 4.], 1, 0., [0., 3.], 14, 6.),\n",
              "       ([0., 3.], 4, 0., [1., 3.], 15, 7.),\n",
              "       ([1., 3.], 0, 0., [1., 3.], 16, 6.),\n",
              "       ([1., 3.], 2, 0., [1., 4.], 17, 6.),\n",
              "       ([1., 4.], 0, 0., [1., 4.], 18, 5.),\n",
              "       ([1., 4.], 0, 0., [1., 4.], 19, 5.),\n",
              "       ([1., 4.], 0, 0., [1., 4.], 20, 5.),\n",
              "       ([1., 4.], 0, 0., [1., 4.], 21, 5.),\n",
              "       ([1., 4.], 1, 0., [1., 3.], 22, 5.),\n",
              "       ([1., 3.], 0, 0., [1., 3.], 23, 6.),\n",
              "       ([1., 3.], 0, 0., [1., 3.], 24, 6.),\n",
              "       ([1., 3.], 2, 0., [1., 4.], 25, 6.),\n",
              "       ([1., 4.], 0, 0., [1., 4.], 26, 5.),\n",
              "       ([1., 4.], 1, 0., [1., 3.], 27, 5.),\n",
              "       ([1., 3.], 4, 0., [2., 3.], 28, 6.),\n",
              "       ([2., 3.], 1, 0., [2., 2.], 29, 5.),\n",
              "       ([2., 2.], 4, 0., [3., 2.], 30, 6.),\n",
              "       ([3., 2.], 4, 0., [4., 2.], 31, 5.),\n",
              "       ([4., 2.], 4, 0., [5., 2.], 32, 4.),\n",
              "       ([5., 2.], 3, 0., [4., 2.], 33, 3.),\n",
              "       ([4., 2.], 1, 0., [4., 1.], 34, 4.),\n",
              "       ([4., 1.], 0, 0., [4., 1.], 35, 5.),\n",
              "       ([4., 1.], 0, 0., [4., 1.], 36, 5.),\n",
              "       ([4., 1.], 0, 0., [4., 1.], 37, 5.),\n",
              "       ([4., 1.], 4, 0., [5., 1.], 38, 5.),\n",
              "       ([5., 1.], 0, 0., [5., 1.], 39, 4.),\n",
              "       ([5., 1.], 4, 0., [6., 1.], 40, 4.),\n",
              "       ([6., 1.], 3, 0., [5., 1.], 41, 4.),\n",
              "       ([5., 1.], 1, 1., [5., 0.], 42, 4.)],\n",
              "      dtype=[('state', '<f8', (2,)), ('action', '<i8'), ('reward', '<f8'), ('state_next', '<f8', (2,)), ('timestep', '<i8'), ('psi', '<f8')])"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aWPsckKYhao",
        "outputId": "10ac346c-55c2-4009-ccdc-57572fd970ca"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.02631578947368421,\n",
              " 0.003289473684210526,\n",
              " 8.656509695290857e-05,\n",
              " 2.2780288671818044e-06,\n",
              " 5.755020296038243e-06,\n",
              " 7.193775370047803e-07,\n",
              " 1.817374830327866e-06,\n",
              " 2.2717185379098326e-07,\n",
              " 5.739078411561682e-07,\n",
              " 1.510283792516232e-08,\n",
              " 3.815453791619955e-08,\n",
              " 9.639041157776727e-08,\n",
              " 2.5365897783622966e-09,\n",
              " 6.408226808494222e-09,\n",
              " 1.686375475919532e-10,\n",
              " 4.437830199788242e-12,\n",
              " 1.167850052575853e-13,\n",
              " 1.4598125657198164e-14,\n",
              " 3.841612015052148e-16,\n",
              " 1.010950530276881e-17,\n",
              " 2.6603961323075813e-19,\n",
              " 7.001042453441003e-21,\n",
              " 1.7686844092903583e-20,\n",
              " 4.654432656027258e-22,\n",
              " 1.2248506989545416e-23,\n",
              " 1.531063373693177e-24,\n",
              " 4.029114141297834e-26,\n",
              " 1.0178814672752422e-25,\n",
              " 2.571490022590085e-25,\n",
              " 6.496395846543372e-25,\n",
              " 1.6411947401793782e-24,\n",
              " 2.0514934252242227e-25,\n",
              " 2.5643667815302784e-26,\n",
              " 6.748333635605995e-28,\n",
              " 1.7048421816267776e-27,\n",
              " 4.4864267937546775e-29,\n",
              " 1.1806386299354413e-30,\n",
              " 3.1069437629880036e-32,\n",
              " 7.849121085443377e-32,\n",
              " 2.065558180379836e-33,\n",
              " 2.581947725474795e-34,\n",
              " 6.79459927756525e-36,\n",
              " 1.7165303438059576e-35]"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IS_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gW62FfxyPmXv",
        "outputId": "0bd68c05-652b-4bf9-9b2b-7f685da4acf6"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2.0551e-37],\n",
              "        [-4.8452e-12],\n",
              "        [ 3.4739e-26],\n",
              "        [ 1.9805e-52],\n",
              "        [ 5.6599e-30],\n",
              "        [ 3.6186e-28],\n",
              "        [ 1.2260e-37],\n",
              "        [ 3.3817e-61],\n",
              "        [ 4.8221e-73],\n",
              "        [ 8.0587e-33],\n",
              "        [ 2.3787e-34],\n",
              "        [ 2.5989e-18],\n",
              "        [ 1.1778e-45],\n",
              "        [ 1.5114e-51],\n",
              "        [ 1.0731e-23],\n",
              "        [ 3.1264e-31],\n",
              "        [ 4.8743e-37],\n",
              "        [ 6.9782e-22],\n",
              "        [ 7.5361e-54],\n",
              "        [ 6.3329e-16],\n",
              "        [ 2.5512e-42],\n",
              "        [ 2.8200e-22],\n",
              "        [ 1.0058e-30],\n",
              "        [ 3.5798e-20],\n",
              "        [ 4.5442e-51],\n",
              "        [ 2.2281e-20],\n",
              "        [ 1.8043e-30],\n",
              "        [ 1.2700e-46],\n",
              "        [ 1.1456e-37],\n",
              "        [ 6.1262e-48],\n",
              "        [ 2.1988e-26],\n",
              "        [ 9.2430e-31],\n",
              "        [ 7.5947e-22],\n",
              "        [ 1.7820e-57],\n",
              "        [ 5.8006e-42],\n",
              "        [ 1.3517e-53],\n",
              "        [ 3.3349e-24],\n",
              "        [ 2.6211e-40],\n",
              "        [ 3.5798e-20],\n",
              "        [ 4.9731e-44],\n",
              "        [ 1.4578e-21],\n",
              "        [ 1.0805e-47],\n",
              "        [ 4.2534e-27],\n",
              "        [ 5.4923e-36],\n",
              "        [ 6.1497e-65],\n",
              "        [ 4.9654e-13],\n",
              "        [ 5.3505e-26],\n",
              "        [ 8.9888e-45],\n",
              "        [ 5.7611e-29],\n",
              "        [ 7.7836e-34],\n",
              "        [ 1.5779e-72],\n",
              "        [ 1.0404e-41],\n",
              "        [ 2.3371e-46],\n",
              "        [ 9.4352e-81],\n",
              "        [ 3.2290e-11],\n",
              "        [ 4.4306e-29],\n",
              "        [ 3.4365e-51],\n",
              "        [ 1.2925e-56],\n",
              "        [ 2.5025e-12],\n",
              "        [ 4.0775e-27],\n",
              "        [ 2.8678e-22],\n",
              "        [ 1.2222e-30],\n",
              "        [ 1.4578e-21],\n",
              "        [ 2.2871e-63],\n",
              "        [ 5.4835e-38],\n",
              "        [ 3.2514e-35],\n",
              "        [ 1.7018e-40],\n",
              "        [ 2.5809e-27],\n",
              "        [ 2.1988e-26],\n",
              "        [ 4.2534e-27],\n",
              "        [ 2.5513e-09],\n",
              "        [ 7.7239e-33],\n",
              "        [ 1.1193e-56],\n",
              "        [ 1.7781e-38],\n",
              "        [ 1.2334e-29],\n",
              "        [ 4.0584e-22],\n",
              "        [ 3.5443e-33],\n",
              "        [ 8.8318e-24],\n",
              "        [ 9.1998e-26],\n",
              "        [ 2.5722e-86],\n",
              "        [ 6.8861e-61],\n",
              "        [ 1.8365e-18],\n",
              "        [ 7.6832e-51],\n",
              "        [ 2.4021e-76],\n",
              "        [ 1.3793e-38],\n",
              "        [ 2.0899e-37],\n",
              "        [ 7.6941e-49],\n",
              "        [ 1.6463e-39],\n",
              "        [ 2.2380e-14],\n",
              "        [ 3.2414e-28],\n",
              "        [ 7.0866e-68],\n",
              "        [ 5.7293e-36],\n",
              "        [ 5.2929e-51],\n",
              "        [ 5.2887e-74],\n",
              "        [ 2.3062e-41],\n",
              "        [ 1.6414e-43],\n",
              "        [-3.4057e-30],\n",
              "        [ 8.8247e-03],\n",
              "        [ 1.7765e-50],\n",
              "        [ 4.9887e-18],\n",
              "        [ 4.0674e-41],\n",
              "        [ 1.0160e-17],\n",
              "        [ 1.5528e-49],\n",
              "        [ 2.1922e-30],\n",
              "        [ 3.8162e-69],\n",
              "        [ 7.2350e-19],\n",
              "        [ 2.5045e-33],\n",
              "        [ 3.4055e-19],\n",
              "        [ 2.3513e-05],\n",
              "        [ 5.0422e-48],\n",
              "        [ 6.8240e-29],\n",
              "        [ 9.3633e-47],\n",
              "        [ 8.3418e-32],\n",
              "        [ 2.2923e-49],\n",
              "        [ 2.1254e-37],\n",
              "        [ 3.5520e-41],\n",
              "        [ 8.3229e-46],\n",
              "        [ 1.3941e-35],\n",
              "        [ 4.6152e-31],\n",
              "        [ 2.9757e-40],\n",
              "        [ 3.0548e-17],\n",
              "        [ 3.3840e-49],\n",
              "        [ 5.2120e-49],\n",
              "        [ 5.1606e-29],\n",
              "        [ 4.2992e-68],\n",
              "        [ 5.9680e-38],\n",
              "        [ 1.3750e-31],\n",
              "        [ 1.4399e-15],\n",
              "        [ 1.3528e-41],\n",
              "        [ 2.8285e-18],\n",
              "        [ 7.7903e-22],\n",
              "        [ 3.3477e-41],\n",
              "        [ 3.0735e-20],\n",
              "        [ 1.8867e-49],\n",
              "        [ 8.1149e-24],\n",
              "        [ 1.3770e-29],\n",
              "        [ 7.7060e-80],\n",
              "        [ 4.4817e-80],\n",
              "        [ 4.5307e-22],\n",
              "        [ 3.2290e-11],\n",
              "        [ 1.6822e-11],\n",
              "        [ 7.6477e-13],\n",
              "        [ 1.4522e-37],\n",
              "        [ 2.5868e-13],\n",
              "        [ 2.8458e-21],\n",
              "        [ 2.2885e-40],\n",
              "        [ 5.8138e-28],\n",
              "        [ 5.9731e-26],\n",
              "        [ 2.7447e-57],\n",
              "        [ 2.6010e-39],\n",
              "        [ 9.6121e-24],\n",
              "        [ 4.9462e-29],\n",
              "        [ 3.8070e-50],\n",
              "        [ 9.5384e-23],\n",
              "        [ 2.5220e-24],\n",
              "        [ 2.1554e-52],\n",
              "        [ 3.4233e-34],\n",
              "        [ 6.8237e-62],\n",
              "        [ 3.6295e-24],\n",
              "        [ 1.6450e-18],\n",
              "        [ 5.3580e-24],\n",
              "        [ 1.2908e-69],\n",
              "        [ 3.2891e-53],\n",
              "        [ 5.0490e-79],\n",
              "        [ 7.1123e-41],\n",
              "        [ 2.7154e-16],\n",
              "        [ 2.3602e-55],\n",
              "        [ 1.0796e-26],\n",
              "        [ 1.3395e-21],\n",
              "        [ 2.1420e-16],\n",
              "        [ 1.7903e-51],\n",
              "        [ 8.2912e-29],\n",
              "        [ 1.9561e-46],\n",
              "        [ 1.9367e-59],\n",
              "        [ 1.1474e-35],\n",
              "        [ 2.1940e-51],\n",
              "        [ 4.6369e-36],\n",
              "        [ 7.4787e-20],\n",
              "        [ 5.2844e-53],\n",
              "        [ 9.0940e-41],\n",
              "        [ 9.3196e-42],\n",
              "        [ 8.4854e-43],\n",
              "        [ 1.3373e-12],\n",
              "        [ 8.2775e-64],\n",
              "        [ 9.8046e-64],\n",
              "        [ 5.5902e-24],\n",
              "        [ 1.0955e-51],\n",
              "        [ 7.9969e-32],\n",
              "        [ 5.8862e-34],\n",
              "        [ 9.6572e-29],\n",
              "        [ 9.2704e-60],\n",
              "        [ 8.7830e-31],\n",
              "        [ 5.6165e-29],\n",
              "        [ 3.2864e-32],\n",
              "        [ 1.0880e-27],\n",
              "        [ 7.0969e-33],\n",
              "        [ 4.6944e-75],\n",
              "        [ 3.7112e-83],\n",
              "        [ 1.0191e-46],\n",
              "        [ 6.0707e-49]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.var(IS_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MENIklmqKgq6",
        "outputId": "dadbf702-f264-4417-c359-13f26c689133"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.8937e-07, dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mean(IS_tensor**2) - torch.mean(IS_tensor)**2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjd3r5nCMFWG",
        "outputId": "7411b265-8782-41bf-f250-2a3fd7dda739"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.8742e-07, dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mean(IS_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSBBkdn5LpI0",
        "outputId": "a988c264-2707-486b-956e-c5ba6a45e43a"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.4241e-05, dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(weights[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmC6YFqmHzcL",
        "outputId": "f0ed6cf3-a94f-42da-8a1e-e075b2db1b24"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(weights_difference[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DI1Hfg1JWRu",
        "outputId": "9a4045e7-e683-4fb0-bb34-38db58f495d9"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(pi_b[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FflnxUpHpPC",
        "outputId": "b530f2e9-b988-4d9c-e85e-2e5180146932"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# single cumprod\n",
        "# 200 trajectories\n",
        "model_200_2_p4 = train_var_play(model_200_2_p4, 200, 0.001, padded_state_tensors, states_first_tensor, states_last_tensor, 1, 1, testing)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_WriHen4pWo",
        "outputId": "3662f880-4886-4038-eeb8-608e6f25a4d2"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Var loss:  tensor(1.1985, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 2.297909386211681\n",
            "E_s_wdiff_all_sq: 1.0994508765271211\n",
            "E_IS_SCOPE: 3.878983758204295e-05\n",
            "E_IS_E_SCOPE: 3.843762575160876e-05\n",
            "Total Loss: 1.1984592160084957\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "Var loss:  tensor(0.0416, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.04392587686827187\n",
            "E_s_wdiff_all_sq: 0.0023080316182087575\n",
            "E_IS_SCOPE: -8.007193464295585e-06\n",
            "E_IS_E_SCOPE: -7.634354580536492e-06\n",
            "Total Loss: 0.04161710147257035\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "Var loss:  tensor(0.0388, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.03925886301233597\n",
            "E_s_wdiff_all_sq: 0.0004488434884700709\n",
            "E_IS_SCOPE: -7.451422098909373e-06\n",
            "E_IS_E_SCOPE: -7.078667767300758e-06\n",
            "Total Loss: 0.03880927591547743\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "Var loss:  tensor(0.0362, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.03618221541199196\n",
            "E_s_wdiff_all_sq: 1.5627195795477096e-05\n",
            "E_IS_SCOPE: -6.73635978293311e-06\n",
            "E_IS_E_SCOPE: -6.363300668902292e-06\n",
            "Total Loss: 0.03616584399824317\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "Var loss:  tensor(0.0341, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.03483415076299158\n",
            "E_s_wdiff_all_sq: 0.0007483471171284855\n",
            "E_IS_SCOPE: -5.954896256454207e-06\n",
            "E_IS_E_SCOPE: -5.581613167763779e-06\n",
            "Total Loss: 0.03408505897996047\n",
            "----------------------------------------\n",
            "Epoch 6\n",
            "Var loss:  tensor(0.0327, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.03500008997453642\n",
            "E_s_wdiff_all_sq: 0.002299828566122942\n",
            "E_IS_SCOPE: -5.201083616526263e-06\n",
            "E_IS_E_SCOPE: -4.8279615663606775e-06\n",
            "Total Loss: 0.032699517064587895\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "Var loss:  tensor(0.0319, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.03627056723217435\n",
            "E_s_wdiff_all_sq: 0.004386374656823539\n",
            "E_IS_SCOPE: -4.4822491843661086e-06\n",
            "E_IS_E_SCOPE: -4.109621191323106e-06\n",
            "Total Loss: 0.03188344921963948\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "Var loss:  tensor(0.0315, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.03824929035390946\n",
            "E_s_wdiff_all_sq: 0.006738201877200653\n",
            "E_IS_SCOPE: -3.82324042087388e-06\n",
            "E_IS_E_SCOPE: -3.4514823381124335e-06\n",
            "Total Loss: 0.031510346860818036\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "Var loss:  tensor(0.0314, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.040508941581502686\n",
            "E_s_wdiff_all_sq: 0.009076811804137457\n",
            "E_IS_SCOPE: -3.245941847961306e-06\n",
            "E_IS_E_SCOPE: -2.8754542389428553e-06\n",
            "Total Loss: 0.03143139070242195\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "Var loss:  tensor(0.0315, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.042621271923216415\n",
            "E_s_wdiff_all_sq: 0.011158634778542032\n",
            "E_IS_SCOPE: -2.765903893180527e-06\n",
            "E_IS_E_SCOPE: -2.3967410027452646e-06\n",
            "Total Loss: 0.03146190071916826\n",
            "----------------------------------------\n",
            "Epoch 11\n",
            "Var loss:  tensor(0.0314, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.044266651997166125\n",
            "E_s_wdiff_all_sq: 0.01281841741840197\n",
            "E_IS_SCOPE: -2.389031988940191e-06\n",
            "E_IS_E_SCOPE: -2.0209475150507352e-06\n",
            "Total Loss: 0.03144750031009113\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "Var loss:  tensor(0.0313, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.045239818172975184\n",
            "E_s_wdiff_all_sq: 0.013948519258881251\n",
            "E_IS_SCOPE: -2.1186112441408252e-06\n",
            "E_IS_E_SCOPE: -1.7521169803677011e-06\n",
            "Total Loss: 0.03129056782584114\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "Var loss:  tensor(0.0309, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.0454763667053736\n",
            "E_s_wdiff_all_sq: 0.014534955972714323\n",
            "E_IS_SCOPE: -1.946147086723511e-06\n",
            "E_IS_E_SCOPE: -1.581752904500871e-06\n",
            "Total Loss: 0.030940683844569578\n",
            "----------------------------------------\n",
            "Epoch 14\n",
            "Var loss:  tensor(0.0304, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.044982254200287265\n",
            "E_s_wdiff_all_sq: 0.014590674951117004\n",
            "E_IS_SCOPE: -1.8653044406692305e-06\n",
            "E_IS_E_SCOPE: -1.5035736953486128e-06\n",
            "Total Loss: 0.030390857687954374\n",
            "----------------------------------------\n",
            "Epoch 15\n",
            "Var loss:  tensor(0.0297, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.04385896261366019\n",
            "E_s_wdiff_all_sq: 0.014184396941775479\n",
            "E_IS_SCOPE: -1.8642884714399405e-06\n",
            "E_IS_E_SCOPE: -1.5055700636623406e-06\n",
            "Total Loss: 0.02967385013534391\n",
            "----------------------------------------\n",
            "Epoch 16\n",
            "Var loss:  tensor(0.0288, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.04223117382857745\n",
            "E_s_wdiff_all_sq: 0.013393948540381943\n",
            "E_IS_SCOPE: -1.9327902088660277e-06\n",
            "E_IS_E_SCOPE: -1.5773754704137532e-06\n",
            "Total Loss: 0.02883651635899335\n",
            "----------------------------------------\n",
            "Epoch 17\n",
            "Var loss:  tensor(0.0279, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.040272442555752234\n",
            "E_s_wdiff_all_sq: 0.012329139230491027\n",
            "E_IS_SCOPE: -2.0548381139786605e-06\n",
            "E_IS_E_SCOPE: -1.7029494763619422e-06\n",
            "Total Loss: 0.027942601448260725\n",
            "----------------------------------------\n",
            "Epoch 18\n",
            "Var loss:  tensor(0.0271, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.03815787516764467\n",
            "E_s_wdiff_all_sq: 0.011103359885243462\n",
            "E_IS_SCOPE: -2.214917342017269e-06\n",
            "E_IS_E_SCOPE: -1.8667013467230403e-06\n",
            "Total Loss: 0.027053820750685374\n",
            "----------------------------------------\n",
            "Epoch 19\n",
            "Var loss:  tensor(0.0262, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.036045122030530674\n",
            "E_s_wdiff_all_sq: 0.009819596471660913\n",
            "E_IS_SCOPE: -2.394384643898371e-06\n",
            "E_IS_E_SCOPE: -2.049887566771903e-06\n",
            "Total Loss: 0.026224838464990262\n",
            "----------------------------------------\n",
            "Epoch 20\n",
            "Var loss:  tensor(0.0255, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.034048284507499645\n",
            "E_s_wdiff_all_sq: 0.00856380955915508\n",
            "E_IS_SCOPE: -2.578006777514063e-06\n",
            "E_IS_E_SCOPE: -2.2373787193848528e-06\n",
            "Total Loss: 0.025483795592503057\n",
            "----------------------------------------\n",
            "Epoch 21\n",
            "Var loss:  tensor(0.0248, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.03210011705996097\n",
            "E_s_wdiff_all_sq: 0.007265569052274326\n",
            "E_IS_SCOPE: -2.7869321418720623e-06\n",
            "E_IS_E_SCOPE: -2.4503620409244804e-06\n",
            "Total Loss: 0.024833876767759503\n",
            "----------------------------------------\n",
            "Epoch 22\n",
            "Var loss:  tensor(0.0243, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.03035880143875993\n",
            "E_s_wdiff_all_sq: 0.0060609501289704635\n",
            "E_IS_SCOPE: -2.9886672191389325e-06\n",
            "E_IS_E_SCOPE: -2.656169330458181e-06\n",
            "Total Loss: 0.024297188214286856\n",
            "----------------------------------------\n",
            "Epoch 23\n",
            "Var loss:  tensor(0.0239, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.028893437377904292\n",
            "E_s_wdiff_all_sq: 0.005036224433765073\n",
            "E_IS_SCOPE: -3.1565300334446345e-06\n",
            "E_IS_E_SCOPE: -2.8279737328275426e-06\n",
            "Total Loss: 0.023856557731812736\n",
            "----------------------------------------\n",
            "Epoch 24\n",
            "Var loss:  tensor(0.0235, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.027683324209120598\n",
            "E_s_wdiff_all_sq: 0.00420977443350421\n",
            "E_IS_SCOPE: -3.2748137328653198e-06\n",
            "E_IS_E_SCOPE: -2.9499748416950865e-06\n",
            "Total Loss: 0.023472901998108798\n",
            "----------------------------------------\n",
            "Epoch 25\n",
            "Var loss:  tensor(0.0231, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.026686837610308146\n",
            "E_s_wdiff_all_sq: 0.0035836433560412716\n",
            "E_IS_SCOPE: -3.331727970206348e-06\n",
            "E_IS_E_SCOPE: -3.0105376470245005e-06\n",
            "Total Loss: 0.023102553773895265\n",
            "----------------------------------------\n",
            "Epoch 26\n",
            "Var loss:  tensor(0.0227, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.025847027049085376\n",
            "E_s_wdiff_all_sq: 0.003139009703658511\n",
            "E_IS_SCOPE: -3.321684196379081e-06\n",
            "E_IS_E_SCOPE: -3.0038344210674964e-06\n",
            "Total Loss: 0.02270738354615099\n",
            "----------------------------------------\n",
            "Epoch 27\n",
            "Var loss:  tensor(0.0223, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.025110536788134106\n",
            "E_s_wdiff_all_sq: 0.0028530780417820333\n",
            "E_IS_SCOPE: -3.2439638220504366e-06\n",
            "E_IS_E_SCOPE: -2.9291155523118645e-06\n",
            "Total Loss: 0.022256830950087344\n",
            "----------------------------------------\n",
            "Epoch 28\n",
            "Var loss:  tensor(0.0217, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.02445254827845828\n",
            "E_s_wdiff_all_sq: 0.0027121430335832987\n",
            "E_IS_SCOPE: -3.0950811895847455e-06\n",
            "E_IS_E_SCOPE: -2.7828293869470027e-06\n",
            "Total Loss: 0.021739782641544456\n",
            "----------------------------------------\n",
            "Epoch 29\n",
            "Var loss:  tensor(0.0212, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.023862469079324513\n",
            "E_s_wdiff_all_sq: 0.002687277465738614\n",
            "E_IS_SCOPE: -2.8846996881920006e-06\n",
            "E_IS_E_SCOPE: -2.5747940778952074e-06\n",
            "Total Loss: 0.02117457370264006\n",
            "----------------------------------------\n",
            "Epoch 30\n",
            "Var loss:  tensor(0.0206, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.02334199743582177\n",
            "E_s_wdiff_all_sq: 0.00275876791942823\n",
            "E_IS_SCOPE: -2.6212076654539654e-06\n",
            "E_IS_E_SCOPE: -2.3133736047279843e-06\n",
            "Total Loss: 0.020582615748546838\n",
            "----------------------------------------\n",
            "Epoch 31\n",
            "Var loss:  tensor(0.0200, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.0228877954925864\n",
            "E_s_wdiff_all_sq: 0.00290140251193011\n",
            "E_IS_SCOPE: -2.3180876457147406e-06\n",
            "E_IS_E_SCOPE: -2.0120692325446993e-06\n",
            "Total Loss: 0.019985782844104703\n",
            "----------------------------------------\n",
            "Epoch 32\n",
            "Var loss:  tensor(0.0194, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.022499263463222115\n",
            "E_s_wdiff_all_sq: 0.0030931384249713507\n",
            "E_IS_SCOPE: -1.9912770986092742e-06\n",
            "E_IS_E_SCOPE: -1.686844240184114e-06\n",
            "Total Loss: 0.019405518072808665\n",
            "----------------------------------------\n",
            "Epoch 33\n",
            "Var loss:  tensor(0.0189, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.02218138527822573\n",
            "E_s_wdiff_all_sq: 0.003315533238852356\n",
            "E_IS_SCOPE: -1.6519068431043025e-06\n",
            "E_IS_E_SCOPE: -1.3489632049508678e-06\n",
            "Total Loss: 0.018865248052371816\n",
            "----------------------------------------\n",
            "Epoch 34\n",
            "Var loss:  tensor(0.0184, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.021939676598509893\n",
            "E_s_wdiff_all_sq: 0.00357011099691371\n",
            "E_IS_SCOPE: -1.3011227865717189e-06\n",
            "E_IS_E_SCOPE: -1.0006736465147596e-06\n",
            "Total Loss: 0.01836896660359082\n",
            "----------------------------------------\n",
            "Epoch 35\n",
            "Var loss:  tensor(0.0179, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.02169695958143122\n",
            "E_s_wdiff_all_sq: 0.003766596027349277\n",
            "E_IS_SCOPE: -9.76442423531455e-07\n",
            "E_IS_E_SCOPE: -6.791607499717546e-07\n",
            "Total Loss: 0.01792977089100958\n",
            "----------------------------------------\n",
            "Epoch 36\n",
            "Var loss:  tensor(0.0175, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.021367123602767508\n",
            "E_s_wdiff_all_sq: 0.00384817055518921\n",
            "E_IS_SCOPE: -6.995754675542332e-07\n",
            "E_IS_E_SCOPE: -4.0584075933746697e-07\n",
            "Total Loss: 0.017518367478436617\n",
            "----------------------------------------\n",
            "Epoch 37\n",
            "Var loss:  tensor(0.0171, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.02084119261402764\n",
            "E_s_wdiff_all_sq: 0.003728740153148207\n",
            "E_IS_SCOPE: -4.962908312687996e-07\n",
            "E_IS_E_SCOPE: -2.0787027719281508e-07\n",
            "Total Loss: 0.01711187752004603\n",
            "----------------------------------------\n",
            "Epoch 38\n",
            "Var loss:  tensor(0.0167, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.02015661990200089\n",
            "E_s_wdiff_all_sq: 0.003452574263615173\n",
            "E_IS_SCOPE: -3.5428511539102974e-07\n",
            "E_IS_E_SCOPE: -7.174935513163259e-08\n",
            "Total Loss: 0.01670348246713995\n",
            "----------------------------------------\n",
            "Epoch 39\n",
            "Var loss:  tensor(0.0163, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.019171650322192545\n",
            "E_s_wdiff_all_sq: 0.002899953543942618\n",
            "E_IS_SCOPE: -3.236982939354758e-07\n",
            "E_IS_E_SCOPE: -4.786063992429541e-08\n",
            "Total Loss: 0.016271147003216656\n",
            "----------------------------------------\n",
            "Epoch 40\n",
            "Var loss:  tensor(0.0158, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.01816520961836425\n",
            "E_s_wdiff_all_sq: 0.0023204547289400346\n",
            "E_IS_SCOPE: -3.259520373806938e-07\n",
            "E_IS_E_SCOPE: -5.7348620134436905e-08\n",
            "Total Loss: 0.01584421958286447\n",
            "----------------------------------------\n",
            "Epoch 41\n",
            "Var loss:  tensor(0.0155, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.017220117575009262\n",
            "E_s_wdiff_all_sq: 0.0017643030091933796\n",
            "E_IS_SCOPE: -3.5217191558103625e-07\n",
            "E_IS_E_SCOPE: -9.12109017177355e-08\n",
            "Total Loss: 0.015455294544062907\n",
            "----------------------------------------\n",
            "Epoch 42\n",
            "Var loss:  tensor(0.0151, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.016420745982184005\n",
            "E_s_wdiff_all_sq: 0.001303225480171744\n",
            "E_IS_SCOPE: -3.719972859653301e-07\n",
            "E_IS_E_SCOPE: -1.2056273848951452e-07\n",
            "Total Loss: 0.015117019533192059\n",
            "----------------------------------------\n",
            "Epoch 43\n",
            "Var loss:  tensor(0.0148, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.01576500741449024\n",
            "E_s_wdiff_all_sq: 0.0009415106538215532\n",
            "E_IS_SCOPE: -3.5853933490358923e-07\n",
            "E_IS_E_SCOPE: -1.1643066324927331e-07\n",
            "Total Loss: 0.01482301444360013\n",
            "----------------------------------------\n",
            "Epoch 44\n",
            "Var loss:  tensor(0.0145, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.015234540157521206\n",
            "E_s_wdiff_all_sq: 0.0006907269713655656\n",
            "E_IS_SCOPE: -3.0736108187771806e-07\n",
            "E_IS_E_SCOPE: -7.377243254886983e-08\n",
            "Total Loss: 0.014543347909131737\n",
            "----------------------------------------\n",
            "Epoch 45\n",
            "Var loss:  tensor(0.0143, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.014775702376684519\n",
            "E_s_wdiff_all_sq: 0.000515355339383985\n",
            "E_IS_SCOPE: -2.3301816794342082e-07\n",
            "E_IS_E_SCOPE: -7.519761420032742e-09\n",
            "Total Loss: 0.014259897940762241\n",
            "----------------------------------------\n",
            "Epoch 46\n",
            "Var loss:  tensor(0.0140, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.014392534465630536\n",
            "E_s_wdiff_all_sq: 0.00042761431519573815\n",
            "E_IS_SCOPE: -1.049192526817825e-07\n",
            "E_IS_E_SCOPE: 1.1335665116636626e-07\n",
            "Total Loss: 0.013964485498901856\n",
            "----------------------------------------\n",
            "Epoch 47\n",
            "Var loss:  tensor(0.0137, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.014067031877123798\n",
            "E_s_wdiff_all_sq: 0.00040057910337717485\n",
            "E_IS_SCOPE: 6.670478460470299e-08\n",
            "E_IS_E_SCOPE: 2.78495260210021e-07\n",
            "Total Loss: 0.013666031093070167\n",
            "----------------------------------------\n",
            "Epoch 48\n",
            "Var loss:  tensor(0.0134, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.013789714953882109\n",
            "E_s_wdiff_all_sq: 0.00041245234746356015\n",
            "E_IS_SCOPE: 2.673981181367783e-07\n",
            "E_IS_E_SCOPE: 4.7321575210973444e-07\n",
            "Total Loss: 0.013376852871425355\n",
            "----------------------------------------\n",
            "Epoch 49\n",
            "Var loss:  tensor(0.0131, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.013556134420975323\n",
            "E_s_wdiff_all_sq: 0.00044693663210773057\n",
            "E_IS_SCOPE: 4.837544551306583e-07\n",
            "E_IS_E_SCOPE: 6.838840547672098e-07\n",
            "Total Loss: 0.013108799429943073\n",
            "----------------------------------------\n",
            "Epoch 50\n",
            "Var loss:  tensor(0.0129, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.013344168280251149\n",
            "E_s_wdiff_all_sq: 0.00048146223359412635\n",
            "E_IS_SCOPE: 6.958703707207129e-07\n",
            "E_IS_E_SCOPE: 8.902933590755734e-07\n",
            "Total Loss: 0.012862319100955066\n",
            "----------------------------------------\n",
            "Epoch 51\n",
            "Var loss:  tensor(0.0126, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.013128497113832781\n",
            "E_s_wdiff_all_sq: 0.0004947913318387111\n",
            "E_IS_SCOPE: 8.819550360020273e-07\n",
            "E_IS_E_SCOPE: 1.07036226466189e-06\n",
            "Total Loss: 0.012633330867811505\n",
            "----------------------------------------\n",
            "Epoch 52\n",
            "Var loss:  tensor(0.0124, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.012888148026360948\n",
            "E_s_wdiff_all_sq: 0.00047671112836318146\n",
            "E_IS_SCOPE: 1.0334036262810518e-06\n",
            "E_IS_E_SCOPE: 1.2153569936101924e-06\n",
            "Total Loss: 0.012411074891537862\n",
            "----------------------------------------\n",
            "Epoch 53\n",
            "Var loss:  tensor(0.0122, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.012611285251020059\n",
            "E_s_wdiff_all_sq: 0.0004208746598268171\n",
            "E_IS_SCOPE: 1.1424879654273389e-06\n",
            "E_IS_E_SCOPE: 1.3173864995723452e-06\n",
            "Total Loss: 0.012190062694399706\n",
            "----------------------------------------\n",
            "Epoch 54\n",
            "Var loss:  tensor(0.0120, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.012293206601517117\n",
            "E_s_wdiff_all_sq: 0.00032659131231060353\n",
            "E_IS_SCOPE: 1.200809310645725e-06\n",
            "E_IS_E_SCOPE: 1.3680133678632635e-06\n",
            "Total Loss: 0.011966282781366832\n",
            "----------------------------------------\n",
            "Epoch 55\n",
            "Var loss:  tensor(0.0117, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.011953148298318882\n",
            "E_s_wdiff_all_sq: 0.00020929931751925048\n",
            "E_IS_SCOPE: 1.2111480021756202e-06\n",
            "E_IS_E_SCOPE: 1.370250048353744e-06\n",
            "Total Loss: 0.011743532676982029\n",
            "----------------------------------------\n",
            "Epoch 56\n",
            "Var loss:  tensor(0.0115, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.011645708295181655\n",
            "E_s_wdiff_all_sq: 0.00010824049892926428\n",
            "E_IS_SCOPE: 1.2012511809202424e-06\n",
            "E_IS_E_SCOPE: 1.3520291652705321e-06\n",
            "Total Loss: 0.011537168140558442\n",
            "----------------------------------------\n",
            "Epoch 57\n",
            "Var loss:  tensor(0.0113, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.011390184585635009\n",
            "E_s_wdiff_all_sq: 4.2006434280738924e-05\n",
            "E_IS_SCOPE: 1.1931914026906156e-06\n",
            "E_IS_E_SCOPE: 1.3357072338403815e-06\n",
            "Total Loss: 0.011347895019966723\n",
            "----------------------------------------\n",
            "Epoch 58\n",
            "Var loss:  tensor(0.0112, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.011182751502713443\n",
            "E_s_wdiff_all_sq: 1.0410333692265589e-05\n",
            "E_IS_SCOPE: 1.207172404805416e-06\n",
            "E_IS_E_SCOPE: 1.3418427795148682e-06\n",
            "Total Loss: 0.011172073728546512\n",
            "----------------------------------------\n",
            "Epoch 59\n",
            "Var loss:  tensor(0.0110, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.01100348079444672\n",
            "E_s_wdiff_all_sq: 9.079580379452349e-07\n",
            "E_IS_SCOPE: 1.2548485067268862e-06\n",
            "E_IS_E_SCOPE: 1.3822636411868356e-06\n",
            "Total Loss: 0.011002319906414608\n",
            "----------------------------------------\n",
            "Epoch 60\n",
            "Var loss:  tensor(0.0108, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.010836025698227928\n",
            "E_s_wdiff_all_sq: 1.3815001815035173e-07\n",
            "E_IS_SCOPE: 1.3363864376115195e-06\n",
            "E_IS_E_SCOPE: 1.4571433487103514e-06\n",
            "Total Loss: 0.010835647934662332\n",
            "----------------------------------------\n",
            "Epoch 61\n",
            "Var loss:  tensor(0.0107, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.010668746086285097\n",
            "E_s_wdiff_all_sq: 5.618208118544752e-07\n",
            "E_IS_SCOPE: 1.452084320592511e-06\n",
            "E_IS_E_SCOPE: 1.5668181991774236e-06\n",
            "Total Loss: 0.010667956697990828\n",
            "----------------------------------------\n",
            "Epoch 62\n",
            "Var loss:  tensor(0.0105, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.0105050270238876\n",
            "E_s_wdiff_all_sq: 2.0560060934047763e-07\n",
            "E_IS_SCOPE: 1.5908895916688176e-06\n",
            "E_IS_E_SCOPE: 1.7000739559691682e-06\n",
            "Total Loss: 0.010504604954824413\n",
            "----------------------------------------\n",
            "Epoch 63\n",
            "Var loss:  tensor(0.0104, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.010351152255609296\n",
            "E_s_wdiff_all_sq: 1.9453383284759797e-09\n",
            "E_IS_SCOPE: 1.73403924650792e-06\n",
            "E_IS_E_SCOPE: 1.8378746227886796e-06\n",
            "Total Loss: 0.01035094453979316\n",
            "----------------------------------------\n",
            "Epoch 64\n",
            "Var loss:  tensor(0.0102, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.010207433070852897\n",
            "E_s_wdiff_all_sq: 3.8801967234060255e-08\n",
            "E_IS_SCOPE: 1.8596894964328984e-06\n",
            "E_IS_E_SCOPE: 1.958050106032603e-06\n",
            "Total Loss: 0.010207199447941216\n",
            "----------------------------------------\n",
            "Epoch 65\n",
            "Var loss:  tensor(0.0101, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.010069114085118094\n",
            "E_s_wdiff_all_sq: 1.202498069755943e-07\n",
            "E_IS_SCOPE: 1.95333524059022e-06\n",
            "E_IS_E_SCOPE: 2.0459116797379765e-06\n",
            "Total Loss: 0.010068810582707578\n",
            "----------------------------------------\n",
            "Epoch 66\n",
            "Var loss:  tensor(0.0099, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.00993492218837907\n",
            "E_s_wdiff_all_sq: 3.1880861893030127e-06\n",
            "E_IS_SCOPE: 2.0069427726803724e-06\n",
            "E_IS_E_SCOPE: 2.093326725353096e-06\n",
            "Total Loss: 0.009931563234559175\n",
            "----------------------------------------\n",
            "Epoch 67\n",
            "Var loss:  tensor(0.0098, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.009812929052107218\n",
            "E_s_wdiff_all_sq: 1.6722923492097697e-05\n",
            "E_IS_SCOPE: 2.023164420470091e-06\n",
            "E_IS_E_SCOPE: 2.1029772945105716e-06\n",
            "Total Loss: 0.009796048403141792\n",
            "----------------------------------------\n",
            "Epoch 68\n",
            "Var loss:  tensor(0.0097, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.009718403173824651\n",
            "E_s_wdiff_all_sq: 4.805244770819048e-05\n",
            "E_IS_SCOPE: 2.010905888881555e-06\n",
            "E_IS_E_SCOPE: 2.0839336144940737e-06\n",
            "Total Loss: 0.00967020657093999\n",
            "----------------------------------------\n",
            "Epoch 69\n",
            "Var loss:  tensor(0.0096, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.009646690656586228\n",
            "E_s_wdiff_all_sq: 9.592515433326874e-05\n",
            "E_IS_SCOPE: 1.991218020249977e-06\n",
            "E_IS_E_SCOPE: 2.057533762100899e-06\n",
            "Total Loss: 0.00955063477104401\n",
            "----------------------------------------\n",
            "Epoch 70\n",
            "Var loss:  tensor(0.0094, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.00958774507183524\n",
            "E_s_wdiff_all_sq: 0.00015066772413066895\n",
            "E_IS_SCOPE: 1.98067809308604e-06\n",
            "E_IS_E_SCOPE: 2.040582687637834e-06\n",
            "Total Loss: 0.009436959438790223\n",
            "----------------------------------------\n",
            "Epoch 71\n",
            "Var loss:  tensor(0.0093, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.009517022312448793\n",
            "E_s_wdiff_all_sq: 0.00019145463698150625\n",
            "E_IS_SCOPE: 1.997583556408386e-06\n",
            "E_IS_E_SCOPE: 2.0515918204922955e-06\n",
            "Total Loss: 0.009325461559213872\n",
            "----------------------------------------\n",
            "Epoch 72\n",
            "Var loss:  tensor(0.0092, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.009418213695419123\n",
            "E_s_wdiff_all_sq: 0.00020742827477355716\n",
            "E_IS_SCOPE: 2.0459906089688907e-06\n",
            "E_IS_E_SCOPE: 2.0946950829359754e-06\n",
            "Total Loss: 0.009210689911972386\n",
            "----------------------------------------\n",
            "Epoch 73\n",
            "Var loss:  tensor(0.0091, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.00930921134127681\n",
            "E_s_wdiff_all_sq: 0.00020976405315419923\n",
            "E_IS_SCOPE: 2.1087619122286057e-06\n",
            "E_IS_E_SCOPE: 2.1525672249549158e-06\n",
            "Total Loss: 0.009099361577771912\n",
            "----------------------------------------\n",
            "Epoch 74\n",
            "Var loss:  tensor(0.0090, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.0091995964762784\n",
            "E_s_wdiff_all_sq: 0.00020638041314544842\n",
            "E_IS_SCOPE: 2.174446446355403e-06\n",
            "E_IS_E_SCOPE: 2.213590572456769e-06\n",
            "Total Loss: 0.008993139675155502\n",
            "----------------------------------------\n",
            "Epoch 75\n",
            "Var loss:  tensor(0.0089, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.009099993714022\n",
            "E_s_wdiff_all_sq: 0.00020799981881966122\n",
            "E_IS_SCOPE: 2.229414726698709e-06\n",
            "E_IS_E_SCOPE: 2.2638977190429157e-06\n",
            "Total Loss: 0.008891926829492403\n",
            "----------------------------------------\n",
            "Epoch 76\n",
            "Var loss:  tensor(0.0088, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.00901508851990273\n",
            "E_s_wdiff_all_sq: 0.00022232141393947887\n",
            "E_IS_SCOPE: 2.263489411115759e-06\n",
            "E_IS_E_SCOPE: 2.2931601150703357e-06\n",
            "Total Loss: 0.008792709664830095\n",
            "----------------------------------------\n",
            "Epoch 77\n",
            "Var loss:  tensor(0.0087, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008948379686704047\n",
            "E_s_wdiff_all_sq: 0.0002544096968894246\n",
            "E_IS_SCOPE: 2.27176921013607e-06\n",
            "E_IS_E_SCOPE: 2.296363760415371e-06\n",
            "Total Loss: 0.008693922700988817\n",
            "----------------------------------------\n",
            "Epoch 78\n",
            "Var loss:  tensor(0.0086, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008903714796784342\n",
            "E_s_wdiff_all_sq: 0.00030649060883905483\n",
            "E_IS_SCOPE: 2.255168584142636e-06\n",
            "E_IS_E_SCOPE: 2.2744780981584286e-06\n",
            "Total Loss: 0.008597187469192009\n",
            "----------------------------------------\n",
            "Epoch 79\n",
            "Var loss:  tensor(0.0085, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008873805120559361\n",
            "E_s_wdiff_all_sq: 0.00037051924468563816\n",
            "E_IS_SCOPE: 2.2279324486813705e-06\n",
            "E_IS_E_SCOPE: 2.2419142898709893e-06\n",
            "Total Loss: 0.008503259812466097\n",
            "----------------------------------------\n",
            "Epoch 80\n",
            "Var loss:  tensor(0.0084, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008848989949106278\n",
            "E_s_wdiff_all_sq: 0.0004372885365886362\n",
            "E_IS_SCOPE: 2.199943390433275e-06\n",
            "E_IS_E_SCOPE: 2.2087120864441973e-06\n",
            "Total Loss: 0.008411685775400373\n",
            "----------------------------------------\n",
            "Epoch 81\n",
            "Var loss:  tensor(0.0083, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008819390982655982\n",
            "E_s_wdiff_all_sq: 0.0004971544392122861\n",
            "E_IS_SCOPE: 2.179381013885778e-06\n",
            "E_IS_E_SCOPE: 2.1832001489248226e-06\n",
            "Total Loss: 0.008322230805448373\n",
            "----------------------------------------\n",
            "Epoch 82\n",
            "Var loss:  tensor(0.0082, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.00877775243334565\n",
            "E_s_wdiff_all_sq: 0.0005436831752453883\n",
            "E_IS_SCOPE: 2.1706706433754043e-06\n",
            "E_IS_E_SCOPE: 2.169872214253779e-06\n",
            "Total Loss: 0.008234072755233258\n",
            "----------------------------------------\n",
            "Epoch 83\n",
            "Var loss:  tensor(0.0081, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008722117012827362\n",
            "E_s_wdiff_all_sq: 0.0005755438795128182\n",
            "E_IS_SCOPE: 2.173043277642234e-06\n",
            "E_IS_E_SCOPE: 2.1679445469076365e-06\n",
            "Total Loss: 0.008146585231050767\n",
            "----------------------------------------\n",
            "Epoch 84\n",
            "Var loss:  tensor(0.0081, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.00865713397376764\n",
            "E_s_wdiff_all_sq: 0.0005968876700513027\n",
            "E_IS_SCOPE: 2.1812827323806136e-06\n",
            "E_IS_E_SCOPE: 2.1721280726982123e-06\n",
            "Total Loss: 0.008060266513310455\n",
            "----------------------------------------\n",
            "Epoch 85\n",
            "Var loss:  tensor(0.0080, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008591523021600633\n",
            "E_s_wdiff_all_sq: 0.0006160458063093296\n",
            "E_IS_SCOPE: 2.188087841227219e-06\n",
            "E_IS_E_SCOPE: 2.1750132367066322e-06\n",
            "Total Loss: 0.007975505264775098\n",
            "----------------------------------------\n",
            "Epoch 86\n",
            "Var loss:  tensor(0.0079, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008534388989960964\n",
            "E_s_wdiff_all_sq: 0.0006421742388989396\n",
            "E_IS_SCOPE: 2.1860096005905963e-06\n",
            "E_IS_E_SCOPE: 2.169041484994533e-06\n",
            "Total Loss: 0.00789225058756797\n",
            "----------------------------------------\n",
            "Epoch 87\n",
            "Var loss:  tensor(0.0078, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008495956476267847\n",
            "E_s_wdiff_all_sq: 0.0006836606500257036\n",
            "E_IS_SCOPE: 2.1685216007829194e-06\n",
            "E_IS_E_SCOPE: 2.147613013266405e-06\n",
            "Total Loss: 0.007812339543691931\n",
            "----------------------------------------\n",
            "Epoch 88\n",
            "Var loss:  tensor(0.0077, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008438616504133668\n",
            "E_s_wdiff_all_sq: 0.0007051137022769351\n",
            "E_IS_SCOPE: 2.162775627442828e-06\n",
            "E_IS_E_SCOPE: 2.138088171608812e-06\n",
            "Total Loss: 0.007733554077043155\n",
            "----------------------------------------\n",
            "Epoch 89\n",
            "Var loss:  tensor(0.0077, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008382767285299476\n",
            "E_s_wdiff_all_sq: 0.0007277951754567229\n",
            "E_IS_SCOPE: 2.1515679659045613e-06\n",
            "E_IS_E_SCOPE: 2.123148081443343e-06\n",
            "Total Loss: 0.00765503084988643\n",
            "----------------------------------------\n",
            "Epoch 90\n",
            "Var loss:  tensor(0.0076, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008350625449189129\n",
            "E_s_wdiff_all_sq: 0.0007734205879803565\n",
            "E_IS_SCOPE: 2.1242675411020434e-06\n",
            "E_IS_E_SCOPE: 2.0920589961909506e-06\n",
            "Total Loss: 0.007577271178573348\n",
            "----------------------------------------\n",
            "Epoch 91\n",
            "Var loss:  tensor(0.0075, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008338909341958117\n",
            "E_s_wdiff_all_sq: 0.0008377826568160024\n",
            "E_IS_SCOPE: 2.083992684941488e-06\n",
            "E_IS_E_SCOPE: 2.047999580028704e-06\n",
            "Total Loss: 0.0075012005716266926\n",
            "----------------------------------------\n",
            "Epoch 92\n",
            "Var loss:  tensor(0.0074, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008340456621861845\n",
            "E_s_wdiff_all_sq: 0.0009135643477882987\n",
            "E_IS_SCOPE: 2.037985537153975e-06\n",
            "E_IS_E_SCOPE: 1.9982779815977825e-06\n",
            "Total Loss: 0.0074269735894594135\n",
            "----------------------------------------\n",
            "Epoch 93\n",
            "Var loss:  tensor(0.0074, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008322226772457341\n",
            "E_s_wdiff_all_sq: 0.0009688195844378601\n",
            "E_IS_SCOPE: 2.003250075498307e-06\n",
            "E_IS_E_SCOPE: 1.960055877607679e-06\n",
            "Total Loss: 0.007353495476690015\n",
            "----------------------------------------\n",
            "Epoch 94\n",
            "Var loss:  tensor(0.0073, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.00829933268020982\n",
            "E_s_wdiff_all_sq: 0.0010186131999866516\n",
            "E_IS_SCOPE: 1.9726130296331335e-06\n",
            "E_IS_E_SCOPE: 1.9261336703498657e-06\n",
            "Total Loss: 0.007280814339216488\n",
            "----------------------------------------\n",
            "Epoch 95\n",
            "Var loss:  tensor(0.0072, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008268338222415501\n",
            "E_s_wdiff_all_sq: 0.0010597202431958793\n",
            "E_IS_SCOPE: 1.9476434350998863e-06\n",
            "E_IS_E_SCOPE: 1.8980991362425127e-06\n",
            "Total Loss: 0.007208718968092089\n",
            "----------------------------------------\n",
            "Epoch 96\n",
            "Var loss:  tensor(0.0071, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008228019505571805\n",
            "E_s_wdiff_all_sq: 0.0010901304783836638\n",
            "E_IS_SCOPE: 1.9285687496650107e-06\n",
            "E_IS_E_SCOPE: 1.8761760300814585e-06\n",
            "Total Loss: 0.0071379957129020614\n",
            "----------------------------------------\n",
            "Epoch 97\n",
            "Var loss:  tensor(0.0071, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008188059319690483\n",
            "E_s_wdiff_all_sq: 0.001119838593450259\n",
            "E_IS_SCOPE: 1.9086996121029974e-06\n",
            "E_IS_E_SCOPE: 1.8536047458625981e-06\n",
            "Total Loss: 0.007068332816247459\n",
            "----------------------------------------\n",
            "Epoch 98\n",
            "Var loss:  tensor(0.0070, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008131621464777009\n",
            "E_s_wdiff_all_sq: 0.001131341432804316\n",
            "E_IS_SCOPE: 1.8948996149661494e-06\n",
            "E_IS_E_SCOPE: 1.837261599497312e-06\n",
            "Total Loss: 0.007000397208278384\n",
            "----------------------------------------\n",
            "Epoch 99\n",
            "Var loss:  tensor(0.0069, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008091475457291983\n",
            "E_s_wdiff_all_sq: 0.001158503447014413\n",
            "E_IS_SCOPE: 1.8711429744163476e-06\n",
            "E_IS_E_SCOPE: 1.8109872176100253e-06\n",
            "Total Loss: 0.006933094222065936\n",
            "----------------------------------------\n",
            "Epoch 100\n",
            "Var loss:  tensor(0.0069, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008072609172742242\n",
            "E_s_wdiff_all_sq: 0.001206256147582139\n",
            "E_IS_SCOPE: 1.8349806167476927e-06\n",
            "E_IS_E_SCOPE: 1.7722987515428524e-06\n",
            "Total Loss: 0.006866480289165266\n",
            "----------------------------------------\n",
            "Epoch 101\n",
            "Var loss:  tensor(0.0068, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008046360764405952\n",
            "E_s_wdiff_all_sq: 0.0012457914777252535\n",
            "E_IS_SCOPE: 1.8007419374267148e-06\n",
            "E_IS_E_SCOPE: 1.7356187210704045e-06\n",
            "Total Loss: 0.006800701433388167\n",
            "----------------------------------------\n",
            "Epoch 102\n",
            "Var loss:  tensor(0.0067, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.008010073504638674\n",
            "E_s_wdiff_all_sq: 0.0012735504894248878\n",
            "E_IS_SCOPE: 1.7701676130225247e-06\n",
            "E_IS_E_SCOPE: 1.7027008319874566e-06\n",
            "Total Loss: 0.00673665984905061\n",
            "----------------------------------------\n",
            "Epoch 103\n",
            "Var loss:  tensor(0.0067, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.007982981601109865\n",
            "E_s_wdiff_all_sq: 0.0013100400272689976\n",
            "E_IS_SCOPE: 1.7361428319988846e-06\n",
            "E_IS_E_SCOPE: 1.6663933662575958e-06\n",
            "Total Loss: 0.006673082973047103\n",
            "----------------------------------------\n",
            "Epoch 104\n",
            "Var loss:  tensor(0.0066, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.007960983096211528\n",
            "E_s_wdiff_all_sq: 0.0013510410062976422\n",
            "E_IS_SCOPE: 1.7009924837652738e-06\n",
            "E_IS_E_SCOPE: 1.6290515038665392e-06\n",
            "Total Loss: 0.006610087872148437\n",
            "----------------------------------------\n",
            "Epoch 105\n",
            "Var loss:  tensor(0.0065, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.007941187348380688\n",
            "E_s_wdiff_all_sq: 0.0013928527068352817\n",
            "E_IS_SCOPE: 1.6666344370623034e-06\n",
            "E_IS_E_SCOPE: 1.5926054372174672e-06\n",
            "Total Loss: 0.0065484845998198486\n",
            "----------------------------------------\n",
            "Epoch 106\n",
            "Var loss:  tensor(0.0065, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.007929160114803062\n",
            "E_s_wdiff_all_sq: 0.0014414044496099986\n",
            "E_IS_SCOPE: 1.6310413009012685e-06\n",
            "E_IS_E_SCOPE: 1.5549824447389268e-06\n",
            "Total Loss: 0.006487909683180141\n",
            "----------------------------------------\n",
            "Epoch 107\n",
            "Var loss:  tensor(0.0064, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.007882529541872995\n",
            "E_s_wdiff_all_sq: 0.0014541886221567746\n",
            "E_IS_SCOPE: 1.6103684643082914e-06\n",
            "E_IS_E_SCOPE: 1.5324918873259775e-06\n",
            "Total Loss: 0.006428498573144939\n",
            "----------------------------------------\n",
            "Epoch 108\n",
            "Var loss:  tensor(0.0064, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.007828247810569958\n",
            "E_s_wdiff_all_sq: 0.001458003663583914\n",
            "E_IS_SCOPE: 1.5922409160034266e-06\n",
            "E_IS_E_SCOPE: 1.5126207297610886e-06\n",
            "Total Loss: 0.006370405287633282\n",
            "----------------------------------------\n",
            "Epoch 109\n",
            "Var loss:  tensor(0.0063, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.007774522355229317\n",
            "E_s_wdiff_all_sq: 0.001461459370749036\n",
            "E_IS_SCOPE: 1.573984608401368e-06\n",
            "E_IS_E_SCOPE: 1.492636922030676e-06\n",
            "Total Loss: 0.006313227580127775\n",
            "----------------------------------------\n",
            "Epoch 110\n",
            "Var loss:  tensor(0.0063, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.007729801544134302\n",
            "E_s_wdiff_all_sq: 0.0014730817657564001\n",
            "E_IS_SCOPE: 1.5511099301739699e-06\n",
            "E_IS_E_SCOPE: 1.4680061995190064e-06\n",
            "Total Loss: 0.006256887886113965\n",
            "----------------------------------------\n",
            "Epoch 111\n",
            "Var loss:  tensor(0.0062, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.007689218330536046\n",
            "E_s_wdiff_all_sq: 0.001488256669386754\n",
            "E_IS_SCOPE: 1.5268100435176147e-06\n",
            "E_IS_E_SCOPE: 1.4419294316260533e-06\n",
            "Total Loss: 0.006201133322647828\n",
            "----------------------------------------\n",
            "Epoch 112\n",
            "Var loss:  tensor(0.0061, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.00764986162838397\n",
            "E_s_wdiff_all_sq: 0.0015040386920734993\n",
            "E_IS_SCOPE: 1.5025672888491617e-06\n",
            "E_IS_E_SCOPE: 1.415909799266442e-06\n",
            "Total Loss: 0.006145998151564388\n",
            "----------------------------------------\n",
            "Epoch 113\n",
            "Var loss:  tensor(0.0061, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.007608384174394664\n",
            "E_s_wdiff_all_sq: 0.0015169963680661982\n",
            "E_IS_SCOPE: 1.4800542433381779e-06\n",
            "E_IS_E_SCOPE: 1.391650719518582e-06\n",
            "Total Loss: 0.006091566513650858\n",
            "----------------------------------------\n",
            "Epoch 114\n",
            "Var loss:  tensor(0.0060, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.007547147064110846\n",
            "E_s_wdiff_all_sq: 0.0015093571606669895\n",
            "E_IS_SCOPE: 1.4657493679299505e-06\n",
            "E_IS_E_SCOPE: 1.375752170910689e-06\n",
            "Total Loss: 0.006037971798112648\n",
            "----------------------------------------\n",
            "Epoch 115\n",
            "Var loss:  tensor(0.0060, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.00748462639294576\n",
            "E_s_wdiff_all_sq: 0.0014993438389927026\n",
            "E_IS_SCOPE: 1.452981223145976e-06\n",
            "E_IS_E_SCOPE: 1.361413219865486e-06\n",
            "Total Loss: 0.005985467590234371\n",
            "----------------------------------------\n",
            "Epoch 116\n",
            "Var loss:  tensor(0.0059, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.007415313631006333\n",
            "E_s_wdiff_all_sq: 0.0014812321668752466\n",
            "E_IS_SCOPE: 1.4441175696071432e-06\n",
            "E_IS_E_SCOPE: 1.3509423470563495e-06\n",
            "Total Loss: 0.0059342697148509396\n",
            "----------------------------------------\n",
            "Epoch 117\n",
            "Var loss:  tensor(0.0059, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.007356485457028489\n",
            "E_s_wdiff_all_sq: 0.001472739044274259\n",
            "E_IS_SCOPE: 1.4278485096937465e-06\n",
            "E_IS_E_SCOPE: 1.3329679244867772e-06\n",
            "Total Loss: 0.005883938074199397\n",
            "----------------------------------------\n",
            "Epoch 118\n",
            "Var loss:  tensor(0.0058, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.0073268216578304705\n",
            "E_s_wdiff_all_sq: 0.0014936613589037365\n",
            "E_IS_SCOPE: 1.3974716596526374e-06\n",
            "E_IS_E_SCOPE: 1.3007555661750458e-06\n",
            "Total Loss: 0.005833355631388442\n",
            "----------------------------------------\n",
            "Epoch 119\n",
            "Var loss:  tensor(0.0058, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.007294701334065443\n",
            "E_s_wdiff_all_sq: 0.0015098690749145154\n",
            "E_IS_SCOPE: 1.3686414240181257e-06\n",
            "E_IS_E_SCOPE: 1.2701327172619556e-06\n",
            "Total Loss: 0.005785031176839193\n",
            "----------------------------------------\n",
            "Epoch 120\n",
            "Var loss:  tensor(0.0057, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.007225942935946969\n",
            "E_s_wdiff_all_sq: 0.0014892553321432405\n",
            "E_IS_SCOPE: 1.3556778278444911e-06\n",
            "E_IS_E_SCOPE: 1.2556353493752482e-06\n",
            "Total Loss: 0.00573688958903542\n",
            "----------------------------------------\n",
            "Epoch 121\n",
            "Var loss:  tensor(0.0057, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.007152278539623219\n",
            "E_s_wdiff_all_sq: 0.0014628651594356874\n",
            "E_IS_SCOPE: 1.3461843768804664e-06\n",
            "E_IS_E_SCOPE: 1.2447528269742843e-06\n",
            "Total Loss: 0.005689618143562097\n",
            "----------------------------------------\n",
            "Epoch 122\n",
            "Var loss:  tensor(0.0056, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.007074413319081597\n",
            "E_s_wdiff_all_sq: 0.0014316689383678577\n",
            "E_IS_SCOPE: 1.3403322511287078e-06\n",
            "E_IS_E_SCOPE: 1.2376358346618868e-06\n",
            "Total Loss: 0.005642951673821426\n",
            "----------------------------------------\n",
            "Epoch 123\n",
            "Var loss:  tensor(0.0056, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.007000544982317966\n",
            "E_s_wdiff_all_sq: 0.0014038677994502034\n",
            "E_IS_SCOPE: 1.3335626127466436e-06\n",
            "E_IS_E_SCOPE: 1.2296538005665591e-06\n",
            "Total Loss: 0.005596886900766876\n",
            "----------------------------------------\n",
            "Epoch 124\n",
            "Var loss:  tensor(0.0056, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.006951674911733834\n",
            "E_s_wdiff_all_sq: 0.0014007879258936772\n",
            "E_IS_SCOPE: 1.3165956700811214e-06\n",
            "E_IS_E_SCOPE: 1.2113745842074228e-06\n",
            "Total Loss: 0.005551099328286657\n",
            "----------------------------------------\n",
            "Epoch 125\n",
            "Var loss:  tensor(0.0055, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.006910616518839402\n",
            "E_s_wdiff_all_sq: 0.001404698638286044\n",
            "E_IS_SCOPE: 1.2960562156893523e-06\n",
            "E_IS_E_SCOPE: 1.1895223380392421e-06\n",
            "Total Loss: 0.0055061328485834105\n",
            "----------------------------------------\n",
            "Epoch 126\n",
            "Var loss:  tensor(0.0055, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.0068463596398622316\n",
            "E_s_wdiff_all_sq: 0.0013858323463310847\n",
            "E_IS_SCOPE: 1.284891444488107e-06\n",
            "E_IS_E_SCOPE: 1.1771498437661987e-06\n",
            "Total Loss: 0.005460744677007343\n",
            "----------------------------------------\n",
            "Epoch 127\n",
            "Var loss:  tensor(0.0054, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.006770904359962036\n",
            "E_s_wdiff_all_sq: 0.0013540954745472522\n",
            "E_IS_SCOPE: 1.2781708719986338e-06\n",
            "E_IS_E_SCOPE: 1.1692739404065535e-06\n",
            "Total Loss: 0.005417028579552721\n",
            "----------------------------------------\n",
            "Epoch 128\n",
            "Var loss:  tensor(0.0054, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.006720479414765168\n",
            "E_s_wdiff_all_sq: 0.0013476359590089938\n",
            "E_IS_SCOPE: 1.2596155827891558e-06\n",
            "E_IS_E_SCOPE: 1.1494572489196661e-06\n",
            "Total Loss: 0.0053730656726986665\n",
            "----------------------------------------\n",
            "Epoch 129\n",
            "Var loss:  tensor(0.0053, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.0066869499611581845\n",
            "E_s_wdiff_all_sq: 0.001357977841158285\n",
            "E_IS_SCOPE: 1.2337182991687376e-06\n",
            "E_IS_E_SCOPE: 1.122249166794644e-06\n",
            "Total Loss: 0.0053291969585394\n",
            "----------------------------------------\n",
            "Epoch 130\n",
            "Var loss:  tensor(0.0053, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.0066629114468284316\n",
            "E_s_wdiff_all_sq: 0.0013770921206919784\n",
            "E_IS_SCOPE: 1.2058350823056723e-06\n",
            "E_IS_E_SCOPE: 1.0930828888053644e-06\n",
            "Total Loss: 0.005286046730798206\n",
            "----------------------------------------\n",
            "Epoch 131\n",
            "Var loss:  tensor(0.0052, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.006609913975435086\n",
            "E_s_wdiff_all_sq: 0.0013663212871194293\n",
            "E_IS_SCOPE: 1.194634791959628e-06\n",
            "E_IS_E_SCOPE: 1.0808221491119755e-06\n",
            "Total Loss: 0.005243822213876106\n",
            "----------------------------------------\n",
            "Epoch 132\n",
            "Var loss:  tensor(0.0052, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.0065137915671138955\n",
            "E_s_wdiff_all_sq: 0.001312693205911151\n",
            "E_IS_SCOPE: 1.2048009314342784e-06\n",
            "E_IS_E_SCOPE: 1.0902539980780411e-06\n",
            "Total Loss: 0.005201329355344209\n",
            "----------------------------------------\n",
            "Epoch 133\n",
            "Var loss:  tensor(0.0052, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.006441660412753178\n",
            "E_s_wdiff_all_sq: 0.0012820780833259875\n",
            "E_IS_SCOPE: 1.2050802100283971e-06\n",
            "E_IS_E_SCOPE: 1.0897147696042058e-06\n",
            "Total Loss: 0.005159814960582792\n",
            "----------------------------------------\n",
            "Epoch 134\n",
            "Var loss:  tensor(0.0051, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.006399931183514836\n",
            "E_s_wdiff_all_sq: 0.0012814043527221858\n",
            "E_IS_SCOPE: 1.191291880673237e-06\n",
            "E_IS_E_SCOPE: 1.0749311780345552e-06\n",
            "Total Loss: 0.00511876145247268\n",
            "----------------------------------------\n",
            "Epoch 135\n",
            "Var loss:  tensor(0.0051, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.006366413808944962\n",
            "E_s_wdiff_all_sq: 0.0012885176488628446\n",
            "E_IS_SCOPE: 1.1723458822767625e-06\n",
            "E_IS_E_SCOPE: 1.0548939970827308e-06\n",
            "Total Loss: 0.005078132964127257\n",
            "----------------------------------------\n",
            "Epoch 136\n",
            "Var loss:  tensor(0.0050, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.006312099861591627\n",
            "E_s_wdiff_all_sq: 0.0012743497244230239\n",
            "E_IS_SCOPE: 1.1625331872437664e-06\n",
            "E_IS_E_SCOPE: 1.0440762996815318e-06\n",
            "Total Loss: 0.005037988951218481\n",
            "----------------------------------------\n",
            "Epoch 137\n",
            "Var loss:  tensor(0.0050, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.006272489538555492\n",
            "E_s_wdiff_all_sq: 0.001274334701018714\n",
            "E_IS_SCOPE: 1.1463993019073197e-06\n",
            "E_IS_E_SCOPE: 1.0268739411575622e-06\n",
            "Total Loss: 0.004998395788533031\n",
            "----------------------------------------\n",
            "Epoch 138\n",
            "Var loss:  tensor(0.0050, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.006250096713026883\n",
            "E_s_wdiff_all_sq: 0.0012913969959237332\n",
            "E_IS_SCOPE: 1.123464539059661e-06\n",
            "E_IS_E_SCOPE: 1.0028174076336424e-06\n",
            "Total Loss: 0.004958942911640754\n",
            "----------------------------------------\n",
            "Epoch 139\n",
            "Var loss:  tensor(0.0049, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.0062359845645877056\n",
            "E_s_wdiff_all_sq: 0.0013154454564992138\n",
            "E_IS_SCOPE: 1.0995180758221853e-06\n",
            "E_IS_E_SCOPE: 9.777372472925195e-07\n",
            "Total Loss: 0.0049207845700203045\n",
            "----------------------------------------\n",
            "Epoch 140\n",
            "Var loss:  tensor(0.0049, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.006178405807424129\n",
            "E_s_wdiff_all_sq: 0.0012969492441318147\n",
            "E_IS_SCOPE: 1.0968729176095886e-06\n",
            "E_IS_E_SCOPE: 9.743265119429493e-07\n",
            "Total Loss: 0.0048817035563784\n",
            "----------------------------------------\n",
            "Epoch 141\n",
            "Var loss:  tensor(0.0048, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.006100416668453988\n",
            "E_s_wdiff_all_sq: 0.0012561137516923717\n",
            "E_IS_SCOPE: 1.1040868061173614e-06\n",
            "E_IS_E_SCOPE: 9.809455442584906e-07\n",
            "Total Loss: 0.004844551099560087\n",
            "----------------------------------------\n",
            "Epoch 142\n",
            "Var loss:  tensor(0.0048, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.006045040778288479\n",
            "E_s_wdiff_all_sq: 0.0012373447039182677\n",
            "E_IS_SCOPE: 1.1001374816064936e-06\n",
            "E_IS_E_SCOPE: 9.762659299457236e-07\n",
            "Total Loss: 0.0048079457177482845\n",
            "----------------------------------------\n",
            "Epoch 143\n",
            "Var loss:  tensor(0.0048, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.006029664292706384\n",
            "E_s_wdiff_all_sq: 0.0012589130266997526\n",
            "E_IS_SCOPE: 1.0756739584144667e-06\n",
            "E_IS_E_SCOPE: 9.508580890478709e-07\n",
            "Total Loss: 0.004771002798020117\n",
            "----------------------------------------\n",
            "Epoch 144\n",
            "Var loss:  tensor(0.0047, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.006030931833783016\n",
            "E_s_wdiff_all_sq: 0.0012969954327172988\n",
            "E_IS_SCOPE: 1.0460167265358186e-06\n",
            "E_IS_E_SCOPE: 9.202104105541383e-07\n",
            "Total Loss: 0.004734189913972433\n",
            "----------------------------------------\n",
            "Epoch 145\n",
            "Var loss:  tensor(0.0047, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.006024382087127848\n",
            "E_s_wdiff_all_sq: 0.0013268896348691112\n",
            "E_IS_SCOPE: 1.0253406143075266e-06\n",
            "E_IS_E_SCOPE: 8.986220157935793e-07\n",
            "Total Loss: 0.0046977477897305175\n",
            "----------------------------------------\n",
            "Epoch 146\n",
            "Var loss:  tensor(0.0047, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.006003590182129443\n",
            "E_s_wdiff_all_sq: 0.0013411004233950558\n",
            "E_IS_SCOPE: 1.0172971018529609e-06\n",
            "E_IS_E_SCOPE: 8.898543808519225e-07\n",
            "Total Loss: 0.004662746544451142\n",
            "----------------------------------------\n",
            "Epoch 147\n",
            "Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005932188363824686\n",
            "E_s_wdiff_all_sq: 0.001304873581964718\n",
            "E_IS_SCOPE: 1.0351949278007678e-06\n",
            "E_IS_E_SCOPE: 9.074548383172794e-07\n",
            "Total Loss: 0.0046275721623136885\n",
            "----------------------------------------\n",
            "Epoch 148\n",
            "Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005847017980544554\n",
            "E_s_wdiff_all_sq: 0.0012545165979354071\n",
            "E_IS_SCOPE: 1.058325729658441e-06\n",
            "E_IS_E_SCOPE: 9.304037679667907e-07\n",
            "Total Loss: 0.0045927591268072835\n",
            "----------------------------------------\n",
            "Epoch 149\n",
            "Var loss:  tensor(0.0046, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.0057864792047962665\n",
            "E_s_wdiff_all_sq: 0.0012280846619330378\n",
            "E_IS_SCOPE: 1.0638555298258055e-06\n",
            "E_IS_E_SCOPE: 9.355511779591883e-07\n",
            "Total Loss: 0.004558653051841714\n",
            "----------------------------------------\n",
            "Epoch 150\n",
            "Var loss:  tensor(0.0045, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005775198157417325\n",
            "E_s_wdiff_all_sq: 0.0012511988495153249\n",
            "E_IS_SCOPE: 1.0392389072007122e-06\n",
            "E_IS_E_SCOPE: 9.100855669703931e-07\n",
            "Total Loss: 0.004524259514857214\n",
            "----------------------------------------\n",
            "Epoch 151\n",
            "Var loss:  tensor(0.0045, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005806709020051685\n",
            "E_s_wdiff_all_sq: 0.001316670237545853\n",
            "E_IS_SCOPE: 9.928177515809362e-07\n",
            "E_IS_E_SCOPE: 8.624680672708002e-07\n",
            "Total Loss: 0.004490301382149205\n",
            "----------------------------------------\n",
            "Epoch 152\n",
            "Var loss:  tensor(0.0045, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005835706223027883\n",
            "E_s_wdiff_all_sq: 0.0013779019380111789\n",
            "E_IS_SCOPE: 9.526219224088915e-07\n",
            "E_IS_E_SCOPE: 8.212133337724664e-07\n",
            "Total Loss: 0.0044580690024687295\n",
            "----------------------------------------\n",
            "Epoch 153\n",
            "Var loss:  tensor(0.0044, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.00580564321532073\n",
            "E_s_wdiff_all_sq: 0.001380680863311377\n",
            "E_IS_SCOPE: 9.450948906026216e-07\n",
            "E_IS_E_SCOPE: 8.131769960039123e-07\n",
            "Total Loss: 0.004425228088073304\n",
            "----------------------------------------\n",
            "Epoch 154\n",
            "Var loss:  tensor(0.0044, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.00571764488842596\n",
            "E_s_wdiff_all_sq: 0.001326188853642343\n",
            "E_IS_SCOPE: 9.703379517381517e-07\n",
            "E_IS_E_SCOPE: 8.384405073264432e-07\n",
            "Total Loss: 0.004391721729947193\n",
            "----------------------------------------\n",
            "Epoch 155\n",
            "Var loss:  tensor(0.0044, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005616803859623317\n",
            "E_s_wdiff_all_sq: 0.001257354041170326\n",
            "E_IS_SCOPE: 1.004380804212145e-06\n",
            "E_IS_E_SCOPE: 8.726444675556512e-07\n",
            "Total Loss: 0.004359715191401057\n",
            "----------------------------------------\n",
            "Epoch 156\n",
            "Var loss:  tensor(0.0043, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005562133315554134\n",
            "E_s_wdiff_all_sq: 0.0012343110226743735\n",
            "E_IS_SCOPE: 1.0140942655088695e-06\n",
            "E_IS_E_SCOPE: 8.821420197532515e-07\n",
            "Total Loss: 0.004328088097646024\n",
            "----------------------------------------\n",
            "Epoch 157\n",
            "Var loss:  tensor(0.0043, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005548745523510721\n",
            "E_s_wdiff_all_sq: 0.0012529292381400921\n",
            "E_IS_SCOPE: 9.978248504623217e-07\n",
            "E_IS_E_SCOPE: 8.652371128870706e-07\n",
            "Total Loss: 0.004296083361120532\n",
            "----------------------------------------\n",
            "Epoch 158\n",
            "Var loss:  tensor(0.0043, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005559204012189817\n",
            "E_s_wdiff_all_sq: 0.001294855830239539\n",
            "E_IS_SCOPE: 9.67086012070673e-07\n",
            "E_IS_E_SCOPE: 8.336320146194316e-07\n",
            "Total Loss: 0.0042646169902199335\n",
            "----------------------------------------\n",
            "Epoch 159\n",
            "Var loss:  tensor(0.0042, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005557752326399675\n",
            "E_s_wdiff_all_sq: 0.0013233540527439747\n",
            "E_IS_SCOPE: 9.442048266983648e-07\n",
            "E_IS_E_SCOPE: 8.100140388094933e-07\n",
            "Total Loss: 0.00423466855550623\n",
            "----------------------------------------\n",
            "Epoch 160\n",
            "Var loss:  tensor(0.0042, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005518625580161883\n",
            "E_s_wdiff_all_sq: 0.0013142774805072405\n",
            "E_IS_SCOPE: 9.431347576064318e-07\n",
            "E_IS_E_SCOPE: 8.085636947515616e-07\n",
            "Total Loss: 0.004204619142055104\n",
            "----------------------------------------\n",
            "Epoch 161\n",
            "Var loss:  tensor(0.0042, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005446060910532108\n",
            "E_s_wdiff_all_sq: 0.0012717598974359254\n",
            "E_IS_SCOPE: 9.607231528934881e-07\n",
            "E_IS_E_SCOPE: 8.260958306385952e-07\n",
            "Total Loss: 0.004174572168015445\n",
            "----------------------------------------\n",
            "Epoch 162\n",
            "Var loss:  tensor(0.0041, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005368492280207882\n",
            "E_s_wdiff_all_sq: 0.001223253442569503\n",
            "E_IS_SCOPE: 9.773930772689486e-07\n",
            "E_IS_E_SCOPE: 8.42734566980901e-07\n",
            "Total Loss: 0.004145510054933708\n",
            "----------------------------------------\n",
            "Epoch 163\n",
            "Var loss:  tensor(0.0041, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005326084894938203\n",
            "E_s_wdiff_all_sq: 0.0012090980387912406\n",
            "E_IS_SCOPE: 9.760191229215644e-07\n",
            "E_IS_E_SCOPE: 8.410903289034203e-07\n",
            "Total Loss: 0.004117258614009752\n",
            "----------------------------------------\n",
            "Epoch 164\n",
            "Var loss:  tensor(0.0041, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005321481684160546\n",
            "E_s_wdiff_all_sq: 0.001232679512619521\n",
            "E_IS_SCOPE: 9.531446000280616e-07\n",
            "E_IS_E_SCOPE: 8.175631466880593e-07\n",
            "Total Loss: 0.004089075234722459\n",
            "----------------------------------------\n",
            "Epoch 165\n",
            "Var loss:  tensor(0.0041, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005334680552508796\n",
            "E_s_wdiff_all_sq: 0.0012729881376299537\n",
            "E_IS_SCOPE: 9.213696238139901e-07\n",
            "E_IS_E_SCOPE: 7.849510235024732e-07\n",
            "Total Loss: 0.004061967152354218\n",
            "----------------------------------------\n",
            "Epoch 166\n",
            "Var loss:  tensor(0.0040, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005318466179485129\n",
            "E_s_wdiff_all_sq: 0.0012836492597140473\n",
            "E_IS_SCOPE: 9.052685418127412e-07\n",
            "E_IS_E_SCOPE: 7.682247034172523e-07\n",
            "Total Loss: 0.004035092907722625\n",
            "----------------------------------------\n",
            "Epoch 167\n",
            "Var loss:  tensor(0.0040, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005264425101702584\n",
            "E_s_wdiff_all_sq: 0.0012566894794211387\n",
            "E_IS_SCOPE: 9.094188369113313e-07\n",
            "E_IS_E_SCOPE: 7.720420052833662e-07\n",
            "Total Loss: 0.004008012276219454\n",
            "----------------------------------------\n",
            "Epoch 168\n",
            "Var loss:  tensor(0.0040, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005193052441715927\n",
            "E_s_wdiff_all_sq: 0.0012119403957072095\n",
            "E_IS_SCOPE: 9.228597256264463e-07\n",
            "E_IS_E_SCOPE: 7.852754751720164e-07\n",
            "Total Loss: 0.00398138911478438\n",
            "----------------------------------------\n",
            "Epoch 169\n",
            "Var loss:  tensor(0.0040, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005134882069096538\n",
            "E_s_wdiff_all_sq: 0.0011801184221524466\n",
            "E_IS_SCOPE: 9.268569701980983e-07\n",
            "E_IS_E_SCOPE: 7.889318019898651e-07\n",
            "Total Loss: 0.00395504139755526\n",
            "----------------------------------------\n",
            "Epoch 170\n",
            "Var loss:  tensor(0.0039, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005098758882083571\n",
            "E_s_wdiff_all_sq: 0.0011703966543161178\n",
            "E_IS_SCOPE: 9.166515621243388e-07\n",
            "E_IS_E_SCOPE: 7.781152696345467e-07\n",
            "Total Loss: 0.003928641200627186\n",
            "----------------------------------------\n",
            "Epoch 171\n",
            "Var loss:  tensor(0.0039, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005078734428481101\n",
            "E_s_wdiff_all_sq: 0.0011764447434115851\n",
            "E_IS_SCOPE: 8.959611941256223e-07\n",
            "E_IS_E_SCOPE: 7.566057236142552e-07\n",
            "Total Loss: 0.0039025702962852907\n",
            "----------------------------------------\n",
            "Epoch 172\n",
            "Var loss:  tensor(0.0039, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005067777516373937\n",
            "E_s_wdiff_all_sq: 0.0011910896128824598\n",
            "E_IS_SCOPE: 8.715901871625362e-07\n",
            "E_IS_E_SCOPE: 7.313480148413162e-07\n",
            "Total Loss: 0.003876970288110873\n",
            "----------------------------------------\n",
            "Epoch 173\n",
            "Var loss:  tensor(0.0039, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.005041734322092077\n",
            "E_s_wdiff_all_sq: 0.0011904918142149462\n",
            "E_IS_SCOPE: 8.580975759760437e-07\n",
            "E_IS_E_SCOPE: 7.17141540871298e-07\n",
            "Total Loss: 0.003851526320222093\n",
            "----------------------------------------\n",
            "Epoch 174\n",
            "Var loss:  tensor(0.0038, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004995700770393556\n",
            "E_s_wdiff_all_sq: 0.0011699683128826666\n",
            "E_IS_SCOPE: 8.575884887187991e-07\n",
            "E_IS_E_SCOPE: 7.161439977385609e-07\n",
            "Total Loss: 0.003826017246767602\n",
            "----------------------------------------\n",
            "Epoch 175\n",
            "Var loss:  tensor(0.0038, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004942487627150221\n",
            "E_s_wdiff_all_sq: 0.001141972813686249\n",
            "E_IS_SCOPE: 8.626024070203891e-07\n",
            "E_IS_E_SCOPE: 7.207700224896264e-07\n",
            "Total Loss: 0.003800800378507786\n",
            "----------------------------------------\n",
            "Epoch 176\n",
            "Var loss:  tensor(0.0038, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004889388032648047\n",
            "E_s_wdiff_all_sq: 0.0011137203007227888\n",
            "E_IS_SCOPE: 8.668604604543136e-07\n",
            "E_IS_E_SCOPE: 7.246127747364586e-07\n",
            "Total Loss: 0.0037759541275714462\n",
            "----------------------------------------\n",
            "Epoch 177\n",
            "Var loss:  tensor(0.0038, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004851455578606807\n",
            "E_s_wdiff_all_sq: 0.0011006254558783525\n",
            "E_IS_SCOPE: 8.608900150070084e-07\n",
            "E_IS_E_SCOPE: 7.18033795434341e-07\n",
            "Total Loss: 0.003751117735442353\n",
            "----------------------------------------\n",
            "Epoch 178\n",
            "Var loss:  tensor(0.0037, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004831378697673755\n",
            "E_s_wdiff_all_sq: 0.0011051875617490872\n",
            "E_IS_SCOPE: 8.426187659234638e-07\n",
            "E_IS_E_SCOPE: 6.989407859613245e-07\n",
            "Total Loss: 0.003726480392159345\n",
            "----------------------------------------\n",
            "Epoch 179\n",
            "Var loss:  tensor(0.0037, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.0048249035947001894\n",
            "E_s_wdiff_all_sq: 0.0011231388540928254\n",
            "E_IS_SCOPE: 8.172766048711727e-07\n",
            "E_IS_E_SCOPE: 6.726684801074345e-07\n",
            "Total Loss: 0.0037020558571316444\n",
            "----------------------------------------\n",
            "Epoch 180\n",
            "Var loss:  tensor(0.0037, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004810112711160102\n",
            "E_s_wdiff_all_sq: 0.0011325047064383992\n",
            "E_IS_SCOPE: 7.984570469702854e-07\n",
            "E_IS_E_SCOPE: 6.530426608695024e-07\n",
            "Total Loss: 0.0036779007337686574\n",
            "----------------------------------------\n",
            "Epoch 181\n",
            "Var loss:  tensor(0.0037, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004764548128711829\n",
            "E_s_wdiff_all_sq: 0.0011112316521693622\n",
            "E_IS_SCOPE: 7.97640404429613e-07\n",
            "E_IS_E_SCOPE: 6.517311229947027e-07\n",
            "Total Loss: 0.003653610195380089\n",
            "----------------------------------------\n",
            "Epoch 182\n",
            "Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004712310194641897\n",
            "E_s_wdiff_all_sq: 0.0010828972227594448\n",
            "E_IS_SCOPE: 8.024652665894328e-07\n",
            "E_IS_E_SCOPE: 6.561677301145933e-07\n",
            "Total Loss: 0.003629707467230155\n",
            "----------------------------------------\n",
            "Epoch 183\n",
            "Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.0046709069476284885\n",
            "E_s_wdiff_all_sq: 0.0010651705965772271\n",
            "E_IS_SCOPE: 8.01668018823555e-07\n",
            "E_IS_E_SCOPE: 6.548995988544426e-07\n",
            "Total Loss: 0.003606031788165953\n",
            "----------------------------------------\n",
            "Epoch 184\n",
            "Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.0046494355893586135\n",
            "E_s_wdiff_all_sq: 0.0010672905028057899\n",
            "E_IS_SCOPE: 7.889046296089398e-07\n",
            "E_IS_E_SCOPE: 6.41476588797913e-07\n",
            "Total Loss: 0.003582441842909198\n",
            "----------------------------------------\n",
            "Epoch 185\n",
            "Var loss:  tensor(0.0036, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.0046349041007615515\n",
            "E_s_wdiff_all_sq: 0.0010762206752812865\n",
            "E_IS_SCOPE: 7.697467985990959e-07\n",
            "E_IS_E_SCOPE: 6.2156329711649e-07\n",
            "Total Loss: 0.003558981692757982\n",
            "----------------------------------------\n",
            "Epoch 186\n",
            "Var loss:  tensor(0.0035, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004609581304227192\n",
            "E_s_wdiff_all_sq: 0.0010741162147654528\n",
            "E_IS_SCOPE: 7.566114774605808e-07\n",
            "E_IS_E_SCOPE: 6.07784845230346e-07\n",
            "Total Loss: 0.0035357646430009522\n",
            "----------------------------------------\n",
            "Epoch 187\n",
            "Var loss:  tensor(0.0035, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004576704808092104\n",
            "E_s_wdiff_all_sq: 0.0010642753377744089\n",
            "E_IS_SCOPE: 7.485972758357742e-07\n",
            "E_IS_E_SCOPE: 5.992416780840037e-07\n",
            "Total Loss: 0.003512730081787951\n",
            "----------------------------------------\n",
            "Epoch 188\n",
            "Var loss:  tensor(0.0035, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004536206148322164\n",
            "E_s_wdiff_all_sq: 0.0010466724343208987\n",
            "E_IS_SCOPE: 7.467388651630075e-07\n",
            "E_IS_E_SCOPE: 5.969592894551453e-07\n",
            "Total Loss: 0.003489835173427433\n",
            "----------------------------------------\n",
            "Epoch 189\n",
            "Var loss:  tensor(0.0035, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004498236491801987\n",
            "E_s_wdiff_all_sq: 0.0010314592779661997\n",
            "E_IS_SCOPE: 7.441602339296764e-07\n",
            "E_IS_E_SCOPE: 5.939615051099517e-07\n",
            "Total Loss: 0.00346707951156818\n",
            "----------------------------------------\n",
            "Epoch 190\n",
            "Var loss:  tensor(0.0034, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004468924180444248\n",
            "E_s_wdiff_all_sq: 0.001024723811763508\n",
            "E_IS_SCOPE: 7.368173174951087e-07\n",
            "E_IS_E_SCOPE: 5.861297242028363e-07\n",
            "Total Loss: 0.003444503644142078\n",
            "----------------------------------------\n",
            "Epoch 191\n",
            "Var loss:  tensor(0.0034, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004448983925283799\n",
            "E_s_wdiff_all_sq: 0.0010271130909300162\n",
            "E_IS_SCOPE: 7.242571222734109e-07\n",
            "E_IS_E_SCOPE: 5.729302937282573e-07\n",
            "Total Loss: 0.003422175388285626\n",
            "----------------------------------------\n",
            "Epoch 192\n",
            "Var loss:  tensor(0.0034, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004423233194831453\n",
            "E_s_wdiff_all_sq: 0.0010232874800201837\n",
            "E_IS_SCOPE: 7.149746002165773e-07\n",
            "E_IS_E_SCOPE: 5.628919936941227e-07\n",
            "Total Loss: 0.0034002517802990675\n",
            "----------------------------------------\n",
            "Epoch 193\n",
            "Var loss:  tensor(0.0034, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004389443386687223\n",
            "E_s_wdiff_all_sq: 0.001011307603792663\n",
            "E_IS_SCOPE: 7.101616689289592e-07\n",
            "E_IS_E_SCOPE: 5.573902690416607e-07\n",
            "Total Loss: 0.0033784432259690873\n",
            "----------------------------------------\n",
            "Epoch 194\n",
            "Var loss:  tensor(0.0034, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004359353417463506\n",
            "E_s_wdiff_all_sq: 0.0010028278609429215\n",
            "E_IS_SCOPE: 7.039567721772232e-07\n",
            "E_IS_E_SCOPE: 5.504752838751707e-07\n",
            "Total Loss: 0.0033568344197719424\n",
            "----------------------------------------\n",
            "Epoch 195\n",
            "Var loss:  tensor(0.0033, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.00433250644488849\n",
            "E_s_wdiff_all_sq: 0.0009974266834676922\n",
            "E_IS_SCOPE: 6.961567879279808e-07\n",
            "E_IS_E_SCOPE: 5.419506713140584e-07\n",
            "Total Loss: 0.0033353900739287777\n",
            "----------------------------------------\n",
            "Epoch 196\n",
            "Var loss:  tensor(0.0033, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004307191150940204\n",
            "E_s_wdiff_all_sq: 0.0009934225166424882\n",
            "E_IS_SCOPE: 6.88138711898242e-07\n",
            "E_IS_E_SCOPE: 5.3321454970314e-07\n",
            "Total Loss: 0.003314080382896859\n",
            "----------------------------------------\n",
            "Epoch 197\n",
            "Var loss:  tensor(0.0033, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004281452467245057\n",
            "E_s_wdiff_all_sq: 0.0009888347871489878\n",
            "E_IS_SCOPE: 6.811485412985601e-07\n",
            "E_IS_E_SCOPE: 5.255322502037095e-07\n",
            "Total Loss: 0.003292930812953011\n",
            "----------------------------------------\n",
            "Epoch 198\n",
            "Var loss:  tensor(0.0033, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004254658478690678\n",
            "E_s_wdiff_all_sq: 0.0009830391035873592\n",
            "E_IS_SCOPE: 6.754693697462542e-07\n",
            "E_IS_E_SCOPE: 5.191929017375946e-07\n",
            "Total Loss: 0.0032719338283140886\n",
            "----------------------------------------\n",
            "Epoch 199\n",
            "Var loss:  tensor(0.0033, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004227576518762368\n",
            "E_s_wdiff_all_sq: 0.0009768376099179945\n",
            "E_IS_SCOPE: 6.705222658861819e-07\n",
            "E_IS_E_SCOPE: 5.136074783411824e-07\n",
            "Total Loss: 0.0032510546386942166\n",
            "----------------------------------------\n",
            "Epoch 200\n",
            "Var loss:  tensor(0.0032, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.826645974121427e-09\n",
            "E_IS_all_sq: 1.9263712212949065e-09\n",
            "E_s_wdiff_sq: 0.004201757957507674\n",
            "E_s_wdiff_all_sq: 0.00097174064474578\n",
            "E_IS_SCOPE: 6.652389060076409e-07\n",
            "E_IS_E_SCOPE: 5.077035404547203e-07\n",
            "Total Loss: 0.003230334283767753\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[-0.1982, -0.5572],\n",
            "        [-0.1966,  0.6373],\n",
            "        [-0.1872,  0.6034],\n",
            "        [ 0.2048,  0.2073],\n",
            "        [ 0.0360,  0.0917],\n",
            "        [-0.5381, -0.2891],\n",
            "        [ 0.4075,  0.6089],\n",
            "        [-0.0640,  0.5867],\n",
            "        [-0.4904,  0.6757],\n",
            "        [ 0.4426, -0.2146],\n",
            "        [-0.0742, -0.5438],\n",
            "        [ 0.5966, -0.7549],\n",
            "        [ 0.5963, -0.2325],\n",
            "        [-0.2952,  0.0108],\n",
            "        [ 0.1167, -0.6869],\n",
            "        [ 0.1609, -0.6295]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([ 0.6531, -0.2189, -0.6595, -0.4758,  0.1414, -0.0896, -0.4736, -0.6275,\n",
            "        -0.2590, -0.2865, -0.0873,  0.2530, -0.1865,  0.3412, -0.6498, -0.2523],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[-0.1546, -0.0545, -0.0697, -0.0867, -0.0794, -0.2138, -0.2200,  0.0882,\n",
            "         -0.0215,  0.0129,  0.0420,  0.1505,  0.1874,  0.1642, -0.2323, -0.0318],\n",
            "        [ 0.0802,  0.0086, -0.0644, -0.1551,  0.1024, -0.0680, -0.0411, -0.1347,\n",
            "         -0.1220,  0.1177, -0.0411, -0.1531,  0.0137,  0.0704,  0.0098,  0.0463],\n",
            "        [-0.1535, -0.2394,  0.1020,  0.1508,  0.2561,  0.0950,  0.1881, -0.0211,\n",
            "         -0.1755,  0.2078, -0.1304,  0.1400,  0.0854, -0.1028, -0.0756,  0.0118],\n",
            "        [ 0.1521,  0.1843,  0.1161, -0.1471, -0.2114, -0.0303,  0.2202,  0.0156,\n",
            "          0.2065,  0.0229, -0.0116, -0.1288, -0.1105, -0.1625,  0.2154,  0.2138],\n",
            "        [ 0.0022,  0.0768, -0.0332,  0.2388,  0.2647,  0.0675,  0.1308,  0.1305,\n",
            "         -0.2184, -0.0698, -0.1668, -0.1146, -0.0992,  0.0173,  0.0410,  0.0983],\n",
            "        [ 0.0632, -0.1089, -0.0067, -0.2158, -0.2066,  0.1576,  0.0614,  0.1457,\n",
            "         -0.2282,  0.0700, -0.1871, -0.1209,  0.1555,  0.0320, -0.0318,  0.2479],\n",
            "        [-0.2332, -0.1246,  0.2135,  0.1455,  0.1984, -0.1430,  0.2140,  0.1744,\n",
            "         -0.1596, -0.0706,  0.2149,  0.1696, -0.1465,  0.0323, -0.1672,  0.0926],\n",
            "        [ 0.1089,  0.1670, -0.2249, -0.2189,  0.1179, -0.0113, -0.0678,  0.2028,\n",
            "         -0.1757,  0.0023, -0.0385,  0.1358, -0.1601, -0.0097,  0.1769, -0.2432],\n",
            "        [-0.0463,  0.1378, -0.0290,  0.0715,  0.1556, -0.0367,  0.1482, -0.1757,\n",
            "         -0.1539, -0.1673, -0.0841,  0.0339,  0.2838,  0.1859,  0.2242,  0.2398],\n",
            "        [ 0.1387,  0.1727,  0.2009,  0.0136, -0.1266,  0.1731, -0.2164,  0.1936,\n",
            "         -0.0926,  0.1236, -0.0625, -0.2264, -0.4129, -0.1619, -0.1795, -0.0079],\n",
            "        [-0.0399,  0.1163,  0.1206, -0.1231,  0.1247, -0.0755, -0.2203,  0.1003,\n",
            "          0.0034, -0.0572,  0.1353, -0.0008, -0.2254, -0.2079, -0.1988, -0.1142],\n",
            "        [ 0.0976,  0.0315,  0.0430, -0.0254, -0.1001,  0.2371, -0.1523, -0.2132,\n",
            "          0.1539, -0.0044,  0.0943,  0.0544,  0.1760, -0.1598, -0.0526, -0.2768],\n",
            "        [ 0.0351,  0.0720, -0.0836,  0.1628, -0.0845, -0.0819,  0.1836, -0.2252,\n",
            "         -0.1398, -0.0636, -0.1314,  0.1209, -0.2052,  0.1925,  0.1158, -0.1535],\n",
            "        [ 0.0212,  0.1279, -0.1914,  0.1408,  0.0490,  0.0389,  0.0423, -0.0826,\n",
            "          0.2231,  0.0557,  0.0821,  0.2298,  0.2168, -0.2212,  0.0398,  0.2307],\n",
            "        [-0.0565, -0.0334, -0.0393,  0.1867,  0.0327,  0.0709, -0.1260, -0.0740,\n",
            "         -0.0886, -0.2016,  0.2351,  0.2023, -0.0943,  0.0312,  0.2274, -0.0230],\n",
            "        [-0.1809,  0.1610, -0.1408, -0.1244,  0.1742,  0.0923, -0.2062,  0.2557,\n",
            "         -0.2121, -0.0775,  0.2405,  0.2165,  0.1261,  0.2476,  0.1001, -0.1018],\n",
            "        [-0.0192,  0.0173,  0.1256, -0.0156, -0.0270,  0.0490, -0.0512,  0.0649,\n",
            "         -0.1934, -0.1255,  0.0803, -0.1295, -0.1560,  0.0079,  0.0418,  0.2188],\n",
            "        [-0.2111,  0.1921,  0.2242,  0.0515, -0.0755,  0.1394,  0.1820, -0.1806,\n",
            "         -0.0030, -0.1068,  0.2356,  0.0478, -0.1334, -0.1540, -0.0214, -0.0463],\n",
            "        [ 0.0334, -0.1430, -0.0417, -0.2481, -0.1653,  0.2342,  0.0070,  0.0118,\n",
            "         -0.2491, -0.0443, -0.0636, -0.0087,  0.0592,  0.1518,  0.2170, -0.0180],\n",
            "        [ 0.1481,  0.1155,  0.2205,  0.0945,  0.0494,  0.1236, -0.0701, -0.0263,\n",
            "         -0.3350, -0.0497, -0.1500, -0.3071,  0.1145,  0.1081,  0.1766,  0.1611],\n",
            "        [-0.2410, -0.1346,  0.1229,  0.1418, -0.0822, -0.0168, -0.1592, -0.1896,\n",
            "          0.1664,  0.0893, -0.0971,  0.1895,  0.2506,  0.1666, -0.0472,  0.0458],\n",
            "        [ 0.0842,  0.2755, -0.2420,  0.0596,  0.0655,  0.0495,  0.1064, -0.0195,\n",
            "          0.2155, -0.1148,  0.0489, -0.2266,  0.1923, -0.0160,  0.1085, -0.2453],\n",
            "        [-0.1452,  0.2444, -0.1142, -0.1677, -0.1545, -0.0282, -0.0396,  0.1553,\n",
            "         -0.1745,  0.1249,  0.0963, -0.0875, -0.0083,  0.1906, -0.2387, -0.1926],\n",
            "        [-0.1340,  0.1325, -0.1715, -0.0767, -0.3052,  0.0273, -0.0505,  0.0942,\n",
            "         -0.2032, -0.1079, -0.1551,  0.1173,  0.1880, -0.1975, -0.1104,  0.1976],\n",
            "        [-0.0623,  0.1707,  0.2052,  0.1002,  0.0170, -0.2230,  0.2580,  0.0406,\n",
            "         -0.1152, -0.0750, -0.1574,  0.0559, -0.1226,  0.2420, -0.1214,  0.0797],\n",
            "        [ 0.0108,  0.1957,  0.0510, -0.2114, -0.0662, -0.2477,  0.0530,  0.1546,\n",
            "          0.1367, -0.2128, -0.1689, -0.0409,  0.1100, -0.1452,  0.1201,  0.0693],\n",
            "        [ 0.0493, -0.1933, -0.1683, -0.1329,  0.2132,  0.1135, -0.0402, -0.1131,\n",
            "         -0.0138, -0.1450,  0.0649,  0.1615, -0.2229,  0.2334,  0.0560, -0.1925],\n",
            "        [ 0.0568, -0.1142, -0.0405, -0.2190,  0.3011, -0.1397, -0.0906,  0.1108,\n",
            "          0.1830,  0.1712, -0.2286, -0.0654,  0.0701, -0.2764, -0.2392,  0.1708],\n",
            "        [-0.0850, -0.1332,  0.0961, -0.0646, -0.1389,  0.2093, -0.1233, -0.2249,\n",
            "         -0.0603, -0.0842,  0.0493, -0.1323, -0.2014, -0.0563, -0.2218, -0.1645],\n",
            "        [-0.2214,  0.1204,  0.1781, -0.1904,  0.0810, -0.2487, -0.0085, -0.1260,\n",
            "          0.0559, -0.1381, -0.0150, -0.2701,  0.0648,  0.2134,  0.2258, -0.1195],\n",
            "        [-0.0683, -0.0635, -0.0428, -0.2306, -0.0144,  0.0132, -0.1317,  0.1891,\n",
            "         -0.1345,  0.1695, -0.1253,  0.0689,  0.1748, -0.0326,  0.0112,  0.0301],\n",
            "        [ 0.0842,  0.1448, -0.1303,  0.0008, -0.1123, -0.0491, -0.1082,  0.1981,\n",
            "          0.0015,  0.1279,  0.2473,  0.1515, -0.0186, -0.2113,  0.0246,  0.1176]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([ 0.0172, -0.1504, -0.0874, -0.2893,  0.2289, -0.1769,  0.1101,  0.0386,\n",
            "         0.1417,  0.0211, -0.0096,  0.0535,  0.1977,  0.0695,  0.2758,  0.2096,\n",
            "        -0.1818, -0.0889, -0.1757, -0.0723, -0.2244,  0.2384,  0.2637,  0.1348,\n",
            "        -0.1132,  0.0609,  0.1632, -0.1413, -0.1888,  0.1368,  0.0030, -0.1752],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[-0.0866,  0.0072,  0.1330,  0.0939,  0.0215, -0.2428, -0.0581,  0.1353,\n",
            "         -0.0059,  0.0968, -0.0737,  0.0536,  0.1304, -0.1576, -0.1444, -0.1279,\n",
            "          0.0682, -0.0187, -0.1720, -0.0956,  0.0347, -0.0174, -0.1482,  0.0554,\n",
            "          0.0281, -0.0432,  0.0036, -0.1145, -0.0082, -0.0987,  0.1181,  0.1102]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([0.1307], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# doubly cumprod, not sure which is right for stepIS\n",
        "model5 = train_var_play(model4, 50, 0.00001, padded_state_tensors, states_first_tensor, states_last_tensor, samples_all_shaping, samples_IS_SCOPE, testing)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymZsAiRhT_Y7",
        "outputId": "0e2605cb-8f98-4742-ed50-1a64d5f7046a"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Var loss:  tensor(3.8975e+86, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 7.837653119776905e+86\n",
            "E_s_wdiff_all_sq: 3.936778943589322e+86\n",
            "E_IS_SCOPE: -4.922151070341052e+83\n",
            "E_IS_E_SCOPE: -3.229592269140938e+83\n",
            "Total Loss: 3.897490314804813e+86\n",
            "----------------------------------------\n",
            "Epoch 2\n",
            "Var loss:  tensor(6.8576e+88, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 1.3783057143777487e+89\n",
            "E_s_wdiff_all_sq: 6.925931966846359e+88\n",
            "E_IS_SCOPE: 6.527757697009708e+84\n",
            "E_IS_E_SCOPE: 4.283174687928771e+84\n",
            "Total Loss: 6.857574106095142e+88\n",
            "----------------------------------------\n",
            "Epoch 3\n",
            "Var loss:  tensor(4.5003e+87, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 9.044137064483694e+87\n",
            "E_s_wdiff_all_sq: 4.545021682025533e+87\n",
            "E_IS_SCOPE: 1.672171354213606e+84\n",
            "E_IS_E_SCOPE: 1.0971964008089646e+84\n",
            "Total Loss: 4.500265457986933e+87\n",
            "----------------------------------------\n",
            "Epoch 4\n",
            "Var loss:  tensor(1.5214e+88, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 3.0583029353013085e+88\n",
            "E_s_wdiff_all_sq: 1.5366475625865213e+88\n",
            "E_IS_SCOPE: -3.074858116302592e+84\n",
            "E_IS_E_SCOPE: -2.017552623022135e+84\n",
            "Total Loss: 1.5214439241783276e+88\n",
            "----------------------------------------\n",
            "Epoch 5\n",
            "Var loss:  tensor(3.8990e+88, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 7.837268553336831e+88\n",
            "E_s_wdiff_all_sq: 3.9379339053594285e+88\n",
            "E_IS_SCOPE: -4.922308531912808e+84\n",
            "E_IS_E_SCOPE: -3.2297516233039736e+84\n",
            "Total Loss: 3.898996149157877e+88\n",
            "----------------------------------------\n",
            "Epoch 6\n",
            "Var loss:  tensor(2.7116e+88, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 5.4506295872945704e+88\n",
            "E_s_wdiff_all_sq: 2.7387164761149973e+88\n",
            "E_IS_SCOPE: -4.104963120562134e+84\n",
            "E_IS_E_SCOPE: -2.693452904678721e+84\n",
            "Total Loss: 2.711630821698593e+88\n",
            "----------------------------------------\n",
            "Epoch 7\n",
            "Var loss:  tensor(5.9902e+87, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 1.2041596706721822e+88\n",
            "E_s_wdiff_all_sq: 6.050094371557648e+87\n",
            "E_IS_SCOPE: -1.9294089061961931e+84\n",
            "E_IS_E_SCOPE: -1.2659695895298638e+84\n",
            "Total Loss: 5.990175582152803e+87\n",
            "----------------------------------------\n",
            "Epoch 8\n",
            "Var loss:  tensor(6.2260e+86, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 1.2509352348714792e+87\n",
            "E_s_wdiff_all_sq: 6.287611866075718e+86\n",
            "E_IS_SCOPE: 6.219108809846561e+83\n",
            "E_IS_E_SCOPE: 4.080711692570723e+83\n",
            "Total Loss: 6.226018533093256e+86\n",
            "----------------------------------------\n",
            "Epoch 9\n",
            "Var loss:  tensor(1.1302e+88, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 2.2715648269907793e+88\n",
            "E_s_wdiff_all_sq: 1.1415002787395577e+88\n",
            "E_IS_SCOPE: 2.6500667929330647e+84\n",
            "E_IS_E_SCOPE: 1.7388395342654813e+84\n",
            "Total Loss: 1.1302468062651514e+88\n",
            "----------------------------------------\n",
            "Epoch 10\n",
            "Var loss:  tensor(1.9833e+88, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 3.986042073292496e+88\n",
            "E_s_wdiff_all_sq: 2.0030198205023387e+88\n",
            "E_IS_SCOPE: 3.510459375607212e+84\n",
            "E_IS_E_SCOPE: 2.303383524109326e+84\n",
            "Total Loss: 1.9832636805226533e+88\n",
            "----------------------------------------\n",
            "Epoch 11\n",
            "Var loss:  tensor(1.5900e+88, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 3.195653088273935e+88\n",
            "E_s_wdiff_all_sq: 1.6058526817015858e+88\n",
            "E_IS_SCOPE: 3.143209092939606e+84\n",
            "E_IS_E_SCOPE: 2.062413362375359e+84\n",
            "Total Loss: 1.5900165782806578e+88\n",
            "----------------------------------------\n",
            "Epoch 12\n",
            "Var loss:  tensor(5.7458e+87, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 1.1547485063429879e+88\n",
            "E_s_wdiff_all_sq: 5.802974245104604e+87\n",
            "E_IS_SCOPE: 1.8894699655776472e+84\n",
            "E_IS_E_SCOPE: 1.239776227470915e+84\n",
            "Total Loss: 5.74581033142345e+87\n",
            "----------------------------------------\n",
            "Epoch 13\n",
            "Var loss:  tensor(7.9471e+85, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 1.5956256908839205e+86\n",
            "E_s_wdiff_all_sq: 8.024481018307015e+85\n",
            "E_IS_SCOPE: 2.2213395875670698e+83\n",
            "E_IS_E_SCOPE: 1.45758751542778e+83\n",
            "Total Loss: 7.947063494171279e+85\n",
            "----------------------------------------\n",
            "Epoch 14\n",
            "Var loss:  tensor(2.9157e+87, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 5.861457695178025e+87\n",
            "E_s_wdiff_all_sq: 2.9448653606518576e+87\n",
            "E_IS_SCOPE: -1.3461146328497164e+84\n",
            "E_IS_E_SCOPE: -8.83242816702203e+83\n",
            "Total Loss: 2.9156667165158357e+87\n",
            "----------------------------------------\n",
            "Epoch 15\n",
            "Var loss:  tensor(8.9492e+87, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 1.798943371559614e+88\n",
            "E_s_wdiff_all_sq: 9.038642868581803e+87\n",
            "E_IS_SCOPE: -2.3582630793778606e+84\n",
            "E_IS_E_SCOPE: -1.5473609573610972e+84\n",
            "Total Loss: 8.949169168392268e+87\n",
            "----------------------------------------\n",
            "Epoch 16\n",
            "Var loss:  tensor(1.0661e+88, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 2.1429836072185233e+88\n",
            "E_s_wdiff_all_sq: 1.0767316325215912e+88\n",
            "E_IS_SCOPE: -2.573910293310698e+84\n",
            "E_IS_E_SCOPE: -1.6888572242494243e+84\n",
            "Total Loss: 1.0660749766453165e+88\n",
            "----------------------------------------\n",
            "Epoch 17\n",
            "Var loss:  tensor(6.6488e+87, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 1.3365460659669224e+88\n",
            "E_s_wdiff_all_sq: 6.7152802868889205e+87\n",
            "E_IS_SCOPE: -2.032705961192708e+84\n",
            "E_IS_E_SCOPE: -1.333747639224853e+84\n",
            "Total Loss: 6.64878258175833e+87\n",
            "----------------------------------------\n",
            "Epoch 18\n",
            "Var loss:  tensor(1.5255e+87, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 3.067038500759716e+87\n",
            "E_s_wdiff_all_sq: 1.5408342807567995e+87\n",
            "E_IS_SCOPE: -9.737221076570453e+83\n",
            "E_IS_E_SCOPE: -6.388985878829503e+83\n",
            "Total Loss: 1.5255346985853312e+87\n",
            "----------------------------------------\n",
            "Epoch 19\n",
            "Var loss:  tensor(1.1045e+86, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 2.217950638602012e+86\n",
            "E_s_wdiff_all_sq: 1.1152759314217639e+86\n",
            "E_IS_SCOPE: 2.6188838977173844e+83\n",
            "E_IS_E_SCOPE: 1.7184350142558822e+83\n",
            "Total Loss: 1.1044768611668018e+86\n",
            "----------------------------------------\n",
            "Epoch 20\n",
            "Var loss:  tensor(2.7594e+87, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 5.54534866802881e+87\n",
            "E_s_wdiff_all_sq: 2.7868343232000967e+87\n",
            "E_IS_SCOPE: 1.309374437032462e+84\n",
            "E_IS_E_SCOPE: 8.591483019713049e+83\n",
            "Total Loss: 2.7594149227207985e+87\n",
            "----------------------------------------\n",
            "Epoch 21\n",
            "Var loss:  tensor(5.6809e+87, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 1.1417080144477217e+88\n",
            "E_s_wdiff_all_sq: 5.737444915957507e+87\n",
            "E_IS_SCOPE: 1.8787710174160626e+84\n",
            "E_IS_E_SCOPE: 1.2327561453964254e+84\n",
            "Total Loss: 5.680927383885712e+87\n",
            "----------------------------------------\n",
            "Epoch 22\n",
            "Var loss:  tensor(5.5033e+87, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 1.1060027672678821e+88\n",
            "E_s_wdiff_all_sq: 5.558023590427719e+87\n",
            "E_IS_SCOPE: 1.849160244884443e+84\n",
            "E_IS_E_SCOPE: 1.2133271266416297e+84\n",
            "Total Loss: 5.50327587410955e+87\n",
            "----------------------------------------\n",
            "Epoch 23\n",
            "Var loss:  tensor(2.6745e+87, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 5.3745910497876315e+87\n",
            "E_s_wdiff_all_sq: 2.701025572434766e+87\n",
            "E_IS_SCOPE: 1.2890575346034187e+84\n",
            "E_IS_E_SCOPE: 8.458174280586367e+83\n",
            "Total Loss: 2.6744520831879185e+87\n",
            "----------------------------------------\n",
            "Epoch 24\n",
            "Var loss:  tensor(2.6730e+86, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 5.369605364434185e+86\n",
            "E_s_wdiff_all_sq: 2.699367556334373e+86\n",
            "E_IS_SCOPE: 4.074677525458872e+83\n",
            "E_IS_E_SCOPE: 2.673649600634012e+83\n",
            "Total Loss: 2.6730411201690913e+86\n",
            "----------------------------------------\n",
            "Epoch 25\n",
            "Var loss:  tensor(4.2614e+86, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 8.56936141220449e+86\n",
            "E_s_wdiff_all_sq: 4.3043805516183637e+86\n",
            "E_IS_SCOPE: -5.146800735968692e+83\n",
            "E_IS_E_SCOPE: -3.376995458396228e+83\n",
            "Total Loss: 4.261442506250611e+86\n",
            "----------------------------------------\n",
            "Epoch 26\n",
            "Var loss:  tensor(2.3215e+87, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 4.667121919114039e+87\n",
            "E_s_wdiff_all_sq: 2.3447776402080183e+87\n",
            "E_IS_SCOPE: -1.2011648130209186e+84\n",
            "E_IS_E_SCOPE: -7.881344304440632e+83\n",
            "Total Loss: 2.32151834376283e+87\n",
            "----------------------------------------\n",
            "Epoch 27\n",
            "Var loss:  tensor(3.4505e+87, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 6.9364773411371185e+87\n",
            "E_s_wdiff_all_sq: 3.4850070260869156e+87\n",
            "E_IS_SCOPE: -1.4643656124980096e+84\n",
            "E_IS_E_SCOPE: -9.608328385946076e+83\n",
            "Total Loss: 3.4504633751243594e+87\n",
            "----------------------------------------\n",
            "Epoch 28\n",
            "Var loss:  tensor(2.5625e+87, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 5.151474009308681e+87\n",
            "E_s_wdiff_all_sq: 2.5881371826118765e+87\n",
            "E_IS_SCOPE: -1.2619563216603506e+84\n",
            "E_IS_E_SCOPE: -8.280225947952616e+83\n",
            "Total Loss: 2.5624690848650376e+87\n",
            "----------------------------------------\n",
            "Epoch 29\n",
            "Var loss:  tensor(7.7909e+86, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 1.5664877086556264e+87\n",
            "E_s_wdiff_all_sq: 7.869195685604381e+86\n",
            "E_IS_SCOPE: -6.958784933936726e+83\n",
            "E_IS_E_SCOPE: -4.5659234052440576e+83\n",
            "Total Loss: 7.790896934114128e+86\n",
            "----------------------------------------\n",
            "Epoch 30\n",
            "Var loss:  tensor(1.6952e+84, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 3.3820384868950102e+84\n",
            "E_s_wdiff_all_sq: 1.7092209991157447e+84\n",
            "E_IS_SCOPE: 3.2365863302345985e+82\n",
            "E_IS_E_SCOPE: 2.1242990703737244e+82\n",
            "Total Loss: 1.6951888549395312e+84\n",
            "----------------------------------------\n",
            "Epoch 31\n",
            "Var loss:  tensor(7.5709e+86, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 1.5211939901987585e+87\n",
            "E_s_wdiff_all_sq: 7.645806988566776e+86\n",
            "E_IS_SCOPE: 6.858055967814821e+83\n",
            "E_IS_E_SCOPE: 4.49995494747505e+83\n",
            "Total Loss: 7.57085037168112e+86\n",
            "----------------------------------------\n",
            "Epoch 32\n",
            "Var loss:  tensor(1.8262e+87, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 3.6698412575815546e+87\n",
            "E_s_wdiff_all_sq: 1.8443519647089066e+87\n",
            "E_IS_SCOPE: 1.06518590189668e+84\n",
            "E_IS_E_SCOPE: 6.989247341010318e+83\n",
            "Total Loss: 1.8262219408302022e+87\n",
            "----------------------------------------\n",
            "Epoch 33\n",
            "Var loss:  tensor(1.8518e+87, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 3.7211967054981814e+87\n",
            "E_s_wdiff_all_sq: 1.870159395351237e+87\n",
            "E_IS_SCOPE: 1.0726128530914907e+84\n",
            "E_IS_E_SCOPE: 7.037979057110123e+83\n",
            "Total Loss: 1.851775065663668e+87\n",
            "----------------------------------------\n",
            "Epoch 34\n",
            "Var loss:  tensor(8.7443e+86, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 1.7570158690357867e+87\n",
            "E_s_wdiff_all_sq: 8.830924585106656e+86\n",
            "E_IS_SCOPE: 7.370470422235385e+83\n",
            "E_IS_E_SCOPE: 4.8361741429783514e+83\n",
            "Total Loss: 8.744303954029355e+86\n",
            "----------------------------------------\n",
            "Epoch 35\n",
            "Var loss:  tensor(6.0753e+85, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 1.2196174581559286e+86\n",
            "E_s_wdiff_all_sq: 6.134259163521959e+85\n",
            "E_IS_SCOPE: 1.9420922956911794e+83\n",
            "E_IS_E_SCOPE: 1.2743602606239946e+83\n",
            "Total Loss: 6.0752826209349756e+85\n",
            "----------------------------------------\n",
            "Epoch 36\n",
            "Var loss:  tensor(2.1256e+86, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 4.275253337170368e+86\n",
            "E_s_wdiff_all_sq: 2.1471299098150054e+86\n",
            "E_IS_SCOPE: -3.635241037565288e+83\n",
            "E_IS_E_SCOPE: -2.385190129908618e+83\n",
            "Total Loss: 2.1256245817596795e+86\n",
            "----------------------------------------\n",
            "Epoch 37\n",
            "Var loss:  tensor(9.0814e+86, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 1.8259214394910263e+87\n",
            "E_s_wdiff_all_sq: 9.172633943479747e+86\n",
            "E_IS_SCOPE: -7.512982716219675e+83\n",
            "E_IS_E_SCOPE: -4.929558598773401e+83\n",
            "Total Loss: 9.081414859415255e+86\n",
            "----------------------------------------\n",
            "Epoch 38\n",
            "Var loss:  tensor(1.1718e+87, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 2.355984214996604e+87\n",
            "E_s_wdiff_all_sq: 1.1835791444580413e+87\n",
            "E_IS_SCOPE: -8.534138190174724e+83\n",
            "E_IS_E_SCOPE: -5.599586672679444e+83\n",
            "Total Loss: 1.1718182858570266e+87\n",
            "----------------------------------------\n",
            "Epoch 39\n",
            "Var loss:  tensor(6.9890e+86, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 1.4052720717014727e+87\n",
            "E_s_wdiff_all_sq: 7.059228570094e+86\n",
            "E_IS_SCOPE: -6.590965774498347e+83\n",
            "E_IS_E_SCOPE: -4.3245799710571113e+83\n",
            "Total Loss: 6.988960631533475e+86\n",
            "----------------------------------------\n",
            "Epoch 40\n",
            "Var loss:  tensor(1.0744e+86, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 2.1615783609290368e+86\n",
            "E_s_wdiff_all_sq: 1.0853666241201738e+86\n",
            "E_IS_SCOPE: -2.584775092475388e+83\n",
            "E_IS_E_SCOPE: -1.695930076104556e+83\n",
            "Total Loss: 1.0744353029957517e+86\n",
            "----------------------------------------\n",
            "Epoch 41\n",
            "Var loss:  tensor(6.1167e+85, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 1.2279312067750127e+86\n",
            "E_s_wdiff_all_sq: 6.176054380017834e+85\n",
            "E_IS_SCOPE: 1.9486992637973178e+83\n",
            "E_IS_E_SCOPE: 1.278695406294073e+83\n",
            "Total Loss: 6.116670327078663e+85\n",
            "----------------------------------------\n",
            "Epoch 42\n",
            "Var loss:  tensor(4.6883e+86, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 9.419116464001514e+86\n",
            "E_s_wdiff_all_sq: 4.734574838098272e+86\n",
            "E_IS_SCOPE: 5.396585778275006e+83\n",
            "E_IS_E_SCOPE: 3.541015711001669e+83\n",
            "Total Loss: 4.6882540222574187e+86\n",
            "----------------------------------------\n",
            "Epoch 43\n",
            "Var loss:  tensor(7.0907e+86, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 1.4247039376532172e+87\n",
            "E_s_wdiff_all_sq: 7.160894951414018e+86\n",
            "E_IS_SCOPE: 6.636997883289355e+83\n",
            "E_IS_E_SCOPE: 4.3549083611694844e+83\n",
            "Total Loss: 7.090709860382026e+86\n",
            "----------------------------------------\n",
            "Epoch 44\n",
            "Var loss:  tensor(4.7157e+86, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 9.474196544894399e+86\n",
            "E_s_wdiff_all_sq: 4.762256367036719e+86\n",
            "E_IS_SCOPE: 5.41234064027121e+83\n",
            "E_IS_E_SCOPE: 3.551353217268139e+83\n",
            "Total Loss: 4.715663408923316e+86\n",
            "----------------------------------------\n",
            "Epoch 45\n",
            "Var loss:  tensor(8.9897e+85, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 1.80508205151314e+86\n",
            "E_s_wdiff_all_sq: 9.07739096634913e+85\n",
            "E_IS_SCOPE: 2.3626221442221024e+83\n",
            "E_IS_E_SCOPE: 1.5502896543407176e+83\n",
            "Total Loss: 8.989688760776205e+85\n",
            "----------------------------------------\n",
            "Epoch 46\n",
            "Var loss:  tensor(2.5718e+85, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 5.179049186358142e+85\n",
            "E_s_wdiff_all_sq: 2.5985241595554088e+85\n",
            "E_IS_SCOPE: -1.2650507802836305e+83\n",
            "E_IS_E_SCOPE: -8.299969580777913e+82\n",
            "Total Loss: 2.5718365125549215e+85\n",
            "----------------------------------------\n",
            "Epoch 47\n",
            "Var loss:  tensor(2.7068e+86, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 5.443731186792979e+86\n",
            "E_s_wdiff_all_sq: 2.734126528315301e+86\n",
            "E_IS_SCOPE: -4.1020867225103166e+83\n",
            "E_IS_E_SCOPE: -2.691509506822782e+83\n",
            "Total Loss: 2.706784760265933e+86\n",
            "----------------------------------------\n",
            "Epoch 48\n",
            "Var loss:  tensor(4.2963e+86, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 8.639441264088649e+86\n",
            "E_s_wdiff_all_sq: 4.339587949052286e+86\n",
            "E_IS_SCOPE: -5.167804526906915e+83\n",
            "E_IS_E_SCOPE: -3.390777018957542e+83\n",
            "Total Loss: 4.296300516240094e+86\n",
            "----------------------------------------\n",
            "Epoch 49\n",
            "Var loss:  tensor(2.8546e+86, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 5.740822526524662e+86\n",
            "E_s_wdiff_all_sq: 2.88337586359815e+86\n",
            "E_IS_SCOPE: -4.212543734590628e+83\n",
            "E_IS_E_SCOPE: -2.7639855397922327e+83\n",
            "Total Loss: 2.854550802756545e+86\n",
            "----------------------------------------\n",
            "Epoch 50\n",
            "Var loss:  tensor(4.9920e+85, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "E_IS_sq: 3.9050883499768664e+80\n",
            "E_IS_all_sq: 2.6488687194959097e+80\n",
            "E_s_wdiff_sq: 1.0047394444118317e+86\n",
            "E_s_wdiff_all_sq: 5.043265829926229e+85\n",
            "E_IS_SCOPE: -1.7621372108929036e+83\n",
            "E_IS_E_SCOPE: -1.156158712885409e+83\n",
            "Total Loss: 4.992021606428242e+85\n",
            "----------------------------------------\n",
            "Parameter name: hidden_layers.0.weight\n",
            "Weights: tensor([[ 0.0057, -0.6100],\n",
            "        [ 0.3443,  0.3599],\n",
            "        [ 0.0603, -0.6894],\n",
            "        [ 0.0467,  0.0746],\n",
            "        [-0.2990, -0.5145],\n",
            "        [ 0.5804, -0.5688],\n",
            "        [ 0.2525,  0.6377],\n",
            "        [-0.0274, -0.5872],\n",
            "        [ 0.3506,  0.6663],\n",
            "        [-0.2037,  0.2161],\n",
            "        [ 0.1259, -0.1210],\n",
            "        [ 0.5856,  0.6529],\n",
            "        [-0.5431, -0.4579],\n",
            "        [-0.3938, -0.1607],\n",
            "        [ 0.5919, -0.2230],\n",
            "        [ 0.2164,  0.1424]], dtype=torch.float64)\n",
            "Parameter name: hidden_layers.0.bias\n",
            "Weights: tensor([-0.2603,  0.3900, -0.1267,  0.3600, -0.3407, -0.4320, -0.4568,  0.0077,\n",
            "         0.1181, -0.0323,  0.3781, -0.2170, -0.1138,  0.3433,  0.5592, -0.6726],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.weight\n",
            "Weights: tensor([[ 0.0385,  0.1607,  0.0537,  0.1362,  0.1027, -0.1052, -0.0967,  0.1405,\n",
            "         -0.2242,  0.1343,  0.2250,  0.1195,  0.0101, -0.0537,  0.0888, -0.0150],\n",
            "        [-0.2443, -0.2089,  0.1078, -0.2029,  0.2421,  0.0321, -0.2072,  0.1845,\n",
            "         -0.1160, -0.2427, -0.1520, -0.2045,  0.1968,  0.1299, -0.0931,  0.0351],\n",
            "        [-0.1388, -0.0849, -0.1800, -0.0828,  0.0163,  0.2144,  0.0428, -0.1220,\n",
            "          0.1630, -0.0051,  0.2334,  0.1353,  0.0479, -0.2065,  0.0663,  0.0205],\n",
            "        [-0.0223, -0.0925,  0.0553,  0.1817,  0.1728,  0.0358,  0.1021,  0.0723,\n",
            "         -0.2108,  0.1436,  0.1223,  0.0515, -0.2234, -0.2380,  0.2588, -0.1484],\n",
            "        [ 0.2326, -0.2058,  0.0210,  0.0105,  0.2428, -0.1296,  0.0172, -0.2466,\n",
            "         -0.0725,  0.2136, -0.1839,  0.1385,  0.2397,  0.1813,  0.0985, -0.0114],\n",
            "        [-0.0598,  0.1158, -0.0868, -0.0648,  0.0944,  0.1485,  0.1504,  0.2069,\n",
            "         -0.1268,  0.1903, -0.0059, -0.1603, -0.1928,  0.2256,  0.0258, -0.0301],\n",
            "        [ 0.0028, -0.1960, -0.1355,  0.2132,  0.1930, -0.1458,  0.1829, -0.2268,\n",
            "         -0.2057,  0.1018, -0.2002, -0.0316,  0.0088, -0.1407, -0.2071, -0.2563],\n",
            "        [ 0.1226, -0.2321, -0.2095,  0.1210,  0.2011, -0.0797, -0.2472, -0.1447,\n",
            "         -0.1118, -0.1112, -0.0644, -0.0462,  0.2324,  0.0267, -0.0405,  0.0270],\n",
            "        [ 0.0356,  0.0735,  0.1655, -0.1377,  0.2421, -0.0151, -0.2196, -0.2296,\n",
            "          0.1087,  0.1373, -0.1671, -0.1895, -0.1617,  0.0957, -0.1707, -0.0964],\n",
            "        [ 0.0864,  0.1653,  0.1580,  0.2232,  0.2087,  0.2240, -0.0733,  0.1772,\n",
            "          0.2404, -0.0513,  0.1970, -0.0834,  0.0132, -0.1743, -0.0942,  0.0490],\n",
            "        [ 0.1404,  0.1331,  0.1049, -0.1975, -0.1276, -0.1781, -0.0294,  0.0525,\n",
            "         -0.0680,  0.0958,  0.0937,  0.0449, -0.2339, -0.1146,  0.0658, -0.2119],\n",
            "        [-0.1854,  0.1002, -0.0539,  0.2179,  0.2327, -0.0351, -0.1866,  0.0155,\n",
            "          0.1941,  0.1905, -0.1512,  0.0818, -0.0459,  0.2223,  0.1095,  0.1137],\n",
            "        [ 0.1301, -0.0741,  0.0088, -0.2102, -0.0019,  0.1090,  0.2121,  0.0169,\n",
            "          0.1982,  0.1137, -0.0476, -0.1419, -0.0138,  0.0242,  0.1944, -0.0159],\n",
            "        [-0.1140,  0.1794,  0.0216, -0.2030, -0.0781, -0.1073, -0.0901,  0.2027,\n",
            "          0.0276, -0.1373, -0.1219, -0.0507,  0.0966, -0.1865,  0.2059,  0.1724],\n",
            "        [-0.0525, -0.2466,  0.0758,  0.2112, -0.2105, -0.0317,  0.0676,  0.0982,\n",
            "          0.0120, -0.1962,  0.1114,  0.0919,  0.0579, -0.1252, -0.2141,  0.1544],\n",
            "        [-0.0700,  0.1529, -0.0512,  0.0674, -0.1620,  0.2611, -0.1782,  0.2083,\n",
            "         -0.1981, -0.1330, -0.1570,  0.2139, -0.2148,  0.1181, -0.0496, -0.1860],\n",
            "        [ 0.2095, -0.1590, -0.0726,  0.0835,  0.0676,  0.0158,  0.1621,  0.2150,\n",
            "          0.0275, -0.0673, -0.0519, -0.0873, -0.1941,  0.1961, -0.0169,  0.2167],\n",
            "        [-0.1702,  0.0076,  0.0832,  0.1387, -0.0534, -0.1946, -0.0532,  0.1080,\n",
            "          0.2263,  0.2426, -0.1710,  0.0973, -0.0738, -0.0918, -0.0796,  0.1665],\n",
            "        [ 0.0752,  0.2095, -0.1088, -0.1003, -0.1436, -0.0289, -0.1112, -0.0959,\n",
            "          0.2292,  0.2397,  0.0689, -0.1798, -0.0281,  0.0557, -0.0527, -0.0226],\n",
            "        [ 0.1749, -0.0238,  0.0266, -0.0917,  0.2317,  0.1405,  0.0147,  0.0478,\n",
            "          0.0114, -0.0634, -0.1340, -0.2402, -0.1246,  0.1135,  0.2237, -0.1618],\n",
            "        [ 0.1508, -0.1032,  0.0307,  0.1573,  0.1597, -0.2207, -0.0863,  0.0799,\n",
            "         -0.0957, -0.1142,  0.1997, -0.0183,  0.0878, -0.1367,  0.1528, -0.1219],\n",
            "        [-0.1164,  0.1273, -0.1732, -0.1619,  0.1850, -0.0230,  0.0280,  0.1014,\n",
            "          0.0235,  0.1276,  0.1700, -0.2250, -0.2457, -0.2397,  0.2155,  0.0816],\n",
            "        [ 0.0717,  0.1566, -0.2082, -0.1406,  0.1578,  0.2227,  0.1878, -0.1951,\n",
            "         -0.0506,  0.0416, -0.1165, -0.0838, -0.2011, -0.0309,  0.0655,  0.1953],\n",
            "        [ 0.1506, -0.0581,  0.0545, -0.1305,  0.0410, -0.0670, -0.1568, -0.2053,\n",
            "         -0.2224, -0.1154,  0.0073,  0.0638, -0.0847, -0.2224, -0.2494,  0.0066],\n",
            "        [ 0.2441, -0.2159,  0.1701,  0.1729,  0.0498, -0.2286, -0.2306,  0.0044,\n",
            "         -0.2085,  0.2553,  0.1823,  0.0364,  0.0049,  0.0330,  0.1710,  0.1530],\n",
            "        [-0.1691,  0.0183,  0.0151,  0.1456, -0.1523,  0.0140,  0.1107,  0.1649,\n",
            "         -0.0961,  0.0369,  0.1660,  0.0854,  0.0902,  0.2101, -0.2266,  0.0532],\n",
            "        [-0.0305,  0.0595, -0.0412, -0.1722, -0.1480,  0.1776,  0.1730, -0.0601,\n",
            "          0.0148, -0.1616,  0.1800,  0.0327,  0.0449, -0.1433, -0.1982,  0.1902],\n",
            "        [-0.2281,  0.1787,  0.2350,  0.1225,  0.1040, -0.2257,  0.1944, -0.1659,\n",
            "         -0.1148,  0.1082, -0.1264,  0.2329, -0.0157,  0.0391, -0.0187,  0.1562],\n",
            "        [ 0.1872, -0.0049, -0.1972, -0.2247,  0.1307,  0.0958, -0.2034,  0.0847,\n",
            "         -0.0691, -0.2042,  0.0478,  0.0534, -0.2466,  0.1539,  0.0483,  0.1013],\n",
            "        [ 0.0984, -0.0091, -0.0703, -0.1365, -0.0303,  0.2239,  0.0346,  0.1965,\n",
            "         -0.0163, -0.1643,  0.1658, -0.0299, -0.2271, -0.0389, -0.2230,  0.1360],\n",
            "        [ 0.0846, -0.1789,  0.1758, -0.0041, -0.0720,  0.1870,  0.1668,  0.0533,\n",
            "          0.1085, -0.2203, -0.0854, -0.1453, -0.0079,  0.1412, -0.1511,  0.2060],\n",
            "        [ 0.1633,  0.1194,  0.2112, -0.2535,  0.2361, -0.1522, -0.1092, -0.1170,\n",
            "         -0.1035, -0.2434, -0.0377,  0.2140,  0.1338,  0.0197, -0.0060, -0.0218]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: hidden_layers.1.bias\n",
            "Weights: tensor([-0.0844,  0.2144,  0.2339,  0.1293, -0.2160,  0.1337, -0.1717,  0.0917,\n",
            "        -0.0122,  0.2378, -0.1503,  0.1356,  0.0690, -0.1095, -0.1798,  0.1041,\n",
            "         0.0093,  0.0048, -0.0405, -0.1691,  0.0958,  0.1319,  0.1541,  0.0802,\n",
            "         0.0656,  0.2310, -0.2521,  0.0452,  0.1527,  0.0092,  0.1901, -0.0566],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.weight\n",
            "Weights: tensor([[-0.1005,  0.1250, -0.1375, -0.0578,  0.0231, -0.1704, -0.0235,  0.0314,\n",
            "         -0.1519,  0.1800, -0.1501,  0.0119, -0.0097, -0.1317,  0.0177, -0.0431,\n",
            "          0.1433,  0.1614,  0.0847,  0.0759,  0.1391, -0.0207,  0.1146,  0.0106,\n",
            "         -0.1546, -0.1361, -0.0071, -0.0994,  0.1144, -0.1813, -0.0998, -0.1650]],\n",
            "       dtype=torch.float64)\n",
            "Parameter name: output_layer.bias\n",
            "Weights: tensor([0.0674], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IS Play"
      ],
      "metadata": {
        "id": "hlu2XrJwhJFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_importance_weights(eval_policy, behav_policy, behavior_policies):\n",
        "    \"\"\"\n",
        "    Calculate importance weights for behavior policies.\n",
        "\n",
        "    Parameters:\n",
        "    - eval_policy: Evaluation policy\n",
        "    - behav_policy: Behavior policy\n",
        "    - behavior_policies: List of behavior policies\n",
        "\n",
        "    Returns:\n",
        "    - all_weights: List of importance weights\n",
        "    \"\"\"\n",
        "    all_weights_temp = []\n",
        "    for trajectory in behavior_policies:\n",
        "        cum_ratio = 1\n",
        "        cumul_weights = []\n",
        "        for step in trajectory:\n",
        "            # eval_action_probs = get_quadrant_policy(step[0], eval_policy)\n",
        "            # behav_action_probs = get_quadrant_policy(step[0], behav_policy)\n",
        "\n",
        "            P_pi_b = behav_policy[tuple(np.append(step[0].astype(int) , (step[1],)))]\n",
        "            P_pi_e = eval_policy[tuple(np.append(step[0].astype(int) , (step[1],)))]\n",
        "\n",
        "            # ratio = (0.8*eval_action_probs[step[1]] +0.2*0.25)/ (0.8*behav_action_probs[step[1]]+0.2*0.25)\n",
        "            ratio = P_pi_e/P_pi_b\n",
        "            cum_ratio *= ratio\n",
        "            cumul_weights.append(cum_ratio)\n",
        "        all_weights_temp.append(cumul_weights)\n",
        "\n",
        "        all_weights = [list(np.cumprod(i)) for i in all_weights_temp]\n",
        "\n",
        "    return all_weights_temp, all_weights"
      ],
      "metadata": {
        "id": "3NvlDTygDhon"
      },
      "execution_count": 125,
=======
        "test1 = SCOPE_variance(model, 0.9, 10000, pi_b, P_pi_b, P_pi_e)"
      ],
      "metadata": {
        "id": "1fEf2grNuo0q"
      },
      "execution_count": 78,
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
<<<<<<< HEAD
        "all_weights_temp, all_weights = calculate_importance_weights(P_pi_e, P_pi_b, pi_b)"
      ],
      "metadata": {
        "id": "eWX9DHMDDl-W"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_weights_temp[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqKsg2xDDtgF",
        "outputId": "b1ba3c6a-026d-4de6-8605-95a8381f831e"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7132352941176471,\n",
              " 0.5087045847750865,\n",
              " 0.36282606414105434,\n",
              " 0.2587803545711932,\n",
              " 0.18457128230445397,\n",
              " 0.1316427528200885,\n",
              " 0.09389225752609254,\n",
              " 0.06696727191199248,\n",
              " 0.0477634218784064,\n",
              " 0.03406655825151045,\n",
              " 0.004258319781438806,\n",
              " 0.0005322899726798508,\n",
              " 0.00037964799522018767,\n",
              " 0.0002707783495320456,\n",
              " 3.38472936915057e-05,\n",
              " 2.4141084471147448e-05,\n",
              " 1.721827348309781e-05,\n",
              " 2.1522841853872264e-06,\n",
              " 1.304822287391006e-05,\n",
              " 9.306453079185852e-06,\n",
              " 1.1633066348982315e-06,\n",
              " 8.297113498906504e-07,\n",
              " 5.917794186720081e-07]"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_weights[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uEATYCyLNex",
        "outputId": "0a34724c-c9d0-4457-d76f-59ff5617b6f6"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7132352941176471,\n",
              " 0.36282606414105434,\n",
              " 0.13164275282008847,\n",
              " 0.034066558251510434,\n",
              " 0.006287708340180658,\n",
              " 0.0008277312348312113,\n",
              " 7.771755426316267e-05,\n",
              " 5.204532588676245e-06,\n",
              " 2.48586285712858e-07,\n",
              " 8.468479182763697e-09,\n",
              " 3.6061492422665387e-11,\n",
              " 1.9195170816455204e-14,\n",
              " 7.287408118376271e-18,\n",
              " 1.973272342660357e-21,\n",
              " 6.678992851535058e-26,\n",
              " 1.612381306110978e-30,\n",
              " 2.776242228765327e-35,\n",
              " 5.9752622437758e-41,\n",
              " 7.796655348684653e-46,\n",
              " 7.255920717711713e-51,\n",
              " 8.440860713209574e-57,\n",
              " 7.003477936596074e-63,\n",
              " 4.1445141020010597e-69]"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract probability for each state-action pair\n",
        "num_steps, num_states, num_actions = P_pi_b.shape\n",
        "num_samples = states_test.shape[0]\n",
        "\n",
        "# Convert states_test to integers for indexing\n",
        "states_int = states_test.astype(int)\n",
        "\n",
        "# Extract probabilities using array indexing\n",
        "probs_pi_b = P_pi_b[states_int[:, 0], states_int[:, 1], actions_test]\n",
        "probs_pi_e = P_pi_e[states_int[:, 0], states_int[:, 1], actions_test]"
      ],
      "metadata": {
        "id": "psMIyTu1j0PS"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs_pi_b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrGoFbE3kx-K",
        "outputId": "f80b0739-0035-4628-a24b-a610ef62764d"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.68, 0.08,\n",
              "       0.08, 0.68, 0.68, 0.08, 0.68, 0.68, 0.08, 0.08, 0.68, 0.08, 0.68,\n",
              "       0.68])"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "probs_pi_e"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_d9hkR7wk_mf",
        "outputId": "3edb3fdf-94bb-4a27-f7f0-3079dca07bec"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.485, 0.485, 0.485, 0.485, 0.485, 0.485, 0.485, 0.485, 0.485,\n",
              "       0.485, 0.01 , 0.01 , 0.485, 0.485, 0.01 , 0.485, 0.485, 0.01 ,\n",
              "       0.485, 0.485, 0.01 , 0.485, 0.485])"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(probs_pi_e/probs_pi_b).cumprod(axis=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iVhb2RVlCI8",
        "outputId": "6af4e661-1c4e-4398-ff9b-170e9bc7e28e"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7.13235294e-01, 5.08704585e-01, 3.62826064e-01, 2.58780355e-01,\n",
              "       1.84571282e-01, 1.31642753e-01, 9.38922575e-02, 6.69672719e-02,\n",
              "       4.77634219e-02, 3.40665583e-02, 4.25831978e-03, 5.32289973e-04,\n",
              "       3.79647995e-04, 2.70778350e-04, 3.38472937e-05, 2.41410845e-05,\n",
              "       1.72182735e-05, 2.15228419e-06, 1.30482229e-05, 9.30645308e-06,\n",
              "       1.16330663e-06, 8.29711350e-07, 5.91779419e-07])"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(probs_pi_e/probs_pi_b).prod(axis=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haf3CzhmnP-g",
        "outputId": "8a4cc96b-b454-43f3-d94c-e4546858ecd8"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.917794186720081e-07"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFeC8cDJlRqF",
        "outputId": "04d5b1ae-ed42-465b-eccd-b87ee7f98e05"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7132352941176471,\n",
              " 0.36282606414105434,\n",
              " 0.13164275282008847,\n",
              " 0.034066558251510434,\n",
              " 0.006287708340180658,\n",
              " 0.0008277312348312113,\n",
              " 7.771755426316267e-05,\n",
              " 5.204532588676245e-06,\n",
              " 2.48586285712858e-07,\n",
              " 8.468479182763697e-09,\n",
              " 3.6061492422665387e-11,\n",
              " 1.9195170816455204e-14,\n",
              " 7.287408118376271e-18,\n",
              " 1.973272342660357e-21,\n",
              " 6.678992851535058e-26,\n",
              " 1.612381306110978e-30,\n",
              " 2.776242228765327e-35,\n",
              " 5.9752622437758e-41,\n",
              " 7.796655348684653e-46,\n",
              " 7.255920717711713e-51,\n",
              " 8.440860713209574e-57,\n",
              " 7.003477936596074e-63,\n",
              " 4.1445141020010597e-69]"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSZax_wTBuz2",
        "outputId": "10644bfa-fb7d-4b7d-ca1a-ecb9f63bd4c2"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.7132352941176471,\n",
              "  0.36282606414105434,\n",
              "  0.13164275282008847,\n",
              "  0.034066558251510434,\n",
              "  0.006287708340180658,\n",
              "  0.0008277312348312113,\n",
              "  7.771755426316267e-05,\n",
              "  5.204532588676245e-06,\n",
              "  2.48586285712858e-07,\n",
              "  8.468479182763697e-09,\n",
              "  3.6061492422665387e-11,\n",
              "  1.9195170816455204e-14,\n",
              "  7.287408118376271e-18,\n",
              "  1.973272342660357e-21,\n",
              "  6.678992851535058e-26,\n",
              "  1.612381306110978e-30,\n",
              "  2.776242228765327e-35,\n",
              "  5.9752622437758e-41,\n",
              "  7.796655348684653e-46,\n",
              "  7.255920717711713e-51,\n",
              "  8.440860713209574e-57,\n",
              "  7.003477936596074e-63,\n",
              "  4.1445141020010597e-69],\n",
              " [6.0625,\n",
              "  26.214183134191178,\n",
              "  80.84510557563685,\n",
              "  177.82956323277526,\n",
              "  278.98895939887166,\n",
              "  2653.5166914163347,\n",
              "  18000.702591032885,\n",
              "  87094.33652773884,\n",
              "  300554.4756778875,\n",
              "  739757.3859855295,\n",
              "  227596.42361250217,\n",
              "  49942.971995499654,\n",
              "  1369.9141292252755,\n",
              "  26.80063802941003,\n",
              "  0.37396395766511065,\n",
              "  0.03163487428795419,\n",
              "  0.001908689588734961,\n",
              "  8.213671358375234e-05,\n",
              "  2.1428466437824626e-05,\n",
              "  3.9872887390228824e-06,\n",
              "  5.291723054894178e-07],\n",
              " [0.7132352941176471,\n",
              "  0.06358807309688581,\n",
              "  0.004043443040174894,\n",
              "  0.00018338331548064946,\n",
              "  1.0396288528903333e-06,\n",
              "  4.203680049584427e-09,\n",
              "  1.2123103392960128e-11,\n",
              "  2.493622974018479e-14,\n",
              "  3.658310788273809e-17,\n",
              "  3.827923332764183e-20,\n",
              "  2.8567924540782985e-23,\n",
              "  1.5206419773333412e-26,\n",
              "  1.011778095713248e-30,\n",
              "  8.41498960820744e-36,\n",
              "  4.991771772741668e-41,\n",
              "  3.7013987228869067e-47,\n",
              "  1.957536400670582e-53,\n",
              "  1.2940880754943391e-60,\n",
              "  6.1016971764870074e-68,\n",
              "  3.596230150266961e-76,\n",
              "  1.2849790795932546e-83,\n",
              "  3.274744808368086e-91,\n",
              "  5.95239431745802e-99,\n",
              "  7.716826756593017e-107,\n",
              "  7.135405081264397e-115,\n",
              "  4.7057769931646824e-123,\n",
              "  1.881463521646853e-130,\n",
              "  5.365288613487482e-138,\n",
              "  1.0912473473433638e-145],\n",
              " [0.125,\n",
              "  0.011144301470588236,\n",
              "  0.0007086446565254968,\n",
              "  3.213934395021691e-05,\n",
              "  1.039628852890333e-06,\n",
              "  2.3985703812334665e-08,\n",
              "  6.917300171277249e-11,\n",
              "  2.4936229740184782e-14,\n",
              "  6.411472515531416e-18,\n",
              "  1.175757087011211e-21,\n",
              "  2.6951779101998296e-26,\n",
              "  4.40646269442255e-31,\n",
              "  4.367616605600319e-35,\n",
              "  3.087676164250621e-39,\n",
              "  1.5568680559372986e-43,\n",
              "  5.598925597374785e-48,\n",
              "  1.2207011013886082e-51,\n",
              "  1.6134879567799814e-54,\n",
              "  1.521090121055426e-57,\n",
              "  1.022767664998916e-60,\n",
              "  4.904919212915387e-64,\n",
              "  1.426062237134181e-66,\n",
              "  2.9571811322967266e-69,\n",
              "  4.3737121729807376e-72,\n",
              "  4.613763172345368e-75,\n",
              "  3.4713085877923017e-78,\n",
              "  1.8627903232948804e-81,\n",
              "  7.129639150096391e-85,\n",
              "  1.946273869590634e-88,\n",
              "  3.789423814439231e-92,\n",
              "  5.262295527618552e-96,\n",
              "  5.212068491909747e-100],\n",
              " [0.7132352941176471,\n",
              "  3.0840215451989623,\n",
              "  9.511188891251395,\n",
              "  177.82956323277526,\n",
              "  2371.406154890409,\n",
              "  22554.891877038845,\n",
              "  153005.9720237795,\n",
              "  740301.8604857799,\n",
              "  447733.2137675746,\n",
              "  193135.72310271577,\n",
              "  10413.960365070396,\n",
              "  400.49957250084367,\n",
              "  10.985530119573722,\n",
              "  0.21491800837354608,\n",
              "  0.0029988684932305667,\n",
              "  2.9845225280935253e-05,\n",
              "  2.1184837024610783e-07,\n",
              "  1.0725269631729829e-09,\n",
              "  3.291872929075463e-11,\n",
              "  7.206273348629824e-13,\n",
              "  1.9719160146074268e-15,\n",
              "  3.848565853595951e-18,\n",
              "  5.357254229013603e-21]]"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights_first = [trajectory[0] for trajectory in weights]\n"
      ],
      "metadata": {
        "id": "fsu9StgFC5UA"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights_first"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmEx-WpwC-FU",
        "outputId": "eeed1cc6-afbf-4cf0-a28e-24aa8de7c279"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7132352941176471, 6.0625, 0.7132352941176471, 0.125, 0.7132352941176471]"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "states[0].astype(int)[:,0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6k1h2M-j_ur",
        "outputId": "98f2d6a9-cc37-4828-9d0b-7abf66df9714"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 0, 0, 0, 0, 1, 1, 2, 3, 4, 4, 5, 6, 6, 7, 8, 8, 7, 8, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
=======
        "s,p_s, p_w, g_w_l, s_f, s_l = test1.prepare()"
      ],
      "metadata": {
        "id": "QLqIwtmVu6Co"
      },
      "execution_count": null,
      "outputs": []
>>>>>>> 1086206d820f64abfe10a2f5230c7ec608c39474
    }
  ]
}